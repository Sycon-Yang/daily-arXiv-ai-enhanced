<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 62]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.DC](#cs.DC) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.PF](#cs.PF) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.LG](#cs.LG) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Argument Quality Annotation and Gender Bias Detection in Financial Communication through Large Language Models](https://arxiv.org/abs/2508.08262)
*Alaa Alhamzeh,Mays Al Rebdawi*

Main category: cs.CL

TL;DR: 本文评估了三个先进LLM在金融论点质量注释中的表现，并引入对抗性攻击来测试模型的公平性和鲁棒性，发现LLM生成的注释比人类注释更一致，但存在性别偏见。


<details>
  <summary>Details</summary>
Motivation: 评估金融论点的质量对于投资决策和公众对金融机构的信任至关重要，但目前的研究仍不充分。

Method: 本文评估了三个最先进的LLM（GPT-4o、Llama 3.1和Gemma 2）在FinArgQuality数据集上的论点质量注释能力，并引入了一种对抗性攻击来分析模型响应以确保公平性和鲁棒性。

Result: LLM生成的注释在一致性方面优于人类注释，但模型仍然表现出不同程度的性别偏见。

Conclusion: 本文提供了对LLM在金融沟通中注释论点质量能力的分析，并提出了未来研究的方向，以实现更可靠、成本效益高和无偏见的注释方法。

Abstract: Financial arguments play a critical role in shaping investment decisions and
public trust in financial institutions. Nevertheless, assessing their quality
remains poorly studied in the literature. In this paper, we examine the
capabilities of three state-of-the-art LLMs GPT-4o, Llama 3.1, and Gemma 2 in
annotating argument quality within financial communications, using the
FinArgQuality dataset. Our contributions are twofold. First, we evaluate the
consistency of LLM-generated annotations across multiple runs and benchmark
them against human annotations. Second, we introduce an adversarial attack
designed to inject gender bias to analyse models responds and ensure model's
fairness and robustness. Both experiments are conducted across three
temperature settings to assess their influence on annotation stability and
alignment with human labels. Our findings reveal that LLM-based annotations
achieve higher inter-annotator agreement than human counterparts, though the
models still exhibit varying degrees of gender bias. We provide a multifaceted
analysis of these outcomes and offer practical recommendations to guide future
research toward more reliable, cost-effective, and bias-aware annotation
methodologies.

</details>


### [2] [TurQUaz at CheckThat! 2025: Debating Large Language Models for Scientific Web Discourse Detection](https://arxiv.org/abs/2508.08265)
*Tarık Saraç,Selin Mergen,Mucahid Kutlu*

Main category: cs.CL

TL;DR: 本文提出了一种基于多模型辩论的科学内容检测方法，并在科学文献引用检测中取得了最佳成绩。


<details>
  <summary>Details</summary>
Motivation: 为了应对科学网络话语检测任务（CheckThat! 2025的Task 4a），我们开发了一种新的方法来提高对科学内容的识别能力。

Method: 我们提出了一个新颖的议会辩论方法，模拟多个大型语言模型（LLMs）之间的结构化学术讨论，以确定给定的推文是否包含科学声明、科学研究的参考或科学实体的提及。

Result: 我们的方法在检测科学文献引用方面表现最佳，但在识别科学声明和科学实体提及方面排名较低。

Conclusion: 虽然我们提出的方法在识别科学声明和科学实体提及方面排名不高，但在检测科学文献引用方面排名第一。

Abstract: In this paper, we present our work developed for the scientific web discourse
detection task (Task 4a) of CheckThat! 2025. We propose a novel council debate
method that simulates structured academic discussions among multiple large
language models (LLMs) to identify whether a given tweet contains (i) a
scientific claim, (ii) a reference to a scientific study, or (iii) mentions of
scientific entities. We explore three debating methods: i) single debate, where
two LLMs argue for opposing positions while a third acts as a judge; ii) team
debate, in which multiple models collaborate within each side of the debate;
and iii) council debate, where multiple expert models deliberate together to
reach a consensus, moderated by a chairperson model. We choose council debate
as our primary model as it outperforms others in the development test set.
Although our proposed method did not rank highly for identifying scientific
claims (8th out of 10) or mentions of scientific entities (9th out of 10), it
ranked first in detecting references to scientific studies.

</details>


### [3] [Heartificial Intelligence: Exploring Empathy in Language Models](https://arxiv.org/abs/2508.08271)
*Victoria Williams,Benjamin Rosman*

Main category: cs.CL

TL;DR: 本研究评估了语言模型在认知和情感共情方面的表现，发现大型语言模型在认知共情方面表现出色，但在情感共情方面仍逊于人类。这表明语言模型在提供虚拟陪伴和情感支持方面有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在全球范围内的广泛应用，了解它们在共情能力方面的表现变得尤为重要。本研究旨在评估语言模型在认知和情感共情方面的表现，以探讨它们在提供虚拟陪伴和情感支持方面的潜力。

Method: 本研究使用标准化的心理学测试，调查了多个小型语言模型（SLMs）和大型语言模型（LLMs）在认知和情感共情方面的表现。

Result: 研究结果表明，LLMs在认知共情任务中 consistently 超过了人类，包括心理学学生。然而，无论是小型还是大型语言模型，在情感共情方面都明显低于人类参与者。

Conclusion: 研究结果表明，语言模型在模拟认知共情方面取得了显著进展，显示出提供有效虚拟陪伴和个性化情感支持的潜力。此外，它们的高认知共情和较低的情感共情使得它们能够提供客观且一致的情感支持，而不会出现情感疲劳或偏见的风险。

Abstract: Large language models have become increasingly common, used by millions of
people worldwide in both professional and personal contexts. As these models
continue to advance, they are frequently serving as virtual assistants and
companions. In human interactions, effective communication typically involves
two types of empathy: cognitive empathy (understanding others' thoughts and
emotions) and affective empathy (emotionally sharing others' feelings). In this
study, we investigated both cognitive and affective empathy across several
small (SLMs) and large (LLMs) language models using standardized psychological
tests. Our results revealed that LLMs consistently outperformed humans -
including psychology students - on cognitive empathy tasks. However, despite
their cognitive strengths, both small and large language models showed
significantly lower affective empathy compared to human participants. These
findings highlight rapid advancements in language models' ability to simulate
cognitive empathy, suggesting strong potential for providing effective virtual
companionship and personalized emotional support. Additionally, their high
cognitive yet lower affective empathy allows objective and consistent emotional
support without running the risk of emotional fatigue or bias.

</details>


### [4] [Real-time News Story Identification](https://arxiv.org/abs/2508.08272)
*Tadej Škvorc,Nikola Ivačič,Sebastjan Hribar,Marko Robnik-Šikonja*

Main category: cs.CL

TL;DR: 本文提出了一种实时故事识别的方法，结合了文本表示技术、聚类算法和在线主题建模方法，如BERTopic、DBStream和TextClust，并在斯洛文尼亚媒体的数据集上进行了评估，结果显示该方法有效。


<details>
  <summary>Details</summary>
Motivation: 为了提高阅读体验，许多新闻网站将新闻组织成主题集合，称为故事。我们需要一种能够实时将文章分配到特定故事中的方法。

Method: 我们结合了文本表示技术、聚类算法和在线主题建模方法，如BERTopic、DBStream和TextClust，以实现实时故事识别。

Result: 我们在斯洛文尼亚媒体的一个为期一个月的新闻数据集上评估了我们的方法，结果表明我们的实时方法产生了合理的结果。

Conclusion: 我们的实时方法在人类评估者看来产生了合理的结果。

Abstract: To improve the reading experience, many news sites organize news into topical
collections, called stories. In this work, we present an approach for
implementing real-time story identification for a news monitoring system that
automatically collects news articles as they appear online and processes them
in various ways. Story identification aims to assign each news article to a
specific story that the article is covering. The process is similar to text
clustering and topic modeling, but requires that articles be grouped based on
particular events, places, and people, rather than general text similarity (as
in clustering) or general (predefined) topics (as in topic modeling). We
present an approach to story identification that is capable of functioning in
real time, assigning articles to stories as they are published online. In the
proposed approach, we combine text representation techniques, clustering
algorithms, and online topic modeling methods. We combine various text
representation methods to extract specific events and named entities necessary
for story identification, showing that a mixture of online topic-modeling
approaches such as BERTopic, DBStream, and TextClust can be adapted for story
discovery. We evaluate our approach on a news dataset from Slovene media
covering a period of 1 month. We show that our real-time approach produces
sensible results as judged by human evaluators.

</details>


### [5] [TT-XAI: Trustworthy Clinical Text Explanations via Keyword Distillation and LLM Reasoning](https://arxiv.org/abs/2508.08273)
*Kristian Miok,Blaz Škrlj,Daniela Zaharie,Marko Robnik Šikonja*

Main category: cs.CL

TL;DR: TT-XAI 是一种轻量级且有效的框架，通过领域感知关键词提炼和利用大型语言模型进行推理，提高了分类性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 临床语言模型在应用于长篇、非结构化的电子健康记录（EHRs）时，往往难以提供值得信赖的预测和解释。因此，需要一种方法来提高分类性能和可解释性。

Method: TT-XAI 框架通过领域感知关键词提炼和利用大型语言模型（LLMs）进行推理来提高分类性能和可解释性。首先，将原始出院记录提炼为简洁的关键词表示，以增强 BERT 分类器性能并提高局部解释的真实性。其次，使用基于关键词的提示生成思维链临床解释，以引导 LLMs，产生更简洁且临床上相关的推理。

Result: 所有评估模式一致支持基于关键词的方法，证实了提炼可以增强机器和人类的可解释性。

Conclusion: TT-XAI 提供了一种可扩展的路径，以实现临床决策支持中的可信和可审计的人工智能。

Abstract: Clinical language models often struggle to provide trustworthy predictions
and explanations when applied to lengthy, unstructured electronic health
records (EHRs). This work introduces TT-XAI, a lightweight and effective
framework that improves both classification performance and interpretability
through domain-aware keyword distillation and reasoning with large language
models (LLMs). First, we demonstrate that distilling raw discharge notes into
concise keyword representations significantly enhances BERT classifier
performance and improves local explanation fidelity via a focused variant of
LIME. Second, we generate chain-of-thought clinical explanations using
keyword-guided prompts to steer LLMs, producing more concise and clinically
relevant reasoning. We evaluate explanation quality using deletion-based
fidelity metrics, self-assessment via LLaMA-3 scoring, and a blinded human
study with domain experts. All evaluation modalities consistently favor the
keyword-augmented method, confirming that distillation enhances both machine
and human interpretability. TT-XAI offers a scalable pathway toward
trustworthy, auditable AI in clinical decision support.

</details>


### [6] [Distilling Knowledge from Large Language Models: A Concept Bottleneck Model for Hate and Counter Speech Recognition](https://arxiv.org/abs/2508.08274)
*Roberto Labadie-Tamayo,Djordje Slijepčević,Xihui Chen,Adrian Jaques Böck,Andreas Babic,Liz Freimann,Christiane Atzmüller Matthias Zeppelzauer*

Main category: cs.CL

TL;DR: 本文提出了一种新的透明方法，即“语音概念瓶颈模型”(SCBM)，用于自动化仇恨和反言论识别。SCBM利用大型语言模型将输入文本映射到基于形容词的抽象表示，然后将其发送到轻量级分类器进行下游任务。在多个基准数据集上，SCBM表现出色，并提供了高水平的可解释性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上仇恨言论的快速增长对社会产生了前所未有的影响，使得自动化检测此类内容变得重要。与之前的黑盒模型不同，我们提出了一个新颖的透明方法来进行自动化仇恨和反言论识别。

Method: 我们提出了一种新的透明方法，即“语音概念瓶颈模型”(SCBM)，使用形容词作为人类可解释的瓶颈概念。SCBM利用大型语言模型(LLMs)将输入文本映射到基于形容词的抽象表示，然后将其发送到轻量级分类器进行下游任务。

Result: 在跨越多种语言和平台的五个基准数据集（例如，Twitter、Reddit、YouTube）上，SCBM平均宏F1得分为0.69，优于文献中最近报告的结果，在五个数据集中的四个上表现更好。除了高识别准确率外，SCBM提供了高水平的局部和全局可解释性。此外，将我们的基于形容词的概念表示与变压器嵌入融合，平均性能提高了1.8%。

Conclusion: 我们的结果表明，基于形容词的概念表示可以作为仇恨和反言论识别的紧凑、可解释和有效的编码。通过调整形容词，我们的方法还可以应用于其他自然语言处理任务。

Abstract: The rapid increase in hate speech on social media has exposed an
unprecedented impact on society, making automated methods for detecting such
content important. Unlike prior black-box models, we propose a novel
transparent method for automated hate and counter speech recognition, i.e.,
"Speech Concept Bottleneck Model" (SCBM), using adjectives as
human-interpretable bottleneck concepts. SCBM leverages large language models
(LLMs) to map input texts to an abstract adjective-based representation, which
is then sent to a light-weight classifier for downstream tasks. Across five
benchmark datasets spanning multiple languages and platforms (e.g., Twitter,
Reddit, YouTube), SCBM achieves an average macro-F1 score of 0.69 which
outperforms the most recently reported results from the literature on four out
of five datasets. Aside from high recognition accuracy, SCBM provides a high
level of both local and global interpretability. Furthermore, fusing our
adjective-based concept representation with transformer embeddings, leads to a
1.8% performance increase on average across all datasets, showing that the
proposed representation captures complementary information. Our results
demonstrate that adjective-based concept representations can serve as compact,
interpretable, and effective encodings for hate and counter speech recognition.
With adapted adjectives, our method can also be applied to other NLP tasks.

</details>


### [7] [MLLM-CBench:A Comprehensive Benchmark for Continual Instruction Tuning of Multimodal LLMs with Chain-of-Thought Reasoning Analysis](https://arxiv.org/abs/2508.08275)
*Haiyun Guo,ZhiYan Hou,Yu Chen,Jinghan He,Yandu Sun,Yuzhe Zhou,Shujing Guo,Kuan Zhu,Jinqiao Wang*

Main category: cs.CL

TL;DR: MLLM-CTBench is a comprehensive evaluation benchmark for continual instruction tuning of Multimodal Large Language Models, offering insights into the effectiveness of different algorithms and training paradigms.


<details>
  <summary>Details</summary>
Motivation: To address the gap in rigorous and systematic benchmarks for continual instruction tuning in Multimodal Large Language Models (MLLMs).

Method: We present MLLM-CTBench, a comprehensive evaluation benchmark with three key contributions: (1) Multidimensional Evaluation, (2) Comprehensive Evaluation of Algorithms and Training Paradigms, (3) Carefully Curated Tasks.

Result: Our key findings include: (i) Models with stronger general capabilities exhibit greater robustness to forgetting during continual learning; (ii) Reasoning chains degrade more slowly than final answers, supporting the hierarchical forgetting hypothesis; (iii) The effectiveness of continual learning algorithms is highly dependent on both model capability and task order; (iv) In reinforcement learning settings, incorporating KL-divergence constraints helps maintain policy stability and plays a crucial role in mitigating forgetting.

Conclusion: MLLM-CTBench establishes a rigorous standard for continual instruction tuning of MLLMs and offers practical guidance for algorithm design and evaluation.

Abstract: Multimodal Large Language Models (MLLMs) rely on continual instruction tuning
to adapt to the evolving demands of real-world applications. However, progress
in this area is hindered by the lack of rigorous and systematic benchmarks. To
address this gap, we present MLLM-CTBench, a comprehensive evaluation benchmark
with three key contributions: (1) Multidimensional Evaluation: We combine final
answer accuracy with fine-grained CoT reasoning quality assessment, enabled by
a specially trained CoT evaluator; (2) Comprehensive Evaluation of Algorithms
and Training Paradigms: We benchmark eight continual learning algorithms across
four major categories and systematically compare reinforcement learning with
supervised fine-tuning paradigms; (3) Carefully Curated Tasks: We select and
organize 16 datasets from existing work, covering six challenging domains. Our
key findings include: (i) Models with stronger general capabilities exhibit
greater robustness to forgetting during continual learning; (ii) Reasoning
chains degrade more slowly than final answers, supporting the hierarchical
forgetting hypothesis; (iii) The effectiveness of continual learning algorithms
is highly dependent on both model capability and task order; (iv) In
reinforcement learning settings, incorporating KL-divergence constraints helps
maintain policy stability and plays a crucial role in mitigating forgetting.
MLLM-CTBench establishes a rigorous standard for continual instruction tuning
of MLLMs and offers practical guidance for algorithm design and evaluation.

</details>


### [8] [Evaluating Contrast Localizer for Identifying Causal Unitsin Social & Mathematical Tasks in Language Models](https://arxiv.org/abs/2508.08276)
*Yassine Jamaa,Badr AlKhamissi,Satrajit Ghosh,Martin Schrimpf*

Main category: cs.CL

TL;DR: 该研究通过对比刺激集定位大型语言模型和视觉-语言模型中的关键单元，并通过消融实验评估其因果作用，发现低激活单元有时对性能影响更大，且数学局部化器的单元可能对ToM任务产生更大负面影响。


<details>
  <summary>Details</summary>
Motivation: 研究旨在确定理论心理（ToM）和数学推理任务中与因果相关的关键单元，以更好地理解大型语言模型和视觉-语言模型的内部工作机制。

Method: 该研究将神经科学中的对比局部化器应用于大型语言模型（LLMs）和视觉-语言模型（VLMs），通过对比刺激集定位最高激活单元，并通过有针对性的消融实验评估其因果作用。

Result: 研究发现，低激活单元有时会导致比高激活单元更大的性能下降，而来自数学局部化器的单元往往比来自ToM局部化器的单元对ToM性能的损害更大。

Conclusion: 研究结果质疑了基于对比的局部化器的因果相关性，并强调需要更广泛的刺激集和更准确地捕捉任务特定单元。

Abstract: This work adapts a neuroscientific contrast localizer to pinpoint causally
relevant units for Theory of Mind (ToM) and mathematical reasoning tasks in
large language models (LLMs) and vision-language models (VLMs). Across 11 LLMs
and 5 VLMs ranging in size from 3B to 90B parameters, we localize top-activated
units using contrastive stimulus sets and assess their causal role via targeted
ablations. We compare the effect of lesioning functionally selected units
against low-activation and randomly selected units on downstream accuracy
across established ToM and mathematical benchmarks. Contrary to expectations,
low-activation units sometimes produced larger performance drops than the
highly activated ones, and units derived from the mathematical localizer often
impaired ToM performance more than those from the ToM localizer. These findings
call into question the causal relevance of contrast-based localizers and
highlight the need for broader stimulus sets and more accurately capture
task-specific units.

</details>


### [9] [Objective Metrics for Evaluating Large Language Models Using External Data Sources](https://arxiv.org/abs/2508.08277)
*Haoze Du,Richard Li,Edward Gehringer*

Main category: cs.CL

TL;DR: 本文提出了一种利用不同学期的类别文本材料得出的主观指标来评估大型语言模型在各种任务中的输出的框架，确保了持续、可重复和最小偏差的测量，并减少了对人类解释的依赖。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）的性能是一个关键但具有挑战性的任务，尤其是在避免主观评估方面。

Method: 本文提出了一种框架，利用不同学期的类别文本材料得出的主观指标来评估大型语言模型在各种任务中的输出。通过使用明确的基准、事实数据集和结构化的评估流程，该方法确保了持续、可重复和最小偏差的测量。

Result: 该框架强调评分的自动化和透明度，减少了对人类解释的依赖，同时确保与现实应用的一致性。

Conclusion: 该方法解决了主观评估方法的局限性，提供了一种可扩展的性能评估解决方案，适用于教育、科学和其他高风险领域。

Abstract: Evaluating the performance of Large Language Models (LLMs) is a critical yet
challenging task, particularly when aiming to avoid subjective assessments.
This paper proposes a framework for leveraging subjective metrics derived from
the class textual materials across different semesters to assess LLM outputs
across various tasks. By utilizing well-defined benchmarks, factual datasets,
and structured evaluation pipelines, the approach ensures consistent,
reproducible, and bias-minimized measurements. The framework emphasizes
automation and transparency in scoring, reducing reliance on human
interpretation while ensuring alignment with real-world applications. This
method addresses the limitations of subjective evaluation methods, providing a
scalable solution for performance assessment in educational, scientific, and
other high-stakes domains.

</details>


### [10] [MinionsLLM: a Task-adaptive Framework For The Training and Control of Multi-Agent Systems Through Natural Language](https://arxiv.org/abs/2508.08283)
*Andres Garcia Rincon,Eliseo Ferrante*

Main category: cs.CL

TL;DR: 本文提出了MinionsLLM，这是一种将大型语言模型（LLMs）与行为树（BTs）和形式语法相结合的新框架，用于在任意用户定义的环境中实现多智能体系统的自然语言控制。MinionsLLM提供了标准化的接口来定义环境、代理和行为原语，并引入了两种合成数据集生成方法（方法A和方法B）来微调LLMs以提高语法有效性和语义任务相关性。我们使用Google的Gemma 3模型系列在三个参数规模（1B、4B和12B）上验证了我们的方法，并展示了显著的提升：方法B将语法有效性提高到92.6%，并在平均任务性能上比基线提高了33%。值得注意的是，我们的实验表明较小的模型从微调中受益最大，这为在资源受限的多智能体控制场景中部署紧凑的本地托管LLMs提供了有希望的方向。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决多智能体系统在任意用户定义的环境中进行自然语言控制的问题，并通过整合大型语言模型（LLMs）、行为树（BTs）和形式语法来实现这一目标。

Method: 本文提出了MinionsLLM，这是一种将大型语言模型（LLMs）与行为树（BTs）和形式语法相结合的新框架，用于在任意用户定义的环境中实现多智能体系统的自然语言控制。MinionsLLM提供了标准化的接口来定义环境、代理和行为原语，并引入了两种合成数据集生成方法（方法A和方法B）来微调LLMs以提高语法有效性和语义任务相关性。

Result: 本文使用Google的Gemma 3模型系列在三个参数规模（1B、4B和12B）上验证了我们的方法，并展示了显著的提升：方法B将语法有效性提高到92.6%，并在平均任务性能上比基线提高了33%。值得注意的是，我们的实验表明较小的模型从微调中受益最大，这为在资源受限的多智能体控制场景中部署紧凑的本地托管LLMs提供了有希望的方向。

Conclusion: 本文提出了MinionsLLM，这是一种将大型语言模型（LLMs）与行为树（BTs）和形式语法相结合的新框架，用于在任意用户定义的环境中实现多智能体系统的自然语言控制。MinionsLLM提供了标准化的接口来定义环境、代理和行为原语，并引入了两种合成数据集生成方法（方法A和方法B）来微调LLMs以提高语法有效性和语义任务相关性。我们使用Google的Gemma 3模型系列在三个参数规模（1B、4B和12B）上验证了我们的方法，并展示了显著的提升：方法B将语法有效性提高到92.6%，并在平均任务性能上比基线提高了33%。值得注意的是，我们的实验表明较小的模型从微调中受益最大，这为在资源受限的多智能体控制场景中部署紧凑的本地托管LLMs提供了有希望的方向。该框架和所有资源均已开源，以支持可重复性和未来研究。

Abstract: This paper presents MinionsLLM, a novel framework that integrates Large
Language Models (LLMs) with Behavior Trees (BTs) and Formal Grammars to enable
natural language control of multi-agent systems within arbitrary, user-defined
environments. MinionsLLM provides standardized interfaces for defining
environments, agents, and behavioral primitives, and introduces two synthetic
dataset generation methods (Method A and Method B) to fine-tune LLMs for
improved syntactic validity and semantic task relevance. We validate our
approach using Google's Gemma 3 model family at three parameter scales (1B, 4B,
and 12B) and demonstrate substantial gains: Method B increases syntactic
validity to 92.6% and achieves a mean task performance improvement of 33% over
baseline. Notably, our experiments show that smaller models benefit most from
fine-tuning, suggesting promising directions for deploying compact, locally
hosted LLMs in resource-constrained multi-agent control scenarios. The
framework and all resources are released open-source to support reproducibility
and future research.

</details>


### [11] [The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs](https://arxiv.org/abs/2508.08285)
*Denis Janiak,Jakub Binkowski,Albert Sawczyn,Bogdan Gabrys,Ravid Schwartz-Ziv,Tomasz Kajdanowicz*

Main category: cs.CL

TL;DR: 本文指出当前幻觉检测方法的评估存在严重问题，建议采用更符合人类判断的评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法（如ROUGE）在衡量幻觉检测方法时存在偏差，无法准确反映人类判断。

Method: 通过全面的人类研究，我们分析了现有评估方法的不足，并提出了基于语义的评估框架。

Result: 实验结果表明，一些现有的检测方法在使用人类对齐的指标（如LLM-as-Judge）时，性能下降高达45.9%。此外，基于响应长度的简单启发式方法可以与复杂的检测技术相媲美。

Conclusion: 我们主张采用语义意识和稳健的评估框架，以准确衡量幻觉检测方法的真实性能，最终确保LLM输出的可信度。

Abstract: Large language models (LLMs) have revolutionized natural language processing,
yet their tendency to hallucinate poses serious challenges for reliable
deployment. Despite numerous hallucination detection methods, their evaluations
often rely on ROUGE, a metric based on lexical overlap that misaligns with
human judgments. Through comprehensive human studies, we demonstrate that while
ROUGE exhibits high recall, its extremely low precision leads to misleading
performance estimates. In fact, several established detection methods show
performance drops of up to 45.9\% when assessed using human-aligned metrics
like LLM-as-Judge. Moreover, our analysis reveals that simple heuristics based
on response length can rival complex detection techniques, exposing a
fundamental flaw in current evaluation practices. We argue that adopting
semantically aware and robust evaluation frameworks is essential to accurately
gauge the true performance of hallucination detection methods, ultimately
ensuring the trustworthiness of LLM outputs.

</details>


### [12] [Sacred or Synthetic? Evaluating LLM Reliability and Abstention for Religious Questions](https://arxiv.org/abs/2508.08287)
*Farah Atif,Nursultan Askarbekuly,Kareem Darwish,Monojit Choudhury*

Main category: cs.CL

TL;DR: 本文介绍了一个名为FiqhQA的新基准，用于评估大型语言模型在伊斯兰教法裁决生成中的表现，并强调了在宗教应用中对LLM进行任务特定评估和谨慎部署的必要性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在回答各种领域的问题中越来越受欢迎，但它们在宗教领域中的可靠性和准确性仍未得到充分研究。此外，之前的工作要么忽略了宗教学派之间的差异，要么未能评估回避行为。

Method: 我们引入了一个名为FiqhQA的新基准，专注于LLM生成的伊斯兰裁决，并根据四大主要逊尼派法学派进行分类。我们评估了LLM在准确性以及识别何时不回答的能力方面的表现。

Result: 零样本和回避实验揭示了LLM、语言和法律学派之间的显著差异。GPT-4o在准确性方面优于其他所有模型，而Gemini和Fanar在回避行为方面表现出色，这对于减少自信的错误答案至关重要。值得注意的是，所有模型在阿拉伯语中的表现都下降了，这表明在英语以外的语言中宗教推理存在局限性。

Conclusion: 我们的研究强调了在宗教应用中对LLM进行任务特定评估和谨慎部署的必要性。

Abstract: Despite the increasing usage of Large Language Models (LLMs) in answering
questions in a variety of domains, their reliability and accuracy remain
unexamined for a plethora of domains including the religious domains. In this
paper, we introduce a novel benchmark FiqhQA focused on the LLM generated
Islamic rulings explicitly categorized by the four major Sunni schools of
thought, in both Arabic and English. Unlike prior work, which either overlooks
the distinctions between religious school of thought or fails to evaluate
abstention behavior, we assess LLMs not only on their accuracy but also on
their ability to recognize when not to answer. Our zero-shot and abstention
experiments reveal significant variation across LLMs, languages, and legal
schools of thought. While GPT-4o outperforms all other models in accuracy,
Gemini and Fanar demonstrate superior abstention behavior critical for
minimizing confident incorrect answers. Notably, all models exhibit a
performance drop in Arabic, highlighting the limitations in religious reasoning
for languages other than English. To the best of our knowledge, this is the
first study to benchmark the efficacy of LLMs for fine-grained Islamic school
of thought specific ruling generation and to evaluate abstention for Islamic
jurisprudence queries. Our findings underscore the need for task-specific
evaluation and cautious deployment of LLMs in religious applications.

</details>


### [13] [Putnam-AXIOM: A Functional and Static Benchmark](https://arxiv.org/abs/2508.08292)
*Aryan Gulati,Brando Miranda,Eric Chen,Emily Xia,Kai Fronsdal,Bruno Dumont,Elyas Obbad,Sanmi Koyejo*

Main category: cs.CL

TL;DR: 本文介绍了 Putnam-AXIOM 基准测试，用于评估大型语言模型的高级数学推理能力，强调了动态和抗污染测试的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前的数学推理基准测试接近饱和，且受训练集污染的影响越来越大。需要一种动态的、抗污染的基准测试来评估大型语言模型的数学推理能力。

Method: 引入了 Putnam-AXIOM 基准测试，包含 522 道大学级别的竞赛问题，并生成了 100 道功能变体以创建无限的未见过的实例。同时，引入了 Teacher-Forced Accuracy (TFA) 轻量级指标来直接评分推理轨迹。

Result: 在原始数据集上，OpenAI 的 o1-preview 模型得分仅为 41.9%，但在配对的变体上准确率下降了 19.6%。其余模型也表现出类似的下降趋势，表明存在记忆化现象。

Conclusion: Putnam-AXIOM 提供了一个严格且抗污染的评估框架，用于评估大型语言模型的高级数学推理能力。

Abstract: Current mathematical reasoning benchmarks for large language models (LLMs)
are approaching saturation, with some achieving > 90% accuracy, and are
increasingly compromised by training-set contamination. We introduce
Putnam-AXIOM, a benchmark of 522 university-level competition problems drawn
from the prestigious William Lowell Putnam Mathematical Competition, and
Putnam-AXIOM Variation, an unseen companion set of 100 functional variants
generated by programmatically perturbing variables and constants. The variation
protocol produces an unlimited stream of equally difficult, unseen instances --
yielding a contamination-resilient test bed. On the Original set, OpenAI's
o1-preview -- the strongest evaluated model -- scores 41.9%, but its accuracy
drops by 19.6% (46.8% relative decrease) on the paired Variations. The
remaining eighteen models show the same downward trend, ten of them with
non-overlapping 95% confidence intervals. These gaps suggest memorization and
highlight the necessity of dynamic benchmarks. We complement "boxed" accuracy
with Teacher-Forced Accuracy (TFA), a lightweight metric that directly scores
reasoning traces and automates natural language proof evaluations. Putnam-AXIOM
therefore provides a rigorous, contamination-resilient evaluation framework for
assessing advanced mathematical reasoning of LLMs. Data and evaluation code are
publicly available at https://github.com/brando90/putnam-axiom.

</details>


### [14] [CoDAE: Adapting Large Language Models for Education via Chain-of-Thought Data Augmentation](https://arxiv.org/abs/2508.08386)
*Shuzhou Yuan,William LaCroix,Hardik Ghoshal,Ercong Nie,Michael Färber*

Main category: cs.CL

TL;DR: 本文提出CoDAE框架，通过链式思维数据增强来改进大型语言模型在教育中的应用，使其能够提供更合适的教学指导并提高对情绪操纵提示的抵抗力。


<details>
  <summary>Details</summary>
Motivation: 由于现成的LLM在教育环境中表现不佳，例如容易泄露答案、无法适应学生的不确定性以及容易受到情绪操纵提示的影响，因此需要一种方法来改进这些模型以更好地服务于教育目的。

Method: 引入CoDAE框架，通过链式思维数据增强来适应LLM用于教育。收集学生与基于ChatGPT的导师之间的实际对话，并使用CoT提示来促进逐步推理和符合教学的指导。设计有针对性的对话案例以解决三个主要限制：过度服从、低响应适应性和威胁易感性。对四个开源LLM进行微调，并在模拟教育场景中评估它们。

Result: 经过CoDAE微调的模型提供了更符合教育的指导，更好地支持推理过程，并有效抵抗过早的答案披露。

Conclusion: 模型经过CoDAE微调后能提供更符合教育的指导，更好地支持推理过程，并有效防止过早透露答案。

Abstract: Large Language Models (LLMs) are increasingly employed as AI tutors due to
their scalability and potential for personalized instruction. However,
off-the-shelf LLMs often underperform in educational settings: they frequently
reveal answers too readily, fail to adapt their responses to student
uncertainty, and remain vulnerable to emotionally manipulative prompts. To
address these challenges, we introduce CoDAE, a framework that adapts LLMs for
educational use through Chain-of-Thought (CoT) data augmentation. We collect
real-world dialogues between students and a ChatGPT-based tutor and enrich them
using CoT prompting to promote step-by-step reasoning and pedagogically aligned
guidance. Furthermore, we design targeted dialogue cases to explicitly mitigate
three key limitations: over-compliance, low response adaptivity, and threat
vulnerability. We fine-tune four open-source LLMs on different variants of the
augmented datasets and evaluate them in simulated educational scenarios using
both automatic metrics and LLM-as-a-judge assessments. Our results show that
models fine-tuned with CoDAE deliver more pedagogically appropriate guidance,
better support reasoning processes, and effectively resist premature answer
disclosure.

</details>


### [15] [Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery](https://arxiv.org/abs/2508.08401)
*Jiatong Li,Weida Wang,Qinggang Zhang,Junxian Li,Di Zhang,Changmeng Zheng,Shufei Zhang,Xiaoyong Wei,Qing Li*

Main category: cs.CL

TL;DR: Mol-R1 is a framework that enhances the reasoning capabilities of large language models in molecule discovery by using a specialized dataset and training strategy.


<details>
  <summary>Details</summary>
Motivation: The motivation is to improve the explainability and reasoning performance of R1-like Explicit Long-CoT reasoning large language models in knowledge-intensive domains such as molecule discovery.

Method: Mol-R1 utilizes a high-quality reasoning dataset generated through Prior Regulation via In-context Distillation (PRID) and a training strategy called Molecular Iterative Adaptation (MoIA), which combines Supervised Fine-tuning (SFT) with Reinforced Policy Optimization (RPO).

Result: Mol-R1 shows superior performance in text-based molecule reasoning generation tasks compared to existing baselines.

Conclusion: Mol-R1 demonstrates superior performance in text-based molecule reasoning generation compared to existing baselines.

Abstract: Large language models (LLMs), especially Explicit Long Chain-of-Thought (CoT)
reasoning models like DeepSeek-R1 and QWQ, have demonstrated powerful reasoning
capabilities, achieving impressive performance in commonsense reasoning and
mathematical inference. Despite their effectiveness, Long-CoT reasoning models
are often criticized for their limited ability and low efficiency in
knowledge-intensive domains such as molecule discovery. Success in this field
requires a precise understanding of domain knowledge, including molecular
structures and chemical principles, which is challenging due to the inherent
complexity of molecular data and the scarcity of high-quality expert
annotations. To bridge this gap, we introduce Mol-R1, a novel framework
designed to improve explainability and reasoning performance of R1-like
Explicit Long-CoT reasoning LLMs in text-based molecule generation. Our
approach begins with a high-quality reasoning dataset curated through Prior
Regulation via In-context Distillation (PRID), a dedicated distillation
strategy to effectively generate paired reasoning traces guided by prior
regulations. Building upon this, we introduce MoIA, Molecular Iterative
Adaptation, a sophisticated training strategy that iteratively combines
Supervised Fine-tuning (SFT) with Reinforced Policy Optimization (RPO),
tailored to boost the reasoning performance of R1-like reasoning models for
molecule discovery. Finally, we examine the performance of Mol-R1 in the
text-based molecule reasoning generation task, showing superior performance
against existing baselines.

</details>


### [16] [Rethinking Tokenization for Rich Morphology: The Dominance of Unigram over BPE and Morphological Alignment](https://arxiv.org/abs/2508.08424)
*Saketh Reddy Vemula,Dipti Mishra Sharma,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: 研究发现形态对齐与基于语法的任务性能有正相关，但字节对编码算法对下游性能的影响更大。简单Unigram分词器表现良好，而结合形态分割的混合分词器在BPE框架中表现更优。


<details>
  <summary>Details</summary>
Motivation: 研究形态对齐的分词方法是否能提高语言模型的性能，特别是对于形态复杂的语言。

Method: 选择了一组语言学多样的语言（泰卢固语、印地语和英语），并进行了全面的语言模型评估，包括分词器训练、微调和下游任务评估。为了评估分词器的形态对齐，创建了一个包含600个派生和7000个屈折词形的黄金形态分割数据集。

Result: 形态对齐与基于语法的任务性能呈正相关，但字节对编码（BPE）算法在影响下游性能方面比形态对齐本身更为重要。简单的Unigram分词器在大多数情况下表现优于其他分词器，尽管结合形态分割的混合分词器在BPE框架内显著提高了性能。内在指标如语料库词数（CTC）和Rényi熵与下游性能无关。

Conclusion: 实验结果表明，更好的形态对齐与基于语法的任务性能呈正相关，但字节对编码（BPE）算法在影响下游性能方面比形态对齐本身更为重要。简单的Unigram分词器在大多数情况下表现优于其他分词器，尽管结合形态分割的混合分词器在BPE框架内显著提高了性能。内在指标如语料库词数（CTC）和Rényi熵与下游性能无关。

Abstract: Prior work on language modeling showed conflicting findings about whether
morphologically aligned approaches to tokenization improve performance,
particularly for languages with complex morphology. To investigate this, we
select a typologically diverse set of languages: Telugu (agglutinative), Hindi
(primarily fusional with some agglutination), and English (fusional). We
conduct a comprehensive evaluation of language models -- starting from
tokenizer training and extending through the finetuning and downstream task
evaluation. To account for the consistent performance differences observed
across tokenizer variants, we focus on two key factors: morphological alignment
and tokenization quality. To assess morphological alignment of tokenizers in
Telugu, we create a dataset containing gold morpheme segmentations of 600
derivational and 7000 inflectional word forms.
  Our experiments reveal that better morphological alignment correlates
positively -- though moderately -- with performance in syntax-based tasks such
as Parts-of-Speech tagging, Named Entity Recognition and Dependency Parsing.
However, we also find that the tokenizer algorithm (Byte-pair Encoding vs.
Unigram) plays a more significant role in influencing downstream performance
than morphological alignment alone. Naive Unigram tokenizers outperform others
across most settings, though hybrid tokenizers that incorporate morphological
segmentation significantly improve performance within the BPE framework. In
contrast, intrinsic metrics like Corpus Token Count (CTC) and R\'enyi entropy
showed no correlation with downstream performance.

</details>


### [17] [Enhancing Small LLM Alignment through Margin-Based Objective Modifications under Resource Constraints](https://arxiv.org/abs/2508.08466)
*Daren Yao,Jinsong Yuan,Ruike Chen*

Main category: cs.CL

TL;DR: 本文提出了两种轻量级DPO变体，以改善小型LLM在性能不足情况下的对齐问题，并在多个基准测试中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 小型大语言模型（LLM）在将输出与人类偏好对齐方面常常面临困难，尤其是在性能差距较大的情况下。

Method: 提出两种轻量级DPO变体——自适应边距-Sigmoid损失和APO-hinge-zero，通过引入基于边距的目标和选择性更新机制来更好地处理性能不足的情况。

Result: APO-hinge-zero方法在AlpacaEval中将胜率提高了+2.0点，在长度控制的胜率上提高了+1.4点；在MT-Bench中，方法在不同类别中保持了竞争力，尤其在STEM和人文学科任务中表现出色。

Conclusion: 这些结果表明，在资源受限的情况下，对基于偏好的目标进行简单的修改可以显著提高小型LLM的对齐效果，为更高效的部署提供了一条实用的路径。

Abstract: Small large language models (LLMs) often face difficulties in aligning output
to human preferences, particularly when operating under severe performance
gaps. In this work, we propose two lightweight DPO-based variants -- Adaptive
Margin-Sigmoid Loss and APO-hinge-zero -- to better address underperformance
scenarios by introducing margin-based objectives and selective update
mechanisms.
  Our APO-hinge-zero method, which combines hinge-induced hard-example mining
with the chosen-focused optimization of APO-zero, achieves strong results. In
AlpacaEval, APO-hinge-zero improves the win rate by +2.0 points and the
length-controlled win rate by +1.4 points compared to the APO-zero baseline. In
MT-Bench, our methods maintain competitive performance in diverse categories,
particularly excelling in STEM and Humanities tasks.
  These results demonstrate that simple modifications to preference-based
objectives can significantly enhance small LLM alignment under resource
constraints, offering a practical path toward more efficient deployment.

</details>


### [18] [Momentum Point-Perplexity Mechanics in Large Language Models](https://arxiv.org/abs/2508.08492)
*Lorenzo Tomaz,Judd Rosenblatt,Thomas Berry Jones,Diogo Schwerz de Lucena*

Main category: cs.CL

TL;DR: 本文通过物理方法研究了大型语言模型在推理过程中隐藏状态的变化，并发现一种类似于能量的量几乎保持恒定。基于此，开发了一种新的控制方法，能够以最小的方式扰动隐藏状态以偏向目标标记，从而提高模型的可预测性和与人类意图的一致性。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在推理过程中隐藏状态的变化，以理解模型的行为并开发新的控制方法。

Method: 采用物理方法研究大型语言模型在推理过程中隐藏状态的变化，通过分析隐藏状态的变化率和模型的下一个标记确定性，发现一种类似于物理学中能量的量几乎保持恒定。

Result: 发现随机权重模型比预训练模型更严格地保持这种“能量”，而训练会使模型进入更快、更果断的模式。使用“对数拉格朗日”视角，开发了一种称为雅可比引导的控制方法，该方法以最小的方式扰动隐藏状态以偏向目标标记。

Conclusion: 通过将变压器模型视为力学系统，可以为可解释性、异常检测和低风险控制提供一个原理基础，这有助于使强大的模型更加可预测并与人类意图对齐。

Abstract: We take a physics-based approach to studying how the internal hidden states
of large language models change from token to token during inference. Across 20
open-source transformer models (135M-3B parameters), we find that a quantity
combining the rate of change in hidden states and the model's next-token
certainty, analogous to energy in physics, remains nearly constant.
Random-weight models conserve this "energy" more tightly than pre-trained ones,
while training shifts models into a faster, more decisive regime with greater
variability. Using this "log-Lagrangian" view, we derive a control method
called Jacobian steering, which perturbs hidden states in the minimal way
needed to favor a target token. This approach maintained near-constant energy
in two tested models and produced continuations rated higher in semantic
quality than the models' natural outputs. Viewing transformers through this
mechanics lens offers a principled basis for interpretability, anomaly
detection, and low-risk steering. This could help make powerful models more
predictable and aligned with human intent.

</details>


### [19] [Steerable Pluralism: Pluralistic Alignment via Few-Shot Comparative Regression](https://arxiv.org/abs/2508.08509)
*Jadie Adams,Brian Hu,Emily Veenhuis,David Joy,Bharadwaj Ravichandran,Aaron Bray,Anthony Hoogs,Arslan Basharat*

Main category: cs.CL

TL;DR: 本文提出了一种基于少量样本比较回归的可调节多元模型，能够适应个体用户偏好，并在价值对齐决策和奖励建模方面展示了其适用性。该方法优于多个基线和最先进的方法，为多元对齐提供了新的见解和研究方向。


<details>
  <summary>Details</summary>
Motivation: 当前的大语言模型对齐技术主要依赖于标量奖励，只能反映用户偏好的平均值。然而，多元对齐旨在捕捉跨一组属性的多样化用户偏好，超越了有用性和无害性的范畴。因此，需要一种能够适应个体用户偏好的方法。

Method: 本文提出了一种基于少量样本比较回归的可调节多元模型，该模型利用上下文学习和推理，基于一组细粒度属性来比较响应选项并做出对齐选择。此外，还提出了两个新的可调节多元基准测试，以评估算法的有效性。

Result: 本文提出的少量样本比较回归方法具有可解释性，并且与不同的属性和大语言模型兼容，同时优于多个基线和最先进的方法。此外，通过两个新的可调节多元基准测试验证了方法的有效性。

Conclusion: 本文提出了一个可调节的多元对齐模型，能够适应个体用户偏好，并在价值对齐决策和奖励建模方面展示了其适用性。同时，该方法优于多个基线和最先进的方法，为多元对齐提供了新的见解和研究方向，有助于更公平和代表性的使用大语言模型，并推动伦理AI的发展。

Abstract: Large language models (LLMs) are currently aligned using techniques such as
reinforcement learning from human feedback (RLHF). However, these methods use
scalar rewards that can only reflect user preferences on average. Pluralistic
alignment instead seeks to capture diverse user preferences across a set of
attributes, moving beyond just helpfulness and harmlessness. Toward this end,
we propose a steerable pluralistic model based on few-shot comparative
regression that can adapt to individual user preferences. Our approach
leverages in-context learning and reasoning, grounded in a set of fine-grained
attributes, to compare response options and make aligned choices. To evaluate
our algorithm, we also propose two new steerable pluralistic benchmarks by
adapting the Moral Integrity Corpus (MIC) and the HelpSteer2 datasets,
demonstrating the applicability of our approach to value-aligned
decision-making and reward modeling, respectively. Our few-shot comparative
regression approach is interpretable and compatible with different attributes
and LLMs, while outperforming multiple baseline and state-of-the-art methods.
Our work provides new insights and research directions in pluralistic
alignment, enabling a more fair and representative use of LLMs and advancing
the state-of-the-art in ethical AI.

</details>


### [20] [DeCAL Tokenwise Compression](https://arxiv.org/abs/2508.08514)
*Sameer Panwar*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper introduces DeCAL, a new method for tokenwise compression. DeCAL
uses an encoder-decoder language model pretrained with denoising to learn to
produce high-quality, general-purpose compressed representations by the
encoder. DeCAL applies small modifications to the encoder, with the emphasis on
maximizing compression quality, even at the expense of compute. We show that
DeCAL at 2x compression can match uncompressed on many downstream tasks, with
usually only minor dropoff in metrics up to 8x compression, among
question-answering, summarization, and multi-vector retrieval tasks. DeCAL
offers significant savings where pre-computed dense representations can be
utilized, and we believe the approach can be further developed to be more
broadly applicable.

</details>


### [21] [DepressLLM: Interpretable domain-adapted language model for depression detection from real-world narratives](https://arxiv.org/abs/2508.08591)
*Sehwan Moon,Aram Lee,Jeong Eun Kim,Hee-Ju Kang,Il-Seon Shin,Sung-Wan Kim,Jae-Min Kim,Min Jhon,Ju-Wan Kim*

Main category: cs.CL

TL;DR: 该研究引入了DepressLLM，一种基于自传体叙述的可解释抑郁症预测模型，并展示了其在不同数据集上的性能和未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 抑郁症预测受到缺乏大规模、高质量和严格注释的数据集的阻碍。

Method: DepressLLM通过其Score-guided Token Probability Summation (SToPS)模块提供可解释的抑郁症预测，并在具有3,699个自传体叙述的新型语料库上进行训练和评估。

Result: DepressLLM在自信度≥0.95的样本上实现了AUC 0.789，甚至达到了0.904。此外，在内部数据集和公共临床访谈数据上验证了其对异构数据的鲁棒性。

Conclusion: 这些发现表明，可解释的人工智能可以实现抑郁症的早期诊断，并强调了医疗人工智能在精神病学中的前景。

Abstract: Advances in large language models (LLMs) have enabled a wide range of
applications. However, depression prediction is hindered by the lack of
large-scale, high-quality, and rigorously annotated datasets. This study
introduces DepressLLM, trained and evaluated on a novel corpus of 3,699
autobiographical narratives reflecting both happiness and distress. DepressLLM
provides interpretable depression predictions and, via its Score-guided Token
Probability Summation (SToPS) module, delivers both improved classification
performance and reliable confidence estimates, achieving an AUC of 0.789, which
rises to 0.904 on samples with confidence $\geq$ 0.95. To validate its
robustness to heterogeneous data, we evaluated DepressLLM on in-house datasets,
including an Ecological Momentary Assessment (EMA) corpus of daily stress and
mood recordings, and on public clinical interview data. Finally, a psychiatric
review of high-confidence misclassifications highlighted key model and data
limitations that suggest directions for future refinements. These findings
demonstrate that interpretable AI can enable earlier diagnosis of depression
and underscore the promise of medical AI in psychiatry.

</details>


### [22] [Optimizing Retrieval-Augmented Generation (RAG) for Colloquial Cantonese: A LoRA-Based Systematic Review](https://arxiv.org/abs/2508.08610)
*David Santandreu Calonge,Linda Smail*

Main category: cs.CL

TL;DR: 本文回顾了参数高效微调（PEFT）的最新进展，特别是低秩适应（LoRA），以优化检索增强生成（RAG）系统。研究发现，动态和集成LoRA适应方法显著减少了可训练参数，同时保持了检索准确性和生成质量。然而，在完全保留细粒度语言细微差别方面仍存在局限，特别是在资源匮乏的语境中。本文强调了PEFT增强的RAG系统在特定领域语言任务中的潜力，并呼吁未来的研究关注方言真实性、动态适应和可扩展的微调管道。


<details>
  <summary>Details</summary>
Motivation: RAG系统在理解和生成真实粤语口语表达方面面临挑战，由于标注数据有限和语言变异性。本文旨在评估LoRA在RAG框架中的整合，基准测试PEFT方法的检索和生成准确性，识别有限数据下的领域适应策略，并比较旨在提高数据稀缺条件下语义保真度的微调技术。

Method: 本文对最近采用多种LoRA变体、合成数据生成、用户反馈整合和自适应参数分配的研究进行了系统分析，以评估它们对计算效率、检索精度、语言真实性和可扩展性的影响。

Result: 研究结果表明，动态和集成LoRA适应方法显著减少了可训练参数，同时保持了检索准确性和生成质量。然而，在完全保留细粒度语言细微差别方面仍存在局限，特别是在资源匮乏的语境中。实时用户反馈和领域特定数据的整合仍不完善，限制了模型的适应性和个性化。选择性参数冻结和非线性适应方法提供了更好的效率与准确性权衡，但其在大规模应用中的鲁棒性仍是开放挑战。

Conclusion: 本文回顾了参数高效微调（PEFT）的最新进展，特别是低秩适应（LoRA），以优化检索增强生成（RAG）系统。研究发现，动态和集成LoRA适应方法显著减少了可训练参数，同时保持了检索准确性和生成质量。然而，在完全保留细粒度语言细微差别方面仍存在局限，特别是在资源匮乏的语境中。本文强调了PEFT增强的RAG系统在特定领域语言任务中的潜力，并呼吁未来的研究关注方言真实性、动态适应和可扩展的微调管道。

Abstract: This review examines recent advances in Parameter-Efficient Fine-Tuning
(PEFT), with a focus on Low-Rank Adaptation (LoRA), to optimize
Retrieval-Augmented Generation (RAG) systems like Qwen3, DeepSeek, and Kimi.
These systems face challenges in understanding and generating authentic
Cantonese colloquial expressions due to limited annotated data and linguistic
variability. The review evaluates the integration of LoRA within RAG
frameworks, benchmarks PEFT methods for retrieval and generation accuracy,
identify domain adaptation strategies under limited data, and compares
fine-tuning techniques aimed at improving semantic fidelity under data-scarce
conditions. A systematic analysis of recent studies employing diverse LoRA
variants, synthetic data generation, user feedback integration, and adaptive
parameter allocation was conducted to assess their impact on computational
efficiency, retrieval precision, linguistic authenticity, and scalability.
Findings reveal that dynamic and ensemble LoRA adaptations significantly reduce
trainable parameters without sacrificing retrieval accuracy and generation
quality in dialectal contexts. However, limitations remain in fully preserving
fine-grained linguistic nuances, especially for low-resource settings like
Cantonese. The integration of real-time user feedback and domain-specific data
remains underdeveloped, limiting model adaptability and personalization. While
selective parameter freezing and nonlinear adaptation methods offer better
trade-offs between efficiency and accuracy, their robustness at scale remains
an open challenge. This review highlights the promise of PEFT-enhanced RAG
systems for domain-specific language tasks and calls for future work targeting
dialectal authenticity, dynamic adaptation, and scalable fine-tuning pipelines.

</details>


### [23] [InternBootcamp Technical Report: Boosting LLM Reasoning with Verifiable Task Scaling](https://arxiv.org/abs/2508.08636)
*Peiji Li,Jiasheng Ye,Yongkang Chen,Yichuan Ma,Zijie Yu,Kedi Chen,Ganqu Cui,Haozhan Li,Jiacheng Chen,Chengqi Lyu,Wenwei Zhang,Linyang Li,Qipeng Guo,Dahua Lin,Bowen Zhou,Kai Chen*

Main category: cs.CL

TL;DR: 本文介绍了InternBootcamp，一个用于LLM推理研究的开源框架，包含1000多个领域多样的任务环境。该框架提供自动生成功能和集成验证模块，有助于RL模型优化、合成数据生成和模型评估。通过自动化代理工作流和手动验证协议，我们快速扩展了任务范围，并建立了Bootcamp-EVAL基准。评估显示，使用InternBootcamp训练可以显著提高模型性能，使我们的32B模型在多个基准上取得最佳结果。


<details>
  <summary>Details</summary>
Motivation: 现实世界的推理场景通常需要模型处理多样且复杂的环境，而窄领域基准无法完全捕捉这些情况。因此，我们需要一个更全面的框架来支持LLM推理研究。

Method: 我们提出了InternBootcamp，这是一个开源框架，包含1000多个领域多样的任务环境，专门用于LLM推理研究。我们的代码库提供了两个关键功能：(1) 自动生成无限的训练/测试案例，具有可配置的难度级别，以及(2) 集成的验证模块用于客观响应评估。此外，我们通过自动化代理工作流和手动验证协议加速了开发过程。

Result: 虽然手动开发这样一个具有广泛任务覆盖的框架非常繁琐，但我们通过自动化代理工作流和手动验证协议加速了开发过程。通过这些训练营，我们建立了Bootcamp-EVAL，一个自动生成的基准，用于全面评估性能。评估结果显示，前沿模型在许多推理任务中仍然表现不佳，而使用InternBootcamp进行训练可以显著提高性能。

Conclusion: 通过InternBootcamp的训练，我们的32B模型在Bootcamp-EVAL上取得了最先进的结果，并在其他基准测试中表现出色。验证表明，更多的训练任务带来了持续的性能提升，即任务扩展，这为实现强大的推理通用模型提供了有希望的路径。

Abstract: Large language models (LLMs) have revolutionized artificial intelligence by
enabling complex reasoning capabilities. While recent advancements in
reinforcement learning (RL) have primarily focused on domain-specific reasoning
tasks (e.g., mathematics or code generation), real-world reasoning scenarios
often require models to handle diverse and complex environments that
narrow-domain benchmarks cannot fully capture. To address this gap, we present
InternBootcamp, an open-source framework comprising 1000+ domain-diverse task
environments specifically designed for LLM reasoning research. Our codebase
offers two key functionalities: (1) automated generation of unlimited
training/testing cases with configurable difficulty levels, and (2) integrated
verification modules for objective response evaluation. These features make
InternBootcamp fundamental infrastructure for RL-based model optimization,
synthetic data generation, and model evaluation. Although manually developing
such a framework with enormous task coverage is extremely cumbersome, we
accelerate the development procedure through an automated agent workflow
supplemented by manual validation protocols, which enables the task scope to
expand rapidly. % With these bootcamps, we further establish Bootcamp-EVAL, an
automatically generated benchmark for comprehensive performance assessment.
Evaluation reveals that frontier models still underperform in many reasoning
tasks, while training with InternBootcamp provides an effective way to
significantly improve performance, leading to our 32B model that achieves
state-of-the-art results on Bootcamp-EVAL and excels on other established
benchmarks. In particular, we validate that consistent performance gains come
from including more training tasks, namely \textbf{task scaling}, over two
orders of magnitude, offering a promising route towards capable reasoning
generalist.

</details>


### [24] [Quick on the Uptake: Eliciting Implicit Intents from Human Demonstrations for Personalized Mobile-Use Agents](https://arxiv.org/abs/2508.08645)
*Zheng Wu,Heyuan Huang,Yanjia Yang,Yuanyi Song,Xingyu Lou,Weiwen Liu,Weinan Zhang,Jun Wang,Zhuosheng Zhang*

Main category: cs.CL

TL;DR: 本文提出IFRAgent框架，通过分析人类演示中的显式和隐式意图流，生成个性化的查询和标准操作程序，从而提高移动使用代理与人类意图的对齐度。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注人类的显式意图流（如步骤序列），而忽视了隐式意图流（如个人偏好），这使得构建个性化的移动使用代理变得困难。因此，需要一种新的方法来评估移动使用代理与人类之间的意图对齐率。

Method: IFRAgent框架基于从人类演示中识别意图流，分析显式意图流以构建标准操作程序（SOP）的查询级向量库，并分析隐式意图流以构建用户级习惯库。然后利用SOP提取器结合检索增强生成和查询重写器，从原始模糊查询中生成个性化查询和SOP。

Result: 实验结果表明，IFRAgent在人类意图对齐率方面平均优于基线6.79%（32.06%的相对改进），在步骤完成率方面平均提高了5.30%（26.34%的相对改进）。

Conclusion: IFRAgent在人类意图对齐率和步骤完成率方面均优于基线，表明其能够有效提升移动使用代理与人类意图的对齐度。

Abstract: As multimodal large language models advance rapidly, the automation of mobile
tasks has become increasingly feasible through the use of mobile-use agents
that mimic human interactions from graphical user interface. To further enhance
mobile-use agents, previous studies employ demonstration learning to improve
mobile-use agents from human demonstrations. However, these methods focus
solely on the explicit intention flows of humans (e.g., step sequences) while
neglecting implicit intention flows (e.g., personal preferences), which makes
it difficult to construct personalized mobile-use agents. In this work, to
evaluate the \textbf{I}ntention \textbf{A}lignment \textbf{R}ate between
mobile-use agents and humans, we first collect \textbf{MobileIAR}, a dataset
containing human-intent-aligned actions and ground-truth actions. This enables
a comprehensive assessment of the agents' understanding of human intent. Then
we propose \textbf{IFRAgent}, a framework built upon \textbf{I}ntention
\textbf{F}low \textbf{R}ecognition from human demonstrations. IFRAgent analyzes
explicit intention flows from human demonstrations to construct a query-level
vector library of standard operating procedures (SOP), and analyzes implicit
intention flows to build a user-level habit repository. IFRAgent then leverages
a SOP extractor combined with retrieval-augmented generation and a query
rewriter to generate personalized query and SOP from a raw ambiguous query,
enhancing the alignment between mobile-use agents and human intent.
Experimental results demonstrate that IFRAgent outperforms baselines by an
average of 6.79\% (32.06\% relative improvement) in human intention alignment
rate and improves step completion rates by an average of 5.30\% (26.34\%
relative improvement). The codes are available at
https://github.com/MadeAgents/Quick-on-the-Uptake.

</details>


### [25] [LLaMA-Based Models for Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2508.08649)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 本文研究了基于LLaMA的开源大型语言模型在复合方面基于情感分析任务中的表现，发现微调后的Orca~2模型在所有任务中都优于最先进的结果，但在零样本和少量样本场景下表现不佳。


<details>
  <summary>Details</summary>
Motivation: 本文动机是探索微调后的大型语言模型在复合方面基于情感分析任务中的潜力。

Method: 本文方法是对基于LLaMA的开源大型语言模型进行微调，并在四个任务和八个英文数据集上评估其性能。

Result: 本文结果发现，微调后的Orca~2模型在所有任务中都超过了最先进的结果，但在零样本和少量样本场景下表现不佳。

Conclusion: 本文结论是，微调后的Orca~2模型在所有任务中都超过了最先进的结果，但所有模型在零样本和少量样本场景下的表现不如完全微调的模型。

Abstract: While large language models (LLMs) show promise for various tasks, their
performance in compound aspect-based sentiment analysis (ABSA) tasks lags
behind fine-tuned models. However, the potential of LLMs fine-tuned for ABSA
remains unexplored. This paper examines the capabilities of open-source LLMs
fine-tuned for ABSA, focusing on LLaMA-based models. We evaluate the
performance across four tasks and eight English datasets, finding that the
fine-tuned Orca~2 model surpasses state-of-the-art results in all tasks.
However, all models struggle in zero-shot and few-shot scenarios compared to
fully fine-tuned ones. Additionally, we conduct error analysis to identify
challenges faced by fine-tuned models.

</details>


### [26] [UWB at WASSA-2024 Shared Task 2: Cross-lingual Emotion Detection](https://arxiv.org/abs/2508.08650)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 本文提出了一种基于微调量化大语言模型和多语言Transformer模型的方法，用于跨语言情感检测任务，并取得了优异的成绩。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决WASSA-2024跨语言情感检测共享任务中的两个子任务：对给定的多语言推文进行情感分类，并预测触发情感的词语。

Method: 我们提出了微调量化大语言模型（如Orca~2）的方法，结合低秩适配器（LoRA）和多语言Transformer模型（如XLM-R和mT5），并通过机器翻译和触发词切换来提高性能。

Result: 系统在数值触发词检测中排名第一，在二进制触发词检测中排名第三，在情感检测中排名第七。

Conclusion: 我们的系统在跨语言情感检测任务中表现出色，排名分别为数值触发词检测第1名、二进制触发词检测第3名和情感检测第7名。

Abstract: This paper presents our system built for the WASSA-2024 Cross-lingual Emotion
Detection Shared Task. The task consists of two subtasks: first, to assess an
emotion label from six possible classes for a given tweet in one of five
languages, and second, to predict words triggering the detected emotions in
binary and numerical formats. Our proposed approach revolves around fine-tuning
quantized large language models, specifically Orca~2, with low-rank adapters
(LoRA) and multilingual Transformer-based models, such as XLM-R and mT5. We
enhance performance through machine translation for both subtasks and trigger
word switching for the second subtask. The system achieves excellent
performance, ranking 1st in numerical trigger words detection, 3rd in binary
trigger words detection, and 7th in emotion detection.

</details>


### [27] [Prompt-Based Approach for Czech Sentiment Analysis](https://arxiv.org/abs/2508.08651)
*Jakub Šmíd,Pavel Přibáň*

Main category: cs.CL

TL;DR: 本文提出了一种基于提示的方法用于捷克语方面的情感分析和情感分类，并证明了其在传统微调方法上的优越性，特别是在零样本和少量样本学习场景中。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索基于提示的方法在捷克语方面的情感分析和情感分类中的应用，并验证其在有限训练数据下的有效性。

Method: 本文使用序列到序列模型同时解决方面级任务，并通过提示方法进行实验。此外，还进行了零样本和少量样本学习实验，以比较提示方法与传统微调的效果。

Result: 实验结果表明，基于提示的方法在传统微调方法上表现出优势，特别是在零样本和少量样本学习场景中。此外，目标领域数据的预训练也能显著提升零样本场景的表现。

Conclusion: 本文介绍了基于提示的方法在捷克语方面的情感分析和情感分类中的应用，并展示了其在传统微调方法上的优势。此外，我们还进行了零样本和少量样本学习实验，结果表明提示方法在有限的训练示例下表现更好。

Abstract: This paper introduces the first prompt-based methods for aspect-based
sentiment analysis and sentiment classification in Czech. We employ the
sequence-to-sequence models to solve the aspect-based tasks simultaneously and
demonstrate the superiority of our prompt-based approach over traditional
fine-tuning. In addition, we conduct zero-shot and few-shot learning
experiments for sentiment classification and show that prompting yields
significantly better results with limited training examples compared to
traditional fine-tuning. We also demonstrate that pre-training on data from the
target domain can lead to significant improvements in a zero-shot scenario.

</details>


### [28] [LLM driven Text-to-Table Generation through Sub-Tasks Guidance and Iterative Refinement](https://arxiv.org/abs/2508.08653)
*Rajmohan C,Sarthak Harne,Arvind Agarwal*

Main category: cs.CL

TL;DR: 本文提出了一种基于LLM的文本到表格生成系统，通过任务分解和迭代自我反馈提高生成质量，并在两个公开数据集上取得了良好结果。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）具有潜力，但它们在处理模糊或领域特定的数据、保持表格结构、处理长输入和解决数值推理方面常常遇到困难。因此，需要一种更有效的系统来改进文本到表格的生成。

Method: 本文提出了一种高效的LLM驱动的文本到表格生成系统，该系统利用了新颖的提示技术，包括将任务分解为可管理的子任务和通过迭代自我反馈来优化生成的表格。

Result: 实验结果表明，该系统能够以分步方式解决问题，并提高生成表格的质量。同时，讨论了迭代自我反馈的优缺点以及性能提升与计算成本之间的权衡。

Conclusion: 本文提出的系统在两个复杂的文本到表格生成数据集上取得了优于基线的结果，展示了其有效性。

Abstract: Transforming unstructured text into structured data is a complex task,
requiring semantic understanding, reasoning, and structural comprehension.
While Large Language Models (LLMs) offer potential, they often struggle with
handling ambiguous or domain-specific data, maintaining table structure,
managing long inputs, and addressing numerical reasoning. This paper proposes
an efficient system for LLM-driven text-to-table generation that leverages
novel prompting techniques. Specifically, the system incorporates two key
strategies: breaking down the text-to-table task into manageable, guided
sub-tasks and refining the generated tables through iterative self-feedback. We
show that this custom task decomposition allows the model to address the
problem in a stepwise manner and improves the quality of the generated table.
Furthermore, we discuss the benefits and potential risks associated with
iterative self-feedback on the generated tables while highlighting the
trade-offs between enhanced performance and computational cost. Our methods
achieve strong results compared to baselines on two complex text-to-table
generation datasets available in the public domain.

</details>


### [29] [TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation](https://arxiv.org/abs/2508.08680)
*Armel Zebaze,Benoît Sagot,Rachel Bawden*

Main category: cs.CL

TL;DR: 本文提出了一种基于LLM的方法TopXGen，用于在多种低资源语言中生成高质量和主题多样的数据，这些数据可以被反向翻译以产生有用的并行文本用于ICL和微调。


<details>
  <summary>Details</summary>
Motivation: 现有的平行数据集在大小、质量和多样性方面限制了改进效果，而低资源语言缺乏高质量的相关靶侧文本，因此需要一种新的方法来生成高质量的平行数据。

Method: 本文提出的方法TopXGen利用LLM在高资源语言中的良好翻译能力和多语言性，生成高质量、自然的靶侧文本，然后通过反向翻译生成有用的并行文本。

Result: 实验表明，TopXGen能够提升LLM在微调和上下文学习中的翻译性能。

Conclusion: 本文提出了一种基于LLM的方法TopXGen，用于在多种低资源语言中生成高质量和主题多样的数据，这些数据可以被反向翻译以产生有用的并行文本用于ICL和微调。

Abstract: LLMs have been shown to perform well in machine translation (MT) with the use
of in-context learning (ICL), rivaling supervised models when translating into
high-resource languages (HRLs). However, they lag behind when translating into
low-resource language (LRLs). Example selection via similarity search and
supervised fine-tuning help. However the improvements they give are limited by
the size, quality and diversity of existing parallel datasets. A common
technique in low-resource MT is synthetic parallel data creation, the most
frequent of which is backtranslation, whereby existing target-side texts are
automatically translated into the source language. However, this assumes the
existence of good quality and relevant target-side texts, which are not readily
available for many LRLs. In this paper, we present \textsc{TopXGen}, an
LLM-based approach for the generation of high quality and topic-diverse data in
multiple LRLs, which can then be backtranslated to produce useful and diverse
parallel texts for ICL and fine-tuning. Our intuition is that while LLMs
struggle to translate into LRLs, their ability to translate well into HRLs and
their multilinguality enable them to generate good quality, natural-sounding
target-side texts, which can be translated well into a high-resource source
language. We show that \textsc{TopXGen} boosts LLM translation performance
during fine-tuning and in-context learning. Code and outputs are available at
https://github.com/ArmelRandy/topxgen.

</details>


### [30] [Out of the Box, into the Clinic? Evaluating State-of-the-Art ASR for Clinical Applications for Older Adults](https://arxiv.org/abs/2508.08684)
*Bram van Dijk,Tiberon Kuiper,Sirin Aoulad si Ahmed,Armel Levebvre,Jake Johnson,Jan Duin,Simon Mooijaart,Marco Spruit*

Main category: cs.CL

TL;DR: 本研究评估了最先进的自动语音识别（ASR）模型在老年荷兰成年人中的表现，发现通用多语言模型优于微调模型，并探讨了截断现有架构对平衡准确性和速度的影响。


<details>
  <summary>Details</summary>
Motivation: 语音控制界面可以在临床环境中支持老年人，但针对非主流群体的可靠自动语音识别（ASR）仍然是一个瓶颈。本研究旨在评估最先进的ASR模型在老年荷兰成年人中的表现，以解决这一问题。

Method: 本研究评估了最先进的ASR模型在老年荷兰成年人语言使用上的表现，这些成年人与为老年护理环境设计的Welzijn.AI聊天机器人进行了交互。研究基准测试了通用多语言ASR模型和针对老年成年人荷兰语微调的模型，并考虑了处理速度。

Result: 研究结果表明，通用多语言模型在老年荷兰成年人的语言使用中表现优于微调模型。此外，研究还发现截断现有架构有助于平衡准确性和速度的权衡，但也发现了一些由于幻觉导致高WER的情况。

Conclusion: 研究结果表明，通用多语言模型在现实数据集上的表现优于微调模型，这表明最新的ASR模型可以很好地进行泛化。此外，研究还发现截断现有架构有助于平衡准确性和速度的权衡，但也发现了一些由于幻觉导致高WER的情况。

Abstract: Voice-controlled interfaces can support older adults in clinical contexts,
with chatbots being a prime example, but reliable Automatic Speech Recognition
(ASR) for underrepresented groups remains a bottleneck. This study evaluates
state-of-the-art ASR models on language use of older Dutch adults, who
interacted with the Welzijn.AI chatbot designed for geriatric contexts. We
benchmark generic multilingual ASR models, and models fine-tuned for Dutch
spoken by older adults, while also considering processing speed. Our results
show that generic multilingual models outperform fine-tuned models, which
suggests recent ASR models can generalise well out of the box to realistic
datasets. Furthermore, our results suggest that truncating existing
architectures is helpful in balancing the accuracy-speed trade-off, though we
also identify some cases with high WER due to hallucinations.

</details>


### [31] [A Survey on Parallel Text Generation: From Parallel Decoding to Diffusion Language Models](https://arxiv.org/abs/2508.08712)
*Lingzhe Zhang,Liancheng Fang,Chiming Duan,Minghua He,Leyi Pan,Pei Xiao,Shiyu Huang,Yunpeng Zhai,Xuming Hu,Philip S. Yu,Aiwei Liu*

Main category: cs.CL

TL;DR: 本文对并行文本生成方法进行了系统综述，分析了其优缺点，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 由于大多数现有LLM依赖于自回归生成，导致生成速度受限，因此需要探索并行文本生成以提高推理效率。

Method: 本文将现有的方法分为基于AR和非AR的范式，并详细分析了每类中的核心技术。

Result: 本文提供了对并行文本生成方法的全面分析，并评估了它们在速度、质量和效率方面的理论权衡。

Conclusion: 本文对并行文本生成方法进行了系统综述，并指出了该领域最近的进展、开放挑战和未来研究方向。

Abstract: As text generation has become a core capability of modern Large Language
Models (LLMs), it underpins a wide range of downstream applications. However,
most existing LLMs rely on autoregressive (AR) generation, producing one token
at a time based on previously generated context-resulting in limited generation
speed due to the inherently sequential nature of the process. To address this
challenge, an increasing number of researchers have begun exploring parallel
text generation-a broad class of techniques aimed at breaking the
token-by-token generation bottleneck and improving inference efficiency.
Despite growing interest, there remains a lack of comprehensive analysis on
what specific techniques constitute parallel text generation and how they
improve inference performance. To bridge this gap, we present a systematic
survey of parallel text generation methods. We categorize existing approaches
into AR-based and Non-AR-based paradigms, and provide a detailed examination of
the core techniques within each category. Following this taxonomy, we assess
their theoretical trade-offs in terms of speed, quality, and efficiency, and
examine their potential for combination and comparison with alternative
acceleration strategies. Finally, based on our findings, we highlight recent
advancements, identify open challenges, and outline promising directions for
future research in parallel text generation.

</details>


### [32] [IROTE: Human-like Traits Elicitation of Large Language Model via In-Context Self-Reflective Optimization](https://arxiv.org/abs/2508.08719)
*Yuzhuo Bai,Shitong Duan,Muhua Huang,Jing Yao,Zhenghao Liu,Peng Zhang,Tun Lu,Xiaoyuan Yi,Maosong Sun,Xing Xie*

Main category: cs.CL

TL;DR: 本文提出了一种新的上下文方法IROTE，用于稳定和可转移的特质提取。通过自动生成和优化提示中的文本自我反思，该方法能够使LLMs在各种下游任务中稳定地模仿目标特质，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在表面提取问题：LLMs只能被引导模仿浅层且不稳定的风格模式，无法在多样化的任务中精确且一致地体现所需的特质。

Method: 我们提出了IROTE，一种新的上下文方法，用于稳定和可转移的特质提取。该方法基于心理理论，通过身份相关的反思来形成特质，并自动生成和优化提示中的文本自我反思，以刺激LLMs的特质驱动行为。

Result: 广泛的实验表明，一个单一的IROTE生成的自我反思可以诱导LLMs在各种下游任务中稳定地模仿目标特质，持续优于现有的强大基线。

Conclusion: 实验结果表明，一个单一的IROTE生成的自我反思可以诱导LLMs在各种下游任务中稳定地模仿目标特质，持续优于现有的强大基线。

Abstract: Trained on various human-authored corpora, Large Language Models (LLMs) have
demonstrated a certain capability of reflecting specific human-like traits
(e.g., personality or values) by prompting, benefiting applications like
personalized LLMs and social simulations. However, existing methods suffer from
the superficial elicitation problem: LLMs can only be steered to mimic shallow
and unstable stylistic patterns, failing to embody the desired traits precisely
and consistently across diverse tasks like humans. To address this challenge,
we propose IROTE, a novel in-context method for stable and transferable trait
elicitation. Drawing on psychological theories suggesting that traits are
formed through identity-related reflection, our method automatically generates
and optimizes a textual self-reflection within prompts, which comprises
self-perceived experience, to stimulate LLMs' trait-driven behavior. The
optimization is performed by iteratively maximizing an information-theoretic
objective that enhances the connections between LLMs' behavior and the target
trait, while reducing noisy redundancy in reflection without any fine-tuning,
leading to evocative and compact trait reflection. Extensive experiments across
three human trait systems manifest that one single IROTE-generated
self-reflection can induce LLMs' stable impersonation of the target trait
across diverse downstream tasks beyond simple questionnaire answering,
consistently outperforming existing strong baselines.

</details>


### [33] [Magical: Medical Lay Language Generation via Semantic Invariance and Layperson-tailored Adaptation](https://arxiv.org/abs/2508.08730)
*Weibin Liao,Tianlong Wang,Yinghao Zhu,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.CL

TL;DR: Magical is an asymmetric LoRA architecture designed for MLLG under heterogeneous data scenarios. It improves semantic fidelity and diverse lay-style generation while reducing trainable parameters.


<details>
  <summary>Details</summary>
Motivation: Recent literature on MLLG commonly employ parameter-efficient fine-tuning methods such as LoRA, but LoRA struggles with challenges posed by multi-source heterogeneous MLLG datasets. Standard LoRA fails to meet the requirement for semantic fidelity and diverse lay-style generation in MLLG tasks.

Method: Magical, an asymmetric LoRA architecture tailored for MLLG under heterogeneous data scenarios, employs a shared matrix $A$ for abstractive summarization, along with multiple isolated matrices $B$ for diverse lay-style generation. It introduces a Semantic Invariance Constraint to mitigate semantic subspace shifts on matrix $A$ and incorporates the Recommendation-guided Switch to prompt the LLM to switch between different matrices $B$.

Result: Magical consistently outperforms prompt-based methods, vanilla LoRA, and its recent variants, while also reducing trainable parameters by 31.66%.

Conclusion: Magical consistently outperforms prompt-based methods, vanilla LoRA, and its recent variants, while also reducing trainable parameters by 31.66%.

Abstract: Medical Lay Language Generation (MLLG) plays a vital role in improving the
accessibility of complex scientific content for broader audiences. Recent
literature to MLLG commonly employ parameter-efficient fine-tuning methods such
as Low-Rank Adaptation (LoRA) to fine-tuning large language models (LLMs) using
paired expert-lay language datasets. However, LoRA struggles with the
challenges posed by multi-source heterogeneous MLLG datasets. Specifically,
through a series of exploratory experiments, we reveal that standard LoRA fail
to meet the requirement for semantic fidelity and diverse lay-style generation
in MLLG task. To address these limitations, we propose Magical, an asymmetric
LoRA architecture tailored for MLLG under heterogeneous data scenarios. Magical
employs a shared matrix $A$ for abstractive summarization, along with multiple
isolated matrices $B$ for diverse lay-style generation. To preserve semantic
fidelity during the lay language generation process, Magical introduces a
Semantic Invariance Constraint to mitigate semantic subspace shifts on matrix
$A$. Furthermore, to better adapt to diverse lay-style generation, Magical
incorporates the Recommendation-guided Switch, an externally interface to
prompt the LLM to switch between different matrices $B$. Experimental results
on three real-world lay language generation datasets demonstrate that Magical
consistently outperforms prompt-based methods, vanilla LoRA, and its recent
variants, while also reducing trainable parameters by 31.66%.

</details>


### [34] [SciRerankBench: Benchmarking Rerankers Towards Scientific Retrieval-Augmented Generated LLMs](https://arxiv.org/abs/2508.08742)
*Haotian Chen,Qingqing Long,Meng Xiao,Xiao Luo,Wei Ju,Chengrui Wang,Xuezhi Wang,Yuanchun Zhou,Hengshu Zhu*

Main category: cs.CL

TL;DR: 本文介绍了SciRerankBench，这是一个用于评估RAG-LLMs中重排序器的基准，通过三种类型的问答对来测试其性能。


<details>
  <summary>Details</summary>
Motivation: 尽管在科学文献问答领域取得了显著进展，但这些工作的潜力和局限性仍未被探索。

Method: 提出了一种科学重排序导向的RAG基准(SciRerankBench)，通过三种类型的问答对来评估重排序器的表现。

Result: 对13个常用的重排序器进行了系统评估，揭示了它们的相对优势和局限性。

Conclusion: SciRerankBench是第一个专门用于评估RAG-LLMs中重排序器的基准，为未来的发展提供了有价值的观察和指导。

Abstract: Scientific literature question answering is a pivotal step towards new
scientific discoveries. Recently, \textit{two-stage} retrieval-augmented
generated large language models (RAG-LLMs) have shown impressive advancements
in this domain. Such a two-stage framework, especially the second stage
(reranker), is particularly essential in the scientific domain, where subtle
differences in terminology may have a greatly negative impact on the final
factual-oriented or knowledge-intensive answers. Despite this significant
progress, the potential and limitations of these works remain unexplored. In
this work, we present a Scientific Rerank-oriented RAG Benchmark
(SciRerankBench), for evaluating rerankers within RAG-LLMs systems, spanning
five scientific subjects. To rigorously assess the reranker performance in
terms of noise resilience, relevance disambiguation, and factual consistency,
we develop three types of question-context-answer (Q-C-A) pairs, i.e., Noisy
Contexts (NC), Semantically Similar but Logically Irrelevant Contexts (SSLI),
and Counterfactual Contexts (CC). Through systematic evaluation of 13 widely
used rerankers on five families of LLMs, we provide detailed insights into
their relative strengths and limitations. To the best of our knowledge,
SciRerankBench is the first benchmark specifically developed to evaluate
rerankers within RAG-LLMs, which provides valuable observations and guidance
for their future development.

</details>


### [35] [DevNous: An LLM-Based Multi-Agent System for Grounding IT Project Management in Unstructured Conversation](https://arxiv.org/abs/2508.08761)
*Stavros Doropoulos,Stavros Vologiannidis,Ioannis Magnisalis*

Main category: cs.CL

TL;DR: 本文介绍了DevNous，一个基于大型语言模型的多智能体专家系统，用于自动化团队对话的结构化转换。通过引入一个新的基准数据集，DevNous在准确性方面表现出色，为该领域提供了重要的贡献。


<details>
  <summary>Details</summary>
Motivation: 手动将非结构化的团队对话转换为IT项目治理所需的结构化工件是现代信息系统管理中的一个关键瓶颈。

Method: DevNous是一个基于大型语言模型的多智能体专家系统，它直接集成到团队聊天环境中，从非正式对话中识别可操作意图，并管理状态化的多轮工作流。

Result: DevNous在基准测试中实现了81.3%的精确匹配回合准确率和0.845的多集F1分数。

Conclusion: DevNous在基准测试中表现出色，证明了其在自动化团队对话结构化转换方面的可行性，并为该领域提供了第一个稳健的实证基线和公开数据集。

Abstract: The manual translation of unstructured team dialogue into the structured
artifacts required for Information Technology (IT) project governance is a
critical bottleneck in modern information systems management. We introduce
DevNous, a Large Language Model-based (LLM) multi-agent expert system, to
automate this unstructured-to-structured translation process. DevNous
integrates directly into team chat environments, identifying actionable intents
from informal dialogue and managing stateful, multi-turn workflows for core
administrative tasks like automated task formalization and progress summary
synthesis. To quantitatively evaluate the system, we introduce a new benchmark
of 160 realistic, interactive conversational turns. The dataset was manually
annotated with a multi-label ground truth and is publicly available. On this
benchmark, DevNous achieves an exact match turn accuracy of 81.3\% and a
multiset F1-Score of 0.845, providing strong evidence for its viability. The
primary contributions of this work are twofold: (1) a validated architectural
pattern for developing ambient administrative agents, and (2) the introduction
of the first robust empirical baseline and public benchmark dataset for this
challenging problem domain.

</details>


### [36] [Privacy-protected Retrieval-Augmented Generation for Knowledge Graph Question Answering](https://arxiv.org/abs/2508.08785)
*Yunfeng Ning,Mayi Xu,Jintao Wen,Qiankun Pi,Yuanyuan Zhu,Ming Zhong,Jiawei Jiang,Tieyun Qian*

Main category: cs.CL

TL;DR: This paper introduces ARoG, a framework for privacy-protected RAG systems that allows effective knowledge retrieval from anonymous KG entities without exposing their semantics to LLMs.


<details>
  <summary>Details</summary>
Motivation: To address privacy risks in RAG systems when using private KGs, especially with LLMs that lack transparency and control.

Method: ARoG framework including relation-centric abstraction and structure-oriented abstraction strategies.

Result: Experiments on three datasets demonstrate that ARoG achieves strong performance and privacy-robustness.

Conclusion: ARoG achieves strong performance and privacy-robustness.

Abstract: LLMs often suffer from hallucinations and outdated or incomplete knowledge.
RAG is proposed to address these issues by integrating external knowledge like
that in KGs into LLMs. However, leveraging private KGs in RAG systems poses
significant privacy risks due to the black-box nature of LLMs and potential
insecure data transmission, especially when using third-party LLM APIs lacking
transparency and control. In this paper, we investigate the privacy-protected
RAG scenario for the first time, where entities in KGs are anonymous for LLMs,
thus preventing them from accessing entity semantics. Due to the loss of
semantics of entities, previous RAG systems cannot retrieve question-relevant
knowledge from KGs by matching questions with the meaningless identifiers of
anonymous entities. To realize an effective RAG system in this scenario, two
key challenges must be addressed: (1) How can anonymous entities be converted
into retrievable information. (2) How to retrieve question-relevant anonymous
entities. Hence, we propose a novel ARoG framework including relation-centric
abstraction and structure-oriented abstraction strategies. For challenge (1),
the first strategy abstracts entities into high-level concepts by dynamically
capturing the semantics of their adjacent relations. It supplements meaningful
semantics which can further support the retrieval process. For challenge (2),
the second strategy transforms unstructured natural language questions into
structured abstract concept paths. These paths can be more effectively aligned
with the abstracted concepts in KGs, thereby improving retrieval performance.
To guide LLMs to effectively retrieve knowledge from KGs, the two strategies
strictly protect privacy from being exposed to LLMs. Experiments on three
datasets demonstrate that ARoG achieves strong performance and
privacy-robustness.

</details>


### [37] [Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments](https://arxiv.org/abs/2508.08791)
*Junjie Ye,Changhao Jiang,Zhengyin Du,Yufei Xu,Xuesong Yao,Zhiheng Xi,Xiaoran Fan,Qi Zhang,Xuanjing Huang,Jiecao Chen*

Main category: cs.CL

TL;DR: 本文提出了一种自动化环境构建流程和可验证的奖励机制，以提高大型语言模型的工具使用性能，同时保持其通用能力。


<details>
  <summary>Details</summary>
Motivation: 有效使用工具对于大型语言模型（LLMs）与环境进行有意义的交互至关重要。然而，由于构建稳定训练环境和设计可验证奖励机制的挑战，进展受到限制。

Method: 我们提出了一个自动环境构建流程，包括场景分解、文档生成、功能集成、复杂度扩展和局部部署。此外，我们引入了一个可验证的奖励机制，评估工具使用的精确性和任务执行的完整性。

Result: 实验表明，我们的方法在不同规模的LLMs上显著提升了工具使用性能，同时保持了模型的通用能力。

Conclusion: 我们的方法显著提高了模型的工具使用性能，而不会损害其通用能力，无论推理模式或训练算法如何。分析表明，这些改进来自于对上下文理解和推理的提升，这是由模型低层MLP参数的更新驱动的。

Abstract: Effective tool use is essential for large language models (LLMs) to interact
meaningfully with their environment. However, progress is limited by the lack
of efficient reinforcement learning (RL) frameworks specifically designed for
tool use, due to challenges in constructing stable training environments and
designing verifiable reward mechanisms. To address this, we propose an
automated environment construction pipeline, incorporating scenario
decomposition, document generation, function integration, complexity scaling,
and localized deployment. This enables the creation of high-quality training
environments that provide detailed and measurable feedback without relying on
external tools. Additionally, we introduce a verifiable reward mechanism that
evaluates both the precision of tool use and the completeness of task
execution. When combined with trajectory data collected from the constructed
environments, this mechanism integrates seamlessly with standard RL algorithms
to facilitate feedback-driven model training. Experiments on LLMs of varying
scales demonstrate that our approach significantly enhances the models'
tool-use performance without degrading their general capabilities, regardless
of inference modes or training algorithms. Our analysis suggests that these
gains result from improved context understanding and reasoning, driven by
updates to the lower-layer MLP parameters in models.

</details>


### [38] [TiMoE: Time-Aware Mixture of Language Experts](https://arxiv.org/abs/2508.08827)
*Robin Faro,Dongyang Fan,Tamar Alphaidze,Martin Jaggi*

Main category: cs.CL

TL;DR: 本文提出了一种名为TiMoE的方法，用于解决大型语言模型因训练数据过时而导致的时间泄漏问题。通过在不同时间段的语料库上预训练多个专家，并在推理时根据查询时间选择合适的专家，从而保证因果有效性。实验结果表明，该方法在标准NLP任务和TSQA基准测试中表现优异，能够有效减少未来知识错误。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）通常是在固定快照的网络上进行训练的，这意味着它们的知识会变得过时，其预测可能会出现时间泄漏：依赖于相对于查询而言未来的信息。

Method: 我们通过从头开始对一组GPT风格的专家进行预训练，这些专家在2013-2024语料库的不同时期切片上进行训练，并通过TiMoE（时间感知的语言专家混合）将它们组合起来，以解决这个问题。在推理时，TiMoE会屏蔽所有训练窗口结束于查询时间戳之后的专家，并在共享空间中合并剩余的日志概率，以确保严格的因果有效性。

Result: 实验结果表明，一个共同适应的TiMoE变体可以与最佳单时期专家相媲美或超越，并将未来知识错误减少了高达15%。

Conclusion: 我们的结果表明，模块化、时间分段的预训练结合因果路由是使LLM保持时间上稳固的一种简单而有效的方法，而不会显著牺牲一般性能。

Abstract: Large language models (LLMs) are typically trained on fixed snapshots of the
web, which means that their knowledge becomes stale and their predictions risk
temporal leakage: relying on information that lies in the future relative to a
query. We tackle this problem by pre-training from scratch a set of GPT-style
experts on disjoint two-year slices of a 2013-2024 corpus and combining them
through TiMoE, a Time-aware Mixture of Language Experts. At inference time,
TiMoE masks all experts whose training window ends after the query timestamp
and merges the remaining log-probabilities in a shared space, guaranteeing
strict causal validity while retaining the breadth of multi-period knowledge.
We also release TSQA, a 10k-question benchmark whose alternatives are
explicitly labelled as past, future or irrelevant, allowing fine-grained
measurement of temporal hallucinations. Experiments on eight standard NLP tasks
plus TSQA show that a co-adapted TiMoE variant matches or exceeds the best
single-period expert and cuts future-knowledge errors by up to 15%. Our results
demonstrate that modular, time-segmented pre-training paired with causal
routing is a simple yet effective path toward LLMs that stay chronologically
grounded without sacrificing general performance much. We open source our code
at TiMoE (Github): https://github.com/epfml/TiMoE

</details>


### [39] [An Investigation of Robustness of LLMs in Mathematical Reasoning: Benchmarking with Mathematically-Equivalent Transformation of Advanced Mathematical Problems](https://arxiv.org/abs/2508.08833)
*Yuren Hao,Xiang Wan,Chengxiang Zhai*

Main category: cs.CL

TL;DR: 本文提出了一种新的评估方法，通过压力测试LLMs在具有语言和参数变化的高级数学问题上的表现，以更准确地评估其数学推理能力。创建了PutnamGAP数据集，并评估了多个LLMs，发现性能在变体上显著下降。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地评估LLMs的数学推理能力，需要一种能够测量其对非数学扰动敏感性的方法。

Method: 本文引入了一种超越传统方法的系统框架，通过在具有语言和参数变化的高级数学问题上对LLMs进行压力测试，以评估其数学推理的鲁棒性。这些转换使我们能够衡量LLMs对非数学扰动的敏感性，从而实现对其数学推理能力的更准确评估。

Result: 使用新的评估方法，我们创建了PutnamGAP数据集，这是一个包含竞赛级数学问题的多个数学等价变体的数据集。评估多个代表性的LLMs后，我们观察到在变体上的性能急剧下降。OpenAI的旗舰推理模型O3在原始问题上得分为49%，但在表面变体上下降了4个百分点，在核心步骤变体上下降了10.5个百分点，而较小的模型表现更差。

Conclusion: 结果表明，所提出的新的评估方法对于加深我们对LLMs鲁棒性的理解以及生成进一步提高其数学推理能力的新见解是有效的。

Abstract: In this paper, we introduce a systematic framework beyond conventional method
to assess LLMs' mathematical-reasoning robustness by stress-testing them on
advanced math problems that are mathematically equivalent but with linguistic
and parametric variation. These transformations allow us to measure the
sensitivity of LLMs to non-mathematical perturbations, thereby enabling a more
accurate evaluation of their mathematical reasoning capabilities. Using this
new evaluation methodology, we created PutnamGAP, a new benchmark dataset with
multiple mathematically-equivalent variations of competition-level math
problems. With the new dataset, we evaluate multiple families of representative
LLMs and examine their robustness. Across 18 commercial and open-source models
we observe sharp performance degradation on the variants. OpenAI's flagship
reasoning model, O3, scores 49 % on the originals but drops by 4 percentage
points on surface variants, and by 10.5 percentage points on core-step-based
variants, while smaller models fare far worse. Overall, the results show that
the proposed new evaluation methodology is effective for deepening our
understanding of the robustness of LLMs and generating new insights for further
improving their mathematical reasoning capabilities.

</details>


### [40] [Steering Towards Fairness: Mitigating Political Bias in LLMs](https://arxiv.org/abs/2508.08846)
*Afrozah Nadeem,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 本文提出了一种框架，通过分析内部模型表示来探测和减轻基于解码器的LLM中的偏见。该方法基于政治指南针测试（PCT），使用对比对来提取和比较来自Mistral和DeepSeek等模型的隐藏层激活。结果表明，解码器LLM在各层中系统性地编码表征偏见，这可以用于基于引导向量的有效缓解。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在各种现实应用中得到了广泛应用，但它们倾向于编码和再现意识形态偏见，特别是在政治和经济维度上，这引发了关注。

Method: 本文提出了一种框架，通过分析内部模型表示来探测和减轻基于解码器的LLM中的偏见。该方法基于政治指南针测试（PCT），使用对比对来提取和比较来自Mistral和DeepSeek等模型的隐藏层激活。

Result: 结果表明，解码器LLM在各层中系统性地编码表征偏见，这可以用于基于引导向量的有效缓解。

Conclusion: 本文提供了关于如何在大型语言模型中编码政治偏见的新见解，并提出了超越表面输出干预的去偏方法。

Abstract: Recent advancements in large language models (LLMs) have enabled their
widespread use across diverse real-world applications. However, concerns remain
about their tendency to encode and reproduce ideological biases, particularly
along political and economic dimensions. In this paper, we propose a framework
for probing and mitigating such biases in decoder-based LLMs through analysis
of internal model representations. Grounded in the Political Compass Test
(PCT), our method uses contrastive pairs to extract and compare hidden layer
activations from models like Mistral and DeepSeek. We introduce a comprehensive
activation extraction pipeline capable of layer-wise analysis across multiple
ideological axes, revealing meaningful disparities linked to political framing.
Our results show that decoder LLMs systematically encode representational bias
across layers, which can be leveraged for effective steering vector-based
mitigation. This work provides new insights into how political bias is encoded
in LLMs and offers a principled approach to debiasing beyond surface-level
output interventions.

</details>


### [41] [BiasGym: Fantastic Biases and How to Find (and Remove) Them](https://arxiv.org/abs/2508.08855)
*Sekh Mainul Islam,Nadav Borenstein,Siddhesh Milind Pawar,Haeun Yu,Arnav Arora,Isabelle Augenstein*

Main category: cs.CL

TL;DR: 本文介绍了BiasGym，这是一个简单、成本效益高且可推广的框架，用于在大型语言模型中可靠地注入、分析和减轻概念关联。该方法能够一致地引发偏差以进行机制分析，并在不损害下游任务性能的情况下支持有针对性的去偏。


<details>
  <summary>Details</summary>
Motivation: Understanding biases and stereotypes encoded in the weights of Large Language Models (LLMs) is crucial for developing effective mitigation strategies. Biased behaviour is often subtle and non-trivial to isolate, even when deliberately elicited, making systematic analysis and debiasing particularly challenging.

Method: BiasGym consists of two components: BiasInject, which injects specific biases into the model via token-based fine-tuning while keeping the model frozen, and BiasScope, which leverages these injected signals to identify and steer the components responsible for biased behavior.

Result: Our method enables consistent bias elicitation for mechanistic analysis, supports targeted debiasing without degrading performance on downstream tasks, and generalizes to biases unseen during training. We demonstrate the effectiveness of BiasGym in reducing real-world stereotypes and in probing fictional associations.

Conclusion: BiasGym is effective in reducing real-world stereotypes and probing fictional associations, showing its utility for both safety interventions and interpretability research.

Abstract: Understanding biases and stereotypes encoded in the weights of Large Language
Models (LLMs) is crucial for developing effective mitigation strategies. Biased
behaviour is often subtle and non-trivial to isolate, even when deliberately
elicited, making systematic analysis and debiasing particularly challenging. To
address this, we introduce BiasGym, a simple, cost-effective, and generalizable
framework for reliably injecting, analyzing, and mitigating conceptual
associations within LLMs. BiasGym consists of two components: BiasInject, which
injects specific biases into the model via token-based fine-tuning while
keeping the model frozen, and BiasScope, which leverages these injected signals
to identify and steer the components responsible for biased behavior. Our
method enables consistent bias elicitation for mechanistic analysis, supports
targeted debiasing without degrading performance on downstream tasks, and
generalizes to biases unseen during training. We demonstrate the effectiveness
of BiasGym in reducing real-world stereotypes (e.g., people from a country
being `reckless drivers') and in probing fictional associations (e.g., people
from a country having `blue skin'), showing its utility for both safety
interventions and interpretability research.

</details>


### [42] [Weakly Supervised Fine-grained Span-Level Framework for Chinese Radiology Report Quality Assurance](https://arxiv.org/abs/2508.08876)
*Kaiyu Wang,Lin Mu,Zhiyao Yang,Ximing Li,Xiaotang Zhou Wanfu Gao,Huimao Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为Sqator的基于段级别的质量保证评估器，用于自动标记放射学报告的QA评分。


<details>
  <summary>Details</summary>
Motivation: 目前的QA评分过程需要大量的人力成本，且可能由于诊断偏见、资深医生的能力等原因导致不准确。因此，需要一种自动标记QA评分的方法。

Method: Sqator通过测量初级和高级报告之间修订段落的重要性来评估QA评分，并通过合并所有修订段落评分来输出最终的QA评分。

Result: 在12,013份放射学报告的集合上评估了Sqator，实验结果表明其可以实现具有竞争力的QA评分，并且修订段落的重要性评分与资深医生的判断一致。

Conclusion: Sqator可以实现具有竞争力的QA评分，并且修订段落的重要性评分与资深医生的判断一致。

Abstract: Quality Assurance (QA) for radiology reports refers to judging whether the
junior reports (written by junior doctors) are qualified. The QA scores of one
junior report are given by the senior doctor(s) after reviewing the image and
junior report. This process requires intensive labor costs for senior doctors.
Additionally, the QA scores may be inaccurate for reasons like diagnosis bias,
the ability of senior doctors, and so on. To address this issue, we propose a
Span-level Quality Assurance EvaluaTOR (Sqator) to mark QA scores
automatically. Unlike the common document-level semantic comparison method, we
try to analyze the semantic difference by exploring more fine-grained text
spans. Unlike the common document-level semantic comparison method, we try to
analyze the semantic difference by exploring more fine-grained text spans.
Specifically, Sqator measures QA scores by measuring the importance of revised
spans between junior and senior reports, and outputs the final QA scores by
merging all revised span scores. We evaluate Sqator using a collection of
12,013 radiology reports. Experimental results show that Sqator can achieve
competitive QA scores. Moreover, the importance scores of revised spans can be
also consistent with the judgments of senior doctors.

</details>


### [43] [Entangled in Representations: Mechanistic Investigation of Cultural Biases in Large Language Models](https://arxiv.org/abs/2508.08879)
*Haeun Yu,Seogyeong Jeong,Siddhesh Pawar,Jisu Shin,Jiho Jin,Junho Myung,Alice Oh,Isabelle Augenstein*

Main category: cs.CL

TL;DR: 本文提出了Culturescope，这是一种基于机制可解释性的方法，用于探测LLM的内部表示以揭示潜在的文化知识空间。实验结果表明，LLMs在其文化知识空间中编码了西方主导偏见和文化扁平化。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在各种文化背景中的部署日益增多，需要更好地理解LLMs表示中对较少记录文化的过度泛化如何影响其文化理解。

Method: 我们提出了Culturescope，这是第一个基于机制可解释性的方法，用于探测LLM的内部表示以揭示潜在的文化知识空间。CultureScope利用一种打补丁的方法来提取文化知识。

Result: 实验结果表明，LLMs在其文化知识空间中编码了西方主导偏见和文化扁平化。我们发现低资源文化对文化偏见的敏感性较低，这可能是由于它们的训练资源有限。

Conclusion: 我们的工作为未来减轻文化偏见和增强LLM的文化理解提供了基础。我们的代码和实验数据是公开的。

Abstract: The growing deployment of large language models (LLMs) across diverse
cultural contexts necessitates a better understanding of how the
overgeneralization of less documented cultures within LLMs' representations
impacts their cultural understanding. Prior work only performs extrinsic
evaluation of LLMs' cultural competence, without accounting for how LLMs'
internal mechanisms lead to cultural (mis)representation. To bridge this gap,
we propose Culturescope, the first mechanistic interpretability-based method
that probes the internal representations of LLMs to elicit the underlying
cultural knowledge space. CultureScope utilizes a patching method to extract
the cultural knowledge. We introduce a cultural flattening score as a measure
of the intrinsic cultural biases. Additionally, we study how LLMs internalize
Western-dominance bias and cultural flattening, which allows us to trace how
cultural biases emerge within LLMs. Our experimental results reveal that LLMs
encode Western-dominance bias and cultural flattening in their cultural
knowledge space. We find that low-resource cultures are less susceptible to
cultural biases, likely due to their limited training resources. Our work
provides a foundation for future research on mitigating cultural biases and
enhancing LLMs' cultural understanding. Our codes and data used for experiments
are publicly available.

</details>


### [44] [ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs](https://arxiv.org/abs/2508.08895)
*Keyu Chen,Zhifeng Shen,Daohai Yu,Haoqian Wu,Wei Wen,Jianfeng He,Ruizhi Qiao,Xing Sun*

Main category: cs.CL

TL;DR: 本文提出了一种自适应串行-并行解码方法（ASPD），以解决大型语言模型推理延迟的问题。通过自动提取和验证可并行结构，并实现混合解码引擎，ASPD在保持生成质量的同时显著提高了推理速度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的规模和复杂性不断增加，导致推理延迟挑战显著，主要由于其自回归解码范式，其特点是下一个标记预测的顺序性。通过重新审视自回归模型的输出，我们观察到一些段落表现出可并行的结构，我们称之为内在并行性。同时解码每个可并行分支（即并行解码）可以显著提高LLMs的整体推理速度。

Method: 我们提出了自适应串行-并行解码（ASPD），解决了两个核心挑战：自动构建可并行的数据和高效的并行解码机制。我们引入了一个非侵入式流水线，可以从自回归模型的响应中自动提取和验证可并行结构。为了实现高效的自适应串行-并行解码，我们实现了混合解码引擎，能够在串行和并行解码模式之间无缝切换，同时保持可重用的KV缓存，最大化计算效率。

Result: 广泛的评估显示，ASPD在有效性和效率方面都取得了前所未有的性能。值得注意的是，在Vicuna Bench上，我们的方法实现了高达3.19倍的速度提升（平均1.85倍），同时保持响应质量与自回归模型相差不超过1%，实现了加速而不牺牲生成质量。

Conclusion: 我们的框架为高效的LLM并行推理设定了突破性的基准，为在延迟敏感的应用中部署铺平了道路，例如AI驱动的客服机器人和答案检索引擎。

Abstract: The increasing scale and complexity of large language models (LLMs) pose
significant inference latency challenges, primarily due to their autoregressive
decoding paradigm characterized by the sequential nature of next-token
prediction. By re-examining the outputs of autoregressive models, we observed
that some segments exhibit parallelizable structures, which we term intrinsic
parallelism. Decoding each parallelizable branch simultaneously (i.e. parallel
decoding) can significantly improve the overall inference speed of LLMs. In
this paper, we propose an Adaptive Serial-Parallel Decoding (ASPD), which
addresses two core challenges: automated construction of parallelizable data
and efficient parallel decoding mechanism. More specifically, we introduce a
non-invasive pipeline that automatically extracts and validates parallelizable
structures from the responses of autoregressive models. To empower efficient
adaptive serial-parallel decoding, we implement a Hybrid Decoding Engine which
enables seamless transitions between serial and parallel decoding modes while
maintaining a reusable KV cache, maximizing computational efficiency. Extensive
evaluations across General Tasks, Retrieval-Augmented Generation, Mathematical
Reasoning, demonstrate that ASPD achieves unprecedented performance in both
effectiveness and efficiency. Notably, on Vicuna Bench, our method achieves up
to 3.19x speedup (1.85x on average) while maintaining response quality within
1% difference compared to autoregressive models, realizing significant
acceleration without compromising generation quality. Our framework sets a
groundbreaking benchmark for efficient LLM parallel inference, paving the way
for its deployment in latency-sensitive applications such as AI-powered
customer service bots and answer retrieval engines.

</details>


### [45] [Munsit at NADI 2025 Shared Task 2: Pushing the Boundaries of Multidialectal Arabic ASR with Weakly Supervised Pretraining and Continual Supervised Fine-tuning](https://arxiv.org/abs/2508.08912)
*Mahmoud Salhab,Shameed Sait,Mohammad Abusheikh,Hasan Abusheikh*

Main category: cs.CL

TL;DR: 本文提出了一种结合弱监督学习与监督微调的可扩展训练流程，用于开发稳健的阿拉伯语自动语音识别（ASR）模型。通过在大量弱标签语音数据上预训练，并利用过滤后的弱标签数据和小规模高质量注释数据集进行微调，该方法在多方言阿拉伯语ASR挑战中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 开发准确的阿拉伯语ASR系统对于低资源语言来说仍然是一个重大挑战，因为标记数据有限，并且由于多种方言带来的语言复杂性。

Method: 我们提出了一种可扩展的训练流程，将弱监督学习与监督微调相结合，以开发一个稳健的阿拉伯语ASR模型。首先，我们在15,000小时的弱标签语音上预训练模型，涵盖现代标准阿拉伯语（MSA）和各种方言阿拉伯语（DA）变体。随后，我们使用过滤后的弱标签数据和一个小而高质量的注释数据集进行持续的监督微调。

Result: 我们的方法在多方言阿拉伯语ASR挑战中取得了最先进的结果，排名第一。

Conclusion: 我们的方法在多方言阿拉伯语ASR挑战中取得了最先进的结果，排名第一。这些发现突显了弱监督与微调结合在克服数据稀缺性并为低资源、方言丰富的语言提供高质量ASR的有效性。

Abstract: Automatic speech recognition (ASR) plays a vital role in enabling natural
human-machine interaction across applications such as virtual assistants,
industrial automation, customer support, and real-time transcription. However,
developing accurate ASR systems for low-resource languages like Arabic remains
a significant challenge due to limited labeled data and the linguistic
complexity introduced by diverse dialects. In this work, we present a scalable
training pipeline that combines weakly supervised learning with supervised
fine-tuning to develop a robust Arabic ASR model. In the first stage, we
pretrain the model on 15,000 hours of weakly labeled speech covering both
Modern Standard Arabic (MSA) and various Dialectal Arabic (DA) variants. In the
subsequent stage, we perform continual supervised fine-tuning using a mixture
of filtered weakly labeled data and a small, high-quality annotated dataset.
Our approach achieves state-of-the-art results, ranking first in the
multi-dialectal Arabic ASR challenge. These findings highlight the
effectiveness of weak supervision paired with fine-tuning in overcoming data
scarcity and delivering high-quality ASR for low-resource, dialect-rich
languages.

</details>


### [46] [Reveal-Bangla: A Dataset for Cross-Lingual Multi-Step Reasoning Evaluation](https://arxiv.org/abs/2508.08933)
*Khondoker Ittehadul Islam,Gabriele Sarti*

Main category: cs.CL

TL;DR: 本文介绍了一个手动翻译的孟加拉语多步骤推理数据集，并评估了英语和孟加拉语中心的多语言小型语言模型在该数据集上的表现，发现推理上下文对非二元问题有帮助，但模型在使用孟加拉语推理步骤时存在困难。


<details>
  <summary>Details</summary>
Motivation: 语言模型在复杂的多步骤推理任务中表现出色，但其评估主要局限于高资源语言，如英语。因此，我们需要一个手动翻译的孟加拉语多步骤推理数据集来扩展评估范围。

Method: 我们对以英语为中心和以孟加拉语为中心的多语言小型语言模型在原始数据集和我们翻译的版本上进行了受控评估，以比较它们利用相关推理步骤产生正确答案的能力。

Result: 在相似的设置下，推理上下文对于更具挑战性的非二元问题是有益的，但模型难以有效地使用相关的孟加拉语推理步骤。

Conclusion: 我们通过探索推理步骤如何影响模型的预测，强调了不同模型和语言之间的不同趋势。

Abstract: Language models have demonstrated remarkable performance on complex
multi-step reasoning tasks. However, their evaluation has been predominantly
confined to high-resource languages such as English. In this paper, we
introduce a manually translated Bangla multi-step reasoning dataset derived
from the English Reveal dataset, featuring both binary and non-binary question
types. We conduct a controlled evaluation of English-centric and Bangla-centric
multilingual small language models on the original dataset and our translated
version to compare their ability to exploit relevant reasoning steps to produce
correct answers. Our results show that, in comparable settings, reasoning
context is beneficial for more challenging non-binary questions, but models
struggle to employ relevant Bangla reasoning steps effectively. We conclude by
exploring how reasoning steps contribute to models' predictions, highlighting
different trends across models and languages.

</details>


### [47] [Train Long, Think Short: Curriculum Learning for Efficient Reasoning](https://arxiv.org/abs/2508.08940)
*Hasan Abed Al Kader Hammoud,Kumail Alhamoud,Abed Hammoud,Elie Bou-Zeid,Marzyeh Ghassemi,Bernard Ghanem*

Main category: cs.CL

TL;DR: 本文提出了一种基于课程学习的长度控制推理方法，通过渐进式约束提高模型的推理能力和效率。实验结果表明，该方法在多个数据集上表现优于固定预算基线。


<details>
  <summary>Details</summary>
Motivation: 现有的方法依赖于固定的长度训练预算，这没有利用学习过程中的自然进展从探索到压缩。我们提出了一种课程学习策略，以利用这种自然进展，从而提高模型的推理能力和效率。

Method: 我们提出了使用Group Relative Policy Optimization (GRPO) 的长度控制推理的课程学习策略。我们的方法从慷慨的token预算开始，并在训练过程中逐渐收紧它们，鼓励模型首先发现有效的解决方案策略，然后将其提炼成更简洁的推理痕迹。我们还引入了一个平衡三个信号的奖励函数：任务正确性（通过验证器反馈）、长度效率和格式遵循（通过结构标签）。

Result: 实验结果表明，基于课程的训练在GSM8K、MATH500、SVAMP、College Math和GSM+数据集上 consistently 超过固定预算基线，实现了更高的准确性和显著的token效率提升。

Conclusion: 我们的实验表明，基于课程的训练在相同的最终预算下 consistently 超过固定预算基线，实现了更高的准确性和显著的token效率提升。我们进一步分析了奖励权重和衰减计划设计的影响，显示逐步约束作为训练高效推理模型的强大归纳偏差。

Abstract: Recent work on enhancing the reasoning abilities of large language models
(LLMs) has introduced explicit length control as a means of constraining
computational cost while preserving accuracy. However, existing approaches rely
on fixed-length training budgets, which do not take advantage of the natural
progression from exploration to compression during learning. In this work, we
propose a curriculum learning strategy for length-controlled reasoning using
Group Relative Policy Optimization (GRPO). Our method starts with generous
token budgets and gradually tightens them over training, encouraging models to
first discover effective solution strategies and then distill them into more
concise reasoning traces. We augment GRPO with a reward function that balances
three signals: task correctness (via verifier feedback), length efficiency, and
formatting adherence (via structural tags). Experiments on GSM8K, MATH500,
SVAMP, College Math, and GSM+ demonstrate that curriculum-based training
consistently outperforms fixed-budget baselines at the same final budget,
achieving higher accuracy and significantly improved token efficiency. We
further ablate the impact of reward weighting and decay schedule design,
showing that progressive constraint serves as a powerful inductive bias for
training efficient reasoning models. Our code and checkpoints are released at:
https://github.com/hammoudhasan/curriculum_grpo.

</details>


### [48] [Jointly Generating and Attributing Answers using Logits of Document-Identifier Tokens](https://arxiv.org/abs/2508.08942)
*Lucas Albarede,Jose Moreno,Lynda Tamine,Luce Lefeuvre*

Main category: cs.CL

TL;DR: 本文介绍了LoDIT，一种通过利用生成过程中的特定标记logits，在RAG中联合生成答案并忠实归因的方法。实验表明，LoDIT在多个指标上优于现有方法，并且在延迟和不同设置下的鲁棒性方面表现良好。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）表现出色，但它们仍然容易产生幻觉，这严重影响了它们的可信度。以前的工作主要集中在解决答案和归属的正确性上，而最近的研究则关注于利用内部模型信号来反映模型在生成答案时的实际决策过程。然而，这些方法增加了额外的延迟，并在直接对齐标记生成与归属生成方面表现出局限性。

Method: LoDIT通过利用生成过程中的特定标记logits，联合生成答案并忠实归因于RAG。它包含两个步骤：(1) 使用特定的标记标识符标记文档，并利用这些标记的logits来估计每个文档对答案的贡献；(2) 将这些贡献聚合为文档归因。

Result: 在专注于信任度的带有归属的文本生成基准Trust-Align上进行的实验表明，LoDIT在多个指标上显著优于最先进的模型。

Conclusion: LoDIT在信任度相关的文本生成基准测试中显著优于最先进的模型，并且在延迟和不同设置下的鲁棒性方面表现出色。

Abstract: Despite their impressive performances, Large Language Models (LLMs) remain
prone to hallucination, which critically undermines their trustworthiness.
While most of the previous work focused on tackling answer and attribution
correctness, a recent line of work investigated faithfulness, with a focus on
leveraging internal model signals to reflect a model's actual decision-making
process while generating the answer. Nevertheless, these methods induce
additional latency and have shown limitations in directly aligning token
generation with attribution generation. In this paper, we introduce LoDIT, a
method that jointly generates and faithfully attributes answers in RAG by
leveraging specific token logits during generation. It consists of two steps:
(1) marking the documents with specific token identifiers and then leveraging
the logits of these tokens to estimate the contribution of each document to the
answer during generation, and (2) aggregating these contributions into document
attributions. Experiments on a trustworthiness-focused attributed
text-generation benchmark, Trust-Align, show that LoDIT significantly
outperforms state-of-the-art models on several metrics. Finally, an in-depth
analysis of LoDIT shows both its efficiency in terms of latency and its
robustness in different settings.

</details>


### [49] [Retrospective Sparse Attention for Efficient Long-Context Generation](https://arxiv.org/abs/2508.09001)
*Seonghwan Choi,Beomseok Kang,Dongwon Jo,Jae-Joon Kim*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) are increasingly deployed in long-context tasks
such as reasoning, code generation, and multi-turn dialogue. However, inference
over extended contexts is bottlenecked by the Key-Value (KV) cache, whose
memory footprint grows linearly with sequence length and dominates latency at
each decoding step. While recent KV cache compression methods identify and load
important tokens, they focus predominantly on input contexts and fail to
address the cumulative attention errors that arise during long decoding. In
this paper, we introduce RetroAttention, a novel KV cache update technique that
retrospectively revises past attention outputs using newly arrived KV entries
from subsequent decoding steps. By maintaining a lightweight output cache,
RetroAttention enables past queries to efficiently access more relevant
context, while incurring minimal latency overhead. This breaks the
fixed-attention-output paradigm and allows continual correction of prior
approximations. Extensive experiments on long-generation benchmarks show that
RetroAttention consistently outperforms state-of-the-art (SOTA) KV compression
methods, increasing effective KV exposure by up to 1.6$\times$ and accuracy by
up to 21.9\%.

</details>


### [50] [LyS at SemEval 2025 Task 8: Zero-Shot Code Generation for Tabular QA](https://arxiv.org/abs/2508.09012)
*Adrián Gude,Roi Santos-Ríos,Francisco Prado-Valiño,Ana Ezquerro,Jesús Vilares*

Main category: cs.CL

TL;DR: 本文介绍了一种用于表格问答的零样本代码生成方法，并在SemEval 2025任务8中取得了不错的成绩。


<details>
  <summary>Details</summary>
Motivation: 本文描述了我们在SemEval 2025任务8中的参与，该任务专注于表格问答。我们希望通过零样本代码生成方法来解决表格问答问题。

Method: 我们开发了一个零样本流水线，利用大型语言模型生成能够从表格数据中提取相关信息的功能性代码。我们的方法包括一个模块化流水线，其中主要的代码生成模块由额外的组件支持，这些组件可以识别最相关的列并分析其数据类型以提高提取准确性。如果生成的代码失败，会触发迭代优化过程，将错误反馈纳入新的生成提示中以增强鲁棒性。

Result: 我们的结果表明，零样本代码生成是表格问答的有效方法，在测试阶段取得了第33名的成绩。

Conclusion: 我们的结果表明，零样本代码生成是表格问答的有效方法，尽管没有任务特定的微调，在测试阶段取得了第33名的成绩。

Abstract: This paper describes our participation in SemEval 2025 Task 8, focused on
Tabular Question Answering. We developed a zero-shot pipeline that leverages an
Large Language Model to generate functional code capable of extracting the
relevant information from tabular data based on an input question. Our approach
consists of a modular pipeline where the main code generator module is
supported by additional components that identify the most relevant columns and
analyze their data types to improve extraction accuracy. In the event that the
generated code fails, an iterative refinement process is triggered,
incorporating the error feedback into a new generation prompt to enhance
robustness. Our results show that zero-shot code generation is a valid approach
for Tabular QA, achieving rank 33 of 53 in the test phase despite the lack of
task-specific fine-tuning.

</details>


### [51] [A Survey on Training-free Alignment of Large Language Models](https://arxiv.org/abs/2508.09016)
*Birong Pan,Yongqi Li,Weiyu Zhang,Wenpeng Lu,Mayi Xu,Shen Zhou,Yuanyuan Zhu,Ming Zhong,Tieyun Qian*

Main category: cs.CL

TL;DR: 本文是对无需训练对齐方法的首次系统性回顾，旨在提供指导并推动更安全和可靠的大型语言模型发展。


<details>
  <summary>Details</summary>
Motivation: 传统对齐方法依赖于资源密集型微调，可能会导致知识退化，并在模型可访问性或计算资源受限的场景中面临挑战。无需训练的方法提供了一种有前景的替代方案，能够在不大量重新训练大型语言模型的情况下实现对齐。

Method: 本文对无需训练的对齐方法进行了系统性回顾，按预解码、解码中和解码后阶段进行分类，并从大型语言模型和多模态大型语言模型的角度进行了详细分析。

Result: 本文对无需训练的对齐方法进行了系统性回顾，分类并分析了各个阶段的机制和限制，同时指出了关键挑战和未来方向。

Conclusion: 本文综述了无需训练的对齐方法，为实践者提供了指导，并推动了更安全和更可靠的大型语言模型的发展。

Abstract: The alignment of large language models (LLMs) aims to ensure their outputs
adhere to human values, ethical standards, and legal norms. Traditional
alignment methods often rely on resource-intensive fine-tuning (FT), which may
suffer from knowledge degradation and face challenges in scenarios where the
model accessibility or computational resources are constrained. In contrast,
training-free (TF) alignment techniques--leveraging in-context learning,
decoding-time adjustments, and post-generation corrections--offer a promising
alternative by enabling alignment without heavily retraining LLMs, making them
adaptable to both open-source and closed-source environments. This paper
presents the first systematic review of TF alignment methods, categorizing them
by stages of pre-decoding, in-decoding, and post-decoding. For each stage, we
provide a detailed examination from the viewpoint of LLMs and multimodal LLMs
(MLLMs), highlighting their mechanisms and limitations. Furthermore, we
identify key challenges and future directions, paving the way for more
inclusive and effective TF alignment techniques. By synthesizing and organizing
the rapidly growing body of research, this survey offers a guidance for
practitioners and advances the development of safer and more reliable LLMs.

</details>


### [52] [LLM-as-a-Supervisor: Mistaken Therapeutic Behaviors Trigger Targeted Supervisory Feedback](https://arxiv.org/abs/2508.09042)
*Chen Xu,Zhenyu Lv,Tian Lan,Xianyang Wang,Luyao Ji,Leyang Cui,Minqiang Yang,Jian Shen,Qunxi Dong,Xiuling Liu,Juan Wang,Bin Hu*

Main category: cs.CL

TL;DR: 本文提出了一种新的治疗师培训范式，通过构建一个包含错误行为和针对性反馈的数据集，利用大型语言模型作为监督者来提高治疗师的培训效果。


<details>
  <summary>Details</summary>
Motivation: 由于直接将大型语言模型应用于患者场景存在伦理和安全问题，因此本研究转向开发一个作为监督者的LLM来训练真正的治疗师。此外，临床治疗师培训数据的隐私以及明确反馈标准的必要性与没有绝对的“黄金标准”之间的矛盾使得治疗行为的训练变得复杂。然而，许多常见的治疗错误是普遍且可识别的，这使它们成为有效的触发因素，可以提供更清晰的证据。

Method: 本文提出了一种新的治疗师培训范式：(1) 建立错误行为和针对性纠正策略的指导方针；(2) 构建一个人机交互对话反馈数据集，其中易出错的代理在访谈中自然地犯标准错误，监督代理定位并识别错误并提供针对性反馈；(3) 在该数据集上进行微调后，最终的监督模型用于真实治疗师的培训。

Result: 自动化、人工和下游评估的详细实验结果表明，基于MATE数据集微调的模型可以按照临床指南提供高质量的反馈，显示出在治疗师培训场景中的显著潜力。

Conclusion: 实验结果表明，基于MATE数据集微调的模型可以根据临床指南提供高质量的反馈，显示出在治疗师培训场景中的显著潜力。

Abstract: Although large language models (LLMs) hold significant promise in
psychotherapy, their direct application in patient-facing scenarios raises
ethical and safety concerns. Therefore, this work shifts towards developing an
LLM as a supervisor to train real therapists. In addition to the privacy of
clinical therapist training data, a fundamental contradiction complicates the
training of therapeutic behaviors: clear feedback standards are necessary to
ensure a controlled training system, yet there is no absolute "gold standard"
for appropriate therapeutic behaviors in practice. In contrast, many common
therapeutic mistakes are universal and identifiable, making them effective
triggers for targeted feedback that can serve as clearer evidence. Motivated by
this, we create a novel therapist-training paradigm: (1) guidelines for
mistaken behaviors and targeted correction strategies are first established as
standards; (2) a human-in-the-loop dialogue-feedback dataset is then
constructed, where a mistake-prone agent intentionally makes standard mistakes
during interviews naturally, and a supervisor agent locates and identifies
mistakes and provides targeted feedback; (3) after fine-tuning on this dataset,
the final supervisor model is provided for real therapist training. The
detailed experimental results of automated, human and downstream assessments
demonstrate that models fine-tuned on our dataset MATE, can provide
high-quality feedback according to the clinical guideline, showing significant
potential for the therapist training scenario.

</details>


### [53] [MVISU-Bench: Benchmarking Mobile Agents for Real-World Tasks by Multi-App, Vague, Interactive, Single-App and Unethical Instructions](https://arxiv.org/abs/2508.09057)
*Zeyu Huang,Juyuan Wang,Longfeng Chen,Boyi Xiao,Leng Cai,Yawen Zeng,Jin Xu*

Main category: cs.CL

TL;DR: 本文提出了一种新的基准测试MVISU-Bench和一个名为Aider的模块，以提高移动代理在处理复杂用户指令时的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的评估基准与现实世界脱节，无法充分满足用户多样化和复杂的需求。

Method: 本文提出了Aider模块，作为动态提示器来减轻风险并澄清用户意图，并构建了MVISU-Bench基准测试以评估移动代理的表现。

Result: Aider模块在MVISU-Bench上成功将整体成功率提高了19.55%，并在不道德和交互指令方面分别提高了53.52%和29.41%。

Conclusion: 本文通过广泛的实验和分析，突显了现有移动代理与实际用户期望之间的差距。

Abstract: Given the significant advances in Large Vision Language Models (LVLMs) in
reasoning and visual understanding, mobile agents are rapidly emerging to meet
users' automation needs. However, existing evaluation benchmarks are
disconnected from the real world and fail to adequately address the diverse and
complex requirements of users. From our extensive collection of user
questionnaire, we identified five tasks: Multi-App, Vague, Interactive,
Single-App, and Unethical Instructions. Around these tasks, we present
\textbf{MVISU-Bench}, a bilingual benchmark that includes 404 tasks across 137
mobile applications. Furthermore, we propose Aider, a plug-and-play module that
acts as a dynamic prompt prompter to mitigate risks and clarify user intent for
mobile agents. Our Aider is easy to integrate into several frameworks and has
successfully improved overall success rates by 19.55\% compared to the current
state-of-the-art (SOTA) on MVISU-Bench. Specifically, it achieves success rate
improvements of 53.52\% and 29.41\% for unethical and interactive instructions,
respectively. Through extensive experiments and analysis, we highlight the gap
between existing mobile agents and real-world user expectations.

</details>


### [54] [READER: Retrieval-Assisted Drafter for Efficient LLM Inference](https://arxiv.org/abs/2508.09072)
*Maxim Divilkovskiy,Vitaly Malygin,Sergey Zlobin,Sultan Isali,Vasily Kalugin,Stanislav Ilyushin,Nuriza Aitassova,Yi Fei,Zeng Weidi*

Main category: cs.CL

TL;DR: READER is a novel lossless speculative decoding method that enhances model-based approaches by leveraging self-repetitions in the text. It outperforms existing methods and achieves significant speedups on search-based tasks.


<details>
  <summary>Details</summary>
Motivation: The sequential nature of Large Language Models (LLMs) makes the inference process inherently difficult to accelerate, posing a significant challenge for efficient deployment. Various methods have been proposed to address this issue, with the most effective approaches often involving the training of additional draft models.

Method: READER (Retrieval-Assisted Drafter for Efficient LLM Inference) is a novel lossless speculative decoding method that enhances model-based approaches by leveraging self-repetitions in the text. Our algorithm expands the speculative decoding tree using tokens obtained through statistical search.

Result: READER requires no additional training and can reuse pre-trained speculator models, increasing the speedup by over 40%. Our method demonstrates particularly strong performance on search-based tasks, such as retrieval-augmented generation, where we achieve more than 10x speedup.

Conclusion: READER outperforms existing speculative decoding methods and demonstrates particularly strong performance on search-based tasks, such as retrieval-augmented generation, where we achieve more than 10x speedup.

Abstract: Large Language Models (LLMs) generate tokens autoregressively, with each
token depending on the preceding context. This sequential nature makes the
inference process inherently difficult to accelerate, posing a significant
challenge for efficient deployment. In recent years, various methods have been
proposed to address this issue, with the most effective approaches often
involving the training of additional draft models. In this paper, we introduce
READER (Retrieval-Assisted Drafter for Efficient LLM Inference), a novel
lossless speculative decoding method that enhances model-based approaches by
leveraging self-repetitions in the text. Our algorithm expands the speculative
decoding tree using tokens obtained through statistical search. This work
focuses on large batch sizes (>= 8), an underexplored yet important area for
industrial applications. We also analyze the key-value (KV) cache size during
speculative decoding and propose an optimization to improve performance for
large batches. As a result, READER outperforms existing speculative decoding
methods. Notably, READER requires no additional training and can reuse
pre-trained speculator models, increasing the speedup by over 40\%. Our method
demonstrates particularly strong performance on search-based tasks, such as
retrieval-augmented generation, where we achieve more than 10x speedup.

</details>


### [55] [CPO: Addressing Reward Ambiguity in Role-playing Dialogue via Comparative Policy Optimization](https://arxiv.org/abs/2508.09074)
*Xinge Ye,Rui Wang,Yuchuan Wu,Victor Ma,Feiteng Fang,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: 本文提出了Comparative Policy Optimization (CPO)，通过将样本级评分转变为比较组级评分来重新定义奖励评估范式。并引入了CharacterArena评估框架，包括两个阶段：情境化多轮角色扮演模拟和轨迹级比较评估。实验证明CPO有效缓解了奖励模糊性，并显著提高了对话质量。


<details>
  <summary>Details</summary>
Motivation: Traditional reward modeling approaches face dual challenges: subjective evaluation criteria and unstable reward signals. Human evaluation inherently combines explicit criteria with implicit comparative judgments.

Method: Comparative Policy Optimization (CPO) redefines the reward evaluation paradigm by shifting from sample-wise scoring to comparative group-wise scoring. CharacterArena evaluation framework comprises two stages: Contextualized Multi-turn Role-playing Simulation, and Trajectory-level Comparative Evaluation.

Result: Empirical results on CharacterEval, CharacterBench, and CharacterArena confirm that CPO effectively mitigates reward ambiguity and leads to substantial improvements in dialogue quality.

Conclusion: CPO effectively mitigates reward ambiguity and leads to substantial improvements in dialogue quality.

Abstract: Reinforcement Learning Fine-Tuning (RLFT) has achieved notable success in
tasks with objectively verifiable answers (e.g., code generation, mathematical
reasoning), yet struggles with open-ended subjective tasks like role-playing
dialogue. Traditional reward modeling approaches, which rely on independent
sample-wise scoring, face dual challenges: subjective evaluation criteria and
unstable reward signals.Motivated by the insight that human evaluation
inherently combines explicit criteria with implicit comparative judgments, we
propose Comparative Policy Optimization (CPO). CPO redefines the reward
evaluation paradigm by shifting from sample-wise scoring to comparative
group-wise scoring.Building on the same principle, we introduce the
CharacterArena evaluation framework, which comprises two stages:(1)
Contextualized Multi-turn Role-playing Simulation, and (2) Trajectory-level
Comparative Evaluation. By operationalizing subjective scoring via objective
trajectory comparisons, CharacterArena minimizes contextual bias and enables
more robust and fair performance evaluation. Empirical results on
CharacterEval, CharacterBench, and CharacterArena confirm that CPO effectively
mitigates reward ambiguity and leads to substantial improvements in dialogue
quality.

</details>


### [56] [Utilizing Multilingual Encoders to Improve Large Language Models for Low-Resource Languages](https://arxiv.org/abs/2508.09091)
*Imalsha Puranegedara,Themira Chathumina,Nisal Ranathunga,Nisansa de Silva,Surangika Ranathunga,Mokanarangan Thayaparan*

Main category: cs.CL

TL;DR: 本文提出了一种新的多语言LLM架构，通过融合所有中间层并使用两种策略来提升低资源语言的表现。


<details>
  <summary>Details</summary>
Motivation: 由于LLM在低资源语言（LRLs）上的表现显著下降，因此需要一种方法来提升它们在这些语言上的性能。

Method: 提出了一种新的架构，融合所有中间层，丰富传递给LLM的语言信息，并采用两种策略：(1) 全局Softmax加权，(2) Transformer Softmax模型学习特定于标记的权重。

Result: 在XNLI、IndicXNLI、Sinhala新闻分类和Amazon Reviews数据集上，Transformer Softmax模型显著优于LangBridge基线。在Sinhala分类准确率上从71.66%提高到75.86%，并在Indic语言如泰米尔语、孟加拉语和马拉雅拉姆语中取得了明显改进。

Conclusion: 该方法为构建更强大和公平的多语言LLM提供了一条可扩展、数据高效的路径。

Abstract: Large Language Models (LLMs) excel in English, but their performance degrades
significantly on low-resource languages (LRLs) due to English-centric training.
While methods like LangBridge align LLMs with multilingual encoders such as the
Massively Multilingual Text-to-Text Transfer Transformer (mT5), they typically
use only the final encoder layer. We propose a novel architecture that fuses
all intermediate layers, enriching the linguistic information passed to the
LLM. Our approach features two strategies: (1) a Global Softmax weighting for
overall layer importance, and (2) a Transformer Softmax model that learns
token-specific weights. The fused representations are mapped into the LLM's
embedding space, enabling it to process multilingual inputs. The model is
trained only on English data, without using any parallel or multilingual data.
Evaluated on XNLI, IndicXNLI, Sinhala News Classification, and Amazon Reviews,
our Transformer Softmax model significantly outperforms the LangBridge
baseline. We observe strong performance gains in LRLs, improving Sinhala
classification accuracy from 71.66% to 75.86% and achieving clear improvements
across Indic languages such as Tamil, Bengali, and Malayalam. These specific
gains contribute to an overall boost in average XNLI accuracy from 70.36% to
71.50%. This approach offers a scalable, data-efficient path toward more
capable and equitable multilingual LLMs.

</details>


### [57] [Link Prediction for Event Logs in the Process Industry](https://arxiv.org/abs/2508.09096)
*Anastasia Zhukova,Thomas Walton,Christian E. Matt,Bela Gipp*

Main category: cs.CL

TL;DR: 本文研究了如何将跨文档共指解析模型应用于过程行业的记录链接任务，通过结合自然语言推理和语义文本相似性，提高了数据质量和连接性。


<details>
  <summary>Details</summary>
Motivation: 在过程行业中，值班日志中的事件日志具有碎片化的特性，相关记录可能保持分离，这阻碍了向用户推荐以前的解决方案。

Method: 我们将记录链接（RL）视为链接预测，将其框架作为跨文档共指解析（CDCR）任务，结合自然语言推理（NLI）和语义文本相似性（STS），并将其转移到因果推断（CI）。我们适应了传统上应用于新闻领域的CDCR，将其作为RL模型在段落级别运行，同时适应过程行业的特定文本格式。

Result: 我们的RL模型分别比最佳版本的NLI和STS驱动基线提高了28%（11.43分）和27%（11.21分）。

Conclusion: 我们的工作展示了如何将最先进的CDCR模型进行领域适应，并通过增强推理能力，有效地针对过程行业进行定制，从而提高值班日志中的数据质量和连接性。

Abstract: Knowledge management (KM) is vital in the process industry for optimizing
operations, ensuring safety, and enabling continuous improvement through
effective use of operational data and past insights. A key challenge in this
domain is the fragmented nature of event logs in shift books, where related
records, e.g., entries documenting issues related to equipment or processes and
the corresponding solutions, may remain disconnected. This fragmentation
hinders the recommendation of previous solutions to the users. To address this
problem, we investigate record linking (RL) as link prediction, commonly
studied in graph-based machine learning, by framing it as a cross-document
coreference resolution (CDCR) task enhanced with natural language inference
(NLI) and semantic text similarity (STS) by shifting it into the causal
inference (CI). We adapt CDCR, traditionally applied in the news domain, into
an RL model to operate at the passage level, similar to NLI and STS, while
accommodating the process industry's specific text formats, which contain
unstructured text and structured record attributes. Our RL model outperformed
the best versions of NLI- and STS-driven baselines by 28% (11.43 points) and
27% (11.21 points), respectively. Our work demonstrates how domain adaptation
of the state-of-the-art CDCR models, enhanced with reasoning capabilities, can
be effectively tailored to the process industry, improving data quality and
connectivity in shift logs.

</details>


### [58] [AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators](https://arxiv.org/abs/2508.09101)
*Jason Chou,Ao Liu,Yuchi Deng,Zhiying Zeng,Tao Zhang,Haotian Zhu,Jianwei Cai,Yue Mao,Chenchen Zhang,Lingyun Tan,Ziyan Xu,Bohui Zhai,Hengyi Liu,Speed Zhu,Wiggin Zhou,Fengzong Lian*

Main category: cs.CL

TL;DR: 本文提出了AutoCodeGen，一种自动化生成高难度多语言代码生成数据集的方法，并介绍了AutoCodeBench系列基准，用于评估LLMs在多语言代码生成任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的代码生成基准存在一些关键限制，如依赖人工注释、主要针对Python语言以及多语言基准的难度有限和语言分布不均。

Method: 提出了一种自动化方法AutoCodeGen，用于生成无需人工注释的高难度多语言代码生成数据集。通过LLMs生成测试输入，并通过多语言沙箱获取测试输出，同时通过逆序问题生成和多个过滤步骤确保数据质量。

Result: 在AutoCodeBench及其简化版AutoCodeBench-Lite上评估了30多个领先的开源和专有LLMs，结果显示即使最先进的LLMs也难以应对这些任务的复杂性、多样性和多语言特性。此外，引入了专门用于基础模型评估其少样本代码生成能力的AutoCodeBench-Complete。

Conclusion: AutoCodeBench系列旨在作为一个有价值的资源，激励社区关注更具挑战性和实际的多语言代码生成场景。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
various domains, with code generation emerging as a key area of focus. While
numerous benchmarks have been proposed to evaluate their code generation
abilities, these benchmarks face several critical limitations. First, they
often rely on manual annotations, which are time-consuming and difficult to
scale across different programming languages and problem complexities. Second,
most existing benchmarks focus primarily on Python, while the few multilingual
benchmarks suffer from limited difficulty and uneven language distribution. To
address these challenges, we propose AutoCodeGen, an automated method for
generating high-difficulty multilingual code generation datasets without manual
annotations. AutoCodeGen ensures the correctness and completeness of test cases
by generating test inputs with LLMs and obtaining test outputs through a
multilingual sandbox, while achieving high data quality through reverse-order
problem generation and multiple filtering steps. Using this novel method, we
introduce AutoCodeBench, a large-scale code generation benchmark comprising
3,920 problems evenly distributed across 20 programming languages. It is
specifically designed to evaluate LLMs on challenging, diverse, and practical
multilingual tasks. We evaluate over 30 leading open-source and proprietary
LLMs on AutoCodeBench and its simplified version AutoCodeBench-Lite. The
results show that even the most advanced LLMs struggle with the complexity,
diversity, and multilingual nature of these tasks. Besides, we introduce
AutoCodeBench-Complete, specifically designed for base models to assess their
few-shot code generation capabilities. We hope the AutoCodeBench series will
serve as a valuable resource and inspire the community to focus on more
challenging and practical multilingual code generation scenarios.

</details>


### [59] [SinLlama -- A Large Language Model for Sinhala](https://arxiv.org/abs/2508.09115)
*H. W. K. Aravinda,Rashad Sirajudeen,Samith Karunathilake,Nisansa de Silva,Surangika Ranathunga,Rishemjit Kaur*

Main category: cs.CL

TL;DR: 该研究扩展了Llama-3-8B以更好地支持僧伽罗语，创建了首个具有显式僧伽罗语支持的开源LLM SinLlama，并在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 低资源语言如僧伽罗语常常被开源大型语言模型（LLM）忽视，因此需要扩展现有模型以更好地服务这些语言。

Method: 通过增强LLM分词器的僧伽罗语特定词汇，并在清理后的1000万僧伽罗语语料库上进行持续预训练，创建了SinLlama模型。

Result: SinLlama在三个文本分类任务中表现出色，显著优于Llama-3-8B的基础版和指令版。

Conclusion: 该研究成功扩展了一个现有的多语言LLM（Llama-3-8B），以更好地支持僧伽罗语，创建了第一个具有显式僧伽罗语支持的基于解码器的开源LLM SinLlama。

Abstract: Low-resource languages such as Sinhala are often overlooked by open-source
Large Language Models (LLMs). In this research, we extend an existing
multilingual LLM (Llama-3-8B) to better serve Sinhala. We enhance the LLM
tokenizer with Sinhala specific vocabulary and perform continual pre-training
on a cleaned 10 million Sinhala corpus, resulting in the SinLlama model. This
is the very first decoder-based open-source LLM with explicit Sinhala support.
When SinLlama was instruction fine-tuned for three text classification tasks,
it outperformed base and instruct variants of Llama-3-8B by a significant
margin.

</details>


### [60] [OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows](https://arxiv.org/abs/2508.09124)
*Weixuan Wang,Dongge Han,Daniel Madrigal Diaz,Jin Xu,Victor Rühle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: OdysseyBench is a comprehensive benchmark for evaluating LLM agents on long-horizon workflows across diverse office applications. It includes two splits with real-world and synthesized tasks, and introduces HomerAgents for scalable benchmark creation.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks predominantly focus on atomic tasks that are self-contained and independent, failing to capture the long-term contextual dependencies and multi-interaction coordination required in realistic scenarios.

Method: We propose HomerAgents, a multi-agent framework that automates the generation of long-horizon workflow benchmarks through systematic environment exploration, task generation, and dialogue synthesis.

Result: OdysseyBench effectively challenges state-of-the-art LLM agents, providing more accurate assessment of their capabilities in complex, real-world contexts compared to existing atomic task benchmarks.

Conclusion: OdysseyBench will serve as a valuable resource for advancing the development and evaluation of LLM agents in real-world productivity scenarios.

Abstract: Autonomous agents powered by large language models (LLMs) are increasingly
deployed in real-world applications requiring complex, long-horizon workflows.
However, existing benchmarks predominantly focus on atomic tasks that are
self-contained and independent, failing to capture the long-term contextual
dependencies and multi-interaction coordination required in realistic
scenarios. To address this gap, we introduce OdysseyBench, a comprehensive
benchmark for evaluating LLM agents on long-horizon workflows across diverse
office applications including Word, Excel, PDF, Email, and Calendar. Our
benchmark comprises two complementary splits: OdysseyBench+ with 300 tasks
derived from real-world use cases, and OdysseyBench-Neo with 302 newly
synthesized complex tasks. Each task requires agent to identify essential
information from long-horizon interaction histories and perform multi-step
reasoning across various applications. To enable scalable benchmark creation,
we propose HomerAgents, a multi-agent framework that automates the generation
of long-horizon workflow benchmarks through systematic environment exploration,
task generation, and dialogue synthesis. Our extensive evaluation demonstrates
that OdysseyBench effectively challenges state-of-the-art LLM agents, providing
more accurate assessment of their capabilities in complex, real-world contexts
compared to existing atomic task benchmarks. We believe that OdysseyBench will
serve as a valuable resource for advancing the development and evaluation of
LLM agents in real-world productivity scenarios. In addition, we release
OdysseyBench and HomerAgents to foster research along this line.

</details>


### [61] [Complex Logical Instruction Generation](https://arxiv.org/abs/2508.09125)
*Mian Zhang,Shujian Liu,Sixun Dong,Ming Yin,Yebowen Hu,Xun Wang,Steven Ma,Song Wang,Sathish Reddy Indurthi,Haoyun Deng,Zhiyu Zoey Chen,Kaiqiang Song*

Main category: cs.CL

TL;DR: 本文提出了LogicIFGen和LogicIFEval，用于生成和评估逻辑丰富的指令，发现当前大型语言模型在遵循这些指令方面仍有显著不足。


<details>
  <summary>Details</summary>
Motivation: 随着任务变得更具挑战性，自然语言指令中嵌入的逻辑结构变得越来越复杂，但大型语言模型在处理这些逻辑丰富的指令方面的表现仍缺乏研究。

Method: 提出了一种可扩展的自动化框架LogicIFGen，用于从代码函数生成可验证的指令，并构建了一个包含426个可验证逻辑丰富指令的基准测试LogicIFEval。

Result: 实验表明，当前最先进的大型语言模型只能正确遵循少于60%的指令，显示出明显的不足之处。

Conclusion: 当前最先进的大型语言模型在遵循LogicIFEval中的指令方面仍然存在困难，这表明在指令跟随能力上存在显著不足。

Abstract: Instruction following has catalyzed the recent era of Large Language Models
(LLMs) and is the foundational skill underpinning more advanced capabilities
such as reasoning and agentic behaviors. As tasks grow more challenging, the
logic structures embedded in natural language instructions becomes increasingly
intricate. However, how well LLMs perform on such logic-rich instructions
remains under-explored. We propose LogicIFGen and LogicIFEval. LogicIFGen is a
scalable, automated framework for generating verifiable instructions from code
functions, which can naturally express rich logic such as conditionals,
nesting, recursion, and function calls. We further curate a collection of
complex code functions and use LogicIFGen to construct LogicIFEval, a benchmark
comprising 426 verifiable logic-rich instructions. Our experiments demonstrate
that current state-of-the-art LLMs still struggle to correctly follow the
instructions in LogicIFEval. Most LLMs can only follow fewer than 60% of the
instructions, revealing significant deficiencies in the instruction-following
ability. Code and Benchmark: https://github.com/mianzhang/LogicIF

</details>


### [62] [Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models](https://arxiv.org/abs/2508.09138)
*Wen Wang,Bozhen Fang,Chenchen Jing,Yongliang Shen,Yangyi Shen,Qiuyu Wang,Hao Ouyang,Hao Chen,Chunhua Shen*

Main category: cs.CL

TL;DR: 本文研究了扩散大语言模型中的时间振荡现象，并提出两种方法来利用时间一致性，以提高生成效果。


<details>
  <summary>Details</summary>
Motivation: 当前的解码策略忽略了中间预测信息，而我们的研究旨在利用这些信息来提高生成质量。

Method: 我们提出了两种方法：时间自一致投票（Temporal Self-Consistency Voting）和时间一致性强化（Temporal Consistency Reinforcement）。前者是一种无需训练的解码策略，后者则通过时间语义熵作为奖励信号来鼓励稳定生成。

Result: 在多个基准测试中，我们的方法表现出色。例如，在Countdown数据集上，仅使用负TSE奖励就实现了24.7%的显著提升，结合准确率奖励后，在GSM8K、MATH500、SVAMP和Countdown上分别实现了2.0%、4.3%、6.6%和25.3%的绝对提升。

Conclusion: 我们的研究揭示了扩散大语言模型中的时间振荡现象，并提出了两种有效的方法来利用时间一致性，从而提升生成效果。

Abstract: Diffusion large language models (dLLMs) generate text through iterative
denoising, yet current decoding strategies discard rich intermediate
predictions in favor of the final output. Our work here reveals a critical
phenomenon, temporal oscillation, where correct answers often emerge in the
middle process, but are overwritten in later denoising steps. To address this
issue, we introduce two complementary methods that exploit temporal
consistency: 1) Temporal Self-Consistency Voting, a training-free, test-time
decoding strategy that aggregates predictions across denoising steps to select
the most consistent output; and 2) a post-training method termed Temporal
Consistency Reinforcement, which uses Temporal Semantic Entropy (TSE), a
measure of semantic stability across intermediate predictions, as a reward
signal to encourage stable generations. Empirical results across multiple
benchmarks demonstrate the effectiveness of our approach. Using the negative
TSE reward alone, we observe a remarkable average improvement of 24.7% on the
Countdown dataset over an existing dLLM. Combined with the accuracy reward, we
achieve absolute gains of 2.0% on GSM8K, 4.3% on MATH500, 6.6% on SVAMP, and
25.3% on Countdown, respectively. Our findings underscore the untapped
potential of temporal dynamics in dLLMs and offer two simple yet effective
tools to harness them.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [63] [Fine-grained Video Dubbing Duration Alignment with Segment Supervised Preference Optimization](https://arxiv.org/abs/2508.08550)
*Chaoqun Cui,Liangbin Huang,Shijing Wang,Zhe Tong,Zhaolong Huang,Xiao Zeng,Xiaofeng Liu*

Main category: cs.SD

TL;DR: 本文提出了一种新的视频配音时长对齐方法SSPO，通过段监督偏好优化策略，有效解决了源语音和目标语音时长不匹配的问题，提升了音画同步效果。


<details>
  <summary>Details</summary>
Motivation: 由于不同语言的信息密度不同，目标语音的时长常常与源语音不匹配，导致音画不同步，严重影响观众体验。因此，需要一种有效的时长对齐方法来解决这一问题。

Method: 提出了一种基于大语言模型的视频配音机器翻译中的时长对齐方法，称为段监督偏好优化（SSPO）。该方法采用逐段采样策略和细粒度损失函数，以减轻源语音和目标语音之间的时长不匹配问题。

Result: 实验结果表明，SSPO方法在时长对齐任务中表现优于现有方法，能够有效提升视频配音的质量。

Conclusion: SSPO方法在时长对齐任务中表现出色，能够有效解决源语音和目标语音时长不匹配的问题，从而改善视频配音的音画同步效果。

Abstract: Video dubbing aims to translate original speech in visual media programs from
the source language to the target language, relying on neural machine
translation and text-to-speech technologies. Due to varying information
densities across languages, target speech often mismatches the source speech
duration, causing audio-video synchronization issues that significantly impact
viewer experience. In this study, we approach duration alignment in LLM-based
video dubbing machine translation as a preference optimization problem. We
propose the Segment Supervised Preference Optimization (SSPO) method, which
employs a segment-wise sampling strategy and fine-grained loss to mitigate
duration mismatches between source and target lines. Experimental results
demonstrate that SSPO achieves superior performance in duration alignment
tasks.

</details>


### [64] [Revealing the Role of Audio Channels in ASR Performance Degradation](https://arxiv.org/abs/2508.08967)
*Kuan-Tang Huang,Li-Wei Chen,Hung-Shin Lee,Berlin Chen,Hsin-Min Wang*

Main category: cs.SD

TL;DR: 本研究提出了一种归一化技术，用于减轻不同录音通道对自动语音识别（ASR）性能的影响，并在未见过的通道和语言上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 尽管之前的研究已经证明了不同录音通道对ASR性能的影响，但通常将其归因于训练和测试语料库之间的不匹配。本研究认为，由不同录音通道引起的语音特征变化会从根本上损害ASR性能。

Method: 提出了一种归一化技术，通过将ASR模型中的内部特征表示与来自干净参考通道的特征对齐，以减轻不同录音通道的影响。

Result: 该方法显著提高了在 previously unseen 通道和语言上的ASR性能，表明其能够泛化到通道和语言差异。

Conclusion: 本研究提出了一种归一化技术，旨在减轻不同录音通道对ASR性能的影响，并显著提高了在未见过的通道和语言上的ASR性能，展示了其在通道和语言差异上的泛化能力。

Abstract: Pre-trained automatic speech recognition (ASR) models have demonstrated
strong performance on a variety of tasks. However, their performance can
degrade substantially when the input audio comes from different recording
channels. While previous studies have demonstrated this phenomenon, it is often
attributed to the mismatch between training and testing corpora. This study
argues that variations in speech characteristics caused by different recording
channels can fundamentally harm ASR performance. To address this limitation, we
propose a normalization technique designed to mitigate the impact of channel
variation by aligning internal feature representations in the ASR model with
those derived from a clean reference channel. This approach significantly
improves ASR performance on previously unseen channels and languages,
highlighting its ability to generalize across channel and language differences.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [65] [P/D-Device: Disaggregated Large Language Model between Cloud and Devices](https://arxiv.org/abs/2508.09035)
*Yibo Jin,Yixu Xu,Yue Chen,Chengbin Wang,Tao Wang,Jiaqi Huang,Rongfei Zhang,Yiming Dong,Yuting Yan,Ke Cheng,Yingjie Zhu,Shulan Wang,Qianqian Tang,Shuaishuai Meng,Guanxin Cheng,Ze Wang,Shuyan Miao,Ketao Wang,Wen Liu,Yifan Yang,Tong Zhang,Anran Wang,Chengzhou Lu,Tiantian Dong,Yongsheng Zhang,Zhe Wang,Hefei Guo,Hongjie Liu,Wei Lu,Zhengyong Zhang*

Main category: cs.DC

TL;DR: 本文提出了一种将大型语言模型分离到云和设备上的方案，以解决资源瓶颈问题，并通过实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 由于云中的长时间占用和设备上的有限计算能力，现有的方法无法满足需求，因此需要一种新的解决方案。

Method: 本文提出了一种名为P/D-Device的方案，将大型语言模型分离到云和设备上，并使用一个算法来决定最佳设置。

Result: 实验结果表明，TTFT至少减少了60%，最大TPOT约为几十毫秒，云吞吐量增加了多达15倍。

Conclusion: 本文提出了一种将大型语言模型分离到云和设备上的方案，以解决资源瓶颈问题，并通过实验验证了其优越性。

Abstract: Serving disaggregated large language models has been widely adopted in
industrial practice for enhanced performance. However, too many tokens
generated in decoding phase, i.e., occupying the resources for a long time,
essentially hamper the cloud from achieving a higher throughput. Meanwhile, due
to limited on-device resources, the time to first token (TTFT), i.e., the
latency of prefill phase, increases dramatically with the growth on prompt
length. In order to concur with such a bottleneck on resources, i.e., long
occupation in cloud and limited on-device computing capacity, we propose to
separate large language model between cloud and devices. That is, the cloud
helps a portion of the content for each device, only in its prefill phase.
Specifically, after receiving the first token from the cloud, decoupling with
its own prefill, the device responds to the user immediately for a lower TTFT.
Then, the following tokens from cloud are presented via a speed controller for
smoothed TPOT (the time per output token), until the device catches up with the
progress. On-device prefill is then amortized using received tokens while the
resource usage in cloud is controlled. Moreover, during cloud prefill, the
prompt can be refined, using those intermediate data already generated, to
further speed up on-device inference. We implement such a scheme P/D-Device,
and confirm its superiority over other alternatives. We further propose an
algorithm to decide the best settings. Real-trace experiments show that TTFT
decreases at least 60%, maximum TPOT is about tens of milliseconds, and cloud
throughput increases by up to 15x.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [66] [MultiAiTutor: Child-Friendly Educational Multilingual Speech Generation Tutor with LLMs](https://arxiv.org/abs/2508.08715)
*Xiaoxue Gao,Huayun Zhang,Nancy F. Chen*

Main category: eess.AS

TL;DR: 本文提出了MultiAiTutor，一个针对教育目的的多语言生成AI导师，通过在三种低资源语言中进行文化相关的图像描述任务，实现了儿童友好语音生成的优越性能。


<details>
  <summary>Details</summary>
Motivation: 生成语音模型在个性化师生互动中展现出巨大潜力，但在低资源语言中实现高质量、儿童友好的语音生成仍具挑战性。

Method: 提出MultiAiTutor，这是一个教育多语言生成AI导师，利用LLM架构进行语音生成，针对教育目的进行了定制。

Result: 实验结果表明，MultiAiTutor在客观指标和主观评估中均优于基线方法。

Conclusion: MultiAiTutor表现出优于基线方法的性能，展示了其在低资源语言中进行儿童友好语音生成的潜力。

Abstract: Generative speech models have demonstrated significant potential in
personalizing teacher-student interactions, offering valuable real-world
applications for language learning in children's education. However, achieving
high-quality, child-friendly speech generation remains challenging,
particularly for low-resource languages across diverse languages and cultural
contexts. In this paper, we propose MultiAiTutor, an educational multilingual
generative AI tutor with child-friendly designs, leveraging LLM architecture
for speech generation tailored for educational purposes. We propose to
integrate age-appropriate multilingual speech generation using LLM
architectures, facilitating young children's language learning through
culturally relevant image-description tasks in three low-resource languages:
Singaporean-accent Mandarin, Malay, and Tamil. Experimental results from both
objective metrics and subjective evaluations demonstrate the superior
performance of the proposed MultiAiTutor compared to baseline methods.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [67] [E3-Rewrite: Learning to Rewrite SQL for Executability, Equivalence,and Efficiency](https://arxiv.org/abs/2508.09023)
*Dongjie Xu,Yue Cui,Weijie Shi,Qingzhi Ma,Hanghui Guo,Jiaming Li,Yao Zhao,Ruiyuan Zhang,Shimin Di,Jia Zhu,Kai Zheng,Jiajie Xu*

Main category: cs.DB

TL;DR: E3-Rewrite is an LLM-based SQL rewriting framework that improves upon rule-based approaches by integrating context construction and reinforcement learning. It achieves better performance and handles complex queries more effectively.


<details>
  <summary>Details</summary>
Motivation: Most existing methods for SQL query rewriting rely on predefined rewrite rules, which face limitations in generalizing to novel query patterns and capturing complex rewriting strategies. Directly applying LLMs often results in suboptimal or non-equivalent rewrites due to a lack of execution awareness and semantic grounding.

Method: E3-Rewrite is an LLM-based SQL rewriting framework that integrates two core components: a context construction module and a reinforcement learning framework. The context module leverages execution plans and retrieved demonstrations to build bottleneck-aware prompts that guide inference-time rewriting. A reward function targeting executability, equivalence, and efficiency is designed, evaluated via syntax checks, equivalence verification, and cost estimation. A staged curriculum is adopted to ensure stable multi-objective learning.

Result: E3-Rewrite achieves up to a 25.6% reduction in query execution time compared to state-of-the-art methods across multiple SQL benchmarks. It also delivers up to 24.4% more successful rewrites, expanding coverage to complex queries that previous systems failed to handle.

Conclusion: E3-Rewrite achieves up to a 25.6% reduction in query execution time compared to state-of-the-art methods across multiple SQL benchmarks. Moreover, it delivers up to 24.4% more successful rewrites, expanding coverage to complex queries that previous systems failed to handle.

Abstract: SQL query rewriting aims to reformulate a query into a more efficient form
while preserving equivalence. Most existing methods rely on predefined rewrite
rules. However, such rule-based approaches face fundamental limitations: (1)
fixed rule sets generalize poorly to novel query patterns and struggle with
complex queries; (2) a wide range of effective rewriting strategies cannot be
fully captured by declarative rules. To overcome these issues, we propose using
large language models (LLMs) to generate rewrites. LLMs can capture complex
strategies, such as evaluation reordering and CTE rewriting. Despite this
potential, directly applying LLMs often results in suboptimal or non-equivalent
rewrites due to a lack of execution awareness and semantic grounding. To
address these challenges, We present E3-Rewrite, an LLM-based SQL rewriting
framework that produces executable, equivalent, and efficient queries. It
integrates two core components: a context construction module and a
reinforcement learning framework. First, the context module leverages execution
plans and retrieved demonstrations to build bottleneck-aware prompts that guide
inference-time rewriting. Second, we design a reward function targeting
executability, equivalence, and efficiency, evaluated via syntax checks,
equivalence verification, and cost estimation. Third, to ensure stable
multi-objective learning, we adopt a staged curriculum that first emphasizes
executability and equivalence, then gradually incorporates efficiency.
Extensive experiments show that E3-Rewrite achieves up to a 25.6\% reduction in
query execution time compared to state-of-the-art methods across multiple SQL
benchmarks. Moreover, it delivers up to 24.4\% more successful rewrites,
expanding coverage to complex queries that previous systems failed to handle.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [68] [Bilevel MCTS for Amortized O(1) Node Selection in Classical Planning](https://arxiv.org/abs/2508.08385)
*Masataro Asai*

Main category: cs.AI

TL;DR: 本文改进了MCTS方法，通过分层修改和树折叠技术，提高了经典规划中的节点选择效率。


<details>
  <summary>Details</summary>
Motivation: MCTS在经典规划中面临节点选择时间过长的问题，因为搜索深度d可以很大，导致节点选择的时间复杂度为O(log N)，而传统队列方法的复杂度为O(1)。

Method: 本文提出了一个分层修改的MCTS方法，从每个选定的叶子节点运行最佳优先搜索，并引入了树折叠技术以减少动作选择步骤。

Result: 该方法实现了节点选择的摊销O(1)时间复杂度，与传统队列方法相当，并通过树折叠技术进一步提升了性能。

Conclusion: 本文提出了一种改进的MCTS方法，通过分层修改和树折叠技术，显著提高了节点选择的效率，从而在经典规划问题中实现了更高效的蒙特卡洛树搜索。

Abstract: We study an efficient implementation of Multi-Armed Bandit (MAB)-based
Monte-Carlo Tree Search (MCTS) for classical planning. One weakness of MCTS is
that it spends a significant time deciding which node to expand next. While
selecting a node from an OPEN list with $N$ nodes has $O(1)$ runtime complexity
with traditional array-based priority-queues for dense integer keys, the
tree-based OPEN list used by MCTS requires $O(\log N)$, which roughly
corresponds to the search depth $d$. In classical planning, $d$ is arbitrarily
large (e.g., $2^k-1$ in $k$-disk Tower-of-Hanoi) and the runtime for node
selection is significant, unlike in game tree search, where the cost is
negligible compared to the node evaluation (rollouts) because $d$ is inherently
limited by the game (e.g., $d\leq 361$ in Go). To improve this bottleneck, we
propose a bilevel modification to MCTS that runs a best-first search from each
selected leaf node with an expansion budget proportional to $d$, which achieves
amortized $O(1)$ runtime for node selection, equivalent to the traditional
queue-based OPEN list. In addition, we introduce Tree Collapsing, an
enhancement that reduces action selection steps and further improves the
performance.

</details>


### [69] [Designing Memory-Augmented AR Agents for Spatiotemporal Reasoning in Personalized Task Assistance](https://arxiv.org/abs/2508.08774)
*Dongwook Choi,Taeyoon Kwon,Dongil Yang,Hyojun Kim,Jinyoung Yeo*

Main category: cs.AI

TL;DR: 本文提出了一种记忆增强型AR代理框架，旨在解决当前AR代理在处理复杂多步骤场景时的不足，并通过四个模块实现个性化任务协助。


<details>
  <summary>Details</summary>
Motivation: 当前的AR代理在支持即时任务方面效果良好，但在需要理解并利用用户长期经验和偏好的复杂多步骤场景中存在困难。这种限制源于它们无法捕捉、保留和在时空上下文中进行推理的历史用户交互。

Method: 本文提出了一个记忆增强型AR代理的概念框架，该框架由四个相互关联的模块组成：(1) 感知模块用于多模态传感器处理，(2) 记忆模块用于持久的时空经验存储，(3) 空间时间推理模块用于综合过去和现在的情境，(4) 执行器模块用于有效的AR通信。

Result: 本文提出了一种概念框架，能够通过学习和适应用户特定经验来提供个性化的任务协助。此外，还提出了一个实施路线图、未来评估策略、潜在目标应用和用例，以展示框架在多个领域的实际适用性。

Conclusion: 本文旨在推动未来研究，开发更智能的AR系统，能够有效地将用户的交互历史与适应性的、情境感知的任务协助结合起来。

Abstract: Augmented Reality (AR) systems are increasingly integrating foundation
models, such as Multimodal Large Language Models (MLLMs), to provide more
context-aware and adaptive user experiences. This integration has led to the
development of AR agents to support intelligent, goal-directed interactions in
real-world environments. While current AR agents effectively support immediate
tasks, they struggle with complex multi-step scenarios that require
understanding and leveraging user's long-term experiences and preferences. This
limitation stems from their inability to capture, retain, and reason over
historical user interactions in spatiotemporal contexts. To address these
challenges, we propose a conceptual framework for memory-augmented AR agents
that can provide personalized task assistance by learning from and adapting to
user-specific experiences over time. Our framework consists of four
interconnected modules: (1) Perception Module for multimodal sensor processing,
(2) Memory Module for persistent spatiotemporal experience storage, (3)
Spatiotemporal Reasoning Module for synthesizing past and present contexts, and
(4) Actuator Module for effective AR communication. We further present an
implementation roadmap, a future evaluation strategy, a potential target
application and use cases to demonstrate the practical applicability of our
framework across diverse domains. We aim for this work to motivate future
research toward developing more intelligent AR systems that can effectively
bridge user's interaction history with adaptive, context-aware task assistance.

</details>


### [70] [A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions](https://arxiv.org/abs/2508.08795)
*Amir Mohammad Salehoof,Ali Ramezani,Yadollah Yaghoobzadeh,Majid Nili Ahmadabadi*

Main category: cs.AI

TL;DR: 本文提出了一种基于功能的分类法，以分析知识编辑方法在不同知识类型中的应用，并总结了现有方法的优缺点及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有的综述主要关注编辑机制（例如参数变化与外部记忆），但往往忽略了被编辑知识的功能。本文旨在提供一个更全面的视角，以更好地理解编辑效果如何依赖于目标知识的性质。

Method: 本文采用了一种新的基于功能的分类法，以分析不同机制如何应用于各种类型的知识（如事实性、时间性、概念性、常识性和社会性知识）。

Result: 本文映射了当前的研究现状，概述了现有方法的优缺点，定义了问题，调查了评估任务和数据集，并总结了开放性挑战和未来方向。

Conclusion: 本文通过引入基于功能的分类法，提供了对知识编辑方法的更全面视角，并指出了当前方法的优缺点，定义了问题，调查了评估任务和数据集，并总结了开放性挑战和未来方向。

Abstract: Large language models (LLMs) acquire vast knowledge from large text corpora,
but this information can become outdated or inaccurate. Since retraining is
computationally expensive, knowledge editing offers an efficient alternative --
modifying internal knowledge without full retraining. These methods aim to
update facts precisely while preserving the model's overall capabilities. While
existing surveys focus on the mechanism of editing (e.g., parameter changes vs.
external memory), they often overlook the function of the knowledge being
edited. This survey introduces a novel, complementary function-based taxonomy
to provide a more holistic view. We examine how different mechanisms apply to
various knowledge types -- factual, temporal, conceptual, commonsense, and
social -- highlighting how editing effectiveness depends on the nature of the
target knowledge. By organizing our review along these two axes, we map the
current landscape, outline the strengths and limitations of existing methods,
define the problem formally, survey evaluation tasks and datasets, and conclude
with open challenges and future directions.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [71] [Adaptive Personalized Conversational Information Retrieval](https://arxiv.org/abs/2508.08634)
*Fengran Mo,Yuchen Hui,Yuxing Tian,Zhaoxuan Tan,Chuan Meng,Zhan Su,Kaiyu Huang,Jian-Yun Nie*

Main category: cs.IR

TL;DR: 本文提出了一种自适应个性化对话信息检索框架APCIR，通过动态调整个性化级别来提高搜索效果。


<details>
  <summary>Details</summary>
Motivation: 现有的研究通常隐式地使用大型语言模型来整合用户的个人资料和对话上下文，而没有区分每个查询回合的具体需求。这种“一刀切”的个性化策略可能导致次优结果。因此，需要一种能够根据查询需求动态调整个性化的策略。

Method: 本文提出了一种自适应个性化方法，首先确定查询所需的个性化级别，并将个性化查询与其他查询重写相结合以生成各种增强查询。然后，设计了一种个性化感知的排名融合方法，根据所需的个性化级别动态分配不同重写查询的融合权重。

Result: 实验结果表明，APCIR框架在两个TREC iKAT数据集上表现出色，优于现有的最先进方法。

Conclusion: 本文提出的自适应个性化对话信息检索框架APCIR在两个TREC iKAT数据集上进行了评估，并证实了其有效性，优于现有的最先进方法。

Abstract: Personalized conversational information retrieval (CIR) systems aim to
satisfy users' complex information needs through multi-turn interactions by
considering user profiles. However, not all search queries require
personalization. The challenge lies in appropriately incorporating
personalization elements into search when needed. Most existing studies
implicitly incorporate users' personal information and conversational context
using large language models without distinguishing the specific requirements
for each query turn. Such a ``one-size-fits-all'' personalization strategy
might lead to sub-optimal results. In this paper, we propose an adaptive
personalization method, in which we first identify the required personalization
level for a query and integrate personalized queries with other query
reformulations to produce various enhanced queries. Then, we design a
personalization-aware ranking fusion approach to assign fusion weights
dynamically to different reformulated queries, depending on the required
personalization level. The proposed adaptive personalized conversational
information retrieval framework APCIR is evaluated on two TREC iKAT datasets.
The results confirm the effectiveness of adaptive personalization of APCIR by
outperforming state-of-the-art methods.

</details>


<div id='cs.PF'></div>

# cs.PF [[Back]](#toc)

### [72] [Maximizing GPU Efficiency via Optimal Adapter Caching: An Analytical Approach for Multi-Tenant LLM Serving](https://arxiv.org/abs/2508.08343)
*Ferran Agullo,Joan Oliveras,Chen Wang,Alberto Gutierrez-Torre,Olivier Tardieu,Alaa Youssef,Jordi Torres,Josep Ll. Berral*

Main category: cs.PF

TL;DR: 本文提出了一种AI驱动的管道，用于在单节点设置中优化LLM适配器的分配，提高了性能和资源效率，并开发了一个数字孪生体来复制在线LLM-适配器服务系统。


<details>
  <summary>Details</summary>
Motivation: 由于服务广泛的适配器会引入多个和显著的开销，导致性能下降和最佳放置的挑战，因此需要一种有效的解决方案来优化适配器的分配。

Method: 我们提出了一种分析性的、AI驱动的管道，以准确确定单节点设置中适配器的最佳分配。这种分配最大化了性能，有效利用了GPU资源，同时防止了请求饥饿。

Result: 数字孪生体在吞吐量方面与实际结果的SMAPE差异不超过5.5%，所提出的管道能够准确预测最优放置，且延迟最小。

Conclusion: 我们的方法通过深入分析LLM适配器服务，考虑了开销和性能变化，并开发了第一个能够复制在线LLM-适配器服务系统的数字孪生体。实验结果表明，数字孪生体在吞吐量方面与实际结果的SMAPE差异不超过5.5%，所提出的管道能够准确预测最优放置，且延迟最小。

Abstract: Serving LLM adapters has gained significant attention as an effective
approach to adapt general-purpose language models to diverse, task-specific use
cases. However, serving a wide range of adapters introduces several and
substantial overheads, leading to performance degradation and challenges in
optimal placement. To address these challenges, we present an analytical,
AI-driven pipeline that accurately determines the optimal allocation of
adapters in single-node setups. This allocation maximizes performance,
effectively using GPU resources, while preventing request starvation.
Crucially, the proposed allocation is given based on current workload patterns.
These insights in single-node setups can be leveraged in multi-replica
deployments for overall placement, load balancing and server configuration,
ultimately enhancing overall performance and improving resource efficiency. Our
approach builds on an in-depth analysis of LLM adapter serving, accounting for
overheads and performance variability, and includes the development of the
first Digital Twin capable of replicating online LLM-adapter serving systems
with matching key performance metrics. The experimental results demonstrate
that the Digital Twin achieves a SMAPE difference of no more than 5.5% in
throughput compared to real results, and the proposed pipeline accurately
predicts the optimal placement with minimal latency.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [73] [Re:Verse -- Can Your VLM Read a Manga?](https://arxiv.org/abs/2508.08508)
*Aaditya Baranwal,Madhav Kataria,Naitik Agrawal,Yogesh S Rawat,Shruti Vyas*

Main category: cs.CV

TL;DR: 本文揭示了当前视觉语言模型在处理连续视觉叙事时的局限性，并提出了一种新的评估框架来系统地表征这些限制。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLMs）在处理顺序视觉故事时，在表面识别和深度叙述推理之间存在关键差距。虽然最近的大规模多模态模型在单个面板解释方面表现出色，但它们在时间因果关系和跨面板连贯性方面系统性失败，这是连贯故事理解的核心要求。

Method: 本文的方法包括(i)通过对齐轻小说文本将视觉元素与叙事结构联系起来的严格注释协议，(ii)跨多个推理范式的全面评估，包括直接推理和检索增强生成，以及(iii)揭示当前VLMs联合表示中基本不对齐的跨模态相似性分析。

Result: 通过对Re:Zero漫画11章308个标注面板的应用，我们进行了首次系统研究，通过三个核心评估轴：生成式讲故事、上下文对话定位和时间推理，展示了当前模型缺乏真正的故事级智能，尤其是在非线性叙述、角色一致性和跨长序列的因果推理方面存在问题。

Conclusion: 本文建立了评估叙事智能的基础和实用方法，并提供了关于多模态模型在离散视觉叙事中的深度序列理解能力的见解。

Abstract: Current Vision Language Models (VLMs) demonstrate a critical gap between
surface-level recognition and deep narrative reasoning when processing
sequential visual storytelling. Through a comprehensive investigation of manga
narrative understanding, we reveal that while recent large multimodal models
excel at individual panel interpretation, they systematically fail at temporal
causality and cross-panel cohesion, core requirements for coherent story
comprehension. We introduce a novel evaluation framework that combines
fine-grained multimodal annotation, cross-modal embedding analysis, and
retrieval-augmented assessment to systematically characterize these
limitations.
  Our methodology includes (i) a rigorous annotation protocol linking visual
elements to narrative structure through aligned light novel text, (ii)
comprehensive evaluation across multiple reasoning paradigms, including direct
inference and retrieval-augmented generation, and (iii) cross-modal similarity
analysis revealing fundamental misalignments in current VLMs' joint
representations. Applying this framework to Re:Zero manga across 11 chapters
with 308 annotated panels, we conduct the first systematic study of long-form
narrative understanding in VLMs through three core evaluation axes: generative
storytelling, contextual dialogue grounding, and temporal reasoning. Our
findings demonstrate that current models lack genuine story-level intelligence,
struggling particularly with non-linear narratives, character consistency, and
causal inference across extended sequences. This work establishes both the
foundation and practical methodology for evaluating narrative intelligence,
while providing actionable insights into the capability of deep sequential
understanding of Discrete Visual Narratives beyond basic recognition in
Multimodal Models.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [74] [Exploring the Technical Knowledge Interaction of Global Digital Humanities: Three-decade Evidence from Bibliometric-based perspectives](https://arxiv.org/abs/2508.08347)
*Jiayi Li,Chengxi Yan,Yurong Zeng,Zhichao Fang,Huiru Wang*

Main category: cs.DL

TL;DR: 本研究引入了主题-方法组合（TMC）的概念，并开发了一种基于TMC的工作流程，结合文献计量分析、主题建模和网络分析，以更深入地理解数字人文领域的发展特征和模式。


<details>
  <summary>Details</summary>
Motivation: 以往的研究在提供对数字人文领域中技术进步和主题发展的深入见解方面存在局限性，因此需要一种新的方法来更好地理解方法与主题之间的相互关系。

Method: 本研究引入了主题-方法组合（TMC）的概念，并开发了一种基于TMC的工作流程，结合了文献计量分析、主题建模和网络分析，以分析数字人文领域的研究特征和发展模式。

Result: 本研究通过应用基于TMC的工作流程到大规模文献计量数据上，能够详细展示知识结构，为其他领域提供了一个可适应的工具。

Conclusion: 本研究通过引入一种新的概念——主题-方法组合（TMC），并开发了一种基于TMC的工作流程，结合了文献计量分析、主题建模和网络分析，以更深入地理解数字人文领域中的技术发展和主题演变。该方法为其他领域提供了可适应的工具。

Abstract: Digital Humanities (DH) is an interdisciplinary field that integrates
computational methods with humanities scholarship to investigate innovative
topics. Each academic discipline follows a unique developmental path shaped by
the topics researchers investigate and the methods they employ. With the help
of bibliometric analysis, most of previous studies have examined DH across
multiple dimensions such as research hotspots, co-author networks, and
institutional rankings. However, these studies have often been limited in their
ability to provide deep insights into the current state of technological
advancements and topic development in DH. As a result, their conclusions tend
to remain superficial or lack interpretability in understanding how methods and
topics interrelate in the field. To address this gap, this study introduced a
new concept of Topic-Method Composition (TMC), which refers to a hybrid
knowledge structure generated by the co-occurrence of specific research topics
and the corresponding method. Especially by analyzing the interaction between
TMCs, we can see more clearly the intersection and integration of digital
technology and humanistic subjects in DH. Moreover, this study developed a
TMC-based workflow combining bibliometric analysis, topic modeling, and network
analysis to analyze the development characteristics and patterns of research
disciplines. By applying this workflow to large-scale bibliometric data, it
enables a detailed view of the knowledge structures, providing a tool adaptable
to other fields.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [75] [Benchmarking Large Language Models for Geolocating Colonial Virginia Land Grants](https://arxiv.org/abs/2508.08266)
*Ryan Mioduski*

Main category: cs.LG

TL;DR: 本研究评估了大型语言模型将历史土地专利摘要转换为地理坐标的能力，并展示了其在准确性、成本效益和可扩展性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 弗吉尼亚州17世纪和18世纪的土地专利主要以叙述性的测量边界描述形式存在，限制了空间分析。因此，需要一种方法来将这些文本转换为地理坐标。

Method: 本研究系统评估了当前一代大型语言模型（LLMs）将这些散文摘要转换为地理上准确的纬度/经度坐标的能力。使用了一个数字化的5,471个弗吉尼亚州专利摘要语料库，并通过43个经过严格验证的测试案例作为初始地理聚焦基准进行测试。

Result: 顶级单次调用模型o3-2025-04-16实现了平均误差23公里（中位数14公里），比中位数LLM（37.4公里）提高了37.5%，比最弱的LLM（50.3公里）提高了53.5%，并比外部基准提高了67%（GIS分析师）和70%（斯坦福NER）。五次调用集成进一步将误差降低到19公里（中位数12公里），在最小的额外成本下（每份专利约0.20美元），比中位数LLM提高了48.6%。

Conclusion: 这些发现表明，大型语言模型在可扩展、准确且成本效益高的历史地理参考方面具有潜力。

Abstract: Virginia's seventeenth- and eighteenth-century land patents survive primarily
as narrative metes-and-bounds descriptions, limiting spatial analysis. This
study systematically evaluates current-generation large language models (LLMs)
in converting these prose abstracts into geographically accurate
latitude/longitude coordinates within a focused evaluation context. A digitized
corpus of 5,471 Virginia patent abstracts (1695-1732) is released, with 43
rigorously verified test cases serving as an initial, geographically focused
benchmark. Six OpenAI models across three architectures (o-series, GPT-4-class,
and GPT-3.5) were tested under two paradigms: direct-to-coordinate and
tool-augmented chain-of-thought invoking external geocoding APIs. Results were
compared with a GIS-analyst baseline, the Stanford NER geoparser, Mordecai-3,
and a county-centroid heuristic.
  The top single-call model, o3-2025-04-16, achieved a mean error of 23 km
(median 14 km), outperforming the median LLM (37.4 km) by 37.5%, the weakest
LLM (50.3 km) by 53.5%, and external baselines by 67% (GIS analyst) and 70%
(Stanford NER). A five-call ensemble further reduced errors to 19 km (median 12
km) at minimal additional cost (approx. USD 0.20 per grant), outperforming the
median LLM by 48.6%. A patentee-name-redaction ablation increased error by
about 9%, indicating reliance on textual landmark and adjacency descriptions
rather than memorization. The cost-efficient gpt-4o-2024-08-06 model maintained
a 28 km mean error at USD 1.09 per 1,000 grants, establishing a strong
cost-accuracy benchmark; external geocoding tools offered no measurable benefit
in this evaluation.
  These findings demonstrate the potential of LLMs for scalable, accurate, and
cost-effective historical georeferencing.

</details>


### [76] [Doctor Sun: A Bilingual Multimodal Large Language Model for Biomedical AI](https://arxiv.org/abs/2508.08270)
*Dong Xue,Ziyao Shao,Zhaoyang Duan,Fangzhou Liu,Bing Li,Zhongheng Zhang*

Main category: cs.LG

TL;DR: 本文介绍了一种专门用于医学的大型多模态生成模型Doctor Sun，以及一个名为SunMed-VL的多模态医学数据集，旨在推动生物医学多模态研究的发展。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态生物医学AI通常基于基础LLM，这限制了对复杂医学概念的理解。此外，最近的LLaVA诱导的医学LMM难以有效捕捉文本和图像之间的复杂关系。

Method: Doctor Sun 结合了预训练的视觉编码器和医学大语言模型，并在各种医学数据集上进行了两阶段训练，专注于特征对齐和指令调优。

Result: Doctor Sun 能够有效地处理生物医学任务，如病理分析、放射科报告生成和生物医学辅助。同时，SunMed-VL数据集为生物医学多模态研究提供了支持。

Conclusion: Doctor Sun 是一个专门用于医学的大型多模态生成模型，能够编码、集成和解释各种生物医学数据模式。此外，研究者发布了SunMed-VL数据集，以支持生物医学多模态研究的发展。

Abstract: Large multimodal models (LMMs) have demonstrated significant potential in
providing innovative solutions for various biomedical tasks, including
pathology analysis, radiology report generation, and biomedical assistance.
However, the existing multimodal biomedical AI is typically based on foundation
LLMs, thus hindering the understanding of intricate medical concepts with
limited medical training data. Moreover, recent LLaVA-induced medical LMMs
struggle to effectively capture the intricate relationship between the texts
and the images. Therefore, we introduce Doctor Sun, a large multimodal
generative model specialized in medicine, developed to encode, integrate, and
interpret diverse biomedical data modalities such as text and images. In
particular, Doctor Sun integrates a pre-trained vision encoder with a medical
LLM and conducts two-stage training on various medical datasets, focusing on
feature alignment and instruction tuning. Moreover, we release SunMed-VL, a
wide-range bilingual medical multimodal dataset, along with all associated
models, code, and resources, to freely support the advancement of biomedical
multimodal research.

</details>


### [77] [MiGrATe: Mixed-Policy GRPO for Adaptation at Test-Time](https://arxiv.org/abs/2508.08641)
*Peter Phan,Dhruv Agarwal,Kavitha Srinivas,Horst Samulowitz,Pavan Kapanipathi,Andrew McCallum*

Main category: cs.LG

TL;DR: MiGrATe is an online TTT method that improves LLM performance on complex search tasks by combining on-policy sampling with off-policy data selection techniques.


<details>
  <summary>Details</summary>
Motivation: Prior methods for black-box optimization using LLMs often struggle to balance exploration and exploitation. Test-time training (TTT) has shown promise, but requires hand-crafted training data, limiting its feasibility and scalability.

Method: MiGrATe uses GRPO as a search algorithm to adapt LLMs at inference without requiring external training data. It combines on-policy sampling with two off-policy data selection techniques: greedy sampling and neighborhood sampling (NS).

Result: MiGrATe consistently outperforms both inference-only and TTT baselines on three challenging domains: word search, molecule optimization, and hypothesis+program induction on the ARC corpus.

Conclusion: MiGrATe demonstrates the potential of online TTT as a solution for complex search tasks without external supervision.

Abstract: Large language models (LLMs) are increasingly being applied to black-box
optimization tasks, from program synthesis to molecule design. Prior work
typically leverages in-context learning to iteratively guide the model towards
better solutions. Such methods, however, often struggle to balance exploration
of new solution spaces with exploitation of high-reward ones. Recently,
test-time training (TTT) with synthetic data has shown promise in improving
solution quality. However, the need for hand-crafted training data tailored to
each task limits feasibility and scalability across domains. To address this
problem, we introduce MiGrATe-a method for online TTT that uses GRPO as a
search algorithm to adapt LLMs at inference without requiring external training
data. MiGrATe operates via a mixed-policy group construction procedure that
combines on-policy sampling with two off-policy data selection techniques:
greedy sampling, which selects top-performing past completions, and
neighborhood sampling (NS), which generates completions structurally similar to
high-reward ones. Together, these components bias the policy gradient towards
exploitation of promising regions in solution space, while preserving
exploration through on-policy sampling. We evaluate MiGrATe on three
challenging domains-word search, molecule optimization, and hypothesis+program
induction on the Abstraction and Reasoning Corpus (ARC)-and find that it
consistently outperforms both inference-only and TTT baselines, demonstrating
the potential of online TTT as a solution for complex search tasks without
external supervision.

</details>


### [78] [$\text{M}^{2}$LLM: Multi-view Molecular Representation Learning with Large Language Models](https://arxiv.org/abs/2508.08657)
*Jiaxin Ju,Yizhen Zheng,Huan Yee Koh,Can Wang,Shirui Pan*

Main category: cs.LG

TL;DR: 本文提出了一种名为M²LLM的多视角框架，通过整合分子结构、任务和规则三个视角，利用大语言模型的强大推理能力，实现了分子属性预测的先进性能。


<details>
  <summary>Details</summary>
Motivation: 准确的分子属性预测是一个关键挑战，具有广泛的应用。现有的分子表示方法往往忽略了数十年积累的语义和上下文知识。最近的大语言模型（LLMs）在科学领域展示了出色的推理能力和先验知识，因此我们假设LLMs在被引导进行多角度推理时可以生成丰富的分子表示。

Method: 提出了一种多视角框架M²LLM，该框架整合了三个视角：分子结构视角、分子任务视角和分子规则视角。这些视角动态融合以适应任务需求。

Result: M²LLM在多个分类和回归任务的基准测试中达到了最先进的性能。通过利用生成分子嵌入和通过高级推理过程整理分子特征这两个核心功能，从LLM中得出的表示实现了卓越的性能。

Conclusion: 实验表明，M²LLM在多个分类和回归任务的基准测试中达到了最先进的性能。此外，通过利用生成分子嵌入和通过高级推理过程整理分子特征这两个核心功能，从LLM中得出的表示实现了卓越的性能。

Abstract: Accurate molecular property prediction is a critical challenge with
wide-ranging applications in chemistry, materials science, and drug discovery.
Molecular representation methods, including fingerprints and graph neural
networks (GNNs), achieve state-of-the-art results by effectively deriving
features from molecular structures. However, these methods often overlook
decades of accumulated semantic and contextual knowledge. Recent advancements
in large language models (LLMs) demonstrate remarkable reasoning abilities and
prior knowledge across scientific domains, leading us to hypothesize that LLMs
can generate rich molecular representations when guided to reason in multiple
perspectives. To address these gaps, we propose $\text{M}^{2}$LLM, a multi-view
framework that integrates three perspectives: the molecular structure view, the
molecular task view, and the molecular rules view. These views are fused
dynamically to adapt to task requirements, and experiments demonstrate that
$\text{M}^{2}$LLM achieves state-of-the-art performance on multiple benchmarks
across classification and regression tasks. Moreover, we demonstrate that
representation derived from LLM achieves exceptional performance by leveraging
two core functionalities: the generation of molecular embeddings through their
encoding capabilities and the curation of molecular features through advanced
reasoning processes.

</details>
