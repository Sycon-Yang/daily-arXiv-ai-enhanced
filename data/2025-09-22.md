<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 56]
- [cs.CV](#cs.CV) [Total: 5]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.SD](#cs.SD) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Synthetic bootstrapped pretraining](https://arxiv.org/abs/2509.15248)
*Zitong Yang,Aonan Zhang,Hong Liu,Tatsunori Hashimoto,Emmanuel Candès,Chong Wang,Ruoming Pang*

Main category: cs.CL

TL;DR: 本文介绍了 Synthetic Bootstrapped Pretraining (SBP)，这是一种语言模型（LM）预训练方法，它首先从预训练数据集中学习文档之间的关系模型，然后利用该模型合成一个庞大的新语料库进行联合训练。SBP 在计算匹配的预训练设置中进行了验证，并在多达 1T tokens 的数据上从头开始预训练了一个 3B 参数模型。结果表明，SBP 持续优于强大的重复基线，并实现了可由访问 20 倍更多独特数据的 oracle 上限获得的显著性能提升的一部分。定性分析显示，合成的文档超越了单纯的改写——SBP 首先从种子材料中抽象出核心概念，然后在其基础上构建新的叙述。此外，SBP 具有自然的贝叶斯解释：合成器隐式地学习抽象相关文档之间共享的潜在概念。


<details>
  <summary>Details</summary>
Motivation: Standard pretraining teaches LMs to learn causal correlations among tokens within a single document, but it is not designed to efficiently model the rich, learnable inter-document correlations that can potentially lead to better performance.

Method: Synthetic Bootstrapped Pretraining (SBP), a language model (LM) pretraining procedure that first learns a model of relations between documents from the pretraining dataset and then leverages it to synthesize a vast new corpus for joint training.

Result: SBP consistently improves upon a strong repetition baseline and delivers a significant fraction of performance improvement attainable by an oracle upper bound with access to 20x more unique data. Qualitative analysis reveals that the synthesized documents go beyond mere paraphrases -- SBP first abstracts a core concept from the seed material and then crafts a new narration on top of it.

Conclusion: SBP consistently improves upon a strong repetition baseline and delivers a significant fraction of performance improvement attainable by an oracle upper bound with access to 20x more unique data. SBP admits a natural Bayesian interpretation: the synthesizer implicitly learns to abstract the latent concepts shared between related documents.

Abstract: We introduce Synthetic Bootstrapped Pretraining (SBP), a language model (LM)
pretraining procedure that first learns a model of relations between documents
from the pretraining dataset and then leverages it to synthesize a vast new
corpus for joint training. While the standard pretraining teaches LMs to learn
causal correlations among tokens within a single document, it is not designed
to efficiently model the rich, learnable inter-document correlations that can
potentially lead to better performance. We validate SBP by designing a
compute-matched pretraining setup and pretrain a 3B-parameter model on up to 1T
tokens from scratch. We find SBP consistently improves upon a strong repetition
baseline and delivers a significant fraction of performance improvement
attainable by an oracle upper bound with access to 20x more unique data.
Qualitative analysis reveals that the synthesized documents go beyond mere
paraphrases -- SBP first abstracts a core concept from the seed material and
then crafts a new narration on top of it. Besides strong empirical performance,
SBP admits a natural Bayesian interpretation: the synthesizer implicitly learns
to abstract the latent concepts shared between related documents.

</details>


### [2] [Comparative Analysis of Tokenization Algorithms for Low-Resource Language Dzongkha](https://arxiv.org/abs/2509.15255)
*Tandin Wangchuk,Tad Gonsalves*

Main category: cs.CL

TL;DR: 本研究评估了三种分词算法在Dzongkha中的表现，发现SentencePiece最为有效，为构建Dzongkha大语言模型提供了基础。


<details>
  <summary>Details</summary>
Motivation: Dzongkha是一种低资源语言，其语言复杂性带来了独特的NLP挑战。尽管取得了一些进展，但关于Dzongkha NLP的研究仍然不足，特别是在分词方面。因此，本研究旨在评估不同分词算法在Dzongkha中的表现。

Method: 本研究评估了三种常见的分词算法（Byte-Pair Encoding、WordPiece和SentencePiece）在Dzongkha中的适用性，并通过子词密度、连续单词比例、归一化序列长度和执行时间等指标进行了性能评估。

Result: 所有三种算法都显示出潜力，但SentencePiece在Dzongkha分词中表现最佳。

Conclusion: 研究显示，SentencePiece在Dzongkha分词中表现最佳，为构建Dzongkha大语言模型铺平了道路。这强调了针对低资源语言的定制方法和持续研究的必要性。

Abstract: Large Language Models (LLMs) are gaining popularity and improving rapidly.
Tokenizers are crucial components of natural language processing, especially
for LLMs. Tokenizers break down input text into tokens that models can easily
process while ensuring the text is accurately represented, capturing its
meaning and structure. Effective tokenizers enhance the capabilities of LLMs by
improving a model's understanding of context and semantics, ultimately leading
to better performance in various downstream tasks, such as translation,
classification, sentiment analysis, and text generation. Most pre-trained
tokenizers are suitable for high-resource languages like English but perform
poorly for low-resource languages. Dzongkha, Bhutan's national language spoken
by around seven hundred thousand people, is a low-resource language, and its
linguistic complexity poses unique NLP challenges. Despite some progress,
significant research in Dzongkha NLP is lacking, particularly in tokenization.
This study evaluates the training and performance of three common tokenization
algorithms in comparison to other popular methods. Specifically, Byte-Pair
Encoding (BPE), WordPiece, and SentencePiece (Unigram) were evaluated for their
suitability for Dzongkha. Performance was assessed using metrics like Subword
Fertility, Proportion of Continued Words, Normalized Sequence Length, and
execution time. The results show that while all three algorithms demonstrate
potential, SentencePiece is the most effective for Dzongkha tokenization,
paving the way for further NLP advancements. This underscores the need for
tailored approaches for low-resource languages and ongoing research. In this
study, we presented three tokenization algorithms for Dzongkha, paving the way
for building Dzongkha Large Language Models.

</details>


### [3] [Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages](https://arxiv.org/abs/2509.15260)
*Yujia Hu,Ming Shan Hee,Preslav Nakov,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: 本文介绍了SGToxicGuard，一个用于评估新加坡多语言环境下大型语言模型安全性的数据集和评估框架，并发现了现有模型在安全防护方面的不足。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的安全机制在低资源、多语言环境中尚未得到充分研究。本文旨在填补这一空白。

Method: 引入了SGToxicGuard，这是一个新的数据集和评估框架，用于在新加坡多语言背景下基准测试大型语言模型的安全性。采用红队方法系统地探测大型语言模型在三个现实场景中的漏洞：对话、问答和内容创作。

Result: 对最先进的多语言大型语言模型进行了广泛的实验，结果揭示了它们在安全防护方面的关键差距。

Conclusion: 通过提供关于文化敏感性和毒性缓解的行动见解，我们为在语言多样环境中更安全和更具包容性的AI系统奠定了基础。

Abstract: The advancement of Large Language Models (LLMs) has transformed natural
language processing; however, their safety mechanisms remain under-explored in
low-resource, multilingual settings. Here, we aim to bridge this gap. In
particular, we introduce \textsf{SGToxicGuard}, a novel dataset and evaluation
framework for benchmarking LLM safety in Singapore's diverse linguistic
context, including Singlish, Chinese, Malay, and Tamil. SGToxicGuard adopts a
red-teaming approach to systematically probe LLM vulnerabilities in three
real-world scenarios: \textit{conversation}, \textit{question-answering}, and
\textit{content composition}. We conduct extensive experiments with
state-of-the-art multilingual LLMs, and the results uncover critical gaps in
their safety guardrails. By offering actionable insights into cultural
sensitivity and toxicity mitigation, we lay the foundation for safer and more
inclusive AI systems in linguistically diverse environments.\footnote{Link to
the dataset: https://github.com/Social-AI-Studio/SGToxicGuard.}
\textcolor{red}{Disclaimer: This paper contains sensitive content that may be
disturbing to some readers.}

</details>


### [4] [PolBiX: Detecting LLMs' Political Bias in Fact-Checking through X-phemisms](https://arxiv.org/abs/2509.15335)
*Charlott Jakob,David Harbecke,Patrick Parschan,Pia Wenzel Neves,Vera Schmitt*

Main category: cs.CL

TL;DR: 研究通过替换词语来检查LLMs在事实核查中的政治偏见，发现判断性词汇比政治倾向更影响结果。


<details>
  <summary>Details</summary>
Motivation: 许多研究发现LLMs倾向于左翼立场，但下游任务如事实核查的影响仍研究不足。

Method: 通过将词语替换为委婉语或贬义词来系统地研究政治偏见，构建事实等价但政治含义不同的最小对，以评估LLMs在分类它们为真或假时的一致性。

Result: 评估了六个LLMs，发现判断性词汇的存在比政治倾向更显著地影响真实性评估。

Conclusion: 研究发现，政治偏见在某些模型中存在，但并未因明确要求客观性而减轻。

Abstract: Large Language Models are increasingly used in applications requiring
objective assessment, which could be compromised by political bias. Many
studies found preferences for left-leaning positions in LLMs, but downstream
effects on tasks like fact-checking remain underexplored. In this study, we
systematically investigate political bias through exchanging words with
euphemisms or dysphemisms in German claims. We construct minimal pairs of
factually equivalent claims that differ in political connotation, to assess the
consistency of LLMs in classifying them as true or false. We evaluate six LLMs
and find that, more than political leaning, the presence of judgmental words
significantly influences truthfulness assessment. While a few models show
tendencies of political bias, this is not mitigated by explicitly calling for
objectivism in prompts.

</details>


### [5] [Quantifying Self-Awareness of Knowledge in Large Language Models](https://arxiv.org/abs/2509.15339)
*Yeongbin Seo,Dongha Lee,Jinyoung Yeo*

Main category: cs.CL

TL;DR: This paper argues that hallucination prediction in LLMs may stem from question-side shortcuts rather than true self-awareness. It introduces AQE to quantify question-awareness and SCAO to enhance model-side signals, showing that SCAO performs well even when question-side cues are reduced.


<details>
  <summary>Details</summary>
Motivation: Hallucination prediction in large language models (LLMs) is often interpreted as a sign of self-awareness. However, we argue that such performance can arise from question-side shortcuts rather than true model-side introspection.

Method: We propose the Approximate Question-side Effect (AQE), which quantifies the contribution of question-awareness. We also introduce SCAO (Semantic Compression by Answering in One word), a method that enhances the use of model-side signals.

Result: Our analysis across multiple datasets reveals that much of the reported success stems from exploiting superficial patterns in questions. Experiments show that SCAO achieves strong and consistent performance.

Conclusion: SCAO achieves strong and consistent performance, particularly in settings with reduced question-side cues, highlighting its effectiveness in fostering genuine self-awareness in LLMs.

Abstract: Hallucination prediction in large language models (LLMs) is often interpreted
as a sign of self-awareness. However, we argue that such performance can arise
from question-side shortcuts rather than true model-side introspection. To
disentangle these factors, we propose the Approximate Question-side Effect
(AQE), which quantifies the contribution of question-awareness. Our analysis
across multiple datasets reveals that much of the reported success stems from
exploiting superficial patterns in questions. We further introduce SCAO
(Semantic Compression by Answering in One word), a method that enhances the use
of model-side signals. Experiments show that SCAO achieves strong and
consistent performance, particularly in settings with reduced question-side
cues, highlighting its effectiveness in fostering genuine self-awareness in
LLMs.

</details>


### [6] [Real, Fake, or Manipulated? Detecting Machine-Influenced Text](https://arxiv.org/abs/2509.15350)
*Yitong Wang,Zhongping Zhang,Margherita Piana,Zheng Zhou,Peter Gerstoft,Bryan A. Plummer*

Main category: cs.CL

TL;DR: 本文介绍了HERO，一种能够区分四种文本类型的机器影响文本检测器，并在多个LLM和领域中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的机器生成文本检测工作主要关注识别文档是人类还是机器编写的，而忽略了这些细粒度的使用情况。

Method: HERO通过结合经过子类别指导训练的长度专业模型的预测来实现文本样本的分离。

Result: HERO能够区分四种主要类型：人工撰写、机器生成、机器润色和机器翻译。

Conclusion: HERO在五个LLM和六个领域中的实验表明，它在平均mAP上优于最先进的方法2.5-3。

Abstract: Large Language Model (LLMs) can be used to write or modify documents,
presenting a challenge for understanding the intent behind their use. For
example, benign uses may involve using LLM on a human-written document to
improve its grammar or to translate it into another language. However, a
document entirely produced by a LLM may be more likely to be used to spread
misinformation than simple translation (\eg, from use by malicious actors or
simply by hallucinating). Prior works in Machine Generated Text (MGT) detection
mostly focus on simply identifying whether a document was human or machine
written, ignoring these fine-grained uses. In this paper, we introduce a
HiErarchical, length-RObust machine-influenced text detector (HERO), which
learns to separate text samples of varying lengths from four primary types:
human-written, machine-generated, machine-polished, and machine-translated.
HERO accomplishes this by combining predictions from length-specialist models
that have been trained with Subcategory Guidance. Specifically, for categories
that are easily confused (\eg, different source languages), our Subcategory
Guidance module encourages separation of the fine-grained categories, boosting
performance. Extensive experiments across five LLMs and six domains demonstrate
the benefits of our HERO, outperforming the state-of-the-art by 2.5-3 mAP on
average.

</details>


### [7] [Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing](https://arxiv.org/abs/2509.15361)
*Zichen Wu,Hsiu-Yuan Huang,Yunfang Wu*

Main category: cs.CL

TL;DR: 本文提出了一种基于因果中介的去偏框架，用于解决多模态大型语言模型中的表面相关性偏差问题，并在多模态讽刺检测和情感分析任务中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型（MLLMs）在整合视觉和文本信息方面表现出色，但经常依赖于虚假的相关性，这损害了它们在复杂多模态推理任务中的鲁棒性和泛化能力。本文旨在解决MLLMs中的表面相关性偏差问题。

Method: 本文提出了一种基于因果中介的去偏框架，通过反事实例子区分核心语义和虚假的文本和视觉上下文，并使用带有动态路由的专家混合（MoE）架构来选择性地激活模态特定的去偏专家。

Result: 实证评估表明，本文提出的框架在多模态讽刺检测和情感分析任务中表现优异，超越了单模态去偏策略和现有的最先进模型。

Conclusion: 本文提出的框架在多模态讽刺检测和情感分析任务中显著优于单模态去偏策略和现有最先进的模型。

Abstract: Multimodal Large Language Models (MLLMs) have shown substantial capabilities
in integrating visual and textual information, yet frequently rely on spurious
correlations, undermining their robustness and generalization in complex
multimodal reasoning tasks. This paper addresses the critical challenge of
superficial correlation bias in MLLMs through a novel causal mediation-based
debiasing framework. Specially, we distinguishing core semantics from spurious
textual and visual contexts via counterfactual examples to activate
training-stage debiasing and employ a Mixture-of-Experts (MoE) architecture
with dynamic routing to selectively engages modality-specific debiasing
experts. Empirical evaluation on multimodal sarcasm detection and sentiment
analysis tasks demonstrates that our framework significantly surpasses unimodal
debiasing strategies and existing state-of-the-art models.

</details>


### [8] [Speech Language Models for Under-Represented Languages: Insights from Wolof](https://arxiv.org/abs/2509.15362)
*Yaya Sy,Dioula Doucouré,Christophe Cerisara,Irina Illina*

Main category: cs.CL

TL;DR: 我们训练了一个针对Wolof语言的语音语言模型，展示了其在语音识别和翻译中的优越性能，并计划公开模型和代码。


<details>
  <summary>Details</summary>
Motivation: 我们旨在训练一个针对Wolof语言的语音语言模型，以解决该语言在语音识别和翻译方面的不足，并通过开放模型和代码促进研究进展。

Method: 我们首先强调了收集大规模、自发、高质量语音数据的重要性，并展示了持续预训练HuBERT在这个数据集上的表现优于基础模型和非洲中心模型。然后，我们将这个语音编码器集成到Wolof LLM中，训练出第一个针对该语言的语音LLM，扩展了其在语音翻译等任务上的能力。此外，我们探索了让语音LLM在转录或翻译之前执行多步骤思维链。

Result: 我们的研究表明，语音LLM不仅提高了语音识别，还在语音翻译中表现良好。

Conclusion: 我们的研究展示了在Wolof语言上训练语音语言模型的旅程，并分享了关键见解。我们强调了收集大规模、自发、高质量语音数据的重要性，并展示了持续预训练HuBERT在这个数据集上的表现优于基础模型和非洲中心模型。我们将这个语音编码器集成到Wolof LLM中，训练出第一个针对该语言的语音LLM，扩展了其在语音翻译等任务上的能力。此外，我们探索了让语音LLM在转录或翻译之前执行多步骤思维链。结果表明，语音LLM不仅提高了语音识别，还在语音翻译中表现良好。模型和代码将公开共享。

Abstract: We present our journey in training a speech language model for Wolof, an
underrepresented language spoken in West Africa, and share key insights. We
first emphasize the importance of collecting large-scale, spontaneous,
high-quality speech data, and show that continued pretraining HuBERT on this
dataset outperforms both the base model and African-centric models on ASR. We
then integrate this speech encoder into a Wolof LLM to train the first Speech
LLM for this language, extending its capabilities to tasks such as speech
translation. Furthermore, we explore training the Speech LLM to perform
multi-step Chain-of-Thought before transcribing or translating. Our results
show that the Speech LLM not only improves speech recognition but also performs
well in speech translation. The models and the code will be openly shared.

</details>


### [9] [Frustratingly Easy Data Augmentation for Low-Resource ASR](https://arxiv.org/abs/2509.15373)
*Katsumi Ibaraki,David Chiang*

Main category: cs.CL

TL;DR: 本文提出三种数据增强方法，通过生成合成数据提升低资源和高资源语言的 ASR 性能。


<details>
  <summary>Details</summary>
Motivation: 由于低资源自动语音识别（ASR）面临数据不足的问题，需要有效的数据增强方法来提高性能。

Method: 本文提出了三种自包含的数据增强方法：基于手语的替换、随机替换以及基于大语言模型的方法，随后使用文本到语音（TTS）生成合成音频。

Result: 在四种低资源语言（Vatlongos、Nashta、Shinekhen Buryat 和 Kakabe）以及高资源语言如英语上，这些方法显著提高了预训练 Wav2Vec2-XLSR-53 模型的性能，例如 Nashta 的 WER 降低了 14.3%。

Conclusion: 本文提出的三种数据增强方法在低资源和高资源语言中都表现出色，展示了其广泛适用性。

Abstract: This paper introduces three self-contained data augmentation methods for
low-resource Automatic Speech Recognition (ASR). Our techniques first generate
novel text--using gloss-based replacement, random replacement, or an LLM-based
approach--and then apply Text-to-Speech (TTS) to produce synthetic audio. We
apply these methods, which leverage only the original annotated data, to four
languages with extremely limited resources (Vatlongos, Nashta, Shinekhen
Buryat, and Kakabe). Fine-tuning a pretrained Wav2Vec2-XLSR-53 model on a
combination of the original audio and generated synthetic data yields
significant performance gains, including a 14.3% absolute WER reduction for
Nashta. The methods prove effective across all four low-resource languages and
also show utility for high-resource languages like English, demonstrating their
broad applicability.

</details>


### [10] [Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering](https://arxiv.org/abs/2509.15403)
*Yangyi Li,Mengdi Huai*

Main category: cs.CL

TL;DR: 本文提出了一种新的不确定性估计框架和鲁棒方法，以提高自然语言解释的可靠性。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏对复杂LLMs的透明度，研究者们致力于开发解释大型语言行为的方法。自然语言解释因其能够以自解释的方式解释LLMs而脱颖而出，但目前尚无研究探讨如何为这些生成的自然语言解释提供有效的不确定性保证。

Method: 本文首先提出了一种新的不确定性估计框架，用于生成的自然语言解释，并设计了一种新的鲁棒不确定性估计方法，以在噪声环境下保持有效性。

Result: 在QA任务上的大量实验表明，所提方法表现出良好的性能。

Conclusion: 本文提出了一种新的不确定性估计框架，可以在事后和模型无关的方式下为生成的自然语言解释提供有效的不确定性保证。此外，还设计了一种新的鲁棒不确定性估计方法，在噪声环境下也能保持有效的不确定性保证。实验结果表明了所提方法的有效性。

Abstract: Large language models (LLMs) have shown strong capabilities, enabling
concise, context-aware answers in question answering (QA) tasks. The lack of
transparency in complex LLMs has inspired extensive research aimed at
developing methods to explain large language behaviors. Among existing
explanation methods, natural language explanations stand out due to their
ability to explain LLMs in a self-explanatory manner and enable the
understanding of model behaviors even when the models are closed-source.
However, despite these promising advancements, there is no existing work
studying how to provide valid uncertainty guarantees for these generated
natural language explanations. Such uncertainty quantification is critical in
understanding the confidence behind these explanations. Notably, generating
valid uncertainty estimates for natural language explanations is particularly
challenging due to the auto-regressive generation process of LLMs and the
presence of noise in medical inquiries. To bridge this gap, in this work, we
first propose a novel uncertainty estimation framework for these generated
natural language explanations, which provides valid uncertainty guarantees in a
post-hoc and model-agnostic manner. Additionally, we also design a novel robust
uncertainty estimation method that maintains valid uncertainty guarantees even
under noise. Extensive experiments on QA tasks demonstrate the desired
performance of our methods.

</details>


### [11] [Deep learning and abstractive summarisation for radiological reports: an empirical study for adapting the PEGASUS models' family with scarce data](https://arxiv.org/abs/2509.15419)
*Claudio Benzoni,Martina Langhals,Martin Boeker,Luise Modersohn,Máté E. Maros*

Main category: cs.CL

TL;DR: 本文研究了在医疗领域中使用非领域特定的抽象摘要模型进行微调的效果，并发现使用更大的检查点可能导致性能下降，强调了在处理稀缺训练数据时使用高表达力模型进行微调的挑战和风险。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能迅速发展，但抽象摘要在医疗等敏感和数据限制领域仍然具有挑战性。随着影像数量的增加，自动化工具在复杂医学文本摘要中的相关性预计会变得非常重要。

Method: 本文研究了非领域特定的抽象摘要编码器-解码器模型家族的微调过程，并通过PEGASUS和PEGASUS-X模型在中等规模的放射学报告公共数据集上进行了实验。对每个模型，我们全面评估了不同大小的同一训练数据的两个不同检查点，并在固定大小的验证集上监控了模型的性能。

Result: PEGASUS表现出不同的阶段，这可以与epoch-wise双下降或峰值下降恢复行为相关联。对于PEGASUS-X，我们发现使用更大的检查点会导致性能下降。

Conclusion: 本文强调了在处理稀缺训练数据时，使用高表达力模型进行微调的挑战和风险，并为未来在专业领域中的摘要模型更稳健的微调策略奠定了基础。

Abstract: Regardless of the rapid development of artificial intelligence, abstractive
summarisation is still challenging for sensitive and data-restrictive domains
like medicine. With the increasing number of imaging, the relevance of
automated tools for complex medical text summarisation is expected to become
highly relevant. In this paper, we investigated the adaptation via fine-tuning
process of a non-domain-specific abstractive summarisation encoder-decoder
model family, and gave insights to practitioners on how to avoid over- and
underfitting. We used PEGASUS and PEGASUS-X, on a medium-sized radiological
reports public dataset. For each model, we comprehensively evaluated two
different checkpoints with varying sizes of the same training data. We
monitored the models' performances with lexical and semantic metrics during the
training history on the fixed-size validation set. PEGASUS exhibited different
phases, which can be related to epoch-wise double-descent, or
peak-drop-recovery behaviour. For PEGASUS-X, we found that using a larger
checkpoint led to a performance detriment. This work highlights the challenges
and risks of fine-tuning models with high expressivity when dealing with scarce
training data, and lays the groundwork for future investigations into more
robust fine-tuning strategies for summarisation models in specialised domains.

</details>


### [12] [BiRQ: Bi-Level Self-Labeling Random Quantization for Self-Supervised Speech Recognition](https://arxiv.org/abs/2509.15430)
*Liuyuan Jiang,Xiaodong Cui,Brian Kingsbury,Tianyi Chen,Lisha Chen*

Main category: cs.CL

TL;DR: BiRQ是一个结合BEST-RQ效率和HuBERT风格标签增强优势的双层SSL框架，通过重新利用模型自身作为伪标签生成器，实现了高效的端到端训练。


<details>
  <summary>Details</summary>
Motivation: A core challenge in speech SSL is generating pseudo-labels that are both informative and efficient: strong labels, such as those used in HuBERT, improve downstream performance but rely on external encoders and multi-stage pipelines, while efficient methods like BEST-RQ achieve simplicity at the cost of weaker labels.

Method: BiRQ, a bilevel SSL framework that combines the efficiency of BEST-RQ with the refinement benefits of HuBERT-style label enhancement. The key idea is to reuse part of the model itself as a pseudo-label generator: intermediate representations are discretized by a random-projection quantizer to produce enhanced labels, while anchoring labels derived directly from the raw input stabilize training and prevent collapse.

Result: BiRQ consistently improves over BEST-RQ while maintaining low complexity and computational efficiency. We validate our method on various datasets, including 960-hour LibriSpeech, 150-hour AMI meetings and 5,000-hour YODAS, demonstrating consistent gains over BEST-RQ.

Conclusion: BiRQ consistently improves over BEST-RQ while maintaining low complexity and computational efficiency.

Abstract: Speech is a rich signal, and labeled audio-text pairs are costly, making
self-supervised learning essential for scalable representation learning. A core
challenge in speech SSL is generating pseudo-labels that are both informative
and efficient: strong labels, such as those used in HuBERT, improve downstream
performance but rely on external encoders and multi-stage pipelines, while
efficient methods like BEST-RQ achieve simplicity at the cost of weaker labels.
We propose BiRQ, a bilevel SSL framework that combines the efficiency of
BEST-RQ with the refinement benefits of HuBERT-style label enhancement. The key
idea is to reuse part of the model itself as a pseudo-label generator:
intermediate representations are discretized by a random-projection quantizer
to produce enhanced labels, while anchoring labels derived directly from the
raw input stabilize training and prevent collapse. Training is formulated as an
efficient first-order bilevel optimization problem, solved end-to-end with
differentiable Gumbel-softmax selection. This design eliminates the need for
external label encoders, reduces memory cost, and enables iterative label
refinement in an end-to-end fashion. BiRQ consistently improves over BEST-RQ
while maintaining low complexity and computational efficiency. We validate our
method on various datasets, including 960-hour LibriSpeech, 150-hour AMI
meetings and 5,000-hour YODAS, demonstrating consistent gains over BEST-RQ.

</details>


### [13] [PILOT: Steering Synthetic Data Generation with Psychological & Linguistic Output Targeting](https://arxiv.org/abs/2509.15447)
*Caitlin Cisar,Emily Sheffield,Joshua Drake,Alden Harrell,Subramanian Chidambaram,Nikita Nangia,Vinayak Arannil,Alex Williams*

Main category: cs.CL

TL;DR: PILOT is a framework for steering large language models using structured psycholinguistic profiles, showing improved coherence and reduced repetition compared to natural language persona steering.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the limitations of relying on natural language representations for user personas in generative AI applications, which can lead to unintended inferences and limited control over outputs.

Method: PILOT is a two-phase framework that translates natural language persona descriptions into multidimensional profiles and uses these profiles to guide generation along measurable axes of variation.

Result: Schema-based approaches (SBS) significantly reduce artificial-sounding persona repetition while improving output coherence, with silhouette scores increasing from 0.098 to 0.237 and topic purity from 0.773 to 0.957. HPS achieves a balance between output variety and structural consistency.

Conclusion: PILOT provides a framework for steering large language models with structured psycholinguistic profiles, achieving a balance between output variety and structural consistency. Expert evaluation confirms high response quality across all conditions.

Abstract: Generative AI applications commonly leverage user personas as a steering
mechanism for synthetic data generation, but reliance on natural language
representations forces models to make unintended inferences about which
attributes to emphasize, limiting precise control over outputs. We introduce
PILOT (Psychological and Linguistic Output Targeting), a two-phase framework
for steering large language models with structured psycholinguistic profiles.
In Phase 1, PILOT translates natural language persona descriptions into
multidimensional profiles with normalized scores across linguistic and
psychological dimensions. In Phase 2, these profiles guide generation along
measurable axes of variation. We evaluate PILOT across three state-of-the-art
LLMs (Mistral Large 2, Deepseek-R1, LLaMA 3.3 70B) using 25 synthetic personas
under three conditions: Natural-language Persona Steering (NPS), Schema-Based
Steering (SBS), and Hybrid Persona-Schema Steering (HPS). Results demonstrate
that schema-based approaches significantly reduce artificial-sounding persona
repetition while improving output coherence, with silhouette scores increasing
from 0.098 to 0.237 and topic purity from 0.773 to 0.957. Our analysis reveals
a fundamental trade-off: SBS produces more concise outputs with higher topical
consistency, while NPS offers greater lexical diversity but reduced
predictability. HPS achieves a balance between these extremes, maintaining
output variety while preserving structural consistency. Expert linguistic
evaluation confirms that PILOT maintains high response quality across all
conditions, with no statistically significant differences between steering
approaches.

</details>


### [14] [Evaluating Multimodal Large Language Models on Spoken Sarcasm Understanding](https://arxiv.org/abs/2509.15476)
*Zhu Li,Xiyuan Gao,Yuqing Zhang,Shekhar Nayak,Matt Coler*

Main category: cs.CL

TL;DR: 本文研究了多模态大语言模型在跨语言、视听文本讽刺检测中的应用，发现基于音频的模型在单模态性能上表现最佳，而文本-音频和音频-视觉组合优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 讽刺检测在自然语言理解中仍然是一个挑战，因为讽刺意图通常依赖于跨越文本、语音和视觉的细微跨模态线索。虽然之前的工作主要集中在文本或视觉-文本讽刺上，但全面的音频-视觉-文本讽刺理解仍缺乏研究。

Method: 我们系统地评估了大型语言模型（LLMs）和多模态LLMs在英语（MUStARD++）和中文（MCSD 1.0）中的讽刺检测，包括零样本、少样本和LoRA微调设置。此外，我们还探索了模型作为特征编码器，并通过协作门控融合模块整合其表示。

Result: 实验结果表明，基于音频的模型在单模态性能上表现最强，而文本-音频和音频-视觉组合优于单模态和三模态模型。此外，MLLMs如Qwen-Omni在零样本和微调性能上表现出色。

Conclusion: 我们的研究结果突显了多模态大语言模型在跨语言、视听文本讽刺理解方面的潜力。

Abstract: Sarcasm detection remains a challenge in natural language understanding, as
sarcastic intent often relies on subtle cross-modal cues spanning text, speech,
and vision. While prior work has primarily focused on textual or visual-textual
sarcasm, comprehensive audio-visual-textual sarcasm understanding remains
underexplored. In this paper, we systematically evaluate large language models
(LLMs) and multimodal LLMs for sarcasm detection on English (MUStARD++) and
Chinese (MCSD 1.0) in zero-shot, few-shot, and LoRA fine-tuning settings. In
addition to direct classification, we explore models as feature encoders,
integrating their representations through a collaborative gating fusion module.
Experimental results show that audio-based models achieve the strongest
unimodal performance, while text-audio and audio-vision combinations outperform
unimodal and trimodal models. Furthermore, MLLMs such as Qwen-Omni show
competitive zero-shot and fine-tuned performance. Our findings highlight the
potential of MLLMs for cross-lingual, audio-visual-textual sarcasm
understanding.

</details>


### [15] [Red Teaming Multimodal Language Models: Evaluating Harm Across Prompt Modalities and Models](https://arxiv.org/abs/2509.15478)
*Madison Van Doren,Casey Ford,Emily Dix*

Main category: cs.CL

TL;DR: 该研究评估了四种多模态大语言模型在面对对抗性提示时的安全性，发现不同模型和模态之间存在显著差异，强调了建立多模态安全基准的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLLMs）在现实世界应用中越来越普遍，但它们在对抗条件下的安全性仍缺乏研究。

Method: 研究评估了四种领先的MLLMs（GPT-4o、Claude Sonnet 3.5、Pixtral 12B和Qwen VL Plus）在面对对抗性提示时的无害性，通过红队生成726个提示，并由17名评估者对2,904个模型输出进行有害性评分。

Result: 结果显示，不同模型和模态之间的易受攻击性存在显著差异。Pixtral 12B表现出最高的有害响应率（约62%），而Claude Sonnet 3.5是最具抵抗力的（约10%）。文本提示比多模态提示略微更有效。统计分析确认了模型类型和输入模态是有害性的显著预测因素。

Conclusion: 研究结果强调了在MLLMs广泛部署的情况下，需要建立稳健的多模态安全基准的紧迫性。

Abstract: Multimodal large language models (MLLMs) are increasingly used in real world
applications, yet their safety under adversarial conditions remains
underexplored. This study evaluates the harmlessness of four leading MLLMs
(GPT-4o, Claude Sonnet 3.5, Pixtral 12B, and Qwen VL Plus) when exposed to
adversarial prompts across text-only and multimodal formats. A team of 26 red
teamers generated 726 prompts targeting three harm categories: illegal
activity, disinformation, and unethical behaviour. These prompts were submitted
to each model, and 17 annotators rated 2,904 model outputs for harmfulness
using a 5-point scale. Results show significant differences in vulnerability
across models and modalities. Pixtral 12B exhibited the highest rate of harmful
responses (~62%), while Claude Sonnet 3.5 was the most resistant (~10%).
Contrary to expectations, text-only prompts were slightly more effective at
bypassing safety mechanisms than multimodal ones. Statistical analysis
confirmed that both model type and input modality were significant predictors
of harmfulness. These findings underscore the urgent need for robust,
multimodal safety benchmarks as MLLMs are deployed more widely.

</details>


### [16] [mucAI at BAREC Shared Task 2025: Towards Uncertainty Aware Arabic Readability Assessment](https://arxiv.org/abs/2509.15485)
*Ahmed Abdou*

Main category: cs.CL

TL;DR: 本文提出了一种用于细粒度阿拉伯语可读性分类的后处理技术，通过应用符合预测和softmax归一化概率计算加权平均值，显著提升了QWK分数，并在实际应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 在阿拉伯语教育评估中，需要一种能够减少高惩罚错误分类的方法，使人类评审员能够专注于少数可能的水平，同时结合统计保证与实用性。

Method: 我们提出了一种简单、模型无关的后处理技术，用于细粒度阿拉伯语可读性分类。该方法应用了符合预测来生成具有覆盖保证的预测集，然后使用softmax归一化概率计算加权平均值。这种不确定性感知解码减少了高惩罚错误分类到更接近的级别。

Result: 我们的方法在不同基础模型上一致提升了QWK分数，达到了1-3分。在严格赛道中，我们的提交在句子级别和文档级别的QWK得分分别为84.9%（测试）和85.7%（盲测），以及73.3%。

Conclusion: 我们的方法在不同基础模型上一致提升了QWK分数，达到了1-3分。在严格赛道中，我们的提交在句子级别和文档级别的QWK得分分别为84.9%（测试）和85.7%（盲测），以及73.3%。这对于阿拉伯语教育评估具有重要意义，使人类评审员能够专注于少数可能的水平，结合统计保证与实用性。

Abstract: We present a simple, model-agnostic post-processing technique for
fine-grained Arabic readability classification in the BAREC 2025 Shared Task
(19 ordinal levels). Our method applies conformal prediction to generate
prediction sets with coverage guarantees, then computes weighted averages using
softmax-renormalized probabilities over the conformal sets. This
uncertainty-aware decoding improves Quadratic Weighted Kappa (QWK) by reducing
high-penalty misclassifications to nearer levels. Our approach shows consistent
QWK improvements of 1-3 points across different base models. In the strict
track, our submission achieves QWK scores of 84.9\%(test) and 85.7\% (blind
test) for sentence level, and 73.3\% for document level. For Arabic educational
assessment, this enables human reviewers to focus on a handful of plausible
levels, combining statistical guarantees with practical usability.

</details>


### [17] [LLM Cache Bandit Revisited: Addressing Query Heterogeneity for Cost-Effective LLM Inference](https://arxiv.org/abs/2509.15515)
*Hantao Yang,Hong Xie,Defu Lian,Enhong Chen*

Main category: cs.CL

TL;DR: 本文研究了LLM缓存赌徒问题，针对查询异构性提出了一个新的方法，通过将最优缓存选择视为一个背包问题，并采用基于累积的策略来平衡计算开销和缓存更新。实验结果表明，该算法在实际数据上减少了约12%的总成本。


<details>
  <summary>Details</summary>
Motivation: 之前的文献通常假设查询大小是均匀的，但异构查询大小引入了缓存选择的组合结构，使得缓存替换过程更加计算和统计上具有挑战性。因此，本文旨在解决查询异构性问题，以实现更有效的LLM推理。

Method: 本文将最优缓存选择视为一个背包问题，并采用基于累积的策略来平衡计算开销和缓存更新。此外，还提供了问题依赖性边界，这是之前工作中缺失的部分。

Result: 理论分析表明，本文算法的遗憾度达到了O(√(MNT))的界限，相比伯克利的结果O(MN√T)，改进了√MN的系数。实验结果显示，该算法在实际数据上减少了约12%的总成本。

Conclusion: 本文提出了一种新的方法来解决LLM缓存赌徒问题，通过将最优缓存选择视为一个背包问题，并采用基于累积的策略来平衡计算开销和缓存更新。实验结果表明，该算法在实际数据上减少了约12%的总成本。

Abstract: This paper revisits the LLM cache bandit problem, with a special focus on
addressing the query heterogeneity for cost-effective LLM inference. Previous
works often assume uniform query sizes. Heterogeneous query sizes introduce a
combinatorial structure for cache selection, making the cache replacement
process more computationally and statistically challenging. We treat optimal
cache selection as a knapsack problem and employ an accumulation-based strategy
to effectively balance computational overhead and cache updates. In theoretical
analysis, we prove that the regret of our algorithm achieves an $O(\sqrt{MNT})$
bound, improving the coefficient of $\sqrt{MN}$ compared to the $O(MN\sqrt{T})$
result in Berkeley, where $N$ is the total number of queries and $M$ is the
cache size. Additionally, we also provide a problem-dependent bound, which was
absent in previous works. The experiment rely on real-world data show that our
algorithm reduces the total cost by approximately 12\%.

</details>


### [18] [How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages](https://arxiv.org/abs/2509.15518)
*Siyang Wu,Zhewei Sun*

Main category: cs.CL

TL;DR: 本研究比较了人类和机器生成的俚语用法，发现LLMs在感知俚语时存在显著偏差，尽管它们掌握了俚语的创造性方面的重要知识，但这些知识与人类的见解并不充分一致，无法用于推断性任务如语言分析。


<details>
  <summary>Details</summary>
Motivation: 俚语是一种常见的非正式语言类型，对NLP系统构成了严峻挑战。虽然大型语言模型（LLMs）的进展使得这一问题更加可解决，但它们的泛化能力和可靠性取决于这些模型是否已捕捉到与人类认可的俚语用法相一致的结构知识。

Method: 我们对人类和机器生成的俚语用法进行了系统比较，并评估了三个核心方面：1）反映机器如何感知俚语的系统性偏见的用法特征；2）通过俚语用法中的词汇创造和词语重用所体现的创造力；3）在模型蒸馏中作为黄金标准示例的俚语用法的信息量。

Result: 通过比较来自在线俚语词典（OSD）的人类认可的俚语用法和GPT-4o和Llama-3生成的俚语，我们发现LLMs在感知俚语时存在显著偏差。

Conclusion: 我们的研究结果表明，尽管LLMs已经掌握了俚语的创造性方面的重要知识，但这些知识与人类的见解并不充分一致，无法使LLMs进行诸如语言分析等推断性任务。

Abstract: Slang is a commonly used type of informal language that poses a daunting
challenge to NLP systems. Recent advances in large language models (LLMs),
however, have made the problem more approachable. While LLM agents are becoming
more widely applied to intermediary tasks such as slang detection and slang
interpretation, their generalizability and reliability are heavily dependent on
whether these models have captured structural knowledge about slang that align
well with human attested slang usages. To answer this question, we contribute a
systematic comparison between human and machine-generated slang usages. Our
evaluative framework focuses on three core aspects: 1) Characteristics of the
usages that reflect systematic biases in how machines perceive slang, 2)
Creativity reflected by both lexical coinages and word reuses employed by the
slang usages, and 3) Informativeness of the slang usages when used as
gold-standard examples for model distillation. By comparing human-attested
slang usages from the Online Slang Dictionary (OSD) and slang generated by
GPT-4o and Llama-3, we find significant biases in how LLMs perceive slang. Our
results suggest that while LLMs have captured significant knowledge about the
creative aspects of slang, such knowledge does not align with humans
sufficiently to enable LLMs for extrapolative tasks such as linguistic
analyses.

</details>


### [19] [A method for improving multilingual quality and diversity of instruction fine-tuning datasets](https://arxiv.org/abs/2509.15549)
*Chunguang Zhao,Yilun Liu,Pufan Zeng,Yuanchang Luo,Shimin Tao,Minggui He,Weibin Meng,Song Xu,Ziang Chen,Chen Liu,Hongxia Ma,Li Zhang,Boxing Chen,Daimeng Wei*

Main category: cs.CL

TL;DR: 本文介绍了一种名为M-DaQ的新方法，用于提高大型语言模型的多语言能力。实验结果表明，使用M-DaQ方法微调的模型在18种语言中表现出显著的性能提升，并且人类评估进一步验证了这些提升。


<details>
  <summary>Details</summary>
Motivation: 多语言指令微调（IFT）对于使大型语言模型（LLMs）在多样化语言和文化背景下有效泛化至关重要。然而，高质量多语言训练数据和相应构建方法的缺乏仍然是一个关键瓶颈。现有的方法在英语环境下表现出潜力，但在跨语言时往往无法推广，因为它们依赖于简单的启发式方法或语言特定的假设。

Method: 本文引入了Multilingual Data Quality and Diversity (M-DaQ)方法，通过选择高质量和语义多样化的多语言指令微调样本，以提高大型语言模型的多语言能力。此外，还进行了首次系统性研究，探讨了超级对齐假设（SAH）在多语言环境中的适用性。

Result: 实验结果表明，在18种语言中，使用M-DaQ方法微调的模型在性能上显著优于基线模型，胜率超过60%。人类评估进一步验证了这些提升，突显了响应中文化点的增加。

Conclusion: 本文提出了一种名为M-DaQ的新方法，用于提高大型语言模型的多语言能力。实验结果表明，使用M-DaQ方法微调的模型在18种语言中表现出显著的性能提升，并且人类评估进一步验证了这些提升。

Abstract: Multilingual Instruction Fine-Tuning (IFT) is essential for enabling large
language models (LLMs) to generalize effectively across diverse linguistic and
cultural contexts. However, the scarcity of high-quality multilingual training
data and corresponding building method remains a critical bottleneck. While
data selection has shown promise in English settings, existing methods often
fail to generalize across languages due to reliance on simplistic heuristics or
language-specific assumptions. In this work, we introduce Multilingual Data
Quality and Diversity (M-DaQ), a novel method for improving LLMs
multilinguality, by selecting high-quality and semantically diverse
multilingual IFT samples. We further conduct the first systematic investigation
of the Superficial Alignment Hypothesis (SAH) in multilingual setting.
Empirical results across 18 languages demonstrate that models fine-tuned with
M-DaQ method achieve significant performance gains over vanilla baselines over
60% win rate. Human evaluations further validate these gains, highlighting the
increment of cultural points in the response. We release the M-DaQ code to
support future research.

</details>


### [20] [DNA-DetectLLM: Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm](https://arxiv.org/abs/2509.15550)
*Xiaowei Zhu,Yubing Ren,Fang Fang,Qingfeng Tan,Shi Wang,Yanan Cao*

Main category: cs.CL

TL;DR: 本文提出了一种基于DNA的视角，通过修复过程捕捉人类撰写和AI生成文本之间的差异，并引入了DNA-DetectLLM，这是一种零样本检测方法，能够在多个公共基准数据集上实现最先进的检测性能。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型的快速发展，AI生成文本和人类撰写文本之间的界限变得模糊，这带来了诸如虚假信息、作者身份不明和知识产权问题等社会风险，因此迫切需要可靠的AI生成文本检测方法。然而，生成语言建模的进展导致了人类撰写和AI生成文本特征分布之间的显著重叠，使得准确检测变得更加具有挑战性。

Method: 提出了一种基于DNA的视角，利用修复过程直接且可解释地捕捉人类撰写和AI生成文本之间的内在差异，并引入了DNA-DetectLLM，这是一种零样本检测方法，用于区分AI生成和人类撰写的文本。

Result: DNA-DetectLLM在AUROC和F1分数方面分别实现了5.55%和2.08%的相对改进，并在多种公共基准数据集上展示了卓越的检测性能。

Conclusion: DNA-DetectLLM在多个公共基准数据集上实现了最先进的检测性能，并对各种对抗性攻击和输入长度表现出强大的鲁棒性。

Abstract: The rapid advancement of large language models (LLMs) has blurred the line
between AI-generated and human-written text. This progress brings societal
risks such as misinformation, authorship ambiguity, and intellectual property
concerns, highlighting the urgent need for reliable AI-generated text detection
methods. However, recent advances in generative language modeling have resulted
in significant overlap between the feature distributions of human-written and
AI-generated text, blurring classification boundaries and making accurate
detection increasingly challenging. To address the above challenges, we propose
a DNA-inspired perspective, leveraging a repair-based process to directly and
interpretably capture the intrinsic differences between human-written and
AI-generated text. Building on this perspective, we introduce DNA-DetectLLM, a
zero-shot detection method for distinguishing AI-generated and human-written
text. The method constructs an ideal AI-generated sequence for each input,
iteratively repairs non-optimal tokens, and quantifies the cumulative repair
effort as an interpretable detection signal. Empirical evaluations demonstrate
that our method achieves state-of-the-art detection performance and exhibits
strong robustness against various adversarial attacks and input lengths.
Specifically, DNA-DetectLLM achieves relative improvements of 5.55% in AUROC
and 2.08% in F1 score across multiple public benchmark datasets.

</details>


### [21] [Exploring Polyglot Harmony: On Multilingual Data Allocation for Large Language Models Pretraining](https://arxiv.org/abs/2509.15556)
*Ping Guo,Yubing Ren,Binbin Liu,Fengze Liu,Haobin Lin,Yifan Zhang,Bingni Zhang,Taifeng Wang,Yin Zheng*

Main category: cs.CL

TL;DR: 本文提出了一种名为Climb的新框架，用于优化多语言数据分配，通过跨语言交互感知的语言比例和两步优化过程，显著提高了多语言LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 由于复杂的跨语言交互和对数据集规模的敏感性，确定最佳语言比例非常具有挑战性。因此，需要一种有效的方法来优化多语言数据分配。

Method: Climb引入了一个跨语言交互感知的语言比例，通过捕捉语言间的依赖关系来量化每种语言的有效分配，并提出了一个两步优化过程：首先平衡各语言的边际收益，然后最大化 resulting 语言分配向量的幅度。

Result: 实验结果表明，Climb可以准确测量各种多语言环境中的跨语言交互。使用Climb衍生比例训练的LLM在多语言性能上 consistently 达到了最先进的水平，甚至在与使用更多token训练的开源LLM竞争中表现出色。

Conclusion: 本文提出了一种新的框架Climb，用于系统地优化多语言数据分配，实验结果表明，使用Climb衍生比例训练的LLM在多语言性能上达到了最先进的水平。

Abstract: Large language models (LLMs) have become integral to a wide range of
applications worldwide, driving an unprecedented global demand for effective
multilingual capabilities. Central to achieving robust multilingual performance
is the strategic allocation of language proportions within training corpora.
However, determining optimal language ratios is highly challenging due to
intricate cross-lingual interactions and sensitivity to dataset scale. This
paper introduces Climb (Cross-Lingual Interaction-aware Multilingual
Balancing), a novel framework designed to systematically optimize multilingual
data allocation. At its core, Climb introduces a cross-lingual
interaction-aware language ratio, explicitly quantifying each language's
effective allocation by capturing inter-language dependencies. Leveraging this
ratio, Climb proposes a principled two-step optimization procedure--first
equalizing marginal benefits across languages, then maximizing the magnitude of
the resulting language allocation vectors--significantly simplifying the
inherently complex multilingual optimization problem. Extensive experiments
confirm that Climb can accurately measure cross-lingual interactions across
various multilingual settings. LLMs trained with Climb-derived proportions
consistently achieve state-of-the-art multilingual performance, even achieving
competitive performance with open-sourced LLMs trained with more tokens.

</details>


### [22] [How important is language for human-like intelligence?](https://arxiv.org/abs/2509.15560)
*Gary Lupyan,Hunter Gentry,Martin Zettersten*

Main category: cs.CL

TL;DR: 本文探讨了语言在促进通用人工智能和人类智能方面的潜力，强调其作为紧凑表示和文化演化的抽象工具的重要性。


<details>
  <summary>Details</summary>
Motivation: 重新审视语言在人类认知中的作用，以及其在人工智能和认知科学中的潜在应用。

Method: 讨论语言的两个相关属性：紧凑的表示和集体智慧的迭代输出。

Result: 语言的压缩表示使学习系统能够逆向工程许多概念和因果结构，从而获得更广泛的领域能力。

Conclusion: 语言可能为更通用的人工智能系统和人类智能的核心方面提供关键。

Abstract: We use language to communicate our thoughts. But is language merely the
expression of thoughts, which are themselves produced by other, nonlinguistic
parts of our minds? Or does language play a more transformative role in human
cognition, allowing us to have thoughts that we otherwise could (or would) not
have? Recent developments in artificial intelligence (AI) and cognitive science
have reinvigorated this old question. We argue that language may hold the key
to the emergence of both more general AI systems and central aspects of human
intelligence. We highlight two related properties of language that make it such
a powerful tool for developing domain--general abilities. First, language
offers compact representations that make it easier to represent and reason
about many abstract concepts (e.g., exact numerosity). Second, these compressed
representations are the iterated output of collective minds. In learning a
language, we learn a treasure trove of culturally evolved abstractions. Taken
together, these properties mean that a sufficiently powerful learning system
exposed to language--whether biological or artificial--learns a compressed
model of the world, reverse engineering many of the conceptual and causal
structures that support human (and human-like) thought.

</details>


### [23] [LiteLong: Resource-Efficient Long-Context Data Synthesis for LLMs](https://arxiv.org/abs/2509.15568)
*Junlong Jia,Xing Wu,Chaochen Gao,Ziyang Chen,Zijia Lin,Zhongzhi Li,Weinong Wang,Haotian Xu,Donghui Jin,Debing Zhang,Binghui Guo*

Main category: cs.CL

TL;DR: LiteLong is a resource-efficient method for synthesizing long-context data through structured topic organization and multi-agent debate, achieving competitive performance while reducing computational and data engineering costs.


<details>
  <summary>Details</summary>
Motivation: High-quality long-context data is essential for training large language models (LLMs) capable of processing extensive documents, yet existing synthesis approaches using relevance-based aggregation face challenges of computational efficiency.

Method: LiteLong is a resource-efficient method for synthesizing long-context data through structured topic organization and multi-agent debate. It leverages the BISAC book classification system for hierarchical topic organization and employs a debate mechanism with multiple LLMs to generate diverse, high-quality topics within this structure. Lightweight BM25 retrieval is used to obtain relevant documents and concatenate them into 128K-token training samples.

Result: Experiments on HELMET and Ruler benchmarks demonstrate that LiteLong achieves competitive long-context performance and can seamlessly integrate with other long-dependency enhancement methods.

Conclusion: LiteLong makes high-quality long-context data synthesis more accessible by reducing both computational and data engineering costs, facilitating further research in long-context language training.

Abstract: High-quality long-context data is essential for training large language
models (LLMs) capable of processing extensive documents, yet existing synthesis
approaches using relevance-based aggregation face challenges of computational
efficiency. We present LiteLong, a resource-efficient method for synthesizing
long-context data through structured topic organization and multi-agent debate.
Our approach leverages the BISAC book classification system to provide a
comprehensive hierarchical topic organization, and then employs a debate
mechanism with multiple LLMs to generate diverse, high-quality topics within
this structure. For each topic, we use lightweight BM25 retrieval to obtain
relevant documents and concatenate them into 128K-token training samples.
Experiments on HELMET and Ruler benchmarks demonstrate that LiteLong achieves
competitive long-context performance and can seamlessly integrate with other
long-dependency enhancement methods. LiteLong makes high-quality long-context
data synthesis more accessible by reducing both computational and data
engineering costs, facilitating further research in long-context language
training.

</details>


### [24] [Relevance to Utility: Process-Supervised Rewrite for RAG](https://arxiv.org/abs/2509.15577)
*Jaeyoung Kim,Jongho Kim,Seung-won Hwang,Seoho Song,Young-In Song*

Main category: cs.CL

TL;DR: 本文提出R2U，通过直接优化生成正确答案的概率来解决检索增强生成系统中的问题，并通过蒸馏管道提高小模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的桥接模块无法捕捉真正的文档效用，因为检索到的文本可能在主题上相关，但在生成过程中缺乏有效推理的内容。

Method: 我们提出了R2U，通过过程监督直接优化生成正确答案的概率。此外，我们还提出了一种高效的蒸馏管道，通过扩展LLM的监督来帮助较小的重写模型更好地泛化。

Result: 我们的方法在多个开放领域问答基准上取得了持续的改进。

Conclusion: 我们的方法在多个开放领域问答基准上表现出色，优于现有的桥接基线。

Abstract: Retrieval-Augmented Generation systems often suffer from a gap between
optimizing retrieval relevance and generative utility: retrieved documents may
be topically relevant but still lack the content needed for effective reasoning
during generation. While existing "bridge" modules attempt to rewrite the
retrieved text for better generation, we show how they fail to capture true
document utility. In this work, we propose R2U, with a key distinction of
directly optimizing to maximize the probability of generating a correct answer
through process supervision. As such direct observation is expensive, we also
propose approximating an efficient distillation pipeline by scaling the
supervision from LLMs, which helps the smaller rewriter model generalize
better. We evaluate our method across multiple open-domain question-answering
benchmarks. The empirical results demonstrate consistent improvements over
strong bridging baselines.

</details>


### [25] [Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization](https://arxiv.org/abs/2509.15579)
*Yun Tang,Cindy Tseng*

Main category: cs.CL

TL;DR: 本文提出了一种基于块的自监督学习算法（Chunk SSL），用于流式和离线语音预训练，实验结果表明该方法在语音到文本任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着语音技术的快速发展，低延迟的语音人机通信变得越来越重要。大多数自监督学习算法都是在完整话语假设下设计的，而在流式应用中经常出现的部分话语情况下需要做出权衡。

Method: 提出了一种基于块的自监督学习（Chunk SSL）算法，该算法使用掩码预测损失进行优化，并鼓励声学编码器利用同一块和前一块中的未掩码帧来恢复被掩码的语音帧索引。还提出了一种复制和追加数据增强方法来进行高效的块级预训练。

Result: 在	extsc{Librispeech}和	extsc{Must-C}数据集上的实验结果表明，所提出的方法在语音到文本任务中表现非常有竞争力。

Conclusion: 实验结果表明，所提出的方法在流式和离线模式下都能在语音到文本任务中取得非常有竞争力的结果。

Abstract: Low latency speech human-machine communication is becoming increasingly
necessary as speech technology advances quickly in the last decade. One of the
primary factors behind the advancement of speech technology is self-supervised
learning. Most self-supervised learning algorithms are designed with full
utterance assumption and compromises have to made if partial utterances are
presented, which are common in the streaming applications. In this work, we
propose a chunk based self-supervised learning (Chunk SSL) algorithm as an
unified solution for both streaming and offline speech pre-training. Chunk SSL
is optimized with the masked prediction loss and an acoustic encoder is
encouraged to restore indices of those masked speech frames with help from
unmasked frames in the same chunk and preceding chunks. A copy and append data
augmentation approach is proposed to conduct efficient chunk based
pre-training. Chunk SSL utilizes a finite scalar quantization (FSQ) module to
discretize input speech features and our study shows a high resolution FSQ
codebook, i.e., a codebook with vocabulary size up to a few millions, is
beneficial to transfer knowledge from the pre-training task to the downstream
tasks. A group masked prediction loss is employed during pre-training to
alleviate the high memory and computation cost introduced by the large
codebook. The proposed approach is examined in two speech to text tasks, i.e.,
speech recognition and speech translation. Experimental results on the
\textsc{Librispeech} and \textsc{Must-C} datasets show that the proposed method
could achieve very competitive results for speech to text tasks at both
streaming and offline modes.

</details>


### [26] [DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models](https://arxiv.org/abs/2509.15587)
*Tsz Ting Chung,Lemao Liu,Mo Yu,Dit-Yan Yeung*

Main category: cs.CL

TL;DR: 本文提出了一个新的逻辑推理基准DivLogicEval和一个新评估指标，以更可靠地评估大型语言模型的逻辑推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的逻辑推理基准在语言多样性方面有限，其分布偏离了理想的逻辑推理基准分布，可能导致评估结果有偏。因此，本文旨在解决这些问题。

Method: 本文提出了一种新的经典逻辑基准DivLogicEval，该基准由多样化的陈述以反直觉的方式组成，并引入了一种新的评估指标，以减轻大型语言模型中固有的偏差和随机性的影响。

Result: 通过实验，本文展示了回答DivLogicEval中的问题所需的逻辑推理程度，并比较了不同流行大型语言模型在进行逻辑推理方面的性能。

Conclusion: 本文提出了一个新的经典逻辑基准DivLogicEval，以及一种新的评估指标，以更可靠地评估大型语言模型的逻辑推理能力。

Abstract: Logic reasoning in natural language has been recognized as an important
measure of human intelligence for Large Language Models (LLMs). Popular
benchmarks may entangle multiple reasoning skills and thus provide unfaithful
evaluations on the logic reasoning skill. Meanwhile, existing logic reasoning
benchmarks are limited in language diversity and their distributions are
deviated from the distribution of an ideal logic reasoning benchmark, which may
lead to biased evaluation results. This paper thereby proposes a new classical
logic benchmark DivLogicEval, consisting of natural sentences composed of
diverse statements in a counterintuitive way. To ensure a more reliable
evaluation, we also introduce a new evaluation metric that mitigates the
influence of bias and randomness inherent in LLMs. Through experiments, we
demonstrate the extent to which logical reasoning is required to answer the
questions in DivLogicEval and compare the performance of different popular LLMs
in conducting logical reasoning.

</details>


### [27] [SciEvent: Benchmarking Multi-domain Scientific Event Extraction](https://arxiv.org/abs/2509.15620)
*Bofu Dong,Pritesh Shah,Sumedh Sonawane,Tiyasha Banerjee,Erin Brady,Xinya Du,Ming Jiang*

Main category: cs.CL

TL;DR: 本文介绍了SciEvent，这是一个新的多领域科学摘要基准，旨在通过统一的事件抽取（EE）模式实现对科学内容的结构化和上下文感知的理解。SciEvent包含五个研究领域的500个摘要，并进行了手动标注。实验表明，当前模型在社会学和人文学科等领域的表现不佳。SciEvent是一个具有挑战性的基准，是向通用、多领域SciIE迈出的一步。


<details>
  <summary>Details</summary>
Motivation: Scientific information extraction (SciIE) has primarily relied on entity-relation extraction in narrow domains, limiting its applicability to interdisciplinary research and struggling to capture the necessary context of scientific information, often resulting in fragmented or conflicting statements.

Method: We define SciIE as a multi-stage EE pipeline: (1) segmenting abstracts into core scientific activities--Background, Method, Result, and Conclusion; and (2) extracting the corresponding triggers and arguments.

Result: Experiments with fine-tuned EE models, large language models (LLMs), and human annotators reveal a performance gap, with current models struggling in domains such as sociology and humanities.

Conclusion: SciEvent serves as a challenging benchmark and a step toward generalizable, multi-domain SciIE.

Abstract: Scientific information extraction (SciIE) has primarily relied on
entity-relation extraction in narrow domains, limiting its applicability to
interdisciplinary research and struggling to capture the necessary context of
scientific information, often resulting in fragmented or conflicting
statements. In this paper, we introduce SciEvent, a novel multi-domain
benchmark of scientific abstracts annotated via a unified event extraction (EE)
schema designed to enable structured and context-aware understanding of
scientific content. It includes 500 abstracts across five research domains,
with manual annotations of event segments, triggers, and fine-grained
arguments. We define SciIE as a multi-stage EE pipeline: (1) segmenting
abstracts into core scientific activities--Background, Method, Result, and
Conclusion; and (2) extracting the corresponding triggers and arguments.
Experiments with fine-tuned EE models, large language models (LLMs), and human
annotators reveal a performance gap, with current models struggling in domains
such as sociology and humanities. SciEvent serves as a challenging benchmark
and a step toward generalizable, multi-domain SciIE.

</details>


### [28] [Concept Unlearning in Large Language Models via Self-Constructed Knowledge Triplets](https://arxiv.org/abs/2509.15621)
*Tomoya Yamashita,Yuuki Yamanaka,Masanori Yamada,Takayuki Miura,Toshiki Shibahara,Tomoharu Iwata*

Main category: cs.CL

TL;DR: 本文提出了概念遗忘（CU）作为机器遗忘的新要求，通过知识图谱表示LLM的内部知识，并提出一种新方法来实现更精确和全面的概念删除。


<details>
  <summary>Details</summary>
Motivation: 现有的机器遗忘方法需要明确的目标句子，不支持删除更广泛的概念，如人或事件。为此，我们引入了概念遗忘（CU）作为LLM遗忘的新要求。

Method: 我们提出了一种新方法，通过提示LLM生成关于遗忘目标的知识三元组和解释性句子，并将遗忘过程应用于这些表示。

Result: 我们的方法通过将遗忘过程与LLM的内部知识表示对齐，实现了更精确和全面的概念删除。

Conclusion: 我们的方法在真实世界和合成数据集上的实验表明，它能够有效地实现概念级别的遗忘，同时保留不相关的知识。

Abstract: Machine Unlearning (MU) has recently attracted considerable attention as a
solution to privacy and copyright issues in large language models (LLMs).
Existing MU methods aim to remove specific target sentences from an LLM while
minimizing damage to unrelated knowledge. However, these approaches require
explicit target sentences and do not support removing broader concepts, such as
persons or events. To address this limitation, we introduce Concept Unlearning
(CU) as a new requirement for LLM unlearning. We leverage knowledge graphs to
represent the LLM's internal knowledge and define CU as removing the forgetting
target nodes and associated edges. This graph-based formulation enables a more
intuitive unlearning and facilitates the design of more effective methods. We
propose a novel method that prompts the LLM to generate knowledge triplets and
explanatory sentences about the forgetting target and applies the unlearning
process to these representations. Our approach enables more precise and
comprehensive concept removal by aligning the unlearning process with the LLM's
internal knowledge representations. Experiments on real-world and synthetic
datasets demonstrate that our method effectively achieves concept-level
unlearning while preserving unrelated knowledge.

</details>


### [29] [Sparse-Autoencoder-Guided Internal Representation Unlearning for Large Language Models](https://arxiv.org/abs/2509.15631)
*Tomoya Yamashita,Akira Ito,Yuuki Yamanaka,Masanori Yamada,Takayuki Miura,Toshiki Shibahara*

Main category: cs.CL

TL;DR: 本文提出了一种新的LLM遗忘方法，通过干预模型内部激活实现真正的遗忘，避免了过度抑制和模型崩溃。


<details>
  <summary>Details</summary>
Motivation: 现有的基于抑制的方法可能无法消除模型内部知识，且容易导致模型崩溃，因此需要一种更有效的LLM遗忘方法。

Method: 本文的方法通过在稀疏自编码器潜在空间中修改目标实体的激活，使其远离已知实体并接近未知实体，从而实现遗忘。

Result: 实验证明，本文的方法能够有效对齐被遗忘目标的内部激活，并在问答任务中减少模型对目标知识的回忆，而不会显著损害非目标知识。

Conclusion: 本文提出了一种新的LLM遗忘方法，该方法直接干预模型的内部激活，实现了真正的遗忘，同时避免了过度抑制和模型崩溃。

Abstract: As large language models (LLMs) are increasingly deployed across various
applications, privacy and copyright concerns have heightened the need for more
effective LLM unlearning techniques. Many existing unlearning methods aim to
suppress undesirable outputs through additional training (e.g., gradient
ascent), which reduces the probability of generating such outputs. While such
suppression-based approaches can control model outputs, they may not eliminate
the underlying knowledge embedded in the model's internal activations; muting a
response is not the same as forgetting it. Moreover, such suppression-based
methods often suffer from model collapse. To address these issues, we propose a
novel unlearning method that directly intervenes in the model's internal
activations. In our formulation, forgetting is defined as a state in which the
activation of a forgotten target is indistinguishable from that of ``unknown''
entities. Our method introduces an unlearning objective that modifies the
activation of the target entity away from those of known entities and toward
those of unknown entities in a sparse autoencoder latent space. By aligning the
target's internal activation with those of unknown entities, we shift the
model's recognition of the target entity from ``known'' to ``unknown'',
achieving genuine forgetting while avoiding over-suppression and model
collapse. Empirically, we show that our method effectively aligns the internal
activations of the forgotten target, a result that the suppression-based
approaches do not reliably achieve. Additionally, our method effectively
reduces the model's recall of target knowledge in question-answering tasks
without significant damage to the non-target knowledge.

</details>


### [30] [Multilingual LLM Prompting Strategies for Medical English-Vietnamese Machine Translation](https://arxiv.org/abs/2509.15640)
*Nhu Vo,Nu-Uyen-Phuong Le,Dung D. Le,Massimo Piccardi,Wray Buntine*

Main category: cs.CL

TL;DR: 本文评估了多语言大语言模型在医疗英语-越南语机器翻译中的表现，发现模型规模是性能的主要驱动因素，术语意识提示和基于嵌入的例子检索能有效提升特定领域的翻译效果。


<details>
  <summary>Details</summary>
Motivation: 医疗英语-越南语机器翻译对于越南的医疗获取和交流至关重要，但越南语仍然是资源匮乏和研究不足的语言。

Method: 我们系统地评估了六种多语言LLM（0.5B-9B参数）在MedEV数据集上的提示策略，比较了零样本、少样本和基于词典的提示与Meddict，一个英语-越南语医学词典。

Result: 结果表明，模型规模是性能的主要驱动因素：更大的LLM实现了强大的零样本结果，而少样本提示仅带来微小的改进。相比之下，术语意识提示和基于嵌入的例子检索持续提高了特定领域的翻译效果。

Conclusion: 这些发现突显了多语言大语言模型在医疗英语-越南语机器翻译中的潜力和当前的局限性。

Abstract: Medical English-Vietnamese machine translation (En-Vi MT) is essential for
healthcare access and communication in Vietnam, yet Vietnamese remains a
low-resource and under-studied language. We systematically evaluate prompting
strategies for six multilingual LLMs (0.5B-9B parameters) on the MedEV dataset,
comparing zero-shot, few-shot, and dictionary-augmented prompting with Meddict,
an English-Vietnamese medical lexicon. Results show that model scale is the
primary driver of performance: larger LLMs achieve strong zero-shot results,
while few-shot prompting yields only marginal improvements. In contrast,
terminology-aware cues and embedding-based example retrieval consistently
improve domain-specific translation. These findings underscore both the promise
and the current limitations of multilingual LLMs for medical En-Vi MT.

</details>


### [31] [Layer-wise Minimal Pair Probing Reveals Contextual Grammatical-Conceptual Hierarchy in Speech Representations](https://arxiv.org/abs/2509.15655)
*Linyang He,Qiaolin Wang,Xilin Jiang,Nima Mesgarani*

Main category: cs.CL

TL;DR: 该研究首次系统评估了语音语言模型在自监督学习、自动语音识别、语音压缩和听觉大型语言模型中的上下文语法和语义特征。


<details>
  <summary>Details</summary>
Motivation: 评估语音语言模型（SLMs）中上下文语法和语义特征的存在情况。

Method: 通过最小对设计和跨71项任务的诊断特征分析，进行逐层和时间解析分析。

Result: 所有语音编码在语法特征上比概念特征更稳健。

Conclusion: 所有语音编码在语法特征上比概念特征更稳健。

Abstract: Transformer-based speech language models (SLMs) have significantly improved
neural speech recognition and understanding. While existing research has
examined how well SLMs encode shallow acoustic and phonetic features, the
extent to which SLMs encode nuanced syntactic and conceptual features remains
unclear. By drawing parallels with linguistic competence assessments for large
language models, this study is the first to systematically evaluate the
presence of contextual syntactic and semantic features across SLMs for
self-supervised learning (S3M), automatic speech recognition (ASR), speech
compression (codec), and as the encoder for auditory large language models
(AudioLLMs). Through minimal pair designs and diagnostic feature analysis
across 71 tasks spanning diverse linguistic levels, our layer-wise and
time-resolved analysis uncovers that 1) all speech encode grammatical features
more robustly than conceptual ones.

</details>


### [32] [VOX-KRIKRI: Unifying Speech and Language through Continuous Fusion](https://arxiv.org/abs/2509.15667)
*Dimitrios Damianos,Leon Voukoutis,Georgios Paraskevopoulos,Vassilis Katsouros*

Main category: cs.CL

TL;DR: 本文提出了一种多模态融合框架，用于将基于解码器的预训练大型语言模型与声学编码器-解码器架构（如Whisper）结合起来，以构建语音启用的LLM。通过探索中间音频条件文本空间，实现了跨模态表示的有效对齐，并在希腊语自动语音识别中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 构建语音启用的LLM，通过探索中间音频条件文本空间来实现更有效的对齐，而不是直接使用音频嵌入。

Method: 我们提出了一种多模态融合框架，将基于解码器的预训练大型语言模型（LLM）与声学编码器-解码器架构（如Whisper）联系起来，通过交叉模态注意力将Whisper的隐藏解码器状态与LLM的状态融合，并支持离线和流式模式。

Result: 我们引入了第一个希腊语语音LLM VoxKrikri，并通过分析表明我们的方法有效地对齐了跨模态的表示，在希腊语自动语音识别中实现了平均约20%的相对改进。

Conclusion: 我们的方法展示了跨模态表示对齐的有效性，并为多语言和低资源语音LLM提供了有前景的路径，同时在希腊语自动语音识别中实现了最先进的结果。

Abstract: We present a multimodal fusion framework that bridges pre-trained
decoder-based large language models (LLM) and acoustic encoder-decoder
architectures such as Whisper, with the aim of building speech-enabled LLMs.
Instead of directly using audio embeddings, we explore an intermediate
audio-conditioned text space as a more effective mechanism for alignment. Our
method operates fully in continuous text representation spaces, fusing
Whisper's hidden decoder states with those of an LLM through cross-modal
attention, and supports both offline and streaming modes. We introduce
\textit{VoxKrikri}, the first Greek speech LLM, and show through analysis that
our approach effectively aligns representations across modalities. These
results highlight continuous space fusion as a promising path for multilingual
and low-resource speech LLMs, while achieving state-of-the-art results for
Automatic Speech Recognition in Greek, providing an average $\sim20\%$ relative
improvement across benchmarks.

</details>


### [33] [Fine-Tuning Large Multimodal Models for Automatic Pronunciation Assessment](https://arxiv.org/abs/2509.15701)
*Ke Wang,Wenning Wei,Yan Deng,Lei He,Sheng Zhao*

Main category: cs.CL

TL;DR: 本研究探讨了使用大型多模态模型进行自动发音评估的有效性，发现微调模型在多个任务中表现优异，但在音素层面仍有挑战。


<details>
  <summary>Details</summary>
Motivation: 自动发音评估对于计算机辅助语言学习至关重要，需要在多个粒度和方面进行评估。大型多模态模型为APA提供了新的机会，但其在细粒度评估中的有效性仍不确定。

Method: 使用Speechocean762数据集和一个私有语料库对大型多模态模型进行微调，以进行自动发音评估。

Result: 微调显著优于零样本设置，并在单粒度任务上与公共和商业系统相比取得了具有竞争力的结果。模型在单词和句子层面表现良好，而音素层面的评估仍然具有挑战性。皮尔逊相关系数达到0.9，而斯皮尔曼等级相关系数约为0.6，这表明斯皮尔曼等级相关系数更能反映顺序一致性。

Conclusion: 这些发现突显了大型多模态模型在自动发音评估中的潜力和局限性，并指出了未来在细粒度建模和排名感知评估方面的工作方向。

Abstract: Automatic Pronunciation Assessment (APA) is critical for Computer-Assisted
Language Learning (CALL), requiring evaluation across multiple granularities
and aspects. Large Multimodal Models (LMMs) present new opportunities for APA,
but their effectiveness in fine-grained assessment remains uncertain. This work
investigates fine-tuning LMMs for APA using the Speechocean762 dataset and a
private corpus. Fine-tuning significantly outperforms zero-shot settings and
achieves competitive results on single-granularity tasks compared to public and
commercial systems. The model performs well at word and sentence levels, while
phoneme-level assessment remains challenging. We also observe that the Pearson
Correlation Coefficient (PCC) reaches 0.9, whereas Spearman's rank Correlation
Coefficient (SCC) remains around 0.6, suggesting that SCC better reflects
ordinal consistency. These findings highlight both the promise and limitations
of LMMs for APA and point to future work on fine-grained modeling and
rank-aware evaluation.

</details>


### [34] [Once Upon a Time: Interactive Learning for Storytelling with Small Language Models](https://arxiv.org/abs/2509.15714)
*Jonas Mayer Martins,Ali Hamza Bashir,Muhammad Rehan Khalid,Lisa Beinborn*

Main category: cs.CL

TL;DR: 研究发现，通过高层次反馈，语言模型可以在少量数据下有效提升讲故事能力。


<details>
  <summary>Details</summary>
Motivation: 儿童通过与社会环境中的他人互动来高效获取语言，而大型语言模型通常通过大量文本进行下一步词预测训练。受此对比启发，我们研究是否可以通过学习高层次的认知反馈来减少语言模型的数据需求。

Method: 训练一个学生模型来生成故事，并让教师模型对可读性、叙事连贯性和创造力进行评分，通过改变反馈循环前的预训练量来评估交互学习的影响。

Result: 高层次反馈非常数据高效：在交互学习中仅使用100万词的输入，讲故事的能力可以提升到与4.1亿词的下一步词预测相当的程度。

Conclusion: 高层次反馈在语言模型训练中非常数据高效，可以在少量输入的情况下显著提升讲故事的能力。

Abstract: Children efficiently acquire language not just by listening, but by
interacting with others in their social environment. Conversely, large language
models are typically trained with next-word prediction on massive amounts of
text. Motivated by this contrast, we investigate whether language models can be
trained with less data by learning not only from next-word prediction but also
from high-level, cognitively inspired feedback. We train a student model to
generate stories, which a teacher model rates on readability, narrative
coherence, and creativity. By varying the amount of pretraining before the
feedback loop, we assess the impact of this interactive learning on formal and
functional linguistic competence. We find that the high-level feedback is
highly data efficient: With just 1 M words of input in interactive learning,
storytelling skills can improve as much as with 410 M words of next-word
prediction.

</details>


### [35] [REFER: Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting](https://arxiv.org/abs/2509.15723)
*Nannan Huang,Haytham M. Fayek,Xiuzhen Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种新的方法REFER，通过频率框架提示来提高语言模型在意见总结中的公平性。


<details>
  <summary>Details</summary>
Motivation: 以往的方法依赖于超参数调整或提供地面真实分布信息，但这些方法在实际应用中存在限制，因此需要一种更实用的解决方案。

Method: 研究基于认知科学的研究，利用频率框架提示（REFER）来减少系统性偏差，并通过系统的实验验证其有效性。

Result: 实验结果表明，REFER能够提高语言模型在意见总结中的公平性，特别是在较大的模型和更强的推理指令下效果更显著。

Conclusion: 研究表明，REFER可以提高语言模型在总结意见时的公平性，尤其是在较大的语言模型和使用更强的推理指令时效果更为明显。

Abstract: Individuals express diverse opinions, a fair summary should represent these
viewpoints comprehensively. Previous research on fairness in opinion
summarisation using large language models (LLMs) relied on hyperparameter
tuning or providing ground truth distributional information in prompts.
However, these methods face practical limitations: end-users rarely modify
default model parameters, and accurate distributional information is often
unavailable. Building upon cognitive science research demonstrating that
frequency-based representations reduce systematic biases in human statistical
reasoning by making reference classes explicit and reducing cognitive load,
this study investigates whether frequency framed prompting (REFER) can
similarly enhance fairness in LLM opinion summarisation. Through systematic
experimentation with different prompting frameworks, we adapted techniques
known to improve human reasoning to elicit more effective information
processing in language models compared to abstract probabilistic
representations.Our results demonstrate that REFER enhances fairness in
language models when summarising opinions. This effect is particularly
pronounced in larger language models and using stronger reasoning instructions.

</details>


### [36] [Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics](https://arxiv.org/abs/2509.15739)
*Reza Sanayei,Srdjan Vesic,Eduardo Blanco,Mihai Surdeanu*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型在非线性结构任务中的表现，发现它们在建模形式化论证语义方面有潜力但存在局限性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索大型语言模型在非线性结构任务中的表现，如自然辩论中的论证图。

Method: 我们评估了大型语言模型是否可以近似计算论证理论（CAT）中的结构化推理，具体使用了定量论证辩论（QuAD）语义，该语义基于攻击和支持关系为论证分配可接受性分数。

Result: 模型在与QuAD排名的对齐上表现出中等程度的一致性，但在输入较长或话语流被打断时性能下降。先进的提示策略有助于减轻这些影响，减少与论证长度和位置相关的偏差。

Conclusion: 我们的研究结果表明，大型语言模型在建模形式化论证语义方面既有潜力也有局限性，这促使未来的研究关注于图感知推理。

Abstract: Large Language Models (LLMs) excel at linear reasoning tasks but remain
underexplored on non-linear structures such as those found in natural debates,
which are best expressed as argument graphs. We evaluate whether LLMs can
approximate structured reasoning from Computational Argumentation Theory (CAT).
Specifically, we use Quantitative Argumentation Debate (QuAD) semantics, which
assigns acceptability scores to arguments based on their attack and support
relations. Given only dialogue-formatted debates from two NoDE datasets, models
are prompted to rank arguments without access to the underlying graph. We test
several LLMs under advanced instruction strategies, including Chain-of-Thought
and In-Context Learning. While models show moderate alignment with QuAD
rankings, performance degrades with longer inputs or disrupted discourse flow.
Advanced prompting helps mitigate these effects by reducing biases related to
argument length and position. Our findings highlight both the promise and
limitations of LLMs in modeling formal argumentation semantics and motivate
future work on graph-aware reasoning.

</details>


### [37] [UniGist: Towards General and Hardware-aligned Sequence-level Long Context Compression](https://arxiv.org/abs/2509.15763)
*Chenlong Deng,Zhisong Zhang,Kelong Mao,Shuaiyi Li,Tianqing Fang,Hongming Zhang,Haitao Mi,Dong Yu,Zhicheng Dou*

Main category: cs.CL

TL;DR: UniGist 是一种用于长上下文压缩的框架，通过使用特殊压缩标记来保留上下文信息，并在多个任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理长上下文输入方面越来越强大，但键值（KV）缓存的内存开销仍然是通用部署的主要瓶颈。虽然已经探索了各种压缩策略，但序列级压缩尤其具有挑战性，因为它可能导致重要上下文信息的丢失。

Method: 引入了 UniGist，一种序列级长上下文压缩框架，通过以细粒度方式用特殊压缩标记（gists）替换原始标记来有效保留上下文信息。采用无块训练策略并设计了一个高效的内核，支持灵活的推理。

Result: 实验表明，UniGist 在多个长上下文任务中显著提高了压缩质量，尤其在细节回忆任务和长距离依赖建模中表现突出。

Conclusion: UniGist 显著提高了压缩质量，尤其在细节回忆任务和长距离依赖建模中表现出色。

Abstract: Large language models are increasingly capable of handling long-context
inputs, but the memory overhead of key-value (KV) cache remains a major
bottleneck for general-purpose deployment. While various compression strategies
have been explored, sequence-level compression, which drops the full KV caches
for certain tokens, is particularly challenging as it can lead to the loss of
important contextual information. To address this, we introduce UniGist, a
sequence-level long-context compression framework that efficiently preserves
context information by replacing raw tokens with special compression tokens
(gists) in a fine-grained manner. We adopt a chunk-free training strategy and
design an efficient kernel with a gist shift trick, enabling optimized GPU
training. Our scheme also supports flexible inference by allowing the actual
removal of compressed tokens, resulting in real-time memory savings.
Experiments across multiple long-context tasks demonstrate that UniGist
significantly improves compression quality, with especially strong performance
in detail-recalling tasks and long-range dependency modeling.

</details>


### [38] [UPRPRC: Unified Pipeline for Reproducing Parallel Resources -- Corpus from the United Nations](https://arxiv.org/abs/2509.15789)
*Qiuyang Lu,Fangjian Shen,Zhengkai Tang,Qiang Liu,Hexuan Cheng,Hui Liu,Wushao Wen*

Main category: cs.CL

TL;DR: 本文提出了一种新的端到端解决方案，用于构建大规模、可重复的多语言语料库，并引入了GAPA算法进行段落级对齐，结果表明该语料库是目前最大的公开可用人工翻译语料库。


<details>
  <summary>Details</summary>
Motivation: 多语言数据集的质量和可访问性对于推进机器翻译至关重要。然而，以前从联合国文件构建的语料库存在过程不透明、难以复制和规模有限的问题。

Method: 我们引入了一个完整的端到端解决方案，从网络爬虫获取数据到文本对齐。整个过程是完全可重复的，包括一个最小化的单机示例和可选的分布式计算步骤以提高可扩展性。核心是一个新的图辅助段落对齐（GAPA）算法，用于高效且灵活的段落级对齐。

Result: 生成的语料库包含超过7.13亿个英语标记，规模超过之前工作的两倍。据我们所知，这是最大的公开可用平行语料库，完全由人工翻译而非AI生成的内容组成。

Conclusion: 我们的代码和语料库在MIT许可证下可获取，这为研究者提供了一个强大的资源，以进一步推动机器翻译的发展。

Abstract: The quality and accessibility of multilingual datasets are crucial for
advancing machine translation. However, previous corpora built from United
Nations documents have suffered from issues such as opaque process, difficulty
of reproduction, and limited scale. To address these challenges, we introduce a
complete end-to-end solution, from data acquisition via web scraping to text
alignment. The entire process is fully reproducible, with a minimalist
single-machine example and optional distributed computing steps for
scalability. At its core, we propose a new Graph-Aided Paragraph Alignment
(GAPA) algorithm for efficient and flexible paragraph-level alignment. The
resulting corpus contains over 713 million English tokens, more than doubling
the scale of prior work. To the best of our knowledge, this represents the
largest publicly available parallel corpus composed entirely of
human-translated, non-AI-generated content. Our code and corpus are accessible
under the MIT License.

</details>


### [39] [RAVE: Retrieval and Scoring Aware Verifiable Claim Detection](https://arxiv.org/abs/2509.15793)
*Yufeng Li,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: RAVE is a framework that combines evidence retrieval with structured signals of relevance and source credibility to detect verifiable claims, and it outperforms existing methods.


<details>
  <summary>Details</summary>
Motivation: The rapid spread of misinformation on social media underscores the need for scalable fact-checking tools. A key step is claim detection, which identifies statements that can be objectively verified.

Method: RAVE combines evidence retrieval with structured signals of relevance and source credibility.

Result: Experiments on CT22-test and PoliClaim-test show that RAVE consistently outperforms text-only and retrieval-based baselines in both accuracy and F1.

Conclusion: RAVE consistently outperforms text-only and retrieval-based baselines in both accuracy and F1.

Abstract: The rapid spread of misinformation on social media underscores the need for
scalable fact-checking tools. A key step is claim detection, which identifies
statements that can be objectively verified. Prior approaches often rely on
linguistic cues or claim check-worthiness, but these struggle with vague
political discourse and diverse formats such as tweets. We present RAVE
(Retrieval and Scoring Aware Verifiable Claim Detection), a framework that
combines evidence retrieval with structured signals of relevance and source
credibility. Experiments on CT22-test and PoliClaim-test show that RAVE
consistently outperforms text-only and retrieval-based baselines in both
accuracy and F1.

</details>


### [40] [Best-of-L: Cross-Lingual Reward Modeling for Mathematical Reasoning](https://arxiv.org/abs/2509.15811)
*Sara Rajaee,Rochelle Choenni,Ekaterina Shutova,Christof Monz*

Main category: cs.CL

TL;DR: 研究显示，通过利用不同语言的互补优势，可以提高多语言大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究多语言大语言模型中推理能力的变化以及不同语言是否能产生互补的推理路径。

Method: 我们训练了一个奖励模型来对跨语言生成的回答进行排序，以评估多语言大语言模型中的推理能力。

Result: 我们的跨语言奖励模型显著提高了数学推理性能，甚至对高资源语言也有好处。虽然英语在多语言模型中通常表现最好，但在低采样预算下，跨语言采样特别有利于英语。

Conclusion: 我们的研究揭示了通过利用不同语言的互补优势来提高多语言推理的新机会。

Abstract: While the reasoning abilities of large language models (LLMs) continue to
advance, it remains unclear how such ability varies across languages in
multilingual LLMs and whether different languages produce reasoning paths that
complement each other. To investigate this question, we train a reward model to
rank generated responses for a given question across languages. Our results
show that our cross-lingual reward model substantially improves mathematical
reasoning performance compared to using reward modeling within a single
language, benefiting even high-resource languages. While English often exhibits
the highest performance in multilingual models, we find that cross-lingual
sampling particularly benefits English under low sampling budgets. Our findings
reveal new opportunities to improve multilingual reasoning by leveraging the
complementary strengths of diverse languages.

</details>


### [41] [The Curious Case of Visual Grounding: Different Effects for Speech- and Text-based Language Encoders](https://arxiv.org/abs/2509.15837)
*Adrian Sauter,Willem Zuidema,Marianne de Heer Kloots*

Main category: cs.CL

TL;DR: 研究探讨了视觉信息如何影响基于音频和文本的深度学习模型中的语言处理，发现视觉基础增强了词身份的编码，但未改善语义区分度。


<details>
  <summary>Details</summary>
Motivation: 我们想了解视觉信息如何影响基于音频和文本的深度学习模型中的语言处理。

Method: 我们通过全局表示比较和有针对性的聚类分析来探究视觉基础对模型内部词表示的影响。

Result: 视觉基础增加了口语和书面语言表示之间的对齐，但这种效果主要由词身份的增强编码驱动，而不是意义。语音表示在视觉基础下仍以语音为主，而视觉基础并未提高语义区分度。

Conclusion: 我们的发现可以有助于开发更有效的方法，将视觉信息融入语音模型的语义中。

Abstract: How does visual information included in training affect language processing
in audio- and text-based deep learning models? We explore how such visual
grounding affects model-internal representations of words, and find
substantially different effects in speech- vs. text-based language encoders.
Firstly, global representational comparisons reveal that visual grounding
increases alignment between representations of spoken and written language, but
this effect seems mainly driven by enhanced encoding of word identity rather
than meaning. We then apply targeted clustering analyses to probe for phonetic
vs. semantic discriminability in model representations. Speech-based
representations remain phonetically dominated with visual grounding, but in
contrast to text-based representations, visual grounding does not improve
semantic discriminability. Our findings could usefully inform the development
of more efficient methods to enrich speech-based models with visually-informed
semantics.

</details>


### [42] [Multi-Physics: A Comprehensive Benchmark for Multimodal LLMs Reasoning on Chinese Multi-Subject Physics Problems](https://arxiv.org/abs/2509.15839)
*Zhongze Luo,Zhenshuai Yin,Yongxin Guo,Zhichao Wang,Jionghao Zhu,Xiaoying Tang*

Main category: cs.CL

TL;DR: 本文提出了一种新的多模态语言模型评估基准，用于中文物理推理，并提供了详细的评估方法和数据集。


<details>
  <summary>Details</summary>
Motivation: 当前评估基准在细粒度主题覆盖、逐步推理过程和视觉信息评估方面存在不足，尤其是在科学领域如物理学的应用中。

Method: 本文采用双评估框架来评估20种不同的多模态大语言模型，分析其最终答案准确性和思维链的完整性，并系统研究难度级别和视觉信息的影响。

Result: 本文构建了包含5个难度级别、1412个图像相关选择题的基准，涵盖了11个高中物理主题，并通过实验分析了模型性能的变化。

Conclusion: 本文提出了一个名为Multi-Physics的全面基准，用于评估多模态大语言模型在中文物理推理中的表现，并提供了细粒度资源和方法论。

Abstract: While multimodal LLMs (MLLMs) demonstrate remarkable reasoning progress,
their application in specialized scientific domains like physics reveals
significant gaps in current evaluation benchmarks. Specifically, existing
benchmarks often lack fine-grained subject coverage, neglect the step-by-step
reasoning process, and are predominantly English-centric, failing to
systematically evaluate the role of visual information. Therefore, we introduce
\textbf {Multi-Physics} for Chinese physics reasoning, a comprehensive
benchmark that includes 5 difficulty levels, featuring 1,412 image-associated,
multiple-choice questions spanning 11 high-school physics subjects. We employ a
dual evaluation framework to evaluate 20 different MLLMs, analyzing both final
answer accuracy and the step-by-step integrity of their chain-of-thought.
Furthermore, we systematically study the impact of difficulty level and visual
information by comparing the model performance before and after changing the
input mode. Our work provides not only a fine-grained resource for the
community but also offers a robust methodology for dissecting the multimodal
reasoning process of state-of-the-art MLLMs, and our dataset and code have been
open-sourced: https://github.com/luozhongze/Multi-Physics.

</details>


### [43] [Distribution-Aligned Decoding for Efficient LLM Task Adaptation](https://arxiv.org/abs/2509.15888)
*Senkang Hu,Xudong Han,Jinqi Jiang,Yihang Tao,Zihan Fang,Sam Tak Wu Kwong,Yuguang Fang*

Main category: cs.CL

TL;DR: SVD is a lightweight, PEFT-compatible method that steers the output distribution of large language models toward the task distribution during decoding, resulting in improved performance on various tasks and benchmarks.


<details>
  <summary>Details</summary>
Motivation: Adapting billion-parameter language models to a downstream task is still costly, even with parameter-efficient fine-tuning (PEFT). The goal is to steer the output distribution toward the task distribution directly during decoding rather than through weight updates.

Method: SVD is introduced as a method that steers the output distribution toward the task distribution during decoding, using a task-aware steering vector extracted from the KL divergence gradient between the output distributions of a warm-started and pre-trained model.

Result: SVD paired with four standard PEFT methods improves multiple-choice accuracy by up to 5 points and open-ended truthfulness by 2 points, with similar gains on commonsense datasets without adding trainable parameters beyond the PEFT adapter.

Conclusion: SVD offers a lightweight, theoretically grounded path to stronger task adaptation for large language models.

Abstract: Adapting billion-parameter language models to a downstream task is still
costly, even with parameter-efficient fine-tuning (PEFT). We re-cast task
adaptation as output-distribution alignment: the objective is to steer the
output distribution toward the task distribution directly during decoding
rather than indirectly through weight updates. Building on this view, we
introduce Steering Vector Decoding (SVD), a lightweight, PEFT-compatible, and
theoretically grounded method. We start with a short warm-start fine-tune and
extract a task-aware steering vector from the Kullback-Leibler (KL) divergence
gradient between the output distribution of the warm-started and pre-trained
models. This steering vector is then used to guide the decoding process to
steer the model's output distribution towards the task distribution. We
theoretically prove that SVD is first-order equivalent to the gradient step of
full fine-tuning and derive a globally optimal solution for the strength of the
steering vector. Across three tasks and nine benchmarks, SVD paired with four
standard PEFT methods improves multiple-choice accuracy by up to 5 points and
open-ended truthfulness by 2 points, with similar gains (1-2 points) on
commonsense datasets without adding trainable parameters beyond the PEFT
adapter. SVD thus offers a lightweight, theoretically grounded path to stronger
task adaptation for large language models.

</details>


### [44] [The Psychology of Falsehood: A Human-Centric Survey of Misinformation Detection](https://arxiv.org/abs/2509.15896)
*Arghodeep Nandi,Megha Sundriyal,Euna Mehnaz Khan,Jikai Sun,Emily Vraga,Jaideep Srivastava,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文调查了传统事实核查方法与心理概念（如认知偏见、社会动态和情感反应）之间的相互作用，指出了当前方法的局限性，并提出了未来研究方向，如神经行为模型，以更有效地检测和减轻虚假信息的社会危害。


<details>
  <summary>Details</summary>
Motivation: 虚假信息的危害不仅限于事实的准确性，还涉及人们对信息的感知、解释和情感反应。因此，需要超越事实性，采用更以人为本的检测框架。

Method: 本文通过分析最新的虚假信息检测系统，从人类心理学和行为的角度出发，探讨了传统事实核查方法与心理概念之间的相互作用。

Result: 本文揭示了当前方法的关键限制，并识别了改进的机会，同时概述了未来的研究方向，旨在创建更强大和适应性的框架。

Conclusion: 本文探讨了传统事实核查方法与心理概念之间的相互作用，并指出了当前方法的局限性，同时提出了未来研究方向，如神经行为模型，以更有效地检测和减轻虚假信息的社会危害。

Abstract: Misinformation remains one of the most significant issues in the digital age.
While automated fact-checking has emerged as a viable solution, most current
systems are limited to evaluating factual accuracy. However, the detrimental
effect of misinformation transcends simple falsehoods; it takes advantage of
how individuals perceive, interpret, and emotionally react to information. This
underscores the need to move beyond factuality and adopt more human-centered
detection frameworks. In this survey, we explore the evolving interplay between
traditional fact-checking approaches and psychological concepts such as
cognitive biases, social dynamics, and emotional responses. By analyzing
state-of-the-art misinformation detection systems through the lens of human
psychology and behavior, we reveal critical limitations of current methods and
identify opportunities for improvement. Additionally, we outline future
research directions aimed at creating more robust and adaptive frameworks, such
as neuro-behavioural models that integrate technological factors with the
complexities of human cognition and social influence. These approaches offer
promising pathways to more effectively detect and mitigate the societal harms
of misinformation.

</details>


### [45] [Re-FRAME the Meeting Summarization SCOPE: Fact-Based Summarization and Personalization via Questions](https://arxiv.org/abs/2509.15901)
*Frederic Kirstein,Sonu Kumar,Terry Ruas,Bela Gipp*

Main category: cs.CL

TL;DR: 研究提出FRAME和SCOPE方法，通过语义增强和推理轨迹构建来改善会议摘要的质量，并引入P-MESA评估框架以提高摘要的准确性和个性化。


<details>
  <summary>Details</summary>
Motivation: 会议摘要仍容易出错，常常产生包含幻觉、遗漏和不相关的内容。

Method: FRAME是一种模块化流程，将摘要重新定义为语义增强任务。SCOPE是一种原因输出协议，让模型在内容选择前通过回答九个问题来构建推理轨迹。P-MESA是一个多维、无参考的评估框架，用于评估摘要是否符合目标读者。

Result: FRAME在QMSum和FAME数据集上减少了幻觉和遗漏，SCOPE提高了知识匹配度和目标一致性。P-MESA能够可靠地识别错误实例，并与人类严重程度评分高度一致。

Conclusion: 研究倡导重新思考摘要以提高控制性、忠实性和个性化。

Abstract: Meeting summarization with large language models (LLMs) remains error-prone,
often producing outputs with hallucinations, omissions, and irrelevancies. We
present FRAME, a modular pipeline that reframes summarization as a semantic
enrichment task. FRAME extracts and scores salient facts, organizes them
thematically, and uses these to enrich an outline into an abstractive summary.
To personalize summaries, we introduce SCOPE, a reason-out-loud protocol that
has the model build a reasoning trace by answering nine questions before
content selection. For evaluation, we propose P-MESA, a multi-dimensional,
reference-free evaluation framework to assess if a summary fits a target
reader. P-MESA reliably identifies error instances, achieving >= 89% balanced
accuracy against human annotations and strongly aligns with human severity
ratings (r >= 0.70). On QMSum and FAME, FRAME reduces hallucination and
omission by 2 out of 5 points (measured with MESA), while SCOPE improves
knowledge fit and goal alignment over prompt-only baselines. Our findings
advocate for rethinking summarization to improve control, faithfulness, and
personalization.

</details>


### [46] [Beyond the Score: Uncertainty-Calibrated LLMs for Automated Essay Assessment](https://arxiv.org/abs/2509.15926)
*Ahmed Karim,Qiao Wang,Zheng Yuan*

Main category: cs.CL

TL;DR: 本文使用符合预测和UAcc方法对自动作文评分系统进行了改进，结果表明开源中型大语言模型可以支持教师在循环中的自动作文评分系统。


<details>
  <summary>Details</summary>
Motivation: 当前自动作文评分系统在一些公共基准上达到接近人类的一致性，但在实际应用中，特别是在高风险考试中，仍然有限。主要障碍是大多数模型只输出一个分数，而没有伴随的置信度或解释。

Method: 本文使用了符合预测方法，这是一种分布无关的包装器，可以为任何分类器提供集合值输出和正式的覆盖保证。同时，使用了UAcc（一种考虑不确定性的准确性）来评估可靠性。

Result: 校准后的模型一致达到了覆盖目标，同时保持了预测集的紧凑性。

Conclusion: 本文表明，开源的中型大语言模型已经能够支持教师在循环中的自动作文评分系统，并讨论了扩展和更广泛用户研究作为未来的工作。

Abstract: Automated Essay Scoring (AES) systems now reach near human agreement on some
public benchmarks, yet real-world adoption, especially in high-stakes
examinations, remains limited. A principal obstacle is that most models output
a single score without any accompanying measure of confidence or explanation.
We address this gap with conformal prediction, a distribution-free wrapper that
equips any classifier with set-valued outputs and formal coverage guarantees.
Two open-source large language models (Llama-3 8B and Qwen-2.5 3B) are
fine-tuned on three diverse corpora (ASAP, TOEFL11, Cambridge-FCE) and
calibrated at a 90 percent risk level. Reliability is assessed with UAcc, an
uncertainty-aware accuracy that rewards models for being both correct and
concise. To our knowledge, this is the first work to combine conformal
prediction and UAcc for essay scoring. The calibrated models consistently meet
the coverage target while keeping prediction sets compact, indicating that
open-source, mid-sized LLMs can already support teacher-in-the-loop AES; we
discuss scaling and broader user studies as future work.

</details>


### [47] [Localmax dynamics for attention in transformers and its asymptotic behavior](https://arxiv.org/abs/2509.15958)
*Henri Cimetière,Maria Teresa Chiri,Bahman Gharesifard*

Main category: cs.CL

TL;DR: 本文提出了一种新的离散时间注意力模型——局部最大动态，它在经典softmax和硬最大动态之间进行插值，并通过一个对齐敏感参数放松邻域交互。研究揭示了该模型的渐近行为，并指出未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 为了更好地描述和理解注意力机制中令牌之间的相互作用，特别是在软最大和硬最大动态之间的过渡区域。

Method: 引入了局部最大动态模型，该模型在经典softmax动态和硬最大动态之间进行插值，并通过一个对齐敏感参数放松邻域交互。此外，还应用了基于李雅普诺夫的方法来分析系统行为。

Result: 证明了局部最大动态的凸包仍然收敛到凸多面体，但其结构不能完全由最大对齐集描述，因此引入了静止集来捕捉接近顶点的令牌的不变行为。此外，展示了局部最大动态不表现出有限时间收敛，并提供了对不同对齐敏感参数的分析结果。

Conclusion: 局部最大动态在理论上提供了对系统渐近行为的深入理解，并指出了未来研究的方向。

Abstract: We introduce a new discrete-time attention model, termed the localmax
dynamics, which interpolates between the classic softmax dynamics and the
hardmax dynamics, where only the tokens that maximize the influence toward a
given token have a positive weight. As in hardmax, uniform weights are
determined by a parameter controlling neighbor influence, but the key extension
lies in relaxing neighborhood interactions through an alignment-sensitivity
parameter, which allows controlled deviations from pure hardmax behavior. As we
prove, while the convex hull of the token states still converges to a convex
polytope, its structure can no longer be fully described by a maximal alignment
set, prompting the introduction of quiescent sets to capture the invariant
behavior of tokens near vertices. We show that these sets play a key role in
understanding the asymptotic behavior of the system, even under time-varying
alignment sensitivity parameters. We further show that localmax dynamics does
not exhibit finite-time convergence and provide results for vanishing, nonzero,
time-varying alignment-sensitivity parameters, recovering the limiting behavior
of hardmax as a by-product. Finally, we adapt Lyapunov-based methods from
classical opinion dynamics, highlighting their limitations in the asymmetric
setting of localmax interactions and outlining directions for future research.

</details>


### [48] [BEFT: Bias-Efficient Fine-Tuning of Language Models](https://arxiv.org/abs/2509.15974)
*Baichuan Huang,Ananth Balashankar,Amir Aminifar*

Main category: cs.CL

TL;DR: 本文提出了一种选择要微调的偏差项的方法，以构建偏差高效微调（BEFT）。在多种大型语言模型和任务中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法，例如基于偏差变化的大小或经验Fisher信息的方法，对于选择特定的偏差项进行有效微调提供的指导有限。

Method: 我们提出了一种选择要微调的偏差项的方法，构成了我们偏差高效微调（BEFT）的基础。

Result: 我们在广泛的大型语言模型上评估了我们的偏差高效方法，结果表明其在分类、多项选择和生成任务中的有效性。

Conclusion: 我们的偏差高效方法在各种下游任务中表现出有效性和优越性。

Abstract: Fine-tuning all-bias-terms stands out among various parameter-efficient
fine-tuning (PEFT) techniques, owing to its out-of-the-box usability and
competitive performance, especially in low-data regimes. Bias-only fine-tuning
has the potential for unprecedented parameter efficiency. However, the link
between fine-tuning different bias terms (i.e., bias terms in the query, key,
or value projections) and downstream performance remains unclear. The existing
approaches, e.g., based on the magnitude of bias change or empirical Fisher
information, provide limited guidance for selecting the particular bias term
for effective fine-tuning. In this paper, we propose an approach for selecting
the bias term to be fine-tuned, forming the foundation of our bias-efficient
fine-tuning (BEFT). We extensively evaluate our bias-efficient approach against
other bias-selection approaches, across a wide range of large language models
(LLMs) spanning encoder-only and decoder-only architectures from 110M to 6.7B
parameters. Our results demonstrate the effectiveness and superiority of our
bias-efficient approach on diverse downstream tasks, including classification,
multiple-choice, and generation tasks.

</details>


### [49] [Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning](https://arxiv.org/abs/2509.16025)
*Hong-Yun Lin,Jhen-Ke Lin,Chung-Chun Wang,Hao-Chien Lu,Berlin Chen*

Main category: cs.CL

TL;DR: 本文提出了一种多模态基础模型方法，用于会话级口语评估，能够同时学习整体和特质级目标，避免了传统方法中的问题，并在基准测试中取得了更好的结果。


<details>
  <summary>Details</summary>
Motivation: 随着第二语言英语学习者的数量增加，对可靠SLA的需求日益增长，而现有的方法往往依赖于容易出现错误传播的级联管道，或者在短音频窗口上运行的端到端模型，可能遗漏话语级证据。

Method: 本文提出了一种新颖的多模态基础模型方法，该方法在单次通过中进行会话级评估。该方法结合了多目标学习与基于冻结的Whisper ASR模型的语音先验，以实现声学感知校准，从而在不使用手工特征的情况下联合学习SLA的整体和特质级目标。

Result: 实验结果表明，本文提出的多模态基础模型方法在Speak & Improve基准测试中优于之前的最先进级联系统，并且在跨参与者方面表现出稳健的泛化能力，产生了一个紧凑的可部署评分器，适用于CALL应用。

Conclusion: 本文提出的多模态基础模型方法在Speak & Improve基准测试中表现优于之前的最先进级联系统，并展示了跨参与者的一致性，产生了一个紧凑的可部署评分器，适用于CALL应用。

Abstract: Spoken Language Assessment (SLA) estimates a learner's oral proficiency from
spontaneous speech. The growing population of L2 English speakers has
intensified the demand for reliable SLA, a critical component of Computer
Assisted Language Learning (CALL). Existing efforts often rely on cascaded
pipelines, which are prone to error propagation, or end-to-end models that
often operate on a short audio window, which might miss discourse-level
evidence. This paper introduces a novel multimodal foundation model approach
that performs session-level evaluation in a single pass. Our approach couples
multi-target learning with a frozen, Whisper ASR model-based speech prior for
acoustic-aware calibration, allowing for jointly learning holistic and
trait-level objectives of SLA without resorting to handcrafted features. By
coherently processing the entire response session of an L2 speaker, the model
excels at predicting holistic oral proficiency. Experiments conducted on the
Speak & Improve benchmark demonstrate that our proposed approach outperforms
the previous state-of-the-art cascaded system and exhibits robust cross-part
generalization, producing a compact deployable grader that is tailored for CALL
applications.

</details>


### [50] [Think, Verbalize, then Speak: Bridging Complex Thoughts and Comprehensible Speech](https://arxiv.org/abs/2509.16028)
*Sang Hoon Woo,Sehun Lee,Kang-wook Kim,Gunhee Kim*

Main category: cs.CL

TL;DR: 本文提出了一种将推理与口语表达分离的框架，以保留大型语言模型的推理能力，同时提高语音的自然度和简洁性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法虽然适应LLMs以产生适合语音的输出，但它们对推理性能的影响仍未被充分探索。直接应用LLMs在口语交流中往往会产生次优结果，因为最佳文本和口头表达之间存在不匹配。

Method: 我们提出了Think-Verbalize-Speak框架，将推理与口语表达分离，以保留LLMs的全部推理能力。中心是将思想转化为自然、适合语音的文本的语义化步骤。我们还引入了ReVerT，这是一种基于增量和异步摘要的延迟效率语义化器。

Result: 在多个基准测试中的实验表明，我们的方法在保持推理能力的同时，提高了语音的自然度和简洁性。

Conclusion: 我们的方法在保持推理能力的同时，提高了语音的自然度和简洁性。

Abstract: Spoken dialogue systems increasingly employ large language models (LLMs) to
leverage their advanced reasoning capabilities. However, direct application of
LLMs in spoken communication often yield suboptimal results due to mismatches
between optimal textual and verbal delivery. While existing approaches adapt
LLMs to produce speech-friendly outputs, their impact on reasoning performance
remains underexplored. In this work, we propose Think-Verbalize-Speak, a
framework that decouples reasoning from spoken delivery to preserve the full
reasoning capacity of LLMs. Central to our method is verbalizing, an
intermediate step that translates thoughts into natural, speech-ready text. We
also introduce ReVerT, a latency-efficient verbalizer based on incremental and
asynchronous summarization. Experiments across multiple benchmarks show that
our method enhances speech naturalness and conciseness with minimal impact on
reasoning. The project page with the dataset and the source code is available
at https://yhytoto12.github.io/TVS-ReVerT

</details>


### [51] [Beyond Pointwise Scores: Decomposed Criteria-Based Evaluation of LLM Responses](https://arxiv.org/abs/2509.16093)
*Fangyi Yu,Nabeel Seedat,Dasha Herrmannova,Frank Schilder,Jonathan Richard Schwarz*

Main category: cs.CL

TL;DR: DeCE is a decomposed LLM evaluation framework that separates precision and recall, using instance-specific criteria automatically extracted from gold answer requirements. It achieves a stronger correlation with expert judgments than traditional metrics and shows interpretable trade-offs between generalist and specialized models.


<details>
  <summary>Details</summary>
Motivation: Evaluating long-form answers in high-stakes domains such as law or medicine remains a fundamental challenge. Standard metrics like BLEU and ROUGE fail to capture semantic correctness, and current LLM-based evaluators often reduce nuanced aspects of answer quality into a single undifferentiated score.

Method: DeCE is a decomposed LLM evaluation framework that separates precision (factual accuracy and relevance) and recall (coverage of required concepts), using instance-specific criteria automatically extracted from gold answer requirements.

Result: DeCE achieves substantially stronger correlation with expert judgments (r=0.78), compared to traditional metrics (r=0.12), pointwise LLM scoring (r=0.35), and modern multidimensional evaluators (r=0.48). It also reveals interpretable trade-offs: generalist models favor recall, while specialized models favor precision. Only 11.95% of LLM-generated criteria required expert revision, underscoring DeCE's scalability.

Conclusion: DeCE offers an interpretable and actionable LLM evaluation framework in expert domains.

Abstract: Evaluating long-form answers in high-stakes domains such as law or medicine
remains a fundamental challenge. Standard metrics like BLEU and ROUGE fail to
capture semantic correctness, and current LLM-based evaluators often reduce
nuanced aspects of answer quality into a single undifferentiated score. We
introduce DeCE, a decomposed LLM evaluation framework that separates precision
(factual accuracy and relevance) and recall (coverage of required concepts),
using instance-specific criteria automatically extracted from gold answer
requirements. DeCE is model-agnostic and domain-general, requiring no
predefined taxonomies or handcrafted rubrics. We instantiate DeCE to evaluate
different LLMs on a real-world legal QA task involving multi-jurisdictional
reasoning and citation grounding. DeCE achieves substantially stronger
correlation with expert judgments ($r=0.78$), compared to traditional metrics
($r=0.12$), pointwise LLM scoring ($r=0.35$), and modern multidimensional
evaluators ($r=0.48$). It also reveals interpretable trade-offs: generalist
models favor recall, while specialized models favor precision. Importantly,
only 11.95% of LLM-generated criteria required expert revision, underscoring
DeCE's scalability. DeCE offers an interpretable and actionable LLM evaluation
framework in expert domains.

</details>


### [52] [DiEP: Adaptive Mixture-of-Experts Compression through Differentiable Expert Pruning](https://arxiv.org/abs/2509.16105)
*Sikai Bai,Haoxi Li,Jie Zhang,Zicong Hong,Song Guo*

Main category: cs.CL

TL;DR: 本文提出了一种名为 DiEP 的非均匀剪枝策略，能够自适应地调整不同层的剪枝率，从而有效处理 MoE 模型中的专家冗余问题，并在多个 NLP 任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的 MoE 剪枝方法通常在所有层中使用统一的稀疏性，这可能导致次优结果和性能下降，因为不同 MoE 层中的专家冗余程度不同。

Method: DiEP 是一种非均匀剪枝策略，通过在层级别自适应调整剪枝率，并联合学习层间重要性，以捕捉不同 MoE 层之间的冗余差异。

Result: 在五个先进的 MoE 模型上的实验表明，DiEP 在各种 NLP 任务中效果显著。特别地，在 Mixtral 8×7B 上，DiEP 仅使用一半的专家就能保留大约 92% 的原始性能，并在 MMLU 数据集上比其他剪枝方法高出最多 7.1%。

Conclusion: DiEP 在各种 NLP 任务中表现出色，能够在减少专家数量的同时保持接近原始性能。

Abstract: Despite the significant breakthrough of Mixture-of-Experts (MoE), the
increasing scale of these MoE models presents huge memory and storage
challenges. Existing MoE pruning methods, which involve reducing parameter size
with a uniform sparsity across all layers, often lead to suboptimal outcomes
and performance degradation due to varying expert redundancy in different MoE
layers. To address this, we propose a non-uniform pruning strategy, dubbed
\textbf{Di}fferentiable \textbf{E}xpert \textbf{P}runing (\textbf{DiEP}), which
adaptively adjusts pruning rates at the layer level while jointly learning
inter-layer importance, effectively capturing the varying redundancy across
different MoE layers. By transforming the global discrete search space into a
continuous one, our method handles exponentially growing non-uniform expert
combinations, enabling adaptive gradient-based pruning. Extensive experiments
on five advanced MoE models demonstrate the efficacy of our method across
various NLP tasks. Notably, \textbf{DiEP} retains around 92\% of original
performance on Mixtral 8$\times$7B with only half the experts, outperforming
other pruning methods by up to 7.1\% on the challenging MMLU dataset.

</details>


### [53] [It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge](https://arxiv.org/abs/2509.16107)
*Lukas Ellinger,Georg Groh*

Main category: cs.CL

TL;DR: 研究发现，当前大型语言模型在解决指代歧义方面存在困难，尤其是在简化语言请求下。通过微调可以显著改善这一问题。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否能够利用常识来解决多轮对话中的指代歧义，并分析当歧义持续存在时它们的行为。此外，研究简化语言请求如何影响这种能力。

Method: 使用了一个新的多语言评估数据集，通过LLM-as-Judge和人工注释测试了DeepSeek v3、GPT-4o、Qwen3-32B、GPT-4o-mini和Llama-3.1-8B。此外，还研究了简化语言请求对这种能力的影响，并对Llama-3.1-8B进行了直接偏好优化的微调。

Result: 当前的大型语言模型在解决歧义方面表现不佳，倾向于坚持单一解释或涵盖所有可能的参考，而不是采取中间立场或寻求澄清。在简化提示下，这种限制变得更加明显，这大大减少了常识推理和多样化的响应策略的使用。对Llama-3.1-8B进行直接偏好优化的微调显著提高了所有请求类型的歧义解决能力。

Conclusion: 当前大型语言模型在有效解决歧义方面存在困难，这表明需要先进的微调来提高它们处理歧义的能力，并确保在不同沟通风格下的稳健性能。

Abstract: Ambiguous words or underspecified references require interlocutors to resolve
them, often by relying on shared context and commonsense knowledge. Therefore,
we systematically investigate whether Large Language Models (LLMs) can leverage
commonsense to resolve referential ambiguity in multi-turn conversations and
analyze their behavior when ambiguity persists. Further, we study how requests
for simplified language affect this capacity. Using a novel multilingual
evaluation dataset, we test DeepSeek v3, GPT-4o, Qwen3-32B, GPT-4o-mini, and
Llama-3.1-8B via LLM-as-Judge and human annotations. Our findings indicate that
current LLMs struggle to resolve ambiguity effectively: they tend to commit to
a single interpretation or cover all possible references, rather than hedging
or seeking clarification. This limitation becomes more pronounced under
simplification prompts, which drastically reduce the use of commonsense
reasoning and diverse response strategies. Fine-tuning Llama-3.1-8B with Direct
Preference Optimization substantially improves ambiguity resolution across all
request types. These results underscore the need for advanced fine-tuning to
improve LLMs' handling of ambiguity and to ensure robust performance across
diverse communication styles.

</details>


### [54] [CodeRAG: Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion](https://arxiv.org/abs/2509.16112)
*Sheng Zhang,Yifan Ding,Shuquan Lian,Shun Song,Hui Li*

Main category: cs.CL

TL;DR: 本文提出CodeRAG框架，用于改进仓库级代码补全，通过多路径检索和重新排序提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在查询构建、单路径代码检索和代码检索器与代码LLM之间的不对齐问题。

Method: CodeRAG框架包括日志概率引导的查询构建、多路径代码检索和偏好对齐的BestFit重新排序。

Result: 在ReccEval和CCEval基准测试中，CodeRAG显著优于最先进的方法。

Conclusion: CodeRAG显著且一致地优于最先进的方法，证明了其有效性。

Abstract: Repository-level code completion automatically predicts the unfinished code
based on the broader information from the repository. Recent strides in Code
Large Language Models (code LLMs) have spurred the development of
repository-level code completion methods, yielding promising results.
Nevertheless, they suffer from issues such as inappropriate query construction,
single-path code retrieval, and misalignment between code retriever and code
LLM. To address these problems, we introduce CodeRAG, a framework tailored to
identify relevant and necessary knowledge for retrieval-augmented
repository-level code completion. Its core components include log probability
guided query construction, multi-path code retrieval, and preference-aligned
BestFit reranking. Extensive experiments on benchmarks ReccEval and CCEval
demonstrate that CodeRAG significantly and consistently outperforms
state-of-the-art methods. The implementation of CodeRAG is available at
https://github.com/KDEGroup/CodeRAG.

</details>


### [55] [CultureScope: A Dimensional Lens for Probing Cultural Understanding in LLMs](https://arxiv.org/abs/2509.16188)
*Jinghao Zhang,Sihang Jiang,Shiwei Guo,Shisong Chen,Yanghua Xiao,Hongwei Feng,Jiaqing Liang,Minggui HE,Shimin Tao,Hongxia Ma*

Main category: cs.CL

TL;DR: 本文提出了CultureScope，这是目前最全面的评估框架，用于评估大型语言模型的文化理解能力。通过受文化冰山理论启发的新型维度模式，指导了针对任何给定语言和文化的特定文化知识库和评估数据集的自动化构建。实验结果表明，该方法有效，并揭示了现有模型在文化能力方面的不足。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在多样化的文化环境中日益部署，评估其文化理解能力对于确保可信和文化一致的应用至关重要。然而，大多数现有的基准测试缺乏全面性，并且在不同文化背景下难以扩展和适应，因为它们的框架往往缺乏来自已建立文化理论的指导，并且依赖于专家驱动的手动注释。

Method: 受文化冰山理论的启发，我们设计了一个新的文化知识分类维度模式，包括3个层次和140个维度，这指导了针对任何给定语言和文化的特定文化知识库和相应评估数据集的自动化构建。

Result: 实验结果表明，我们的方法可以有效地评估文化理解能力。结果还揭示了现有的大型语言模型在文化能力方面存在不足，仅仅包含多语言数据并不一定能增强文化理解能力。

Conclusion: 实验结果表明，我们的方法可以有效地评估文化理解能力。结果还揭示了现有的大型语言模型在文化能力方面存在不足，仅仅包含多语言数据并不一定能增强文化理解能力。

Abstract: As large language models (LLMs) are increasingly deployed in diverse cultural
environments, evaluating their cultural understanding capability has become
essential for ensuring trustworthy and culturally aligned applications.
However, most existing benchmarks lack comprehensiveness and are challenging to
scale and adapt across different cultural contexts, because their frameworks
often lack guidance from well-established cultural theories and tend to rely on
expert-driven manual annotations. To address these issues, we propose
CultureScope, the most comprehensive evaluation framework to date for assessing
cultural understanding in LLMs. Inspired by the cultural iceberg theory, we
design a novel dimensional schema for cultural knowledge classification,
comprising 3 layers and 140 dimensions, which guides the automated construction
of culture-specific knowledge bases and corresponding evaluation datasets for
any given languages and cultures. Experimental results demonstrate that our
method can effectively evaluate cultural understanding. They also reveal that
existing large language models lack comprehensive cultural competence, and
merely incorporating multilingual data does not necessarily enhance cultural
understanding. All code and data files are available at
https://github.com/HoganZinger/Culture

</details>


### [56] [RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation](https://arxiv.org/abs/2509.16198)
*Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang*

Main category: cs.CL

TL;DR: 本文提出了Repository Planning Graph (RPG) 和 ZeroRepo 框架，用于从零开始生成仓库，并在 RepoCraft 基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 生成完整的仓库从头开始仍然是一个基本挑战，需要在提案级和实现级阶段进行连贯且可靠的规划，而自然语言由于其模糊性和冗长性，不适合忠实表示复杂的软件结构。

Method: 引入了Repository Planning Graph (RPG)，这是一种统一提案级和实现级规划的持久表示，通过编码能力、文件结构、数据流和函数在一个图中。基于RPG，开发了ZeroRepo，一个从零开始生成仓库的图驱动框架。

Result: 在RepoCraft上，ZeroRepo生成的仓库平均接近36K LOC，大约是最强基线（Claude Code）的3.9倍，其他基线的64倍。它实现了81.5%的功能覆盖率和69.7%的通过率，分别超过Claude Code 27.3和35.8个百分点。

Conclusion: RPG模型能够处理复杂的依赖关系，并通过近线性扩展实现更高级的规划，同时提高大型语言模型对仓库的理解，从而加速代理定位。

Abstract: Large language models excel at function- and file-level code generation, yet
generating complete repositories from scratch remains a fundamental challenge.
This process demands coherent and reliable planning across proposal- and
implementation-level stages, while natural language, due to its ambiguity and
verbosity, is ill-suited for faithfully representing complex software
structures. To address this, we introduce the Repository Planning Graph (RPG),
a persistent representation that unifies proposal- and implementation-level
planning by encoding capabilities, file structures, data flows, and functions
in one graph. RPG replaces ambiguous natural language with an explicit
blueprint, enabling long-horizon planning and scalable repository generation.
Building on RPG, we develop ZeroRepo, a graph-driven framework for repository
generation from scratch. It operates in three stages: proposal-level planning
and implementation-level refinement to construct the graph, followed by
graph-guided code generation with test validation. To evaluate this setting, we
construct RepoCraft, a benchmark of six real-world projects with 1,052 tasks.
On RepoCraft, ZeroRepo produces repositories averaging nearly 36K LOC, roughly
3.9$\times$ the strongest baseline (Claude Code) and about 64$\times$ other
baselines. It attains 81.5% functional coverage and a 69.7% pass rate,
exceeding Claude Code by 27.3 and 35.8 percentage points, respectively. Further
analysis shows that RPG models complex dependencies, enables progressively more
sophisticated planning through near-linear scaling, and enhances LLM
understanding of repositories, thereby accelerating agent localization.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [57] [ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding](https://arxiv.org/abs/2509.15235)
*Jialiang Kang,Han Shu,Wenshuo Li,Yingjie Zhai,Xinghao Chen*

Main category: cs.CV

TL;DR: ViSpec is a new framework for accelerating inference in vision-language models by effectively filtering redundant image information and enhancing multimodal coherence.


<details>
  <summary>Details</summary>
Motivation: Existing methods for speculative decoding in vision-language models have only achieved modest speedups, and there is a need for more effective techniques as multimodal capabilities become central to large-scale models.

Method: ViSpec uses a lightweight vision adaptor module to compress image tokens and integrates it into the draft model's attention mechanism. It also extracts a global feature vector for each input image and augments text tokens with this feature.

Result: Experiments validate ViSpec, achieving the first substantial speedup in VLM speculative decoding.

Conclusion: ViSpec is a novel framework for vision-language models that achieves significant speedup in speculative decoding.

Abstract: Speculative decoding is a widely adopted technique for accelerating inference
in large language models (LLMs), yet its application to vision-language models
(VLMs) remains underexplored, with existing methods achieving only modest
speedups (<1.5x). This gap is increasingly significant as multimodal
capabilities become central to large-scale models. We hypothesize that large
VLMs can effectively filter redundant image information layer by layer without
compromising textual comprehension, whereas smaller draft models struggle to do
so. To address this, we introduce Vision-Aware Speculative Decoding (ViSpec), a
novel framework tailored for VLMs. ViSpec employs a lightweight vision adaptor
module to compress image tokens into a compact representation, which is
seamlessly integrated into the draft model's attention mechanism while
preserving original image positional information. Additionally, we extract a
global feature vector for each input image and augment all subsequent text
tokens with this feature to enhance multimodal coherence. To overcome the
scarcity of multimodal datasets with long assistant responses, we curate a
specialized training dataset by repurposing existing datasets and generating
extended outputs using the target VLM with modified prompts. Our training
strategy mitigates the risk of the draft model exploiting direct access to the
target model's hidden states, which could otherwise lead to shortcut learning
when training solely on target model outputs. Extensive experiments validate
ViSpec, achieving, to our knowledge, the first substantial speedup in VLM
speculative decoding.

</details>


### [58] [M-PACE: Mother Child Framework for Multimodal Compliance](https://arxiv.org/abs/2509.15241)
*Shreyash Verma,Amit Kesari,Vinayak Trivedi,Anupam Purwar,Ratnesh Jamidar*

Main category: cs.CV

TL;DR: 本文提出了一种名为 M-PACE 的多模态合规引擎，用于评估视觉和文本输入的属性，并在广告合规性方面进行了测试，展示了其在成本和输出质量之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 传统合规框架通常依赖于分离的多阶段管道，这增加了运营开销，阻碍了可扩展性，并且难以适应动态指南。随着多模态大语言模型（MLLMs）的出现，有潜力将这些工作流程统一到一个通用框架中。

Method: M-PACE 采用了一种母-子 MLLM 设置，其中更强的父 MLLM 评估较小的子模型的输出，从而减少对人工审查员的依赖。此外，还引入了一个经过人工标注的基准测试，以支持结构化的评估。

Result: M-PACE 能够评估超过15个与合规性相关的属性，并且在推理成本方面减少了31倍。最有效的模型（Gemini 2.0 Flash 作为子 MLLM）每张图像的成本为0.0005，而 Gemini 2.5 Pro 的成本为0.0159，显示出实时部署中成本和输出质量之间的权衡。

Conclusion: M-PACE 是一种用于评估跨视觉和文本输入属性的框架，它展示了在广告合规性方面的应用，并通过实验验证了其在成本和输出质量之间的权衡。

Abstract: Ensuring that multi-modal content adheres to brand, legal, or
platform-specific compliance standards is an increasingly complex challenge
across domains. Traditional compliance frameworks typically rely on disjointed,
multi-stage pipelines that integrate separate modules for image classification,
text extraction, audio transcription, hand-crafted checks, and rule-based
merges. This architectural fragmentation increases operational overhead,
hampers scalability, and hinders the ability to adapt to dynamic guidelines
efficiently. With the emergence of Multimodal Large Language Models (MLLMs),
there is growing potential to unify these workflows under a single,
general-purpose framework capable of jointly processing visual and textual
content. In light of this, we propose Multimodal Parameter Agnostic Compliance
Engine (M-PACE), a framework designed for assessing attributes across
vision-language inputs in a single pass. As a representative use case, we apply
M-PACE to advertisement compliance, demonstrating its ability to evaluate over
15 compliance-related attributes. To support structured evaluation, we
introduce a human-annotated benchmark enriched with augmented samples that
simulate challenging real-world conditions, including visual obstructions and
profanity injection. M-PACE employs a mother-child MLLM setup, demonstrating
that a stronger parent MLLM evaluating the outputs of smaller child models can
significantly reduce dependence on human reviewers, thereby automating quality
control. Our analysis reveals that inference costs reduce by over 31 times,
with the most efficient models (Gemini 2.0 Flash as child MLLM selected by
mother MLLM) operating at 0.0005 per image, compared to 0.0159 for Gemini 2.5
Pro with comparable accuracy, highlighting the trade-off between cost and
output quality achieved in real time by M-PACE in real life deployment over
advertising data.

</details>


### [59] [Beyond Words: Enhancing Desire, Emotion, and Sentiment Recognition with Non-Verbal Cues](https://arxiv.org/abs/2509.15540)
*Wei Chen,Tongguan Wang,Feiyue Xue,Junkai Li,Hui Liu,Ying Sha*

Main category: cs.CV

TL;DR: 本文提出了一种对称双向多模态学习框架，用于更准确地理解和识别人类的欲望、情绪和情感。


<details>
  <summary>Details</summary>
Motivation: 现有的情感分析方法主要强调语言线索，而忽略了图像作为补充非语言线索的作用。因此，本文旨在探索专门针对人类欲望理解的多模态方法，以填补这一研究空白。

Method: 本文提出了一种对称双向多模态学习框架，利用低分辨率图像获取全局视觉表示以进行跨模态对齐，同时将高分辨率图像分割为子图像并使用掩码图像建模来增强细粒度局部特征的捕捉能力。引入了文本引导的图像解码器和图像引导的文本解码器，以促进图像信息在局部和全局表示上的深度跨模态交互。此外，采用混合尺度图像策略来平衡感知收益与计算成本。

Result: 在MSED数据集上的实验结果表明，本文提出的框架在欲望理解、情绪识别和情感分析任务中分别实现了1.1%、0.6%和0.9%的F1分数提升，验证了方法的有效性。

Conclusion: 本文提出了一种对人类欲望、情绪和情感识别的对称双向多模态学习框架，通过相互指导文本和图像模态来有效捕捉与意图相关的表示。实验结果表明，该方法在多个任务上均优于现有方法，验证了其有效性。

Abstract: Desire, as an intention that drives human behavior, is closely related to
both emotion and sentiment. Multimodal learning has advanced sentiment and
emotion recognition, but multimodal approaches specially targeting human desire
understanding remain underexplored. And existing methods in sentiment analysis
predominantly emphasize verbal cues and overlook images as complementary
non-verbal cues. To address these gaps, we propose a Symmetrical Bidirectional
Multimodal Learning Framework for Desire, Emotion, and Sentiment Recognition,
which enforces mutual guidance between text and image modalities to effectively
capture intention-related representations in the image. Specifically,
low-resolution images are used to obtain global visual representations for
cross-modal alignment, while high resolution images are partitioned into
sub-images and modeled with masked image modeling to enhance the ability to
capture fine-grained local features. A text-guided image decoder and an
image-guided text decoder are introduced to facilitate deep cross-modal
interaction at both local and global representations of image information.
Additionally, to balance perceptual gains with computation cost, a mixed-scale
image strategy is adopted, where high-resolution images are cropped into
sub-images for masked modeling. The proposed approach is evaluated on MSED, a
multimodal dataset that includes a desire understanding benchmark, as well as
emotion and sentiment recognition. Experimental results indicate consistent
improvements over other state-of-the-art methods, validating the effectiveness
of our proposed method. Specifically, our method outperforms existing
approaches, achieving F1-score improvements of 1.1% in desire understanding,
0.6% in emotion recognition, and 0.9% in sentiment analysis. Our code is
available at: https://github.com/especiallyW/SyDES.

</details>


### [60] [Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks](https://arxiv.org/abs/2509.16163)
*Het Patel,Muzammil Allie,Qian Zhang,Jia Chen,Evangelos E. Papalexakis*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的防御方法，利用张量分解来过滤对抗性噪声，提高VLM的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的防御措施通常需要昂贵的重新训练或显著的架构更改，因此需要一种轻量级的防御方法。

Method: 使用张量分解的方法，通过分解和重建视觉编码器表示来过滤对抗性噪声，同时保留语义。

Result: 在Flickr30K数据集上，该方法恢复了12.3%因攻击而损失的性能，将Recall@1准确率从7.5%提高到19.8%；在COCO数据集上，恢复了8.1%的性能，将准确率从3.8%提高到11.9%。

Conclusion: 该方法为现有的VLM提供了一种实用且即插即用的解决方案，具有最小的开销。

Abstract: Vision language models (VLMs) excel in multimodal understanding but are prone
to adversarial attacks. Existing defenses often demand costly retraining or
significant architecture changes. We introduce a lightweight defense using
tensor decomposition suitable for any pre-trained VLM, requiring no retraining.
By decomposing and reconstructing vision encoder representations, it filters
adversarial noise while preserving meaning. Experiments with CLIP on COCO and
Flickr30K show improved robustness. On Flickr30K, it restores 12.3\%
performance lost to attacks, raising Recall@1 accuracy from 7.5\% to 19.8\%. On
COCO, it recovers 8.1\% performance, improving accuracy from 3.8\% to 11.9\%.
Analysis shows Tensor Train decomposition with low rank (8-32) and low residual
strength ($\alpha=0.1-0.2$) is optimal. This method is a practical,
plug-and-play solution with minimal overhead for existing VLMs.

</details>


### [61] [MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer](https://arxiv.org/abs/2509.16197)
*Yanghao Li,Rui Qian,Bowen Pan,Haotian Zhang,Haoshuo Huang,Bowen Zhang,Jialing Tong,Haoxuan You,Xianzhi Du,Zhe Gan,Hyunjik Kim,Chao Jia,Zhenbang Wang,Yinfei Yang,Mingfei Gao,Zi-Yi Dou,Wenze Hu,Chang Gao,Dongxu Li,Philipp Dufter,Zirui Wang,Guoli Yin,Zhengdong Zhang,Chen Chen,Yang Zhao,Ruoming Pang,Zhifeng Chen*

Main category: cs.CV

TL;DR: Manzano is a unified framework that reduces the performance trade-off between understanding and generating visual content by using a hybrid image tokenizer and a well-curated training recipe.


<details>
  <summary>Details</summary>
Motivation: Unified multimodal Large Language Models (LLMs) that can both understand and generate visual content hold immense potential. However, existing open-source models often suffer from a performance trade-off between these capabilities.

Method: Manzano is a simple and scalable unified framework that couples a hybrid image tokenizer with a well-curated training recipe. A single shared vision encoder feeds two lightweight adapters that produce continuous embeddings for image-to-text understanding and discrete tokens for text-to-image generation within a common semantic space. A unified autoregressive LLM predicts high-level semantics in the form of text and image tokens, with an auxiliary diffusion decoder subsequently translating the image tokens into pixels.

Result: Manzano achieves state-of-the-art results among unified models, and is competitive with specialist models, particularly on text-rich evaluation. Our studies show minimal task conflicts and consistent gains from scaling model size, validating our design choice of a hybrid tokenizer.

Conclusion: Manzano achieves state-of-the-art results among unified models, and is competitive with specialist models, particularly on text-rich evaluation. Our studies show minimal task conflicts and consistent gains from scaling model size, validating our design choice of a hybrid tokenizer.

Abstract: Unified multimodal Large Language Models (LLMs) that can both understand and
generate visual content hold immense potential. However, existing open-source
models often suffer from a performance trade-off between these capabilities. We
present Manzano, a simple and scalable unified framework that substantially
reduces this tension by coupling a hybrid image tokenizer with a well-curated
training recipe. A single shared vision encoder feeds two lightweight adapters
that produce continuous embeddings for image-to-text understanding and discrete
tokens for text-to-image generation within a common semantic space. A unified
autoregressive LLM predicts high-level semantics in the form of text and image
tokens, with an auxiliary diffusion decoder subsequently translating the image
tokens into pixels. The architecture, together with a unified training recipe
over understanding and generation data, enables scalable joint learning of both
capabilities. Manzano achieves state-of-the-art results among unified models,
and is competitive with specialist models, particularly on text-rich
evaluation. Our studies show minimal task conflicts and consistent gains from
scaling model size, validating our design choice of a hybrid tokenizer.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [62] [Learning Analytics from Spoken Discussion Dialogs in Flipped Classroom](https://arxiv.org/abs/2301.12399)
*Hang Su,Borislav Dzodzo,Changlun Li,Danyang Zhao,Hao Geng,Yunxiang Li,Sidharth Jaggi,Helen Meng*

Main category: cs.CY

TL;DR: 本研究探讨了翻转课堂中小组讨论对话的学习分析，通过机器学习算法预测学习成果，取得了较高的准确率。


<details>
  <summary>Details</summary>
Motivation: 翻转课堂是一种新兴的教学策略，其中口语讨论对话包含丰富的信息，可以反映学生的学习过程和进展。本研究旨在通过学习分析来了解小组学习的过程和结果。

Method: 研究通过收集和分析翻转课堂中的小组讨论对话，提取特征并进行统计分析，然后应用机器学习算法来预测小组学习成果。

Result: 研究成功地应用了机器学习算法来预测小组学习成果，并达到了78.9%的最佳预测准确率。

Conclusion: 该研究展示了从翻转课堂中的小组讨论对话中自动预测学习成果的可行性，最佳预测准确率达到78.9%。

Abstract: The flipped classroom is a new pedagogical strategy that has been gaining
increasing importance recently. Spoken discussion dialog commonly occurs in
flipped classroom, which embeds rich information indicating processes and
progression of students' learning. This study focuses on learning analytics
from spoken discussion dialog in the flipped classroom, which aims to collect
and analyze the discussion dialogs in flipped classroom in order to get to know
group learning processes and outcomes. We have recently transformed a course
using the flipped classroom strategy, where students watched video-recorded
lectures at home prior to group-based problem-solving discussions in class. The
in-class group discussions were recorded throughout the semester and then
transcribed manually. After features are extracted from the dialogs by multiple
tools and customized processing techniques, we performed statistical analyses
to explore the indicators that are related to the group learning outcomes from
face-to-face discussion dialogs in the flipped classroom. Then, machine
learning algorithms are applied to the indicators in order to predict the group
learning outcome as High, Mid or Low. The best prediction accuracy reaches
78.9%, which demonstrates the feasibility of achieving automatic learning
outcome prediction from group discussion dialog in flipped classroom.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [63] [Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents](https://arxiv.org/abs/2509.15233)
*Xueqiao Zhang,Chao Zhang,Jingtao Xu,Yifan Zhu,Xin Shi,Yi Yang,Yawei Luo*

Main category: cs.MM

TL;DR: 本文提出了一种基于视频模态的动态角色配置文件方法，并构建了一个大规模数据集，验证了其在提升RPAs性能方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注静态角色配置文件，忽略了人类固有的动态感知能力，因此需要引入动态角色配置文件以提高RPAs的交互性和沉浸感。

Method: 本文引入了动态角色配置文件，结合视频模态和对话数据，构建了一个包含自适应时间采样和动态与静态角色配置文件表示的RPA框架。

Result: 实验结果表明，本文提出的框架在八个评估指标上均表现出色，证明了动态角色配置文件在开发RPAs中的重要性。

Conclusion: 本文提出了动态角色配置文件的概念，并通过构建Role-playing-Video60k数据集和开发一个综合的RPA框架，验证了其在提升RPAs生成响应能力方面的有效性。

Abstract: Role-playing agents (RPAs) have attracted growing interest for their ability
to simulate immersive and interactive characters. However, existing approaches
primarily focus on static role profiles, overlooking the dynamic perceptual
abilities inherent to humans. To bridge this gap, we introduce the concept of
dynamic role profiles by incorporating video modality into RPAs. To support
this, we construct Role-playing-Video60k, a large-scale, high-quality dataset
comprising 60k videos and 700k corresponding dialogues. Based on this dataset,
we develop a comprehensive RPA framework that combines adaptive temporal
sampling with both dynamic and static role profile representations.
Specifically, the dynamic profile is created by adaptively sampling video
frames and feeding them to the LLM in temporal order, while the static profile
consists of (1) character dialogues from training videos during fine-tuning,
and (2) a summary context from the input video during inference. This joint
integration enables RPAs to generate greater responses. Furthermore, we propose
a robust evaluation method covering eight metrics. Experimental results
demonstrate the effectiveness of our framework, highlighting the importance of
dynamic role profiles in developing RPAs.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [64] [VoXtream: Full-Stream Text-to-Speech with Extremely Low Latency](https://arxiv.org/abs/2509.15969)
*Nikita Torgashov,Gustav Eje Henter,Gabriel Skantze*

Main category: eess.AS

TL;DR: VoXtream is a low-delay, high-performance streaming TTS system that maps phonemes to audio tokens using a combination of transformers.


<details>
  <summary>Details</summary>
Motivation: The motivation is to create a fully autoregressive, zero-shot streaming text-to-speech system that can start speaking from the first word with minimal delay.

Method: VoXtream uses a monotonic alignment scheme and dynamic look-ahead to map incoming phonemes to audio tokens. It is built around an incremental phoneme transformer, a temporal transformer predicting semantic and duration tokens, and a depth transformer producing acoustic tokens.

Result: VoXtream achieves an initial delay of 102 ms on GPU and performs well despite being trained on a mid-scale 9k-hour corpus.

Conclusion: VoXtream achieves the lowest initial delay among publicly available streaming TTS and matches or surpasses larger baselines on several metrics.

Abstract: We present VoXtream, a fully autoregressive, zero-shot streaming
text-to-speech (TTS) system for real-time use that begins speaking from the
first word. VoXtream directly maps incoming phonemes to audio tokens using a
monotonic alignment scheme and a dynamic look-ahead that does not delay onset.
Built around an incremental phoneme transformer, a temporal transformer
predicting semantic and duration tokens, and a depth transformer producing
acoustic tokens, VoXtream achieves, to our knowledge, the lowest initial delay
among publicly available streaming TTS: 102 ms on GPU. Despite being trained on
a mid-scale 9k-hour corpus, it matches or surpasses larger baselines on several
metrics, while delivering competitive quality in both output- and
full-streaming settings. Demo and code are available at
https://herimor.github.io/voxtream.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [65] [EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol](https://arxiv.org/abs/2509.15957)
*Kanato Masayoshi,Masahiro Hashimoto,Ryoichi Yokoyama,Naoki Toda,Yoshifumi Uwamino,Shogo Fukuda,Ho Namkoong,Masahiro Jinzaki*

Main category: cs.AI

TL;DR: 研究评估了通过MCP连接到EHR数据库的LLM在真实医院环境中自主检索临床相关信息的能力。结果显示，LLM在简单任务中表现接近完美，但在需要时间依赖计算的复杂任务中表现较差。EHR-MCP提供了一种安全、一致的数据访问基础设施，未来应扩展至推理、生成和临床影响评估。


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) show promise in medicine, but their deployment in hospitals is limited by restricted access to electronic health record (EHR) systems. The Model Context Protocol (MCP) enables integration between LLMs and external tools.

Method: We developed EHR-MCP, a framework of custom MCP tools integrated with the hospital EHR database, and used GPT-4.1 through a LangGraph ReAct agent to interact with it. Six tasks were tested, derived from use cases of the infection control team (ICT). Eight patients discussed at ICT conferences were retrospectively analyzed. Agreement with physician-generated gold standards was measured.

Result: The LLM consistently selected and executed the correct MCP tools. Except for two tasks, all tasks achieved near-perfect accuracy. Performance was lower in the complex task requiring time-dependent calculations. Most errors arose from incorrect arguments or misinterpretation of tool results. Responses from EHR-MCP were reliable, though long and repetitive data risked exceeding the context window.

Conclusion: LLMs can retrieve clinical data from an EHR via MCP tools in a real hospital setting, achieving near-perfect performance in simple tasks while highlighting challenges in complex ones. EHR-MCP provides an infrastructure for secure, consistent data access and may serve as a foundation for hospital AI agents. Future work should extend beyond retrieval to reasoning, generation, and clinical impact assessment, paving the way for effective integration of generative AI into clinical practice.

Abstract: Background: Large language models (LLMs) show promise in medicine, but their
deployment in hospitals is limited by restricted access to electronic health
record (EHR) systems. The Model Context Protocol (MCP) enables integration
between LLMs and external tools.
  Objective: To evaluate whether an LLM connected to an EHR database via MCP
can autonomously retrieve clinically relevant information in a real hospital
setting.
  Methods: We developed EHR-MCP, a framework of custom MCP tools integrated
with the hospital EHR database, and used GPT-4.1 through a LangGraph ReAct
agent to interact with it. Six tasks were tested, derived from use cases of the
infection control team (ICT). Eight patients discussed at ICT conferences were
retrospectively analyzed. Agreement with physician-generated gold standards was
measured.
  Results: The LLM consistently selected and executed the correct MCP tools.
Except for two tasks, all tasks achieved near-perfect accuracy. Performance was
lower in the complex task requiring time-dependent calculations. Most errors
arose from incorrect arguments or misinterpretation of tool results. Responses
from EHR-MCP were reliable, though long and repetitive data risked exceeding
the context window.
  Conclusions: LLMs can retrieve clinical data from an EHR via MCP tools in a
real hospital setting, achieving near-perfect performance in simple tasks while
highlighting challenges in complex ones. EHR-MCP provides an infrastructure for
secure, consistent data access and may serve as a foundation for hospital AI
agents. Future work should extend beyond retrieval to reasoning, generation,
and clinical impact assessment, paving the way for effective integration of
generative AI into clinical practice.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [66] [Fleming-R1: Toward Expert-Level Medical Reasoning via Reinforcement Learning](https://arxiv.org/abs/2509.15279)
*Chi Liu,Derek Li,Yan Shu,Robin Chen,Derek Duan,Teng Fang,Bryan Dai*

Main category: cs.LG

TL;DR: 本文介绍了Fleming-R1，一种通过三个互补创新实现可验证医学推理的模型，包括推理导向数据策略、思维链冷启动和基于可验证奖励的强化学习框架。实验结果显示，Fleming-R1在多个医学基准测试中表现出色，证明了其在临床推理方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在医学应用中显示出前景，但由于需要准确的答案和透明的推理过程，实现专家级的临床推理仍然具有挑战性。

Method: 引入Fleming-R1，一种通过三个互补创新实现可验证医学推理的模型。首先，我们的推理导向数据策略（RODS）结合了精心挑选的医学QA数据集和基于知识图的合成，以提高对未被充分代表的疾病、药物和多跳推理链的覆盖范围。其次，我们采用思维链（CoT）冷启动来蒸馏教师模型中的高质量推理轨迹，建立稳健的推理先验。第三，我们实施了一个两阶段的基于可验证奖励的强化学习（RLVR）框架，使用组相对策略优化，巩固核心推理技能，并通过自适应硬样本挖掘针对持续失败模式。

Result: 在各种医学基准测试中，Fleming-R1实现了显著的参数高效改进：7B变体超过了更大的基线，而32B模型与GPT-4o几乎达到一致，并且始终优于强大的开源替代方案。

Conclusion: 这些结果表明，结构化数据设计、以推理为导向的初始化和可验证的强化学习可以将临床推理推进到超越简单准确性优化的水平。我们公开发布Fleming-R1，以促进医疗AI中透明、可重复和可审计的进步，使在高风险临床环境中的安全部署成为可能。

Abstract: While large language models show promise in medical applications, achieving
expert-level clinical reasoning remains challenging due to the need for both
accurate answers and transparent reasoning processes. To address this
challenge, we introduce Fleming-R1, a model designed for verifiable medical
reasoning through three complementary innovations. First, our
Reasoning-Oriented Data Strategy (RODS) combines curated medical QA datasets
with knowledge-graph-guided synthesis to improve coverage of underrepresented
diseases, drugs, and multi-hop reasoning chains. Second, we employ
Chain-of-Thought (CoT) cold start to distill high-quality reasoning
trajectories from teacher models, establishing robust inference priors. Third,
we implement a two-stage Reinforcement Learning from Verifiable Rewards (RLVR)
framework using Group Relative Policy Optimization, which consolidates core
reasoning skills while targeting persistent failure modes through adaptive
hard-sample mining. Across diverse medical benchmarks, Fleming-R1 delivers
substantial parameter-efficient improvements: the 7B variant surpasses much
larger baselines, while the 32B model achieves near-parity with GPT-4o and
consistently outperforms strong open-source alternatives. These results
demonstrate that structured data design, reasoning-oriented initialization, and
verifiable reinforcement learning can advance clinical reasoning beyond simple
accuracy optimization. We release Fleming-R1 publicly to promote transparent,
reproducible, and auditable progress in medical AI, enabling safer deployment
in high-stakes clinical environments.

</details>


### [67] [Small LLMs with Expert Blocks Are Good Enough for Hyperparamter Tuning](https://arxiv.org/abs/2509.15561)
*Om Naphade,Saksham Bansal,Parikshit Pareek*

Main category: cs.LG

TL;DR: 本文提出了一种使用小型LLM进行超参数调优的专家块框架，通过轨迹上下文摘要器（TCS）实现可靠的优化进度分析，并在多个任务中表现出接近大型模型的性能。


<details>
  <summary>Details</summary>
Motivation: Hyper-parameter Tuning (HPT) 在机器学习（ML）流水线中是必要的步骤，但随着模型变大，变得计算昂贵且不透明。尽管最近探索了大型语言模型（LLMs）用于HPT，但大多数依赖于超过1000亿参数的模型。

Method: 我们提出了一个专家块框架用于HPT，核心是轨迹上下文摘要器（TCS），它将原始训练轨迹转换为结构化上下文，使小型LLM能够可靠地分析优化进度。

Result: 使用两个本地运行的LLM（phi4:reasoning14B和qwen2.5-coder:32B）和一个10次试验预算，我们的TCS增强的HPT管道在六个不同的任务中平均性能与GPT-4相差约0.9个百分点。

Conclusion: 我们的TCS增强的HPT管道在六个不同的任务中平均性能与GPT-4相差约0.9个百分点，证明了使用小型LLM进行HPT的有效性。

Abstract: Hyper-parameter Tuning (HPT) is a necessary step in machine learning (ML)
pipelines but becomes computationally expensive and opaque with larger models.
Recently, Large Language Models (LLMs) have been explored for HPT, yet most
rely on models exceeding 100 billion parameters. We propose an Expert Block
Framework for HPT using Small LLMs. At its core is the Trajectory Context
Summarizer (TCS), a deterministic block that transforms raw training
trajectories into structured context, enabling small LLMs to analyze
optimization progress with reliability comparable to larger models. Using two
locally-run LLMs (phi4:reasoning14B and qwen2.5-coder:32B) and a 10-trial
budget, our TCS-enabled HPT pipeline achieves average performance within ~0.9
percentage points of GPT-4 across six diverse tasks.

</details>


### [68] [KITE: Kernelized and Information Theoretic Exemplars for In-Context Learning](https://arxiv.org/abs/2509.15676)
*Vaibhav Singh,Soumya Suvra Ghosal,Kapu Nirmal Joshua,Soumyabrata Pal,Sayak Ray Chowdhury*

Main category: cs.LG

TL;DR: 本文从信息论角度研究了Icl中的示例选择问题，提出了一种新的方法，通过结构感知和多样化选择提升了性能。


<details>
  <summary>Details</summary>
Motivation: 由于LLM的上下文大小有限，如何选择示例以最大化性能是一个关键问题。传统的基于最近邻的方法在高维嵌入空间中存在泛化能力差和多样性不足的问题。

Method: 本文将LLM建模为输入嵌入上的线性函数，并将示例选择任务形式化为查询特定的优化问题，同时引入核技巧和最优设计正则化来增强方法。

Result: 实验证明，本文方法在一系列分类任务中显著优于标准检索方法，展示了结构感知和多样化示例选择的优势。

Conclusion: 本文提出了一种基于信息论的示例选择方法，通过结构感知和多样化的示例选择，显著提高了在现实世界、标签稀缺场景下的Icl性能。

Abstract: In-context learning (ICL) has emerged as a powerful paradigm for adapting
large language models (LLMs) to new and data-scarce tasks using only a few
carefully selected task-specific examples presented in the prompt. However,
given the limited context size of LLMs, a fundamental question arises: Which
examples should be selected to maximize performance on a given user query?
While nearest-neighbor-based methods like KATE have been widely adopted for
this purpose, they suffer from well-known drawbacks in high-dimensional
embedding spaces, including poor generalization and a lack of diversity. In
this work, we study this problem of example selection in ICL from a principled,
information theory-driven perspective. We first model an LLM as a linear
function over input embeddings and frame the example selection task as a
query-specific optimization problem: selecting a subset of exemplars from a
larger example bank that minimizes the prediction error on a specific query.
This formulation departs from traditional generalization-focused learning
theoretic approaches by targeting accurate prediction for a specific query
instance. We derive a principled surrogate objective that is approximately
submodular, enabling the use of a greedy algorithm with an approximation
guarantee. We further enhance our method by (i) incorporating the kernel trick
to operate in high-dimensional feature spaces without explicit mappings, and
(ii) introducing an optimal design-based regularizer to encourage diversity in
the selected examples. Empirically, we demonstrate significant improvements
over standard retrieval methods across a suite of classification tasks,
highlighting the benefits of structure-aware, diverse example selection for ICL
in real-world, label-scarce scenarios.

</details>


### [69] [EmoHeal: An End-to-End System for Personalized Therapeutic Music Retrieval from Fine-grained Emotions](https://arxiv.org/abs/2509.15986)
*Xinchen Wan,Jinhua Liang,Huan Zhang*

Main category: cs.LG

TL;DR: EmoHeal是一个端到端系统，提供个性化的三阶段支持叙述。它通过微调XLM-RoBERTa模型检测27种细粒度情绪，并利用基于音乐治疗原理的知识图谱将其映射到音乐参数。然后使用CLAMP3模型检索视听内容，引导用户从当前状态走向更平静的状态。实验结果显示了显著的情绪改善和高感知情绪识别准确性，证明了理论驱动的、情绪感知的数字健康工具的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有的数字心理健康工具往往忽视日常挑战背后的细微情感状态。例如，睡前焦虑影响全球超过15亿人，但目前的方法仍然主要是静态的，'一刀切'，无法适应个体需求。

Method: EmoHeal系统通过微调XLM-RoBERTa模型检测27种细粒度情绪，并利用基于音乐治疗原理的知识图谱（GEMS，iso-principle）将它们映射到音乐参数。然后使用CLAMP3模型检索视听内容，引导用户从当前状态走向更平静的状态（“match-guide-target”）。

Result: 一项针对40名参与者的被试内研究显示，参与者报告了显著的情绪改善（M=4.12，p<0.001）和高度的感知情绪识别准确性（M=4.05，p<0.001）。感知准确性和治疗结果之间存在强相关性（r=0.72，p<0.001），验证了我们的细粒度方法。

Conclusion: 这些发现证明了理论驱动的、情绪感知的数字健康工具的可行性，并为实现音乐治疗原则提供了可扩展的AI蓝图。

Abstract: Existing digital mental wellness tools often overlook the nuanced emotional
states underlying everyday challenges. For example, pre-sleep anxiety affects
more than 1.5 billion people worldwide, yet current approaches remain largely
static and "one-size-fits-all", failing to adapt to individual needs. In this
work, we present EmoHeal, an end-to-end system that delivers personalized,
three-stage supportive narratives. EmoHeal detects 27 fine-grained emotions
from user text with a fine-tuned XLM-RoBERTa model, mapping them to musical
parameters via a knowledge graph grounded in music therapy principles (GEMS,
iso-principle). EmoHeal retrieves audiovisual content using the CLAMP3 model to
guide users from their current state toward a calmer one
("match-guide-target"). A within-subjects study (N=40) demonstrated significant
supportive effects, with participants reporting substantial mood improvement
(M=4.12, p<0.001) and high perceived emotion recognition accuracy (M=4.05,
p<0.001). A strong correlation between perceived accuracy and therapeutic
outcome (r=0.72, p<0.001) validates our fine-grained approach. These findings
establish the viability of theory-driven, emotion-aware digital wellness tools
and provides a scalable AI blueprint for operationalizing music therapy
principles.

</details>


### [70] [SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection](https://arxiv.org/abs/2509.16060)
*Maithili Joshi,Palash Nandi,Tanmoy Chakraborty*

Main category: cs.LG

TL;DR: 研究发现大型语言模型的安全机制主要嵌入在中层到后期层中，并提出了一种新的白盒越狱方法SABER，该方法通过残差连接连接两个中间层，以实现对模型安全机制的绕过。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型经过了精心的对齐过程，但它们仍然容易受到越狱攻击，因此需要一种有效的方法来检测和防止这种攻击。

Method: 研究提出了一种名为SABER的新型白盒越狱方法，该方法通过残差连接连接两个中间层，以实现对LLMs安全机制的绕过。

Result: SABER在HarmBench测试集上比最佳基线方法提高了51%的性能，并且在HarmBench验证集上仅引起了一个微小的困惑度变化。

Conclusion: 研究发现，LLMs中的安全机制主要嵌入在中层到后期层中，并提出了一种新的白盒越狱方法SABER，该方法通过残差连接连接两个中间层，从而实现了对模型安全机制的绕过。

Abstract: Large Language Models (LLMs) with safe-alignment training are powerful
instruments with robust language comprehension capabilities. These models
typically undergo meticulous alignment procedures involving human feedback to
ensure the acceptance of safe inputs while rejecting harmful or unsafe ones.
However, despite their massive scale and alignment efforts, LLMs remain
vulnerable to jailbreak attacks, where malicious users manipulate the model to
produce harmful outputs that it was explicitly trained to avoid. In this study,
we find that the safety mechanisms in LLMs are predominantly embedded in the
middle-to-late layers. Building on this insight, we introduce a novel white-box
jailbreak method, SABER (Safety Alignment Bypass via Extra Residuals), which
connects two intermediate layers $s$ and $e$ such that $s < e$, through a
residual connection. Our approach achieves a 51% improvement over the
best-performing baseline on the HarmBench test set. Furthermore, SABER induces
only a marginal shift in perplexity when evaluated on the HarmBench validation
set. The source code is publicly available at
https://github.com/PalGitts/SABER.

</details>


### [71] [Latent learning: episodic memory complements parametric learning by enabling flexible reuse of experiences](https://arxiv.org/abs/2509.16189)
*Andrew Kyle Lampinen,Martin Engelcke,Yuxuan Li,Arslan Chaudhry,James L. McClelland*

Main category: cs.LG

TL;DR: 本文探讨了机器学习系统在泛化方面的不足，并提出通过情景记忆和检索机制来改善这一问题。


<details>
  <summary>Details</summary>
Motivation: 我们试图理解机器学习系统为何在泛化方面存在不足，并寻找可能的改进机制。

Method: 我们从认知科学中获得灵感，探讨了机器学习系统在泛化方面的失败原因，并提出了潜在的解决方案，如利用情景记忆和检索机制来提高泛化能力。

Result: 我们展示了检索机制如何帮助机器学习系统更灵活地利用学习经验，从而在多个挑战中更好地进行泛化。此外，我们还识别了有效使用检索的关键组件，包括在示例内的上下文学习的重要性。

Conclusion: 我们的结果说明了当前机器学习系统相对于自然智能的数据效率较低的一个可能原因，并有助于理解检索方法如何补充参数学习以提高泛化能力。

Abstract: When do machine learning systems fail to generalize, and what mechanisms
could improve their generalization? Here, we draw inspiration from cognitive
science to argue that one weakness of machine learning systems is their failure
to exhibit latent learning -- learning information that is not relevant to the
task at hand, but that might be useful in a future task. We show how this
perspective links failures ranging from the reversal curse in language modeling
to new findings on agent-based navigation. We then highlight how cognitive
science points to episodic memory as a potential part of the solution to these
issues. Correspondingly, we show that a system with an oracle retrieval
mechanism can use learning experiences more flexibly to generalize better
across many of these challenges. We also identify some of the essential
components for effectively using retrieval, including the importance of
within-example in-context learning for acquiring the ability to use information
across retrieved examples. In summary, our results illustrate one possible
contributor to the relative data inefficiency of current machine learning
systems compared to natural intelligence, and help to understand how retrieval
methods can complement parametric learning to improve generalization.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [72] [Efficient and Versatile Model for Multilingual Information Retrieval of Islamic Text: Development and Deployment in Real-World Scenarios](https://arxiv.org/abs/2509.15380)
*Vera Pavlova,Mohammed Makhlouf*

Main category: cs.IR

TL;DR: 本文研究了如何在伊斯兰领域开发一个能够满足用户多语言信息需求的即兴信息检索系统，并通过实验验证了混合训练方法的有效性，同时强调了部署单一轻量级模型的成本效益。


<details>
  <summary>Details</summary>
Motivation: 尽管在多语言信息检索（MLIR）方面取得了进展，但研究与实际部署之间仍存在显著差距。许多研究在孤立环境中评估MLIR性能，限制了其在现实场景中的适用性。

Method: 本文利用《古兰经》多语言语料库的特点，准备了十一种检索模型，采用了四种训练方法：单语、跨语言、翻译训练全部和一种结合跨语言和单语技术的新混合方法。

Result: 在领域内数据集上的评估表明，混合方法在各种检索场景中都取得了有希望的结果。此外，本文详细分析了不同训练配置如何影响嵌入空间及其对多语言检索效果的影响。

Conclusion: 本文讨论了在实际应用中部署多语言信息检索系统的重要性，并强调了使用单一、轻量级模型的高成本效益。

Abstract: Despite recent advancements in Multilingual Information Retrieval (MLIR), a
significant gap remains between research and practical deployment. Many studies
assess MLIR performance in isolated settings, limiting their applicability to
real-world scenarios. In this work, we leverage the unique characteristics of
the Quranic multilingual corpus to examine the optimal strategies to develop an
ad-hoc IR system for the Islamic domain that is designed to satisfy users'
information needs in multiple languages. We prepared eleven retrieval models
employing four training approaches: monolingual, cross-lingual,
translate-train-all, and a novel mixed method combining cross-lingual and
monolingual techniques. Evaluation on an in-domain dataset demonstrates that
the mixed approach achieves promising results across diverse retrieval
scenarios. Furthermore, we provide a detailed analysis of how different
training configurations affect the embedding space and their implications for
multilingual retrieval effectiveness. Finally, we discuss deployment
considerations, emphasizing the cost-efficiency of deploying a single
versatile, lightweight model for real-world MLIR applications.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [73] [SightSound-R1: Cross-Modal Reasoning Distillation from Vision to Audio Language Models](https://arxiv.org/abs/2509.15661)
*Qiaolin Wang,Xilin Jiang,Linyang He,Junkai Wu,Nima Mesgarani*

Main category: cs.SD

TL;DR: 本文提出了一种跨模态蒸馏框架SightSound-R1，通过将视觉推理转移到音频模型中，提高了音频语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大规模的链式思维音频数据来教授LALM逐步推理，因此在复杂声景中的推理能力仍然落后于LVLM。

Method: SightSound-R1，一个跨模态蒸馏框架，将更强的LVLM教师的高级推理转移到较弱的LALM学生上。

Result: SightSound-R1提高了LALM在域内AVQA测试集以及未见过的听觉场景和问题中的推理性能，优于预训练和仅标签蒸馏基线。

Conclusion: 视觉推理可以有效地转移到音频模型中，并且可以通过丰富的音视频数据进行扩展。

Abstract: While large audio-language models (LALMs) have demonstrated state-of-the-art
audio understanding, their reasoning capability in complex soundscapes still
falls behind large vision-language models (LVLMs). Compared to the visual
domain, one bottleneck is the lack of large-scale chain-of-thought audio data
to teach LALM stepwise reasoning. To circumvent this data and modality gap, we
present SightSound-R1, a cross-modal distillation framework that transfers
advanced reasoning from a stronger LVLM teacher to a weaker LALM student on the
same audio-visual question answering (AVQA) dataset. SightSound-R1 consists of
three core steps: (i) test-time scaling to generate audio-focused chains of
thought (CoT) from an LVLM teacher, (ii) audio-grounded validation to filter
hallucinations, and (iii) a distillation pipeline with supervised fine-tuning
(SFT) followed by Group Relative Policy Optimization (GRPO) for the LALM
student. Results show that SightSound-R1 improves LALM reasoning performance
both in the in-domain AVQA test set as well as in unseen auditory scenes and
questions, outperforming both pretrained and label-only distilled baselines.
Thus, we conclude that vision reasoning can be effectively transferred to audio
models and scaled with abundant audio-visual data.

</details>


### [74] [Direct Simultaneous Translation Activation for Large Audio-Language Models](https://arxiv.org/abs/2509.15692)
*Pei Zhang,Yiming Wang,Jialong Tang,Baosong Yang,Rui Wang,Derek F. Wong,Fei Huang*

Main category: cs.SD

TL;DR: 本文提出了一种名为SimulSA的策略，利用大型音频语言模型的内在能力来获得同时数据，并通过将其纳入离线SFT数据中，有效弥合了预训练期间离线翻译和推理期间同时翻译之间的分布差距。实验结果表明，仅增强约1%的同时数据就可以显著激活LALMs的Simul-S2TT能力，而无需修改模型架构或解码策略。


<details>
  <summary>Details</summary>
Motivation: 随着大型音频语言模型（LALMs）的兴起，关键挑战是如何在不进行额外架构更改的情况下直接激活基础模型的Simul-S2TT功能。

Method: 本文引入了SimulSA策略，利用LALMs的内在能力通过随机截断语音和构建部分对齐翻译来获得同时数据。

Result: 实验结果表明，增强约1%的同时数据可以显著激活LALMs的Simul-S2TT能力，而无需修改模型架构或解码策略。

Conclusion: 实验结果表明，仅增强约1%的同时数据就可以显著激活LALMs的Simul-S2TT能力，而无需修改模型架构或解码策略。

Abstract: Simultaneous speech-to-text translation (Simul-S2TT) aims to translate speech
into target text in real time, outputting translations while receiving source
speech input, rather than waiting for the entire utterance to be spoken.
Simul-S2TT research often modifies model architectures to implement read-write
strategies. However, with the rise of large audio-language models (LALMs), a
key challenge is how to directly activate Simul-S2TT capabilities in base
models without additional architectural changes. In this paper, we introduce
{\bf Simul}taneous {\bf S}elf-{\bf A}ugmentation ({\bf SimulSA}), a strategy
that utilizes LALMs' inherent capabilities to obtain simultaneous data by
randomly truncating speech and constructing partially aligned translation. By
incorporating them into offline SFT data, SimulSA effectively bridges the
distribution gap between offline translation during pretraining and
simultaneous translation during inference. Experimental results demonstrate
that augmenting only about {\bf 1\%} of the simultaneous data, compared to the
full offline SFT data, can significantly activate LALMs' Simul-S2TT
capabilities without modifications to model architecture or decoding strategy.

</details>
