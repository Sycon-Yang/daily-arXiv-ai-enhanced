<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 36]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.CC](#cs.CC) [Total: 1]
- [cs.CV](#cs.CV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.SE](#cs.SE) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models](https://arxiv.org/abs/2507.12547)
*Lionel Wong,Katherine M. Collins,Lance Ying,Cedegao E. Zhang,Adrian Weller,Tobias Gersternberg,Timothy O'Donnell,Alexander K. Lew,Jacob D. Andreas,Joshua B. Tenenbaum,Tyler Brooke-Wilson*

Main category: cs.CL

TL;DR: 本文提出了一种名为“模型合成架构”（MSA）的计算模型，利用语言模型和概率程序来模拟人类在新情境下的推理能力。实验表明，MSA在捕捉人类判断方面优于仅使用语言模型的基线。


<details>
  <summary>Details</summary>
Motivation: 当面对新情况时，人们能够从广泛的背景知识中调动相关考虑因素，并将这些用于推断和预测。是什么让我们能够在全球相关的信息上进行推理？

Method: 我们提出了一个计算实现，即“模型合成架构”（MSA），使用语言模型来实现基于全局相关性的检索和模型合成，以及概率程序来实现定制的、连贯的世界模型。

Result: 我们的MSA方法比仅使用语言模型的基线更好地捕捉了人类判断，在支持模型合成的语言模型的直接和链式思维生成中都表现更好。

Conclusion: 这些结果表明，MSA可以以一种模仿人类在开放领域中提供局部连贯推理的方式实现，为理解和复制人类推理提供了一条路径。

Abstract: When faced with novel situations, people are able to marshal relevant
considerations from a wide range of background knowledge and put these to use
in inferences and predictions. What permits us to draw in globally relevant
information and reason over it coherently? Here, we explore the hypothesis that
people use a combination of distributed and symbolic representations to
construct bespoke mental models tailored to novel situations. We propose a
computational implementation of this idea -- a ``Model Synthesis Architecture''
(MSA) -- using language models to implement global relevance-based retrieval
and model synthesis and probabilistic programs to implement bespoke, coherent
world models. We evaluate our MSA as a model of human judgments on a novel
reasoning dataset. The dataset -- built around a `Model Olympics` domain of
sports vignettes -- tests models' capacity for human-like, open-ended reasoning
by requiring (i) judgments about novel causal structures described in language;
(ii) drawing on large bodies of background knowledge; and (iii) doing both in
light of observations that introduce arbitrary novel variables. Our MSA
approach captures human judgments better than language model-only baselines,
under both direct and chain-of-thought generations from the LM that supports
model synthesis. These results suggest that MSAs can be implemented in a way
that mirrors people's ability to deliver locally coherent reasoning over
globally relevant variables, offering a path to understanding and replicating
human reasoning in open-ended domains.

</details>


### [2] [Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility](https://arxiv.org/abs/2507.12553)
*Michael A. Lepori,Jennifer Hu,Ishita Dasgupta,Roma Patel,Thomas Serre,Ellie Pavlick*

Main category: cs.CL

TL;DR: 本文通过机制解释技术，发现语言模型能够可靠地进行模态分类，并且模态差异向量可以用来建模人类的分类行为。


<details>
  <summary>Details</summary>
Motivation: 语言模型需要能够辨别句子的模态类别，但最近的研究质疑了语言模型对模态分类的能力。本文旨在探索语言模型是否能够可靠地进行模态分类，并研究其与人类分类行为的关系。

Method: 本文识别了线性表示，这些表示可以在各种语言模型中区分模态类别，称为模态差异向量。分析模态差异向量揭示了语言模型比之前报告的更可靠的模态分类判断。此外，发现模态差异向量在模型变得更熟练时以一致的顺序出现。最后，发现语言模型激活中的模态差异向量可以用来建模精细的人类分类行为。

Result: 分析表明，语言模型具有比之前报告的更可靠的模态分类判断。模态差异向量在模型变得更熟练时以一致的顺序出现。此外，模态差异向量可以用来建模精细的人类分类行为。

Conclusion: 本文通过机制解释技术，得出了关于语言模型模态分类的新见解，这可能有助于我们理解人类的模态分类。

Abstract: Language models (LMs) are used for a diverse range of tasks, from question
answering to writing fantastical stories. In order to reliably accomplish these
tasks, LMs must be able to discern the modal category of a sentence (i.e.,
whether it describes something that is possible, impossible, completely
nonsensical, etc.). However, recent studies have called into question the
ability of LMs to categorize sentences according to modality (Michaelov et al.,
2025; Kauf et al., 2023). In this work, we identify linear representations that
discriminate between modal categories within a variety of LMs, or modal
difference vectors. Analysis of modal difference vectors reveals that LMs have
access to more reliable modal categorization judgments than previously
reported. Furthermore, we find that modal difference vectors emerge in a
consistent order as models become more competent (i.e., through training steps,
layers, and parameter count). Notably, we find that modal difference vectors
identified within LM activations can be used to model fine-grained human
categorization behavior. This potentially provides a novel view into how human
participants distinguish between modal categories, which we explore by
correlating projections along modal difference vectors with human participants'
ratings of interpretable features. In summary, we derive new insights into LM
modal categorization using techniques from mechanistic interpretability, with
the potential to inform our understanding of modal categorization in humans.

</details>


### [3] [The first open machine translation system for the Chechen language](https://arxiv.org/abs/2507.12672)
*Abu-Viskhan A. Umishov,Vladislav A. Grigorian*

Main category: cs.CL

TL;DR: 本文介绍了第一个用于车臣语和俄语之间翻译的开源模型，并收集了用于训练和评估该模型的数据集。


<details>
  <summary>Details</summary>
Motivation: 为了实现车臣语和俄语之间的翻译，需要一个开放源代码模型和相关数据集。

Method: 本文探索了将新语言纳入多语言翻译NLLB-200大型语言模型系统的微调能力。

Result: 我们的模型在俄语到车臣语和反向翻译中的BLEU / ChrF++得分分别为8.34 / 34.69和20.89 / 44.55。

Conclusion: 本文介绍了第一个用于车臣语和俄语之间翻译的开源模型，并收集了用于训练和评估该模型的数据集。

Abstract: We introduce the first open-source model for translation between the
vulnerable Chechen language and Russian, and the dataset collected to train and
evaluate it. We explore fine-tuning capabilities for including a new language
into a large language model system for multilingual translation NLLB-200. The
BLEU / ChrF++ scores for our model are 8.34 / 34.69 and 20.89 / 44.55 for
translation from Russian to Chechen and reverse direction, respectively. The
release of the translation models is accompanied by the distribution of
parallel words, phrases and sentences corpora and multilingual sentence encoder
adapted to the Chechen language.

</details>


### [4] [Improving Drug Identification in Overdose Death Surveillance using Large Language Models](https://arxiv.org/abs/2507.12679)
*Arthur J. Funnell,Panayiotis Petousis,Fabrice Harel-Canada,Ruby Romero,Alex A. T. Bui,Adam Koncsol,Hritika Chaturvedi,Chelsea Shover,David Goodman-Meza*

Main category: cs.CL

TL;DR: 本研究探讨了使用自然语言处理（NLP）模型，特别是经过微调的临床变体如BioClinicalBERT，来自动分类过量用药死亡报告中的药物参与情况。结果表明，这些模型在内部测试集上表现出接近完美的性能，并在外部验证中保持稳健，优于传统机器学习方法和各种解码器仅大型语言模型。NLP模型为从自由文本报告中进行过量用药死亡分类提供了高度准确且可扩展的解决方案，可以显著加速监测工作流程，克服手动ICD-10编码的局限性，并支持近实时检测新兴物质使用趋势。


<details>
  <summary>Details</summary>
Motivation: The rising rate of drug-related deaths in the United States, largely driven by fentanyl, requires timely and accurate surveillance. However, critical overdose data are often buried in free-text coroner reports, leading to delays and information loss when coded into ICD (International Classification of Disease)-10 classifications.

Method: Multiple NLP approaches were evaluated for classifying specific drug involvement from unstructured death certificate text. These included traditional single- and multi-label classifiers, as well as fine-tuned encoder-only language models such as BERT and BioClinicalBERT, and contemporary decoder-only large language models such as Qwen 3 and Llama 3.

Result: Fine-tuned BioClinicalBERT models achieved near-perfect performance, with macro F1 scores >=0.998 on the internal test set. External validation confirmed robustness (macro F1=0.966), outperforming conventional machine learning, general-domain BERT models, and various decoder-only large language models.

Conclusion: NLP models, particularly fine-tuned clinical variants like BioClinicalBERT, offer a highly accurate and scalable solution for overdose death classification from free-text reports. These methods can significantly accelerate surveillance workflows, overcoming the limitations of manual ICD-10 coding and supporting near real-time detection of emerging substance use trends.

Abstract: The rising rate of drug-related deaths in the United States, largely driven
by fentanyl, requires timely and accurate surveillance. However, critical
overdose data are often buried in free-text coroner reports, leading to delays
and information loss when coded into ICD (International Classification of
Disease)-10 classifications. Natural language processing (NLP) models may
automate and enhance overdose surveillance, but prior applications have been
limited. A dataset of 35,433 death records from multiple U.S. jurisdictions in
2020 was used for model training and internal testing. External validation was
conducted using a novel separate dataset of 3,335 records from 2023-2024.
Multiple NLP approaches were evaluated for classifying specific drug
involvement from unstructured death certificate text. These included
traditional single- and multi-label classifiers, as well as fine-tuned
encoder-only language models such as Bidirectional Encoder Representations from
Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large
language models such as Qwen 3 and Llama 3. Model performance was assessed
using macro-averaged F1 scores, and 95% confidence intervals were calculated to
quantify uncertainty. Fine-tuned BioClinicalBERT models achieved near-perfect
performance, with macro F1 scores >=0.998 on the internal test set. External
validation confirmed robustness (macro F1=0.966), outperforming conventional
machine learning, general-domain BERT models, and various decoder-only large
language models. NLP models, particularly fine-tuned clinical variants like
BioClinicalBERT, offer a highly accurate and scalable solution for overdose
death classification from free-text reports. These methods can significantly
accelerate surveillance workflows, overcoming the limitations of manual ICD-10
coding and supporting near real-time detection of emerging substance use
trends.

</details>


### [5] [AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.12695)
*S M Rafiuddin,Sadia Kamal,Mohammed Rakib,Arunkumar Bagavathi,Atriya Sen*

Main category: cs.CL

TL;DR: AdaptiSent is a new framework for Multimodal Aspect-Based Sentiment Analysis that improves sentiment classification and aspect term extraction using adaptive cross-modal attention mechanisms.


<details>
  <summary>Details</summary>
Motivation: The paper aims to improve sentiment classification and aspect term extraction from multimodal data by focusing on how textual cues and visual context interact.

Method: AdaptiSent uses adaptive cross-modal attention mechanisms, dynamic modality weighting, and context-adaptive attention to improve sentiment classification and aspect term extraction from both text and images.

Result: AdaptiSent surpasses existing models in precision, recall, and F1 score, particularly in identifying nuanced inter-modal relationships crucial for accurate sentiment and aspect term extraction.

Conclusion: AdaptiSent sets a new standard for MABSA, significantly outperforming current methods, especially in understanding complex multimodal information.

Abstract: We introduce AdaptiSent, a new framework for Multimodal Aspect-Based
Sentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms
to improve sentiment classification and aspect term extraction from both text
and images. Our model integrates dynamic modality weighting and
context-adaptive attention, enhancing the extraction of sentiment and
aspect-related information by focusing on how textual cues and visual context
interact. We tested our approach against several baselines, including
traditional text-based models and other multimodal methods. Results from
standard Twitter datasets show that AdaptiSent surpasses existing models in
precision, recall, and F1 score, and is particularly effective in identifying
nuanced inter-modal relationships that are crucial for accurate sentiment and
aspect term extraction. This effectiveness comes from the model's ability to
adjust its focus dynamically based on the context's relevance, improving the
depth and accuracy of sentiment analysis across various multimodal data sets.
AdaptiSent sets a new standard for MABSA, significantly outperforming current
methods, especially in understanding complex multimodal information.

</details>


### [6] [AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation](https://arxiv.org/abs/2507.12705)
*Potsawee Manakul,Woody Haosheng Gan,Michael J. Ryan,Ali Sartaz Khan,Warit Sirichotedumrong,Kunat Pipatanakul,William Held,Diyi Yang*

Main category: cs.CL

TL;DR: 本文提出了一种基于大型音频模型的统一评估框架AudioJudge，用于解决当前语音评估中的两个关键问题。通过多方面集成的AudioJudge，实现了对语音评估的通用性，并在系统排名基准上达到了与人类偏好高度相关的性能。然而，LAM在声学噪声下表现出较强的鲁棒性，但存在显著的冗长性和位置偏差，需要仔细缓解。


<details>
  <summary>Details</summary>
Motivation: 当前语音评估面临两个关键限制：需要设计针对特定音频特征的专用系统，以及自动评估方法与人类偏好之间的相关性较差。本文旨在提出一种统一的评估框架，以解决这些问题。

Method: 本文系统地研究了AudioJudge在音频特征检测任务（包括发音、语速、说话人识别和语音质量）以及系统级人类偏好模拟方面的表现。探索了不同的提示工程策略，发现音频拼接结合上下文学习显著提高了性能。进一步引入了多方面集成的AudioJudge，将语音评估分解为专门的判断者，分别处理词汇内容、语音质量和副语言特征。

Result: AudioJudge在音频特征检测和人类偏好模拟任务中表现出色，特别是在使用音频拼接结合上下文学习时性能显著提升。多方面集成的AudioJudge在系统排名基准上实现了高达0.91的Spearman相关性，与人类偏好高度一致。然而，LAM在声学噪声下表现出较强的鲁棒性，但存在显著的冗长性和位置偏差。

Conclusion: 本文提出了一种基于大型音频模型（LAM）的统一评估框架AudioJudge，能够解决当前语音评估中的两个关键问题。通过多方面集成的AudioJudge，实现了对语音评估的通用性，并在系统排名基准上达到了与人类偏好高度相关的性能。然而，LAM在声学噪声下表现出较强的鲁棒性，但存在显著的冗长性和位置偏差，需要仔细缓解。

Abstract: Current speech evaluation suffers from two critical limitations: the need and
difficulty of designing specialized systems targeting individual audio
characteristics, and poor correlation between automatic evaluation methods and
human preferences. This work presents a systematic study of Large Audio Model
(LAM) as a Judge, AudioJudge, investigating whether it can provide a unified
evaluation framework that addresses both challenges. We systematically explore
AudioJudge across audio characteristic detection tasks, including
pronunciation, speaking rate, speaker identification and speech quality, and
system-level human preference simulation for automated benchmarking. We
investigate different prompt engineering strategies, finding that audio
concatenation combined with in-context learning significantly improves
performance across both audio characteristic detection and human preference
simulation tasks. We further introduce a multi-aspect ensemble AudioJudge to
enable general-purpose multi-aspect audio evaluation. This method decomposes
speech assessment into specialized judges for lexical content, speech quality,
and paralinguistic features, achieving up to 0.91 Spearman correlation with
human preferences on our system ranking benchmark. Robustness analysis reveals
that while LAMs maintain strong performance under acoustic noise, they exhibit
significant verbosity and positional biases that require careful mitigation.

</details>


### [7] [FLEXITOKENS: Flexible Tokenization for Evolving Language Models](https://arxiv.org/abs/2507.12720)
*Abraham Toluase Owodunni,Orevaoghene Ahia,Sachin Kumar*

Main category: cs.CL

TL;DR: 本文提出了一种新的分词方法FLEXITOKENS，通过引入可学习的分词器，提高了语言模型在适应新数据分布时的灵活性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的分词器在适应过程中缺乏灵活性，导致在分布外领域、未见过的语言或脚本中出现效率低下的分词问题。

Method: 开发了具有可学习分词器的字节级语言模型，引入了一个子模块来学习预测输入字节序列之间的边界，编码为可变长度的段。提出了FLEXITOKENS，一种简化的训练目标，以在适应过程中实现更大的灵活性。

Result: 在多个多语言基准、形态多样任务和领域中评估，FLEXITOKENS能够一致地减少token过碎片化，并在下游任务性能上取得显著提升。

Conclusion: FLEXITOKENS能够显著减少token过碎片化，并在下游任务性能上相比subword和其他基于梯度的tokenizer有高达10%的提升。

Abstract: Language models (LMs) are challenging to adapt to new data distributions by
simple finetuning. This is due to the rigidity of their subword tokenizers,
which typically remain unchanged during adaptation. This inflexibility often
leads to inefficient tokenization, causing overfragmentation of
out-of-distribution domains, unseen languages, or scripts. In this work, we
develop byte-level LMs with learnable tokenizers to make tokenization adaptive.
Our models include a submodule that learns to predict boundaries between the
input byte sequence, encoding it into variable-length segments. Existing
tokenizer-free methods train this boundary predictor using an auxiliary loss
that enforces a fixed compression rate across the training corpus, introducing
a new kind of rigidity. We propose FLEXITOKENS, a simplified training objective
that enables significantly greater flexibility during adaptation. Evaluating
across multiple multilingual benchmarks, morphologically diverse tasks, and
domains, we demonstrate that FLEXITOKENS consistently reduces token
over-fragmentation and achieves up to 10\% improvements on downstream task
performance compared to subword and other gradient-based tokenizers. Code and
data for our experiments will be released at
https://github.com/owos/flexitokens

</details>


### [8] [TransEvalnia: Reasoning-based Evaluation and Ranking of Translations](https://arxiv.org/abs/2507.12724)
*Richard Sproat,Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: TransEvalnia是一种基于提示的翻译评估和排名系统，能够提供细粒度评估并返回最佳翻译。它在多个语言对上表现优异，并且其评估结果得到人类评分者的认可。


<details>
  <summary>Details</summary>
Motivation: 现有的翻译评估系统可能无法全面反映翻译质量，因此需要一种更精确、更细致的评估方法。

Method: TransEvalnia是一种基于提示的翻译评估和排名系统，利用推理进行评估和排名。它基于Multidimensional Quality Metrics的一个子集提供细粒度评估，并返回最佳翻译的评估结果以及各个维度和整体翻译的数值分数。

Result: TransEvalnia在英语-日语数据以及多个WMT共享任务的语言对上表现与或优于MT-Ranker。使用Claude-3.5-Sonnet和Qwen-2.5-72B-Instruct作为评估LLM，结果显示其评估结果被人类评分者高度认可，且分数与人类评分者给出的分数相关性良好。

Conclusion: TransEvalnia在翻译评估和排名方面表现出色，甚至优于最先进的MT-Ranker系统，并且其评估结果得到了人类评分者的高度认可。此外，该系统还展示了对位置偏差的敏感性，并提出了相应的解决方法。

Abstract: We present TransEvalnia, a prompting-based translation evaluation and ranking
system that uses reasoning in performing its evaluations and ranking. This
system presents fine-grained evaluations based on a subset of the
Multidimensional Quality Metrics (https://themqm.org/), returns an assessment
of which translation it deems the best, and provides numerical scores for the
various dimensions and for the overall translation. We show that TransEvalnia
performs as well as or better than the state-of-the-art MT-Ranker (Moosa et al.
2024) on our own English-Japanese data as well as several language pairs from
various WMT shared tasks. Using Anthropic's Claude-3.5-Sonnet and
Qwen-2.5-72B-Instruct as the evaluation LLMs, we show that the evaluations
returned are deemed highly acceptable to human raters, and that the scores
assigned to the translations by Sonnet, as well as other LLMs, correlate well
with scores assigned by the human raters. We also note the sensitivity of our
system -- as well as MT-Ranker -- to the order in which the translations are
presented, and we propose methods to address this position bias. All data,
including the system's evaluation and reasoning, human assessments, as well as
code is released.

</details>


### [9] [Strategy Adaptation in Large Language Model Werewolf Agents](https://arxiv.org/abs/2507.12732)
*Fuya Nakamori,Yin Jou Huang,Fei Cheng*

Main category: cs.CL

TL;DR: 本研究提出了一种基于游戏背景和玩家角色估计的策略切换方法，以提高狼人杀代理人的性能，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 先前的狼人杀代理人研究使用提示工程，采用有效策略隐式定义的方法，但无法适应变化的情况。

Method: 本研究提出了一种显式选择适当策略的方法，基于游戏背景和对其他玩家角色的估计。

Result: 比较了策略适应性狼人杀代理人与使用隐式或固定策略的基线代理人，并验证了所提出方法的有效性。

Conclusion: 本研究提出了一种方法，通过根据其他玩家的态度和对话背景在预定义策略之间切换来提高狼人杀代理人的性能。

Abstract: This study proposes a method to improve the performance of Werewolf agents by
switching between predefined strategies based on the attitudes of other players
and the context of conversations. While prior works of Werewolf agents using
prompt engineering have employed methods where effective strategies are
implicitly defined, they cannot adapt to changing situations. In this research,
we propose a method that explicitly selects an appropriate strategy based on
the game context and the estimated roles of other players. We compare the
strategy adaptation Werewolf agents with baseline agents using implicit or
fixed strategies and verify the effectiveness of our proposed method.

</details>


### [10] [Logit Arithmetic Elicits Long Reasoning Capabilities Without Training](https://arxiv.org/abs/2507.12759)
*Yunxiang Zhang,Muhammad Khalifa,Lechen Zhang,Xin Liu,Ayoung Lee,Xinliang Frederick Zhang,Farima Fatahi Bayat,Lu Wang*

Main category: cs.CL

TL;DR: 本文介绍了一种无需额外训练即可激发大型语言模型长推理能力的方法，名为ThinkLogit及其改进版本ThinkLogit-DPO，并展示了其在多个数学数据集上的显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 最近的研究表明，一些模型本质上具有这些长期推理能力，这可能通过额外训练来解锁。我们的工作首先调查是否可以在没有任何训练的情况下激发这种行为。

Method: 我们提出了一个解码时间方法，ThinkLogit，它使用logits算术来调整目标大LM，使其进行长推理。此外，我们还通过在正确/错误推理对上进行偏好优化来进一步提升性能，这种方法称为ThinkLogit-DPO。

Result: 实验表明，ThinkLogit和ThinkLogit-DPO分别在四个数学数据集上相对于Qwen2.5-32B提高了26%和29%的pass@1。此外，ThinkLogit可以转移通过强化学习获得的长期推理技能，相比Qwen2.5-32B基础模型提高了13%的pass@1。

Conclusion: 我们的工作提出了一种计算效率高的方法，在不需要额外训练的情况下激发大型模型的长推理能力。

Abstract: Large reasoning models (LRMs) can do complex reasoning via long
chain-of-thought (CoT) involving cognitive strategies such as backtracking and
self-correction. Recent studies suggest that some models inherently possess
these long reasoning abilities, which may be unlocked via extra training. Our
work first investigates whether we can elicit such behavior without any
training. To this end, we propose a decoding-time approach, ThinkLogit, which
utilizes logits arithmetic (Liu et al., 2024) to tune a target large LM for
long reasoning using a substantially smaller model as guider. We then show that
we can further boost performance by training the guider model with preference
optimization over correct/incorrect reasoning pairs sampled from both the
target and guider model -- a setup we refer to as ThinkLogit-DPO. Our
experiments demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative
improvement in pass@1 by 26% and 29%, respectively, over four mathematical
datasets using the Qwen2.5-32B when guided by R1-Distill-Qwen-1.5B -- a model
21x smaller. Lastly, we show that ThinkLogit can transfer long reasoning skills
acquired through reinforcement learning, improving pass@1 by 13% relative
compared to the Qwen2.5-32B base model. Our work presents a
computationally-efficient method to elicit long reasoning in large models with
minimal or no additional training.

</details>


### [11] [Synergy: End-to-end Concept Model](https://arxiv.org/abs/2507.12769)
*Keli Zheng,Zerong Xie*

Main category: cs.CL

TL;DR: Synergy是一种通过学习路由机制在端到端方式下桥接不同抽象层次的语言模型，它在字节级别上进行训练，表现出优于Llama3的性能，并展示了无需分词器架构的可行性。


<details>
  <summary>Details</summary>
Motivation: 为了在不同抽象层次上实现更高效和灵活的处理，我们提出了Synergy模型。

Method: 我们通过一种学习的路由机制，在端到端的方式下桥接不同抽象层次，训练模型作为字节级语言模型。

Result: 我们的模型在相同模型规模和训练数据集大小下优于Llama3，并且在移除位置编码后，中间部分表现更好，表明出现了与位置无关的概念。

Conclusion: 这些发现展示了无需分词器架构的可行性，为更稳健和灵活的流程铺平了道路。

Abstract: In this paper, we present Synergy, a language model that bridges different
levels of abstraction in an end-to-end fashion through a learned routing
mechanism. Focusing on low-level linguistic abstraction, we trained our model
as a byte-level language model. Our model spontaneously learns to tokenize
bytes, producing fewer concept tokens than Byte-level Byte Pair Encoder (BBPE)
tokenizers while keeping comparable performance. By comparing with Llama3, we
observed an advantage of Synergy under the same model scale and training
dataset size. Further studies show that the middle part (the higher abstraction
part) of our model performs better when positional encodings are removed,
suggesting the emergence of position-independent concepts. These findings
demonstrate the feasibility of tokenizer-free architectures, paving the way for
more robust and flexible pipelines.

</details>


### [12] [Learning Robust Negation Text Representations](https://arxiv.org/abs/2507.12782)
*Thinh Hung Truong,Karin Verspoor,Trevor Cohn,Timothy Baldwin*

Main category: cs.CL

TL;DR: 本文提出了一种通过从大型语言模型中蒸馏数据来提高文本编码器否定鲁棒性的策略，并展示了该方法在保持一般性能的同时显著提升了否定理解能力，同时还可以适应大型语言模型以进一步提高性能。


<details>
  <summary>Details</summary>
Motivation: 尽管自回归大型语言模型得到了快速采用，但较小的文本编码器在需要丰富上下文表示的文本理解任务中仍然发挥着重要作用。否定是一个重要的语义功能，目前仍未被这些方法正确捕捉，影响了许多依赖文本嵌入的下游应用。

Method: 我们提出了一种策略，通过使用多样化的否定和回避模式从大型语言模型中蒸馏数据，以提高文本编码器的否定鲁棒性。我们采用标准的对比学习策略来微调一个基于BERT的强模型。

Result: 我们观察到在保持一般基准测试中的竞争力的同时，否定理解能力有了显著提升。此外，我们的方法还可以适应大型语言模型，从而在否定基准测试中取得更好的性能。

Conclusion: 我们的方法可以提高文本编码器对否定的理解能力，并且可以在大型语言模型上进行适应，从而在否定基准测试中取得更好的性能。

Abstract: Despite rapid adoption of autoregressive large language models, smaller text
encoders still play an important role in text understanding tasks that require
rich contextualized representations. Negation is an important semantic function
that is still not properly captured by such methods, affecting many downstream
applications relying on text embeddings. We propose a strategy to improve
negation robustness of text encoders, by distilling data from large language
models using diverse patterns of negation and hedging. We adopt a standard
contrastive learning strategy to finetune a strong BERT-based model, and
observe large improvement in negation understanding capabilities while
maintaining competitive performance on general benchmarks. In addition, we also
show that our method can be adapted to LLMs, leading to improved performance on
negation benchmarks.

</details>


### [13] [Large Language Models' Internal Perception of Symbolic Music](https://arxiv.org/abs/2507.12808)
*Andrew Shin,Kunitake Kaneko*

Main category: cs.CL

TL;DR: This paper explores how large language models (LLMs) represent musical concepts by generating symbolic music data from textual prompts and evaluating their performance in tasks like genre and style classification, showing both their potential and limitations in encoding musical patterns.


<details>
  <summary>Details</summary>
Motivation: To investigate how LLMs represent musical concepts and explore their potential in generating symbolic music without explicit musical training.

Method: We generate symbolic music data from textual prompts describing combinations of genres and styles, and evaluate their utility through recognition and generation tasks. We produce a dataset of LLM-generated MIDI files without relying on explicit musical training, then train neural networks on this dataset for genre and style classification as well as melody completion.

Result: Our results demonstrate that LLMs can infer rudimentary musical structures and temporal relationships from text, but they also highlight limitations due to a lack of explicit musical context.

Conclusion: LLMs can infer rudimentary musical structures and temporal relationships from text, highlighting their potential to implicitly encode musical patterns and their limitations due to a lack of explicit musical context.

Abstract: Large language models (LLMs) excel at modeling relationships between strings
in natural language and have shown promise in extending to other symbolic
domains like coding or mathematics. However, the extent to which they
implicitly model symbolic music remains underexplored. This paper investigates
how LLMs represent musical concepts by generating symbolic music data from
textual prompts describing combinations of genres and styles, and evaluating
their utility through recognition and generation tasks. We produce a dataset of
LLM-generated MIDI files without relying on explicit musical training. We then
train neural networks entirely on this LLM-generated MIDI dataset and perform
genre and style classification as well as melody completion, benchmarking their
performance against established models. Our results demonstrate that LLMs can
infer rudimentary musical structures and temporal relationships from text,
highlighting both their potential to implicitly encode musical patterns and
their limitations due to a lack of explicit musical context, shedding light on
their generative capabilities for symbolic music.

</details>


### [14] [Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?](https://arxiv.org/abs/2507.12838)
*Xi Ai,Mahardika Krisna Ihsani,Min-Yen Kan*

Main category: cs.CL

TL;DR: 本文研究了多语言模型的跨语言一致性，发现其受多种因素影响，并提出了一些有效的策略来提高跨语言一致性。


<details>
  <summary>Details</summary>
Motivation: 跨语言一致性应被考虑以评估跨语言可转移性，保持模型知识的真实性，并保持语言模型性能的平等性。

Method: 研究使用了一些可解释性方法来分析模型在跨语言环境中的行为，通过检查混合语言的核心指代陈述来研究跨语言知识的一致性。

Result: 多语言模型在跨语言一致性方面表现出不同的水平，受语言家族、语言因素和特定层的瓶颈影响。代码切换训练和跨语言词对齐目标显示出最有望的结果。

Conclusion: 研究发现，多语言模型在跨语言一致性方面表现出不同的水平，这取决于语言家族、语言因素以及特定层的瓶颈。此外，评估了旨在提高多语言性能的常见策略，发现代码切换训练和跨语言词对齐目标显示出最有希望的结果，强调了跨语言对齐监督和代码切换训练对于多语言性能和跨语言一致性增强的重要性。

Abstract: Cross-lingual consistency should be considered to assess cross-lingual
transferability, maintain the factuality of the model knowledge across
languages, and preserve the parity of language model performance. We are thus
interested in analyzing, evaluating, and interpreting cross-lingual consistency
for factual knowledge. We examine code-mixed coreferential statements conveyed
identical knowledge across languages to study cross-lingual knowledge
consistency. We use some interpretability approaches to analyze the behavior of
a model in cross-lingual contexts, discovering that multilingual models show
different levels of consistency, subject to language families, linguistic
factors, and a bottleneck in cross-lingual consistency on a particular layer.
In addition, we evaluate common strategies aimed at improving multilingual
performance to observe whether these strategies can improve knowledge
consistency at the same time. While knowledge is not cross-lingual consistency
in many cases, code-switching training and cross-lingual word alignment
objectives show the most promising results, emphasizing the noteworthiness of
cross-lingual alignment supervision and code-switching training for both
multilingual performance and cross-lingual consistency enhancement.

</details>


### [15] [Making Language Model a Hierarchical Classifier and Generator](https://arxiv.org/abs/2507.12930)
*Yihong Wang,Zhonglin Jiang,Ningyuan Xi,Yue Zhao,Qingqing Gu,Xiyuan Chen,Hao Wu,Sheng Xu,Hange Zhou,Yong Chen,Luo Ji*

Main category: cs.CL

TL;DR: 本研究提出了一种分层解码器架构，通过将预训练语言模型的最后层语言头复制到中间层并进行微调，实现了在多个任务上的先进性能，并展示了构建通用分层推理器的可能性。


<details>
  <summary>Details</summary>
Motivation: 受到人类层次化思维能力的启发，提出构建一个分层解码器架构，使不同层能够同时解码文本。

Method: 将预训练语言模型的最后层的语言头复制到不同的中间层，并使用不同的任务输入进行微调，以构建分层解码器架构。

Result: 实验结果表明，这些选择的中间层可以生成有意义和合理的文本内容，这种分层解码器范式在多个任务上获得了最先进的性能。

Conclusion: 本研究表明，通过将预训练语言模型的最后层的语言头复制到不同的中间层并进行微调，可以构建一种分层解码器架构，从而在多个任务上获得最先进的性能。这表明了从零开始预训练通用分层推理器的可能性。

Abstract: Decoder-only language models, such as GPT and LLaMA, generally decode on the
last layer. Motivated by human's hierarchical thinking capability, we propose
that a hierarchical decoder architecture could be built with different layers
decoding texts simultaneously. Due to limited time and computationally
resources, we choose to adapt a pretrained language model into this form of
hierarchical decoder. Language heads of the last layer are copied to different
selected intermediate layers, and fine-tuned with different task inputs. By
thorough experiments, we validate that these selective intermediate layers
could be adapted to speak meaningful and reasonable contents, and this paradigm
of hierarchical decoder can obtain state-of-the-art performances on multiple
tasks such as hierarchical text classification, classification-guided
generation, and hierarchical text generation. This study suggests the
possibility of a generalized hierarchical reasoner, pretraining from scratch.

</details>


### [16] [MRT at IberLEF-2025 PRESTA Task: Maximizing Recovery from Tables with Multiple Steps](https://arxiv.org/abs/2507.12981)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Héctor Cerezo-Costas,Pedro Alonso Doval,Jorge Alcalde Vesteiro*

Main category: cs.CL

TL;DR: 本文提出了一种基于LLMs的Python代码生成方法，用于解决西班牙语表格的问题和答案任务，并取得了85%的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决关于西班牙语表格的问题和答案任务，通过自动化的方式提高处理效率和准确性。

Method: 通过实现Python代码生成与LLMs结合，用于过滤和处理表格中的数据。该方法从Semeval 2025相关任务的MRT实现演变而来。

Result: 在任务中实现了85%的准确率。

Conclusion: 通过这种方法，我们在任务中获得了85%的准确率。

Abstract: This paper presents our approach for the IberLEF 2025 Task PRESTA: Preguntas
y Respuestas sobre Tablas en Espa\~nol (Questions and Answers about Tables in
Spanish). Our solution obtains answers to the questions by implementing Python
code generation with LLMs that is used to filter and process the table. This
solution evolves from the MRT implementation for the Semeval 2025 related task.
The process consists of multiple steps: analyzing and understanding the content
of the table, selecting the useful columns, generating instructions in natural
language, translating these instructions to code, running it, and handling
potential errors or exceptions. These steps use open-source LLMs and
fine-grained optimized prompts for each step. With this approach, we achieved
an accuracy score of 85\% in the task.

</details>


### [17] [Formalizing Attack Scenario Description: A Proposed Model](https://arxiv.org/abs/2507.13076)
*Quentin Goux,Nadira Lammari*

Main category: cs.CL

TL;DR: 本文提出了一种基于UML类模型的攻击场景形式化模型，用于描述攻击的上下文和场景，并展示了该模型在攻击分析和自动生成功能攻击脚本中的应用。


<details>
  <summary>Details</summary>
Motivation: 组织面临着不断变化的威胁环境，必须持续投入大量努力来保护其资产，因此采用更多的网络安全自动化是不可避免的。然而，流程自动化需要输入数据的正式化，本文旨在解决使用攻击场景作为输入的过程的需求。

Method: 本文提出了一个基于UML类模型的攻击场景形式化模型，用于描述攻击的上下文和场景，并展示了该模型在攻击分析和自动生成功能攻击脚本中的应用。

Result: 本文提出了一个新颖的形式化模型，能够涵盖攻击的上下文描述和其场景，并通过UML类模型进行抽象。该模型被应用于攻击分析和自动生成功能攻击脚本，以用于网络安全培训。

Conclusion: 本文的主要研究贡献是一个新的形式化模型，涵盖了攻击的上下文描述和其场景，并使用UML类模型进行抽象。该模型可以用于上游攻击分析过程以及自动生成功能攻击脚本，以用于网络安全培训。

Abstract: Organizations face an ever-changing threat landscape. They must continuously
dedicate significant efforts to protect their assets, making their adoption of
increased cybersecurity automation inevitable. However, process automation
requires formalization of input data. Through this paper, we address this need
for processes that use attack scenarios as input. Among these processes, one
can mention both the generation of scripts for attack simulation and training
purposes, as well as the analysis of attacks. Therefore, the paper's main
research contribution is a novel formal model that encompasses the attack's
context description and its scenario. It is abstracted using UML class model.
Once the description of our model done, we will show how it could serve an
upstream attack analysis process. We will show also its use for an automatic
generation of attack scripts in the context of cybersecurity training. These
two uses cases constitute the second contribution of this present research
work.

</details>


### [18] [SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts](https://arxiv.org/abs/2507.13105)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

TL;DR: SemCSE is an unsupervised method for learning semantic embeddings of scientific texts that outperforms traditional citation-based approaches.


<details>
  <summary>Details</summary>
Motivation: Traditional citation-based approaches do not necessarily reflect semantic similarity, so there is a need for a method that captures the true semantic content of a text.

Method: SemCSE is an unsupervised method that leverages LLM-generated summaries of scientific abstracts to train a model that positions semantically related summaries closer together in the embedding space.

Result: SemCSE demonstrates stronger semantic separation within the embedding space and achieves state-of-the-art performance on the SciRepEval benchmark.

Conclusion: SemCSE achieves state-of-the-art performance on the SciRepEval benchmark, demonstrating the benefits of a semantically focused training approach.

Abstract: We introduce SemCSE, an unsupervised method for learning semantic embeddings
of scientific texts. Building on recent advances in contrastive learning for
text embeddings, our approach leverages LLM-generated summaries of scientific
abstracts to train a model that positions semantically related summaries closer
together in the embedding space. This resulting objective ensures that the
model captures the true semantic content of a text, in contrast to traditional
citation-based approaches that do not necessarily reflect semantic similarity.
To validate this, we propose a novel benchmark designed to assess a model's
ability to understand and encode the semantic content of scientific texts,
demonstrating that our method enforces a stronger semantic separation within
the embedding space. Additionally, we evaluate SemCSE on the comprehensive
SciRepEval benchmark for scientific text embeddings, where it achieves
state-of-the-art performance among models of its size, thus highlighting the
benefits of a semantically focused training approach.

</details>


### [19] [A Computational Framework to Identify Self-Aspects in Text](https://arxiv.org/abs/2507.13115)
*Jaya Caporusso,Matthew Purver,Senja Pollak*

Main category: cs.CL

TL;DR: 该论文提案旨在开发一个计算框架，用于识别文本中的自我方面，并通过案例研究在心理健康和经验现象学中应用表现最佳的模型。


<details>
  <summary>Details</summary>
Motivation: 自我是一个多面的构造，在语言中有所体现，但在自然语言处理（NLP）中仍研究不足。许多自我方面与心理健康的良好研究现象相关，因此需要系统性的NLP分析。

Method: 论文计划引入自我方面的本体论和金标准标注数据集，并开发和评估传统判别模型、生成式大语言模型和基于嵌入的检索方法。

Result: 论文将通过四个主要标准（可解释性、真实数据一致性、准确性和计算效率）评估模型，并将表现最佳的模型应用于心理健康和经验现象学的案例研究。

Conclusion: 该论文提案旨在开发一个计算框架，用于识别文本中的自我方面，并通过案例研究在心理健康和经验现象学中应用表现最佳的模型。

Abstract: This Ph.D. proposal introduces a plan to develop a computational framework to
identify Self-aspects in text. The Self is a multifaceted construct and it is
reflected in language. While it is described across disciplines like cognitive
science and phenomenology, it remains underexplored in natural language
processing (NLP). Many of the aspects of the Self align with psychological and
other well-researched phenomena (e.g., those related to mental health),
highlighting the need for systematic NLP-based analysis. In line with this, we
plan to introduce an ontology of Self-aspects and a gold-standard annotated
dataset. Using this foundation, we will develop and evaluate conventional
discriminative models, generative large language models, and embedding-based
retrieval approaches against four main criteria: interpretability, ground-truth
adherence, accuracy, and computational efficiency. Top-performing models will
be applied in case studies in mental health and empirical phenomenology.

</details>


### [20] [Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation](https://arxiv.org/abs/2507.13138)
*Hadi Mohammadi,Tina Shahedi,Pablo Mosteiro,Massimo Poesio,Ayoub Bagheri,Anastasia Giachanou*

Main category: cs.CL

TL;DR: 该研究探讨了标注者人口统计特征对标注决策的影响，并评估了生成式AI模型作为注释者的可靠性。结果表明，内容是主要因素，而生成式AI模型在简单角色提示下表现不佳。


<details>
  <summary>Details</summary>
Motivation: 理解标注中的变异来源对于开发公平的自然语言处理系统至关重要，特别是在像性别歧视检测这样的任务中，人口统计偏差是一个值得关注的问题。

Method: 使用广义线性混合模型来量化注释者人口统计特征对标注决策的影响，并评估生成式AI模型作为注释者的可靠性。

Result: 研究发现，虽然人口统计因素在统计上存在影响，但它们仅占观察到的方差的8%，而推文内容是主要因素。此外，简单的角色提示通常无法提高性能，有时甚至会降低性能。

Conclusion: 研究认为，关注内容驱动的解释和稳健的标注协议比潜在的人格模拟更能可靠地实现公平性。

Abstract: Understanding the sources of variability in annotations is crucial for
developing fair NLP systems, especially for tasks like sexism detection where
demographic bias is a concern. This study investigates the extent to which
annotator demographic features influence labeling decisions compared to text
content. Using a Generalized Linear Mixed Model, we quantify this inf luence,
finding that while statistically present, demographic factors account for a
minor fraction ( 8%) of the observed variance, with tweet content being the
dominant factor. We then assess the reliability of Generative AI (GenAI) models
as annotators, specifically evaluating if guiding them with demographic
personas improves alignment with human judgments. Our results indicate that
simplistic persona prompting often fails to enhance, and sometimes degrades,
performance compared to baseline models. Furthermore, explainable AI (XAI)
techniques reveal that model predictions rely heavily on content-specific
tokens related to sexism, rather than correlates of demographic
characteristics. We argue that focusing on content-driven explanations and
robust annotation protocols offers a more reliable path towards fairness than
potentially persona simulation.

</details>


### [21] [Feature-based analysis of oral narratives from Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13164)
*Emma Sharratt,Annelien Smith,Retief Louw,Daleen Klop,Febe de Wet,Herman Kamper*

Main category: cs.CL

TL;DR: 这项研究分析了四岁和五岁阿非利堪斯语和科萨语儿童的口头叙述，发现词汇多样性和话语长度是典型发展的指标，而特定动词和助动词的使用与较低的干预需求相关。


<details>
  <summary>Details</summary>
Motivation: 口头叙述技能是后期读写能力发展的强大预测因素。这项研究检查了被专家认定需要干预的儿童的口头叙述特征。

Method: 使用简单的机器学习方法，我们分析了四岁和五岁阿非利堪斯语和科萨语儿童的录音故事。

Result: 词汇多样性（独特单词）和基于长度的特征（平均话语长度）是典型发展的指标，但像发音率这样的特征则不太有信息量。尽管在词性模式上存在跨语言差异，但与目标导向的故事讲述相关的特定动词和助动词的使用与需要干预的可能性降低相关。

Conclusion: 我们的分析揭示了语言特定和共享的叙事能力预测因素，这对多语言环境中的早期评估有影响。

Abstract: Oral narrative skills are strong predictors of later literacy development.
This study examines the features of oral narratives from children who were
identified by experts as requiring intervention. Using simple machine learning
methods, we analyse recorded stories from four- and five-year-old Afrikaans-
and isiXhosa-speaking children. Consistent with prior research, we identify
lexical diversity (unique words) and length-based features (mean utterance
length) as indicators of typical development, but features like articulation
rate prove less informative. Despite cross-linguistic variation in
part-of-speech patterns, the use of specific verbs and auxiliaries associated
with goal-directed storytelling is correlated with a reduced likelihood of
requiring intervention. Our analysis of two linguistically distinct languages
reveals both language-specific and shared predictors of narrative proficiency,
with implications for early assessment in multilingual contexts.

</details>


### [22] [GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems](https://arxiv.org/abs/2507.13190)
*Jisoo Lee,Raeyoung Chang,Dongwook Kwon,Harmanpreet Singh,Nikhil Verma*

Main category: cs.CL

TL;DR: 本文介绍了GEMMAS，一种基于图的评估框架，用于分析多智能体系统的内部协作过程。通过提出信息多样性得分和不必要的路径比率两个过程级度量，揭示了仅基于结果的度量不足以评估多智能体性能，并强调了过程级诊断的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的评估只关注最终输出的正确性，而忽略了低效通信和不良协调导致的冗余推理和更高的计算成本。

Method: 引入GEMMAS，一种基于图的评估框架，通过将智能体交互建模为有向无环图来分析内部协作过程。提出两个过程级度量：信息多样性得分（IDS）和不必要的路径比率（UPR）。

Result: 在五个基准测试中评估GEMMAS，并在GSM8K上突出显示结果，其中准确率仅有2.1%的差异，但IDS相差12.8%，UPR相差80%，显示出内部协作的显著差异。

Conclusion: 结果表明，仅基于结果的度量不足以评估多智能体性能，并强调了过程级诊断在设计更可解释和资源高效的协作AI系统中的重要性。

Abstract: Multi-agent systems built on language models have shown strong performance on
collaborative reasoning tasks. However, existing evaluations focus only on the
correctness of the final output, overlooking how inefficient communication and
poor coordination contribute to redundant reasoning and higher computational
costs. We introduce GEMMAS, a graph-based evaluation framework that analyzes
the internal collaboration process by modeling agent interactions as a directed
acyclic graph. To capture collaboration quality, we propose two process-level
metrics: Information Diversity Score (IDS) to measure semantic variation in
inter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant
reasoning paths. We evaluate GEMMAS across five benchmarks and highlight
results on GSM8K, where systems with only a 2.1% difference in accuracy differ
by 12.8% in IDS and 80% in UPR, revealing substantial variation in internal
collaboration. These findings demonstrate that outcome-only metrics are
insufficient for evaluating multi-agent performance and highlight the
importance of process-level diagnostics in designing more interpretable and
resource-efficient collaborative AI systems.

</details>


### [23] [Automatically assessing oral narratives of Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13205)
*R. Louw,E. Sharratt,F. de Wet,C. Jacobs,A. Smith,H. Kamper*

Main category: cs.CL

TL;DR: 本文介绍了一种用于自动评估学龄前儿童口语叙述的系统，该系统使用自动语音识别和机器学习评分模型。基于大语言模型的系统在大多数情况下优于线性模型，并且在标记需要干预的儿童方面与人类专家相当。


<details>
  <summary>Details</summary>
Motivation: 在大型幼儿园教室中，教师难以准确识别需要干预的学生。发展早期儿童的叙事和理解能力对于以后的读写能力至关重要。

Method: 我们提出了一种系统，用于自动评估南非语和科萨语的学龄前儿童的口头叙述。该系统使用自动语音识别，然后使用机器学习评分模型来预测叙述和理解分数。

Result: 基于大语言模型的系统在大多数情况下优于线性模型，但尽管其简单性，线性系统仍然具有竞争力。基于大语言模型的系统在标记需要干预的儿童方面与人类专家相当。

Conclusion: 我们为课堂中的自动口语评估奠定了基础，使教师能够额外关注儿童学习的个性化支持。

Abstract: Developing narrative and comprehension skills in early childhood is critical
for later literacy. However, teachers in large preschool classrooms struggle to
accurately identify students who require intervention. We present a system for
automatically assessing oral narratives of preschool children in Afrikaans and
isiXhosa. The system uses automatic speech recognition followed by a machine
learning scoring model to predict narrative and comprehension scores. For
scoring predicted transcripts, we compare a linear model to a large language
model (LLM). The LLM-based system outperforms the linear model in most cases,
but the linear system is competitive despite its simplicity. The LLM-based
system is comparable to a human expert in flagging children who require
intervention. We lay the foundation for automatic oral assessments in
classrooms, giving teachers extra capacity to focus on personalised support for
children's learning.

</details>


### [24] [Enhancing Cross-task Transfer of Large Language Models via Activation Steering](https://arxiv.org/abs/2507.13236)
*Xinyu Tang,Zhihao Lv,Xiaoxue Cheng,Junyi Li,Wayne Xin Zhao,Zujie Wen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种新的跨任务激活引导传输框架CAST，能够在不更新参数或扩展输入的情况下实现跨任务的知识迁移。实验结果表明，该方法在跨领域和跨语言转移设置中优于现有基线，并展示了更高的可扩展性和更低的计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的跨任务上下文学习在鲁棒性、可扩展性和效率方面面临挑战。本文旨在探索是否可以通过潜在空间引导实现跨任务传输，而无需参数更新或输入扩展。

Method: 本文通过分析大语言模型（LLM）潜在空间中的激活模式，发现由上下文示例引起的增强激活在不同任务中具有一致的模式。基于这些发现，提出了CAST框架，通过操纵模型的内部激活状态来实现有效的跨任务传输。首先从高资源任务中选择有影响力和多样化的样本，然后利用其对比表示增强的激活来适应低资源任务。

Result: 在跨领域和跨语言转移设置中，本文的方法优于竞争基线，展示了更高的可扩展性和更低的计算成本。

Conclusion: 本文提出了一种新的跨任务激活引导传输框架CAST，能够在不更新参数或扩展输入的情况下实现跨任务的知识迁移。实验结果表明，该方法在跨领域和跨语言转移设置中优于现有基线，并展示了更高的可扩展性和更低的计算成本。

Abstract: Large language models (LLMs) have shown impressive abilities in leveraging
pretrained knowledge through prompting, but they often struggle with unseen
tasks, particularly in data-scarce scenarios. While cross-task in-context
learning offers a direct solution for transferring knowledge across tasks, it
still faces critical challenges in terms of robustness, scalability, and
efficiency. In this paper, we investigate whether cross-task transfer can be
achieved via latent space steering without parameter updates or input
expansion. Through an analysis of activation patterns in the latent space of
LLMs, we observe that the enhanced activations induced by in-context examples
have consistent patterns across different tasks. Inspired by these findings, we
propose CAST, a novel Cross-task Activation Steering Transfer framework that
enables effective transfer by manipulating the model's internal activation
states. Our approach first selects influential and diverse samples from
high-resource tasks, then utilizes their contrastive representation-enhanced
activations to adapt LLMs to low-resource tasks. Extensive experiments across
both cross-domain and cross-lingual transfer settings show that our method
outperforms competitive baselines and demonstrates superior scalability and
lower computational costs.

</details>


### [25] [HATS: Hindi Analogy Test Set for Evaluating Reasoning in Large Language Models](https://arxiv.org/abs/2507.13238)
*Ashray Gupta,Rohan Joseph,Sunny Rai*

Main category: cs.CL

TL;DR: 本文介绍了一个新的印地语类比测试集（HATS），用于评估大型语言模型在印地语中的推理能力，并提出了一种基于认知理论的类比推理方法，实验显示模型在英语提示下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型在印地语中的能力研究不足，限制了我们对这些模型是否能在不同语言中泛化的理解，因此需要一个专门的测试集来评估它们的推理能力。

Method: 我们引入了一个新的印地语类比测试集（HATS），并使用各种提示策略对最先进的多语言LLM进行了基准测试，还提出了一种基于认知理论的类比推理的方法。

Result: 实验表明，无论采用何种提示策略，模型在英语提示下的表现最佳。

Conclusion: 我们的测试集解决了缺乏评估大型语言模型在印地语中推理能力的关键资源的问题。

Abstract: Analogies test a model's ability to infer implicit relationships between
concepts, making them a key benchmark for evaluating reasoning capabilities.
While large language models (LLMs) are widely evaluated for reasoning in
English, their abilities in Indic languages remain understudied, limiting our
understanding of whether these models generalize across languages. To address
this gap, we introduce a new Hindi Analogy Test Set (HATS), comprising 405
multiple-choice questions sourced from Indian government exams. We benchmark
state-of-the-art multilingual LLMs using various prompting strategies and
introduce a grounded Chain of Thought approach that leverages cognitive
theories of analogical reasoning. This approach improves model performance on
Hindi analogy questions. Our experiments show that models perform best with
English prompts, irrespective of the prompting strategy. Our test set addresses
the lack of a critical resource to evaluate LLM reasoning capabilities in
Hindi.

</details>


### [26] [Automating Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2507.13255)
*Lyucheng Wu,Mengru Wang,Ziwen Xu,Tri Cao,Nay Oo,Bryan Hooi,Shumin Deng*

Main category: cs.CL

TL;DR: AutoSteer is a modular and adaptive inference-time intervention technology that improves the safety of Multimodal Large Language Models without requiring model fine-tuning.


<details>
  <summary>Details</summary>
Motivation: To improve the safety of MLLMs during inference without requiring any fine-tuning of the underlying model.

Method: AutoSteer incorporates three core components: a Safety Awareness Score (SAS), an adaptive safety prober, and a lightweight Refusal Head.

Result: Experiments on LLaVA-OV and Chameleon demonstrate that AutoSteer significantly reduces the Attack Success Rate (ASR) for textual, visual, and cross-modal threats while maintaining general abilities.

Conclusion: AutoSteer is positioned as a practical, interpretable, and effective framework for safer deployment of multimodal AI systems.

Abstract: Recent progress in Multimodal Large Language Models (MLLMs) has unlocked
powerful cross-modal reasoning abilities, but also raised new safety concerns,
particularly when faced with adversarial multimodal inputs. To improve the
safety of MLLMs during inference, we introduce a modular and adaptive
inference-time intervention technology, AutoSteer, without requiring any
fine-tuning of the underlying model. AutoSteer incorporates three core
components: (1) a novel Safety Awareness Score (SAS) that automatically
identifies the most safety-relevant distinctions among the model's internal
layers; (2) an adaptive safety prober trained to estimate the likelihood of
toxic outputs from intermediate representations; and (3) a lightweight Refusal
Head that selectively intervenes to modulate generation when safety risks are
detected. Experiments on LLaVA-OV and Chameleon across diverse safety-critical
benchmarks demonstrate that AutoSteer significantly reduces the Attack Success
Rate (ASR) for textual, visual, and cross-modal threats, while maintaining
general abilities. These findings position AutoSteer as a practical,
interpretable, and effective framework for safer deployment of multimodal AI
systems.

</details>


### [27] [QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation](https://arxiv.org/abs/2507.13266)
*Jiazheng Li,Hong Lu,Kaiyue Wen,Zaiwen Yang,Jiaxuan Gao,Hongzhou Lin,Yi Wu,Jingzhao Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为QuestA的简单而有效的策略，通过在训练过程中引入部分解决方案来提高强化学习在多步骤推理任务中的效果。该方法在数学推理任务中表现出色，实现了新的最先进结果，并提供了理论解释，表明QuestA提高了样本效率。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习（RL）已成为训练大型语言推理模型（LLMs）的关键组件，但最近的研究质疑其在提高多步骤推理方面的有效性，特别是在困难问题上。因此，需要一种有效的方法来解决这一挑战。

Method: QuestA是一种通过在训练过程中引入部分解决方案来简化问题并提供更有效的学习信号的策略。这种方法应用于强化学习训练，以提高数学推理任务中的性能。

Result: QuestA在数学推理任务中不仅提高了pass@1，还提高了pass@k，尤其是在标准RL难以取得进展的问题上。使用1.5B参数模型，在数学基准测试中取得了新的最先进结果：AIME24为67.1%（+5.3%），AIME25为59.5%（+10.0%），HMMT25为35.5%（+4.0%）。

Conclusion: QuestA通过引入部分解决方案来减少问题难度并提供更有信息的学习信号，从而提高了强化学习在多步骤推理中的效果。该方法在数学推理任务中表现出色，实现了新的最先进结果，并提供了理论解释，表明QuestA提高了样本效率。

Abstract: Reinforcement learning (RL) has become a key component in training large
language reasoning models (LLMs). However, recent studies questions its
effectiveness in improving multi-step reasoning-particularly on hard problems.
To address this challenge, we propose a simple yet effective strategy via
Question Augmentation: introduce partial solutions during training to reduce
problem difficulty and provide more informative learning signals. Our method,
QuestA, when applied during RL training on math reasoning tasks, not only
improves pass@1 but also pass@k-particularly on problems where standard RL
struggles to make progress. This enables continual improvement over strong
open-source models such as DeepScaleR and OpenMath Nemotron, further enhancing
their reasoning capabilities. We achieve new state-of-the-art results on math
benchmarks using 1.5B-parameter models: 67.1% (+5.3%) on AIME24, 59.5% (+10.0%)
on AIME25, and 35.5% (+4.0%) on HMMT25. Further, we provide theoretical
explanations that QuestA improves sample efficiency, offering a practical and
generalizable pathway for expanding reasoning capability through RL.

</details>


### [28] [Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management](https://arxiv.org/abs/2507.13275)
*Luis Gasco,Hermenegildo Fabregat,Laura García-Sardiña,Paula Estrella,Daniel Deniz,Alvaro Rodrigo,Rabih Zbib*

Main category: cs.CL

TL;DR: TalentCLEF 2025 is the first evaluation campaign for skill and job title intelligence, providing a public benchmark for developing robust, fair, and transferable language technologies in the labor market.


<details>
  <summary>Details</summary>
Motivation: The adoption and progress of language technologies in Human Capital Management depend on reliable and fair models evaluated on public data and open benchmarks, which have been unavailable in this domain.

Method: The paper presents TalentCLEF 2025, the first evaluation campaign focused on skill and job title intelligence. It includes two tasks: Task A - Multilingual Job Title Matching, and Task B - Job Title-Based Skill Prediction. The corpora were built from real job applications and manually annotated.

Result: TalentCLEF attracted 76 registered teams with more than 280 submissions. Most systems relied on information retrieval techniques using multilingual encoder-based models fine-tuned with contrastive learning, and several incorporated large language models for data augmentation or re-ranking. The results show that training strategies have a larger effect than model size alone.

Conclusion: TalentCLEF provides the first public benchmark in this field and encourages the development of robust, fair, and transferable language technologies for the labor market.

Abstract: Advances in natural language processing and large language models are driving
a major transformation in Human Capital Management, with a growing interest in
building smart systems based on language technologies for talent acquisition,
upskilling strategies, and workforce planning. However, the adoption and
progress of these technologies critically depend on the development of reliable
and fair models, properly evaluated on public data and open benchmarks, which
have so far been unavailable in this domain.
  To address this gap, we present TalentCLEF 2025, the first evaluation
campaign focused on skill and job title intelligence. The lab consists of two
tasks: Task A - Multilingual Job Title Matching, covering English, Spanish,
German, and Chinese; and Task B - Job Title-Based Skill Prediction, in English.
Both corpora were built from real job applications, carefully anonymized, and
manually annotated to reflect the complexity and diversity of real-world labor
market data, including linguistic variability and gender-marked expressions.
  The evaluations included monolingual and cross-lingual scenarios and covered
the evaluation of gender bias.
  TalentCLEF attracted 76 registered teams with more than 280 submissions. Most
systems relied on information retrieval techniques built with multilingual
encoder-based models fine-tuned with contrastive learning, and several of them
incorporated large language models for data augmentation or re-ranking. The
results show that the training strategies have a larger effect than the size of
the model alone. TalentCLEF provides the first public benchmark in this field
and encourages the development of robust, fair, and transferable language
technologies for the labor market.

</details>


### [29] [Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis](https://arxiv.org/abs/2507.13285)
*Wang Xi,Quan Shi,Tian Yu,Yujie Peng,Jiayi Sun,Mengxing Ren,Zenghui Ding,Ningguang Yao*

Main category: cs.CL

TL;DR: 本文提出了一种名为RCPS的新框架，用于生成高质量的媒体演示文稿，并引入了PREVAL评估框架来衡量演示文稿的质量。实验结果表明，RCPS在所有质量维度上均优于现有方法，而PREVAL与人类判断高度相关，验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法往往产生逻辑不一致和布局不佳的演示文稿，难以达到专业标准。因此，需要一种新的框架来解决这些问题。

Method: RCPS（反思连贯演示合成）框架，包括三个关键组件：(1) 深度结构化叙事规划；(2) 自适应布局生成；(3) 迭代优化循环。此外，还提出了PREVAL，一种基于偏好的评估框架，采用增强理由的多维模型来评估演示文稿的质量。

Result: 实验结果表明，RCPS在所有质量维度上均显著优于基线方法，产生的演示文稿接近人类专家标准。PREVAL与人类判断有很强的相关性，验证了其作为评估演示文稿质量的可靠自动化工具的有效性。

Conclusion: RCPS显著优于基线方法，在所有质量维度上都表现出色，产生的演示文稿接近人类专家标准。PREVAL与人类判断有很强的相关性，验证了其作为评估演示文稿质量的可靠自动化工具的有效性。

Abstract: Automated generation of high-quality media presentations is challenging,
requiring robust content extraction, narrative planning, visual design, and
overall quality optimization. Existing methods often produce presentations with
logical inconsistencies and suboptimal layouts, thereby struggling to meet
professional standards. To address these challenges, we introduce RCPS
(Reflective Coherent Presentation Synthesis), a novel framework integrating
three key components: (1) Deep Structured Narrative Planning; (2) Adaptive
Layout Generation; (3) an Iterative Optimization Loop. Additionally, we propose
PREVAL, a preference-based evaluation framework employing rationale-enhanced
multi-dimensional models to assess presentation quality across Content,
Coherence, and Design. Experimental results demonstrate that RCPS significantly
outperforms baseline methods across all quality dimensions, producing
presentations that closely approximate human expert standards. PREVAL shows
strong correlation with human judgments, validating it as a reliable automated
tool for assessing presentation quality.

</details>


### [30] [AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research](https://arxiv.org/abs/2507.13300)
*Yilun Zhao,Weiyuan Chen,Zhijian Xu,Manasi Patwardhan,Yixin Liu,Chengye Wang,Lovekesh Vig,Arman Cohan*

Main category: cs.CL

TL;DR: 我们引入了AbGen基准来评估LLM在设计消融实验方面的能力，并发现LLM与人类专家之间存在显著差距。此外，现有自动化评估方法不可靠，我们开发了AbGen-Eval来研究这一问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在设计消融实验方面与人类专家存在性能差距，且现有的自动化评估方法不可靠。我们需要一个基准来评估LLM的能力，并探索更有效的评估系统。

Method: 我们引入了AbGen，这是第一个用于评估LLM在设计科学研究中的消融实验能力的基准。AbGen包含1,500个专家标注的例子，来源于807篇NLP论文。我们评估了领先的LLM，如DeepSeek-R1-0528和o4-mini，并开发了AbGen-Eval来评估自动化评估系统的可靠性。

Result: 评估结果显示，LLM在重要性、忠实性和合理性方面与人类专家有显著差距。同时，现有的自动化评估方法与人类评估存在显著差异。通过AbGen-Eval，我们进一步验证了这一点，并为未来研究提供了方向。

Conclusion: 我们的研究揭示了当前LLM在设计消融实验方面的性能与人类专家之间的显著差距，并表明现有的自动化评估方法不可靠。我们开发了AbGen-Eval来更好地研究这一问题，并为未来开发更有效和可靠的LLM评估系统提供了见解。

Abstract: We introduce AbGen, the first benchmark designed to evaluate the capabilities
of LLMs in designing ablation studies for scientific research. AbGen consists
of 1,500 expert-annotated examples derived from 807 NLP papers. In this
benchmark, LLMs are tasked with generating detailed ablation study designs for
a specified module or process based on the given research context. Our
evaluation of leading LLMs, such as DeepSeek-R1-0528 and o4-mini, highlights a
significant performance gap between these models and human experts in terms of
the importance, faithfulness, and soundness of the ablation study designs.
Moreover, we demonstrate that current automated evaluation methods are not
reliable for our task, as they show a significant discrepancy when compared to
human assessment. To better investigate this, we develop AbGen-Eval, a
meta-evaluation benchmark designed to assess the reliability of commonly used
automated evaluation systems in measuring LLM performance on our task. We
investigate various LLM-as-Judge systems on AbGen-Eval, providing insights for
future research on developing more effective and reliable LLM-based evaluation
systems for complex scientific tasks.

</details>


### [31] [HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals](https://arxiv.org/abs/2507.13318)
*Guimin Hu,Daniel Hershcovich,Hasti Seifi*

Main category: cs.CL

TL;DR: 本文创建了HapticCap数据集并提出了haptic-caption retrieval任务，展示了T5和AST模型在该任务中的优秀表现。


<details>
  <summary>Details</summary>
Motivation: 设计能够与用户产生有意义共鸣的触觉信号是具有挑战性的，因此需要一个大规模的、带有文本描述的触觉数据集来促进这一领域的发展。

Method: 本文提出了haptic-caption retrieval任务，并使用监督对比学习框架进行研究，结合了语言模型T5和音频模型AST。

Result: HapticCap数据集包含92,070个触觉-文本对，用于用户描述振动的感觉、情感和关联属性。语言模型T5和音频模型AST在haptic-caption retrieval任务中表现出色，尤其是在每个描述类别上单独训练时。

Conclusion: 本文介绍了HapticCap数据集和haptic-caption retrieval任务，展示了语言模型T5和音频模型AST在该任务中的最佳表现，特别是在每个描述类别上单独训练时。

Abstract: Haptic signals, from smartphone vibrations to virtual reality touch feedback,
can effectively convey information and enhance realism, but designing signals
that resonate meaningfully with users is challenging. To facilitate this, we
introduce a multimodal dataset and task, of matching user descriptions to
vibration haptic signals, and highlight two primary challenges: (1) lack of
large haptic vibration datasets annotated with textual descriptions as
collecting haptic descriptions is time-consuming, and (2) limited capability of
existing tasks and models to describe vibration signals in text. To advance
this area, we create HapticCap, the first fully human-annotated
haptic-captioned dataset, containing 92,070 haptic-text pairs for user
descriptions of sensory, emotional, and associative attributes of vibrations.
Based on HapticCap, we propose the haptic-caption retrieval task and present
the results of this task from a supervised contrastive learning framework that
brings together text representations within specific categories and vibrations.
Overall, the combination of language model T5 and audio model AST yields the
best performance in the haptic-caption retrieval task, especially when
separately trained for each description category.

</details>


### [32] [Social and Political Framing in Search Engine Results](https://arxiv.org/abs/2507.13325)
*Amrit Poudel,Tim Weninger*

Main category: cs.CL

TL;DR: 本研究分析了搜索引擎如何通过优先考虑内容和意识形态驱动的用户查询来加剧信息偏见，并发现不同搜索引擎在来源优先级上存在差异。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨搜索引擎和意识形态驱动的用户查询如何共同导致搜索结果中的偏见。

Method: 该研究使用政治和社会议题的数据集分析了主要搜索引擎的输出。

Result: 研究发现，搜索引擎不仅以反映潜在偏见的方式优先考虑内容，而且意识形态驱动的用户查询会加剧这些偏见，导致特定叙事的放大。此外，不同搜索引擎在优先考虑的来源方面存在显著差异。

Conclusion: 研究结果表明，搜索引擎可能在通过强化意识形态分歧来塑造公众认知方面发挥关键作用，从而对信息极化问题做出贡献。

Abstract: Search engines play a crucial role in shaping public discourse by influencing
how information is accessed and framed. While prior research has extensively
examined various dimensions of search bias -- such as content prioritization,
indexical bias, political polarization, and sources of bias -- an important
question remains underexplored: how do search engines and
ideologically-motivated user queries contribute to bias in search results. This
study analyzes the outputs of major search engines using a dataset of political
and social topics. The findings reveal that search engines not only prioritize
content in ways that reflect underlying biases but also that
ideologically-driven user queries exacerbate these biases, resulting in the
amplification of specific narratives. Moreover, significant differences were
observed across search engines in terms of the sources they prioritize. These
results suggest that search engines may play a pivotal role in shaping public
perceptions by reinforcing ideological divides, thereby contributing to the
broader issue of information polarization.

</details>


### [33] [Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It](https://arxiv.org/abs/2507.13328)
*Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim*

Main category: cs.CL

TL;DR: 研究显示，VL训练不会显著改变语言模型的语义知识，但会改善这些知识在特定任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究VL训练是否能以有意义的方式改变语言模型的语义表示。

Method: 通过比较仅文本的语言模型和其VL训练后的对应模型，在需要概念分类理解的文本问答任务中进行实验。

Result: VL模型在需要分类理解的任务中表现优于仅文本模型，但在分类知识本身上没有显著差异。

Conclusion: VL训练不会显著改变语言模型的语义知识，但会改善这些知识在特定任务中的应用。

Abstract: Does vision-and-language (VL) training change the linguistic representations
of language models in meaningful ways? Most results in the literature have
shown inconsistent or marginal differences, both behaviorally and
representationally. In this work, we start from the hypothesis that the domain
in which VL training could have a significant effect is lexical-conceptual
knowledge, in particular its taxonomic organization. Through comparing minimal
pairs of text-only LMs and their VL-trained counterparts, we first show that
the VL models often outperform their text-only counterparts on a text-only
question-answering task that requires taxonomic understanding of concepts
mentioned in the questions. Using an array of targeted behavioral and
representational analyses, we show that the LMs and VLMs do not differ
significantly in terms of their taxonomic knowledge itself, but they differ in
how they represent questions that contain concepts in a taxonomic relation vs.
a non-taxonomic relation. This implies that the taxonomic knowledge itself does
not change substantially through additional VL training, but VL training does
improve the deployment of this knowledge in the context of a specific task,
even when the presentation of the task is purely linguistic.

</details>


### [34] [The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner](https://arxiv.org/abs/2507.13332)
*Zhouqi Hua,Wenwei Zhang,Chengqi Lyu,Yuzhe Gu,Songyang Gao,Kuikun Liu,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出TAIL方法，通过生成模仿图灵机执行过程的思维链数据，提高LLM的长度泛化能力，并在多个任务上取得了优异结果。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在特定任务的数据驱动方法上，但这些方法性能有限。为了寻找更通用的解决方案，本文关注可计算的推理问题，这些问题可以通过算法解决。

Method: 本文提出了Turing MAchine Imitation Learning (TAIL)，通过计算机程序生成模仿图灵机执行过程的思维链数据，以提高LLM的长度泛化能力。

Result: TAIL在仅使用合成数据的情况下显著提高了Qwen2.5-7B在各种任务上的长度泛化能力和性能，超过了之前的方法和DeepSeek-R1。

Conclusion: 本文提供了一种有前景的方向，用于未来研究从合成数据中学习LLM推理。

Abstract: Length generalization, the ability to solve problems of longer sequences than
those observed during training, poses a core challenge of Transformer-based
large language models (LLM). Although existing studies have predominantly
focused on data-driven approaches for arithmetic operations and symbolic
manipulation tasks, these approaches tend to be task-specific with limited
overall performance. To pursue a more general solution, this paper focuses on a
broader case of reasoning problems that are computable, i.e., problems that
algorithms can solve, thus can be solved by the Turing Machine. From this
perspective, this paper proposes Turing MAchine Imitation Learning (TAIL) to
improve the length generalization ability of LLMs. TAIL synthesizes
chain-of-thoughts (CoT) data that imitate the execution process of a Turing
Machine by computer programs, which linearly expands the reasoning steps into
atomic states to alleviate shortcut learning and explicit memory fetch
mechanism to reduce the difficulties of dynamic and long-range data access in
elementary operations. To validate the reliability and universality of TAIL, we
construct a challenging synthetic dataset covering 8 classes of algorithms and
18 tasks. Without bells and whistles, TAIL significantly improves the length
generalization ability as well as the performance of Qwen2.5-7B on various
tasks using only synthetic data, surpassing previous methods and DeepSeek-R1.
The experimental results reveal that the key concepts in the Turing Machine,
instead of the thinking styles, are indispensable for TAIL for length
generalization, through which the model exhibits read-and-write behaviors
consistent with the properties of the Turing Machine in their attention layers.
This work provides a promising direction for future research in the learning of
LLM reasoning from synthetic data.

</details>


### [35] [A Survey of Context Engineering for Large Language Models](https://arxiv.org/abs/2507.13334)
*Lingrui Mei,Jiayu Yao,Yuyao Ge,Yiwei Wang,Baolong Bi,Yujun Cai,Jiazhi Liu,Mingyu Li,Zhong-Zhi Li,Duzhen Zhang,Chenlin Zhou,Jiayi Mao,Tianze Xia,Jiafeng Guo,Shenghua Liu*

Main category: cs.CL

TL;DR: 本文介绍了Context Engineering这一正式学科，提出了一个全面的分类体系，并通过系统分析超过1300篇研究论文，揭示了模型能力之间的不对称性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在介绍Context Engineering这一正式学科，以超越简单的提示设计，涵盖对LLMs的信息负载进行系统优化。

Method: 本文对超过1300篇研究论文进行了系统分析，提出了一个全面的分类体系，将Context Engineering分解为其基础组件和复杂的实现。

Result: 本文不仅建立了该领域的技术路线图，还揭示了一个关键的研究空白：模型能力之间存在根本性的不对称性。

Conclusion: 本文提供了用于研究人员和工程师推进上下文感知AI的统一框架。

Abstract: The performance of Large Language Models (LLMs) is fundamentally determined
by the contextual information provided during inference. This survey introduces
Context Engineering, a formal discipline that transcends simple prompt design
to encompass the systematic optimization of information payloads for LLMs. We
present a comprehensive taxonomy decomposing Context Engineering into its
foundational components and the sophisticated implementations that integrate
them into intelligent systems. We first examine the foundational components:
context retrieval and generation, context processing and context management. We
then explore how these components are architecturally integrated to create
sophisticated system implementations: retrieval-augmented generation (RAG),
memory systems and tool-integrated reasoning, and multi-agent systems. Through
this systematic analysis of over 1300 research papers, our survey not only
establishes a technical roadmap for the field but also reveals a critical
research gap: a fundamental asymmetry exists between model capabilities. While
current models, augmented by advanced context engineering, demonstrate
remarkable proficiency in understanding complex contexts, they exhibit
pronounced limitations in generating equally sophisticated, long-form outputs.
Addressing this gap is a defining priority for future research. Ultimately,
this survey provides a unified framework for both researchers and engineers
advancing context-aware AI.

</details>


### [36] [Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour Understanding from Traditional Puns to Topical Jokes](https://arxiv.org/abs/2507.13335)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型在解释不同类型幽默（如双关语和需要现实世界知识的幽默）方面的能力，发现目前的模型在处理复杂幽默时存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 现有计算幽默的研究几乎只关注短小的双关语笑话，而忽略了需要现实世界知识和事件理解的更复杂的幽默形式。因此，本研究旨在探讨大型语言模型解释幽默的能力是否依赖于特定的幽默形式。

Method: 研究者收集了一个包含600个笑话的数据集，分为4种笑话类型，并手动编写高质量的解释。然后使用这个数据集比较各种大型语言模型在零样本设置下准确且全面解释不同类型的笑话的能力。

Result: 研究发现，没有一个测试的模型能够可靠地生成所有笑话类型的充分解释，这表明当前的模型在处理复杂幽默形式时存在显著不足。

Conclusion: 研究发现，目前测试的模型（包括推理模型）都无法可靠地生成所有笑话类型的充分解释，进一步突显了大多数计算幽默研究对过于简单的笑话形式的狭隘关注。

Abstract: Humour, as a complex language form, is derived from myriad aspects of life,
whilst existing work on computational humour has focussed almost exclusively on
short pun-based jokes. In this work, we investigate whether the ability of
Large Language Models (LLMs) to explain humour depends on the particular humour
form. We compare models on simple puns and more complex topical humour that
requires knowledge of real-world entities and events. In doing so, we curate a
dataset of 600 jokes split across 4 joke types and manually write high-quality
explanations. These jokes include heterographic and homographic puns,
contemporary internet humour, and topical jokes, where understanding relies on
reasoning beyond "common sense", rooted instead in world knowledge regarding
news events and pop culture. Using this dataset, we compare the zero-shot
abilities of a range of LLMs to accurately and comprehensively explain jokes of
different types, identifying key research gaps in the task of humour
explanation. We find that none of the tested models (inc. reasoning models) are
capable of reliably generating adequate explanations of all joke types, further
highlighting the narrow focus of most works in computational humour on overly
simple joke forms.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [37] [UniSLU: Unified Spoken Language Understanding from Heterogeneous Cross-Task Datasets](https://arxiv.org/abs/2507.12951)
*Zhichao Sheng,Shilin Zhou,Chen Gong,Zhenghua Li*

Main category: eess.AS

TL;DR: 本文提出了UniSLU，一个统一的框架，用于在单一架构中联合建模多个SLU任务，通过统一表示和生成方法提升任务交互，并在公共数据集上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常依赖于单独的模型架构来处理各个任务，如spoken NER和SA，这增加了系统复杂性，限制了跨任务交互，并未能充分利用任务间的异构数据集。

Method: 我们提出了UniSLU，一个统一的框架，在单一架构中联合建模多个SLU任务。具体来说，我们为多样化的SLU任务提出了一个统一的表示，以充分利用跨多个任务的异构数据集。在此表示基础上，我们提出了一个统一的生成方法，联合建模ASR、spoken NER和SA任务，增强任务交互并实现与大型语言模型的无缝集成，以利用它们强大的生成能力。

Result: 在公共SLU数据集上的广泛实验表明了我们方法的有效性，相比几种基准方法取得了优越的SLU性能。

Conclusion: 我们的方法在公共SLU数据集上进行了广泛的实验，证明了其有效性，相比几种基准方法取得了优越的SLU性能，使其非常适合实际的基于语音的多媒体场景。

Abstract: Spoken Language Understanding (SLU) plays a crucial role in speech-centric
multimedia applications, enabling machines to comprehend spoken language in
scenarios such as meetings, interviews, and customer service interactions. SLU
encompasses multiple tasks, including Automatic Speech Recognition (ASR),
spoken Named Entity Recognition (NER), and spoken Sentiment Analysis (SA).
However, existing methods often rely on separate model architectures for
individual tasks such as spoken NER and SA, which increases system complexity,
limits cross-task interaction, and fails to fully exploit heterogeneous
datasets available across tasks. To address these limitations, we propose
UniSLU, a unified framework that jointly models multiple SLU tasks within a
single architecture. Specifically, we propose a unified representation for
diverse SLU tasks, enabling full utilization of heterogeneous datasets across
multiple tasks. Built upon this representation, we propose a unified generative
method that jointly models ASR, spoken NER, and SA tasks, enhancing task
interactions and enabling seamless integration with large language models to
harness their powerful generative capabilities. Extensive experiments on public
SLU datasets demonstrate the effectiveness of our approach, achieving superior
SLU performance compared to several benchmark methods, making it well-suited
for real-world speech-based multimedia scenarios. We will release all code and
models at github to facilitate future research.

</details>


<div id='cs.CC'></div>

# cs.CC [[Back]](#toc)

### [38] [Perfect diffusion is $\mathsf{TC}^0$ -- Bad diffusion is Turing-complete](https://arxiv.org/abs/2507.12469)
*Yuxi Liu*

Main category: cs.CC

TL;DR: 本文分析了扩散模型在语言建模任务中的计算复杂性，提出了一个基于分数匹配网络质量的二分法，并探讨了其理论和实际影响。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨扩散模型在语言建模任务中的计算复杂性，以及它们在顺序计算任务中的能力和限制。

Method: 本文基于分数匹配网络的质量在扩散模型中的计算复杂性进行了二分法分析。一方面，一个能准确计算初始分布分数函数的网络只能在TC^0复杂度类中进行语言建模，这反映了快速收敛的限制。另一方面，如果不要求网络匹配任何分数函数，则扩散建模可以在某种意义上模拟任何图灵机。

Result: 本文证明了扩散模型在分数匹配网络质量方面的二分法。一方面，精确计算分数函数的网络只能在TC^0复杂度类中进行语言建模。另一方面，如果不要求网络匹配任何分数函数，则扩散建模可以在某种意义上模拟任何图灵机。

Conclusion: 本文提供了对扩散模型能力与限制的理论视角，特别是针对需要顺序计算的任务。我们推测了理论结果的扩展，包括当扩散模型不是完美但只是良好时的情况。此外，我们讨论了更广泛的情境和实际影响，并假设一种能够在顺序和并行操作模式之间进行插值的机器学习架构将优于Transformer和扩散模型。

Abstract: This paper explores the computational complexity of diffusion-based language
modeling. We prove a dichotomy based on the quality of the score-matching
network in a diffusion model. In one direction, a network that exactly computes
the score function of some initial distribution can only perform language
modeling within the $\mathsf{TC}^0$ complexity class, reflecting limitations
tied to rapid convergence. In the other direction, we show that if there is no
requirement for the network to match any score function, then diffusion
modeling can simulate any Turing machine in a certain sense. This dichotomy
provides a theoretical lens on the capabilities and limitations of diffusion
models, particularly concerning tasks requiring sequential computation. We
conjecture extensions of our theoretical results, including for the case where
the diffusion model is not perfect, but merely good. We also discuss the wider
context and practical implications, and hypothesize that a machine learning
architecture that can interpolate between sequential and parallel modes of
operation would be superior to both Transformers and diffusion models.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [39] [Spatially Grounded Explanations in Vision Language Models for Document Visual Question Answering](https://arxiv.org/abs/2507.12490)
*Maximiliano Hormazábal Lagos,Héctor Cerezo-Costas,Dimosthenis Karatzas*

Main category: cs.CV

TL;DR: EaGERS是一种无需训练且与模型无关的管道，通过生成自然语言推理和空间区域定位来提高DocVQA任务的性能和透明度。


<details>
  <summary>Details</summary>
Motivation: 为了提高DocVQA任务的透明度和可重复性，同时不需要额外的模型微调。

Method: EaGERS通过生成自然语言推理、计算多模态嵌入相似性并限制响应生成区域来实现其目标。

Result: EaGERS的最佳配置在精确匹配准确率和平均归一化Levenshtein相似度指标上优于基础模型。

Conclusion: EaGERS在DocVQA数据集上表现出色，不仅提高了准确性和相似度指标，还增强了透明度和可重复性。

Abstract: We introduce EaGERS, a fully training-free and model-agnostic pipeline that
(1) generates natural language rationales via a vision language model, (2)
grounds these rationales to spatial sub-regions by computing multimodal
embedding similarities over a configurable grid with majority voting, and (3)
restricts the generation of responses only from the relevant regions selected
in the masked image. Experiments on the DocVQA dataset demonstrate that our
best configuration not only outperforms the base model on exact match accuracy
and Average Normalized Levenshtein Similarity metrics but also enhances
transparency and reproducibility in DocVQA without additional model
fine-tuning.

</details>


### [40] [Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal Large Language Models](https://arxiv.org/abs/2507.12566)
*Gen Luo,Wenhan Dou,Wenhao Li,Zhaokai Wang,Xue Yang,Changyao Tian,Hao Li,Weiyun Wang,Wenhai Wang,Xizhou Zhu,Yu Qiao,Jifeng Dai*

Main category: cs.CV

TL;DR: This paper presents Mono-InternVL and Mono-InternVL-1.5, advanced monolithic MLLMs that improve upon existing models by incorporating visual experts and optimizing pre-training processes. They achieve competitive performance while reducing computational costs.


<details>
  <summary>Details</summary>
Motivation: Existing structures and pre-training strategies for monolithic MLLMs often suffer from unstable optimization and catastrophic forgetting. The paper aims to address these challenges by embedding a new visual parameter space into a pre-trained LLM, enabling stable learning of visual knowledge from noisy data via delta tuning.

Method: The paper introduces Mono-InternVL, a monolithic MLLM that incorporates visual experts through a multimodal mixture-of-experts architecture. It also designs an innovative Endogenous Visual Pre-training (EViP) for Mono-InternVL. For further improvements, Mono-InternVL-1.5 is presented with an improved EViP++ that introduces additional visual attention experts and reorganizes the pre-training process efficiently. During inference, it includes a fused CUDA kernel to speed up MoE operations.

Result: Mono-InternVL outperforms existing monolithic MLLMs on 12 out of 15 benchmarks, such as a +114-point improvement over Emu3 on OCRBench. Compared to its modular counterpart, InternVL-1.5, Mono-InternVL-1.5 achieves similar multimodal performance while reducing first-token latency by up to 69%.

Conclusion: Mono-InternVL-1.5 significantly reduces training and inference costs while maintaining competitive performance with Mono-InternVL. It achieves similar multimodal performance to its modular counterpart, InternVL-1.5, while reducing first-token latency by up to 69%.

Abstract: This paper focuses on monolithic Multimodal Large Language Models (MLLMs),
which integrate visual encoding and language decoding into a single model.
Existing structures and pre-training strategies for monolithic MLLMs often
suffer from unstable optimization and catastrophic forgetting. To address these
challenges, our key idea is to embed a new visual parameter space into a
pre-trained LLM, enabling stable learning of visual knowledge from noisy data
via delta tuning. Based on this principle, we first introduce Mono-InternVL, an
advanced monolithic MLLM that incorporates a set of visual experts through a
multimodal mixture-of-experts architecture. In addition, we design an
innovative Endogenous Visual Pre-training (EViP) for Mono-InternVL to maximize
its visual capabilities via progressive learning. Mono-InternVL achieves
competitive performance against existing MLLMs but also leads to relatively
expensive data cost. Therefore, we further present Mono-InternVL-1.5, a cheaper
and stronger monolithic MLLM equipped with an improved EViP (EViP++). EViP++
introduces additional visual attention experts to Mono-InternVL-1.5 and
re-organizes the pre-training process in an efficient manner. During inference,
it includes a fused CUDA kernel to speed up its MoE operations. With these
designs, Mono-InternVL-1.5 significantly reduces training and inference costs,
while still maintaining competitive performance with Mono-InternVL. To evaluate
our approach, we conduct extensive experiments across 15 benchmarks. Results
demonstrate that Mono-InternVL outperforms existing monolithic MLLMs on 12 out
of 15 benchmarks, e.g., +114-point improvement over Emu3 on OCRBench. Compared
to its modular counterpart, i.e., InternVL-1.5, Mono-InternVL-1.5 achieves
similar multimodal performance while reducing first-token latency by up to 69%.
Code and models are released at https://github.com/OpenGVLab/Mono-InternVL.

</details>


### [41] [VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning](https://arxiv.org/abs/2507.13348)
*Senqiao Yang,Junyi Li,Xin Lai,Bei Yu,Hengshuang Zhao,Jiaya Jia*

Main category: cs.CV

TL;DR: 本文提出了一种名为VisionThink的新方法，用于动态处理不同分辨率的图像，从而在保持性能的同时节省视觉标记。该方法通过强化学习和LLM-as-Judge策略实现了高效的视觉标记压缩，并在多个任务中展示了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的高效视觉语言模型方法通常使用固定的修剪比例或阈值来压缩标记，但在实际应用中，许多场景并不需要如此多的视觉标记。因此，本文旨在提出一种更灵活、自适应的视觉标记压缩方法。

Method: 本文提出了一种基于强化学习的视觉标记压缩方法，称为VisionThink。该方法通过智能决策是否需要更高分辨率的图像来动态处理不同的样本。此外，还提出了LLM-as-Judge策略和精心设计的奖励函数与惩罚机制，以实现稳定的图像缩放调用比例。

Result: 实验结果表明，VisionThink在OCR相关任务中表现出强大的细粒度视觉理解能力，同时在简单任务中节省了大量视觉标记。此外，该方法在一般VQA任务中也展示了优越的性能和效率。

Conclusion: 本文提出了一种新的视觉标记压缩范式VisionThink，它能够根据任务需求动态处理不同分辨率的图像，从而在保持性能的同时节省大量的视觉标记。实验结果表明该方法在OCR相关任务中表现出色，并且在一般VQA任务中也具有优越的效率和有效性。

Abstract: Recent advancements in vision-language models (VLMs) have improved
performance by increasing the number of visual tokens, which are often
significantly longer than text tokens. However, we observe that most real-world
scenarios do not require such an extensive number of visual tokens. While the
performance drops significantly in a small subset of OCR-related tasks, models
still perform accurately in most other general VQA tasks with only 1/4
resolution. Therefore, we propose to dynamically process distinct samples with
different resolutions, and present a new paradigm for visual token compression,
namely, VisionThink. It starts with a downsampled image and smartly decides
whether it is sufficient for problem solving. Otherwise, the model could output
a special token to request the higher-resolution image. Compared to existing
Efficient VLM methods that compress tokens using fixed pruning ratios or
thresholds, VisionThink autonomously decides whether to compress tokens case by
case. As a result, it demonstrates strong fine-grained visual understanding
capability on OCR-related tasks, and meanwhile saves substantial visual tokens
on simpler tasks. We adopt reinforcement learning and propose the LLM-as-Judge
strategy to successfully apply RL to general VQA tasks. Moreover, we carefully
design a reward function and penalty mechanism to achieve a stable and
reasonable image resize call ratio. Extensive experiments demonstrate the
superiority, efficiency, and effectiveness of our method. Our code is available
at https://github.com/dvlab-research/VisionThink.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [42] [Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training](https://arxiv.org/abs/2507.12507)
*Mingjie Liu,Shizhe Diao,Jian Hu,Ximing Lu,Xin Dong,Hao Zhang,Alexander Bukharin,Shaokun Zhang,Jiaqi Zeng,Makesh Narsimhan Sreedhar,Gerald Shen,David Mosallanezhad,Di Zhang,Jonas Yang,June Yang,Oleksii Kuchaiev,Guilin Liu,Zhiding Yu,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong*

Main category: cs.LG

TL;DR: 本文研究了延长强化学习对小型语言模型的影响，并提出了关键的训练方法，使模型在多个推理任务中取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 最近的进展表明，通过链式思维推理和迭代探索来扩展测试时计算可以显著提高复杂任务的表现。这些突破由大规模强化学习（RL）推动，特别是当与可验证的奖励信号结合时。我们想研究延长强化学习对小型语言模型的影响。

Method: 我们研究了延长强化学习对小型语言模型在多个推理领域的影响，并识别了有效训练的关键要素，包括使用可验证的奖励任务、对Group Relative Policy Optimization (GRPO)的增强以及提高训练稳定性和泛化的实用技术。

Result: 我们的模型在数学任务上提升了14.7%，在编程任务上提升了13.9%，在逻辑谜题任务上提升了54.8%。

Conclusion: 我们的模型在数学、编程和逻辑谜题任务上相比强基线有显著提升，并且我们公开了模型以促进持续研究。

Abstract: Recent advancements in reasoning-focused language models such as OpenAI's O1
and DeepSeek-R1 have shown that scaling test-time computation-through
chain-of-thought reasoning and iterative exploration-can yield substantial
improvements on complex tasks like mathematics and code generation. These
breakthroughs have been driven by large-scale reinforcement learning (RL),
particularly when combined with verifiable reward signals that provide
objective and grounded supervision. In this report, we investigate the effects
of prolonged reinforcement learning on a small language model across a diverse
set of reasoning domains. Our work identifies several key ingredients for
effective training, including the use of verifiable reward tasks, enhancements
to Group Relative Policy Optimization (GRPO), and practical techniques to
improve training stability and generalization. We introduce controlled KL
regularization, clipping ratio, and periodic reference policy resets as
critical components for unlocking long-term performance gains. Our model
achieves significant improvements over strong baselines, including +14.7% on
math, +13.9% on coding, and +54.8% on logic puzzle tasks. To facilitate
continued research, we release our model publicly.

</details>


### [43] [A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models](https://arxiv.org/abs/2507.12774)
*Weijieying Ren,Jingxi Zhu,Zehao Liu,Tianxiang Zhao,Vasant Honavar*

Main category: cs.LG

TL;DR: 本文综述了深度学习和大语言模型在电子健康记录建模中的应用，提出了一个统一的分类体系，并讨论了未来的研究方向和挑战。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）数据的固有异质性、时间不规则性和领域特定性给AI在医疗保健中的应用带来了独特的挑战，这些挑战与视觉和自然语言任务中的挑战截然不同。

Method: 本文介绍了五个关键设计维度：数据导向的方法、神经网络架构设计、学习导向策略、多模态学习和基于大语言模型（LLM）的建模系统，并回顾了相关方法以解决数据质量增强、结构和时间表示、自监督学习以及与临床知识的整合问题。

Result: 本文提供了深度学习、大语言模型（LLMs）和EHR建模交叉领域的最新进展的全面概述，并强调了诸如基础模型、LLM驱动的临床代理和EHR到文本的翻译等新兴趋势。

Conclusion: 本文旨在为推进AI驱动的EHR建模和临床决策支持提供一个结构化的路线图。

Abstract: Artificial intelligence (AI) has demonstrated significant potential in
transforming healthcare through the analysis and modeling of electronic health
records (EHRs). However, the inherent heterogeneity, temporal irregularity, and
domain-specific nature of EHR data present unique challenges that differ
fundamentally from those in vision and natural language tasks. This survey
offers a comprehensive overview of recent advancements at the intersection of
deep learning, large language models (LLMs), and EHR modeling. We introduce a
unified taxonomy that spans five key design dimensions: data-centric
approaches, neural architecture design, learning-focused strategies, multimodal
learning, and LLM-based modeling systems. Within each dimension, we review
representative methods addressing data quality enhancement, structural and
temporal representation, self-supervised learning, and integration with
clinical knowledge. We further highlight emerging trends such as foundation
models, LLM-driven clinical agents, and EHR-to-text translation for downstream
reasoning. Finally, we discuss open challenges in benchmarking, explainability,
clinical alignment, and generalization across diverse clinical settings. This
survey aims to provide a structured roadmap for advancing AI-driven EHR
modeling and clinical decision support. For a comprehensive list of EHR-related
methods, kindly refer to https://survey-on-tabular-data.github.io/.

</details>


### [44] [PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database](https://arxiv.org/abs/2507.12805)
*Hui Sun,Yanfeng Ding,Liping Yi,Huidong Ma,Gang Wang,Xiaoguang Liu,Cheng Zhong,Wentong Cai*

Main category: cs.LG

TL;DR: 本文提出了一种新的并行多知识学习压缩器PMKLC，通过四个关键设计显著提升了压缩性能和鲁棒性，并在多个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的无损压缩器在压缩比、压缩和解压吞吐量以及压缩鲁棒性方面存在不足，限制了其在工业和学术界的广泛应用。

Method: 提出了一种基于自动化多知识学习的压缩框架，设计了GPU加速的(s,k)-mer编码器，引入了数据块分割和逐步模型传递机制，并设计了两种压缩模式PMKLC-S和PMKLC-M。

Result: PMKLC-S/M在15个真实世界数据集上与14个基线（7个传统和7个基于学习的）进行基准测试，平均压缩比提升高达73.609%和73.480%，平均吞吐量提升高达3.036倍和10.710倍，并且实现了最佳的鲁棒性和具有竞争力的内存成本。

Conclusion: PMKLC-S/M在压缩比、吞吐量和鲁棒性方面表现出色，表明其在不同数据集上的稳定性和在内存受限设备上的强大能力。

Abstract: Learning-based lossless compressors play a crucial role in large-scale
genomic database backup, storage, transmission, and management. However, their
1) inadequate compression ratio, 2) low compression \& decompression
throughput, and 3) poor compression robustness limit their widespread adoption
and application in both industry and academia. To solve those challenges, we
propose a novel \underline{P}arallel \underline{M}ulti-\underline{K}nowledge
\underline{L}earning-based \underline{C}ompressor (PMKLC) with four crucial
designs: 1) We propose an automated multi-knowledge learning-based compression
framework as compressors' backbone to enhance compression ratio and robustness;
2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compression
throughput and computing resource usage; 3) we introduce data block
partitioning and Step-wise Model Passing (SMP) mechanisms for parallel
acceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meet
the complex application scenarios, where the former runs on a
resource-constrained single GPU and the latter is multi-GPU accelerated. We
benchmark PMKLC-S/M and 14 baselines (7 traditional and 7 leaning-based) on 15
real-world datasets with different species and data sizes. Compared to
baselines on the testing datasets, PMKLC-S/M achieve the average compression
ratio improvement up to 73.609\% and 73.480\%, the average throughput
improvement up to 3.036$\times$ and 10.710$\times$, respectively. Besides,
PMKLC-S/M also achieve the best robustness and competitive memory cost,
indicating its greater stability against datasets with different probability
distribution perturbations, and its strong ability to run on memory-constrained
devices.

</details>


### [45] [Probabilistic Soundness Guarantees in LLM Reasoning Chains](https://arxiv.org/abs/2507.12948)
*Weiqiu You,Anton Xue,Shreya Havaldar,Delip Rao,Helen Jin,Chris Callison-Burch,Eric Wong*

Main category: cs.LG

TL;DR: 本文提出了一种新的概率框架ARES，用于检测大型语言模型生成的推理链中的传播错误，该方法在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的错误检测方法往往无法检测传播错误，因为它们没有正确考虑早期错误如何可能破坏下游推理的判断。

Method: 引入了自回归推理蕴含稳定性（ARES），这是一种新颖的概率框架，通过仅基于之前评估的合理前提来判断每个主张，从而防止错误传播。

Result: ARES在四个基准测试中实现了72.1%的宏F1分数，比现有方法高出8.2分，并在非常长的合成推理链中表现出色，检测传播错误的F1分数达到90.3%，比现有方法高出27.6分。

Conclusion: ARES在四个基准测试中实现了最先进的性能，并在非常长的合成推理链中表现出色，能够有效检测传播错误。

Abstract: In reasoning chains generated by large language models (LLMs), initial errors
often propagate and undermine the reliability of the final conclusion. Current
LLM-based error detection methods often fail to detect propagated errors
because they do not properly account for how earlier errors might corrupt
judgments of downstream reasoning. To better detect such propagated errors, we
introduce Autoregressive Reasoning Entailment Stability (ARES), a novel
probabilistic framework that prevents error propagation by judging each claim
based only on previously-assessed sound premises. This inductive method yields
a nuanced score for each step and provides certified statistical guarantees of
its soundness, rather than a brittle binary label. ARES achieves
state-of-the-art performance across four benchmarks (72.1% Macro-F1, +8.2
points) and demonstrates superior robustness on very long synthetic reasoning
chains, where it excels at detecting propagated errors (90.3% F1, +27.6
points).

</details>


### [46] [Teach Old SAEs New Domain Tricks with Boosting](https://arxiv.org/abs/2507.12990)
*Nikita Koriagin,Yaroslav Aksenov,Daniil Laptev,Gleb Gerasimov,Nikita Balagansky,Daniil Gavrilov*

Main category: cs.LG

TL;DR: 本文提出了一种残差学习方法，通过训练一个次级稀疏自编码器（SAE）来建模预训练SAE在特定领域文本上的重构误差，从而捕捉主模型遗漏的特征。实验表明，该方法在多个专业领域中显著提高了LLM的交叉熵和解释方差指标，同时保持了在通用任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏自编码器（SAE）在解释大型语言模型（LLM）内部表示时表现强大，但往往无法捕捉训练语料库中不常见的领域特定特征。因此，需要一种方法来解决这一问题，而无需完全重新训练SAE。

Method: 本文提出了一种残差学习方法，通过训练一个次级稀疏自编码器（SAE）来建模预训练SAE在特定领域文本上的重构误差，从而捕捉主模型遗漏的特征。在推理过程中，将两个模型的输出相加，以提高性能。

Result: 实验结果表明，该方法在多个专业领域中显著提高了LLM的交叉熵和解释方差指标，同时保持了在通用任务上的性能。此外，该方法能够高效地将新领域的知识整合到现有的SAE中。

Conclusion: 本文提出了一种残差学习方法，能够在不完全重新训练的情况下解决稀疏自编码器（SAE）在特定领域特征上的盲点问题。通过在特定领域文本上训练一个次级SAE来建模预训练SAE的重构误差，有效地捕捉了主模型遗漏的特征。实验表明，该方法在多个专业领域中显著提高了LLM的交叉熵和解释方差指标，同时保持了在通用任务上的性能。这种方法使研究人员能够选择性地增强SAE在特定领域的可解释性，为LLM的定向机制可解释性打开了新的可能性。

Abstract: Sparse Autoencoders have emerged as powerful tools for interpreting the
internal representations of Large Language Models, yet they often fail to
capture domain-specific features not prevalent in their training corpora. This
paper introduces a residual learning approach that addresses this feature
blindness without requiring complete retraining. We propose training a
secondary SAE specifically to model the reconstruction error of a pretrained
SAE on domain-specific texts, effectively capturing features missed by the
primary model. By summing the outputs of both models during inference, we
demonstrate significant improvements in both LLM cross-entropy and explained
variance metrics across multiple specialized domains. Our experiments show that
this method efficiently incorporates new domain knowledge into existing SAEs
while maintaining their performance on general tasks. This approach enables
researchers to selectively enhance SAE interpretability for specific domains of
interest, opening new possibilities for targeted mechanistic interpretability
of LLMs.

</details>


### [47] [Inverse Reinforcement Learning Meets Large Language Model Post-Training: Basics, Advances, and Opportunities](https://arxiv.org/abs/2507.13158)
*Hao Sun,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 本文通过逆强化学习的视角全面回顾了大型语言模型对齐的最新进展，强调了在LLM对齐中使用的强化学习技术与传统强化学习任务的区别。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型（LLM）时代，对齐已成为追求更可靠、可控和强大机器智能的基本但具有挑战性的问题。最近推理模型和对话AI系统的成功突显了强化学习（RL）在增强这些系统中的关键作用，推动了RL和LLM对齐交叉领域的研究兴趣增加。

Method: 本文通过逆强化学习（IRL）的视角全面回顾了LLM对齐的最新进展，强调了在LLM对齐中使用的RL技术与传统RL任务中的区别。

Result: 本文介绍了RL的基础概念，以提供对不熟悉该领域的读者的基础。然后，我们审查了这一研究议程的最新进展，讨论了在LLM对齐中进行IRL的关键挑战和机遇。除了方法论考虑之外，我们还探讨了实际方面，包括数据集、基准测试、评估指标、基础设施以及计算高效的训练和推理技术。最后，我们从稀疏奖励RL的文献中汲取见解，以确定开放问题和潜在的研究方向。

Conclusion: 本文旨在提供一个结构化且批判性的概述，突出未解决的挑战，并概述通过强化学习（RL）和逆强化学习（IRL）技术改进LLM对齐的有希望的未来方向。

Abstract: In the era of Large Language Models (LLMs), alignment has emerged as a
fundamental yet challenging problem in the pursuit of more reliable,
controllable, and capable machine intelligence. The recent success of reasoning
models and conversational AI systems has underscored the critical role of
reinforcement learning (RL) in enhancing these systems, driving increased
research interest at the intersection of RL and LLM alignment. This paper
provides a comprehensive review of recent advances in LLM alignment through the
lens of inverse reinforcement learning (IRL), emphasizing the distinctions
between RL techniques employed in LLM alignment and those in conventional RL
tasks. In particular, we highlight the necessity of constructing neural reward
models from human data and discuss the formal and practical implications of
this paradigm shift. We begin by introducing fundamental concepts in RL to
provide a foundation for readers unfamiliar with the field. We then examine
recent advances in this research agenda, discussing key challenges and
opportunities in conducting IRL for LLM alignment. Beyond methodological
considerations, we explore practical aspects, including datasets, benchmarks,
evaluation metrics, infrastructure, and computationally efficient training and
inference techniques. Finally, we draw insights from the literature on
sparse-reward RL to identify open questions and potential research directions.
By synthesizing findings from diverse studies, we aim to provide a structured
and critical overview of the field, highlight unresolved challenges, and
outline promising future directions for improving LLM alignment through RL and
IRL techniques.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [48] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu,Jielin Qiu,Shiyu Wang,Jianguo Zhang,Zuxin Liu,Roshan Ram,Haolin Chen,Weiran Yao,Huan Wang,Shelby Heinecke,Silvio Savarese,Caiming Xiong*

Main category: cs.AI

TL;DR: 本文提出了一种基于MCP的框架MCPEval，用于自动化评估LLM代理，并在多个领域中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法依赖于静态基准和人工数据收集，限制了实际评估的可行性。需要一种更强大、可扩展的评估框架。

Method: 引入了一个基于模型上下文协议（MCP）的框架，称为MCPEval，用于自动化端到端任务生成和深度评估LLM代理。

Result: 在五个现实领域中的实证结果表明，MCPEval能够有效揭示不同领域中LLM代理的细微性能。

Conclusion: MCPEval能够有效揭示不同领域中LLM代理的细微性能，并通过公开发布促进可重复和标准化的LLM代理评估。

Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [49] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang,Ruiyu Fang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 本文提出了一种解决方案，用于NLPCC 2025任务8的ESC评估，通过大规模语言模型和提示工程及微调技术提高模型生成支持性回应的能力。最佳模型在比赛中排名第二，未来工作将关注情感理解和回应个性化。


<details>
  <summary>Details</summary>
Motivation: 情感支持对话（ESC）旨在通过对话提供共情和有效的心理支持，满足日益增长的心理健康支持需求。

Method: 我们利用大规模语言模型，通过提示工程和微调技术来解决NLPCC 2025任务8的ESC评估问题。我们探索了参数高效的低秩适应和全参数微调策略，以提高模型生成支持性和上下文适当的回应的能力。

Result: 我们的最佳模型在比赛中排名第二，这表明结合大型语言模型和有效的适应方法在ESC任务中具有潜力。

Conclusion: 我们的最佳模型在比赛中排名第二，这表明结合大型语言模型和有效的适应方法在ESC任务中具有潜力。未来的工作将专注于进一步增强情感理解和回应个性化，以构建更实用和可靠的的情感支持系统。

Abstract: Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [50] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
*Ahmed Bahloul,Simon Malberg*

Main category: cs.AI

TL;DR: 本文提出了一种动态强化学习框架，用于改进基于树的推理方法，提高解决方案质量和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的ProbTree框架存在两个关键限制：推理树在初始构建阶段是固定的，无法动态适应中间结果；每个节点需要对所有可能的解决方案策略进行详尽评估，导致计算效率低下。因此，需要一种更高效和灵活的推理方法。

Method: 本文提出了一种动态强化学习框架，将基于树的推理转化为自适应过程。该方法根据实时置信度估计逐步构建推理树，并学习最优的动作选择策略（分解、检索或聚合）。

Result: 本文的方法在保持ProbTree的概率严谨性的同时，通过选择性扩展和集中资源分配提高了解决方案质量和计算效率。实验结果表明，该方法在现实世界问答系统中具有更好的性能。

Conclusion: 本文提出了一种动态强化学习框架，将基于树的推理转化为自适应过程，从而在保持ProbTree的概率严谨性的同时，通过选择性扩展和集中资源分配提高了解决方案质量和计算效率。该工作建立了一个新的树结构推理范式，平衡了概率框架的可靠性与现实世界问答系统所需的灵活性。

Abstract: Modern language models address complex questions through chain-of-thought
(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,
2021), yet struggle with error propagation and knowledge integration.
Tree-structured reasoning methods, particularly the Probabilistic
Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues
by decomposing questions into hierarchical structures and selecting answers
through confidence-weighted aggregation of parametric and retrieved knowledge
(Yao et al., 2023). However, ProbTree's static implementation introduces two
key limitations: (1) the reasoning tree is fixed during the initial
construction phase, preventing dynamic adaptation to intermediate results, and
(2) each node requires exhaustive evaluation of all possible solution
strategies, creating computational inefficiency. We present a dynamic
reinforcement learning (Sutton and Barto, 2018) framework that transforms
tree-based reasoning into an adaptive process. Our approach incrementally
constructs the reasoning tree based on real-time confidence estimates, while
learning optimal policies for action selection (decomposition, retrieval, or
aggregation). This maintains ProbTree's probabilistic rigor while improving
both solution quality and computational efficiency through selective expansion
and focused resource allocation. The work establishes a new paradigm for
treestructured reasoning that balances the reliability of probabilistic
frameworks with the flexibility required for real-world question answering
systems.

</details>


### [51] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
*Carlos Arriaga,Gonzalo Martínez,Eneko Sendin,Javier Conde,Pedro Reviriego*

Main category: cs.AI

TL;DR: 本文提出GEA，一个结合模型能耗信息的评估平台，结果显示用户在了解能耗后更偏好小而高效的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型评估方法存在局限性，如自动化基准测试与人类判断的相关性较差，而人工评估又面临可扩展性和成本问题。同时，模型的能耗问题日益重要，因此需要一种能够考虑能耗因素的评估方法。

Method: 本文介绍了GEA（Generative Energy Arena），这是一个在评估过程中结合模型能耗信息的平台。通过GEA进行初步实验，分析用户在了解能耗情况下的选择倾向。

Result: GEA的初步结果表明，大多数情况下，用户在了解能耗后更倾向于选择小而高效的模型。这说明复杂且高性能的模型在能耗方面的额外成本可能并不值得。

Conclusion: 研究表明，当用户了解模型的能耗时，他们更倾向于选择较小且能效更高的模型。这表明，对于大多数用户交互，复杂且性能更好的模型所增加的成本和能耗并没有带来响应质量的提升，因此不值得使用。

Abstract: The evaluation of large language models is a complex task, in which several
approaches have been proposed. The most common is the use of automated
benchmarks in which LLMs have to answer multiple-choice questions of different
topics. However, this method has certain limitations, being the most
concerning, the poor correlation with the humans. An alternative approach, is
to have humans evaluate the LLMs. This poses scalability issues as there is a
large and growing number of models to evaluate making it impractical (and
costly) to run traditional studies based on recruiting a number of evaluators
and having them rank the responses of the models. An alternative approach is
the use of public arenas, such as the popular LM arena, on which any user can
freely evaluate models on any question and rank the responses of two models.
The results are then elaborated into a model ranking. An increasingly important
aspect of LLMs is their energy consumption and, therefore, evaluating how
energy awareness influences the decisions of humans in selecting a model is of
interest. In this paper, we present GEA, the Generative Energy Arena, an arena
that incorporates information on the energy consumption of the model in the
evaluation process. Preliminary results obtained with GEA are also presented,
showing that for most questions, when users are aware of the energy
consumption, they favor smaller and more energy efficient models. This suggests
that for most user interactions, the extra cost and energy incurred by the more
complex and top-performing models do not provide an increase in the perceived
quality of the responses that justifies their use.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [52] [Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities](https://arxiv.org/abs/2507.13019)
*Liuyi Wang,Xinyuan Xia,Hui Zhao,Hanqing Wang,Tai Wang,Yilun Chen,Chengju Liu,Qijun Chen,Jiangmiao Pang*

Main category: cs.RO

TL;DR: The paper introduces VLN-PE, a physically realistic VLN platform, and evaluates several VLN methods in physical robotic settings, revealing performance issues and inspiring future research.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between recent Vision-and-Language Navigation (VLN) advancements and their idealized assumptions about robot movement and control, which fail to reflect physically embodied deployment challenges.

Method: Introduce VLN-PE, a physically realistic VLN platform supporting different types of robots. Systematically evaluate several ego-centric VLN methods in physical robotic settings across different technical pipelines.

Result: Significant performance degradation due to limited robot observation space, environmental lighting variations, and physical challenges like collisions and falls. Also exposes locomotion constraints for legged robots in complex environments.

Conclusion: VLN-PE provides a new pathway for improving cross-embodiment's overall adaptability and inspires the community to rethink VLN limitations and advance robust, practical VLN models.

Abstract: Recent Vision-and-Language Navigation (VLN) advancements are promising, but
their idealized assumptions about robot movement and control fail to reflect
physically embodied deployment challenges. To bridge this gap, we introduce
VLN-PE, a physically realistic VLN platform supporting humanoid, quadruped, and
wheeled robots. For the first time, we systematically evaluate several
ego-centric VLN methods in physical robotic settings across different technical
pipelines, including classification models for single-step discrete action
prediction, a diffusion model for dense waypoint prediction, and a train-free,
map-based large language model (LLM) integrated with path planning. Our results
reveal significant performance degradation due to limited robot observation
space, environmental lighting variations, and physical challenges like
collisions and falls. This also exposes locomotion constraints for legged
robots in complex environments. VLN-PE is highly extensible, allowing seamless
integration of new scenes beyond MP3D, thereby enabling more comprehensive VLN
evaluation. Despite the weak generalization of current models in physical
deployment, VLN-PE provides a new pathway for improving cross-embodiment's
overall adaptability. We hope our findings and tools inspire the community to
rethink VLN limitations and advance robust, practical VLN models. The code is
available at https://crystalsixone.github.io/vln_pe.github.io/.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [53] [A Survey of AIOps in the Era of Large Language Models](https://arxiv.org/abs/2507.12472)
*Lingzhe Zhang,Tong Jia,Mengxi Jia,Yifan Wu,Aiwei Liu,Yong Yang,Zhonghai Wu,Xuming Hu,Philip S. Yu,Ying Li*

Main category: cs.SE

TL;DR: 本文对LLM在AIOps中的应用进行了详细调查，分析了183篇论文，探讨了失败数据源、任务演变、LLM方法和评估方法，并提出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）日益复杂和普及，它们在各种人工智能运维（AIOps）任务中的应用引起了广泛关注。然而，对LLMs在AIOps中的影响、潜力和局限性的全面理解仍处于初级阶段。

Method: 我们分析了2020年1月至2024年12月间发表的183篇研究论文，以回答四个关键研究问题（RQs）。

Result: 我们详细调查了LLM4AIOps，重点是LLMs如何优化流程并改善该领域结果。我们分析了四个关键研究问题，包括失败数据源、AIOps任务的演变、LLM方法的应用以及评估方法。

Conclusion: 基于我们的发现，我们讨论了最先进的进展和趋势，识别了现有研究中的差距，并提出了未来探索的有前景的方向。

Abstract: As large language models (LLMs) grow increasingly sophisticated and
pervasive, their application to various Artificial Intelligence for IT
Operations (AIOps) tasks has garnered significant attention. However, a
comprehensive understanding of the impact, potential, and limitations of LLMs
in AIOps remains in its infancy. To address this gap, we conducted a detailed
survey of LLM4AIOps, focusing on how LLMs can optimize processes and improve
outcomes in this domain. We analyzed 183 research papers published between
January 2020 and December 2024 to answer four key research questions (RQs). In
RQ1, we examine the diverse failure data sources utilized, including advanced
LLM-based processing techniques for legacy data and the incorporation of new
data sources enabled by LLMs. RQ2 explores the evolution of AIOps tasks,
highlighting the emergence of novel tasks and the publication trends across
these tasks. RQ3 investigates the various LLM-based methods applied to address
AIOps challenges. Finally, RQ4 reviews evaluation methodologies tailored to
assess LLM-integrated AIOps approaches. Based on our findings, we discuss the
state-of-the-art advancements and trends, identify gaps in existing research,
and propose promising directions for future exploration.

</details>


### [54] [A Fuzzy Approach to Project Success: Measuring What Matters](https://arxiv.org/abs/2507.12653)
*João Granja-Correia,Remedios Hernández-Linares,Luca Ferranti,Arménio Rego*

Main category: cs.SE

TL;DR: 本文介绍了一种新的项目成功评估方法，通过将模糊逻辑整合到现有结构中，以更准确地衡量项目成功。


<details>
  <summary>Details</summary>
Motivation: 传统的Likert量表测量常常忽视了项目成功的上下文依赖性和多面性，因此需要一种新的方法来更准确地衡量项目成功。

Method: 本文提出了一个分层的Type-1 Mamdani模糊系统，以优先考虑对最终用户的持续积极影响，减少对次要结果如利益相关者满意度和内部项目成功的关注。

Result: 该动态方法可能提供更准确的项目成功衡量，并且可以适应复杂的评估。

Conclusion: 本文提出了一种新的项目成功评估方法，通过将模糊逻辑整合到现有结构中，可以更准确地衡量项目成功，并可能适用于复杂的评估。

Abstract: This paper introduces a novel approach to project success evaluation by
integrating fuzzy logic into an existing construct. Traditional Likert-scale
measures often overlook the context-dependent and multifaceted nature of
project success. The proposed hierarchical Type-1 Mamdani fuzzy system
prioritizes sustained positive impact for end-users, reducing emphasis on
secondary outcomes like stakeholder satisfaction and internal project success.
This dynamic approach may provide a more accurate measure of project success
and could be adaptable to complex evaluations. Future research will focus on
empirical testing and broader applications of fuzzy logic in social science.

</details>
