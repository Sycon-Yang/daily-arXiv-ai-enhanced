<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 28]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.AI](#cs.AI) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [DrDiff: Dynamic Routing Diffusion with Hierarchical Attention for Breaking the Efficiency-Quality Trade-off](https://arxiv.org/abs/2509.02785)
*Jusheng Zhang,Yijia Fan,Kaitong Cai,Zimeng Huang,Xiaofei Sun,Jian Wang,Chengpei Tang,Keze Wang*

Main category: cs.CL

TL;DR: 本文介绍了DrDiff，一种通过三种核心技术克服效率与质量权衡的长文本生成框架，实验结果表明其优于现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长文本生成中面临效率与质量之间的权衡问题，需要一种更高效且性能优越的框架。

Method: DrDiff通过三种核心技术克服了效率与质量的权衡：动态专家调度机制、分层稀疏注意力（HSA）机制和软吸收引导优化策略。

Result: DrDiff在各种长文本生成基准上进行了全面实验，结果表明其优于现有的SOTA方法。

Conclusion: DrDiff在各种长文本生成基准上表现出色，优于现有的SOTA方法。

Abstract: This paper introduces DrDiff, a novel framework for long-text generation that
overcomes the efficiency-quality trade-off through three core technologies.
First, we design a dynamic expert scheduling mechanism that intelligently
allocates computational resources during the diffusion process based on text
complexity, enabling more efficient handling of text generation tasks of
varying difficulty. Second, we introduce a Hierarchical Sparse Attention (HSA)
mechanism that adaptively adjusts attention patterns according to a variety of
input lengths, reducing computational complexity from O($n^2$) to O($n$) while
maintaining model performance. Finally, we propose a soft absorption guidance
optimization strategy that combines with DPM-solver++ to reduce diffusion
steps, significantly improving generation speed. Comprehensive experiments on
various long-text generation benchmarks demonstrate the superiority of our
DrDiff over the existing SOTA methods.

</details>


### [2] [SSVD: Structured SVD for Parameter-Efficient Fine-Tuning and Benchmarking under Domain Shift in ASR](https://arxiv.org/abs/2509.02830)
*Pu Wang,Shinji Watanabe,Hugo Van hamme*

Main category: cs.CL

TL;DR: 本文在ESPnet中全面集成和基准测试了参数高效微调（PEFT）方法，并引入了结构化SVD引导（SSVD）微调方法，以实现稳健的领域适应和更高的效率。


<details>
  <summary>Details</summary>
Motivation: 参数高效微调（PEFT）已成为适应大型基础模型的可扩展解决方案。虽然低秩适应（LoRA）在语音应用中被广泛使用，但其最先进的变体主要用于语言和视觉任务，而在语音领域的验证有限。

Method: 本文介绍了结构化SVD引导（SSVD）微调方法，该方法选择性地旋转与输入相关的右奇异向量，同时保持与输出相关的向量固定，以保留语义映射。

Result: 本文在域转移的语音识别任务上评估了所有方法，包括儿童语音和方言变化，在从0.1B到2B的模型规模上进行了测试。

Conclusion: 本文提出了结构化SVD引导（SSVD）微调方法，并在ESPnet中全面集成和基准测试了这些PEFT方法，以支持可重复性和未来工作。

Abstract: Parameter-efficient fine-tuning (PEFT) has emerged as a scalable solution for
adapting large foundation models. While low-rank adaptation (LoRA) is widely
used in speech applications, its state-of-the-art variants, e.g., VeRA, DoRA,
PiSSA, and SVFT, are developed mainly for language and vision tasks, with
limited validation in speech. This work presents the first comprehensive
integration and benchmarking of these PEFT methods within ESPnet. We further
introduce structured SVD-guided (SSVD) fine-tuning, which selectively rotates
input-associated right singular vectors while keeping output-associated vectors
fixed to preserve semantic mappings. This design enables robust domain
adaptation with minimal trainable parameters and improved efficiency. We
evaluate all methods on domain-shifted speech recognition tasks, including
child speech and dialectal variation, across model scales from 0.1B to 2B. All
implementations are released in ESPnet to support reproducibility and future
work.

</details>


### [3] [Clustering Discourses: Racial Biases in Short Stories about Women Generated by Large Language Models](https://arxiv.org/abs/2509.02834)
*Gustavo Bonil,João Gondim,Marina dos Santos,Simone Hashiguti,Helena Maia,Nadia Silva,Helio Pedrini,Sandra Avila*

Main category: cs.CL

TL;DR: 该研究分析了LLaMA 3.2-3B模型在葡萄牙语短篇小说中构建黑人和白人女性叙述的方式，发现其文本中存在殖民结构的女性身体框架，研究提出了一种结合机器学习和定性分析的综合方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示大型语言模型在生成关于黑人和白人女性的叙述时可能存在的潜在偏见和历史不平等的再现。

Method: 从2100个文本中应用计算方法对语义相似的故事进行分组，然后进行定性分析。

Result: 分析揭示了语法连贯、看似中立的文本如何体现一种结晶化的、殖民结构的女性身体框架，从而强化了历史不平等。

Conclusion: 研究提出了一种结合机器学习技术和定性手动话语分析的综合方法，以更好地理解大型语言模型在构建关于黑人和白人女性叙述中的潜在偏见和历史不平等的再现。

Abstract: This study investigates how large language models, in particular LLaMA
3.2-3B, construct narratives about Black and white women in short stories
generated in Portuguese. From 2100 texts, we applied computational methods to
group semantically similar stories, allowing a selection for qualitative
analysis. Three main discursive representations emerge: social overcoming,
ancestral mythification and subjective self-realization. The analysis uncovers
how grammatically coherent, seemingly neutral texts materialize a crystallized,
colonially structured framing of the female body, reinforcing historical
inequalities. The study proposes an integrated approach, that combines machine
learning techniques with qualitative, manual discourse analysis.

</details>


### [4] [IDEAlign: Comparing Large Language Models to Human Experts in Open-ended Interpretive Annotations](https://arxiv.org/abs/2509.02855)
*Hyunji Nam,Lucia Langlois,James Malamut,Mei Tan,Dorottya Demszky*

Main category: cs.CL

TL;DR: 本文介绍了IDEAlgin，一种用于评估LLM生成的解释性注释与专家注释对齐程度的基准测试范式，并发现基于向量的度量在捕捉专家意义的相似性方面效果不佳，而通过IDEAlgin提示LLM能显著提高与专家判断的一致性。


<details>
  <summary>Details</summary>
Motivation: 评估LLM生成的注释是否与专家人类生成的注释一致在规模上具有挑战性，目前尚无经过验证的、可扩展的衡量思想相似性的方法。

Method: 引入了IDEAlgin，这是一种直观的基准测试范式，通过“选择异常项”的三元组判断任务来捕捉专家相似性评分，并评估各种相似性度量（包括基于向量的度量和LLM作为评判者）与这些人类基准的对比。

Result: 基于向量的度量在捕捉专家有意义的相似性细微差别方面表现不佳。通过IDEAlgin提示LLM显著提高了与专家判断的一致性（增加了9-30%）。

Conclusion: 这些结果确立了IDEAlgin作为一种有前景的范式，用于大规模评估LLMs与开放式专家注释的对齐程度，为LLMs在教育和其他领域的负责任部署提供了依据。

Abstract: Large language models (LLMs) are increasingly applied to open-ended,
interpretive annotation tasks, such as thematic analysis by researchers or
generating feedback on student work by teachers. These tasks involve free-text
annotations requiring expert-level judgments grounded in specific objectives
(e.g., research questions or instructional goals). Evaluating whether
LLM-generated annotations align with those generated by expert humans is
challenging to do at scale, and currently, no validated, scalable measure of
similarity in ideas exists. In this paper, we (i) introduce the scalable
evaluation of interpretive annotation by LLMs as a critical and understudied
task, (ii) propose IDEAlgin, an intuitive benchmarking paradigm for capturing
expert similarity ratings via a "pick-the-odd-one-out" triplet judgment task,
and (iii) evaluate various similarity metrics, including vector-based ones
(topic models, embeddings) and LLM-as-a-judge via IDEAlgin, against these human
benchmarks. Applying this approach to two real-world educational datasets
(interpretive analysis and feedback generation), we find that vector-based
metrics largely fail to capture the nuanced dimensions of similarity meaningful
to experts. Prompting LLMs via IDEAlgin significantly improves alignment with
expert judgments (9-30% increase) compared to traditional lexical and
vector-based metrics. These results establish IDEAlgin as a promising paradigm
for evaluating LLMs against open-ended expert annotations at scale, informing
responsible deployment of LLMs in education and beyond.

</details>


### [5] [A-SEA3L-QA: A Fully Automated Self-Evolving, Adversarial Workflow for Arabic Long-Context Question-Answer Generation](https://arxiv.org/abs/2509.02864)
*Kesen Wang,Daulet Toibazar,Pedro J. Moreno*

Main category: cs.CL

TL;DR: 我们提出了一种自进化的工作流，用于阿拉伯语的长上下文问答生成，该工作流在没有人工干预的情况下不断改进其性能，并在大规模基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了提高阿拉伯语长上下文问答生成的性能，我们需要一种能够自我改进的系统，而无需人工干预。

Method: 我们提出了一个端到端、自我进化的对抗性工作流，用于阿拉伯语的长上下文问答生成。通过协调多个专业 LVLM：一个问题生成器、一个评估器和一群答案生成器，我们的系统在没有任何人工干预的情况下迭代改进其性能。

Result: 我们发布了 AraLongBench，这是一个大规模的阿拉伯语基准，涵盖了单页和多页挑战，跨越数百页，并展示了我们的自进化工作流在长上下文理解能力方面明显优于静态流水线。

Conclusion: 我们的自进化工作流显著优于静态流水线，显着提升了领先的阿拉伯语大型视觉语言模型（LVLM）的长上下文理解能力。

Abstract: We present an end-to-end, self-evolving adversarial workflow for long-context
Question-Answer (QA) Generation in Arabic. By orchestrating multiple
specialized LVLMs: a question generator, an evaluator, and a swarm of answer
generators, our system iteratively refines its own performance without any
human intervention. Starting from raw, multi-page Arabic documents across
diverse domains, the question generator produces fine-grained, context-aware
queries to be tackled by the answer generator swarm, and the evaluator assesses
and feeds back quality metrics. This closed-loop cycle enables continuous
learning: low-confidence outputs trigger automated re-generation and model
updates, progressively enhancing question difficulty and relevance. Moreover,
we set the quality metrics as a tunable hyperparameter, enabling question
generation at controllable and customizable difficulty levels. We release
AraLongBench, a large-scale Arabic benchmark of single- and multi-page
challenges spanning hundreds of pages, and demonstrate that our self-evolving
workflow substantially outperform static pipelines, markedly boosting the
long-context comprehension capabilities of leading Arabic Large Vision Language
Models (LVLMs). Lastly, we also meticulously architect a fully automated
agentic workflow for long-context Arabic document collection.

</details>


### [6] [Advancing Minority Stress Detection with Transformers: Insights from the Social Media Datasets](https://arxiv.org/abs/2509.02908)
*Santosh Chapagain,Cory J Cascalheira,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi,Jillian R. Scheer*

Main category: cs.CL

TL;DR: 本研究评估了基于变压器的架构在检测在线言论中的少数群体压力方面的表现，并发现图增强可以提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 由于少数群体压力导致性少数群体和性别少数群体的健康状况较差，因此需要一种更有效的检测方法。

Method: 本研究评估了基于变压器的架构在检测在线言论中的少数群体压力方面的表现，并通过图增强来建模社会联系和对话上下文。

Result: 结果表明，整合图结构可以提高检测性能，并且监督微调比零样本和少量样本方法表现更好。

Conclusion: 图增强的变压器在数字健康干预和公共卫生政策中提供了最可靠的基。

Abstract: Individuals from sexual and gender minority groups experience
disproportionately high rates of poor health outcomes and mental disorders
compared to their heterosexual and cisgender counterparts, largely as a
consequence of minority stress as described by Meyer's (2003) model. This study
presents the first comprehensive evaluation of transformer-based architectures
for detecting minority stress in online discourse. We benchmark multiple
transformer models including ELECTRA, BERT, RoBERTa, and BART against
traditional machine learning baselines and graph-augmented variants. We further
assess zero-shot and few-shot learning paradigms to assess their applicability
on underrepresented datasets. Experiments are conducted on the two largest
publicly available Reddit corpora for minority stress detection, comprising
12,645 and 5,789 posts, and are repeated over five random seeds to ensure
robustness. Our results demonstrate that integrating graph structure
consistently improves detection performance across transformer-only models and
that supervised fine-tuning with relational context outperforms zero and
few-shot approaches. Theoretical analysis reveals that modeling social
connectivity and conversational context via graph augmentation sharpens the
models' ability to identify key linguistic markers such as identity
concealment, internalized stigma, and calls for support, suggesting that
graph-enhanced transformers offer the most reliable foundation for digital
health interventions and public health policy.

</details>


### [7] [English Pronunciation Evaluation without Complex Joint Training: LoRA Fine-tuned Speech Multimodal LLM](https://arxiv.org/abs/2509.02915)
*Taekyung Ahn,Hosung Nam*

Main category: cs.CL

TL;DR: 本研究展示了通过LoRA调整的多模态大型语言模型可以同时执行自动发音评估和错误发音检测与诊断，提供了一种更简单、高效的计算机辅助发音训练方法。


<details>
  <summary>Details</summary>
Motivation: 传统上，APA和MDD需要复杂的架构更改或单独的训练过程，而本研究旨在提供一种更简单、高效的解决方案。

Method: 研究使用了微软的Phi-4-multimodal-instruct模型，并通过LoRA方法进行微调，无需复杂的架构更改或单独的训练过程。

Result: 微调后的模型在Speechocean762数据集上表现出与人类评分高度相关的发音评估分数（PCC > 0.7），同时实现了低单词错误率（WER）和音素错误率（PER）（均< 0.15）。仅微调LoRA层即可达到与微调所有音频层相当的性能。

Conclusion: 这项研究表明，通过低秩适应（LoRA）调整的多模态大型语言模型（MLLM）可以同时执行自动发音评估（APA）和错误发音检测与诊断（MDD）。这种高效的方法为英语二语学习者的计算机辅助发音训练（CAPT）技术提供了更易于访问、集成和有效的途径。

Abstract: This study demonstrates that a Multimodal Large Language Model (MLLM) adapted
via Low-Rank Adaptation (LoRA) can perform both Automatic Pronunciation
Assessment (APA) and Mispronunciation Detection and Diagnosis (MDD)
simultaneously. Leveraging Microsoft's Phi-4-multimodal-instruct, our
fine-tuning method eliminates the need for complex architectural changes or
separate training procedures conventionally required for these distinct tasks.
Fine-tuned on the Speechocean762 dataset, the pronunciation evaluation scores
predicted by the model exhibited a strong Pearson Correlation Coefficient (PCC
> 0.7) with human-assigned scores, while achieving low Word Error Rate (WER)
and Phoneme Error Rate (PER) (both < 0.15). Notably, fine-tuning only the LoRA
layers was sufficient to achieve performance levels comparable to those
achieved by fine-tuning all audio layers. This research highlights that an
integrated pronunciation assessment system can be established by adapting large
multimodal models without full fine-tuning, utilizing a significantly simpler
training methodology compared to previous joint models designed for
simultaneous APA and MDD. This efficient LoRA-based approach paves the way for
more accessible, integrated, and effective Computer-Assisted Pronunciation
Training (CAPT) technologies for English L2 learners.

</details>


### [8] [Decoding the Rule Book: Extracting Hidden Moderation Criteria from Reddit Communities](https://arxiv.org/abs/2509.02926)
*Youngwoo Kim,Himanshu Beniwal,Steven L. Johnson,Thomas Hartvigsen*

Main category: cs.CL

TL;DR: 该研究提出了一种从历史审核数据中提取隐式审核标准的方法，揭示了不同社区在内容审核上的差异，并发现了新的审核模式。


<details>
  <summary>Details</summary>
Motivation: 在线社区如subreddits通常有多种隐式标准，而有效的内容审核系统需要明确的分类标准。因此，需要一种方法来识别和提取这些隐式标准。

Method: 该研究使用可解释的架构从历史审核数据中识别和提取隐式标准，并将审核标准表示为与内容删除相关的词汇表达评分表。

Result: 实验表明，这些提取的词汇模式能够有效复制神经审核模型的性能，同时提供透明的决策过程洞察。

Conclusion: 该研究通过提取隐式标准并将其表示为评分表，揭示了不同社区在内容审核上的显著差异，并发现了之前未记录的审核模式。

Abstract: Effective content moderation systems require explicit classification
criteria, yet online communities like subreddits often operate with diverse,
implicit standards. This work introduces a novel approach to identify and
extract these implicit criteria from historical moderation data using an
interpretable architecture. We represent moderation criteria as score tables of
lexical expressions associated with content removal, enabling systematic
comparison across different communities. Our experiments demonstrate that these
extracted lexical patterns effectively replicate the performance of neural
moderation models while providing transparent insights into decision-making
processes. The resulting criteria matrix reveals significant variations in how
seemingly shared norms are actually enforced, uncovering previously
undocumented moderation patterns including community-specific tolerances for
language, features for topical restrictions, and underlying subcategories of
the toxic speech classification.

</details>


### [9] [ProMQA-Assembly: Multimodal Procedural QA Dataset on Assembly](https://arxiv.org/abs/2509.02949)
*Kimihiro Hasegawa,Wiradee Imrattanatrai,Masaki Asada,Susan Holm,Yuran Wang,Vincent Zhou,Ken Fukuda,Teruko Mitamura*

Main category: cs.CL

TL;DR: 本文提出了一种新的多模态QA数据集ProMQA-Assembly，用于评估装配任务中的助手系统。


<details>
  <summary>Details</summary>
Motivation: 目前没有测试平台支持在实际设置中进行面向应用的系统评估，特别是在装配方面。为了促进发展，我们提出了一个关于装配活动的新多模态QA数据集。

Method: 我们采用了一种半自动的QA注释方法，其中LLM生成候选答案，人类进行验证，并通过集成细粒度的动作标签来改进它，以多样化问题类型。此外，我们为组装玩具车辆的目标任务创建了指令任务图。

Result: 我们的结果表明，当前模型有很大的改进空间。

Conclusion: 我们相信我们的新评估数据集可以促进程序性活动助手的进一步发展。

Abstract: Assistants on assembly tasks have a large potential to benefit humans from
everyday tasks to industrial settings. However, no testbeds support
application-oriented system evaluation in a practical setting, especially in
assembly. To foster the development, we propose a new multimodal QA dataset on
assembly activities. Our dataset, ProMQA-Assembly, consists of 391 QA pairs
that require the multimodal understanding of human-activity recordings and
their instruction manuals in an online-style manner. In the development, we
adopt a semi-automated QA annotation approach, where LLMs generate candidates
and humans verify them, as a cost-effective method, and further improve it by
integrating fine-grained action labels to diversify question types.
Furthermore, we create instruction task graphs for the target tasks of
assembling toy vehicles. These newly created task graphs are used in our
benchmarking experiment, as well as to facilitate the human verification
process in the QA annotation. Utilizing our dataset, we benchmark models,
including competitive proprietary multimodal models. Our results suggest great
room for improvement for the current models. We believe our new evaluation
dataset can contribute to the further development of procedural-activity
assistants.

</details>


### [10] [DiaCBT: A Long-Periodic Dialogue Corpus Guided by Cognitive Conceptualization Diagram for CBT-based Psychological Counseling](https://arxiv.org/abs/2509.02999)
*Yougen Zhou,Ningning Zhou,Qin Chen,Jie Zhou,Aimin Zhou,Liang He*

Main category: cs.CL

TL;DR: 本文构建了一个基于认知行为疗法的长期对话语料库，用于训练更专业的咨询代理，结果表明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 由于社会污名和治疗师数量有限，只有少数人能接受心理治疗。因此，需要一种解决方案来扩大心理健康服务的可及性。

Method: 构建基于认知行为疗法的长期对话语料库，并使用认知概念图指导客户模拟，训练深入咨询模型并提出全面评估框架以与既定的心理学标准进行比较。

Result: 结果表明，DiaCBT 有效增强了大型语言模型模拟具有认知行为疗法专业知识的心理学家的能力。

Conclusion: DiaCBT 有效增强了大型语言模型模拟具有认知行为疗法专业知识的心理学家的能力，突显了其在培训更专业的咨询代理方面的潜力。

Abstract: Psychotherapy reaches only a small fraction of individuals suffering from
mental disorders due to social stigma and the limited availability of
therapists. Large language models (LLMs), when equipped with professional
psychotherapeutic skills, offer a promising solution to expand access to mental
health services. However, the lack of psychological conversation datasets
presents significant challenges in developing effective psychotherapy-guided
conversational agents. In this paper, we construct a long-periodic dialogue
corpus for counseling based on cognitive behavioral therapy (CBT). Our curated
dataset includes multiple sessions for each counseling and incorporates
cognitive conceptualization diagrams (CCDs) to guide client simulation across
diverse scenarios. To evaluate the utility of our dataset, we train an in-depth
counseling model and present a comprehensive evaluation framework to benchmark
it against established psychological criteria for CBT-based counseling. Results
demonstrate that DiaCBT effectively enhances LLMs' ability to emulate
psychologists with CBT expertise, underscoring its potential for training more
professional counseling agents.

</details>


### [11] [Mitigating Data Imbalance in Automated Speaking Assessment](https://arxiv.org/abs/2509.03010)
*Fong-Chun Tsai,Kuan-Tang Huang,Bi-Cheng Yan,Tien-Hong Lo,Berlin Chen*

Main category: cs.CL

TL;DR: 该研究提出了一种新的损失函数BLV，用于改善ASA模型在类别不平衡情况下的性能，从而提高分类准确性和公平性。


<details>
  <summary>Details</summary>
Motivation: ASA模型常常受到类别不平衡的影响，导致预测偏差。为了解决这个问题，该研究提出了一种新的目标函数，以提高模型的性能。

Method: 该研究引入了一种名为Balancing Logit Variation (BLV)的损失函数，用于训练ASA模型，以改善少数类的特征表示，而无需修改数据集。

Result: 在ICNALE基准数据集上的评估表明，将BLV损失函数集成到基于文本的(BERT)模型中，显著提高了分类准确性和公平性。

Conclusion: 该研究通过引入BLV损失函数，提高了ASA模型的分类准确性和公平性，使自动化语音评估对多样化的学习者更加稳健。

Abstract: Automated Speaking Assessment (ASA) plays a crucial role in evaluating
second-language (L2) learners proficiency. However, ASA models often suffer
from class imbalance, leading to biased predictions. To address this, we
introduce a novel objective for training ASA models, dubbed the Balancing Logit
Variation (BLV) loss, which perturbs model predictions to improve feature
representation for minority classes without modifying the dataset. Evaluations
on the ICNALE benchmark dataset show that integrating the BLV loss into a
celebrated text-based (BERT) model significantly enhances classification
accuracy and fairness, making automated speech evaluation more robust for
diverse learners.

</details>


### [12] [Training LLMs to be Better Text Embedders through Bidirectional Reconstruction](https://arxiv.org/abs/2509.03020)
*Chang Su,Dengliang Shi,Siyuan Huang,Jintao Du,Changhua Meng,Yu Cheng,Weiqiang Wang,Zhouhan Lin*

Main category: cs.CL

TL;DR: 本文提出在对比学习前增加一个训练阶段，通过双向生成重建任务提升最终标记的语义，从而提高LLM在文本嵌入任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的文本嵌入方法通常利用最终标记的嵌入，通常是保留的特殊标记如[EOS]。然而，这些标记并未被有意训练以捕捉整个上下文的语义，限制了它们作为文本嵌入的能力，尤其是在检索和重新排序任务中。

Method: 我们在对比学习之前添加了一个新的训练阶段，该阶段采用双向生成重建任务，即EBQ2D（基于嵌入的查询到文档）和EBD2Q（基于嵌入的文档到查询），这些任务交织在一起以锚定[EOS]嵌入并重建查询-文档对的任一侧。

Result: 实验结果表明，我们的额外训练阶段显著提高了LLM在MTEB上的性能，实现了不同LLM基础模型和规模的新最先进结果。

Conclusion: 我们的额外训练阶段显著提高了LLM在Massive Text Embedding Benchmark (MTEB)上的性能，实现了不同LLM基础模型和规模的新最先进结果。

Abstract: Large language models (LLMs) have increasingly been explored as powerful text
embedders. Existing LLM-based text embedding approaches often leverage the
embedding of the final token, typically a reserved special token such as [EOS].
However, these tokens have not been intentionally trained to capture the
semantics of the whole context, limiting their capacity as text embeddings,
especially for retrieval and re-ranking tasks. We propose to add a new training
stage before contrastive learning to enrich the semantics of the final token
embedding. This stage employs bidirectional generative reconstruction tasks,
namely EBQ2D (Embedding-Based Query-to-Document) and EBD2Q (Embedding-Based
Document-to-Query), which interleave to anchor the [EOS] embedding and
reconstruct either side of Query-Document pairs. Experimental results
demonstrate that our additional training stage significantly improves LLM
performance on the Massive Text Embedding Benchmark (MTEB), achieving new
state-of-the-art results across different LLM base models and scales.

</details>


### [13] [Structure-Learnable Adapter Fine-Tuning for Parameter-Efficient Large Language Models](https://arxiv.org/abs/2509.03057)
*Ming Gong,Yingnan Deng,Nia Qi,Yujun Zou,Zhihao Xue,Yun Zi*

Main category: cs.CL

TL;DR: 本文提出了一种基于适配器的微调方法，通过结构可学习机制实现参数高效微调，提高了模型的灵活性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型微调中的参数冗余、结构僵化和任务适应性有限的问题。

Method: 提出了一种基于适配器的微调方法，该方法建立在结构可学习机制上，通过引入可微分门控函数和结构稀疏性控制变量，实现了适配器插入点、激活路径和模块组合的自动优化。

Result: 实验结果表明，该方法在多个任务中优于主流的参数高效微调技术，实现了更好的平衡。

Conclusion: 该方法在多个任务中表现出色，实现了准确性、压缩率和对噪声及扰动的鲁棒性之间的更好平衡。

Abstract: This paper addresses the issues of parameter redundancy, rigid structure, and
limited task adaptability in the fine-tuning of large language models. It
proposes an adapter-based fine-tuning method built on a structure-learnable
mechanism. By introducing differentiable gating functions and structural
sparsity control variables, the method enables automatic optimization of
adapter insertion points, activation paths, and module combinations. This
allows the model to adjust its structure flexibly in multi-task settings to
match different task characteristics. With the backbone parameters kept frozen,
the method uses a structure search mechanism to guide the dynamic construction
of task-specific efficient substructures during training. This significantly
improves parameter utilization and representational capacity. In addition, the
paper designs a set of sensitivity analysis experiments to systematically
evaluate the effects of sparsity weight, noise injection ratio, and data
perturbation on model performance. These experiments verify the stability and
robustness of the proposed method across various multi-task natural language
understanding tasks. The experimental results show that the proposed method
outperforms mainstream parameter-efficient tuning techniques on multiple tasks.
It achieves a better balance among accuracy, compression rate, and robustness
to noise and perturbation.

</details>


### [14] [A Long Short-Term Memory (LSTM) Model for Business Sentiment Analysis Based on Recurrent Neural Network](https://arxiv.org/abs/2509.03060)
*Md. Jahidul Islam Razin,Md. Abdul Karim,M. F. Mridha,S M Rafiuddin,Tahira Alam*

Main category: cs.CL

TL;DR: 本文提出了一种改进的RNN模型用于商业情感分析，实验表明其准确率较高，有助于企业分析客户反馈并优化营销策略。


<details>
  <summary>Details</summary>
Motivation: 商业情感分析是自然语言处理中的一个重要和热门话题，可以帮助企业了解客户对产品的看法，从而优化营销策略。传统的RNN模型存在梯度消失问题，因此需要一种改进的方法。

Method: 论文使用了长短期记忆（LSTM）模型，这是一种改进的循环神经网络，以解决梯度消失问题。通过使用产品评论数据集，70%的数据用于训练，30%的数据用于测试，并将结果与其他传统RNN模型进行比较。

Result: 实验结果显示，提出的改进RNN模型在准确率上达到了约91.33%，优于其他传统RNN模型。

Conclusion: 该论文提出了一种改进的循环神经网络（RNN）模型，用于商业情感分析。实验结果表明，该模型在准确率方面优于传统的RNN模型，能够帮助企业和电商平台更好地理解客户反馈并优化营销策略。

Abstract: Business sentiment analysis (BSA) is one of the significant and popular
topics of natural language processing. It is one kind of sentiment analysis
techniques for business purposes. Different categories of sentiment analysis
techniques like lexicon-based techniques and different types of machine
learning algorithms are applied for sentiment analysis on different languages
like English, Hindi, Spanish, etc. In this paper, long short-term memory (LSTM)
is applied for business sentiment analysis, where a recurrent neural network is
used. An LSTM model is used in a modified approach to prevent the vanishing
gradient problem rather than applying the conventional recurrent neural network
(RNN). To apply the modified RNN model, product review dataset is used. In this
experiment, 70\% of the data is trained for the LSTM and the rest 30\% of the
data is used for testing. The result of this modified RNN model is compared
with other conventional RNN models, and a comparison is made among the results.
It is noted that the proposed model performs better than the other conventional
RNN models. Here, the proposed model, i.e., the modified RNN model approach has
achieved around 91.33\% of accuracy. By applying this model, any business
company or e-commerce business site can identify the feedback from their
customers about different types of products that customers like or dislike.
Based on the customer reviews, a business company or e-commerce platform can
evaluate its marketing strategy.

</details>


### [15] [Measuring Scalar Constructs in Social Science with LLMs](https://arxiv.org/abs/2509.03116)
*Hauke Licht,Rupak Sarkar,Patrick Y. Wu,Pranav Goel,Niklas Stoehr,Elliott Ash,Alexander Miserlis Hoyle*

Main category: cs.CL

TL;DR: 本研究评估了LLM在社会科学中测量标量结构的方法，发现通过标记概率加权点评分和微调较小的模型可以提高测量质量。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型（LLMs）是测量标量结构的有吸引力的工具，但它们对数值输出的独特处理方式引发了如何最佳应用它们的问题。我们通过全面评估LLM在社会科学中的标量结构测量方法来解决这些问题。

Method: 我们使用来自政治科学文献的多个数据集评估了四种方法：未加权直接点评分、成对比较的聚合、基于标记概率的点评分和微调。

Result: LLM直接从文本生成点评分会产生不连续的分布，并在任意数字上聚集。通过LLM进行成对比较的质量会提高，但通过标记概率加权点评分会进一步提高。最后，使用最少1000个训练对微调较小的模型可以匹配或超过提示LLM的性能。

Conclusion: 我们的研究为应用研究人员提供了可行的发现。首先，直接从文本生成点评分的LLM会产生不连续的分布，并在任意数字上聚集。通过LLM进行成对比较的质量会提高，但通过标记概率加权点评分会进一步提高。最后，使用最少1000个训练对微调较小的模型可以匹配或超过提示LLM的性能。

Abstract: Many constructs that characterize language, like its complexity or
emotionality, have a naturally continuous semantic structure; a public speech
is not just "simple" or "complex," but exists on a continuum between extremes.
Although large language models (LLMs) are an attractive tool for measuring
scalar constructs, their idiosyncratic treatment of numerical outputs raises
questions of how to best apply them. We address these questions with a
comprehensive evaluation of LLM-based approaches to scalar construct
measurement in social science. Using multiple datasets sourced from the
political science literature, we evaluate four approaches: unweighted direct
pointwise scoring, aggregation of pairwise comparisons,
token-probability-weighted pointwise scoring, and finetuning. Our study yields
actionable findings for applied researchers. First, LLMs prompted to generate
pointwise scores directly from texts produce discontinuous distributions with
bunching at arbitrary numbers. The quality of the measurements improves with
pairwise comparisons made by LLMs, but it improves even more by taking
pointwise scores and weighting them by token probability. Finally, finetuning
smaller models with as few as 1,000 training pairs can match or exceed the
performance of prompted LLMs.

</details>


### [16] [From Evaluation to Defense: Constructing Persistent Edit-Based Fingerprints for Large Language Models](https://arxiv.org/abs/2509.03122)
*Yue Li,Xin Yi,Dongsheng Shi,Yongyi Cui,Gerard de Melo,Xiaoling Wang,Linlin Wang*

Main category: cs.CL

TL;DR: 本文提出了一种新的指纹注入方法FSFT，该方法在大规模微调中表现出色，但仍然存在指纹与相似文本难以区分的问题，需要更强大的指纹注入方法。


<details>
  <summary>Details</summary>
Motivation: 现有的指纹注入方法在模型性能、计算资源和持久性方面存在不足，因此需要一种轻量级且更适合指纹注入的方法。

Method: 本文首次将知识编辑应用于指纹注入，并提出了Fingerprint Subspace-aware Fine-Tuning (FSFT) 方法，通过约束指纹子空间的更新来减少指纹退化。

Result: FSFT方法在大规模微调中表现出优于传统微调的性能，提升了10%。同时，指纹注入模型在区分指纹和相似文本时存在困难。

Conclusion: 本文提出了一种新的指纹注入方法，即Fingerprint Subspace-aware Fine-Tuning (FSFT)，该方法在大规模微调中表现出优于传统微调的性能。同时，文章指出当前指纹注入方法存在不足，需要更强大和细粒度的指纹注入方法。

Abstract: The intellectual property (IP) protection of Large Language Models (LLMs) is
increasingly critical. Injecting specialized fingerprints into LLMs through
instruction tuning is a common IP protection technique. However, this may
significantly degrade model performance, requires substantial computational
resources, and exhibits poor persistence under model modifications. We argue
that knowledge editing offers a lightweight alternative that is more suitable
for fingerprint injection. Accordingly, we apply knowledge editing to
fingerprint injection for the first time and demonstrate its strong capability.
Despite using scrambled text as fingerprints to prevent them from being
overwritten during fine-tuning, degradation still occurs under large-scale
fine-tuning. To address this, we propose Fingerprint Subspace-aware Fine-Tuning
(FSFT), which reduces fingerprint degradation by constraining the update of the
fingerprint subspace. The performance of FSFT exceeds fine-tuning by 10% even
in the worst-case scenario. Additionally, we observe that the
fingerprint-injected models struggle to distinguish between fingerprints and
similar texts due to the high similarity of their features. This finding
underscores the urgent need for more robust and fine-grained fingerprinting
injection methods for LLMs.

</details>


### [17] [An experimental and computational study of an Estonian single-person word naming](https://arxiv.org/abs/2509.03143)
*Kaidi Lõo,Arvi Tavast,Maria Heitmeier,Harald Baayen*

Main category: cs.CL

TL;DR: 本研究探讨了计算模型生成的词汇处理指标在 Estonian 词汇处理中的预测能力，并与传统预测因子进行了比较。研究发现，DLM-based measures 是强大的预测因子，但使用深度学习的 DLM-measures 并不总是更精确。传统预测因子在大多数情况下比 DLM-based 预测因子更精确，除了总注视持续时间。此外，在命名任务中，词汇变量对首次注视持续时间和总注视次数没有预测作用。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨计算模型生成的词汇处理指标是否能预测这些响应变量，并与传统预测因子（如词频、邻域大小和屈折范式大小）进行比较。

Method: 本研究结合了单词命名任务和眼动追踪，分析了五个响应变量（首次注视持续时间、总注视持续时间、注视次数、单词命名延迟和口语单词持续时间），并使用广义可加模型进行分析。计算模型通过线性和深度映射实现。

Result: 首先，DLM-based measures是词汇处理的强大预测因子；其次，使用深度学习的DLM-measures并不一定比使用线性映射的DLM-measures更精确；第三，传统预测因子通常比DLM-based预测因子更精确（除了总注视持续时间，两者拟合度相当）；第四，在命名任务中，词汇变量对首次注视持续时间和总注视次数没有预测作用。

Conclusion: 研究发现，DLM-based measures对于词汇处理具有强大的预测能力，但使用深度学习的DLM-measures并不一定比使用线性映射的DLM-measures更精确。经典预测因子在大多数情况下比DLM-based预测因子更精确，除了总注视持续时间外，两者提供了等效的拟合度。此外，在命名任务中，词汇变量对于首次注视持续时间和总注视次数没有预测作用。

Abstract: This study investigates lexical processing in Estonian. A large-scale
single-subject experiment is reported that combines the word naming task with
eye-tracking. Five response variables (first fixation duration, total fixation
duration, number of fixations, word naming latency, and spoken word duration)
are analyzed with the generalized additive model. Of central interest is the
question of whether measures for lexical processing generated by a
computational model of the mental lexicon (the Discriminative Lexicon Model,
DLM) are predictive for these response variables, and how they compare to
classical predictors such as word frequency, neighborhood size, and
inflectional paradigm size. Computational models were implemented both with
linear and deep mappings. Central findings are, first, that DLM-based measures
are powerful predictors for lexical processing, second, that DLM-measures using
deep learning are not necessarily more precise predictors of lexical processing
than DLM-measures using linear mappings, third, that classical predictors tend
to provide somewhat more precise fits compared to DLM-based predictors (except
for total fixation duration, where the two provide equivalent goodness of fit),
and fourth, that in the naming task lexical variables are not predictive for
first fixation duration and the total number of fixations. As the DLM works
with mappings from form to meaning, the predictivity of DLM-based measures for
total fixation duration, naming latencies, and spoken word duration indicates
that meaning is heavily involved in the present word naming task.

</details>


### [18] [Expanding the WMT24++ Benchmark with Rumantsch Grischun, Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader](https://arxiv.org/abs/2509.03148)
*Jannis Vamvas,Ignacio Pérez Prat,Not Battesta Soliva,Sandra Baltermia-Guetg,Andrina Beeli,Simona Beeli,Madlaina Capeder,Laura Decurtins,Gian Peder Gregori,Flavia Hobi,Gabriela Holderegger,Arina Lazzarini,Viviana Lazzarini,Walter Rosselli,Bettina Vital,Anna Rutkiewicz,Rico Sennrich*

Main category: cs.CL

TL;DR: 本文为六种罗曼什语变体创建了一个基准，并发现翻译从罗曼什语到德语相对较好，但翻译到罗曼什语仍有挑战。


<details>
  <summary>Details</summary>
Motivation: 罗曼什语在瑞士使用，但机器翻译评估资源有限。

Method: 我们创建了六种罗曼什语变体的基准：Rumantsch Grischun和五个地区变体。参考翻译由人类翻译者根据WMT24++基准创建，确保与其他55多种语言的平行性。

Result: 现有MT系统和LLMs的自动评估显示，翻译从罗曼什语到德语对于所有变体来说相对较好，但翻译到罗曼什语仍然具有挑战性。

Conclusion: 翻译从罗曼什语到德语对于所有变体来说相对较好，但翻译到罗曼什语仍然具有挑战性。

Abstract: The Romansh language, spoken in Switzerland, has limited resources for
machine translation evaluation. In this paper, we present a benchmark for six
varieties of Romansh: Rumantsch Grischun, a supra-regional variety, and five
regional varieties: Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader. Our
reference translations were created by human translators based on the WMT24++
benchmark, which ensures parallelism with more than 55 other languages. An
automatic evaluation of existing MT systems and LLMs shows that translation out
of Romansh into German is handled relatively well for all the varieties, but
translation into Romansh is still challenging.

</details>


### [19] [Domain Adaptation of LLMs for Process Data](https://arxiv.org/abs/2509.03161)
*Rafael Seidi Oyamada,Jari Peeperkorn,Jochen De Weerdt,Johannes De Smedt*

Main category: cs.CL

TL;DR: 本研究探索了直接使用预训练大语言模型处理过程数据的方法，通过参数高效微调提高了预测过程监控的性能，并减少了计算开销。


<details>
  <summary>Details</summary>
Motivation: 当前的研究主要集中在提示工程或事件日志到叙述式数据集的转换上，而本研究旨在探索直接适应预训练大语言模型以处理数据的方法，因为这些模型在生成序列令牌方面表现出色。

Method: 研究采用参数高效微调技术，将预训练的大语言模型直接应用于过程数据，而不进行自然语言重写，以利用其生成序列令牌的能力。

Result: 实验结果表明，在预测过程监控任务中，特别是多任务设置中，该方法在预测性能上优于最先进的循环神经网络方法和最近的基于叙述式数据的方法，同时收敛更快，需要的超参数优化更少。

Conclusion: 研究表明，通过参数高效微调预训练大语言模型可以直接处理过程数据，而无需自然语言重写，这在预测过程监控任务中表现出优于现有方法的性能，并且收敛更快，超参数优化需求更少。

Abstract: In recent years, Large Language Models (LLMs) have emerged as a prominent
area of interest across various research domains, including Process Mining
(PM). Current applications in PM have predominantly centered on prompt
engineering strategies or the transformation of event logs into narrative-style
datasets, thereby exploiting the semantic capabilities of LLMs to address
diverse tasks. In contrast, this study investigates the direct adaptation of
pretrained LLMs to process data without natural language reformulation,
motivated by the fact that these models excel in generating sequences of
tokens, similar to the objective in PM. More specifically, we focus on
parameter-efficient fine-tuning techniques to mitigate the computational
overhead typically associated with such models. Our experimental setup focuses
on Predictive Process Monitoring (PPM), and considers both single- and
multi-task predictions. The results demonstrate a potential improvement in
predictive performance over state-of-the-art recurrent neural network (RNN)
approaches and recent narrative-style-based solutions, particularly in the
multi-task setting. Additionally, our fine-tuned models exhibit faster
convergence and require significantly less hyperparameter optimization.

</details>


### [20] [SinhalaMMLU: A Comprehensive Benchmark for Evaluating Multitask Language Understanding in Sinhala](https://arxiv.org/abs/2509.03162)
*Ashmari Pramodya,Nirasha Nelki,Heshan Shalinda,Chamila Liyanage,Yusuke Sakai,Randil Pushpananda,Ruvan Weerasinghe,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: 研究介绍了SinhalaMMLU，这是一个针对僧伽罗语的多项选择题问答基准，评估了26个大型语言模型的表现，发现尽管某些模型表现较好，但整体性能有限，特别是在文化丰富的领域。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言基准测试往往依赖自动翻译，这可能引入错误并歪曲原始文化背景。因此，需要一个专门针对低资源语言和文化特定内容的评估基准。

Method: 引入了SinhalaMMLU，这是首个专为僧伽罗语设计的多项选择题问答基准。该数据集包含超过7,000个问题，涵盖从中学到大学教育水平，并与斯里兰卡国家课程一致，覆盖六个领域和30个学科，包括一般学术主题和文化基础的知识。评估了26个LLMs在SinhalaMMLU上的表现。

Result: 评估了26个LLMs在SinhalaMMLU上的表现，发现Claude 3.5 sonnet和GPT-4o分别达到67%和62%的平均准确率，但整体模型性能有限，尤其在文化丰富的领域如人文学科中表现不佳。

Conclusion: 研究结果表明，尽管Claude 3.5 sonnet和GPT-4o在SinhalaMMLU上表现最佳，但整体模型性能仍然有限，尤其是在文化丰富的领域如人文学科中，显示出在适应低资源和文化特定上下文方面仍有很大改进空间。

Abstract: Large Language Models (LLMs) demonstrate impressive general knowledge and
reasoning abilities, yet their evaluation has predominantly focused on global
or anglocentric subjects, often neglecting low-resource languages and
culturally specific content. While recent multilingual benchmarks attempt to
bridge this gap, many rely on automatic translation, which can introduce errors
and misrepresent the original cultural context. To address this, we introduce
SinhalaMMLU, the first multiple-choice question answering benchmark designed
specifically for Sinhala, a low-resource language. The dataset includes over
7,000 questions spanning secondary to collegiate education levels, aligned with
the Sri Lankan national curriculum, and covers six domains and 30 subjects,
encompassing both general academic topics and culturally grounded knowledge. We
evaluate 26 LLMs on SinhalaMMLU and observe that, while Claude 3.5 sonnet and
GPT-4o achieve the highest average accuracies at 67% and 62% respectively,
overall model performance remains limited. In particular, models struggle in
culturally rich domains such as the Humanities, revealing substantial room for
improvement in adapting LLMs to low-resource and culturally specific contexts.

</details>


### [21] [Comparison of End-to-end Speech Assessment Models for the NOCASA 2025 Challenge](https://arxiv.org/abs/2509.03256)
*Aleksei Žavoronkov,Tanel Alumäe*

Main category: cs.CL

TL;DR: 本文分析了三种用于NOCASA 2025挑战的端到端模型，其中基于GOP-CTC的模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为学习挪威语作为第二语言的儿童提供自动单词级发音评估。

Method: 我们开发了三种端到端模型：E2E-R编码器-解码器Siamese架构、利用预训练wav2vec2.0表示的前缀调整直接分类模型，以及一种结合无需对齐的发音质量（GOP）特征的新型模型。

Result: 我们的GOP-CTC模型在NOCASA 2025挑战中取得了最高性能，显著超越了挑战基准并达到了顶级排行榜成绩。

Conclusion: 我们的GOP-CTC模型在NOCASA 2025挑战中表现最佳，显著超越了基准并取得了顶级排行榜成绩。

Abstract: This paper presents an analysis of three end-to-end models developed for the
NOCASA 2025 Challenge, aimed at automatic word-level pronunciation assessment
for children learning Norwegian as a second language. Our models include an
encoder-decoder Siamese architecture (E2E-R), a prefix-tuned direct
classification model leveraging pretrained wav2vec2.0 representations, and a
novel model integrating alignment-free goodness-of-pronunciation (GOP) features
computed via CTC. We introduce a weighted ordinal cross-entropy loss tailored
for optimizing metrics such as unweighted average recall and mean absolute
error. Among the explored methods, our GOP-CTC-based model achieved the highest
performance, substantially surpassing challenge baselines and attaining top
leaderboard scores.

</details>


### [22] [LatPhon: Lightweight Multilingual G2P for Romance Languages and English](https://arxiv.org/abs/2509.03300)
*Luis Felipe Chary,Miguel Arjona Ramirez*

Main category: cs.CL

TL;DR: LatPhon是一个7.5M参数的Transformer模型，联合训练了六种拉丁语语言，实现了较低的音素错误率，并且适合在设备上部署。


<details>
  <summary>Details</summary>
Motivation: Grapheme-to-phoneme (G2P)转换是文本到语音(TTS)、自动语音识别(ASR)、语音到语音翻译(S2ST)和对齐系统的关键前端，尤其是在多种拉丁语脚本语言中。

Method: LatPhon是一个7.5M参数的Transformer模型，联合训练了六种语言--英语、西班牙语、法语、意大利语、葡萄牙语和罗马尼亚语。

Result: 在公共ipa-dict语料库上，它达到了3.5%的平均音素错误率(PER)，优于字节级ByT5基线(5.4%)，并接近语言特定的WFSTs(3.2%)，同时占用30 MB内存，这使得在设备上部署成为可能。

Conclusion: 这些结果表明，紧凑的多语言G2P可以作为拉丁语语音管道的通用前端。

Abstract: Grapheme-to-phoneme (G2P) conversion is a key front-end for text-to-speech
(TTS), automatic speech recognition (ASR), speech-to-speech translation (S2ST)
and alignment systems, especially across multiple Latin-script languages.We
present LatPhon, a 7.5 M - parameter Transformer jointly trained on six such
languages--English, Spanish, French, Italian, Portuguese, and Romanian. On the
public ipa-dict corpus, it attains a mean phoneme error rate (PER) of 3.5%,
outperforming the byte-level ByT5 baseline (5.4%) and approaching
language-specific WFSTs (3.2%) while occupying 30 MB of memory, which makes
on-device deployment feasible when needed. These results indicate that compact
multilingual G2P can serve as a universal front-end for Latin-language speech
pipelines.

</details>


### [23] [AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?](https://arxiv.org/abs/2509.03312)
*Guibin Zhang,Junhao Wang,Junjie Chen,Wangchunshu Zhou,Kun Wang,Shuicheng Yan*

Main category: cs.CL

TL;DR: 本文提出了一种新的框架AgenTracer，用于自动标注失败的多智能体轨迹，并开发了AgenTracer-8B，一种轻量级的失败追踪器，能够在多智能体交互中高效诊断错误。


<details>
  <summary>Details</summary>
Motivation: 现有的推理大语言模型在处理agentic system failure attribution任务时表现不佳，准确率通常低于10%。

Method: 提出了一种名为AgenTracer的自动化框架，通过反事实重放和程序化故障注入对失败的多智能体轨迹进行注释，并利用该资源开发了AgenTracer-8B，这是一种轻量级的失败追踪器，采用多粒度强化学习进行训练。

Result: AgenTracer-8B在Who&When基准测试中优于Gemini-2.5-Pro和Claude-4-Sonnet等大型专有模型，性能提升了18.18%。此外，它还为MetaGPT和MaAS等现成的多智能体系统带来了4.8-14.2%的性能提升。

Conclusion: AgenTracer-8B能够为多智能体系统提供可操作的反馈，从而实现自我纠正和自我进化。

Abstract: Large Language Model (LLM)-based agentic systems, often comprising multiple
models, complex tool invocations, and orchestration protocols, substantially
outperform monolithic agents. Yet this very sophistication amplifies their
fragility, making them more prone to system failure. Pinpointing the specific
agent or step responsible for an error within long execution traces defines the
task of agentic system failure attribution. Current state-of-the-art reasoning
LLMs, however, remain strikingly inadequate for this challenge, with accuracy
generally below 10%. To address this gap, we propose AgenTracer, the first
automated framework for annotating failed multi-agent trajectories via
counterfactual replay and programmed fault injection, producing the curated
dataset TracerTraj. Leveraging this resource, we develop AgenTracer-8B, a
lightweight failure tracer trained with multi-granular reinforcement learning,
capable of efficiently diagnosing errors in verbose multi-agent interactions.
On the Who&When benchmark, AgenTracer-8B outperforms giant proprietary LLMs
like Gemini-2.5-Pro and Claude-4-Sonnet by up to 18.18%, setting a new standard
in LLM agentic failure attribution. More importantly, AgenTracer-8B delivers
actionable feedback to off-the-shelf multi-agent systems like MetaGPT and MaAS
with 4.8-14.2% performance gains, empowering self-correcting and self-evolving
agentic AI.

</details>


### [24] [LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations](https://arxiv.org/abs/2509.03405)
*Daniela Gottesman,Alon Gilae-Dotan,Ido Cohen,Yoav Gur-Arieh,Marius Mosbach,Ori Yoran,Mor Geva*

Main category: cs.CL

TL;DR: LMEnt是一个用于分析语言模型在预训练过程中知识获取的工具集，包括知识丰富的语料库、高效的实体检索方法和多个预训练模型。


<details>
  <summary>Details</summary>
Motivation: 为了研究语言模型如何将数据转化为对世界的知识和信念表示，需要更深入的理解，以便开发出更一致、稳健和完整的知识表示。

Method: LMEnt引入了一个知识丰富的预训练语料库，基于维基百科并完全标注了实体提及，以及一种基于实体的检索方法，还提供了12个预训练模型和4K个中间检查点。

Result: LMEnt的实体检索方法比之前的方法提高了80.4%，并且提供的模型在知识基准测试中表现与流行的开源模型相当。

Conclusion: LMEnt提供了研究语言模型中知识获取的受控环境，并释放了资源以支持知识表示、可塑性、编辑、归因和学习动态的研究。

Abstract: Language models (LMs) increasingly drive real-world applications that require
world knowledge. However, the internal processes through which models turn data
into representations of knowledge and beliefs about the world, are poorly
understood. Insights into these processes could pave the way for developing LMs
with knowledge representations that are more consistent, robust, and complete.
To facilitate studying these questions, we present LMEnt, a suite for analyzing
knowledge acquisition in LMs during pretraining. LMEnt introduces: (1) a
knowledge-rich pretraining corpus, fully annotated with entity mentions, based
on Wikipedia, (2) an entity-based retrieval method over pretraining data that
outperforms previous approaches by as much as 80.4%, and (3) 12 pretrained
models with up to 1B parameters and 4K intermediate checkpoints, with
comparable performance to popular open-sourced models on knowledge benchmarks.
Together, these resources provide a controlled environment for analyzing
connections between entity mentions in pretraining and downstream performance,
and the effects of causal interventions in pretraining data. We show the
utility of LMEnt by studying knowledge acquisition across checkpoints, finding
that fact frequency is key, but does not fully explain learning trends. We
release LMEnt to support studies of knowledge in LMs, including knowledge
representations, plasticity, editing, attribution, and learning dynamics.

</details>


### [25] [Learning Mechanism Underlying NLP Pre-Training and Fine-Tuning](https://arxiv.org/abs/2509.03407)
*Yarden Tzach,Ronit D. Gross,Ella Koresh,Shalom Rosner,Or Shpringer,Tal Halevi,Ido Kanter*

Main category: cs.CL

TL;DR: 研究了预训练在自然语言处理中的机制及其对微调任务的影响，发现预训练能提高分类任务的准确性，并揭示了其在图像分类任务中的潜在普遍性。


<details>
  <summary>Details</summary>
Motivation: 理解预训练的成功机制以及预训练准确性和微调分类任务之间的相互作用。

Method: 通过分析BERT-6架构在Wikipedia数据集上的预训练和FewRel、DBpedia分类任务上的微调，研究了预训练机制和其对分类任务的影响。

Result: 预训练提高了每个标记的准确性（APT），并将其作为衡量预训练成功的参数。预训练打破了标记之间的对称性，将它们分组为有限的小簇，这在变压器块中逐渐增强。此外，预训练生成了高阶语言结构，并且输出标签预测的置信度与平均输入APT无关。

Conclusion: 预训练在自然语言处理中具有重要作用，其机制与微调任务中的表现密切相关。此外，预训练的原理可能在图像分类任务中也具有普遍性。

Abstract: Natural language processing (NLP) enables the understanding and generation of
meaningful human language, typically using a pre-trained complex architecture
on a large dataset to learn the language and next fine-tune its weights to
implement a specific task. Twofold goals are examined; to understand the
mechanism underlying successful pre-training and to determine the interplay
between the pre-training accuracy and the fine-tuning of classification tasks.
The following main results were obtained; the accuracy per token (APT)
increased with its appearance frequency in the dataset, and its average over
all tokens served as an order parameter to quantify pre-training success, which
increased along the transformer blocks. Pre-training broke the symmetry among
tokens and grouped them into finite, small, strong match token clusters, as
inferred from the presented token confusion matrix. This feature was sharpened
along the transformer blocks toward the output layer, enhancing its performance
considerably compared with that of the embedding layer. Consequently,
higher-order language structures were generated by pre-training, even though
the learning cost function was directed solely at identifying a single token.
These pre-training findings were reflected by the improved fine-tuning accuracy
along the transformer blocks. Additionally, the output label prediction
confidence was found to be independent of the average input APT, as the input
meaning was preserved since the tokens are replaced primarily by strong match
tokens. Finally, although pre-training is commonly absent in image
classification tasks, its underlying mechanism is similar to that used in
fine-tuning NLP classification tasks, hinting at its universality. The results
were based on the BERT-6 architecture pre-trained on the Wikipedia dataset and
fine-tuned on the FewRel and DBpedia classification tasks.

</details>


### [26] [Curse of Knowledge: When Complex Evaluation Context Benefits yet Biases LLM Judges](https://arxiv.org/abs/2509.03419)
*Weiyuan Li,Xintao Wang,Siyu Yuan,Rui Xu,Jiangjie Chen,Qingqing Dong,Yanghua Xiao,Deqing Yang*

Main category: cs.CL

TL;DR: 本文构建了ComplexEval基准测试，研究了复杂任务中评估模型的偏差问题，发现所有模型都易受这些偏差影响，且大型推理模型尤为脆弱。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）能力的提升，它们面临越来越多样和复杂的任务，使得可靠的评估变得具有挑战性。尽管LLMs作为评估者的范式已被提出，但以往的研究主要集中在简单的设置上，而在复杂任务中的可靠性仍缺乏研究。

Method: 本文构建了ComplexEval基准测试，用于系统地暴露和量化辅助信息引起的偏差，并在12个基础和3个高级场景中研究了6种之前未探索的偏差。

Result: 研究发现所有评估的模型都对这些偏差表现出显著的易感性，且偏差的程度随着任务复杂性的增加而增加。值得注意的是，大型推理模型（LRMs）表现出矛盾的脆弱性。

Conclusion: 本文通过深入分析揭示了评估信号的准确性和可验证性的重要性，并为构建更通用和稳健的评估模型指明了方向。

Abstract: As large language models (LLMs) grow more capable, they face increasingly
diverse and complex tasks, making reliable evaluation challenging. The paradigm
of LLMs as judges has emerged as a scalable solution, yet prior work primarily
focuses on simple settings. Their reliability in complex tasks--where
multi-faceted rubrics, unstructured reference answers, and nuanced criteria are
critical--remains understudied. In this paper, we constructed ComplexEval, a
challenge benchmark designed to systematically expose and quantify Auxiliary
Information Induced Biases. We systematically investigated and validated 6
previously unexplored biases across 12 basic and 3 advanced scenarios. Key
findings reveal: (1) all evaluated models exhibit significant susceptibility to
these biases, with bias magnitude scaling with task complexity; (2) notably,
Large Reasoning Models (LRMs) show paradoxical vulnerability. Our in-depth
analysis offers crucial insights for improving the accuracy and verifiability
of evaluation signals, paving the way for more general and robust evaluation
models.

</details>


### [27] [Continuous Saudi Sign Language Recognition: A Vision Transformer Approach](https://arxiv.org/abs/2509.03467)
*Soukeina Elhassen,Lama Al Khuzayem,Areej Alhothali,Ohoud Alzamzami,Nahed Alowaidi*

Main category: cs.CL

TL;DR: 本文介绍了第一个连续的沙特阿拉伯手语数据集KAU-CSSL，并提出了一种基于Transformer的模型，实现了高精度的SSL识别和翻译，为改善SSL社区的交流工具和推动手语研究做出了贡献。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏针对阿拉伯手语（特别是SSL）的资源，现有的技术方法主要集中在非阿拉伯手语上，导致阿拉伯手语的翻译技术不够精确和可靠。因此，需要开发更准确和可靠的翻译技术来解决这一问题。

Method: 我们引入了第一个连续的沙特阿拉伯手语数据集KAU-CSSL，并提出了一种基于Transformer的模型，利用预训练的ResNet-18进行空间特征提取，以及使用Transformer编码器和双向LSTM处理时间依赖性。

Result: 我们提出的模型在签名者依赖模式下达到了99.02%的准确率，在签名者独立模式下达到了77.71%的准确率。

Conclusion: 我们的研究代表了开发SSL资源的重要一步，通过引入第一个连续的沙特阿拉伯手语数据集KAU-CSSL，以及提出一种基于Transformer的模型，实现了高精度的SSL识别和翻译。这不仅改善了SSL社区的交流工具，还对更广泛的签名语言领域做出了重要贡献。

Abstract: Sign language (SL) is an essential communication form for hearing-impaired
and deaf people, enabling engagement within the broader society. Despite its
significance, limited public awareness of SL often leads to inequitable access
to educational and professional opportunities, thereby contributing to social
exclusion, particularly in Saudi Arabia, where over 84,000 individuals depend
on Saudi Sign Language (SSL) as their primary form of communication. Although
certain technological approaches have helped to improve communication for
individuals with hearing impairments, there continues to be an urgent
requirement for more precise and dependable translation techniques, especially
for Arabic sign language variants like SSL. Most state-of-the-art solutions
have primarily focused on non-Arabic sign languages, resulting in a
considerable absence of resources dedicated to Arabic sign language,
specifically SSL. The complexity of the Arabic language and the prevalence of
isolated sign language datasets that concentrate on individual words instead of
continuous speech contribute to this issue. To address this gap, our research
represents an important step in developing SSL resources. To address this, we
introduce the first continuous Saudi Sign Language dataset called KAU-CSSL,
focusing on complete sentences to facilitate further research and enable
sophisticated recognition systems for SSL recognition and translation.
Additionally, we propose a transformer-based model, utilizing a pretrained
ResNet-18 for spatial feature extraction and a Transformer Encoder with
Bidirectional LSTM for temporal dependencies, achieving 99.02\% accuracy at
signer dependent mode and 77.71\% accuracy at signer independent mode. This
development leads the way to not only improving communication tools for the SSL
community but also making a substantial contribution to the wider field of sign
language.

</details>


### [28] [Design and Optimization of Reinforcement Learning-Based Agents in Text-Based Games](https://arxiv.org/abs/2509.03479)
*Haonan Wang,Mingjia Zhao,Junfeng Sun,Wei Liu*

Main category: cs.CL

TL;DR: 本文提出了一种新的代理设计和学习方法，利用深度学习和强化学习来提高文本游戏中的表现，并为更广泛的领域应用奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的进步，研究使用代理玩文本游戏越来越受欢迎。本文提出了一种新的代理设计和学习方法，以强化学习为背景。

Method: 首先应用深度学习模型来处理游戏文本并构建世界模型，然后通过基于策略梯度的深度强化学习方法来学习代理，以促进从状态价值到最优策略的转换。

Result: 增强的代理在几个文本游戏实验中表现更好，并在游戏完成率和获胜率上显著超越了之前的代理。

Conclusion: 本研究为使用强化学习进行文本游戏提供了新的理解和实证基础，并为开发和优化更通用领域的强化学习代理奠定了基础。

Abstract: As AI technology advances, research in playing text-based games with agents
has becomeprogressively popular. In this paper, a novel approach to agent
design and agent learning ispresented with the context of reinforcement
learning. A model of deep learning is first applied toprocess game text and
build a world model. Next, the agent is learned through a policy gradient-based
deep reinforcement learning method to facilitate conversion from state value to
optimal policy.The enhanced agent works better in several text-based game
experiments and significantlysurpasses previous agents on game completion ratio
and win rate. Our study introduces novelunderstanding and empirical ground for
using reinforcement learning for text games and sets thestage for developing
and optimizing reinforcement learning agents for more general domains
andproblems.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [29] [SESGO: Spanish Evaluation of Stereotypical Generative Outputs](https://arxiv.org/abs/2509.03329)
*Melissa Robles,Catalina Bernal,Denniss Raigoso,Mateo Dulce Rubio*

Main category: cs.CY

TL;DR: 本文提出了一种新的文化基础框架，用于检测指令调优大型语言模型中的社会偏见，并展示了该框架在西班牙语文化背景下的有效性。研究发现，针对英语优化的偏见缓解技术在西班牙语任务中效果不佳，且偏见模式在不同采样温度下保持一致。该框架具有模块化特性，可以扩展到新的偏见类别、语言和文化背景，为更公平和文化意识的AI系统评估提供了重要进展。


<details>
  <summary>Details</summary>
Motivation: 当前对多语言大型语言模型（LLMs）的偏见评估存在显著缺口，特别是在西班牙语的文化意识拉丁美洲背景下。现有评估主要集中在美式英语上，未能充分考察其他语言和文化背景下的潜在危害。

Method: 本文采用了一种基于 BBQ 数据集的未明确问题方法，并结合了文化特定的表达和谚语，以检测指令调优大型语言模型中的社会偏见。此外，还提出了一个新指标，将准确性与错误方向相结合，以平衡模型性能和偏见对齐。

Result: 本研究首次系统地评估了领先的商业 LLMs 在西班牙语文化特定偏见上的表现，揭示了不同最先进的模型在偏见表现上的差异。此外，研究还提供了证据表明，针对英语优化的偏见缓解技术在西班牙语任务中效果不佳，且偏见模式在不同采样温度下保持一致。

Conclusion: 本文提出了一种新的文化基础框架，用于检测指令调优大型语言模型中的社会偏见，并展示了该框架在西班牙语文化背景下的有效性。此外，研究还表明，针对英语优化的偏见缓解技术在西班牙语任务中并不有效，且偏见模式在不同采样温度下保持一致。该框架具有模块化特性，可以扩展到新的偏见类别、语言和文化背景，为更公平和文化意识的AI系统评估提供了重要进展。

Abstract: This paper addresses the critical gap in evaluating bias in multilingual
Large Language Models (LLMs), with a specific focus on Spanish language within
culturally-aware Latin American contexts. Despite widespread global deployment,
current evaluations remain predominantly US-English-centric, leaving potential
harms in other linguistic and cultural contexts largely underexamined. We
introduce a novel, culturally-grounded framework for detecting social biases in
instruction-tuned LLMs. Our approach adapts the underspecified question
methodology from the BBQ dataset by incorporating culturally-specific
expressions and sayings that encode regional stereotypes across four social
categories: gender, race, socioeconomic class, and national origin. Using more
than 4,000 prompts, we propose a new metric that combines accuracy with the
direction of error to effectively balance model performance and bias alignment
in both ambiguous and disambiguated contexts. To our knowledge, our work
presents the first systematic evaluation examining how leading commercial LLMs
respond to culturally specific bias in the Spanish language, revealing varying
patterns of bias manifestation across state-of-the-art models. We also
contribute evidence that bias mitigation techniques optimized for English do
not effectively transfer to Spanish tasks, and that bias patterns remain
largely consistent across different sampling temperatures. Our modular
framework offers a natural extension to new stereotypes, bias categories, or
languages and cultural contexts, representing a significant step toward more
equitable and culturally-aware evaluation of AI systems in the diverse
linguistic environments where they operate.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [30] [Mitigating Multimodal Hallucinations via Gradient-based Self-Reflection](https://arxiv.org/abs/2509.03113)
*Shan Wang,Maying Shen,Nadine Chang,Chuong Nguyen,Hongdong Li,Jose M. Alvarez*

Main category: cs.CV

TL;DR: 本文研究了多模态大语言模型中的幻觉问题，提出了基于梯度的自我反思方法来估计不同标记类型的影响，并通过集成到对比解码框架中来减轻文本-视觉偏差和共现偏差，无需额外资源即可有效减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有的缓解方法以启发式方式解决这些偏差，而没有理解实例之间的波动偏差水平。

Method: 我们首先提出使用基于梯度的自我反思方法估计各自标记类型（视觉、提示和先前输出）的影响。估计的标记影响进一步使检测与对象相关的视觉标记并将其集成到一个感知影响的对比解码框架中成为可能，从而同时减轻这两种偏差。

Result: 广泛的实验表明，它有效地减少了幻觉，在LLaVA-QA90上实现了高达92%的准确率提升。

Conclusion: 我们的方法有效地减少了幻觉，实现了LLaVA-QA90上高达92%的准确率提升。

Abstract: Hallucinations in multimodal large language model are caused by the
text-visual bias and the co-occurrence bias. The former reflects an
over-reliance on text information in the decision-making process, while the
latter arises from the statistical object-pairing patterns abstracted from the
training data. Existing mitigation methods heuristically address these biases
without understanding the fluctuating bias level across the instances. We first
propose estimating the influence of respective token types (visual, prompt, and
previous outputs) using a gradient-based self-reflection method. The estimated
token influence further enables the detection of object-related visual tokens
and their integration into an influence-aware contrastive decoding framework to
mitigate both types of biases simultaneously. Our method operates without the
need for additional resources, such as costly fine-tuning, extra models, or
data statistics. Extensive experiments show it effectively reduces
hallucinations, achieving up to a 92% accuracy increase on LLaVA-QA90.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [31] [Language Models Do Not Follow Occam's Razor: A Benchmark for Inductive and Abductive Reasoning](https://arxiv.org/abs/2509.03345)
*Yunxin Sun,Abulhair Saparov*

Main category: cs.AI

TL;DR: This paper evaluates the inductive and abductive reasoning capabilities of large language models (LLMs) using a new dataset called InAbHyD. The results show that LLMs can handle simple scenarios but struggle with complex ones.


<details>
  <summary>Details</summary>
Motivation: Most work focuses exclusively on deductive reasoning, which is problematic since other types of reasoning are also essential in solving real-world problems, and they are less explored.

Method: We introduce a programmable and synthetic dataset, InAbHyD, where each reasoning example consists of an incomplete world model and a set of observations. The task for the intelligent agent is to produce hypotheses to explain observations under the incomplete world model to solve each reasoning example. We propose a new metric to evaluate the quality of hypotheses based on Occam's Razor.

Result: Our analysis shows that LLMs can perform inductive and abductive reasoning in simple scenarios, but struggle with complex world models and producing high-quality hypotheses, even with popular reasoning-enhancing techniques such as in-context learning and RLVR.

Conclusion: LLMs can perform inductive and abductive reasoning in simple scenarios, but struggle with complex world models and producing high-quality hypotheses, even with popular reasoning-enhancing techniques such as in-context learning and RLVR.

Abstract: Reasoning is a core capability in artificial intelligence systems, for which
large language models (LLMs) have recently shown remarkable progress. However,
most work focuses exclusively on deductive reasoning, which is problematic
since other types of reasoning are also essential in solving real-world
problems, and they are less explored. This work focuses on evaluating LLMs'
inductive and abductive reasoning capabilities. We introduce a programmable and
synthetic dataset, InAbHyD (pronounced in-a-bid), where each reasoning example
consists of an incomplete world model and a set of observations. The task for
the intelligent agent is to produce hypotheses to explain observations under
the incomplete world model to solve each reasoning example. We propose a new
metric to evaluate the quality of hypotheses based on Occam's Razor. We
evaluate and analyze some state-of-the-art LLMs. Our analysis shows that LLMs
can perform inductive and abductive reasoning in simple scenarios, but struggle
with complex world models and producing high-quality hypotheses, even with
popular reasoning-enhancing techniques such as in-context learning and RLVR.

</details>


### [32] [Situating AI Agents in their World: Aspective Agentic AI for Dynamic Partially Observable Information Systems](https://arxiv.org/abs/2509.03380)
*Peter J. Bentley,Soo Ling Lim,Fuyuki Ishikawa*

Main category: cs.AI

TL;DR: 本文介绍了一种新的AI代理框架，通过引入'方面'概念，使代理能够以不同方式感知环境，从而实现零信息泄露，提高安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前的AI代理往往是自主聊天机器人，受不可靠的导演控制。需要一种更有效的框架来控制信息，提高安全性和效率。

Method: 本文提出了一种自下而上的框架，将AI代理置于其环境中，所有行为由环境变化触发。引入了'方面'的概念，类似于'umwelt'的想法，使代理能够以不同的方式感知环境。

Result: 与典型架构相比，基于方面的AI代理实现了零信息泄露，证明了该方法的有效性。

Conclusion: 本文提出了一个基于环境的AI代理框架，通过引入'方面'的概念，使代理能够以不同的方式感知环境，从而实现更清晰的信息控制。结果表明，与传统架构相比，这种基于方面的AI代理可以实现零信息泄露，并有望提高安全性和效率。

Abstract: Agentic LLM AI agents are often little more than autonomous chatbots: actors
following scripts, often controlled by an unreliable director. This work
introduces a bottom-up framework that situates AI agents in their environment,
with all behaviors triggered by changes in their environments. It introduces
the notion of aspects, similar to the idea of umwelt, where sets of agents
perceive their environment differently to each other, enabling clearer control
of information. We provide an illustrative implementation and show that
compared to a typical architecture, which leaks up to 83% of the time,
aspective agentic AI enables zero information leakage. We anticipate that this
concept of specialist agents working efficiently in their own information
niches can provide improvements to both security and efficiency.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [33] [Identifiability and minimality bounds of quantum and post-quantum models of classical stochastic processes](https://arxiv.org/abs/2509.03004)
*Paul M. Riechers,Thomas J. Elliott*

Main category: quant-ph

TL;DR: 本文研究了经典随机过程中模型的可识别性问题，并提供了一种比较任何两种模型的方法，无论这些模型是经典、量子还是“后量子”模型。


<details>
  <summary>Details</summary>
Motivation: 为了确定两个不同的模型是否产生相同的可观测行为，即可识别性问题，本文研究了经典随机过程中的模型比较。

Method: 通过将模型映射到一个规范的“广义”隐马尔可夫模型，解决了经典随机过程中模型的可识别性问题。

Result: 本文提供了一种比较任何两种模型的方法，无论这些模型是经典、量子还是“后量子”模型，并能对生成给定经典随机过程所需的量子模型的最小维度进行有时是紧致的限制。

Conclusion: 本文解决了在经典随机过程中模型可识别性问题，并提供了一种比较任何两种模型的方法，无论这些模型是经典、量子还是“后量子”模型。此外，它还能对生成给定经典随机过程所需的量子模型的最小维度进行有时是紧致的限制。

Abstract: To make sense of the world around us, we develop models, constructed to
enable us to replicate, describe, and explain the behaviours we see. Focusing
on the broad case of sequences of correlated random variables, i.e., classical
stochastic processes, we tackle the question of determining whether or not two
different models produce the same observable behavior. This is the problem of
identifiability. Curiously, the physics of the model need not correspond to the
physics of the observations; recent work has shown that it is even advantageous
-- in terms of memory and thermal efficiency -- to employ quantum models to
generate classical stochastic processes. We resolve the identifiability problem
in this regime, providing a means to compare any two models of a classical
process, be the models classical, quantum, or `post-quantum', by mapping them
to a canonical `generalized' hidden Markov model. Further, this enables us to
place (sometimes tight) bounds on the minimal dimension required of a quantum
model to generate a given classical stochastic process.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [34] [Speech DF Arena: A Leaderboard for Speech DeepFake Detection Models](https://arxiv.org/abs/2509.02859)
*Sandipana Dowerah,Atharva Kulkarni,Ajinkya Kulkarni,Hoan My Tran,Joonas Kalda,Artem Fedorchenko,Benoit Fauve,Damien Lolive,Tanel Alumäe,Matthew Magimai Doss*

Main category: cs.SD

TL;DR: 我们引入了Speech DeepFake (DF) Arena，这是第一个用于音频深度伪造检测的综合基准。它提供了一个工具包，可以统一评估检测系统，目前涵盖14个不同的数据集和攻击场景，标准化的评估指标和协议，以及一个排行榜来比较和排名系统。


<details>
  <summary>Details</summary>
Motivation: 尽管深度伪造音频生成技术不断发展，但音频深度伪造检测也取得了显著进展。然而，仍然缺乏标准化和全面的基准。

Method: 我们引入了Speech DeepFake (DF) Arena，这是第一个用于音频深度伪造检测的综合基准。Speech DF Arena提供了一个工具包，可以统一评估检测系统，目前涵盖14个不同的数据集和攻击场景，标准化的评估指标和协议以确保可重复性和透明度。

Result: Speech DF Arena提供了工具包，目前涵盖了14个不同的数据集和攻击场景，标准化的评估指标和协议，以及一个排行榜来比较和排名系统。我们包括了14个评估集，12个最先进的开源和3个专有检测系统。

Conclusion: 我们的研究展示了多个系统在跨领域场景中表现出较高的EER，突显了进行广泛跨领域评估的必要性。

Abstract: Parallel to the development of advanced deepfake audio generation, audio
deepfake detection has also seen significant progress. However, a standardized
and comprehensive benchmark is still missing. To address this, we introduce
Speech DeepFake (DF) Arena, the first comprehensive benchmark for audio
deepfake detection. Speech DF Arena provides a toolkit to uniformly evaluate
detection systems, currently across 14 diverse datasets and attack scenarios,
standardized evaluation metrics and protocols for reproducibility and
transparency. It also includes a leaderboard to compare and rank the systems to
help researchers and developers enhance their reliability and robustness. We
include 14 evaluation sets, 12 state-of-the-art open-source and 3 proprietary
detection systems. Our study presents many systems exhibiting high EER in
out-of-domain scenarios, highlighting the need for extensive cross-domain
evaluation. The leaderboard is hosted on Huggingface1 and a toolkit for
reproducing results across the listed datasets is available on GitHub.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [35] [LimiX: Unleashing Structured-Data Modeling Capability for Generalist Intelligence](https://arxiv.org/abs/2509.03505)
*Xingxuan Zhang,Gang Ren,Han Yu,Hao Yuan,Hui Wang,Jiansheng Li,Jiayun Wu,Lang Mo,Li Mao,Mingchao Hao,Ningbo Dai,Renzhe Xu,Shuyang Li,Tianyang Zhang,Yue He,Yuanrui Wang,Yunjia Zhang,Zijing Xu,Dongzhe Li,Fang Gao,Hao Zou,Jiandong Liu,Jiashuo Liu,Jiawei Xu,Kaijie Cheng,Kehan Li,Linjun Zhou,Qing Li,Shaohua Fan,Xiaoyu Lin,Xinyan Han,Xuanyue Li,Yan Lu,Yuan Xue,Yuanyuan Jiang,Zimu Wang,Zhenlei Wang,Peng Cui*

Main category: cs.LG

TL;DR: LimiX 是一种新的结构化数据模型，能够统一处理多种表格任务，表现出色且无需任务特定的训练。


<details>
  <summary>Details</summary>
Motivation: 为了实现通用智能的进步，需要基于语言、物理世界和结构化数据的互补基础模型。

Method: LimiX 通过查询的条件预测处理表格任务，使用掩码联合分布建模进行预训练，并采用基于上下文的目标进行快速、无训练的适应。

Result: LimiX 在10个大型结构化数据基准测试中表现优于梯度提升树、深度表格网络、最近的表格基础模型和自动集成模型。

Conclusion: LimiX 是一个统一的模型，可以在各种结构化数据任务中表现出色，而无需任务特定的架构或定制训练。

Abstract: We argue that progress toward general intelligence requires complementary
foundation models grounded in language, the physical world, and structured
data. This report presents LimiX, the first installment of our large
structured-data models (LDMs). LimiX treats structured data as a joint
distribution over variables and missingness, thus capable of addressing a wide
range of tabular tasks through query-based conditional prediction via a single
model. LimiX is pretrained using masked joint-distribution modeling with an
episodic, context-conditional objective, where the model predicts for query
subsets conditioned on dataset-specific contexts, supporting rapid,
training-free adaptation at inference. We evaluate LimiX across 10 large
structured-data benchmarks with broad regimes of sample size, feature
dimensionality, class number, categorical-to-numerical feature ratio,
missingness, and sample-to-feature ratios. With a single model and a unified
interface, LimiX consistently surpasses strong baselines including
gradient-boosting trees, deep tabular networks, recent tabular foundation
models, and automated ensembles, as shown in Figure 1 and Figure 2. The
superiority holds across a wide range of tasks, such as classification,
regression, missing value imputation, and data generation, often by substantial
margins, while avoiding task-specific architectures or bespoke training per
task. All LimiX models are publicly accessible under Apache 2.0.

</details>
