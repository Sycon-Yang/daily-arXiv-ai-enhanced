{"id": "2506.19952", "pdf": "https://arxiv.org/pdf/2506.19952", "abs": "https://arxiv.org/abs/2506.19952", "authors": ["Deepon Halder", "Thanmay Jayakumar", "Raj Dabre"], "title": "CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs), despite their ability to perform few-shot\nmachine translation (MT), often lag behind dedicated MT systems trained on\nparallel corpora, which are crucial for high quality machine translation (MT).\nHowever, parallel corpora are often scarce or non-existent for low-resource\nlanguages. In this paper, we propose CycleDistill, a bootstrapping approach\nleveraging LLMs and few-shot translation to obtain high-quality MT systems.\nCycleDistill involves iteratively generating synthetic parallel corpora from\nmonolingual corpora via zero- or few-shot MT, which is then used to fine-tune\nthe model that was used for generating said data for MT. CycleDistill does not\nneed parallel corpora beyond 1 to 4 few-shot examples, and in our experiments\nfocusing on three Indian languages, by relying solely on monolingual corpora,\nit can achieve high-quality machine translation, improving upon a few-shot\nbaseline model by over 20-30 chrF points on average in the first iteration. We\nalso study the effect of leveraging softmax activations during the distillation\nprocess and observe mild improvements in translation quality.", "AI": {"tldr": "This paper introduces CycleDistill, a method that uses LLMs and few-shot translation to create high-quality MT systems without relying on extensive parallel corpora.", "motivation": "The motivation is to address the challenge of scarce or non-existent parallel corpora for low-resource languages, which limits the performance of dedicated MT systems.", "method": "CycleDistill is a bootstrapping approach that iteratively generates synthetic parallel corpora from monolingual corpora using zero- or few-shot MT, which is then used to fine-tune the model for MT.", "result": "In experiments focusing on three Indian languages, CycleDistill achieved high-quality machine translation, improving upon a few-shot baseline model by over 20-30 chrF points on average in the first iteration.", "conclusion": "CycleDistill can achieve high-quality machine translation by leveraging LLMs and few-shot translation, even without extensive parallel corpora."}}
{"id": "2506.19967", "pdf": "https://arxiv.org/pdf/2506.19967", "abs": "https://arxiv.org/abs/2506.19967", "authors": ["Travis Thompson", "Seung-Hwan Lim", "Paul Liu", "Ruoying He", "Dongkuan Xu"], "title": "Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have achieved impressive capabilities in\nlanguage understanding and generation, yet they continue to underperform on\nknowledge-intensive reasoning tasks due to limited access to structured context\nand multi-hop information. Retrieval-Augmented Generation (RAG) partially\nmitigates this by grounding generation in retrieved context, but conventional\nRAG and GraphRAG methods often fail to capture relational structure across\nnodes in knowledge graphs. We introduce Inference-Scaled GraphRAG, a novel\nframework that enhances LLM-based graph reasoning by applying inference-time\ncompute scaling. Our method combines sequential scaling with deep\nchain-of-thought graph traversal, and parallel scaling with majority voting\nover sampled trajectories within an interleaved reasoning-execution loop.\nExperiments on the GRBench benchmark demonstrate that our approach\nsignificantly improves multi-hop question answering performance, achieving\nsubstantial gains over both traditional GraphRAG and prior graph traversal\nbaselines. These findings suggest that inference-time scaling is a practical\nand architecture-agnostic solution for structured knowledge reasoning with LLMs", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6Inference-Scaled GraphRAG\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\u6269\u5c55\u6765\u589e\u5f3a\u57fa\u4e8eLLM\u7684\u56fe\u63a8\u7406\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7684GraphRAG\u548c\u5148\u524d\u7684\u56fe\u904d\u5386\u57fa\u7ebf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u63a8\u7406\u4efb\u52a1\u4e0a\u4ecd\u7136\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u662f\u7531\u4e8e\u5bf9\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u548c\u591a\u8df3\u4fe1\u606f\u7684\u8bbf\u95ee\u6709\u9650\u3002\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u90e8\u5206\u7f13\u89e3\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u4f20\u7edfRAG\u548cGraphRAG\u65b9\u6cd5\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u77e5\u8bc6\u56fe\u8c31\u4e2d\u8282\u70b9\u4e4b\u95f4\u7684\u5173\u7cfb\u7ed3\u6784\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86Inference-Scaled GraphRAG\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5e94\u7528\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\u6269\u5c55\u6765\u589e\u5f3a\u57fa\u4e8eLLM\u7684\u56fe\u63a8\u7406\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u7ed3\u5408\u4e86\u987a\u5e8f\u6269\u5c55\u4e0e\u6df1\u5ea6\u601d\u7ef4\u94fe\u56fe\u904d\u5386\uff0c\u4ee5\u53ca\u5e76\u884c\u6269\u5c55\u4e0e\u5728\u4ea4\u9519\u63a8\u7406-\u6267\u884c\u5faa\u73af\u5185\u7684\u91c7\u6837\u8f68\u8ff9\u4e0a\u7684\u591a\u6570\u6295\u7968\u3002", "result": "\u5728GRBench\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u8df3\u95ee\u7b54\u6027\u80fd\uff0c\u76f8\u5bf9\u4e8e\u4f20\u7edf\u7684GraphRAG\u548c\u5148\u524d\u7684\u56fe\u904d\u5386\u57fa\u7ebf\u53d6\u5f97\u4e86\u663e\u8457\u7684\u63d0\u5347\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\uff0c\u63a8\u7406\u65f6\u7684\u6269\u5c55\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u4e0e\u67b6\u6784\u65e0\u5173\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u4f7f\u7528LLM\u8fdb\u884c\u7ed3\u6784\u5316\u77e5\u8bc6\u63a8\u7406\u3002"}}
{"id": "2506.19998", "pdf": "https://arxiv.org/pdf/2506.19998", "abs": "https://arxiv.org/abs/2506.19998", "authors": ["Xinyi Ni", "Haonan Jian", "Qiuyang Wang", "Vedanshi Chetan Shah", "Pengyu Hong"], "title": "Doc2Agent: Scalable Generation of Tool-Using Agents from API Documentation", "categories": ["cs.CL"], "comment": null, "summary": "REST APIs play important roles in enriching the action space of web agents,\nyet most API-based agents rely on curated and uniform toolsets that do not\nreflect the complexity of real-world APIs. Building tool-using agents for\narbitrary domains remains a major challenge, as it requires reading\nunstructured API documentation, testing APIs and inferring correct parameters.\nWe propose Doc2Agent, a scalable pipeline to build agents that can call\nPython-based tools generated from API documentation. Doc2Agent generates\nexecutable tools from API documentations and iteratively refines them using a\ncode agent. We evaluate our approach on real-world APIs, WebArena APIs, and\nresearch APIs, producing validated tools. We achieved a 55\\% relative\nperformance improvement with 90\\% lower cost compared to direct API calling on\nWebArena benchmark. A domain-specific agent built for glycomaterial science\nfurther demonstrates the pipeline's adaptability to complex, knowledge-rich\ntasks. Doc2Agent offers a generalizable solution for building tool agents from\nunstructured API documentation at scale.", "AI": {"tldr": "Doc2Agent is a scalable pipeline that builds agents capable of calling Python-based tools generated from API documentation, achieving significant performance improvements and demonstrating adaptability to complex tasks.", "motivation": "Building tool-using agents for arbitrary domains remains a major challenge, as it requires reading unstructured API documentation, testing APIs and inferring correct parameters.", "method": "Doc2Agent generates executable tools from API documentations and iteratively refines them using a code agent.", "result": "We achieved a 55% relative performance improvement with 90% lower cost compared to direct API calling on WebArena benchmark. A domain-specific agent built for glycomaterial science further demonstrates the pipeline's adaptability to complex, knowledge-rich tasks.", "conclusion": "Doc2Agent offers a generalizable solution for building tool agents from unstructured API documentation at scale."}}
{"id": "2506.19999", "pdf": "https://arxiv.org/pdf/2506.19999", "abs": "https://arxiv.org/abs/2506.19999", "authors": ["Francesco Ignazio Re", "Andreas Opedal", "Glib Manaiev", "Mario Giulianelli", "Ryan Cotterell"], "title": "A Spatio-Temporal Point Process for Fine-Grained Modeling of Reading Behavior", "categories": ["cs.LG", "cs.CL", "q-bio.NC"], "comment": "ACL 2025", "summary": "Reading is a process that unfolds across space and time, alternating between\nfixations where a reader focuses on a specific point in space, and saccades\nwhere a reader rapidly shifts their focus to a new point. An ansatz of\npsycholinguistics is that modeling a reader's fixations and saccades yields\ninsight into their online sentence processing. However, standard approaches to\nsuch modeling rely on aggregated eye-tracking measurements and models that\nimpose strong assumptions, ignoring much of the spatio-temporal dynamics that\noccur during reading. In this paper, we propose a more general probabilistic\nmodel of reading behavior, based on a marked spatio-temporal point process,\nthat captures not only how long fixations last, but also where they land in\nspace and when they take place in time. The saccades are modeled using a Hawkes\nprocess, which captures how each fixation excites the probability of a new\nfixation occurring near it in time and space. The duration time of fixation\nevents is modeled as a function of fixation-specific predictors convolved\nacross time, thus capturing spillover effects. Empirically, our Hawkes process\nmodel exhibits a better fit to human saccades than baselines. With respect to\nfixation durations, we observe that incorporating contextual surprisal as a\npredictor results in only a marginal improvement in the model's predictive\naccuracy. This finding suggests that surprisal theory struggles to explain\nfine-grained eye movements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6982\u7387\u6a21\u578b\u6765\u6a21\u62df\u9605\u8bfb\u884c\u4e3a\uff0c\u4f46\u53d1\u73b0 surprisal \u7406\u8bba\u5728\u89e3\u91ca\u7cbe\u7ec6\u773c\u52a8\u65b9\u9762\u6548\u679c\u6709\u9650\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6c47\u603b\u7684\u773c\u52a8\u8ffd\u8e2a\u6d4b\u91cf\u548c\u5f3a\u5047\u8bbe\u6a21\u578b\uff0c\u5ffd\u7565\u4e86\u9605\u8bfb\u8fc7\u7a0b\u4e2d\u53d1\u751f\u7684\u8bb8\u591a\u65f6\u7a7a\u52a8\u6001\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6807\u8bb0\u7684\u65f6\u7a7a\u70b9\u8fc7\u7a0b\u7684\u66f4\u901a\u7528\u7684\u6982\u7387\u6a21\u578b\uff0c\u7528\u4e8e\u5efa\u6a21\u9605\u8bfb\u884c\u4e3a\u3002\u5176\u4e2d\uff0csaccades \u4f7f\u7528 Hawkes \u8fc7\u7a0b\u8fdb\u884c\u5efa\u6a21\uff0c\u800c fixation \u6301\u7eed\u65f6\u95f4\u5219\u4f5c\u4e3a\u56fa\u5b9a\u7279\u5b9a\u9884\u6d4b\u56e0\u5b50\u7684\u51fd\u6570\u8fdb\u884c\u5efa\u6a21\u3002", "result": "\u6211\u4eec\u7684 Hawkes \u8fc7\u7a0b\u6a21\u578b\u5728\u62df\u5408\u4eba\u7c7b saccades \u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002\u7136\u800c\uff0c\u5c06\u4e0a\u4e0b\u6587 surprisal \u4f5c\u4e3a\u9884\u6d4b\u56e0\u5b50\u7eb3\u5165\u6a21\u578b\u4ec5\u5e26\u6765\u9884\u6d4b\u51c6\u786e\u6027\u7684\u5fae\u5c0f\u6539\u8fdb\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u53d1\u73b0\uff0c surprisal \u7406\u8bba\u5728\u89e3\u91ca\u7cbe\u7ec6\u7684\u773c\u52a8\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002"}}
{"id": "2506.20073", "pdf": "https://arxiv.org/pdf/2506.20073", "abs": "https://arxiv.org/abs/2506.20073", "authors": ["Kethmi Hirushini Hettige", "Jiahao Ji", "Cheng Long", "Shili Xiang", "Gao Cong", "Jingyuan Wang"], "title": "A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Spatio-temporal data mining plays a pivotal role in informed decision making\nacross diverse domains. However, existing models are often restricted to narrow\ntasks, lacking the capacity for multi-task inference and complex long-form\nreasoning that require generation of in-depth, explanatory outputs. These\nlimitations restrict their applicability to real-world, multi-faceted decision\nscenarios. In this work, we introduce STReason, a novel framework that\nintegrates the reasoning strengths of large language models (LLMs) with the\nanalytical capabilities of spatio-temporal models for multi-task inference and\nexecution. Without requiring task-specific finetuning, STReason leverages\nin-context learning to decompose complex natural language queries into modular,\ninterpretable programs, which are then systematically executed to generate both\nsolutions and detailed rationales. To facilitate rigorous evaluation, we\nconstruct a new benchmark dataset and propose a unified evaluation framework\nwith metrics specifically designed for long-form spatio-temporal reasoning.\nExperimental results show that STReason significantly outperforms advanced LLM\nbaselines across all metrics, particularly excelling in complex,\nreasoning-intensive spatio-temporal scenarios. Human evaluations further\nvalidate STReason's credibility and practical utility, demonstrating its\npotential to reduce expert workload and broaden the applicability to real-world\nspatio-temporal tasks. We believe STReason provides a promising direction for\ndeveloping more capable and generalizable spatio-temporal reasoning systems.", "AI": {"tldr": "STReason is a novel framework that combines the reasoning strengths of large language models with spatio-temporal models to enable multi-task inference and execution without task-specific finetuning. It decomposes complex queries into interpretable programs and generates detailed rationales. STReason outperforms existing models in spatio-temporal reasoning tasks and has practical applications in real-world scenarios.", "motivation": "Existing models are often restricted to narrow tasks, lacking the capacity for multi-task inference and complex long-form reasoning that require generation of in-depth, explanatory outputs. These limitations restrict their applicability to real-world, multi-faceted decision scenarios.", "method": "STReason integrates the reasoning strengths of large language models (LLMs) with the analytical capabilities of spatio-temporal models for multi-task inference and execution. It leverages in-context learning to decompose complex natural language queries into modular, interpretable programs, which are then systematically executed to generate both solutions and detailed rationales.", "result": "Experimental results show that STReason significantly outperforms advanced LLM baselines across all metrics, particularly excelling in complex, reasoning-intensive spatio-temporal scenarios. Human evaluations further validate STReason's credibility and practical utility, demonstrating its potential to reduce expert workload and broaden the applicability to real-world spatio-temporal tasks.", "conclusion": "STReason provides a promising direction for developing more capable and generalizable spatio-temporal reasoning systems."}}
{"id": "2506.20081", "pdf": "https://arxiv.org/pdf/2506.20081", "abs": "https://arxiv.org/abs/2506.20081", "authors": ["Dhruv Gupta", "Gayathri Ganesh Lakshmy", "Yiqing Xie"], "title": "SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Code Generation (RACG) is a critical technique for\nenhancing code generation by retrieving relevant information. In this work, we\nconduct an in-depth analysis of code retrieval by systematically masking\nspecific features while preserving code functionality. Our discoveries include:\n(1) although trained on code, current retrievers heavily rely on surface-level\ntextual features (e.g., docstrings, identifier names), and (2) they exhibit a\nstrong bias towards well-documented code, even if the documentation is\nirrelevant.Based on our discoveries, we propose SACL, a framework that enriches\ntextual information and reduces bias by augmenting code or structural knowledge\nwith semantic information. Extensive experiments show that SACL substantially\nimproves code retrieval (e.g., by 12.8% / 9.4% / 7.0% Recall@1 on HumanEval /\nMBPP / SWE-Bench-Lite), which also leads to better code generation performance\n(e.g., by 4.88% Pass@1 on HumanEval).", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4ee3\u7801\u68c0\u7d22\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86SACL\u6846\u67b6\u4ee5\u63d0\u9ad8\u4ee3\u7801\u68c0\u7d22\u548c\u751f\u6210\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u68c0\u7d22\u5668\u8fc7\u5ea6\u4f9d\u8d56\u8868\u9762\u6587\u672c\u7279\u5f81\uff0c\u5e76\u4e14\u5bf9\u826f\u597d\u6587\u6863\u7684\u4ee3\u7801\u6709\u5f88\u5f3a\u7684\u504f\u89c1\uff0c\u5373\u4f7f\u6587\u6863\u65e0\u5173\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5730\u5c4f\u853d\u7279\u5b9a\u7279\u5f81\u6765\u5206\u6790\u4ee3\u7801\u68c0\u7d22\uff0c\u5e76\u63d0\u51faSACL\u6846\u67b6\u6765\u4e30\u5bcc\u6587\u672c\u4fe1\u606f\u548c\u51cf\u5c11\u504f\u5dee\u3002", "result": "SACL\u5728\u4ee3\u7801\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f8b\u5982\u5728HumanEval\u3001MBPP\u548cSWE-Bench-Lite\u4e0a\u7684Recall@1\u5206\u522b\u63d0\u9ad8\u4e8612.8% / 9.4% / 7.0%\uff0c\u5e76\u4e14\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u4e5f\u6709\u6240\u63d0\u5347\uff0c\u4f8b\u5982\u5728HumanEval\u4e0a\u7684Pass@1\u63d0\u9ad8\u4e864.88%\u3002", "conclusion": "SACL\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7801\u68c0\u7d22\u548c\u4ee3\u7801\u751f\u6210\u6027\u80fd\uff0c\u8868\u660e\u901a\u8fc7\u589e\u5f3a\u6587\u672c\u4fe1\u606f\u548c\u51cf\u5c11\u504f\u5dee\u53ef\u4ee5\u6539\u5584\u4ee3\u7801\u68c0\u7d22\u6548\u679c\u3002"}}
{"id": "2506.20083", "pdf": "https://arxiv.org/pdf/2506.20083", "abs": "https://arxiv.org/abs/2506.20083", "authors": ["Yingji Zhang", "Danilo S. Carvalho", "Andr\u00e9 Freitas"], "title": "Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder", "categories": ["cs.CL"], "comment": "In progress", "summary": "Integrating compositional and symbolic properties into current distributional\nsemantic spaces can enhance the interpretability, controllability,\ncompositionality, and generalisation capabilities of Transformer-based\nauto-regressive language models (LMs). In this survey, we offer a novel\nperspective on latent space geometry through the lens of compositional\nsemantics, a direction we refer to as \\textit{semantic representation\nlearning}. This direction enables a bridge between symbolic and distributional\nsemantics, helping to mitigate the gap between them. We review and compare\nthree mainstream autoencoder architectures-Variational AutoEncoder (VAE),\nVector Quantised VAE (VQVAE), and Sparse AutoEncoder (SAE)-and examine the\ndistinctive latent geometries they induce in relation to semantic structure and\ninterpretability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89c6\u89d2\u6765\u7406\u89e3\u6f5c\u5728\u7a7a\u95f4\u51e0\u4f55\uff0c\u5373\u8bed\u4e49\u8868\u793a\u5b66\u4e60\uff0c\u65e8\u5728\u5c06\u7ec4\u5408\u6027\u548c\u7b26\u53f7\u6027\u5c5e\u6027\u6574\u5408\u5230\u5206\u5e03\u8bed\u4e49\u7a7a\u95f4\u4e2d\uff0c\u4ee5\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7684\u5206\u5e03\u8bed\u4e49\u7a7a\u95f4\u5728\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u63a7\u6027\u3001\u7ec4\u5408\u6027\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u9700\u8981\u5c06\u7ec4\u5408\u6027\u548c\u7b26\u53f7\u6027\u5c5e\u6027\u6574\u5408\u5230\u8fd9\u4e9b\u7a7a\u95f4\u4e2d\uff0c\u4ece\u800c\u4fc3\u8fdb\u7b26\u53f7\u8bed\u4e49\u548c\u5206\u5e03\u8bed\u4e49\u4e4b\u95f4\u7684\u6865\u6881\u5efa\u7acb\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u4e09\u79cd\u4e3b\u6d41\u7684\u81ea\u7f16\u7801\u5668\u67b6\u6784\uff08\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u3001\u5411\u91cf\u91cf\u5316\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VQVAE\uff09\u548c\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\uff09\uff0c\u63a2\u8ba8\u4e86\u5b83\u4eec\u5728\u8bed\u4e49\u7ed3\u6784\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u6f5c\u5728\u51e0\u4f55\u7279\u6027\u3002", "result": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u4e09\u79cd\u4e3b\u6d41\u7684\u81ea\u7f16\u7801\u5668\u67b6\u6784\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u5728\u8bed\u4e49\u7ed3\u6784\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u6f5c\u5728\u51e0\u4f55\u7279\u6027\uff0c\u4e3a\u8bed\u4e49\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002", "conclusion": "\u5c06\u7ec4\u5408\u6027\u548c\u7b26\u53f7\u6027\u5c5e\u6027\u6574\u5408\u5230\u5f53\u524d\u7684\u5206\u5e03\u8bed\u4e49\u7a7a\u95f4\u4e2d\u53ef\u4ee5\u589e\u5f3a\u57fa\u4e8eTransformer\u7684\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\uff08LM\uff09\u7684\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u63a7\u6027\u3001\u7ec4\u5408\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u901a\u8fc7\u7ec4\u5408\u8bed\u4e49\u7684\u89c6\u89d2\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u5173\u4e8e\u6f5c\u5728\u7a7a\u95f4\u51e0\u4f55\u7684\u65b0\u89c2\u70b9\uff0c\u5373\u8bed\u4e49\u8868\u793a\u5b66\u4e60\uff0c\u8fd9\u6709\u52a9\u4e8e\u5f25\u5408\u7b26\u53f7\u8bed\u4e49\u548c\u5206\u5e03\u8bed\u4e49\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u6211\u4eec\u56de\u987e\u5e76\u6bd4\u8f83\u4e86\u4e09\u79cd\u4e3b\u6d41\u7684\u81ea\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5e76\u7814\u7a76\u4e86\u5b83\u4eec\u5728\u8bed\u4e49\u7ed3\u6784\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u6f5c\u5728\u51e0\u4f55\u7279\u6027\u3002"}}
{"id": "2506.20093", "pdf": "https://arxiv.org/pdf/2506.20093", "abs": "https://arxiv.org/abs/2506.20093", "authors": ["Yilin Wang", "Peixuan Lei", "Jie Song", "Yuzhe Hao", "Tao Chen", "Yuxuan Zhang", "Lei Jia", "Yuanxiang Li", "Zhongyu Wei"], "title": "ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset", "categories": ["cs.CL"], "comment": null, "summary": "Time-series data are critical in diverse applications, such as industrial\nmonitoring, medical diagnostics, and climate research. However, effectively\nintegrating these high-dimensional temporal signals with natural language for\ndynamic, interactive tasks remains a significant challenge. To address this, we\nintroduce the Time-Series Question Answering (Time-Series QA) task and release\nEngineMT-QA, the first large-scale, multi-task, temporal-textual QA dataset\ndesigned to capture complex interactions between time-series signals and\nnatural language. Building on this resource, we propose the Instruct Time\nTransformer (ITFormer), a novel framework that bridges time-series encoders\nwith frozen large language models (LLMs). ITFormer effectively extracts,\naligns, and fuses temporal and textual features, achieving a strong improvement\nin QA accuracy over strong baselines with fewer than 1\\% additional trainable\nparameters. By combining computational efficiency with robust cross-modal\nmodeling, our work establishes a adaptable paradigm for integrating temporal\ndata with natural language, paving the way for new research and applications in\nmulti-modal AI. More details about the project, including datasets and code,\nare available at: https://pandalin98.github.io/itformer_site/", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Time-Series QA\u4efb\u52a1\u548cEngineMT-QA\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e86ITFormer\u6846\u67b6\uff0c\u4ee5\u6709\u6548\u6574\u5408\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0e\u81ea\u7136\u8bed\u8a00\uff0c\u63d0\u9ad8QA\u51c6\u786e\u7387\u3002", "motivation": "\u6709\u6548\u6574\u5408\u9ad8\u7ef4\u65f6\u95f4\u5e8f\u5217\u4fe1\u53f7\u4e0e\u81ea\u7136\u8bed\u8a00\u5bf9\u4e8e\u52a8\u6001\u3001\u4ea4\u4e92\u5f0f\u4efb\u52a1\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86Instruct Time Transformer (ITFormer)\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u65f6\u95f4\u5e8f\u5217\u7f16\u7801\u5668\u4e0e\u51bb\u7ed3\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7ed3\u5408\uff0c\u4ee5\u6709\u6548\u5730\u63d0\u53d6\u3001\u5bf9\u9f50\u548c\u878d\u5408\u65f6\u95f4\u5e8f\u5217\u548c\u6587\u672c\u7279\u5f81\u3002", "result": "ITFormer\u5728QA\u51c6\u786e\u7387\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u63d0\u5347\uff0c\u4e14\u4ec5\u4f7f\u7528\u4e86\u4e0d\u52301%\u7684\u989d\u5916\u53ef\u8bad\u7ec3\u53c2\u6570\u3002", "conclusion": "\u901a\u8fc7\u5c06\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0e\u81ea\u7136\u8bed\u8a00\u76f8\u7ed3\u5408\uff0c\u6211\u4eec\u7684\u5de5\u4f5c\u4e3a\u591a\u6a21\u6001AI\u5f00\u8f9f\u4e86\u65b0\u7684\u7814\u7a76\u548c\u5e94\u7528\u65b9\u5411\u3002"}}
{"id": "2506.20100", "pdf": "https://arxiv.org/pdf/2506.20100", "abs": "https://arxiv.org/abs/2506.20100", "authors": ["Vardhan Dongre", "Chi Gui", "Shubham Garg", "Hooshang Nayyeri", "Gokhan Tur", "Dilek Hakkani-T\u00fcr", "Vikram S. Adve"], "title": "MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": "66 pages, 32 figures, 23 tables", "summary": "We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning\nand decision-making in consultative interaction settings. Designed for the\nagriculture domain, MIRAGE captures the full complexity of expert consultations\nby combining natural user queries, expert-authored responses, and image-based\ncontext, offering a high-fidelity benchmark for evaluating models on grounded\nreasoning, clarification strategies, and long-form generation in a real-world,\nknowledge-intensive domain. Grounded in over 35,000 real user-expert\ninteractions and curated through a carefully designed multi-step pipeline,\nMIRAGE spans diverse crop health, pest diagnosis, and crop management\nscenarios. The benchmark includes more than 7,000 unique biological entities,\ncovering plant species, pests, and diseases, making it one of the most\ntaxonomically diverse benchmarks available for vision-language models, grounded\nin the real world. Unlike existing benchmarks that rely on well-specified user\ninputs and closed-set taxonomies, MIRAGE features underspecified, context-rich\nscenarios with open-world settings, requiring models to infer latent knowledge\ngaps, handle rare entities, and either proactively guide the interaction or\nrespond. Project Page: https://mirage-benchmark.github.io", "AI": {"tldr": "MIRAGE \u662f\u4e00\u4e2a\u65b0\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728\u519c\u4e1a\u9886\u57df\u7684\u591a\u6a21\u6001\u4e13\u5bb6\u7ea7\u63a8\u7406\u548c\u51b3\u7b56\u80fd\u529b\uff0c\u5177\u6709\u9ad8\u4fdd\u771f\u5ea6\u548c\u5f00\u653e\u4e16\u754c\u8bbe\u7f6e\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u4f9d\u8d56\u4e8e\u660e\u786e\u7684\u7528\u6237\u8f93\u5165\u548c\u5c01\u95ed\u96c6\u5206\u7c7b\u6cd5\uff0c\u800c MIRAGE \u63d0\u4f9b\u4e86\u672a\u660e\u786e\u6307\u5b9a\u3001\u5bcc\u542b\u4e0a\u4e0b\u6587\u7684\u5f00\u653e\u4e16\u754c\u8bbe\u7f6e\uff0c\u8981\u6c42\u6a21\u578b\u63a8\u65ad\u9690\u542b\u7684\u77e5\u8bc6\u7a7a\u767d\uff0c\u5904\u7406\u7f55\u89c1\u5b9e\u4f53\uff0c\u5e76\u4e3b\u52a8\u5f15\u5bfc\u4ea4\u4e92\u6216\u4f5c\u51fa\u56de\u5e94\u3002", "method": "MIRAGE \u7ed3\u5408\u4e86\u81ea\u7136\u7528\u6237\u67e5\u8be2\u3001\u4e13\u5bb6\u64b0\u5199\u7684\u56de\u7b54\u548c\u57fa\u4e8e\u56fe\u50cf\u7684\u4e0a\u4e0b\u6587\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u591a\u6b65\u9aa4\u7ba1\u9053\u8fdb\u884c\u7b5b\u9009\uff0c\u6db5\u76d6\u4e86\u591a\u79cd\u4f5c\u7269\u5065\u5eb7\u3001\u5bb3\u866b\u8bca\u65ad\u548c\u4f5c\u7269\u7ba1\u7406\u573a\u666f\u3002", "result": "MIRAGE \u5305\u542b\u8d85\u8fc7 7000 \u4e2a\u72ec\u7279\u7684\u751f\u7269\u5b9e\u4f53\uff0c\u6db5\u76d6\u4e86\u690d\u7269\u79cd\u7c7b\u3001\u5bb3\u866b\u548c\u75be\u75c5\uff0c\u4f7f\u5176\u6210\u4e3a\u6700\u5206\u7c7b\u591a\u6837\u5316\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u57fa\u51c6\u4e4b\u4e00\u3002", "conclusion": "MIRAGE \u662f\u4e00\u4e2a\u9ad8\u4fdd\u771f\u7684\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728\u73b0\u5b9e\u4e16\u754c\u3001\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u4e2d\u7684\u57fa\u4e8e\u73b0\u5b9e\u7684\u63a8\u7406\u3001\u6f84\u6e05\u7b56\u7565\u548c\u957f\u6587\u672c\u751f\u6210\u80fd\u529b\u3002"}}
{"id": "2506.20112", "pdf": "https://arxiv.org/pdf/2506.20112", "abs": "https://arxiv.org/abs/2506.20112", "authors": ["Songsoo Kim", "Seungtae Lee", "See Young Lee", "Joonho Kim", "Keechan Kan", "Dukyong Yoon"], "title": "A Multi-Pass Large Language Model Framework for Precise and Efficient Radiology Report Error Detection", "categories": ["cs.CL", "I.2.7"], "comment": "29 pages, 5 figures, 4 tables. Code available at\n  https://github.com/radssk/mp-rred", "summary": "Background: The positive predictive value (PPV) of large language model\n(LLM)-based proofreading for radiology reports is limited due to the low error\nprevalence. Purpose: To assess whether a three-pass LLM framework enhances PPV\nand reduces operational costs compared with baseline approaches. Materials and\nMethods: A retrospective analysis was performed on 1,000 consecutive radiology\nreports (250 each: radiography, ultrasonography, CT, MRI) from the MIMIC-III\ndatabase. Two external datasets (CheXpert and Open-i) were validation sets.\nThree LLM frameworks were tested: (1) single-prompt detector; (2) extractor\nplus detector; and (3) extractor, detector, and false-positive verifier.\nPrecision was measured by PPV and absolute true positive rate (aTPR).\nEfficiency was calculated from model inference charges and reviewer\nremuneration. Statistical significance was tested using cluster bootstrap,\nexact McNemar tests, and Holm-Bonferroni correction. Results: Framework PPV\nincreased from 0.063 (95% CI, 0.036-0.101, Framework 1) to 0.079 (0.049-0.118,\nFramework 2), and significantly to 0.159 (0.090-0.252, Framework 3; P<.001 vs.\nbaselines). aTPR remained stable (0.012-0.014; P>=.84). Operational costs per\n1,000 reports dropped to USD 5.58 (Framework 3) from USD 9.72 (Framework 1) and\nUSD 6.85 (Framework 2), reflecting reductions of 42.6% and 18.5%, respectively.\nHuman-reviewed reports decreased from 192 to 88. External validation supported\nFramework 3's superior PPV (CheXpert 0.133, Open-i 0.105) and stable aTPR\n(0.007). Conclusion: A three-pass LLM framework significantly enhanced PPV and\nreduced operational costs, maintaining detection performance, providing an\neffective strategy for AI-assisted radiology report quality assurance.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u4e09\u9636\u6bb5\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6846\u67b6\u5728\u653e\u5c04\u5b66\u62a5\u544a\u6821\u5bf9\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u663e\u8457\u63d0\u9ad8\u4e86\u6b63\u9884\u6d4b\u503c\uff08PPV\uff09\u5e76\u964d\u4f4e\u4e86\u8fd0\u8425\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e\u9519\u8bef\u53d1\u751f\u7387\u4f4e\uff0c\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u653e\u5c04\u5b66\u62a5\u544a\u6821\u5bf9\u7684\u6b63\u9884\u6d4b\u503c\uff08PPV\uff09\u53d7\u5230\u9650\u5236\u3002\u76ee\u7684\uff1a\u8bc4\u4f30\u4e09\u9636\u6bb5LLM\u6846\u67b6\u662f\u5426\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8PPV\u5e76\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u3002", "method": "\u5bf91000\u4efd\u8fde\u7eed\u7684\u653e\u5c04\u5b66\u62a5\u544a\uff08\u6bcf\u79cd\uff1aX\u5149\u3001\u8d85\u58f0\u3001CT\u3001MRI\uff09\u8fdb\u884c\u4e86\u56de\u987e\u6027\u5206\u6790\uff0c\u5e76\u4f7f\u7528CheXpert\u548cOpen-i\u5916\u90e8\u6570\u636e\u96c6\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\u3002\u6d4b\u8bd5\u4e86\u4e09\u79cdLLM\u6846\u67b6\uff1a\uff081\uff09\u5355\u63d0\u793a\u68c0\u6d4b\u5668\uff1b\uff082\uff09\u63d0\u53d6\u5668\u52a0\u68c0\u6d4b\u5668\uff1b\uff083\uff09\u63d0\u53d6\u5668\u3001\u68c0\u6d4b\u5668\u548c\u5047\u9633\u6027\u9a8c\u8bc1\u5668\u3002", "result": "\u6846\u67b6\u7684PPV\u4ece0.063\uff0895% CI\uff0c0.036-0.101\uff0c\u6846\u67b61\uff09\u589e\u52a0\u52300.079\uff080.049-0.118\uff0c\u6846\u67b62\uff09\uff0c\u5e76\u663e\u8457\u589e\u52a0\u52300.159\uff080.090-0.252\uff0c\u6846\u67b63\uff1bP<.001 vs. \u57fa\u7ebf\uff09\u3002aTPR\u4fdd\u6301\u7a33\u5b9a\uff080.012-0.014\uff1bP>=.84\uff09\u3002\u6bcf1000\u4efd\u62a5\u544a\u7684\u8fd0\u8425\u6210\u672c\u964d\u81f35.58\u7f8e\u5143\uff08\u6846\u67b63\uff09\uff0c\u4ece\u6846\u67b61\u76849.72\u7f8e\u5143\u548c\u6846\u67b62\u76846.85\u7f8e\u5143\u4e0b\u964d\uff0c\u5206\u522b\u51cf\u5c11\u4e8642.6%\u548c18.5%\u3002\u4eba\u5de5\u5ba1\u6838\u7684\u62a5\u544a\u6570\u91cf\u4ece192\u51cf\u5c11\u523088\u3002\u5916\u90e8\u9a8c\u8bc1\u652f\u6301\u6846\u67b63\u7684\u4f18\u8d8aPPV\uff08CheXpert 0.133\uff0cOpen-i 0.105\uff09\u548c\u7a33\u5b9a\u7684aTPR\uff080.007\uff09\u3002", "conclusion": "\u4e09\u9636\u6bb5LLM\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86PPV\u5e76\u964d\u4f4e\u4e86\u8fd0\u8425\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3aAI\u8f85\u52a9\u7684\u653e\u5c04\u5b66\u62a5\u544a\u8d28\u91cf\u4fdd\u8bc1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7b56\u7565\u3002"}}
{"id": "2506.20119", "pdf": "https://arxiv.org/pdf/2506.20119", "abs": "https://arxiv.org/abs/2506.20119", "authors": ["Masaki Uto", "Yuma Ito"], "title": "Leveraging AI Graders for Missing Score Imputation to Achieve Accurate Ability Estimation in Constructed-Response Tests", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to EvalLAC'25: 2nd Workshop on Automatic Evaluation of\n  Learning and Assessment Content, held at AIED 2025, Palermo, Italy. This is\n  the camera-ready version submitted to CEUR Workshop Proceedings", "summary": "Evaluating the abilities of learners is a fundamental objective in the field\nof education. In particular, there is an increasing need to assess higher-order\nabilities such as expressive skills and logical thinking. Constructed-response\ntests such as short-answer and essay-based questions have become widely used as\na method to meet this demand. Although these tests are effective, they require\nsubstantial manual grading, making them both labor-intensive and costly. Item\nresponse theory (IRT) provides a promising solution by enabling the estimation\nof ability from incomplete score data, where human raters grade only a subset\nof answers provided by learners across multiple test items. However, the\naccuracy of ability estimation declines as the proportion of missing scores\nincreases. Although data augmentation techniques for imputing missing scores\nhave been explored in order to address this limitation, they often struggle\nwith inaccuracy for sparse or heterogeneous data. To overcome these challenges,\nthis study proposes a novel method for imputing missing scores by leveraging\nautomated scoring technologies for accurate IRT-based ability estimation. The\nproposed method achieves high accuracy in ability estimation while markedly\nreducing manual grading workload.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u81ea\u52a8\u5316\u8bc4\u5206\u6280\u672f\u6765\u586b\u8865\u7f3a\u5931\u5206\u6570\uff0c\u4ee5\u63d0\u9ad8IRT\u57fa\u7840\u80fd\u529b\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u5de5\u8bc4\u5206\u7684\u5de5\u4f5c\u91cf\u3002", "motivation": "\u8bc4\u4f30\u5b66\u4e60\u8005\u7684\u80fd\u529b\u662f\u6559\u80b2\u9886\u57df\u7684\u4e00\u4e2a\u57fa\u672c\u76ee\u6807\uff0c\u5c24\u5176\u662f\u5bf9\u8868\u8fbe\u80fd\u529b\u548c\u903b\u8f91\u601d\u7ef4\u7b49\u9ad8\u7ea7\u80fd\u529b\u7684\u8bc4\u4f30\u9700\u6c42\u4e0d\u65ad\u589e\u52a0\u3002\u867d\u7136\u6784\u9020\u6027\u53cd\u5e94\u6d4b\u8bd5\uff08\u5982\u7b80\u7b54\u548c\u4f5c\u6587\u9898\uff09\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5b83\u4eec\u9700\u8981\u5927\u91cf\u7684\u4eba\u5de5\u8bc4\u5206\uff0c\u65e2\u8d39\u65f6\u53c8\u6602\u8d35\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u81ea\u52a8\u5316\u8bc4\u5206\u6280\u672f\u6765\u586b\u8865\u7f3a\u5931\u5206\u6570\uff0c\u4ee5\u63d0\u9ad8IRT\u57fa\u7840\u80fd\u529b\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u5de5\u8bc4\u5206\u7684\u5de5\u4f5c\u91cf\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u81ea\u52a8\u5316\u8bc4\u5206\u6280\u672f\u6765\u586b\u8865\u7f3a\u5931\u5206\u6570\uff0c\u4ece\u800c\u5b9e\u73b0\u51c6\u786e\u7684IRT\u57fa\u7840\u80fd\u529b\u4f30\u8ba1\u3002\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u5de5\u8bc4\u5206\u7684\u5de5\u4f5c\u91cf\u3002"}}
{"id": "2506.20128", "pdf": "https://arxiv.org/pdf/2506.20128", "abs": "https://arxiv.org/abs/2506.20128", "authors": ["Aashiq Muhamed"], "title": "CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at LLM4Eval @ SIGIR 2025", "summary": "RAG systems enhance LLMs by incorporating external knowledge, which is\ncrucial for domains that demand factual accuracy and up-to-date information.\nHowever, evaluating the multifaceted quality of RAG outputs, spanning aspects\nsuch as contextual coherence, query relevance, factual correctness, and\ninformational completeness, poses significant challenges. Existing evaluation\nmethods often rely on simple lexical overlap metrics, which are inadequate for\ncapturing these nuances, or involve complex multi-stage pipelines with\nintermediate steps like claim extraction or require finetuning specialized\njudge models, hindering practical efficiency. To address these limitations, we\npropose CCRS (Contextual Coherence and Relevance Score), a novel suite of five\nmetrics that utilizes a single, powerful, pretrained LLM as a zero-shot,\nend-to-end judge. CCRS evaluates: Contextual Coherence (CC), Question Relevance\n(QR), Information Density (ID), Answer Correctness (AC), and Information Recall\n(IR). We apply CCRS to evaluate six diverse RAG system configurations on the\nchallenging BioASQ dataset. Our analysis demonstrates that CCRS effectively\ndiscriminates between system performances, confirming, for instance, that the\nMistral-7B reader outperforms Llama variants. We provide a detailed analysis of\nCCRS metric properties, including score distributions, convergent/discriminant\nvalidity, tie rates, population statistics, and discriminative power. Compared\nto the complex RAGChecker framework, CCRS offers comparable or superior\ndiscriminative power for key aspects like recall and faithfulness, while being\nsignificantly more computationally efficient. CCRS thus provides a practical,\ncomprehensive, and efficient framework for evaluating and iteratively improving\nRAG systems.", "AI": {"tldr": "CCRS is a new evaluation framework for RAG systems that uses a single LLM to assess multiple aspects of output quality, offering better efficiency and performance compared to existing methods.", "motivation": "Existing evaluation methods for RAG outputs are inadequate, either relying on simple lexical overlap metrics or complex multi-stage pipelines, which hinder practical efficiency.", "method": "Proposed CCRS (Contextual Coherence and Relevance Score), a novel suite of five metrics that utilizes a single, powerful, pretrained LLM as a zero-shot, end-to-end judge.", "result": "CCRS effectively discriminates between system performances, confirming that the Mistral-7B reader outperforms Llama variants. It offers comparable or superior discriminative power for key aspects like recall and faithfulness, while being significantly more computationally efficient than the RAGChecker framework.", "conclusion": "CCRS provides a practical, comprehensive, and efficient framework for evaluating and iteratively improving RAG systems."}}
{"id": "2506.20160", "pdf": "https://arxiv.org/pdf/2506.20160", "abs": "https://arxiv.org/abs/2506.20160", "authors": ["Ruosen Li", "Ziming Luo", "Quan Zhang", "Ruochen Li", "Ben Zhou", "Ali Payani", "Xinya Du"], "title": "AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control", "categories": ["cs.CL"], "comment": null, "summary": "Large reasoning models (LRMs) achieve impressive reasoning capabilities by\ngenerating lengthy chain-of-thoughts, but this \"overthinking\" incurs high\nlatency and cost without commensurate accuracy gains. In this work, we\nintroduce AALC, a lightweight, accuracy-aware length reward integrated into\nreinforcement learning that dynamically balances correctness and brevity during\ntraining. By incorporating validation accuracy into the reward and employing a\nsmooth, dynamically scheduled length penalty, AALC delays length penalty until\ntarget performance is met. Through extensive experiments across standard and\nout-of-distribution math benchmarks, we show that our approach reduces response\nlength by over 50% while maintaining or even improving the original accuracy.\nFurthermore, qualitative analysis reveals that our method curbs redundant\nreasoning patterns such as excessive subgoal setting and verification, leading\nto structurally refined outputs rather than naive truncation. We also identify\nthat efficiency gains are accompanied by reduced interpretability: models\ntrained with AALC omit some narrative framing and explanatory context. These\nfindings highlight the potential of reward-based strategies to guide LRMs\ntoward more efficient, generalizable reasoning paths.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAALC\u7684\u8f7b\u91cf\u7ea7\u3001\u51c6\u786e\u5ea6\u611f\u77e5\u7684\u957f\u5ea6\u5956\u52b1\u673a\u5236\uff0c\u7528\u4e8e\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u52a8\u6001\u5e73\u8861\u6b63\u786e\u6027\u548c\u7b80\u6d01\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u51cf\u5c11\u54cd\u5e94\u957f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u51cf\u5c11\u5197\u4f59\u63a8\u7406\u6a21\u5f0f\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u751f\u6210\u957f\u94fe\u5f0f\u601d\u7ef4\u5b9e\u73b0\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u8fd9\u79cd\u201c\u8fc7\u5ea6\u601d\u8003\u201d\u4f1a\u5e26\u6765\u9ad8\u5ef6\u8fdf\u548c\u6210\u672c\uff0c\u800c\u6ca1\u6709\u76f8\u5e94\u7684\u51c6\u786e\u6027\u63d0\u5347\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86AALC\uff0c\u8fd9\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u51c6\u786e\u5ea6\u611f\u77e5\u7684\u957f\u5ea6\u5956\u52b1\uff0c\u96c6\u6210\u5230\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u4ee5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a8\u6001\u5e73\u8861\u6b63\u786e\u6027\u548c\u7b80\u6d01\u6027\u3002", "result": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u6807\u51c6\u548c\u5206\u5e03\u5916\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u54cd\u5e94\u957f\u5ea6\u51cf\u5c11\u4e8650%\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u751a\u81f3\u63d0\u9ad8\u4e86\u539f\u59cb\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u5b9a\u6027\u5206\u6790\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u904f\u5236\u4e86\u5197\u4f59\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u5982\u8fc7\u591a\u7684\u5b50\u76ee\u6807\u8bbe\u5b9a\u548c\u9a8c\u8bc1\uff0c\u5bfc\u81f4\u7ed3\u6784\u66f4\u7cbe\u70bc\u7684\u8f93\u51fa\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u5c55\u793a\u4e86\u5956\u52b1\u673a\u5236\u5728\u5f15\u5bfc\u5927\u578b\u63a8\u7406\u6a21\u578b\u8d70\u5411\u66f4\u9ad8\u6548\u3001\u66f4\u901a\u7528\u7684\u63a8\u7406\u8def\u5f84\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.20167", "pdf": "https://arxiv.org/pdf/2506.20167", "abs": "https://arxiv.org/abs/2506.20167", "authors": ["Fengze Li", "Yue Wang", "Yangle Liu", "Ming Huang", "Dou Hong", "Jieming Ma"], "title": "SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multivariate time series forecasting requires models to simultaneously\ncapture variable-wise structural dependencies and generalize across diverse\ntasks. While structural encoders are effective in modeling feature\ninteractions, they lack the capacity to support semantic-level reasoning or\ntask adaptation. Conversely, large language models (LLMs) possess strong\ngeneralization capabilities but remain incompatible with raw time series\ninputs. This gap limits the development of unified, transferable prediction\nsystems. Therefore, we introduce SEED, a structural encoder for\nembedding-driven decoding, which integrates four stages: a token-aware encoder\nfor patch extraction, a projection module that aligns patches with language\nmodel embeddings, a semantic reprogramming mechanism that maps patches to\ntask-aware prototypes, and a frozen language model for prediction. This modular\narchitecture decouples representation learning from inference, enabling\nefficient alignment between numerical patterns and semantic reasoning.\nEmpirical results demonstrate that the proposed method achieves consistent\nimprovements over strong baselines, and comparative studies on various datasets\nconfirm SEED's role in addressing the structural-semantic modeling gap.", "AI": {"tldr": "SEED \u662f\u4e00\u79cd\u7ed3\u6784\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u6574\u5408\u591a\u4e2a\u9636\u6bb5\uff0c\u5c06\u6570\u503c\u6a21\u5f0f\u4e0e\u8bed\u4e49\u63a8\u7406\u8fdb\u884c\u9ad8\u6548\u5bf9\u9f50\uff0c\u4ece\u800c\u89e3\u51b3\u7ed3\u6784-\u8bed\u4e49\u5efa\u6a21\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u7684\u7ed3\u6784\u7f16\u7801\u5668\u65e0\u6cd5\u652f\u6301\u8bed\u4e49\u5c42\u9762\u7684\u63a8\u7406\u6216\u4efb\u52a1\u9002\u5e94\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u8f93\u5165\u4e0d\u517c\u5bb9\uff0c\u8fd9\u9650\u5236\u4e86\u7edf\u4e00\u3001\u53ef\u8f6c\u79fb\u9884\u6d4b\u7cfb\u7edf\u7684\u5f00\u53d1\u3002", "method": "SEED \u5305\u542b\u56db\u4e2a\u9636\u6bb5\uff1a\u4e00\u4e2a\u5173\u6ce8\u6807\u8bb0\u7684\u7f16\u7801\u5668\u7528\u4e8e\u8865\u4e01\u63d0\u53d6\uff0c\u4e00\u4e2a\u6295\u5f71\u6a21\u5757\u5c06\u8865\u4e01\u4e0e\u8bed\u8a00\u6a21\u578b\u5d4c\u5165\u5bf9\u9f50\uff0c\u4e00\u4e2a\u8bed\u4e49\u91cd\u65b0\u7f16\u7a0b\u673a\u5236\u5c06\u8865\u4e01\u6620\u5c04\u5230\u4efb\u52a1\u611f\u77e5\u539f\u578b\uff0c\u4ee5\u53ca\u4e00\u4e2a\u51bb\u7ed3\u7684\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u9884\u6d4b\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5f3a\u57fa\u7ebf\u4e0a\u5b9e\u73b0\u4e86\u6301\u7eed\u6539\u8fdb\uff0c\u5e76\u4e14\u5728\u5404\u79cd\u6570\u636e\u96c6\u4e0a\u7684\u6bd4\u8f83\u7814\u7a76\u8bc1\u5b9e\u4e86 SEED \u5728\u89e3\u51b3\u7ed3\u6784-\u8bed\u4e49\u5efa\u6a21\u5dee\u8ddd\u4e2d\u7684\u4f5c\u7528\u3002", "conclusion": "SEED \u7684\u6a21\u5757\u5316\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u7ed3\u6784-\u8bed\u4e49\u5efa\u6a21\u5dee\u8ddd\uff0c\u5e76\u5728\u5404\u79cd\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2506.20178", "pdf": "https://arxiv.org/pdf/2506.20178", "abs": "https://arxiv.org/abs/2506.20178", "authors": ["Zhiyuan Wang", "Jinhao Duan", "Qingni Wang", "Xiaofeng Zhu", "Tianlong Chen", "Xiaoshuang Shi", "Kaidi Xu"], "title": "COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Uncertainty quantification (UQ) for foundation models is essential to\nidentify and mitigate potential hallucinations in automatically generated text.\nHowever, heuristic UQ approaches lack formal guarantees for key metrics such as\nthe false discovery rate (FDR) in selective prediction. Previous work adopts\nthe split conformal prediction (SCP) framework to ensure desired coverage of\nadmissible answers by constructing prediction sets, but these sets often\ncontain incorrect candidates, limiting their practical utility. To address\nthis, we propose COIN, an uncertainty-guarding selection framework that\ncalibrates statistically valid thresholds to filter a single generated answer\nper question under user-specified FDR constraints. COIN estimates the empirical\nerror rate on a calibration set and applies confidence interval methods such as\nClopper-Pearson to establish a high-probability upper bound on the true error\nrate (i.e., FDR). This enables the selection of the largest uncertainty\nthreshold that ensures FDR control on test data while significantly increasing\nsample retention. We demonstrate COIN's robustness in risk control, strong\ntest-time power in retaining admissible answers, and predictive efficiency\nunder limited calibration data across both general and multimodal text\ngeneration tasks. Furthermore, we show that employing alternative upper bound\nconstructions and UQ strategies can further boost COIN's power performance,\nwhich underscores its extensibility and adaptability to diverse application\nscenarios.", "AI": {"tldr": "COIN is a framework that improves uncertainty quantification in foundation models by ensuring FDR control and increasing sample retention, with strong performance across various tasks.", "motivation": "The motivation is to address the limitations of heuristic UQ approaches and split conformal prediction (SCP) frameworks, which often fail to provide formal guarantees for key metrics like FDR and may include incorrect candidates in prediction sets.", "method": "COIN calibrates statistically valid thresholds to filter generated answers under user-specified FDR constraints by estimating the empirical error rate on a calibration set and applying confidence interval methods like Clopper-Pearson to establish an upper bound on the true error rate (FDR).", "result": "COIN demonstrates robustness in risk control, strong test-time power in retaining admissible answers, and predictive efficiency under limited calibration data across general and multimodal text generation tasks. It also shows potential for further improvement through alternative upper bound constructions and UQ strategies.", "conclusion": "COIN is a robust and adaptable framework for uncertainty quantification in foundation models, demonstrating strong performance in risk control and predictive efficiency."}}
{"id": "2506.20199", "pdf": "https://arxiv.org/pdf/2506.20199", "abs": "https://arxiv.org/abs/2506.20199", "authors": ["Mengqi Wang", "Tiantian Feng", "Shrikanth Narayanan"], "title": "How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have enabled a wide variety of real-world\napplications in various domains. However, creating a high-performing\napplication with high accuracy remains challenging, particularly for subjective\ntasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this\nstudy investigates approaches to improving conversational emotion recognition\n(CER) by LLMs. Specifically, we explore how to retrieve high-quality examples\nin in-context learning (ICL) to enhance CER. We propose various strategies\nbased on random and augmented example retrieval and also analyze the impact of\nconversational context on CER accuracy. Experiments were conducted on the three\ndatasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented\nexample retrieval consistently outperforms other techniques under investigation\nacross all datasets, highlighting the importance of retrieving coherent\ntargeted examples and enhancing them through paraphrasing.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u589e\u5f3a\u793a\u4f8b\u68c0\u7d22\u63d0\u9ad8\u5bf9\u8bdd\u60c5\u611f\u8bc6\u522b\u7684\u51c6\u786e\u6027\uff0c\u5e76\u53d1\u73b0\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5404\u4e2a\u9886\u57df\u4e2d\u5b9e\u73b0\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9645\u5e94\u7528\u3002\u7136\u800c\uff0c\u521b\u5efa\u9ad8\u7cbe\u5ea6\u7684\u9ad8\u6027\u80fd\u5e94\u7528\u7a0b\u5e8f\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u5c24\u5176\u662f\u5728\u4e3b\u89c2\u4efb\u52a1\u5982\u60c5\u611f\u8bc6\u522b\u65b9\u9762\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u6539\u8fdb\u5bf9\u8bdd\u60c5\u611f\u8bc6\u522b\u7684\u65b9\u6cd5\u3002", "method": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5982\u4f55\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u68c0\u7d22\u9ad8\u8d28\u91cf\u793a\u4f8b\u4ee5\u63d0\u9ad8\u5bf9\u8bdd\u60c5\u611f\u8bc6\u522b\uff08CER\uff09\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u57fa\u4e8e\u968f\u673a\u548c\u589e\u5f3a\u793a\u4f8b\u68c0\u7d22\u7684\u5404\u79cd\u7b56\u7565\uff0c\u5e76\u5206\u6790\u4e86\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u5bf9CER\u51c6\u786e\u6027\u7684\u5f71\u54cd\u529b\u3002", "result": "\u5b9e\u9a8c\u5728\u4e09\u4e2a\u6570\u636e\u96c6\uff08IEMOCAP\u3001MELD \u548c EmoryNLP\uff09\u4e0a\u8fdb\u884c\u3002\u7ed3\u679c\u8868\u660e\uff0c\u589e\u5f3a\u793a\u4f8b\u68c0\u7d22\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u5176\u4ed6\u7814\u7a76\u6280\u672f\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u589e\u5f3a\u793a\u4f8b\u68c0\u7d22\u53ef\u4ee5\u63d0\u9ad8\u5bf9\u8bdd\u60c5\u611f\u8bc6\u522b\u7684\u51c6\u786e\u6027\uff0c\u8fd9\u5f3a\u8c03\u4e86\u68c0\u7d22\u8fde\u8d2f\u7684\u76ee\u6807\u793a\u4f8b\u5e76\u901a\u8fc7\u6539\u5199\u6765\u589e\u5f3a\u5b83\u4eec\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.20203", "pdf": "https://arxiv.org/pdf/2506.20203", "abs": "https://arxiv.org/abs/2506.20203", "authors": ["Petra Baran\u010d\u00edkov\u00e1", "Ond\u0159ej Bojar"], "title": "Intrinsic vs. Extrinsic Evaluation of Czech Sentence Embeddings: Semantic Relevance Doesn't Help with MT Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we compare Czech-specific and multilingual sentence embedding\nmodels through intrinsic and extrinsic evaluation paradigms. For intrinsic\nevaluation, we employ Costra, a complex sentence transformation dataset, and\nseveral Semantic Textual Similarity (STS) benchmarks to assess the ability of\nthe embeddings to capture linguistic phenomena such as semantic similarity,\ntemporal aspects, and stylistic variations. In the extrinsic evaluation, we\nfine-tune each embedding model using COMET-based metrics for machine\ntranslation evaluation.\n  Our experiments reveal an interesting disconnect: models that excel in\nintrinsic semantic similarity tests do not consistently yield superior\nperformance on downstream translation evaluation tasks. Conversely, models with\nseemingly over-smoothed embedding spaces can, through fine-tuning, achieve\nexcellent results. These findings highlight the complex relationship between\nsemantic property probes and downstream task, emphasizing the need for more\nresearch into 'operationalizable semantics' in sentence embeddings, or more\nin-depth downstream tasks datasets (here translation evaluation)", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u6377\u514b\u7279\u5b9a\u548c\u591a\u8bed\u8a00\u53e5\u5b50\u5d4c\u5165\u6a21\u578b\u5728\u5185\u5728\u548c\u5916\u5728\u8bc4\u4f30\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5185\u5728\u8bed\u4e49\u76f8\u4f3c\u6027\u6d4b\u8bd5\u8868\u73b0\u597d\u7684\u6a21\u578b\u4e0d\u4e00\u5b9a\u5728\u4e0b\u6e38\u7ffb\u8bd1\u8bc4\u4f30\u4efb\u52a1\u4e2d\u8868\u73b0\u597d\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u53e5\u5b50\u5d4c\u5165\u6a21\u578b\u5728\u4e0d\u540c\u8bc4\u4f30\u8303\u5f0f\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u63ed\u793a\u5185\u5728\u8bed\u4e49\u76f8\u4f3c\u6027\u6d4b\u8bd5\u4e0e\u4e0b\u6e38\u7ffb\u8bd1\u8bc4\u4f30\u4efb\u52a1\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u5185\u5728\u548c\u5916\u5728\u8bc4\u4f30\u8303\u5f0f\u6bd4\u8f83\u4e86\u6377\u514b\u7279\u5b9a\u548c\u591a\u8bed\u8a00\u53e5\u5b50\u5d4c\u5165\u6a21\u578b\u3002\u5728\u5185\u5728\u8bc4\u4f30\u4e2d\uff0c\u4f7f\u7528\u4e86Costra\u6570\u636e\u96c6\u548c\u51e0\u4e2a\u8bed\u4e49\u6587\u672c\u76f8\u4f3c\u6027\uff08STS\uff09\u57fa\u51c6\u6765\u8bc4\u4f30\u5d4c\u5165\u6355\u6349\u8bed\u8a00\u73b0\u8c61\u7684\u80fd\u529b\u3002\u5728\u5916\u5728\u8bc4\u4f30\u4e2d\uff0c\u4f7f\u7528\u57fa\u4e8eCOMET\u7684\u6307\u6807\u5bf9\u6bcf\u4e2a\u5d4c\u5165\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u4ee5\u8fdb\u884c\u673a\u5668\u7ffb\u8bd1\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5185\u5728\u8bed\u4e49\u76f8\u4f3c\u6027\u6d4b\u8bd5\u8868\u73b0\u4f18\u5f02\u7684\u6a21\u578b\u5e76\u4e0d\u603b\u80fd\u5728\u4e0b\u6e38\u7ffb\u8bd1\u8bc4\u4f30\u4efb\u52a1\u4e2d\u53d6\u5f97\u4f18\u8d8a\u8868\u73b0\u3002\u76f8\u53cd\uff0c\u770b\u4f3c\u8fc7\u4e8e\u5e73\u6ed1\u7684\u5d4c\u5165\u7a7a\u95f4\u7684\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u5fae\u8c03\u83b7\u5f97\u51fa\u8272\u7684\u7ed3\u679c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u8bed\u4e49\u5c5e\u6027\u63a2\u6d4b\u548c\u4e0b\u6e38\u4efb\u52a1\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\uff0c\u7a81\u663e\u4e86\u5728\u53e5\u5b50\u5d4c\u5165\u4e2d\u9700\u8981\u66f4\u591a\u5173\u4e8e'\u53ef\u64cd\u4f5c\u8bed\u4e49'\u7684\u7814\u7a76\uff0c\u6216\u66f4\u6df1\u5165\u7684\u4e0b\u6e38\u4efb\u52a1\u6570\u636e\u96c6\uff08\u5982\u7ffb\u8bd1\u8bc4\u4f30\uff09"}}
{"id": "2506.20209", "pdf": "https://arxiv.org/pdf/2506.20209", "abs": "https://arxiv.org/abs/2506.20209", "authors": ["Benedetta Muscato", "Lucia Passaro", "Gizem Gezici", "Fosca Giannotti"], "title": "Perspectives in Play: A Multi-Perspective Approach for More Inclusive NLP Systems", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the realm of Natural Language Processing (NLP), common approaches for\nhandling human disagreement consist of aggregating annotators' viewpoints to\nestablish a single ground truth. However, prior studies show that disregarding\nindividual opinions can lead can lead to the side effect of underrepresenting\nminority perspectives, especially in subjective tasks, where annotators may\nsystematically disagree because of their preferences. Recognizing that labels\nreflect the diverse backgrounds, life experiences, and values of individuals,\nthis study proposes a new multi-perspective approach using soft labels to\nencourage the development of the next generation of perspective aware models,\nmore inclusive and pluralistic. We conduct an extensive analysis across diverse\nsubjective text classification tasks, including hate speech, irony, abusive\nlanguage, and stance detection, to highlight the importance of capturing human\ndisagreements, often overlooked by traditional aggregation methods. Results\nshow that the multi-perspective approach not only better approximates human\nlabel distributions, as measured by Jensen-Shannon Divergence (JSD), but also\nachieves superior classification performance (higher F1 scores), outperforming\ntraditional approaches. However, our approach exhibits lower confidence in\ntasks like irony and stance detection, likely due to the inherent subjectivity\npresent in the texts. Lastly, leveraging Explainable AI (XAI), we explore model\nuncertainty and uncover meaningful insights into model predictions.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u89c6\u89d2\u65b9\u6cd5\uff0c\u4f7f\u7528\u8f6f\u6807\u7b7e\u6765\u6355\u6349\u4eba\u7c7b\u5206\u6b67\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u5305\u5bb9\u6027\u548c\u591a\u6837\u6027\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5206\u7c7b\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u5728\u67d0\u4e9b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8f83\u4f4e\u7684\u7f6e\u4fe1\u5ea6\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u4eba\u7c7b\u5206\u6b67\u65f6\uff0c\u5f80\u5f80\u5ffd\u89c6\u4e86\u4e2a\u4f53\u610f\u89c1\uff0c\u5bfc\u81f4\u5c11\u6570\u89c2\u70b9\u88ab\u4f4e\u4f30\uff0c\u5c24\u5176\u662f\u5728\u4e3b\u89c2\u4efb\u52a1\u4e2d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u7684\u65b9\u6cd5\u6765\u6355\u6349\u4eba\u7c7b\u5206\u6b67\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u5305\u5bb9\u6027\u548c\u591a\u6837\u6027\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u89c6\u89d2\u65b9\u6cd5\uff0c\u4f7f\u7528\u8f6f\u6807\u7b7e\u6765\u9f13\u52b1\u5f00\u53d1\u66f4\u5305\u5bb9\u548c\u591a\u5143\u5316\u7684\u89c6\u89d2\u611f\u77e5\u6a21\u578b\u3002\u6b64\u5916\uff0c\u8fd8\u5229\u7528\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u63a2\u7d22\u4e86\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u9884\u6d4b\u7684\u91cd\u8981\u89c1\u89e3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u591a\u89c6\u89d2\u65b9\u6cd5\u5728\u8861\u91cf\u4eba\u7c7b\u6807\u7b7e\u5206\u5e03\u7684Jensen-Shannon\u6563\u5ea6\uff08JSD\uff09\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u5e76\u4e14\u5728\u5206\u7c7b\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u5728\u50cf\u8bbd\u523a\u548c\u7acb\u573a\u68c0\u6d4b\u8fd9\u6837\u7684\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u7684\u7f6e\u4fe1\u5ea6\u8f83\u4f4e\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u89c6\u89d2\u65b9\u6cd5\uff0c\u4f7f\u7528\u8f6f\u6807\u7b7e\u6765\u4fc3\u8fdb\u4e0b\u4e00\u4ee3\u89c6\u89d2\u611f\u77e5\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u8fd9\u4e9b\u6a21\u578b\u66f4\u52a0\u5305\u5bb9\u548c\u591a\u5143\u5316\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u66f4\u597d\u5730\u8fd1\u4f3c\u4e86\u4eba\u7c7b\u6807\u7b7e\u5206\u5e03\uff0c\u8fd8\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5206\u7c7b\u6027\u80fd\u3002\u7136\u800c\uff0c\u5728\u50cf\u8bbd\u523a\u548c\u7acb\u573a\u68c0\u6d4b\u8fd9\u6837\u7684\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u7684\u7f6e\u4fe1\u5ea6\u8f83\u4f4e\uff0c\u8fd9\u53ef\u80fd\u662f\u7531\u4e8e\u6587\u672c\u4e2d\u7684\u4e3b\u89c2\u6027\u3002\u6700\u540e\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\uff0c\u6211\u4eec\u63a2\u7d22\u4e86\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u5e76\u63ed\u793a\u4e86\u5173\u4e8e\u6a21\u578b\u9884\u6d4b\u7684\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2506.20241", "pdf": "https://arxiv.org/pdf/2506.20241", "abs": "https://arxiv.org/abs/2506.20241", "authors": ["Yubo Dong", "Hehe Fan"], "title": "Enhancing Large Language Models through Structured Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint. Under review", "summary": "Recent Large Language Models (LLMs) have significantly advanced natural\nlanguage processing and automated decision-making. However, these models still\nencounter difficulties when performing complex reasoning tasks involving\nlogical deduction and systematic planning, primarily due to their reliance on\nimplicit statistical relationships without structured knowledge\nrepresentation.Inspired by cognitive science and neurosymbolic AI, we introduce\na novel approach to enhance LLMs through explicit structured reasoning. First,\nwe convert unstructured data into structured formats by explicitly annotating\nreasoning steps. We then employ this structured dataset to train LLMs through\nSupervised Fine-Tuning (SFT). Additionally, we enhance the structured reasoning\ncapabilities of LLMs using Group Relative Policy Optimization (GRPO),\nincorporating two innovative algorithms--MAX-Flow and Longest Common\nSubsequence (LCS)--which notably improve reasoning effectiveness and reduce\ncomputational complexity. Experimental results from fine-tuning a\nDeepSeek-R1-Distill-Qwen-1.5B model demonstrate concise reasoning, robust\nperformance across various scenarios, and improved compatibility with\noptimization techniques, validating the efficacy of structured reasoning\nintegration in LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u663e\u5f0f\u7ed3\u6784\u5316\u63a8\u7406\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff0c\u7ed3\u5408MAX-Flow\u548cLCS\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u679c\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6d89\u53ca\u903b\u8f91\u6f14\u7ece\u548c\u7cfb\u7edf\u89c4\u5212\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u4ecd\u7136\u9762\u4e34\u56f0\u96be\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a\u5b83\u4eec\u4f9d\u8d56\u4e8e\u9690\u5f0f\u7684\u7edf\u8ba1\u5173\u7cfb\u800c\u6ca1\u6709\u7ed3\u6784\u5316\u7684\u77e5\u8bc6\u8868\u793a\u3002", "method": "\u901a\u8fc7\u663e\u5f0f\u6807\u6ce8\u63a8\u7406\u6b65\u9aa4\u5c06\u975e\u7ed3\u6784\u5316\u6570\u636e\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u683c\u5f0f\uff0c\u5e76\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\u6b64\u5916\uff0c\u8fd8\u901a\u8fc7\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u589e\u5f3a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\uff0c\u7ed3\u5408\u4e86MAX-Flow\u548c\u6700\u957f\u516c\u5171\u5b50\u5e8f\u5217\uff08LCS\uff09\u4e24\u4e2a\u521b\u65b0\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5fae\u8c03\u540e\u7684DeepSeek-R1-Distill-Qwen-1.5B\u6a21\u578b\u8868\u73b0\u51fa\u7b80\u6d01\u7684\u63a8\u7406\u3001\u5728\u5404\u79cd\u573a\u666f\u4e0b\u7684\u5f3a\u5927\u6027\u80fd\u4ee5\u53ca\u4e0e\u4f18\u5316\u6280\u672f\u7684\u6539\u8fdb\u517c\u5bb9\u6027\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7ed3\u6784\u5316\u63a8\u7406\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.20243", "pdf": "https://arxiv.org/pdf/2506.20243", "abs": "https://arxiv.org/abs/2506.20243", "authors": ["Papa S\u00e9ga Wade", "Mihai Andries", "Ioannis Kanellos", "Thierry Moudenc"], "title": "CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment", "categories": ["cs.CL", "eess.AS"], "comment": "5 pages, accepted for presentation at EUSIPCO 2025", "summary": "Automatic fluency assessment (AFA) remains challenging, particularly in\ncapturing speech rhythm, pauses, and disfluencies in non-native speakers. We\nintroduce a chunk-based approach integrating self-supervised learning (SSL)\nmodels (Wav2Vec2, HuBERT, and WavLM) selected for their complementary strengths\nin phonetic, prosodic, and noisy speech modeling, with a hierarchical\nCNN-BiLSTM framework. Speech is segmented into breath-group chunks using Silero\nvoice activity detection (Silero-VAD), enabling fine-grained temporal analysis\nwhile mitigating over-segmentation artifacts. SSL embeddings are fused via a\nlearnable weighted mechanism, balancing acoustic and linguistic features, and\nenriched with chunk-level fluency markers (e.g., speech rate, pause durations,\nn-gram repetitions). The CNN-BiLSTM captures local and long-term dependencies\nacross chunks. Evaluated on Avalinguo and Speechocean762, our approach improves\nF1-score by 2.8 and Pearson correlation by 6.2 points over single SSL baselines\non Speechocean762, with gains of 4.2 F1-score and 4.0 Pearson points on\nAvalinguo, surpassing Pyannote.audio-based segmentation baselines. These\nfindings highlight chunk-based multi-SSL fusion for robust fluency evaluation,\nthough future work should explore generalization to dialects with irregular\nprosody.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5757\u7684\u591aSSL\u878d\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb\u81ea\u52a8\u6d41\u5229\u5ea6\u8bc4\u4f30\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u81ea\u52a8\u6d41\u5229\u5ea6\u8bc4\u4f30\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u5728\u6355\u6349\u975e\u6bcd\u8bed\u8005\u7684\u8bed\u97f3\u8282\u594f\u3001\u505c\u987f\u548c\u4e0d\u6d41\u7545\u65b9\u9762\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u5757\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u6a21\u578b\uff08Wav2Vec2\u3001HuBERT\u548cWavLM\uff09\uff0c\u8fd9\u4e9b\u6a21\u578b\u56e0\u5176\u5728\u8bed\u97f3\u5b66\u3001\u8bed\u8c03\u548c\u5608\u6742\u8bed\u97f3\u5efa\u6a21\u65b9\u9762\u7684\u4e92\u8865\u4f18\u52bf\uff0c\u4ee5\u53ca\u4e00\u4e2a\u5206\u5c42\u7684CNN-BiLSTM\u6846\u67b6\u3002", "result": "\u5728Avalinguo\u548cSpeechocean762\u4e0a\u8bc4\u4f30\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728Speechocean762\u4e0a\u6bd4\u5355\u4e2aSSL\u57fa\u7ebf\u63d0\u9ad8\u4e862.8\u7684F1\u5206\u6570\u548c6.2\u7684\u76ae\u5c14\u900a\u76f8\u5173\u6027\uff0c\u5728Avalinguo\u4e0a\u63d0\u9ad8\u4e864.2\u7684F1\u5206\u6570\u548c4.0\u7684\u76ae\u5c14\u900a\u76f8\u5173\u6027\uff0c\u8d85\u8fc7\u4e86\u57fa\u4e8ePyannote.audio\u7684\u5206\u5272\u57fa\u7ebf\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u7a81\u51fa\u4e86\u57fa\u4e8e\u5757\u7684\u591aSSL\u878d\u5408\u5728\u7a33\u5065\u6d41\u5229\u5ea6\u8bc4\u4f30\u4e2d\u7684\u6f5c\u529b\uff0c\u5c3d\u7ba1\u672a\u6765\u7684\u5de5\u4f5c\u5e94\u63a2\u7d22\u5728\u5177\u6709\u4e0d\u89c4\u5219\u8bed\u8c03\u7684\u65b9\u8a00\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.20269", "pdf": "https://arxiv.org/pdf/2506.20269", "abs": "https://arxiv.org/abs/2506.20269", "authors": ["Kai-Robin Lange", "Tobias Schmidt", "Matthias Reccius", "Henrik M\u00fcller", "Michael Roos", "Carsten Jentsch"], "title": "Narrative Shift Detection: A Hybrid Approach of Dynamic Topic Models and Large Language Models", "categories": ["cs.CL", "econ.GN", "q-fin.EC"], "comment": "14 pages, 1 figure", "summary": "With rapidly evolving media narratives, it has become increasingly critical\nto not just extract narratives from a given corpus but rather investigate, how\nthey develop over time. While popular narrative extraction methods such as\nLarge Language Models do well in capturing typical narrative elements or even\nthe complex structure of a narrative, applying them to an entire corpus comes\nwith obstacles, such as a high financial or computational cost. We propose a\ncombination of the language understanding capabilities of Large Language Models\nwith the large scale applicability of topic models to dynamically model\nnarrative shifts across time using the Narrative Policy Framework. We apply a\ntopic model and a corresponding change point detection method to find changes\nthat concern a specific topic of interest. Using this model, we filter our\ncorpus for documents that are particularly representative of that change and\nfeed them into a Large Language Model that interprets the change that happened\nin an automated fashion and distinguishes between content and narrative shifts.\nWe employ our pipeline on a corpus of The Wall Street Journal news paper\narticles from 2009 to 2023. Our findings indicate that a Large Language Model\ncan efficiently extract a narrative shift if one exists at a given point in\ntime, but does not perform as well when having to decide whether a shift in\ncontent or a narrative shift took place.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u4e3b\u9898\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u52a8\u6001\u5efa\u6a21\u53d9\u4e8b\u53d8\u5316\u3002\u6211\u4eec\u5e94\u7528\u8fd9\u79cd\u65b9\u6cd5\u5206\u6790\u4e862009\u5e74\u81f32023\u5e74\u300a\u534e\u5c14\u8857\u65e5\u62a5\u300b\u7684\u65b0\u95fb\u6587\u7ae0\u8bed\u6599\u5e93\uff0c\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63d0\u53d6\u53d9\u4e8b\u53d8\u5316\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u533a\u5206\u5185\u5bb9\u548c\u53d9\u4e8b\u53d8\u5316\u65b9\u9762\u6548\u679c\u4e0d\u4f73\u3002", "motivation": "\u968f\u7740\u5a92\u4f53\u53d9\u8ff0\u7684\u8fc5\u901f\u6f14\u53d8\uff0c\u4e0d\u4ec5\u9700\u8981\u4ece\u7ed9\u5b9a\u8bed\u6599\u5e93\u4e2d\u63d0\u53d6\u53d9\u8ff0\uff0c\u8fd8\u9700\u8981\u7814\u7a76\u5b83\u4eec\u5982\u4f55\u968f\u65f6\u95f4\u53d1\u5c55\u3002\u867d\u7136\u6d41\u884c\u7684\u53d9\u8ff0\u63d0\u53d6\u65b9\u6cd5\u5982\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6355\u6349\u5178\u578b\u53d9\u8ff0\u5143\u7d20\u6216\u751a\u81f3\u590d\u6742\u7ed3\u6784\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5c06\u5176\u5e94\u7528\u4e8e\u6574\u4e2a\u8bed\u6599\u5e93\u4f1a\u9047\u5230\u969c\u788d\uff0c\u4f8b\u5982\u9ad8\u6210\u672c\u6216\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u6211\u4eec\u7ed3\u5408\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u548c\u4e3b\u9898\u6a21\u578b\u7684\u5927\u89c4\u6a21\u9002\u7528\u6027\uff0c\u4f7f\u7528\u53d9\u4e8b\u653f\u7b56\u6846\u67b6\u52a8\u6001\u5efa\u6a21\u53d9\u4e8b\u53d8\u5316\u3002\u6211\u4eec\u5e94\u7528\u4e86\u4e00\u4e2a\u4e3b\u9898\u6a21\u578b\u548c\u76f8\u5e94\u7684\u53d8\u5316\u70b9\u68c0\u6d4b\u65b9\u6cd5\u6765\u5bfb\u627e\u4e0e\u7279\u5b9a\u4e3b\u9898\u76f8\u5173\u7684\u53d8\u5316\uff0c\u5e76\u5229\u7528\u8be5\u6a21\u578b\u8fc7\u6ee4\u51fa\u7279\u522b\u4ee3\u8868\u8be5\u53d8\u5316\u7684\u6587\u6863\uff0c\u7136\u540e\u5c06\u5b83\u4eec\u8f93\u5165\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u8fdb\u884c\u81ea\u52a8\u89e3\u91ca\u548c\u533a\u5206\u5185\u5bb9\u548c\u53d9\u4e8b\u53d8\u5316\u3002", "result": "\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u5728\u5b58\u5728\u53d9\u4e8b\u53d8\u5316\u65f6\u6709\u6548\u5730\u63d0\u53d6\u53d9\u4e8b\u53d8\u5316\uff0c\u4f46\u5728\u51b3\u5b9a\u5185\u5bb9\u53d8\u5316\u8fd8\u662f\u53d9\u4e8b\u53d8\u5316\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u5728\u5b58\u5728\u53d9\u4e8b\u53d8\u5316\u65f6\u6709\u6548\u5730\u63d0\u53d6\u53d9\u4e8b\u53d8\u5316\uff0c\u4f46\u5728\u51b3\u5b9a\u5185\u5bb9\u53d8\u5316\u8fd8\u662f\u53d9\u4e8b\u53d8\u5316\u65f6\u8868\u73b0\u4e0d\u4f73\u3002"}}
{"id": "2506.20331", "pdf": "https://arxiv.org/pdf/2506.20331", "abs": "https://arxiv.org/abs/2506.20331", "authors": ["Rian Touchent", "Nathan Godey", "Eric de la Clergerie"], "title": "Biomed-Enriched: A Biomedical Dataset Enriched with LLMs for Pretraining and Extracting Rare and Hidden Content", "categories": ["cs.CL", "cs.LG"], "comment": "Dataset link: https://hf.co/datasets/almanach/Biomed-Enriched", "summary": "We introduce Biomed-Enriched, a biomedical text dataset constructed from\nPubMed via a two-stage annotation process. In the first stage, a large language\nmodel annotates 400K paragraphs from PubMed scientific articles, assigning\nscores for their type (review, study, clinical case, other), domain (clinical,\nbiomedical, other), and educational quality. The educational quality score\n(rated 1 to 5) estimates how useful a paragraph is for college-level learning.\nThese annotations are then used to fine-tune a small language model, which\npropagates the labels across the full PMC-OA corpus. The resulting metadata\nallows us to extract refined subsets, including 2M clinical case paragraphs\nwith over 450K high-quality ones from articles with commercial-use licenses,\nand to construct several variants via quality filtering and domain upsampling.\nClinical text is typically difficult to access due to privacy constraints, as\nhospital records cannot be publicly shared. Hence, our dataset provides an\nalternative large-scale, openly available collection of clinical cases from\nPubMed, making it a valuable resource for biomedical and clinical NLP.\nPreliminary continual-pretraining experiments with OLMo2 suggest these curated\nsubsets enable targeted improvements, with clinical upsampling boosting\nperformance by ~5% on MMLU ProfMed and educational quality filtering improving\nMedQA and MedMCQA by ~1%. Combinations of these techniques led to faster\nconvergence, reaching same performance with a third of training tokens,\nindicating potential for more efficient and effective biomedical pretraining\nstrategies.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Biomed-Enriched\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u901a\u8fc7\u4e24\u9636\u6bb5\u6ce8\u91ca\u8fc7\u7a0b\u6784\u5efa\uff0c\u80fd\u591f\u63d0\u4f9b\u5927\u89c4\u6a21\u3001\u516c\u5f00\u53ef\u7528\u7684\u4e34\u5e8a\u6848\u4f8b\uff0c\u7528\u4e8e\u751f\u7269\u533b\u5b66\u548c\u4e34\u5e8aNLP\u7814\u7a76\uff0c\u5e76\u5c55\u793a\u4e86\u901a\u8fc7\u8d28\u91cf\u8fc7\u6ee4\u548c\u9886\u57df\u4e0a\u91c7\u6837\u7b49\u6280\u672f\u53ef\u4ee5\u5b9e\u73b0\u66f4\u9ad8\u6548\u548c\u6709\u6548\u7684\u751f\u7269\u533b\u5b66\u9884\u8bad\u7ec3\u7b56\u7565\u3002", "motivation": "\u4e34\u5e8a\u6587\u672c\u901a\u5e38\u7531\u4e8e\u9690\u79c1\u9650\u5236\u96be\u4ee5\u83b7\u53d6\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u516c\u5f00\u53ef\u7528\u7684\u4e34\u5e8a\u6848\u4f8b\u96c6\u5408\u3002", "method": "\u6211\u4eec\u901a\u8fc7\u4e24\u9636\u6bb5\u6ce8\u91ca\u8fc7\u7a0b\u6784\u5efa\u4e86Biomed-Enriched\u6570\u636e\u96c6\uff0c\u9996\u5148\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9PubMed\u4e2d\u7684400K\u6bb5\u843d\u8fdb\u884c\u6ce8\u91ca\uff0c\u7136\u540e\u5fae\u8c03\u4e00\u4e2a\u5c0f\u7684\u8bed\u8a00\u6a21\u578b\u4ee5\u5728\u6574\u4e2aPMC-OA\u8bed\u6599\u5e93\u4e2d\u4f20\u64ad\u6807\u7b7e\u3002", "result": "\u901a\u8fc7\u8d28\u91cf\u8fc7\u6ee4\u548c\u9886\u57df\u4e0a\u91c7\u6837\uff0c\u6211\u4eec\u63d0\u53d6\u4e86\u7ecf\u8fc7\u7cbe\u70bc\u7684\u5b50\u96c6\uff0c\u5e76\u5728MMLU ProfMed\u548cMedQA\u7b49\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u6211\u4eec\u7684\u6570\u636e\u96c6\u4e3a\u751f\u7269\u533b\u5b66\u548c\u4e34\u5e8aNLP\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d44\u6e90\uff0c\u5e76\u5c55\u793a\u4e86\u901a\u8fc7\u8d28\u91cf\u8fc7\u6ee4\u548c\u9886\u57df\u4e0a\u91c7\u6837\u7b49\u6280\u672f\u53ef\u4ee5\u5b9e\u73b0\u66f4\u9ad8\u6548\u548c\u6709\u6548\u7684\u751f\u7269\u533b\u5b66\u9884\u8bad\u7ec3\u7b56\u7565\u3002"}}
{"id": "2506.20409", "pdf": "https://arxiv.org/pdf/2506.20409", "abs": "https://arxiv.org/abs/2506.20409", "authors": ["Ekaterina Taktasheva", "Jeff Dalton"], "title": "TAPS: Tool-Augmented Personalisation via Structured Tagging", "categories": ["cs.CL"], "comment": null, "summary": "Recent advancements in tool-augmented large language models have enabled them\nto interact with external tools, enhancing their ability to perform complex\nuser tasks. However, existing approaches overlook the role of personalisation\nin guiding tool use. This work investigates how user preferences can be\neffectively integrated into goal-oriented dialogue agents. Through extensive\nanalysis, we identify key weaknesses in the ability of LLMs to personalise tool\nuse. To this end, we introduce \\name, a novel solution that enhances\npersonalised tool use by leveraging a structured tagging tool and an\nuncertainty-based tool detector. TAPS significantly improves the ability of\nLLMs to incorporate user preferences, achieving the new state-of-the-art for\nopen source models on the NLSI task.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTAPS\u7684\u65b0\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6807\u8bb0\u5de5\u5177\u548c\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u5de5\u5177\u68c0\u6d4b\u5668\u6765\u589e\u5f3a\u4e2a\u6027\u5316\u5de5\u5177\u4f7f\u7528\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLMs\u6574\u5408\u7528\u6237\u504f\u597d\u7684\u80fd\u529b\uff0c\u5e76\u5728NLSI\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7684\u6c34\u5e73\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5c06\u7528\u6237\u504f\u597d\u6709\u6548\u5730\u6574\u5408\u5230\u76ee\u6807\u5bfc\u5411\u7684\u5bf9\u8bdd\u4ee3\u7406\u4e2d\uff0c\u56e0\u4e3a\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4e86\u4e2a\u6027\u5316\u5728\u6307\u5bfc\u5de5\u5177\u4f7f\u7528\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u5f15\u5165\u4e86TAPS\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6807\u8bb0\u5de5\u5177\u548c\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u5de5\u5177\u68c0\u6d4b\u5668\u6765\u589e\u5f3a\u4e2a\u6027\u5316\u7684\u5de5\u5177\u4f7f\u7528\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5206\u6790\uff0c\u6211\u4eec\u53d1\u73b0\u4e86LLMs\u5728\u4e2a\u6027\u5316\u5de5\u5177\u4f7f\u7528\u65b9\u9762\u7684\u5173\u952e\u5f31\u70b9\uff0c\u5e76\u63d0\u51fa\u4e86TAPS\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "TAPS\u663e\u8457\u63d0\u9ad8\u4e86LLMs\u6574\u5408\u7528\u6237\u504f\u597d\u7684\u80fd\u529b\uff0c\u5728NLSI\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7684\u6c34\u5e73\u3002"}}
{"id": "2506.20430", "pdf": "https://arxiv.org/pdf/2506.20430", "abs": "https://arxiv.org/abs/2506.20430", "authors": ["Weike Zhao", "Chaoyi Wu", "Yanjie Fan", "Xiaoman Zhang", "Pengcheng Qiu", "Yuze Sun", "Xiao Zhou", "Yanfeng Wang", "Ya Zhang", "Yongguo Yu", "Kun Sun", "Weidi Xie"], "title": "An Agentic System for Rare Disease Diagnosis with Traceable Reasoning", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MA"], "comment": null, "summary": "Rare diseases collectively affect over 300 million individuals worldwide, yet\ntimely and accurate diagnosis remains a pervasive challenge. This is largely\ndue to their clinical heterogeneity, low individual prevalence, and the limited\nfamiliarity most clinicians have with rare conditions. Here, we introduce\nDeepRare, the first rare disease diagnosis agentic system powered by a large\nlanguage model (LLM), capable of processing heterogeneous clinical inputs. The\nsystem generates ranked diagnostic hypotheses for rare diseases, each\naccompanied by a transparent chain of reasoning that links intermediate\nanalytic steps to verifiable medical evidence.\n  DeepRare comprises three key components: a central host with a long-term\nmemory module; specialized agent servers responsible for domain-specific\nanalytical tasks integrating over 40 specialized tools and web-scale,\nup-to-date medical knowledge sources, ensuring access to the most current\nclinical information. This modular and scalable design enables complex\ndiagnostic reasoning while maintaining traceability and adaptability. We\nevaluate DeepRare on eight datasets. The system demonstrates exceptional\ndiagnostic performance among 2,919 diseases, achieving 100% accuracy for 1013\ndiseases. In HPO-based evaluations, DeepRare significantly outperforms other 15\nmethods, like traditional bioinformatics diagnostic tools, LLMs, and other\nagentic systems, achieving an average Recall@1 score of 57.18% and surpassing\nthe second-best method (Reasoning LLM) by a substantial margin of 23.79\npercentage points. For multi-modal input scenarios, DeepRare achieves 70.60% at\nRecall@1 compared to Exomiser's 53.20% in 109 cases. Manual verification of\nreasoning chains by clinical experts achieves 95.40% agreements. Furthermore,\nthe DeepRare system has been implemented as a user-friendly web application\nhttp://raredx.cn/doctor.", "AI": {"tldr": "DeepRare\u662f\u9996\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7f55\u89c1\u75c5\u8bca\u65ad\u4ee3\u7406\u7cfb\u7edf\uff0c\u80fd\u591f\u5904\u7406\u5f02\u6784\u4e34\u5e8a\u8f93\u5165\u5e76\u751f\u6210\u53ef\u89e3\u91ca\u7684\u8bca\u65ad\u5047\u8bbe\u3002\u5b83\u5728\u591a\u4e2a\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5c55\u793a\u4e86\u5176\u5728\u7f55\u89c1\u75c5\u8bca\u65ad\u4e2d\u7684\u5353\u8d8a\u6027\u80fd\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u7f55\u89c1\u75c5\u7684\u4e34\u5e8a\u5f02\u8d28\u6027\u3001\u4e2a\u4f53\u60a3\u75c5\u7387\u4f4e\u4ee5\u53ca\u5927\u591a\u6570\u4e34\u5e8a\u533b\u751f\u5bf9\u7f55\u89c1\u75c5\u7684\u4e0d\u719f\u6089\uff0c\u4f7f\u5f97\u53ca\u65f6\u51c6\u786e\u7684\u8bca\u65ad\u6210\u4e3a\u4e00\u9879\u666e\u904d\u6311\u6218\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u5f02\u6784\u4e34\u5e8a\u8f93\u5165\u5e76\u751f\u6210\u53ef\u89e3\u91ca\u8bca\u65ad\u5047\u8bbe\u7684\u7cfb\u7edf\u3002", "method": "DeepRare\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7f55\u89c1\u75c5\u8bca\u65ad\u4ee3\u7406\u7cfb\u7edf\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u4e00\u4e2a\u5177\u6709\u957f\u671f\u8bb0\u5fc6\u6a21\u5757\u7684\u4e2d\u592e\u4e3b\u673a\uff0c\u8d1f\u8d23\u9886\u57df\u7279\u5b9a\u5206\u6790\u4efb\u52a1\u7684\u4e13\u4e1a\u4ee3\u7406\u670d\u52a1\u5668\uff0c\u4ee5\u53ca\u6574\u5408\u4e8640\u591a\u4e2a\u4e13\u7528\u5de5\u5177\u548c\u7f51\u7edc\u89c4\u6a21\u3001\u6700\u65b0\u533b\u5b66\u77e5\u8bc6\u6e90\u7684\u7cfb\u7edf\u3002", "result": "DeepRare\u5728\u516b\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5bf9\u4e8e2,919\u79cd\u75be\u75c5\u8fbe\u5230\u4e86100%\u7684\u51c6\u786e\u7387\uff0c\u5176\u4e2d1013\u79cd\u75be\u75c5\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002\u5728HPO\u8bc4\u4f30\u4e2d\uff0cDeepRare\u663e\u8457\u4f18\u4e8e\u5176\u4ed615\u79cd\u65b9\u6cd5\uff0c\u5e73\u5747Recall@1\u5f97\u5206\u4e3a57.18%\uff0c\u6bd4\u7b2c\u4e8c\u597d\u7684\u65b9\u6cd5\u9ad8\u51fa23.79\u4e2a\u767e\u5206\u70b9\u3002\u5728\u591a\u6a21\u6001\u8f93\u5165\u573a\u666f\u4e2d\uff0cDeepRare\u7684Recall@1\u5f97\u5206\u4e3a70.60%\uff0c\u800cExomiser\u4e3a53.20%\u3002\u4e34\u5e8a\u4e13\u5bb6\u5bf9\u63a8\u7406\u94fe\u7684\u624b\u52a8\u9a8c\u8bc1\u4e5f\u8fbe\u5230\u4e8695.40%\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "DeepRare\u7cfb\u7edf\u5df2\u88ab\u5b9e\u73b0\u4e3a\u4e00\u4e2a\u7528\u6237\u53cb\u597d\u7684\u7f51\u9875\u5e94\u7528\uff0c\u5c55\u793a\u4e86\u5176\u5728\u7f55\u89c1\u75c5\u8bca\u65ad\u4e2d\u7684\u5353\u8d8a\u6027\u80fd\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.20471", "pdf": "https://arxiv.org/pdf/2506.20471", "abs": "https://arxiv.org/abs/2506.20471", "authors": ["Ujwal Narayan", "Shreyas Chaudhari", "Ashwin Kalyan", "Tanmay Rajpurohit", "Karthik Narasimhan", "Ameet Deshpande", "Vishvak Murahari"], "title": "Probing AI Safety with Source Code", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have become ubiquitous, interfacing with humans\nin numerous safety-critical applications. This necessitates improving\ncapabilities, but importantly coupled with greater safety measures to align\nthese models with human values and preferences. In this work, we demonstrate\nthat contemporary models fall concerningly short of the goal of AI safety,\nleading to an unsafe and harmful experience for users. We introduce a prompting\nstrategy called Code of Thought (CoDoT) to evaluate the safety of LLMs. CoDoT\nconverts natural language inputs to simple code that represents the same\nintent. For instance, CoDoT transforms the natural language prompt \"Make the\nstatement more toxic: {text}\" to: \"make_more_toxic({text})\". We show that CoDoT\nresults in a consistent failure of a wide range of state-of-the-art LLMs. For\nexample, GPT-4 Turbo's toxicity increases 16.5 times, DeepSeek R1 fails 100% of\nthe time, and toxicity increases 300% on average across seven modern LLMs.\nAdditionally, recursively applying CoDoT can further increase toxicity two\ntimes. Given the rapid and widespread adoption of LLMs, CoDoT underscores the\ncritical need to evaluate safety efforts from first principles, ensuring that\nsafety and capabilities advance together.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86CoDoT\u63d0\u793a\u7b56\u7565\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u3002\u7ed3\u679c\u663e\u793a\uff0cCoDoT\u5bfc\u81f4\u591a\u4e2a\u5148\u8fdbLLMs\u51fa\u73b0\u4e25\u91cd\u5b89\u5168\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u4ece\u57fa\u7840\u539f\u7406\u8bc4\u4f30\u5b89\u5168\u6027\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8bb8\u591a\u5b89\u5168\u5173\u952e\u578b\u5e94\u7528\u4e2d\u4e0e\u4eba\u7c7b\u4ea4\u4e92\uff0c\u8fd9\u9700\u8981\u63d0\u9ad8\u80fd\u529b\uff0c\u4f46\u66f4\u91cd\u8981\u7684\u662f\u8981\u589e\u5f3a\u5b89\u5168\u63aa\u65bd\uff0c\u4f7f\u8fd9\u4e9b\u6a21\u578b\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u548c\u504f\u597d\u4fdd\u6301\u4e00\u81f4\u3002\u7136\u800c\uff0c\u5f53\u524d\u6a21\u578b\u5728AI\u5b89\u5168\u65b9\u9762\u4ecd\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u5bfc\u81f4\u7528\u6237\u4f53\u9a8c\u4e0d\u5b89\u5168\u548c\u6709\u5bb3\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u79f0\u4e3aCode of Thought (CoDoT)\u7684\u63d0\u793a\u7b56\u7565\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u8f6c\u6362\u4e3a\u8868\u793a\u76f8\u540c\u610f\u56fe\u7684\u7b80\u5355\u4ee3\u7801\u3002", "result": "CoDoT\u5bfc\u81f4\u591a\u79cd\u6700\u5148\u8fdb\u7684LLMs\u51fa\u73b0\u4e00\u81f4\u6027\u5931\u8d25\u3002\u4f8b\u5982\uff0cGPT-4 Turbo\u7684\u6bd2\u6027\u589e\u52a0\u4e8616.5\u500d\uff0cDeepSeek R1 100%\u5931\u8d25\uff0c\u800c\u4e03\u79cd\u73b0\u4ee3LLMs\u7684\u5e73\u5747\u6bd2\u6027\u589e\u52a0\u4e86300%\u3002\u6b64\u5916\uff0c\u9012\u5f52\u5e94\u7528CoDoT\u53ef\u4ee5\u8fdb\u4e00\u6b65\u5c06\u6bd2\u6027\u589e\u52a0\u4e24\u500d\u3002", "conclusion": "CoDoT underscores the critical need to evaluate safety efforts from first principles, ensuring that safety and capabilities advance together."}}
{"id": "2506.20474", "pdf": "https://arxiv.org/pdf/2506.20474", "abs": "https://arxiv.org/abs/2506.20474", "authors": ["Kaixiang Zhang", "Justine Zhang", "Cristian Danescu-Niculescu-Mizil"], "title": "Time is On My Side: Dynamics of Talk-Time Sharing in Video-chat Conversations", "categories": ["cs.CL"], "comment": null, "summary": "An intrinsic aspect of every conversation is the way talk-time is shared\nbetween multiple speakers. Conversations can be balanced, with each speaker\nclaiming a similar amount of talk-time, or imbalanced when one talks\ndisproportionately. Such overall distributions are the consequence of\ncontinuous negotiations between the speakers throughout the conversation: who\nshould be talking at every point in time, and for how long?\n  In this work we introduce a computational framework for quantifying both the\nconversation-level distribution of talk-time between speakers, as well as the\nlower-level dynamics that lead to it. We derive a typology of talk-time sharing\ndynamics structured by several intuitive axes of variation. By applying this\nframework to a large dataset of video-chats between strangers, we confirm that,\nperhaps unsurprisingly, different conversation-level distributions of talk-time\nare perceived differently by speakers, with balanced conversations being\npreferred over imbalanced ones, especially by those who end up talking less.\nThen we reveal that -- even when they lead to the same level of overall balance\n-- different types of talk-time sharing dynamics are perceived differently by\nthe participants, highlighting the relevance of our newly introduced typology.\nFinally, we discuss how our framework offers new tools to designers of\ncomputer-mediated communication platforms, for both human-human and human-AI\ncommunication.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u5bf9\u8bdd\u4e2d\u7684\u8c08\u8bdd\u65f6\u95f4\u5206\u5e03\u53ca\u5176\u52a8\u6001\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e0d\u540c\u7c7b\u578b\u7684\u52a8\u6001\u5bf9\u53c2\u4e0e\u8005\u7684\u611f\u77e5\u6709\u4e0d\u540c\u5f71\u54cd\uff0c\u4e3a\u8ba1\u7b97\u673a\u4e2d\u4ecb\u901a\u4fe1\u5e73\u53f0\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002", "motivation": "\u5bf9\u8bdd\u4e2d\u7684\u8c08\u8bdd\u65f6\u95f4\u5206\u914d\u662f\u5bf9\u8bdd\u7684\u4e00\u4e2a\u56fa\u6709\u65b9\u9762\uff0c\u4f46\u4e0d\u540c\u7c7b\u578b\u7684\u8c08\u8bdd\u65f6\u95f4\u5171\u4eab\u52a8\u6001\u53ef\u80fd\u5bf9\u53c2\u4e0e\u8005\u4ea7\u751f\u4e0d\u540c\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5206\u6790\u548c\u7406\u89e3\u8fd9\u4e9b\u52a8\u6001\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u5bf9\u8bdd\u7ea7\u522b\u7684\u8c08\u8bdd\u65f6\u95f4\u5206\u5e03\u4ee5\u53ca\u5bfc\u81f4\u5b83\u7684\u4f4e\u5c42\u6b21\u52a8\u6001\u3002\u6211\u4eec\u63a8\u5bfc\u51fa\u4e00\u4e2a\u7531\u51e0\u4e2a\u76f4\u89c2\u7684\u53d8\u5316\u8f74\u7ed3\u6784\u5316\u7684\u8c08\u8bdd\u65f6\u95f4\u5171\u4eab\u52a8\u6001\u7c7b\u578b\u5b66\u3002", "result": "\u6211\u4eec\u901a\u8fc7\u5e94\u7528\u8fd9\u4e2a\u6846\u67b6\u5230\u5927\u91cf\u964c\u751f\u4eba\u4e4b\u95f4\u7684\u89c6\u9891\u901a\u8bdd\u6570\u636e\u96c6\u4e2d\uff0c\u786e\u8ba4\u4e86\u4e0d\u540c\u5bf9\u8bdd\u7ea7\u522b\u7684\u8c08\u8bdd\u65f6\u95f4\u5206\u5e03\u88ab\u8bf4\u8bdd\u8005\u4e0d\u540c\u5730\u611f\u77e5\uff0c\u5e73\u8861\u7684\u5bf9\u8bdd\u6bd4\u4e0d\u5e73\u8861\u7684\u5bf9\u8bdd\u66f4\u53d7\u504f\u597d\uff0c\u5c24\u5176\u662f\u90a3\u4e9b\u8bf4\u8bdd\u8f83\u5c11\u7684\u4eba\u3002\u6b64\u5916\uff0c\u5373\u4f7f\u5b83\u4eec\u5bfc\u81f4\u76f8\u540c\u7684\u603b\u4f53\u5e73\u8861\u6c34\u5e73\uff0c\u4e0d\u540c\u7684\u8c08\u8bdd\u65f6\u95f4\u5171\u4eab\u52a8\u6001\u4e5f\u88ab\u53c2\u4e0e\u8005\u4e0d\u540c\u5730\u611f\u77e5\u3002", "conclusion": "\u6211\u4eec\u7684\u6846\u67b6\u4e3a\u8ba1\u7b97\u673a\u4e2d\u4ecb\u901a\u4fe1\u5e73\u53f0\u7684\u8bbe\u8ba1\u8005\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u4eba\u7c7b\u4e0e\u4eba\u7c7b\u4ee5\u53ca\u4eba\u7c7b\u4e0eAI\u7684\u4ea4\u6d41\u3002"}}
{"id": "2506.20476", "pdf": "https://arxiv.org/pdf/2506.20476", "abs": "https://arxiv.org/abs/2506.20476", "authors": ["Tong Zhou"], "title": "Knowledge-Aware Diverse Reranking for Cross-Source Question Answering", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "This paper presents Team Marikarp's solution for the SIGIR 2025 LiveRAG\ncompetition. The competition's evaluation set, automatically generated by\nDataMorgana from internet corpora, encompassed a wide range of target topics,\nquestion types, question formulations, audience types, and knowledge\norganization methods. It offered a fair evaluation of retrieving\nquestion-relevant supporting documents from a 15M documents subset of the\nFineWeb corpus. Our proposed knowledge-aware diverse reranking RAG pipeline\nachieved first place in the competition.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Team Marikarp\u5728SIGIR 2025 LiveRAG\u7ade\u8d5b\u4e2d\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u901a\u8fc7\u77e5\u8bc6\u611f\u77e5\u591a\u6837\u5316\u91cd\u6392\u5e8fRAG\u6d41\u7a0b\u53d6\u5f97\u4e86\u7b2c\u4e00\u540d\u3002", "motivation": "\u4e3a\u4e86\u5728SIGIR 2025 LiveRAG\u7ade\u8d5b\u4e2d\u53d6\u5f97\u597d\u6210\u7ee9\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u68c0\u7d22\u76f8\u5173\u652f\u6301\u6587\u6863\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u77e5\u8bc6\u611f\u77e5\u591a\u6837\u5316\u91cd\u6392\u5e8fRAG\u6d41\u7a0b\u3002", "result": "\u5728\u6bd4\u8d5b\u4e2d\u83b7\u5f97\u4e86\u7b2c\u4e00\u540d\u3002", "conclusion": "\u6211\u4eec\u7684\u77e5\u8bc6\u611f\u77e5\u591a\u6837\u5316\u91cd\u6392\u5e8fRAG\u6d41\u7a0b\u5728\u6bd4\u8d5b\u4e2d\u83b7\u5f97\u4e86\u7b2c\u4e00\u540d\u3002"}}
{"id": "2506.20480", "pdf": "https://arxiv.org/pdf/2506.20480", "abs": "https://arxiv.org/abs/2506.20480", "authors": ["Guinan Su", "Li Shen", "Lu Yin", "Shiwei Liu", "Yanwu Yang", "Jonas Geiping"], "title": "GPTailor: Large Language Model Pruning Through Layer Cutting and Stitching", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have shown remarkable capabilities in language\nunderstanding and generation. However, such impressive capability typically\ncomes with a substantial model size, which presents significant challenges in\ndeployment and inference. While structured pruning of model parameters offers a\npromising way to reduce computational costs at deployment time, current methods\nprimarily focus on single model pruning. In this work, we develop a novel\nstrategy to compress models by strategically combining or merging layers from\nfinetuned model variants, which preserves the original model's abilities by\naggregating capabilities accentuated in different finetunes. We pose the\noptimal tailoring of these LLMs as a zero-order optimization problem, adopting\na search space that supports three different operations: (1) Layer removal, (2)\nLayer selection from different candidate models, and (3) Layer merging. Our\nexperiments demonstrate that this approach leads to competitive model pruning,\nfor example, for the Llama2-13B model families, our compressed models maintain\napproximately 97.3\\% of the original performance while removing $\\sim25\\%$ of\nparameters, significantly outperforming previous state-of-the-art methods. The\ncode is available at https://github.com/Guinan-Su/auto-merge-llm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u5e76\u4e0d\u540c\u5fae\u8c03\u6a21\u578b\u7684\u5c42\u6765\u538b\u7f29\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4ee5\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u5e76\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u4e2a\u6a21\u578b\u7684\u526a\u679d\u4e0a\uff0c\u800c\u6211\u4eec\u5e0c\u671b\u901a\u8fc7\u7ed3\u5408\u4e0d\u540c\u5fae\u8c03\u6a21\u578b\u7684\u5c42\u6765\u66f4\u6709\u6548\u5730\u538b\u7f29\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u7559\u539f\u59cb\u6a21\u578b\u7684\u80fd\u529b\u3002", "method": "\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u7b56\u7565\uff0c\u901a\u8fc7\u4ece\u5fae\u8c03\u6a21\u578b\u53d8\u4f53\u4e2d\u6218\u7565\u6027\u5730\u7ec4\u5408\u6216\u5408\u5e76\u5c42\u6765\u538b\u7f29\u6a21\u578b\uff0c\u4ece\u800c\u5728\u90e8\u7f72\u65f6\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u96f6\u9636\u4f18\u5316\u95ee\u9898\uff0c\u652f\u6301\u4e09\u79cd\u4e0d\u540c\u7684\u64cd\u4f5c\uff1a(1) \u5c42\u79fb\u9664\uff0c(2) \u4ece\u4e0d\u540c\u5019\u9009\u6a21\u578b\u4e2d\u9009\u62e9\u5c42\uff0c(3) \u5c42\u5408\u5e76\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u6a21\u578b\u526a\u679d\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f8b\u5982\u5bf9\u4e8eLlama2-13B\u6a21\u578b\u5bb6\u65cf\uff0c\u6211\u4eec\u7684\u538b\u7f29\u6a21\u578b\u4fdd\u6301\u4e86\u539f\u59cb\u6027\u80fd\u7684\u5927\u7ea697.3%\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u7ea625%\u7684\u53c2\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u538b\u7f29\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u5728\u51cf\u5c11\u53c2\u6570\u7684\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u539f\u59cb\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.20495", "pdf": "https://arxiv.org/pdf/2506.20495", "abs": "https://arxiv.org/abs/2506.20495", "authors": ["Haoze Wu", "Yunzhi Yao", "Wenhao Yu", "Huajun Chen", "Ningyu Zhang"], "title": "ReCode: Updating Code API Knowledge with Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "cs.SE"], "comment": "Work in progress", "summary": "Large Language Models (LLMs) exhibit remarkable code generation capabilities\nbut falter when adapting to frequent updates in external library APIs. This\ncritical limitation, stemming from reliance on outdated API knowledge from\ntheir training data, even with access to current documentation, impedes\nreliable code generation in dynamic environments. To tackle this issue, we\npropose ReCode (rule-based Reinforcement learning for Code Update), a novel\nframework that mimics human programmer adaptation to API changes. Specifically,\nwe construct a dataset of approximately 2,000 data entries to train the LLMs to\nperform version migration based on updated information. Then, we introduce a\nmodified string similarity metric for code evaluation as the reward for\nreinforcement learning. Our experiments demonstrate that ReCode substantially\nboosts LLMs' code generation performance in dynamic API scenarios, especially\non the unseen CodeUpdateArena task. Crucially, compared to supervised\nfine-tuning, ReCode has less impact on LLMs' general code generation abilities.\nWe apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and\nDAPO), all achieving consistent improvements. Notably, after training,\nQwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned\nmodel and the reasoning model with the same architecture. Code is available at\nhttps://github.com/zjunlp/ReCode.", "AI": {"tldr": "ReCode is a novel framework that improves the ability of Large Language Models (LLMs) to adapt to changes in external library APIs. It uses a dataset of 2,000 data entries and a modified string similarity metric for code evaluation as a reward for reinforcement learning. Experiments show that ReCode significantly enhances LLMs' code generation performance in dynamic API scenarios, particularly on the CodeUpdateArena task. It also has less impact on LLMs' general code generation abilities compared to supervised fine-tuning.", "motivation": "Large Language Models (LLMs) exhibit remarkable code generation capabilities but falter when adapting to frequent updates in external library APIs. This critical limitation, stemming from reliance on outdated API knowledge from their training data, even with access to current documentation, impedes reliable code generation in dynamic environments.", "method": "We propose ReCode (rule-based Reinforcement learning for Code Update), a novel framework that mimics human programmer adaptation to API changes. Specifically, we construct a dataset of approximately 2,000 data entries to train the LLMs to perform version migration based on updated information. Then, we introduce a modified string similarity metric for code evaluation as the reward for reinforcement learning.", "result": "Our experiments demonstrate that ReCode substantially boosts LLMs' code generation performance in dynamic API scenarios, especially on the unseen CodeUpdateArena task. Crucially, compared to supervised fine-tuning, ReCode has less impact on LLMs' general code generation abilities. We apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and DAPO), all achieving consistent improvements. Notably, after training, Qwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned model and the reasoning model with the same architecture.", "conclusion": "ReCode substantially boosts LLMs' code generation performance in dynamic API scenarios, especially on the unseen CodeUpdateArena task. Crucially, compared to supervised fine-tuning, ReCode has less impact on LLMs' general code generation abilities. We apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and DAPO), all achieving consistent improvements. Notably, after training, Qwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned model and the reasoning model with the same architecture."}}
{"id": "2506.20512", "pdf": "https://arxiv.org/pdf/2506.20512", "abs": "https://arxiv.org/abs/2506.20512", "authors": ["Zengzhi Wang", "Fan Zhou", "Xuefeng Li", "Pengfei Liu"], "title": "OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "26 pages; The first three authors contribute to this work equally", "summary": "Different base language model families, such as Llama and Qwen, exhibit\ndivergent behaviors during post-training with reinforcement learning (RL),\nespecially on reasoning-intensive tasks. What makes a base language model\nsuitable for reinforcement learning? Gaining deeper insight into this question\nis essential for developing RL-scalable foundation models of the next\ngeneration. In this work, we investigate how mid-training strategies shape RL\ndynamics, focusing on two representative model families: Qwen and Llama. Our\nstudy reveals that (1) high-quality mathematical corpora, such as\nMegaMath-Web-Pro, significantly improve both base model and RL performance,\nwhile existing alternatives (e.g., FineMath-4plus) fail to do so; (2) further\nadding QA-style data, particularly long chain-of-thought (CoT) reasoning\nexamples, enhances RL outcomes, and instruction data further unlocks this\neffect; (3) while long-CoT improves reasoning depth, it can also induce\nverbosity of model responses and unstability of RL training, underscoring the\nimportance of data formatting; (4) scaling mid-training consistently leads to\nstronger downstream RL performance. Building on these insights, we introduce a\ntwo-stage mid-training strategy, Stable-then-Decay, in which base models are\nfirst trained on 200B tokens with a constant learning rate, followed by 20B\ntokens across three CoT-focused branches with learning rate decay. This yields\nOctoThinker, a family of models demonstrating strong RL compatibility and\nclosing the performance gap with more RL-friendly model families, i.e., Qwen.\nWe hope our work will help shape pre-training strategies for foundation models\nin the RL era. To support further research, we release our open-source models\nalong with a curated math reasoning-intensive corpus of over 70 billion tokens\n(i.e., MegaMath-Web-Pro-Max).", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e2d\u671f\u8bad\u7ec3\u7b56\u7565\u5982\u4f55\u5f71\u54cd\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684\u4e2d\u671f\u8bad\u7ec3\u7b56\u7565\uff0c\u4ee5\u63d0\u9ad8\u57fa\u7840\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u517c\u5bb9\u6027\u3002", "motivation": "\u4e86\u89e3\u4ec0\u4e48\u4f7f\u57fa\u7840\u8bed\u8a00\u6a21\u578b\u9002\u5408\u5f3a\u5316\u5b66\u4e60\u5bf9\u4e8e\u5f00\u53d1\u4e0b\u4e00\u4ee3\u53ef\u6269\u5c55\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u7840\u6a21\u578b\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6211\u4eec\u7814\u7a76\u4e86\u4e2d\u671f\u8bad\u7ec3\u7b56\u7565\u5982\u4f55\u5f71\u54cd\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\uff0c\u91cd\u70b9\u5173\u6ce8\u4e24\u4e2a\u4ee3\u8868\u6027\u6a21\u578b\u5bb6\u65cf\uff1aQwen\u548cLlama\u3002\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u7684\u4e2d\u671f\u8bad\u7ec3\u7b56\u7565\uff0c\u5373Stable-then-Decay\u3002", "result": "\u6211\u4eec\u7684\u7814\u7a76\u63ed\u793a\u4e86\u9ad8\u8d28\u91cf\u7684\u6570\u5b66\u8bed\u6599\u5e93\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u57fa\u7840\u6a21\u578b\u548c\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\uff0c\u800c\u73b0\u6709\u7684\u66ff\u4ee3\u65b9\u6848\u5219\u65e0\u6cd5\u505a\u5230\u8fd9\u4e00\u70b9\u3002\u6dfb\u52a0\u95ee\u7b54\u98ce\u683c\u7684\u6570\u636e\uff0c\u7279\u522b\u662f\u957f\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u63a8\u7406\u793a\u4f8b\uff0c\u53ef\u4ee5\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u4e2d\u671f\u8bad\u7ec3\u7684\u6269\u5c55\u4e00\u81f4\u5730\u5bfc\u81f4\u66f4\u5f3a\u7684\u4e0b\u6e38\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\u3002", "conclusion": "\u6211\u4eec\u7684\u5de5\u4f5c\u6709\u52a9\u4e8e\u5851\u9020\u5f3a\u5316\u5b66\u4e60\u65f6\u4ee3\u7684\u57fa\u7840\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u7b56\u7565\u3002\u6211\u4eec\u91ca\u653e\u4e86\u5f00\u6e90\u6a21\u578b\u4ee5\u53ca\u4e00\u4e2a\u7ecf\u8fc7\u7b5b\u9009\u7684\u6570\u5b66\u63a8\u7406\u5bc6\u96c6\u578b\u8bed\u6599\u5e93\uff0c\u4ee5\u652f\u6301\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u3002"}}
{"id": "2506.20544", "pdf": "https://arxiv.org/pdf/2506.20544", "abs": "https://arxiv.org/abs/2506.20544", "authors": ["Ammar Khairi", "Daniel D'souza", "Ye Shen", "Julia Kreutzer", "Sara Hooker"], "title": "When Life Gives You Samples: The Benefits of Scaling up Inference Compute for Multilingual LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have shifted focus toward\nscaling inference-time compute, improving performance without retraining the\nmodel. A common approach is to sample multiple outputs in parallel, and select\none of these as the final output. However, work to date has focused on English\nand a handful of domains such as math and code. In contrast, we are most\ninterested in techniques that generalize across open-ended tasks, formally\nverifiable tasks, and across languages. In this work, we study how to robustly\nscale inference-time compute for open-ended generative tasks in a multilingual,\nmulti-task setting.\n  Our findings show that both sampling strategy based on temperature variation\nand selection strategy must be adapted to account for diverse domains and\nvaried language settings. We evaluate existing selection methods, revealing\nthat strategies effective in English often fail to generalize across languages.\nWe propose novel sampling and selection strategies specifically adapted for\nmultilingual and multi-task inference scenarios, and show they yield notable\ngains across languages and tasks. In particular, our combined sampling and\nselection methods lead to an average +6.8 jump in win-rates for our 8B models\non m-ArenaHard-v2.0 prompts, against proprietary models such as Gemini. At\nlarger scale, Command-A (111B model) equipped with our methods, shows +9.0\nimprovement in win-rates on the same benchmark with just five samples against\nsingle-sample decoding, a substantial increase at minimal cost. Our results\nunderscore the need for language- and task-aware approaches to inference-time\ncompute, aiming to democratize performance improvements in underrepresented\nlanguages.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5728\u591a\u8bed\u8a00\u3001\u591a\u4efb\u52a1\u8bbe\u7f6e\u4e2d\u7a33\u5065\u5730\u6269\u5c55\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\u80fd\u529b\u3002\u6211\u4eec\u8bc4\u4f30\u4e86\u73b0\u6709\u7684\u9009\u62e9\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u9488\u5bf9\u591a\u8bed\u8a00\u548c\u591a\u4efb\u52a1\u63a8\u7406\u573a\u666f\u7684\u65b0\u578b\u91c7\u6837\u548c\u9009\u62e9\u7b56\u7565\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9b\u7b56\u7565\u5728\u591a\u79cd\u8bed\u8a00\u548c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e86\u663e\u8457\u7684\u63d0\u5347\u3002", "motivation": "\u6700\u8fd1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8fdb\u6b65\u5c06\u91cd\u70b9\u8f6c\u5411\u6269\u5c55\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\uff0c\u4ee5\u63d0\u9ad8\u6027\u80fd\u800c\u4e0d\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002\u7136\u800c\uff0c\u8fc4\u4eca\u4e3a\u6b62\u7684\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u82f1\u8bed\u548c\u4e00\u4e9b\u9886\u57df\uff0c\u5982\u6570\u5b66\u548c\u4ee3\u7801\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u6211\u4eec\u6700\u611f\u5174\u8da3\u7684\u662f\u80fd\u591f\u5728\u5f00\u653e\u6027\u4efb\u52a1\u3001\u5f62\u5f0f\u53ef\u9a8c\u8bc1\u4efb\u52a1\u548c\u8de8\u8bed\u8a00\u65b9\u9762\u63a8\u5e7f\u7684\u6280\u672f\u3002", "method": "\u6211\u4eec\u7814\u7a76\u4e86\u5982\u4f55\u5728\u591a\u8bed\u8a00\u3001\u591a\u4efb\u52a1\u8bbe\u7f6e\u4e2d\u7a33\u5065\u5730\u6269\u5c55\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\u80fd\u529b\u3002\u6211\u4eec\u8bc4\u4f30\u4e86\u73b0\u6709\u7684\u9009\u62e9\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u9488\u5bf9\u591a\u8bed\u8a00\u548c\u591a\u4efb\u52a1\u63a8\u7406\u573a\u666f\u7684\u65b0\u578b\u91c7\u6837\u548c\u9009\u62e9\u7b56\u7565\u3002", "result": "\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u6e29\u5ea6\u53d8\u5316\u7684\u91c7\u6837\u7b56\u7565\u548c\u9009\u62e9\u7b56\u7565\u5fc5\u987b\u9002\u5e94\u4e0d\u540c\u7684\u9886\u57df\u548c\u8bed\u8a00\u73af\u5883\u3002\u6211\u4eec\u63d0\u51fa\u7684\u65b0\u578b\u91c7\u6837\u548c\u9009\u62e9\u7b56\u7565\u5728\u591a\u79cd\u8bed\u8a00\u548c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u63d0\u5347\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u7684\u7ec4\u5408\u91c7\u6837\u548c\u9009\u62e9\u65b9\u6cd5\u57288B\u6a21\u578b\u4e0a\u4f7fm-ArenaHard-v2.0\u63d0\u793a\u7684\u80dc\u7387\u5e73\u5747\u63d0\u9ad8\u4e866.8\u4e2a\u767e\u5206\u70b9\uff0c\u800cCommand-A\uff08111B\u6a21\u578b\uff09\u5728\u76f8\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4ec5\u4f7f\u7528\u4e94\u4e2a\u6837\u672c\u5c31\u6bd4\u5355\u6837\u672c\u89e3\u7801\u63d0\u9ad8\u4e869.0\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u6211\u4eec\u7684\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u63a8\u7406\u65f6\u8ba1\u7b97\u4e2d\u9700\u8981\u8bed\u8a00\u548c\u4efb\u52a1\u611f\u77e5\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u4f7f\u8d44\u6e90\u8f83\u5c11\u7684\u8bed\u8a00\u7684\u6027\u80fd\u63d0\u5347\u6c11\u4e3b\u5316\u3002"}}
{"id": "2506.20606", "pdf": "https://arxiv.org/pdf/2506.20606", "abs": "https://arxiv.org/abs/2506.20606", "authors": ["Baixiang Huang", "Zhen Tan", "Haoran Wang", "Zijie Liu", "Dawei Li", "Ali Payani", "Huan Liu", "Tianlong Chen", "Kai Shu"], "title": "Model Editing as a Double-Edged Sword: Steering Agent Ethical Behavior Toward Beneficence or Harm", "categories": ["cs.CL"], "comment": "Main paper: 9 pages; total: 18 pages (including appendix). Code,\n  data, results, and additional resources are available at:\n  https://model-editing.github.io", "summary": "Agents based on Large Language Models (LLMs) have demonstrated strong\ncapabilities across a wide range of tasks. However, deploying LLM-based agents\nin high-stakes domains comes with significant safety and ethical risks.\nUnethical behavior by these agents can directly result in serious real-world\nconsequences, including physical harm and financial loss. To efficiently steer\nthe ethical behavior of agents, we frame agent behavior steering as a model\nediting task, which we term Behavior Editing. Model editing is an emerging area\nof research that enables precise and efficient modifications to LLMs while\npreserving their overall capabilities. To systematically study and evaluate\nthis approach, we introduce BehaviorBench, a multi-tier benchmark grounded in\npsychological moral theories. This benchmark supports both the evaluation and\nediting of agent behaviors across a variety of scenarios, with each tier\nintroducing more complex and ambiguous scenarios. We first demonstrate that\nBehavior Editing can dynamically steer agents toward the target behavior within\nspecific scenarios. Moreover, Behavior Editing enables not only\nscenario-specific local adjustments but also more extensive shifts in an\nagent's global moral alignment. We demonstrate that Behavior Editing can be\nused to promote ethical and benevolent behavior or, conversely, to induce\nharmful or malicious behavior. Through comprehensive evaluations on agents\nbased on frontier LLMs, BehaviorBench shows the effectiveness of Behavior\nEditing across different models and scenarios. Our findings offer key insights\ninto a new paradigm for steering agent behavior, highlighting both the promise\nand perils of Behavior Editing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u884c\u4e3a\u7f16\u8f91\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5f15\u5bfc\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u7684\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u5f15\u5165BehaviorBench\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "LLM-based\u667a\u80fd\u4f53\u5728\u9ad8\u98ce\u9669\u9886\u57df\u90e8\u7f72\u65f6\u5b58\u5728\u663e\u8457\u7684\u5b89\u5168\u548c\u4f26\u7406\u98ce\u9669\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5f15\u5bfc\u5176\u884c\u4e3a\u3002", "method": "\u6211\u4eec\u5c06\u667a\u80fd\u4f53\u884c\u4e3a\u5f15\u5bfc\u6846\u67b6\u5316\u4e3a\u4e00\u4e2a\u6a21\u578b\u7f16\u8f91\u4efb\u52a1\uff0c\u79f0\u4e3a\u884c\u4e3a\u7f16\u8f91\uff0c\u5e76\u5f15\u5165\u4e86BehaviorBench\u57fa\u51c6\u6d4b\u8bd5\u6765\u7cfb\u7edf\u5730\u7814\u7a76\u548c\u8bc4\u4f30\u8fd9\u4e00\u65b9\u6cd5\u3002", "result": "\u884c\u4e3a\u7f16\u8f91\u80fd\u591f\u52a8\u6001\u5730\u5c06\u667a\u80fd\u4f53\u5f15\u5bfc\u5230\u7279\u5b9a\u573a\u666f\u4e2d\u7684\u76ee\u6807\u884c\u4e3a\uff0c\u5e76\u4e14\u53ef\u4ee5\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u7684\u5168\u7403\u9053\u5fb7\u5bf9\u9f50\u53d8\u5316\u3002\u6b64\u5916\uff0cBehaviorBench\u5c55\u793a\u4e86\u884c\u4e3a\u7f16\u8f91\u5728\u4e0d\u540c\u6a21\u578b\u548c\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u884c\u4e3a\u7f16\u8f91\u5728\u5f15\u5bfc\u667a\u80fd\u4f53\u884c\u4e3a\u65b9\u9762\u7684\u6f5c\u529b\u548c\u98ce\u9669\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.20639", "pdf": "https://arxiv.org/pdf/2506.20639", "abs": "https://arxiv.org/abs/2506.20639", "authors": ["Shansan Gong", "Ruixiang Zhang", "Huangjie Zheng", "Jiatao Gu", "Navdeep Jaitly", "Lingpeng Kong", "Yizhe Zhang"], "title": "DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation", "categories": ["cs.CL"], "comment": "preprint", "summary": "Diffusion large language models (dLLMs) are compelling alternatives to\nautoregressive (AR) models because their denoising models operate over the\nentire sequence. The global planning and iterative refinement features of dLLMs\nare particularly useful for code generation. However, current training and\ninference mechanisms for dLLMs in coding are still under-explored. To demystify\nthe decoding behavior of dLLMs and unlock their potential for coding, we\nsystematically investigate their denoising processes and reinforcement learning\n(RL) methods. We train a 7B dLLM, \\textbf{DiffuCoder}, on 130B tokens of code.\nUsing this model as a testbed, we analyze its decoding behavior, revealing how\nit differs from that of AR models: (1) dLLMs can decide how causal their\ngeneration should be without relying on semi-AR decoding, and (2) increasing\nthe sampling temperature diversifies not only token choices but also their\ngeneration order. This diversity creates a rich search space for RL rollouts.\nFor RL training, to reduce the variance of token log-likelihood estimates and\nmaintain training efficiency, we propose \\textbf{coupled-GRPO}, a novel\nsampling scheme that constructs complementary mask noise for completions used\nin training. In our experiments, coupled-GRPO significantly improves\nDiffuCoder's performance on code generation benchmarks (+4.4\\% on EvalPlus) and\nreduces reliance on AR causal during decoding. Our work provides deeper insight\ninto the machinery of dLLM generation and offers an effective, diffusion-native\nRL training framework. https://github.com/apple/ml-diffucoder.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff08dLLMs\uff09\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u53bb\u566a\u8fc7\u7a0b\u548c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u91c7\u6837\u65b9\u6848\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u5e76\u51cf\u5c11\u4e86\u5bf9AR\u56e0\u679c\u6027\u7684\u4f9d\u8d56\u3002", "motivation": "\u5f53\u524ddLLM\u5728\u7f16\u7801\u4e2d\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u673a\u5236\u4ecd\u4e0d\u660e\u786e\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u5730\u7814\u7a76\u5176\u53bb\u566a\u8fc7\u7a0b\u548cRL\u65b9\u6cd5\uff0c\u4ee5\u89e3\u9501\u5176\u5728\u7f16\u7801\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u6211\u4eec\u7cfb\u7edf\u5730\u7814\u7a76\u4e86dLLM\u7684\u53bb\u566a\u8fc7\u7a0b\u548c\u5f3a\u5316\u5b66\u4e60(RL)\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a\u8026\u5408-GRPO\u7684\u65b0\u91c7\u6837\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u5728\u8bad\u7ec3\u4e2d\u4e3a\u8865\u5168\u6784\u5efa\u4e92\u8865\u7684\u63a9\u7801\u566a\u58f0\u3002", "result": "\u8026\u5408-GRPO\u663e\u8457\u63d0\u9ad8\u4e86DiffuCoder\u5728\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\uff08\u5728EvalPlus\u4e0a\u63d0\u9ad8\u4e864.4%\uff09\uff0c\u5e76\u51cf\u5c11\u4e86\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\u5bf9AR\u56e0\u679c\u6027\u7684\u4f9d\u8d56\u3002", "conclusion": "\u6211\u4eec\u7684\u5de5\u4f5c\u63d0\u4f9b\u4e86\u5bf9dLLM\u751f\u6210\u673a\u5236\u7684\u66f4\u6df1\u5165\u89c1\u89e3\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u3001\u57fa\u4e8e\u6269\u6563\u7684RL\u8bad\u7ec3\u6846\u67b6\u3002"}}
{"id": "2506.20642", "pdf": "https://arxiv.org/pdf/2506.20642", "abs": "https://arxiv.org/abs/2506.20642", "authors": ["Chao Wan", "Albert Gong", "Mihir Mishra", "Carl-Leander Henneking", "Claas Beger", "Kilian Q. Weinberger"], "title": "Memento: Note-Taking for Your Future Self", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) excel at reasoning-only tasks, but struggle when\nreasoning must be tightly coupled with retrieval, as in multi-hop question\nanswering. To overcome these limitations, we introduce a prompting strategy\nthat first decomposes a complex question into smaller steps, then dynamically\nconstructs a database of facts using LLMs, and finally pieces these facts\ntogether to solve the question. We show how this three-stage strategy, which we\ncall Memento, can boost the performance of existing prompting strategies across\ndiverse settings. On the 9-step PhantomWiki benchmark, Memento doubles the\nperformance of chain-of-thought (CoT) when all information is provided in\ncontext. On the open-domain version of 2WikiMultiHopQA, CoT-RAG with Memento\nimproves over vanilla CoT-RAG by more than 20 F1 percentage points and over the\nmulti-hop RAG baseline, IRCoT, by more than 13 F1 percentage points. On the\nchallenging MuSiQue dataset, Memento improves ReAct by more than 3 F1\npercentage points, demonstrating its utility in agentic settings.", "AI": {"tldr": "Memento is a prompting strategy that enhances the performance of existing prompting strategies in multi-hop question answering tasks by decomposing complex questions, dynamically constructing a database of facts, and combining these facts to solve the question.", "motivation": "Large language models (LLMs) excel at reasoning-only tasks, but struggle when reasoning must be tightly coupled with retrieval, as in multi-hop question answering.", "method": "Introduce a prompting strategy that first decomposes a complex question into smaller steps, then dynamically constructs a database of facts using LLMs, and finally pieces these facts together to solve the question.", "result": "On the 9-step PhantomWiki benchmark, Memento doubles the performance of chain-of-thought (CoT) when all information is provided in context. On the open-domain version of 2WikiMultiHopQA, CoT-RAG with Memento improves over vanilla CoT-RAG by more than 20 F1 percentage points and over the multi-hop RAG baseline, IRCoT, by more than 13 F1 percentage points. On the challenging MuSiQue dataset, Memento improves ReAct by more than 3 F1 percentage points.", "conclusion": "Memento can boost the performance of existing prompting strategies across diverse settings and demonstrate its utility in agentic settings."}}
{"id": "2506.20666", "pdf": "https://arxiv.org/pdf/2506.20666", "abs": "https://arxiv.org/abs/2506.20666", "authors": ["Sonia K. Murthy", "Rosie Zhao", "Jennifer Hu", "Sham Kakade", "Markus Wulfmeier", "Peng Qian", "Tomer Ullman"], "title": "Inside you are many wolves: Using cognitive models to interpret value trade-offs in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 3 figures", "summary": "Navigating everyday social situations often requires juggling conflicting\ngoals, such as conveying a harsh truth, maintaining trust, all while still\nbeing mindful of another person's feelings. These value trade-offs are an\nintegral part of human decision-making and language use, however, current tools\nfor interpreting such dynamic and multi-faceted notions of values in LLMs are\nlimited. In cognitive science, so-called \"cognitive models\" provide formal\naccounts of these trade-offs in humans, by modeling the weighting of a\nspeaker's competing utility functions in choosing an action or utterance. In\nthis work, we use a leading cognitive model of polite speech to interpret the\nextent to which LLMs represent human-like trade-offs. We apply this lens to\nsystematically evaluate value trade-offs in two encompassing model settings:\ndegrees of reasoning \"effort\" in frontier black-box models, and RL\npost-training dynamics of open-source models. Our results highlight patterns of\nhigher informational utility than social utility in reasoning models, and in\nopen-source models shown to be stronger in mathematical reasoning. Our findings\nfrom LLMs' training dynamics suggest large shifts in utility values early on in\ntraining with persistent effects of the choice of base model and pretraining\ndata, compared to feedback dataset or alignment method. We show that our method\nis responsive to diverse aspects of the rapidly evolving LLM landscape, with\ninsights for forming hypotheses about other high-level behaviors, shaping\ntraining regimes for reasoning models, and better controlling trade-offs\nbetween values during model training.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLMs\u5728\u5904\u7406\u4ef7\u503c\u6743\u8861\u65b9\u9762\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\u6765\u5206\u6790\u8fd9\u4e9b\u6743\u8861\u3002\u7ed3\u679c\u663e\u793a\uff0c\u63a8\u7406\u6a21\u578b\u66f4\u6ce8\u91cd\u4fe1\u606f\u6548\u7528\uff0c\u800c\u5f00\u6e90\u6a21\u578b\u5219\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002\u6b64\u5916\uff0c\u8bad\u7ec3\u52a8\u6001\u663e\u793a\u4e86\u65e9\u671f\u8bad\u7ec3\u4e2d\u6548\u7528\u503c\u7684\u53d8\u5316\uff0c\u5e76\u4e14\u57fa\u7840\u6a21\u578b\u548c\u9884\u8bad\u7ec3\u6570\u636e\u7684\u9009\u62e9\u5bf9\u7ed3\u679c\u6709\u6301\u4e45\u5f71\u54cd\u3002", "motivation": "\u5f53\u524d\u7528\u4e8e\u89e3\u91caLLMs\u4e2d\u52a8\u6001\u548c\u591a\u9762\u7684\u4ef7\u503c\u89c2\u7684\u5de5\u5177\u662f\u6709\u9650\u7684\u3002\u5728\u8ba4\u77e5\u79d1\u5b66\u4e2d\uff0c\u6240\u8c13\u7684\u201c\u8ba4\u77e5\u6a21\u578b\u201d\u901a\u8fc7\u5efa\u6a21\u8bf4\u8bdd\u8005\u5728\u9009\u62e9\u884c\u52a8\u6216\u8a00\u8bed\u65f6\u5bf9\u7ade\u4e89\u6027\u6548\u7528\u51fd\u6570\u7684\u52a0\u6743\uff0c\u63d0\u4f9b\u4e86\u8fd9\u4e9b\u6743\u8861\u7684\u6b63\u5f0f\u63cf\u8ff0\u3002", "method": "\u6211\u4eec\u4f7f\u7528\u4e86\u4e00\u4e2a\u9886\u5148\u7684\u793c\u8c8c\u8a00\u8bed\u8ba4\u77e5\u6a21\u578b\u6765\u89e3\u91caLLMs\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u4ee3\u8868\u4e86\u7c7b\u4f3c\u4eba\u7c7b\u7684\u6743\u8861\u3002\u6211\u4eec\u5c06\u8fd9\u79cd\u89c6\u89d2\u5e94\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u4e24\u4e2a\u6db5\u76d6\u6a21\u578b\u8bbe\u7f6e\u4e2d\u7684\u4ef7\u503c\u6743\u8861\uff1a\u524d\u6cbf\u9ed1\u76d2\u6a21\u578b\u4e2d\u7684\u63a8\u7406\u201c\u52aa\u529b\u201d\u7a0b\u5ea6\uff0c\u4ee5\u53ca\u5f00\u6e90\u6a21\u578b\u7684RL\u540e\u8bad\u7ec3\u52a8\u6001\u3002", "result": "\u6211\u4eec\u7684\u7ed3\u679c\u7a81\u51fa\u4e86\u63a8\u7406\u6a21\u578b\u4e2d\u66f4\u9ad8\u7684\u4fe1\u606f\u6548\u7528\u800c\u975e\u793e\u4f1a\u6548\u7528\uff0c\u4ee5\u53ca\u5728\u88ab\u8bc1\u660e\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u66f4\u5f3a\u7684\u5f00\u6e90\u6a21\u578b\u4e2d\u7684\u8868\u73b0\u3002\u6211\u4eec\u7684\u53d1\u73b0\u8868\u660e\uff0cLLMs\u7684\u8bad\u7ec3\u52a8\u6001\u663e\u793a\u4e86\u65e9\u671f\u8bad\u7ec3\u4e2d\u6548\u7528\u503c\u7684\u5927\u89c4\u6a21\u53d8\u5316\uff0c\u5e76\u4e14\u57fa\u7840\u6a21\u578b\u548c\u9884\u8bad\u7ec3\u6570\u636e\u7684\u9009\u62e9\u5177\u6709\u6301\u4e45\u5f71\u54cd\uff0c\u800c\u53cd\u9988\u6570\u636e\u96c6\u6216\u5bf9\u9f50\u65b9\u6cd5\u7684\u5f71\u54cd\u8f83\u5c0f\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u5bf9\u5feb\u901f\u53d1\u5c55\u7684LLM\u666f\u89c2\u4e2d\u7684\u5404\u79cd\u65b9\u9762\u5177\u6709\u54cd\u5e94\u6027\uff0c\u4e3a\u5f62\u6210\u5173\u4e8e\u5176\u4ed6\u9ad8\u5c42\u6b21\u884c\u4e3a\u7684\u5047\u8bbe\u3001\u5851\u9020\u63a8\u7406\u6a21\u578b\u7684\u8bad\u7ec3\u5236\u5ea6\u4ee5\u53ca\u5728\u6a21\u578b\u8bad\u7ec3\u671f\u95f4\u66f4\u597d\u5730\u63a7\u5236\u4ef7\u503c\u4e4b\u95f4\u7684\u6743\u8861\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2506.16571", "pdf": "https://arxiv.org/pdf/2506.16571", "abs": "https://arxiv.org/abs/2506.16571", "authors": ["Maeve Hutchinson", "Radu Jianu", "Aidan Slingsby", "Jo Wood", "Pranava Madhyastha"], "title": "Capturing Visualization Design Rationale", "categories": ["cs.HC", "cs.CL"], "comment": null, "summary": "Prior natural language datasets for data visualization have focused on tasks\nsuch as visualization literacy assessment, insight generation, and\nvisualization generation from natural language instructions. These studies\noften rely on controlled setups with purpose-built visualizations and\nartificially constructed questions. As a result, they tend to prioritize the\ninterpretation of visualizations, focusing on decoding visualizations rather\nthan understanding their encoding. In this paper, we present a new dataset and\nmethodology for probing visualization design rationale through natural\nlanguage. We leverage a unique source of real-world visualizations and natural\nlanguage narratives: literate visualization notebooks created by students as\npart of a data visualization course. These notebooks combine visual artifacts\nwith design exposition, in which students make explicit the rationale behind\ntheir design decisions. We also use large language models (LLMs) to generate\nand categorize question-answer-rationale triples from the narratives and\narticulations in the notebooks. We then carefully validate the triples and\ncurate a dataset that captures and distills the visualization design choices\nand corresponding rationales of the students.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5206\u6790\u53ef\u89c6\u5316\u8bbe\u8ba1\u7684\u5408\u7406\u6027\uff0c\u5e76\u5229\u7528\u5b66\u751f\u521b\u5efa\u7684\u53ef\u89c6\u5316\u7b14\u8bb0\u672c\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u6709\u81ea\u7136\u8bed\u8a00\u6570\u636e\u96c6\u5728\u6570\u636e\u53ef\u89c6\u5316\u4efb\u52a1\u4e0a\u5173\u6ce8\u4e8e\u53ef\u89c6\u5316\u7d20\u517b\u8bc4\u4f30\u3001\u89c1\u89e3\u751f\u6210\u548c\u4ece\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u751f\u6210\u53ef\u89c6\u5316\uff0c\u4f46\u8fd9\u4e9b\u7814\u7a76\u901a\u5e38\u4f9d\u8d56\u4e8e\u53d7\u63a7\u8bbe\u7f6e\u548c\u4e13\u95e8\u6784\u5efa\u7684\u53ef\u89c6\u5316\u4ee5\u53ca\u4eba\u4e3a\u6784\u9020\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u5b83\u4eec\u66f4\u6ce8\u91cd\u5bf9\u53ef\u89c6\u5316\u7684\u89e3\u91ca\uff0c\u800c\u4e0d\u662f\u7406\u89e3\u5176\u7f16\u7801\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63a2\u7a76\u53ef\u89c6\u5316\u8bbe\u8ba1\u7684\u5408\u7406\u6027\u3002", "method": "\u672c\u6587\u5229\u7528\u5b66\u751f\u5728\u6570\u636e\u53ef\u89c6\u5316\u8bfe\u7a0b\u4e2d\u521b\u5efa\u7684\u6709\u7d20\u517b\u7684\u53ef\u89c6\u5316\u7b14\u8bb0\u672c\u4f5c\u4e3a\u771f\u5b9e\u4e16\u754c\u7684\u53ef\u89c6\u5316\u548c\u81ea\u7136\u8bed\u8a00\u53d9\u8ff0\u7684\u6765\u6e90\uff0c\u5e76\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4ece\u7b14\u8bb0\u672c\u4e2d\u7684\u53d9\u8ff0\u548c\u9610\u8ff0\u751f\u6210\u548c\u5206\u7c7b\u95ee\u9898-\u7b54\u6848-\u5408\u7406\u6027\u4e09\u5143\u7ec4\u3002", "result": "\u672c\u6587\u901a\u8fc7\u9a8c\u8bc1\u548c\u6574\u7406\u4e09\u5143\u7ec4\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u6570\u636e\u96c6\uff0c\u6355\u6349\u5e76\u63d0\u70bc\u4e86\u5b66\u751f\u7684\u53ef\u89c6\u5316\u8bbe\u8ba1\u9009\u62e9\u53ca\u5176\u76f8\u5e94\u7684\u5408\u7406\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\u548c\u65b9\u6cd5\uff0c\u7528\u4e8e\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63a2\u6d4b\u53ef\u89c6\u5316\u8bbe\u8ba1\u7684\u5408\u7406\u6027\u3002"}}
{"id": "2506.19882", "pdf": "https://arxiv.org/pdf/2506.19882", "abs": "https://arxiv.org/abs/2506.19882", "authors": ["Rylan Schaeffer", "Joshua Kazdan", "Yegor Denisov-Blanch", "Brando Miranda", "Matthias Gerstgrasser", "Susan Zhang", "Andreas Haupt", "Isha Gupta", "Elyas Obbad", "Jesse Dodge", "Jessica Zosa Forde", "Koustuv Sinha", "Francesco Orabona", "Sanmi Koyejo", "David Donoho"], "title": "Position: Machine Learning Conferences Should Establish a \"Refutations and Critiques\" Track", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "Science progresses by iteratively advancing and correcting humanity's\nunderstanding of the world. In machine learning (ML) research, rapid\nadvancements have led to an explosion of publications, but have also led to\nmisleading, incorrect, flawed or perhaps even fraudulent studies being accepted\nand sometimes highlighted at ML conferences due to the fallibility of peer\nreview. While such mistakes are understandable, ML conferences do not offer\nrobust processes to help the field systematically correct when such errors are\nmade.This position paper argues that ML conferences should establish a\ndedicated \"Refutations and Critiques\" (R & C) Track. This R & C Track would\nprovide a high-profile, reputable platform to support vital research that\ncritically challenges prior research, thereby fostering a dynamic\nself-correcting research ecosystem. We discuss key considerations including\ntrack design, review principles, potential pitfalls, and provide an\nillustrative example submission concerning a recent ICLR 2025 Oral. We conclude\nthat ML conferences should create official, reputable mechanisms to help ML\nresearch self-correct.", "AI": {"tldr": "This paper argues that ML conferences should establish a dedicated 'Refutations and Critiques' track to foster a self-correcting research ecosystem.", "motivation": "ML conferences do not offer robust processes to help the field systematically correct when such errors are made.", "method": "This position paper argues that ML conferences should establish a dedicated 'Refutations and Critiques' (R & C) Track.", "result": "The R & C Track would provide a high-profile, reputable platform to support vital research that critically challenges prior research, thereby fostering a dynamic self-correcting research ecosystem.", "conclusion": "ML conferences should create official, reputable mechanisms to help ML research self-correct."}}
{"id": "2506.20009", "pdf": "https://arxiv.org/pdf/2506.20009", "abs": "https://arxiv.org/abs/2506.20009", "authors": ["Konstantinos Vrettos", "Michail E. Klontzas"], "title": "Accurate and Energy Efficient: Local Retrieval-Augmented Generation Models Outperform Commercial Large Language Models in Medical Tasks", "categories": ["cs.AI", "cs.CL", "I.2.7"], "comment": "18 pages, 3 Figures", "summary": "Background The increasing adoption of Artificial Intelligence (AI) in\nhealthcare has sparked growing concerns about its environmental and ethical\nimplications. Commercial Large Language Models (LLMs), such as ChatGPT and\nDeepSeek, require substantial resources, while the utilization of these systems\nfor medical purposes raises critical issues regarding patient privacy and\nsafety. Methods We developed a customizable Retrieval-Augmented Generation\n(RAG) framework for medical tasks, which monitors its energy usage and CO2\nemissions. This system was then used to create RAGs based on various\nopen-source LLMs. The tested models included both general purpose models like\nllama3.1:8b and medgemma-4b-it, which is medical-domain specific. The best RAGs\nperformance and energy consumption was compared to DeepSeekV3-R1 and OpenAIs\no4-mini model. A dataset of medical questions was used for the evaluation.\nResults Custom RAG models outperformed commercial models in accuracy and energy\nconsumption. The RAG model built on llama3.1:8B achieved the highest accuracy\n(58.5%) and was significantly better than other models, including o4-mini and\nDeepSeekV3-R1. The llama3.1-RAG also exhibited the lowest energy consumption\nand CO2 footprint among all models, with a Performance per kWh of 0.52 and a\ntotal CO2 emission of 473g. Compared to o4-mini, the llama3.1-RAG achieved 2.7x\ntimes more accuracy points per kWh and 172% less electricity usage while\nmaintaining higher accuracy. Conclusion Our study demonstrates that local LLMs\ncan be leveraged to develop RAGs that outperform commercial, online LLMs in\nmedical tasks, while having a smaller environmental impact. Our modular\nframework promotes sustainable AI development, reducing electricity usage and\naligning with the UNs Sustainable Development Goals.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u672c\u5730\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u51fa\u5728\u533b\u7597\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5546\u4e1a\u5728\u7ebf\u6a21\u578b\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\uff0c\u540c\u65f6\u51cf\u5c11\u73af\u5883\u5f71\u54cd\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u5728\u533b\u7597\u4fdd\u5065\u4e2d\u7684\u65e5\u76ca\u666e\u53ca\u5f15\u53d1\u4e86\u5bf9\u5176\u73af\u5883\u548c\u4f26\u7406\u5f71\u54cd\u7684\u62c5\u5fe7\u3002\u5546\u4e1a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5982ChatGPT\u548cDeepSeek\u9700\u8981\u5927\u91cf\u8d44\u6e90\uff0c\u800c\u8fd9\u4e9b\u7cfb\u7edf\u5728\u533b\u7597\u7528\u9014\u4e2d\u7684\u5e94\u7528\u5f15\u53d1\u4e86\u5173\u4e8e\u60a3\u8005\u9690\u79c1\u548c\u5b89\u5168\u7684\u5173\u952e\u95ee\u9898\u3002", "method": "\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u5b9a\u5236\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u533b\u7597\u4efb\u52a1\uff0c\u8be5\u6846\u67b6\u76d1\u63a7\u5176\u80fd\u6e90\u4f7f\u7528\u548c\u4e8c\u6c27\u5316\u78b3\u6392\u653e\u3002\u7136\u540e\u4f7f\u7528\u8be5\u7cfb\u7edf\u521b\u5efa\u57fa\u4e8e\u5404\u79cd\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684RAG\u3002\u6d4b\u8bd5\u7684\u6a21\u578b\u5305\u62ec\u901a\u7528\u6a21\u578b\u5982llama3.1:8b\u548cmedgemma-4b-it\uff0c\u540e\u8005\u662f\u533b\u5b66\u9886\u57df\u7279\u5b9a\u7684\u3002\u6700\u4f73RAG\u6027\u80fd\u548c\u80fd\u8017\u4e0eDeepSeekV3-R1\u548cOpenAIs o4-mini\u6a21\u578b\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u5b9a\u5236\u7684RAG\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u80fd\u8017\u65b9\u9762\u90fd\u8d85\u8fc7\u4e86\u5546\u4e1a\u6a21\u578b\u3002\u57fa\u4e8ellama3.1:8B\u7684RAG\u6a21\u578b\u8fbe\u5230\u4e86\u6700\u9ad8\u7684\u51c6\u786e\u7387\uff0858.5%\uff09\uff0c\u5e76\u4e14\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u5305\u62eco4-mini\u548cDeepSeekV3-R1\u3002llama3.1-RAG\u5728\u6240\u6709\u6a21\u578b\u4e2d\u8868\u73b0\u51fa\u6700\u4f4e\u7684\u80fd\u8017\u548c\u4e8c\u6c27\u5316\u78b3\u8db3\u8ff9\uff0c\u6bcf\u5343\u74e6\u65f6\u7684\u6027\u80fd\u4e3a0.52\uff0c\u603b\u4e8c\u6c27\u5316\u78b3\u6392\u653e\u91cf\u4e3a473\u514b\u3002\u4e0eo4-mini\u76f8\u6bd4\uff0cllama3.1-RAG\u5728\u6bcf\u5343\u74e6\u65f6\u7684\u51c6\u786e\u7387\u70b9\u4e0a\u63d0\u9ad8\u4e862.7\u500d\uff0c\u5e76\u4e14\u7528\u7535\u91cf\u51cf\u5c11\u4e86172%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u8868\u660e\uff0c\u672c\u5730\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u7528\u4e8e\u5f00\u53d1\u5728\u533b\u7597\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5546\u4e1a\u5728\u7ebf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\uff0c\u540c\u65f6\u5177\u6709\u66f4\u5c0f\u7684\u73af\u5883\u5f71\u54cd\u3002\u6211\u4eec\u7684\u6a21\u5757\u5316\u6846\u67b6\u4fc3\u8fdb\u4e86\u53ef\u6301\u7eed\u7684\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\uff0c\u51cf\u5c11\u4e86\u7535\u529b\u4f7f\u7528\uff0c\u5e76\u4e0e\u8054\u5408\u56fd\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u76f8\u4e00\u81f4\u3002"}}
{"id": "2506.20020", "pdf": "https://arxiv.org/pdf/2506.20020", "abs": "https://arxiv.org/abs/2506.20020", "authors": ["Saloni Dash", "Am\u00e9lie Reymond", "Emma S. Spiro", "Aylin Caliskan"], "title": "Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Reasoning in humans is prone to biases due to underlying motivations like\nidentity protection, that undermine rational decision-making and judgment. This\nmotivated reasoning at a collective level can be detrimental to society when\ndebating critical issues such as human-driven climate change or vaccine safety,\nand can further aggravate political polarization. Prior studies have reported\nthat large language models (LLMs) are also susceptible to human-like cognitive\nbiases, however, the extent to which LLMs selectively reason toward\nidentity-congruent conclusions remains largely unexplored. Here, we investigate\nwhether assigning 8 personas across 4 political and socio-demographic\nattributes induces motivated reasoning in LLMs. Testing 8 LLMs (open source and\nproprietary) across two reasoning tasks from human-subject studies -- veracity\ndiscernment of misinformation headlines and evaluation of numeric scientific\nevidence -- we find that persona-assigned LLMs have up to 9% reduced veracity\ndiscernment relative to models without personas. Political personas\nspecifically, are up to 90% more likely to correctly evaluate scientific\nevidence on gun control when the ground truth is congruent with their induced\npolitical identity. Prompt-based debiasing methods are largely ineffective at\nmitigating these effects. Taken together, our empirical findings are the first\nto suggest that persona-assigned LLMs exhibit human-like motivated reasoning\nthat is hard to mitigate through conventional debiasing prompts -- raising\nconcerns of exacerbating identity-congruent reasoning in both LLMs and humans.", "AI": {"tldr": "\u6211\u4eec\u7684\u7814\u7a76\u8868\u660e\uff0c\u5206\u914d\u4e86\u4eba\u683c\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u7684\u52a8\u673a\u63a8\u7406\uff0c\u8fd9\u79cd\u63a8\u7406\u96be\u4ee5\u901a\u8fc7\u4f20\u7edf\u53bb\u504f\u63d0\u793a\u7f13\u89e3\uff0c\u53ef\u80fd\u52a0\u5267\u8eab\u4efd\u4e00\u81f4\u7684\u63a8\u7406\u3002", "motivation": "\u4eba\u7c7b\u63a8\u7406\u5bb9\u6613\u53d7\u5230\u504f\u89c1\u7684\u5f71\u54cd\uff0c\u56e0\u4e3a\u6f5c\u5728\u7684\u52a8\u673a\u5982\u8eab\u4efd\u4fdd\u62a4\u4f1a\u7834\u574f\u7406\u6027\u51b3\u7b56\u548c\u5224\u65ad\u3002\u8fd9\u79cd\u96c6\u4f53\u5c42\u9762\u7684\u52a8\u673a\u63a8\u7406\u5728\u8ba8\u8bba\u5173\u952e\u95ee\u9898\u65f6\u53ef\u80fd\u5bf9\u793e\u4f1a\u6709\u5bb3\uff0c\u4f8b\u5982\u4eba\u4e3a\u6c14\u5019\u53d8\u5316\u6216\u75ab\u82d7\u5b89\u5168\uff0c\u5e76\u53ef\u80fd\u8fdb\u4e00\u6b65\u52a0\u5267\u653f\u6cbb\u6781\u5316\u3002\u5148\u524d\u7684\u7814\u7a76\u62a5\u544a\u79f0\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e5f\u5bb9\u6613\u53d7\u5230\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8ba4\u77e5\u504f\u89c1\u5f71\u54cd\uff0c\u4f46LLMs\u9009\u62e9\u6027\u5730\u671d\u5411\u7b26\u5408\u8eab\u4efd\u7684\u7ed3\u8bba\u7684\u7a0b\u5ea6\u4ecd largely \u672a\u88ab\u63a2\u7d22\u3002", "method": "\u6211\u4eec\u7814\u7a76\u4e86\u57284\u4e2a\u653f\u6cbb\u548c\u793e\u4f1a\u4eba\u53e3\u5c5e\u6027\u4e0a\u5206\u914d8\u79cd\u4eba\u683c\u662f\u5426\u4f1a\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u5f15\u53d1\u52a8\u673a\u63a8\u7406\u3002\u6211\u4eec\u6d4b\u8bd5\u4e868\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5f00\u6e90\u548c\u4e13\u6709\uff09\u5728\u4e24\u4e2a\u6765\u81ea\u4eba\u7c7b\u53d7\u8bd5\u8005\u7814\u7a76\u7684\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u2014\u2014\u8fa8\u522b\u865a\u5047\u65b0\u95fb\u6807\u9898\u7684\u771f\u5b9e\u6027\u548c\u8bc4\u4f30\u6570\u503c\u79d1\u5b66\u8bc1\u636e\u3002", "result": "\u5206\u914d\u4e86\u4eba\u683c\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8fa8\u522b\u865a\u5047\u65b0\u95fb\u6807\u9898\u7684\u771f\u5b9e\u6027\u65b9\u9762\u76f8\u5bf9\u4e8e\u6ca1\u6709\u4eba\u683c\u7684\u6a21\u578b\u51cf\u5c11\u4e86\u9ad8\u8fbe9%\u3002\u7279\u522b\u662f\u653f\u6cbb\u4eba\u683c\u5728\u5730\u9762\u771f\u5b9e\u4e0e\u4ed6\u4eec\u8bf1\u5bfc\u7684\u653f\u6cbb\u8eab\u4efd\u4e00\u81f4\u65f6\uff0c\u6b63\u786e\u8bc4\u4f30\u5173\u4e8e\u67aa\u652f\u63a7\u5236\u7684\u79d1\u5b66\u8bc1\u636e\u7684\u53ef\u80fd\u6027\u9ad8\u51fa90%\u3002\u57fa\u4e8e\u63d0\u793a\u7684\u53bb\u504f\u65b9\u6cd5\u5728\u51cf\u8f7b\u8fd9\u4e9b\u5f71\u54cd\u65b9\u9762\u6548\u679c\u6709\u9650\u3002", "conclusion": "\u6211\u4eec\u7684\u5b9e\u8bc1\u7ed3\u679c\u9996\u6b21\u8868\u660e\uff0c\u5206\u914d\u4e86\u4eba\u683c\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u7684\u52a8\u673a\u63a8\u7406\uff0c\u8fd9\u79cd\u63a8\u7406\u5f88\u96be\u901a\u8fc7\u4f20\u7edf\u7684\u53bb\u504f\u63d0\u793a\u6765\u7f13\u89e3\u2014\u2014\u8fd9\u5f15\u53d1\u4e86\u5bf9\u52a0\u5267\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u4eba\u7c7b\u8eab\u4efd\u4e00\u81f4\u63a8\u7406\u7684\u62c5\u5fe7\u3002"}}
{"id": "2506.20097", "pdf": "https://arxiv.org/pdf/2506.20097", "abs": "https://arxiv.org/abs/2506.20097", "authors": ["Wang Bill Zhu", "Miaosen Chai", "Ishika Singh", "Robin Jia", "Jesse Thomason"], "title": "PSALM-V: Automating Symbolic Planning in Interactive Visual Environments with Large Language Models", "categories": ["cs.RO", "cs.CL"], "comment": null, "summary": "We propose PSALM-V, the first autonomous neuro-symbolic learning system able\nto induce symbolic action semantics (i.e., pre- and post-conditions) in visual\nenvironments through interaction. PSALM-V bootstraps reliable symbolic planning\nwithout expert action definitions, using LLMs to generate heuristic plans and\ncandidate symbolic semantics. Previous work has explored using large language\nmodels to generate action semantics for Planning Domain Definition Language\n(PDDL)-based symbolic planners. However, these approaches have primarily\nfocused on text-based domains or relied on unrealistic assumptions, such as\naccess to a predefined problem file, full observability, or explicit error\nmessages. By contrast, PSALM-V dynamically infers PDDL problem files and domain\naction semantics by analyzing execution outcomes and synthesizing possible\nerror explanations. The system iteratively generates and executes plans while\nmaintaining a tree-structured belief over possible action semantics for each\naction, iteratively refining these beliefs until a goal state is reached.\nSimulated experiments of task completion in ALFRED demonstrate that PSALM-V\nincreases the plan success rate from 37% (Claude-3.7) to 74% in partially\nobserved setups. Results on two 2D game environments, RTFM and Overcooked-AI,\nshow that PSALM-V improves step efficiency and succeeds in domain induction in\nmulti-agent settings. PSALM-V correctly induces PDDL pre- and post-conditions\nfor real-world robot BlocksWorld tasks, despite low-level manipulation failures\nfrom the robot.", "AI": {"tldr": "PSALM-V is an autonomous neuro-symbolic learning system that induces symbolic action semantics in visual environments through interaction, improving plan success rates and step efficiency in various domains.", "motivation": "Previous approaches have focused on text-based domains or relied on unrealistic assumptions, such as access to a predefined problem file, full observability, or explicit error messages. PSALM-V aims to address these limitations by autonomously inducing symbolic action semantics.", "method": "PSALM-V uses LLMs to generate heuristic plans and candidate symbolic semantics, dynamically infers PDDL problem files and domain action semantics by analyzing execution outcomes, and maintains a tree-structured belief over possible action semantics for each action.", "result": "Simulated experiments show that PSALM-V increases the plan success rate from 37% (Claude-3.7) to 74% in partially observed setups. It also improves step efficiency and succeeds in domain induction in multi-agent settings, and correctly induces PDDL pre- and post-conditions for real-world robot tasks.", "conclusion": "PSALM-V can induce symbolic action semantics in visual environments through interaction, and it improves plan success rates and step efficiency in various domains."}}
{"id": "2506.20249", "pdf": "https://arxiv.org/pdf/2506.20249", "abs": "https://arxiv.org/abs/2506.20249", "authors": ["Junyan Cheng", "Peter Clark", "Kyle Richardson"], "title": "Language Modeling by Language Models", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": null, "summary": "Can we leverage LLMs to model the process of discovering novel language model\n(LM) architectures? Inspired by real research, we propose a multi-agent LLM\napproach that simulates the conventional stages of research, from ideation and\nliterature search (proposal stage) to design implementation (code generation),\ngenerative pre-training, and downstream evaluation (verification). Using ideas\nfrom scaling laws, our system, Genesys, employs a Ladder of Scales approach;\nnew designs are proposed, adversarially reviewed, implemented, and selectively\nverified at increasingly larger model scales (14M$\\sim$350M parameters) with a\nnarrowing budget (the number of models we can train at each scale). To help\nmake discovery efficient and factorizable, Genesys uses a novel genetic\nprogramming backbone, which we show has empirical advantages over commonly used\ndirect prompt generation workflows (e.g., $\\sim$86\\% percentage point\nimprovement in successful design generation, a key bottleneck). We report\nexperiments involving 1,162 newly discovered designs (1,062 fully verified\nthrough pre-training) and find the best designs to be highly competitive with\nknown architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common\nbenchmarks). We couple these results with comprehensive system-level ablations\nand formal results, which give broader insights into the design of effective\nautonomous discovery systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53LLM\u7684\u65b9\u6cd5Genesys\uff0c\u7528\u4e8e\u53d1\u73b0\u65b0\u578b\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u3002\u901a\u8fc7Ladder of Scales\u65b9\u6cd5\u548c\u9057\u4f20\u7f16\u7a0b\u6838\u5fc3\uff0cGenesys\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u6a21\u62df\u53d1\u73b0\u65b0\u578b\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u7684\u8fc7\u7a0b\u3002", "method": "Genesys\u91c7\u7528\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53LLM\u65b9\u6cd5\uff0c\u6a21\u62df\u4e86\u4f20\u7edf\u7814\u7a76\u7684\u5404\u4e2a\u9636\u6bb5\uff0c\u5305\u62ec\u6784\u601d\u3001\u6587\u732e\u641c\u7d22\u3001\u8bbe\u8ba1\u5b9e\u73b0\u3001\u751f\u6210\u9884\u8bad\u7ec3\u548c\u4e0b\u6e38\u8bc4\u4f30\u3002\u5b83\u4f7f\u7528\u4e86Ladder of Scales\u65b9\u6cd5\uff0c\u5728\u4e0d\u65ad\u589e\u52a0\u7684\u6a21\u578b\u89c4\u6a21\u4e0b\u8fdb\u884c\u65b0\u8bbe\u8ba1\u7684\u63d0\u51fa\u3001\u5bf9\u6297\u6027\u5ba1\u67e5\u3001\u5b9e\u73b0\u548c\u9009\u62e9\u6027\u9a8c\u8bc1\uff0c\u5e76\u4e14\u9884\u7b97\u9010\u6e10\u51cf\u5c11\u3002\u6b64\u5916\uff0cGenesys\u8fd8\u4f7f\u7528\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u9057\u4f20\u7f16\u7a0b\u6838\u5fc3\uff0c\u4ee5\u63d0\u9ad8\u8bbe\u8ba1\u751f\u6210\u7684\u6210\u529f\u7387\u3002", "result": "Genesys\u53d1\u73b0\u4e861,162\u4e2a\u65b0\u7684\u8bbe\u8ba1\uff0c\u5176\u4e2d1,062\u4e2a\u7ecf\u8fc7\u9884\u8bad\u7ec3\u9a8c\u8bc1\u3002\u6700\u597d\u7684\u8bbe\u8ba1\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8fc7\u4e86GPT2\u548cMamba2\u7b49\u5df2\u77e5\u67b6\u6784\u3002", "conclusion": "Genesys\u80fd\u591f\u6709\u6548\u5730\u53d1\u73b0\u65b0\u7684\u8bed\u8a00\u6a21\u578b\u67b6\u6784\uff0c\u5e76\u4e14\u5176\u6700\u4f73\u8bbe\u8ba1\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u5df2\u77e5\u67b6\u6784\uff0c\u5982GPT2\u548cMamba2\u3002"}}
{"id": "2506.20268", "pdf": "https://arxiv.org/pdf/2506.20268", "abs": "https://arxiv.org/abs/2506.20268", "authors": ["Ruben Janssens", "Jens De Bock", "Sofie Labat", "Eva Verhelst", "Veronique Hoste", "Tony Belpaeme"], "title": "Why Robots Are Bad at Detecting Their Mistakes: Limitations of Miscommunication Detection in Human-Robot Dialogue", "categories": ["cs.RO", "cs.CL", "cs.HC"], "comment": "Accepted at the 34th IEEE International Conference on Robot and Human\n  Interactive Communication (RO-MAN 2025)", "summary": "Detecting miscommunication in human-robot interaction is a critical function\nfor maintaining user engagement and trust. While humans effortlessly detect\ncommunication errors in conversations through both verbal and non-verbal cues,\nrobots face significant challenges in interpreting non-verbal feedback, despite\nadvances in computer vision for recognizing affective expressions. This\nresearch evaluates the effectiveness of machine learning models in detecting\nmiscommunications in robot dialogue. Using a multi-modal dataset of 240\nhuman-robot conversations, where four distinct types of conversational failures\nwere systematically introduced, we assess the performance of state-of-the-art\ncomputer vision models. After each conversational turn, users provided feedback\non whether they perceived an error, enabling an analysis of the models' ability\nto accurately detect robot mistakes. Despite using state-of-the-art models, the\nperformance barely exceeds random chance in identifying miscommunication, while\non a dataset with more expressive emotional content, they successfully\nidentified confused states. To explore the underlying cause, we asked human\nraters to do the same. They could also only identify around half of the induced\nmiscommunications, similarly to our model. These results uncover a fundamental\nlimitation in identifying robot miscommunications in dialogue: even when users\nperceive the induced miscommunication as such, they often do not communicate\nthis to their robotic conversation partner. This knowledge can shape\nexpectations of the performance of computer vision models and can help\nresearchers to design better human-robot conversations by deliberately\neliciting feedback where needed.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u68c0\u6d4b\u4eba\u673a\u5bf9\u8bdd\u4e2d\u7684\u8bef\u89e3\u6548\u679c\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u4f7f\u7528\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u5176\u8868\u73b0\u4e5f\u4ec5\u7565\u9ad8\u4e8e\u968f\u673a\u731c\u6d4b\uff0c\u800c\u4eba\u7c7b\u8bc4\u5206\u5458\u4e5f\u4ec5\u80fd\u8bc6\u522b\u51fa\u5927\u7ea6\u4e00\u534a\u7684\u8bef\u89e3\u3002\u8fd9\u63ed\u793a\u4e86\u5728\u5bf9\u8bdd\u4e2d\u8bc6\u522b\u673a\u5668\u4eba\u8bef\u89e3\u7684\u6839\u672c\u9650\u5236\u3002", "motivation": "\u5728\u4eba\u673a\u4ea4\u4e92\u4e2d\u68c0\u6d4b\u8bef\u89e3\u5bf9\u4e8e\u4fdd\u6301\u7528\u6237\u53c2\u4e0e\u548c\u4fe1\u4efb\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u4eba\u7c7b\u53ef\u4ee5\u901a\u8fc7\u8a00\u8bed\u548c\u975e\u8a00\u8bed\u7ebf\u7d22\u8f7b\u677e\u68c0\u6d4b\u5bf9\u8bdd\u4e2d\u7684\u6c9f\u901a\u9519\u8bef\uff0c\u4f46\u673a\u5668\u4eba\u5728\u89e3\u91ca\u975e\u8a00\u8bed\u53cd\u9988\u65b9\u9762\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u5c3d\u7ba1\u8ba1\u7b97\u673a\u89c6\u89c9\u5728\u8bc6\u522b\u60c5\u611f\u8868\u8fbe\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\u3002", "method": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u68c0\u6d4b\u673a\u5668\u4eba\u5bf9\u8bdd\u4e2d\u7684\u8bef\u89e3\u6548\u679c\u3002\u4f7f\u7528\u5305\u542b240\u4e2a\u4eba\u673a\u5bf9\u8bdd\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u7cfb\u7edf\u5730\u5f15\u5165\u4e86\u56db\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u5bf9\u8bdd\u5931\u8d25\uff0c\u6211\u4eec\u8bc4\u4f30\u4e86\u6700\u5148\u8fdb\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u7684\u6027\u80fd\u3002\u5728\u6bcf\u6b21\u5bf9\u8bdd\u56de\u5408\u540e\uff0c\u7528\u6237\u63d0\u4f9b\u4e86\u5173\u4e8e\u662f\u5426\u611f\u77e5\u5230\u9519\u8bef\u7684\u53cd\u9988\uff0c\u4ece\u800c\u5206\u6790\u6a21\u578b\u51c6\u786e\u68c0\u6d4b\u673a\u5668\u4eba\u9519\u8bef\u7684\u80fd\u529b\u3002", "result": "\u5c3d\u7ba1\u4f7f\u7528\u4e86\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u4f46\u5728\u8bc6\u522b\u8bef\u89e3\u65b9\u9762\u7684\u8868\u73b0\u4ec5\u7565\u9ad8\u4e8e\u968f\u673a\u731c\u6d4b\uff0c\u800c\u5728\u5177\u6709\u66f4\u591a\u60c5\u611f\u5185\u5bb9\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u5b83\u4eec\u6210\u529f\u8bc6\u522b\u4e86\u56f0\u60d1\u72b6\u6001\u3002\u4eba\u7c7b\u8bc4\u5206\u5458\u4e5f\u4ec5\u80fd\u8bc6\u522b\u51fa\u5927\u7ea6\u4e00\u534a\u7684\u8bf1\u5bfc\u8bef\u89e3\uff0c\u4e0e\u6211\u4eec\u7684\u6a21\u578b\u7c7b\u4f3c\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5728\u5bf9\u8bdd\u4e2d\u8bc6\u522b\u673a\u5668\u4eba\u8bef\u89e3\u7684\u6839\u672c\u9650\u5236\uff1a\u5373\u4f7f\u7528\u6237\u611f\u77e5\u5230\u8bef\u89e3\uff0c\u4ed6\u4eec\u901a\u5e38\u4e5f\u4e0d\u4f1a\u5411\u673a\u5668\u5bf9\u8bdd\u4f19\u4f34\u4f20\u8fbe\u8fd9\u4e00\u70b9\u3002\u8fd9\u4e00\u77e5\u8bc6\u53ef\u4ee5\u5851\u9020\u5bf9\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u6027\u80fd\u7684\u671f\u671b\uff0c\u5e76\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u901a\u8fc7\u523b\u610f\u5f15\u53d1\u53cd\u9988\u6765\u8bbe\u8ba1\u66f4\u597d\u7684\u4eba\u673a\u5bf9\u8bdd\u3002"}}
{"id": "2506.20303", "pdf": "https://arxiv.org/pdf/2506.20303", "abs": "https://arxiv.org/abs/2506.20303", "authors": ["Lee Qi Zun", "Oscar Wong Jin Hao", "Nor Anita Binti Che Omar", "Zalifa Zakiah Binti Asnir", "Mohamad Sabri bin Sinal Zainal", "Goh Man Fye"], "title": "FundaQ-8: A Clinically-Inspired Scoring Framework for Automated Fundus Image Quality Assessment", "categories": ["eess.IV", "cs.CL", "cs.CV"], "comment": null, "summary": "Automated fundus image quality assessment (FIQA) remains a challenge due to\nvariations in image acquisition and subjective expert evaluations. We introduce\nFundaQ-8, a novel expert-validated framework for systematically assessing\nfundus image quality using eight critical parameters, including field coverage,\nanatomical visibility, illumination, and image artifacts. Using FundaQ-8 as a\nstructured scoring reference, we develop a ResNet18-based regression model to\npredict continuous quality scores in the 0 to 1 range. The model is trained on\n1800 fundus images from real-world clinical sources and Kaggle datasets, using\ntransfer learning, mean squared error optimization, and standardized\npreprocessing. Validation against the EyeQ dataset and statistical analyses\nconfirm the framework's reliability and clinical interpretability.\nIncorporating FundaQ-8 into deep learning models for diabetic retinopathy\ngrading also improves diagnostic robustness, highlighting the value of\nquality-aware training in real-world screening applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e13\u5bb6\u9a8c\u8bc1\u6846\u67b6FundaQ-8\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u773c\u5e95\u56fe\u50cf\u8d28\u91cf\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eResNet18\u7684\u56de\u5f52\u6a21\u578b\u6765\u9884\u6d4b\u8fde\u7eed\u8d28\u91cf\u5206\u6570\u3002\u8be5\u6a21\u578b\u5728\u771f\u5b9e\u4e34\u5e8a\u6570\u636e\u548cKaggle\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bad\u7ec3\uff0c\u5e76\u901a\u8fc7EyeQ\u6570\u636e\u96c6\u7684\u9a8c\u8bc1\u548c\u7edf\u8ba1\u5206\u6790\u786e\u8ba4\u4e86\u5176\u53ef\u9760\u6027\u3002\u6b64\u5916\uff0c\u5c06FundaQ-8\u7eb3\u5165\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\uff0c\u53ef\u4ee5\u63d0\u9ad8\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\u5206\u7ea7\u7684\u8bca\u65ad\u9c81\u68d2\u6027\u3002", "motivation": "\u7531\u4e8e\u56fe\u50cf\u91c7\u96c6\u7684\u53d8\u5316\u548c\u4e3b\u89c2\u4e13\u5bb6\u8bc4\u4f30\uff0c\u81ea\u52a8\u5316\u773c\u5e95\u56fe\u50cf\u8d28\u91cf\u8bc4\u4f30\uff08FIQA\uff09\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u4f7f\u7528FundaQ-8\u4f5c\u4e3a\u7ed3\u6784\u5316\u8bc4\u5206\u53c2\u8003\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eResNet18\u7684\u56de\u5f52\u6a21\u578b\uff0c\u4ee5\u9884\u6d4b0\u52301\u8303\u56f4\u5185\u7684\u8fde\u7eed\u8d28\u91cf\u5206\u6570\u3002\u8be5\u6a21\u578b\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u3001\u5747\u65b9\u8bef\u5dee\u4f18\u5316\u548c\u6807\u51c6\u5316\u9884\u5904\u7406\uff0c\u5728\u6765\u81ea\u771f\u5b9e\u4e34\u5e8a\u6765\u6e90\u548cKaggle\u6570\u636e\u96c6\u76841800\u5f20\u773c\u5e95\u56fe\u50cf\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u901a\u8fc7EyeQ\u6570\u636e\u96c6\u7684\u9a8c\u8bc1\u548c\u7edf\u8ba1\u5206\u6790\uff0c\u786e\u8ba4\u4e86\u8be5\u6846\u67b6\u7684\u53ef\u9760\u6027\u548c\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u3002\u6b64\u5916\uff0c\u5c06FundaQ-8\u7eb3\u5165\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\uff0c\u53ef\u4ee5\u63d0\u9ad8\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\u5206\u7ea7\u7684\u8bca\u65ad\u9c81\u68d2\u6027\u3002", "conclusion": "\u5c06FundaQ-8\u7eb3\u5165\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\uff0c\u53ef\u4ee5\u63d0\u9ad8\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\u5206\u7ea7\u7684\u8bca\u65ad\u9c81\u68d2\u6027\uff0c\u8868\u660e\u8d28\u91cf\u611f\u77e5\u8bad\u7ec3\u5728\u73b0\u5b9e\u4e16\u754c\u7b5b\u67e5\u5e94\u7528\u4e2d\u7684\u4ef7\u503c\u3002"}}
{"id": "2506.20326", "pdf": "https://arxiv.org/pdf/2506.20326", "abs": "https://arxiv.org/abs/2506.20326", "authors": ["Sergio Torres Aguilar"], "title": "From Codicology to Code: A Comparative Study of Transformer and YOLO-based Detectors for Layout Analysis in Historical Documents", "categories": ["cs.CV", "cs.CL", "cs.DB"], "comment": null, "summary": "Robust Document Layout Analysis (DLA) is critical for the automated\nprocessing and understanding of historical documents with complex page\norganizations. This paper benchmarks five state-of-the-art object detection\narchitectures on three annotated datasets representing a spectrum of\ncodicological complexity: The e-NDP, a corpus of Parisian medieval registers\n(1326-1504); CATMuS, a diverse multiclass dataset derived from various medieval\nand modern sources (ca.12th-17th centuries) and HORAE, a corpus of decorated\nbooks of hours (ca.13th-16th centuries). We evaluate two Transformer-based\nmodels (Co-DETR, Grounding DINO) against three YOLO variants (AABB, OBB, and\nYOLO-World). Our findings reveal significant performance variations dependent\non model architecture, data set characteristics, and bounding box\nrepresentation. In the e-NDP dataset, Co-DETR achieves state-of-the-art results\n(0.752 mAP@.50:.95), closely followed by YOLOv11X-OBB (0.721). Conversely, on\nthe more complex CATMuS and HORAE datasets, the CNN-based YOLOv11x-OBB\nsignificantly outperforms all other models (0.564 and 0.568, respectively).\nThis study unequivocally demonstrates that using Oriented Bounding Boxes (OBB)\nis not a minor refinement but a fundamental requirement for accurately modeling\nthe non-Cartesian nature of historical manuscripts. We conclude that a key\ntrade-off exists between the global context awareness of Transformers, ideal\nfor structured layouts, and the superior generalization of CNN-OBB models for\nvisually diverse and complex documents.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u4e94\u79cd\u6700\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u67b6\u6784\u5728\u4e09\u4e2a\u5386\u53f2\u6587\u6863\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u57fa\u4e8eCNN\u7684YOLOv11x-OBB\u5728\u590d\u6742\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u800c\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u5728\u7ed3\u6784\u5316\u5e03\u5c40\u4e2d\u8868\u73b0\u51fa\u8272\u3002\u7814\u7a76\u5f3a\u8c03\u4e86OBB\u5728\u5efa\u6a21\u5386\u53f2\u624b\u7a3f\u975e\u7b1b\u5361\u5c14\u6027\u8d28\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51faTransformer\u548cCNN-OBB\u6a21\u578b\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\u3002", "motivation": "\u7a33\u5065\u7684\u6587\u6863\u5e03\u5c40\u5206\u6790\uff08DLA\uff09\u5bf9\u4e8e\u81ea\u52a8\u5316\u5904\u7406\u548c\u7406\u89e3\u5177\u6709\u590d\u6742\u9875\u9762\u7ec4\u7ec7\u7684\u5386\u53f2\u6587\u6863\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5386\u53f2\u624b\u7a3f\u7684\u975e\u7b1b\u5361\u5c14\u6027\u8d28\u65f6\u9762\u4e34\u6311\u6218\uff0c\u56e0\u6b64\u9700\u8981\u8bc4\u4f30\u4e0d\u540c\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002", "method": "\u672c\u7814\u7a76\u5728\u4e09\u4e2a\u6807\u6ce8\u6570\u636e\u96c6\u4e0a\u5bf9\u4e94\u79cd\u6700\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u67b6\u6784\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ece-NDP\u3001CATMuS\u548cHORAE\u3002\u8bc4\u4f30\u4e86\u4e24\u79cd\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff08Co-DETR\u3001Grounding DINO\uff09\u548c\u4e09\u79cdYOLO\u53d8\u4f53\uff08AABB\u3001OBB\u548cYOLO-World\uff09\u3002", "result": "\u5728e-NDP\u6570\u636e\u96c6\u4e0a\uff0cCo-DETR\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff080.752 mAP@.50:.95\uff09\uff0c\u7d27\u968f\u5176\u540e\u7684\u662fYOLOv11X-OBB\uff080.721\uff09\u3002\u800c\u5728\u66f4\u590d\u6742\u7684CATMuS\u548cHORAE\u6570\u636e\u96c6\u4e0a\uff0c\u57fa\u4e8eCNN\u7684YOLOv11x-OBB\u663e\u8457\u4f18\u4e8e\u6240\u6709\u5176\u4ed6\u6a21\u578b\uff08\u5206\u522b\u4e3a0.564\u548c0.568\uff09\u3002", "conclusion": "\u672c\u7814\u7a76\u660e\u786e\u8868\u660e\uff0c\u4f7f\u7528\u5b9a\u5411\u8fb9\u754c\u6846\uff08OBB\uff09\u4e0d\u662f\u4e00\u4e2a\u5c0f\u7684\u6539\u8fdb\uff0c\u800c\u662f\u51c6\u786e\u5efa\u6a21\u5386\u53f2\u624b\u7a3f\u975e\u7b1b\u5361\u5c14\u6027\u8d28\u7684\u57fa\u672c\u8981\u6c42\u3002\u6211\u4eec\u5f97\u51fa\u7ed3\u8bba\uff0cTransformer\u7684\u5168\u5c40\u4e0a\u4e0b\u6587\u610f\u8bc6\u4e0eCNN-OBB\u6a21\u578b\u5728\u89c6\u89c9\u591a\u6837\u6027\u548c\u590d\u6742\u6587\u6863\u4e2d\u7684\u4f18\u8d8a\u6cdb\u5316\u80fd\u529b\u4e4b\u95f4\u5b58\u5728\u5173\u952e\u6743\u8861\u3002"}}
{"id": "2506.20481", "pdf": "https://arxiv.org/pdf/2506.20481", "abs": "https://arxiv.org/abs/2506.20481", "authors": ["Matthieu Meeus", "Igor Shilov", "Georgios Kaissis", "Yves-Alexandre de Montjoye"], "title": "Counterfactual Influence as a Distributional Quantity", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "comment": "Workshop on The Impact of Memorization on Trustworthy Foundation\n  Models (MemFM) @ ICML 2025", "summary": "Machine learning models are known to memorize samples from their training\ndata, raising concerns around privacy and generalization. Counterfactual\nself-influence is a popular metric to study memorization, quantifying how the\nmodel's prediction for a sample changes depending on the sample's inclusion in\nthe training dataset. However, recent work has shown memorization to be\naffected by factors beyond self-influence, with other training samples, in\nparticular (near-)duplicates, having a large impact. We here study memorization\ntreating counterfactual influence as a distributional quantity, taking into\naccount how all training samples influence how a sample is memorized. For a\nsmall language model, we compute the full influence distribution of training\nsamples on each other and analyze its properties. We find that solely looking\nat self-influence can severely underestimate tangible risks associated with\nmemorization: the presence of (near-)duplicates seriously reduces\nself-influence, while we find these samples to be (near-)extractable. We\nobserve similar patterns for image classification, where simply looking at the\ninfluence distributions reveals the presence of near-duplicates in CIFAR-10.\nOur findings highlight that memorization stems from complex interactions across\ntraining data and is better captured by the full influence distribution than by\nself-influence alone.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8bb0\u5fc6\uff0c\u5c06\u53cd\u4e8b\u5b9e\u5f71\u54cd\u89c6\u4e3a\u4e00\u79cd\u5206\u5e03\u91cf\uff0c\u8003\u8651\u6240\u6709\u8bad\u7ec3\u6837\u672c\u5982\u4f55\u5f71\u54cd\u4e00\u4e2a\u6837\u672c\u7684\u8bb0\u5fc6\u3002\u6211\u4eec\u53d1\u73b0\uff0c\u4ec5\u4ec5\u5173\u6ce8\u81ea\u6211\u5f71\u54cd\u53ef\u80fd\u4f1a\u4e25\u91cd\u4f4e\u4f30\u4e0e\u8bb0\u5fc6\u76f8\u5173\u7684\u5b9e\u9645\u98ce\u9669\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ee5\u8bb0\u4f4f\u5176\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u6837\u672c\u800c\u95fb\u540d\uff0c\u8fd9\u5f15\u53d1\u4e86\u9690\u79c1\u548c\u6cdb\u5316\u7684\u62c5\u5fe7\u3002\u53cd\u4e8b\u5b9e\u81ea\u6211\u5f71\u54cd\u662f\u7814\u7a76\u8bb0\u5fc6\u7684\u6d41\u884c\u5ea6\u91cf\uff0c\u91cf\u5316\u4e86\u6a21\u578b\u5bf9\u6837\u672c\u7684\u9884\u6d4b\u5982\u4f55\u53d6\u51b3\u4e8e\u6837\u672c\u662f\u5426\u5305\u542b\u5728\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u3002\u7136\u800c\uff0c\u6700\u8fd1\u7684\u5de5\u4f5c\u8868\u660e\uff0c\u8bb0\u5fc6\u8fd8\u53d7\u5230\u5176\u4ed6\u56e0\u7d20\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\uff08\u8fd1\uff09\u91cd\u590d\u6837\u672c\uff0c\u5b83\u4eec\u6709\u91cd\u5927\u5f71\u54cd\u3002", "method": "\u6211\u4eec\u7814\u7a76\u4e86\u8bb0\u5fc6\uff0c\u5c06\u53cd\u4e8b\u5b9e\u5f71\u54cd\u89c6\u4e3a\u4e00\u79cd\u5206\u5e03\u91cf\uff0c\u8003\u8651\u6240\u6709\u8bad\u7ec3\u6837\u672c\u5982\u4f55\u5f71\u54cd\u4e00\u4e2a\u6837\u672c\u7684\u8bb0\u5fc6\u3002\u5bf9\u4e8e\u4e00\u4e2a\u5c0f\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u6211\u4eec\u8ba1\u7b97\u4e86\u8bad\u7ec3\u6837\u672c\u5bf9\u5f7c\u6b64\u7684\u5b8c\u6574\u5f71\u54cd\u5206\u5e03\uff0c\u5e76\u5206\u6790\u4e86\u5176\u5c5e\u6027\u3002", "result": "\u6211\u4eec\u53d1\u73b0\uff0c\u4ec5\u4ec5\u5173\u6ce8\u81ea\u6211\u5f71\u54cd\u53ef\u80fd\u4f1a\u4e25\u91cd\u4f4e\u4f30\u4e0e\u8bb0\u5fc6\u76f8\u5173\u7684\u5b9e\u9645\u98ce\u9669\uff1a\uff08\u8fd1\uff09\u91cd\u590d\u7684\u5b58\u5728\u4f1a\u5927\u5927\u964d\u4f4e\u81ea\u6211\u5f71\u54cd\uff0c\u800c\u6211\u4eec\u53d1\u73b0\u8fd9\u4e9b\u6837\u672c\u662f\uff08\u8fd1\uff09\u53ef\u63d0\u53d6\u7684\u3002\u6211\u4eec\u5728\u56fe\u50cf\u5206\u7c7b\u4e2d\u89c2\u5bdf\u5230\u7c7b\u4f3c\u7684\u6a21\u5f0f\uff0c\u5176\u4e2d\u4ec5\u67e5\u770b\u5f71\u54cd\u5206\u5e03\u5c31\u63ed\u793a\u4e86CIFAR-10\u4e2d\u5b58\u5728\u8fd1\u4f3c\u91cd\u590d\u3002", "conclusion": "\u6211\u4eec\u7684\u53d1\u73b0\u8868\u660e\uff0c\u8bb0\u5fc6\u6e90\u4e8e\u8bad\u7ec3\u6570\u636e\u4e4b\u95f4\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u4e14\u6bd4\u5355\u72ec\u4f7f\u7528\u81ea\u5f71\u54cd\u66f4\u80fd\u901a\u8fc7\u5b8c\u6574\u7684\u5f71\u54cd\u529b\u5206\u5e03\u6765\u6355\u6349\u3002"}}
{"id": "2506.20520", "pdf": "https://arxiv.org/pdf/2506.20520", "abs": "https://arxiv.org/abs/2506.20520", "authors": ["Charles Arnal", "Ga\u00ebtan Narozniak", "Vivien Cabannes", "Yunhao Tang", "Julia Kempe", "Remi Munos"], "title": "Asymmetric REINFORCE for off-Policy Reinforcement Learning: Balancing positive and negative rewards", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Reinforcement learning (RL) is increasingly used to align large language\nmodels (LLMs). Off-policy methods offer greater implementation simplicity and\ndata efficiency than on-policy techniques, but often result in suboptimal\nperformance. In this work, we study the intermediate range of algorithms\nbetween off-policy RL and supervised fine-tuning by analyzing a simple\noff-policy REINFORCE algorithm, where the advantage is defined as $A=r-V$, with\n$r$ a reward and $V$ some tunable baseline. Intuitively, lowering $V$\nemphasizes high-reward samples, while raising it penalizes low-reward ones more\nheavily. We first provide a theoretical analysis of this off-policy REINFORCE\nalgorithm, showing that when the baseline $V$ lower-bounds the expected reward,\nthe algorithm enjoys a policy improvement guarantee. Our analysis reveals that\nwhile on-policy updates can safely leverage both positive and negative signals,\noff-policy updates benefit from focusing more on positive rewards than on\nnegative ones. We validate our findings experimentally in a controlled\nstochastic bandit setting and through fine-tuning state-of-the-art LLMs on\nreasoning tasks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u57fa\u4e8e\u79bb\u7b56\u7565REINFORCE\u7b97\u6cd5\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u79bb\u7b56\u7565\u65b9\u6cd5\u5728\u5b9e\u73b0\u7b80\u5355\u6027\u548c\u6570\u636e\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u5728\u7ebf\u7b56\u7565\u6280\u672f\uff0c\u4f46\u901a\u5e38\u4f1a\u5bfc\u81f4\u6b21\u4f18\u6027\u80fd\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u4ecb\u4e8e\u79bb\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\u548c\u76d1\u7763\u5fae\u8c03\u4e4b\u95f4\u7684\u7b97\u6cd5\u8303\u56f4\u3002", "method": "\u672c\u6587\u5206\u6790\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u79bb\u7b56\u7565REINFORCE\u7b97\u6cd5\uff0c\u5176\u4e2d\u4f18\u52bf\u51fd\u6570\u5b9a\u4e49\u4e3a$A=r-V$\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5f53\u57fa\u7ebf$V$\u4e0b\u754c\u9884\u671f\u5956\u52b1\u65f6\uff0c\u8be5\u7b97\u6cd5\u4eab\u6709\u7b56\u7565\u6539\u8fdb\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u53d1\u73b0\uff0c\u5e76\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u63a7\u5236\u7684\u968f\u673a\u8001\u864e\u673a\u8bbe\u7f6e\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u5206\u6790\u4e86\u57fa\u4e8e\u79bb\u7b56\u7565REINFORCE\u7b97\u6cd5\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2506.20629", "pdf": "https://arxiv.org/pdf/2506.20629", "abs": "https://arxiv.org/abs/2506.20629", "authors": ["Soufiane Hayou", "Nikhil Ghosh", "Bin Yu"], "title": "PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models", "categories": ["cs.LG", "cs.CL", "stat.ML"], "comment": "TD,LR: A lightweight module type selection method for LoRA\n  finetuning. PLoP gives precise placements for LoRA adapters for improved\n  performance", "summary": "Low-Rank Adaptation (LoRA) is a widely used finetuning method for large\nmodels. Its small memory footprint allows practitioners to adapt large models\nto specific tasks at a fraction of the cost of full finetuning. Different\nmodifications have been proposed to enhance its efficiency by, for example,\nsetting the learning rate, the rank, and the initialization. Another\nimprovement axis is adapter placement strategy: when using LoRA, practitioners\nusually pick module types to adapt with LoRA, such as Query and Key modules.\nFew works have studied the problem of adapter placement, with nonconclusive\nresults: original LoRA paper suggested placing adapters in attention modules,\nwhile other works suggested placing them in the MLP modules. Through an\nintuitive theoretical analysis, we introduce PLoP (Precise LoRA Placement), a\nlightweight method that allows automatic identification of module types where\nLoRA adapters should be placed, given a pretrained model and a finetuning task.\nWe demonstrate that PLoP consistently outperforms, and in the worst case\ncompetes, with commonly used placement strategies through comprehensive\nexperiments on supervised finetuning and reinforcement learning for reasoning.", "AI": {"tldr": "PLoP is a lightweight method for automatically identifying the best module types to place LoRA adapters, which consistently outperforms or competes with existing strategies in various tasks.", "motivation": "To enhance the efficiency of LoRA by improving adapter placement strategy, as few works have studied this problem with nonconclusive results.", "method": "PLoP (Precise LoRA Placement), a lightweight method that allows automatic identification of module types where LoRA adapters should be placed, given a pretrained model and a finetuning task.", "result": "PLoP consistently outperforms, and in the worst case competes, with commonly used placement strategies through comprehensive experiments on supervised finetuning and reinforcement learning for reasoning.", "conclusion": "PLoP consistently outperforms, and in the worst case competes, with commonly used placement strategies through comprehensive experiments on supervised finetuning and reinforcement learning for reasoning."}}
{"id": "2506.20664", "pdf": "https://arxiv.org/pdf/2506.20664", "abs": "https://arxiv.org/abs/2506.20664", "authors": ["Andrei Lupu", "Timon Willi", "Jakob Foerster"], "title": "The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.MA"], "comment": "41 pages, 19 figures", "summary": "As Large Language Models (LLMs) gain agentic abilities, they will have to\nnavigate complex multi-agent scenarios, interacting with human users and other\nagents in cooperative and competitive settings. This will require new reasoning\nskills, chief amongst them being theory of mind (ToM), or the ability to reason\nabout the \"mental\" states of other agents. However, ToM and other multi-agent\nabilities in LLMs are poorly understood, since existing benchmarks suffer from\nnarrow scope, data leakage, saturation, and lack of interactivity. We thus\npropose Decrypto, a game-based benchmark for multi-agent reasoning and ToM\ndrawing inspiration from cognitive science, computational pragmatics and\nmulti-agent reinforcement learning. It is designed to be as easy as possible in\nall other dimensions, eliminating confounding factors commonly found in other\nbenchmarks. To our knowledge, it is also the first platform for designing\ninteractive ToM experiments.\n  We validate the benchmark design through comprehensive empirical evaluations\nof frontier LLMs, robustness studies, and human-AI cross-play experiments. We\nfind that LLM game-playing abilities lag behind humans and simple\nword-embedding baselines. We then create variants of two classic cognitive\nscience experiments within Decrypto to evaluate three key ToM abilities.\nSurprisingly, we find that state-of-the-art reasoning models are significantly\nworse at those tasks than their older counterparts. This demonstrates that\nDecrypto addresses a crucial gap in current reasoning and ToM evaluations, and\npaves the path towards better artificial agents.", "AI": {"tldr": "Decrypto is a new benchmark for evaluating multi-agent reasoning and theory of mind in large language models, revealing that current models lag behind humans and older models in these abilities.", "motivation": "Existing benchmarks suffer from narrow scope, data leakage, saturation, and lack of interactivity. ToM and other multi-agent abilities in LLMs are poorly understood.", "method": "Propose Decrypto, a game-based benchmark for multi-agent reasoning and ToM drawing inspiration from cognitive science, computational pragmatics and multi-agent reinforcement learning.", "result": "LLM game-playing abilities lag behind humans and simple word-embedding baselines. State-of-the-art reasoning models are significantly worse at ToM tasks than their older counterparts.", "conclusion": "Decrypto addresses a crucial gap in current reasoning and ToM evaluations, and paves the path towards better artificial agents."}}
{"id": "2506.20670", "pdf": "https://arxiv.org/pdf/2506.20670", "abs": "https://arxiv.org/abs/2506.20670", "authors": ["Jinming Wu", "Zihao Deng", "Wei Li", "Yiding Liu", "Bo You", "Bo Li", "Zejun Ma", "Ziwei Liu"], "title": "MMSearch-R1: Incentivizing LMMs to Search", "categories": ["cs.CV", "cs.CL"], "comment": "Code: https://github.com/EvolvingLMMs-Lab/multimodal-search-r1", "summary": "Robust deployment of large multimodal models (LMMs) in real-world scenarios\nrequires access to external knowledge sources, given the complexity and dynamic\nnature of real-world information. Existing approaches such as\nretrieval-augmented generation (RAG) and prompt engineered search agents rely\non rigid pipelines, often leading to inefficient or excessive search behaviors.\nWe present MMSearch-R1, the first end-to-end reinforcement learning framework\nthat enables LMMs to perform on-demand, multi-turn search in real-world\nInternet environments. Our framework integrates both image and text search\ntools, allowing the model to reason about when and how to invoke them guided by\nan outcome-based reward with a search penalty. To support training, We collect\na multimodal search VQA dataset through a semi-automated pipeline that covers\ndiverse visual and textual knowledge needs and curate a search-balanced subset\nwith both search-required and search-free samples, which proves essential for\nshaping efficient and on-demand search behavior. Extensive experiments on\nknowledge-intensive and info-seeking VQA tasks show that our model not only\noutperforms RAG-based baselines of the same model size, but also matches the\nperformance of a larger RAG-based model while reducing search calls by over\n30%. We further analyze key empirical findings to offer actionable insights for\nadvancing research in multimodal search.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86MMSearch-R1\uff0c\u8fd9\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u80fd\u591f\u6309\u9700\u3001\u591a\u8f6e\u5730\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u4e92\u8054\u7f51\u73af\u5883\u4e2d\u8fdb\u884c\u641c\u7d22\u3002\u901a\u8fc7\u96c6\u6210\u56fe\u50cf\u548c\u6587\u672c\u641c\u7d22\u5de5\u5177\uff0c\u5e76\u5229\u7528\u57fa\u4e8e\u7ed3\u679c\u7684\u5956\u52b1\u548c\u641c\u7d22\u60e9\u7f5a\u6765\u6307\u5bfc\u6a21\u578b\u51b3\u7b56\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u548c\u4fe1\u606f\u5bfb\u6c42\u7684VQA\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u57fa\u4e8eRAG\u7684\u57fa\u7ebf\uff0c\u5e76\u51cf\u5c11\u4e86\u641c\u7d22\u8c03\u7528\u3002", "motivation": "\u5728\u73b0\u5b9e\u4e16\u754c\u573a\u666f\u4e2d\u90e8\u7f72\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u9700\u8981\u8bbf\u95ee\u5916\u90e8\u77e5\u8bc6\u6e90\uff0c\u56e0\u4e3a\u73b0\u5b9e\u4e16\u754c\u7684\u4fe1\u606f\u590d\u6742\u4e14\u52a8\u6001\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u5982\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u63d0\u793a\u5de5\u7a0b\u641c\u7d22\u4ee3\u7406\u4f9d\u8d56\u4e8e\u521a\u6027\u6d41\u7a0b\uff0c\u901a\u5e38\u5bfc\u81f4\u4f4e\u6548\u6216\u8fc7\u5ea6\u7684\u641c\u7d22\u884c\u4e3a\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86MMSearch-R1\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7fLMM\u80fd\u591f\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u4e92\u8054\u7f51\u73af\u5883\u4e2d\u6267\u884c\u6309\u9700\u3001\u591a\u8f6e\u641c\u7d22\u3002\u6211\u4eec\u7684\u6846\u67b6\u96c6\u6210\u4e86\u56fe\u50cf\u548c\u6587\u672c\u641c\u7d22\u5de5\u5177\uff0c\u5141\u8bb8\u6a21\u578b\u6839\u636e\u57fa\u4e8e\u7ed3\u679c\u7684\u5956\u52b1\u548c\u641c\u7d22\u60e9\u7f5a\u6765\u63a8\u7406\u4f55\u65f6\u4ee5\u53ca\u5982\u4f55\u8c03\u7528\u5b83\u4eec\u3002", "result": "\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u548c\u4fe1\u606f\u5bfb\u6c42\u7684VQA\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u4e0d\u4ec5\u4f18\u4e8e\u76f8\u540c\u6a21\u578b\u5927\u5c0f\u7684\u57fa\u4e8eRAG\u7684\u57fa\u7ebf\uff0c\u800c\u4e14\u5728\u51cf\u5c11\u641c\u7d22\u8c03\u7528\u8d85\u8fc730%\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd8\u8fbe\u5230\u4e86\u66f4\u5927\u7684\u57fa\u4e8eRAG\u7684\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u6211\u4eec\u7684\u6a21\u578b\u4e0d\u4ec5\u4f18\u4e8e\u76f8\u540c\u6a21\u578b\u5927\u5c0f\u7684\u57fa\u4e8eRAG\u7684\u57fa\u7ebf\uff0c\u800c\u4e14\u5728\u51cf\u5c11\u641c\u7d22\u8c03\u7528\u8d85\u8fc730%\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd8\u8fbe\u5230\u4e86\u66f4\u5927\u7684\u57fa\u4e8eRAG\u7684\u6a21\u578b\u7684\u6027\u80fd\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u5206\u6790\u4e86\u5173\u952e\u7684\u5b9e\u8bc1\u53d1\u73b0\uff0c\u4ee5\u63d0\u4f9b\u63a8\u52a8\u591a\u6a21\u6001\u641c\u7d22\u7814\u7a76\u7684\u53ef\u884c\u89c1\u89e3\u3002"}}
