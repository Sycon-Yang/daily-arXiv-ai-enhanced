{"id": "2507.14189", "pdf": "https://arxiv.org/pdf/2507.14189", "abs": "https://arxiv.org/abs/2507.14189", "authors": ["Song Mao", "Lejun Cheng", "Pinlong Cai", "Guohang Yan", "Ding Wang", "Botian Shi"], "title": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base", "categories": ["cs.CL", "cs.AI"], "comment": "work in process", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious applications. However, their use as writing assistants in specialized\ndomains like finance, medicine, and law is often hampered by a lack of deep\ndomain-specific knowledge and a tendency to hallucinate. Existing solutions,\nsuch as Retrieval-Augmented Generation (RAG), can suffer from inconsistency\nacross multiple retrieval steps, while online search-based methods often\ndegrade quality due to unreliable web content. To address these challenges, we\nintroduce DeepWriter, a customizable, multimodal, long-form writing assistant\nthat operates on a curated, offline knowledge base. DeepWriter leverages a\nnovel pipeline that involves task decomposition, outline generation, multimodal\nretrieval, and section-by-section composition with reflection. By deeply mining\ninformation from a structured corpus and incorporating both textual and visual\nelements, DeepWriter generates coherent, factually grounded, and\nprofessional-grade documents. We also propose a hierarchical knowledge\nrepresentation to enhance retrieval efficiency and accuracy. Our experiments on\nfinancial report generation demonstrate that DeepWriter produces high-quality,\nverifiable articles that surpasses existing baselines in factual accuracy and\ngenerated content quality.", "AI": {"tldr": "DeepWriter is a customizable, multimodal, long-form writing assistant that operates on a curated, offline knowledge base. It uses a novel pipeline to generate high-quality, verifiable articles that surpass existing baselines in factual accuracy and content quality.", "motivation": "The use of Large Language Models (LLMs) as writing assistants in specialized domains like finance, medicine, and law is often hampered by a lack of deep domain-specific knowledge and a tendency to hallucinate. Existing solutions, such as Retrieval-Augmented Generation (RAG), can suffer from inconsistency across multiple retrieval steps, while online search-based methods often degrade quality due to unreliable web content.", "method": "DeepWriter leverages a novel pipeline that involves task decomposition, outline generation, multimodal retrieval, and section-by-section composition with reflection. We also propose a hierarchical knowledge representation to enhance retrieval efficiency and accuracy.", "result": "DeepWriter generates coherent, factually grounded, and professional-grade documents by deeply mining information from a structured corpus and incorporating both textual and visual elements.", "conclusion": "DeepWriter produces high-quality, verifiable articles that surpasses existing baselines in factual accuracy and generated content quality."}}
{"id": "2507.14198", "pdf": "https://arxiv.org/pdf/2507.14198", "abs": "https://arxiv.org/abs/2507.14198", "authors": ["Fufang Wen", "Shichang Zhang"], "title": "Retention analysis of edited knowledge after fine-tuning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) store vast amounts of knowledge, which often\nrequires updates to correct factual errors, incorporate newly acquired\ninformation, or adapt model behavior. Model editing methods have emerged as\nefficient solutions for such updates, offering localized and precise knowledge\nmodification at significantly lower computational cost than continual training.\nIn parallel, LLMs are frequently fine-tuned for a wide range of downstream\ntasks. However, the effect of fine-tuning on previously edited knowledge\nremains poorly understood. In this work, we systematically investigate how\ndifferent fine-tuning objectives interact with various model editing\ntechniques. Our findings show that edited knowledge is substantially more\nsusceptible to forgetting during fine-tuning than intrinsic knowledge acquired\nthrough pre-training. This analysis highlights a key limitation of current\nediting approaches and suggests that evaluating edit robustness under\ndownstream fine-tuning is critical for their practical deployment. We further\nfind that freezing layers associated with edited content can significantly\nimprove knowledge retention, offering insight into how future editing methods\nmight be made more robust.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5fae\u8c03\u5bf9\u6a21\u578b\u7f16\u8f91\u77e5\u8bc6\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u7f16\u8f91\u77e5\u8bc6\u5728\u5fae\u8c03\u4e2d\u66f4\u5bb9\u6613\u88ab\u9057\u5fd8\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u51bb\u7ed3\u76f8\u5173\u5c42\u6765\u63d0\u9ad8\u77e5\u8bc6\u4fdd\u7559\u5ea6\u3002", "motivation": "\u4e86\u89e3\u5fae\u8c03\u5bf9\u4e4b\u524d\u7f16\u8f91\u77e5\u8bc6\u7684\u5f71\u54cd\uff0c\u4ee5\u6539\u8fdb\u7f16\u8f91\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u4e0d\u540c\u5fae\u8c03\u76ee\u6807\u5982\u4f55\u4e0e\u5404\u79cd\u6a21\u578b\u7f16\u8f91\u6280\u672f\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u7f16\u8f91\u7684\u77e5\u8bc6\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u6bd4\u901a\u8fc7\u9884\u8bad\u7ec3\u83b7\u5f97\u7684\u5185\u5728\u77e5\u8bc6\u66f4\u5bb9\u6613\u88ab\u9057\u5fd8\u3002\u51bb\u7ed3\u4e0e\u7f16\u8f91\u5185\u5bb9\u76f8\u5173\u7684\u5c42\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u77e5\u8bc6\u4fdd\u7559\u5ea6\u3002", "conclusion": "\u5f53\u524d\u7f16\u8f91\u65b9\u6cd5\u5b58\u5728\u5173\u952e\u9650\u5236\uff0c\u8bc4\u4f30\u7f16\u8f91\u5728\u4e0b\u6e38\u5fae\u8c03\u4e0b\u7684\u9c81\u68d2\u6027\u5bf9\u4e8e\u5b9e\u9645\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u53d1\u73b0\uff0c\u51bb\u7ed3\u4e0e\u7f16\u8f91\u5185\u5bb9\u76f8\u5173\u7684\u5c42\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u77e5\u8bc6\u4fdd\u7559\u5ea6\uff0c\u4e3a\u672a\u6765\u66f4\u7a33\u5065\u7684\u7f16\u8f91\u65b9\u6cd5\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2507.14200", "pdf": "https://arxiv.org/pdf/2507.14200", "abs": "https://arxiv.org/abs/2507.14200", "authors": ["Shengji Tang", "Jianjian Cao", "Weihao Lin", "Jiale Hong", "Bo Zhang", "Shuyue Hu", "Lei Bai", "Tao Chen", "Wanli Ouyang", "Peng Ye"], "title": "Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper aims to demonstrate the potential and strengths of open-source\ncollectives. It leads to a promising question: Can we harness multiple\nopen-source LLMs to match or even beat the closed-source LLMs? To answer this,\nwe propose SMACS, a scalable multi-agent collaboration system (MACS) framework\nwith high performance. Specifically, for continuous integration of new LLMs and\ngeneralization to diverse questions, we first propose a Retrieval-based Prior\nSelection (RPS), which assigns a proxy performance score to each LLM to select\nthe Top-k LLMs at the instance level for any given question. Then, we propose\nan Exploration-Exploitation-Driven Posterior Enhancement (EPE), encouraging the\ngeneration of diverse responses through prior dropping and selecting the\nhigh-quality response via a hybrid posterior score. Experiments on eight\nmainstream benchmarks validate the effectiveness of our SMACS: by integrating\nfifteen open-source LLMs, SMACS outperforms leading closed-source LLMs in 2025,\ne.g., Claude-3.7-Sonnet (+12.73%), GPT-4.1(+5.36%) and GPT-o3-mini(+5.28%)\nacross multiple tasks. Remarkably, it even exceeds the average of best results\nof different datasets from both open-source LLMs (+2.86%) and closed-source\nLLMs (+2.04%), pushing the upper bound of intelligence. Code will be released\nat https://github.com/magent4aci/SMACS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SMACS\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u591a\u4e2a\u5f00\u6e90LLM\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u95ed\u6e90LLM\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5f00\u6e90\u96c6\u4f53\u7684\u6f5c\u529b\u3002", "motivation": "\u63a2\u8ba8\u80fd\u5426\u5229\u7528\u591a\u4e2a\u5f00\u6e90LLM\u6765\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u95ed\u6e90LLM\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68c0\u7d22\u7684\u5148\u9a8c\u9009\u62e9\uff08RPS\uff09\u548c\u4e00\u79cd\u63a2\u7d22-\u5229\u7528\u9a71\u52a8\u7684\u540e\u9a8c\u589e\u5f3a\uff08EPE\uff09\uff0c\u4ee5\u5b9e\u73b0LLM\u7684\u6301\u7eed\u96c6\u6210\u548c\u591a\u6837\u5316\u95ee\u9898\u7684\u6cdb\u5316\u3002", "result": "\u5728\u516b\u4e2a\u4e3b\u6d41\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86SMACS\u7684\u6709\u6548\u6027\uff0c\u96c6\u621015\u4e2a\u5f00\u6e90LLM\u540e\uff0cSMACS\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u4f18\u4e8eClaude-3.7-Sonnet\u3001GPT-4.1\u548cGPT-o3-mini\u7b49\u95ed\u6e90LLM\u3002", "conclusion": "SMACS\u901a\u8fc7\u96c6\u621015\u4e2a\u5f00\u6e90LLM\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u9886\u5148\u7684\u95ed\u6e90LLM\uff0c\u751a\u81f3\u8d85\u8fc7\u4e86\u5f00\u6e90\u548c\u95ed\u6e90LLM\u7684\u6700\u4f73\u7ed3\u679c\u5e73\u5747\u503c\uff0c\u63a8\u52a8\u4e86\u667a\u80fd\u7684\u4e0a\u9650\u3002"}}
{"id": "2507.14214", "pdf": "https://arxiv.org/pdf/2507.14214", "abs": "https://arxiv.org/abs/2507.14214", "authors": ["Rui Zhao", "Vladyslav Melnychuk", "Jun Zhao", "Jesse Wright", "Nigel Shadbolt"], "title": "Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale", "categories": ["cs.CL", "cs.CR", "cs.CY"], "comment": null, "summary": "In modern times, people have numerous online accounts, but they rarely read\nthe Terms of Service or Privacy Policy of those sites despite claiming\notherwise. This paper introduces PoliAnalyzer, a neuro-symbolic system that\nassists users with personalized privacy policy analysis. PoliAnalyzer uses\nNatural Language Processing (NLP) to extract formal representations of data\nusage practices from policy texts. In favor of deterministic, logical inference\nis applied to compare user preferences with the formal privacy policy\nrepresentation and produce a compliance report. To achieve this, we extend an\nexisting formal Data Terms of Use policy language to model privacy policies as\napp policies and user preferences as data policies. In our evaluation using our\nenriched PolicyIE dataset curated by legal experts, PoliAnalyzer demonstrated\nhigh accuracy in identifying relevant data usage practices, achieving F1-score\nof 90-100% across most tasks. Additionally, we demonstrate how PoliAnalyzer can\nmodel diverse user data-sharing preferences, derived from prior research as 23\nuser profiles, and perform compliance analysis against the top 100 most-visited\nwebsites. This analysis revealed that, on average, 95.2% of a privacy policy's\nsegments do not conflict with the analyzed user preferences, enabling users to\nconcentrate on understanding the 4.8% (636 / 13205) that violates preferences,\nsignificantly reducing cognitive burden. Further, we identified common\npractices in privacy policies that violate user expectations - such as the\nsharing of location data with 3rd parties. This paper demonstrates that\nPoliAnalyzer can support automated personalized privacy policy analysis at\nscale using off-the-shelf NLP tools. This sheds light on a pathway to help\nindividuals regain control over their data and encourage societal discussions\non platform data practices to promote a fairer power dynamic.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aPoliAnalyzer\u7684\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\uff0c\u7528\u4e8e\u5e2e\u52a9\u7528\u6237\u8fdb\u884c\u4e2a\u6027\u5316\u7684\u9690\u79c1\u653f\u7b56\u5206\u6790\u3002\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u903b\u8f91\u63a8\u7406\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u6570\u636e\u4f7f\u7528\u5b9e\u8df5\uff0c\u5e76\u751f\u6210\u5408\u89c4\u62a5\u544a\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0cPoliAnalyzer\u5728\u8bc6\u522b\u76f8\u5173\u6570\u636e\u4f7f\u7528\u5b9e\u8df5\u65b9\u9762\u5177\u6709\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u80fd\u6709\u6548\u51cf\u5c11\u7528\u6237\u7684\u8ba4\u77e5\u8d1f\u62c5\u3002", "motivation": "\u73b0\u4ee3\u4eba\u6709\u8bb8\u591a\u5728\u7ebf\u8d26\u6237\uff0c\u4f46\u5f88\u5c11\u9605\u8bfb\u7f51\u7ad9\u7684\u300a\u670d\u52a1\u6761\u6b3e\u300b\u6216\u300a\u9690\u79c1\u653f\u7b56\u300b\uff0c\u5c3d\u7ba1\u4ed6\u4eec\u58f0\u79f0\u76f8\u53cd\u3002\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u5e2e\u52a9\u7528\u6237\u8fdb\u884c\u4e2a\u6027\u5316\u9690\u79c1\u653f\u7b56\u5206\u6790\u7684\u7cfb\u7edf\u3002", "method": "PoliAnalyzer\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\uff0c\u5b83\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u4ece\u653f\u7b56\u6587\u672c\u4e2d\u63d0\u53d6\u6570\u636e\u4f7f\u7528\u5b9e\u8df5\u7684\u5f62\u5f0f\u5316\u8868\u793a\u3002\u4e3a\u4e86\u8fdb\u884c\u786e\u5b9a\u6027\u3001\u903b\u8f91\u63a8\u7406\uff0c\u5c06\u7528\u6237\u504f\u597d\u4e0e\u5f62\u5f0f\u5316\u7684\u9690\u79c1\u653f\u7b56\u8868\u793a\u8fdb\u884c\u6bd4\u8f83\uff0c\u5e76\u751f\u6210\u5408\u89c4\u62a5\u544a\u3002\u6211\u4eec\u6269\u5c55\u4e86\u4e00\u4e2a\u73b0\u6709\u7684\u6b63\u5f0f\u6570\u636e\u6761\u6b3e\u4f7f\u7528\u653f\u7b56\u8bed\u8a00\uff0c\u4ee5\u5c06\u9690\u79c1\u653f\u7b56\u5efa\u6a21\u4e3a\u5e94\u7528\u7b56\u7565\uff0c\u5c06\u7528\u6237\u504f\u597d\u5efa\u6a21\u4e3a\u6570\u636e\u7b56\u7565\u3002", "result": "\u5728\u4f7f\u7528\u7531\u6cd5\u5f8b\u4e13\u5bb6\u6574\u7406\u7684\u589e\u5f3a\u578bPolicyIE\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u65f6\uff0cPoliAnalyzer\u5728\u8bc6\u522b\u76f8\u5173\u6570\u636e\u4f7f\u7528\u5b9e\u8df5\u65b9\u9762\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\uff0c\u5927\u591a\u6570\u4efb\u52a1\u7684F1\u5206\u6570\u4e3a90-100%\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5c55\u793a\u4e86PoliAnalyzer\u5982\u4f55\u5efa\u6a21\u591a\u6837\u5316\u7684\u7528\u6237\u6570\u636e\u5171\u4eab\u504f\u597d\uff0c\u5e76\u5bf9\u8bbf\u95ee\u91cf\u6700\u9ad8\u7684100\u4e2a\u7f51\u7ad9\u8fdb\u884c\u5408\u89c4\u5206\u6790\u3002\u5206\u6790\u663e\u793a\uff0c\u5e73\u5747\u800c\u8a00\uff0c\u9690\u79c1\u653f\u7b56\u768495.2%\u7684\u6bb5\u843d\u4e0d\u4e0e\u5206\u6790\u7684\u7528\u6237\u504f\u597d\u51b2\u7a81\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u4e13\u6ce8\u4e8e\u7406\u89e34.8%\uff08636 / 13205\uff09\u8fdd\u53cd\u504f\u597d\u7684\u90e8\u5206\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8ba4\u77e5\u8d1f\u62c5\u3002", "conclusion": "\u672c\u6587\u5c55\u793a\u4e86PoliAnalyzer\u53ef\u4ee5\u4f7f\u7528\u73b0\u6210\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5de5\u5177\u5728\u5927\u89c4\u6a21\u4e0a\u652f\u6301\u81ea\u52a8\u5316\u7684\u4e2a\u6027\u5316\u9690\u79c1\u653f\u7b56\u5206\u6790\u3002\u8fd9\u4e3a\u4e2a\u4eba\u91cd\u65b0\u638c\u63a7\u81ea\u5df1\u7684\u6570\u636e\u6307\u660e\u4e86\u4e00\u6761\u9053\u8def\uff0c\u5e76\u9f13\u52b1\u793e\u4f1a\u8ba8\u8bba\u5e73\u53f0\u7684\u6570\u636e\u5b9e\u8df5\uff0c\u4ee5\u4fc3\u8fdb\u66f4\u516c\u5e73\u7684\u6743\u529b\u52a8\u6001\u3002"}}
{"id": "2507.14231", "pdf": "https://arxiv.org/pdf/2507.14231", "abs": "https://arxiv.org/abs/2507.14231", "authors": ["Khalid Hasan", "Jamil Saquer"], "title": "Beyond Architectures: Evaluating the Role of Contextual Embeddings in Detecting Bipolar Disorder on Social Media", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "The 37th International Conference on Software Engineering & Knowledge\n  Engineering, SEKE 2025 (camera-ready)", "summary": "Bipolar disorder is a chronic mental illness frequently underdiagnosed due to\nsubtle early symptoms and social stigma. This paper explores the advanced\nnatural language processing (NLP) models for recognizing signs of bipolar\ndisorder based on user-generated social media text. We conduct a comprehensive\nevaluation of transformer-based models (BERT, RoBERTa, ALBERT, ELECTRA,\nDistilBERT) and Long Short Term Memory (LSTM) models based on contextualized\n(BERT) and static (GloVe, Word2Vec) word embeddings. Experiments were performed\non a large, annotated dataset of Reddit posts after confirming their validity\nthrough sentiment variance and judgmental analysis. Our results demonstrate\nthat RoBERTa achieves the highest performance among transformer models with an\nF1 score of ~98% while LSTM models using BERT embeddings yield nearly identical\nresults. In contrast, LSTMs trained on static embeddings fail to capture\nmeaningful patterns, scoring near-zero F1. These findings underscore the\ncritical role of contextual language modeling in detecting bipolar disorder. In\naddition, we report model training times and highlight that DistilBERT offers\nan optimal balance between efficiency and accuracy. In general, our study\noffers actionable insights for model selection in mental health NLP\napplications and validates the potential of contextualized language models to\nsupport early bipolar disorder screening.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u591a\u79cdNLP\u6a21\u578b\u5728\u68c0\u6d4b\u53cc\u76f8\u60c5\u611f\u969c\u788d\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0RoBERTa\u548c\u4f7f\u7528BERT\u5d4c\u5165\u7684LSTM\u6a21\u578b\u6548\u679c\u6700\u4f73\uff0c\u800c\u4f7f\u7528\u9759\u6001\u5d4c\u5165\u7684LSTM\u6a21\u578b\u6548\u679c\u8f83\u5dee\u3002", "motivation": "\u53cc\u76f8\u60c5\u611f\u969c\u788d\u662f\u4e00\u79cd\u6162\u6027\u7cbe\u795e\u75be\u75c5\uff0c\u7531\u4e8e\u65e9\u671f\u75c7\u72b6\u5fae\u5999\u548c\u793e\u4f1a\u6c61\u540d\u800c\u7ecf\u5e38\u88ab\u8bef\u8bca\u3002\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u5148\u8fdb\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u6a21\u578b\uff0c\u4ee5\u8bc6\u522b\u7528\u6237\u751f\u6210\u7684\u793e\u4ea4\u5a92\u4f53\u6587\u672c\u4e2d\u7684\u53cc\u76f8\u60c5\u611f\u969c\u788d\u8ff9\u8c61\u3002", "method": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u57fa\u4e8etransformer\u7684\u6a21\u578b\uff08BERT\u3001RoBERTa\u3001ALBERT\u3001ELECTRA\u3001DistilBERT\uff09\u548c\u57fa\u4e8e\u4e0a\u4e0b\u6587\uff08BERT\uff09\u548c\u9759\u6001\uff08GloVe\u3001Word2Vec\uff09\u8bcd\u5d4c\u5165\u7684LSTM\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRoBERTa\u5728transformer\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u4f73\uff0cF1\u5206\u6570\u7ea6\u4e3a98%\uff0c\u800c\u4f7f\u7528BERT\u5d4c\u5165\u7684LSTM\u6a21\u578b\u51e0\u4e4e\u8fbe\u5230\u76f8\u540c\u7684\u7ed3\u679c\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u4f7f\u7528\u9759\u6001\u5d4c\u5165\u8bad\u7ec3\u7684LSTMs\u672a\u80fd\u6355\u6349\u5230\u6709\u610f\u4e49\u7684\u6a21\u5f0f\uff0cF1\u5206\u6570\u63a5\u8fd1\u96f6\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u5fc3\u7406\u5065\u5eb7NLP\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6a21\u578b\u9009\u62e9\u89c1\u89e3\uff0c\u5e76\u9a8c\u8bc1\u4e86\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u5728\u652f\u6301\u65e9\u671f\u53cc\u76f8\u60c5\u611f\u969c\u788d\u7b5b\u67e5\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.14238", "pdf": "https://arxiv.org/pdf/2507.14238", "abs": "https://arxiv.org/abs/2507.14238", "authors": ["Matthew Kearney", "Reuben Binns", "Yarin Gal"], "title": "Language Models Change Facts Based on the Way You Talk", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "Large language models (LLMs) are increasingly being used in user-facing\napplications, from providing medical consultations to job interview advice.\nRecent research suggests that these models are becoming increasingly proficient\nat inferring identity information about the author of a piece of text from\nlinguistic patterns as subtle as the choice of a few words. However, little is\nknown about how LLMs use this information in their decision-making in\nreal-world applications. We perform the first comprehensive analysis of how\nidentity markers present in a user's writing bias LLM responses across five\ndifferent high-stakes LLM applications in the domains of medicine, law,\npolitics, government benefits, and job salaries. We find that LLMs are\nextremely sensitive to markers of identity in user queries and that race,\ngender, and age consistently influence LLM responses in these applications. For\ninstance, when providing medical advice, we find that models apply different\nstandards of care to individuals of different ethnicities for the same\nsymptoms; we find that LLMs are more likely to alter answers to align with a\nconservative (liberal) political worldview when asked factual questions by\nolder (younger) individuals; and that LLMs recommend lower salaries for\nnon-White job applicants and higher salaries for women compared to men. Taken\ntogether, these biases mean that the use of off-the-shelf LLMs for these\napplications may cause harmful differences in medical care, foster wage gaps,\nand create different political factual realities for people of different\nidentities. Beyond providing an analysis, we also provide new tools for\nevaluating how subtle encoding of identity in users' language choices impacts\nmodel decisions. Given the serious implications of these findings, we recommend\nthat similar thorough assessments of LLM use in user-facing applications are\nconducted before future deployment.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e0d\u540c\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u5bf9\u7528\u6237\u8eab\u4efd\u6807\u8bb0\u7684\u654f\u611f\u6027\uff0c\u53d1\u73b0\u79cd\u65cf\u3001\u6027\u522b\u548c\u5e74\u9f84\u4f1a\u5f71\u54cdLLMs\u7684\u54cd\u5e94\uff0c\u53ef\u80fd\u5bfc\u81f4\u533b\u7597\u62a4\u7406\u5dee\u5f02\u3001\u5de5\u8d44\u5dee\u8ddd\u548c\u653f\u6cbb\u4e8b\u5b9e\u73b0\u5b9e\u7684\u4e0d\u540c\u3002\u4f5c\u8005\u5efa\u8bae\u5728\u90e8\u7f72LLMs\u524d\u8fdb\u884c\u7c7b\u4f3c\u8bc4\u4f30\u3002", "motivation": "\u4e86\u89e3LLMs\u5982\u4f55\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4f7f\u7528\u8eab\u4efd\u4fe1\u606f\u8fdb\u884c\u51b3\u7b56\uff0c\u4ee5\u53ca\u8fd9\u79cd\u51b3\u7b56\u53ef\u80fd\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "method": "\u6211\u4eec\u5bf9\u4e94\u4e2a\u9ad8\u98ce\u9669\u7684LLM\u5e94\u7528\u8fdb\u884c\u4e86\u9996\u6b21\u5168\u9762\u5206\u6790\uff0c\u8fd9\u4e9b\u5e94\u7528\u6d89\u53ca\u533b\u5b66\u3001\u6cd5\u5f8b\u3001\u653f\u6cbb\u3001\u653f\u5e9c\u798f\u5229\u548c\u5de5\u4f5c\u85aa\u8d44\u9886\u57df\u3002\u6211\u4eec\u7814\u7a76\u4e86\u7528\u6237\u5199\u4f5c\u4e2d\u7684\u8eab\u4efd\u6807\u8bb0\u5982\u4f55\u5f71\u54cdLLMs\u7684\u54cd\u5e94\u3002", "result": "LLMs\u5bf9\u7528\u6237\u67e5\u8be2\u4e2d\u7684\u8eab\u4efd\u6807\u8bb0\u975e\u5e38\u654f\u611f\uff0c\u79cd\u65cf\u3001\u6027\u522b\u548c\u5e74\u9f84\u5728\u8fd9\u4e9b\u5e94\u7528\u4e2d\u6301\u7eed\u5f71\u54cdLLMs\u7684\u54cd\u5e94\u3002\u4f8b\u5982\uff0c\u5728\u63d0\u4f9b\u533b\u7597\u5efa\u8bae\u65f6\uff0c\u6a21\u578b\u4f1a\u5bf9\u4e0d\u540c\u79cd\u65cf\u7684\u4eba\u91c7\u7528\u4e0d\u540c\u7684\u62a4\u7406\u6807\u51c6\uff1b\u5728\u56de\u7b54\u4e8b\u5b9e\u6027\u95ee\u9898\u65f6\uff0c\u5e74\u957f\u8005\u7684\u95ee\u9898\u4f1a\u66f4\u503e\u5411\u4e8e\u4fdd\u5b88\u7684\u653f\u6cbb\u89c2\u70b9\uff0c\u800c\u5e74\u8f7b\u8005\u7684\u95ee\u9898\u5219\u66f4\u503e\u5411\u4e8e\u81ea\u7531\u7684\u653f\u6cbb\u89c2\u70b9\uff1b\u975e\u767d\u4eba\u6c42\u804c\u8005\u7684\u85aa\u8d44\u5efa\u8bae\u8f83\u4f4e\uff0c\u800c\u5973\u6027\u7684\u85aa\u8d44\u5efa\u8bae\u8f83\u9ad8\u3002", "conclusion": "\u4f7f\u7528\u73b0\u6210\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8fd9\u4e9b\u5e94\u7528\u4e2d\u53ef\u80fd\u5bfc\u81f4\u533b\u7597\u62a4\u7406\u4e2d\u7684\u6709\u5bb3\u5dee\u5f02\uff0c\u52a0\u5267\u5de5\u8d44\u5dee\u8ddd\uff0c\u5e76\u4e3a\u4e0d\u540c\u8eab\u4efd\u7684\u4eba\u521b\u9020\u4e0d\u540c\u7684\u653f\u6cbb\u4e8b\u5b9e\u73b0\u5b9e\u3002\u56e0\u6b64\uff0c\u5efa\u8bae\u5728\u672a\u6765\u7684\u90e8\u7f72\u4e4b\u524d\u5bf9LLMs\u5728\u9762\u5411\u7528\u6237\u7684\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\u8fdb\u884c\u7c7b\u4f3c\u7684\u5168\u9762\u8bc4\u4f30\u3002"}}
{"id": "2507.14239", "pdf": "https://arxiv.org/pdf/2507.14239", "abs": "https://arxiv.org/abs/2507.14239", "authors": ["Weihua Zheng", "Roy Ka-Wei Lee", "Zhengyuan Liu", "Kui Wu", "AiTi Aw", "Bowei Zou"], "title": "CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multilingual Large Language Models(MLLMs) demonstrate strong generalization\nacross languages, yet they remain prone to hallucinations, especially in\nlow-resource languages, due to training data imbalances. These hallucinations,\nwhich include inaccurate or fabricated outputs, are particularly problematic in\ndomain-specific generation tasks (Chataigner et al., 2024). To address this\nchallenge, we propose CCL-XCoT(Curriculum-based Contrastive Learning-based\nCross-lingual Chain-of-Thought), a two-stage fine-tuning framework for\nmitigating hallucination in MLLMs. Our approach first enhances cross-lingual\nsemantic alignment through curriculum-based contrastive learning combined with\nnext-token prediction during continued pre-training. Building on this\nfoundation, we then introduce a cross-lingual Chain-of-Thought (XCoT) prompting\nstrategy during instruction fine-tuning, which guides the model to reason in a\nhigh-resource language before generating answers in the target low-resource\nlanguage. Experimental results show that CCL-XCoT reduces hallucination rates\nby up to 62% and substantially improves factual knowledge transfer across\nlanguage pairs, without relying on external retrieval or multi-model ensembles.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCCL-XCoT\u7684\u4e24\u9636\u6bb5\u5fae\u8c03\u6846\u67b6\uff0c\u7528\u4e8e\u51cf\u5c11\u591a\u8bed\u8a00\u5927\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u73b0\u8c61\u5e76\u63d0\u9ad8\u8de8\u8bed\u8a00\u4e8b\u5b9e\u77e5\u8bc6\u7684\u4f20\u9012\u6548\u679c\u3002", "motivation": "\u591a\u8bed\u8a00\u5927\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u7279\u522b\u662f\u5728\u7279\u5b9a\u9886\u57df\u751f\u6210\u4efb\u52a1\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u5fae\u8c03\u6846\u67b6CCL-XCoT\uff0c\u5305\u62ec\u57fa\u4e8e\u8bfe\u7a0b\u7684\u5bf9\u6bd4\u5b66\u4e60\u548c\u8de8\u8bed\u8a00\u601d\u7ef4\u94fe\u63d0\u793a\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCCL-XCoT\u53ef\u4ee5\u5c06\u5e7b\u89c9\u7387\u964d\u4f4e\u591a\u8fbe62%\uff0c\u5e76\u4e14\u5728\u4e0d\u4f9d\u8d56\u5916\u90e8\u68c0\u7d22\u6216\u591a\u6a21\u578b\u96c6\u6210\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u9ad8\u8de8\u8bed\u8a00\u4e8b\u5b9e\u77e5\u8bc6\u7684\u4f20\u9012\u6548\u679c\u3002", "conclusion": "CCL-XCoT\u80fd\u591f\u6709\u6548\u51cf\u5c11\u591a\u8bed\u8a00\u5927\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u73b0\u8c61\uff0c\u5e76\u663e\u8457\u63d0\u5347\u8de8\u8bed\u8a00\u7684\u4e8b\u5b9e\u77e5\u8bc6\u4f20\u9012\u6548\u679c\u3002"}}
{"id": "2507.14240", "pdf": "https://arxiv.org/pdf/2507.14240", "abs": "https://arxiv.org/abs/2507.14240", "authors": ["Mohammad Shahedur Rahman", "Peng Gao", "Yuede Ji"], "title": "HuggingGraph: Understanding the Supply Chain of LLM Ecosystem", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 5 figures", "summary": "Large language models (LLMs) leverage deep learning to process and predict\nsequences of words from context, enabling them to perform various NLP tasks,\nsuch as translation, summarization, question answering, and content generation.\nHowever, the growing size and complexity of developing, training, and deploying\nadvanced LLMs require extensive computational resources and large datasets.\nThis creates a barrier for users. As a result, platforms that host models and\ndatasets are widely used. For example, Hugging Face, one of the most popular\nplatforms, hosted 1.8 million models and 450K datasets by June 2025, with no\nsign of slowing down. Since many LLMs are built from base models, pre-trained\nmodels, and external datasets, they can inherit vulnerabilities, biases, or\nmalicious components from earlier models or datasets. Therefore, it is critical\nto understand the origin and development of these components to better detect\npotential risks, improve model fairness, and ensure compliance. Motivated by\nthis, our project aims to study the relationships between models and datasets,\nwhich are core components of the LLM supply chain. First, we design a method to\nsystematically collect LLM supply chain data. Using this data, we build a\ndirected heterogeneous graph to model the relationships between models and\ndatasets, resulting in a structure with 397,376 nodes and 453,469 edges. We\nthen perform various analyses and uncover several findings, such as: (i) the\nLLM supply chain graph is large, sparse, and follows a power-law degree\ndistribution; (ii) it features a densely connected core and a fragmented\nperiphery; (iii) datasets play pivotal roles in training; (iv) strong\ninterdependence exists between models and datasets; and (v) the graph is\ndynamic, with daily updates reflecting the ecosystem's ongoing evolution.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u6709\u5411\u5f02\u6784\u56fe\u6765\u5efa\u6a21LLM\u4f9b\u5e94\u94fe\uff0c\u5e76\u53d1\u73b0\u4e86\u591a\u4e2a\u91cd\u8981\u7ed3\u679c\u3002", "motivation": "\u7531\u4e8e\u8bb8\u591aLLM\u662f\u4ece\u57fa\u7840\u6a21\u578b\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u5916\u90e8\u6570\u636e\u96c6\u4e2d\u6784\u5efa\u7684\uff0c\u5b83\u4eec\u53ef\u80fd\u4f1a\u7ee7\u627f\u65e9\u671f\u6a21\u578b\u6216\u6570\u636e\u96c6\u4e2d\u7684\u6f0f\u6d1e\u3001\u504f\u89c1\u6216\u6076\u610f\u7ec4\u4ef6\uff0c\u56e0\u6b64\u9700\u8981\u7406\u89e3\u8fd9\u4e9b\u7ec4\u4ef6\u7684\u8d77\u6e90\u548c\u53d1\u5c55\u3002", "method": "\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b9\u6cd5\u6765\u7cfb\u7edf\u5730\u6536\u96c6LLM\u4f9b\u5e94\u94fe\u6570\u636e\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u6709\u5411\u5f02\u6784\u56fe\u6765\u5efa\u6a21\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u6211\u4eec\u53d1\u73b0LLM\u4f9b\u5e94\u94fe\u56fe\u662f\u5927\u578b\u3001\u7a00\u758f\u7684\uff0c\u5e76\u9075\u5faa\u5e42\u5f8b\u5ea6\u5206\u5e03\uff1b\u5b83\u5177\u6709\u5bc6\u96c6\u8fde\u63a5\u7684\u6838\u5fc3\u548c\u788e\u7247\u5316\u7684\u5916\u56f4\uff1b\u6570\u636e\u96c6\u5728\u8bad\u7ec3\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff1b\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e4b\u95f4\u5b58\u5728\u5f3a\u70c8\u7684\u76f8\u4e92\u4f9d\u8d56\u6027\uff1b\u5e76\u4e14\u8be5\u56fe\u662f\u52a8\u6001\u7684\uff0c\u6bcf\u5929\u66f4\u65b0\u4ee5\u53cd\u6620\u751f\u6001\u7cfb\u7edf\u7684\u6301\u7eed\u6f14\u53d8\u3002", "conclusion": "\u4e3a\u4e86\u66f4\u597d\u5730\u68c0\u6d4b\u6f5c\u5728\u98ce\u9669\u3001\u63d0\u9ad8\u6a21\u578b\u516c\u5e73\u6027\u5e76\u786e\u4fdd\u5408\u89c4\u6027\uff0c\u7406\u89e3\u8fd9\u4e9b\u7ec4\u4ef6\u7684\u8d77\u6e90\u548c\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.14241", "pdf": "https://arxiv.org/pdf/2507.14241", "abs": "https://arxiv.org/abs/2507.14241", "authors": ["Rithesh Murthy", "Ming Zhu", "Liangwei Yang", "Jielin Qiu", "Juntao Tan", "Shelby Heinecke", "Huan Wang", "Caiming Xiong", "Silvio Savarese"], "title": "Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) perform best with well-crafted prompts, yet\nprompt engineering remains manual, inconsistent, and inaccessible to\nnon-experts. We introduce Promptomatix, an automatic prompt optimization\nframework that transforms natural language task descriptions into high-quality\nprompts without requiring manual tuning or domain expertise. Promptomatix\nsupports both a lightweight meta-prompt-based optimizer and a DSPy-powered\ncompiler, with modular design enabling future extension to more advanced\nframeworks. The system analyzes user intent, generates synthetic training data,\nselects prompting strategies, and refines prompts using cost-aware objectives.\nEvaluated across 5 task categories, Promptomatix achieves competitive or\nsuperior performance compared to existing libraries, while reducing prompt\nlength and computational overhead making prompt optimization scalable and\nefficient.", "AI": {"tldr": "Promptomatix \u662f\u4e00\u4e2a\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u80fd\u591f\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u8f6c\u5316\u4e3a\u9ad8\u8d28\u91cf\u63d0\u793a\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u6574\u6216\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3002\u5b83\u5728\u591a\u4e2a\u4efb\u52a1\u7c7b\u522b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6bd4\u73b0\u6709\u5e93\u66f4\u5177\u7ade\u4e89\u529b\uff0c\u540c\u65f6\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff0c\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u4e0b\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u63d0\u793a\u5de5\u7a0b\u4ecd\u7136\u662f\u624b\u52a8\u3001\u4e0d\u4e00\u81f4\u4e14\u5bf9\u975e\u4e13\u5bb6\u4e0d\u53cb\u597d\u3002\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u7684\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u63d0\u793a\u7684\u8d28\u91cf\u548c\u53ef\u7528\u6027\u3002", "method": "Promptomatix \u662f\u4e00\u4e2a\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u5b83\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u8f6c\u6362\u4e3a\u9ad8\u8d28\u91cf\u63d0\u793a\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u6574\u6216\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3002\u5b83\u652f\u6301\u57fa\u4e8e\u5143\u63d0\u793a\u7684\u4f18\u5316\u5668\u548cDSPy\u9a71\u52a8\u7684\u7f16\u8bd1\u5668\uff0c\u5e76\u5177\u6709\u6a21\u5757\u5316\u8bbe\u8ba1\u4ee5\u652f\u6301\u672a\u6765\u6269\u5c55\u3002\u7cfb\u7edf\u5206\u6790\u7528\u6237\u610f\u56fe\u3001\u751f\u6210\u5408\u6210\u8bad\u7ec3\u6570\u636e\u3001\u9009\u62e9\u63d0\u793a\u7b56\u7565\u5e76\u4f7f\u7528\u6210\u672c\u610f\u8bc6\u76ee\u6807\u4f18\u5316\u63d0\u793a\u3002", "result": "Promptomatix \u57285\u4e2a\u4efb\u52a1\u7c7b\u522b\u4e2d\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u5176\u6027\u80fd\u4e0e\u73b0\u6709\u5e93\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\u6216\u66f4\u4f18\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u63d0\u793a\u957f\u5ea6\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u4f7f\u63d0\u793a\u4f18\u5316\u66f4\u52a0\u9ad8\u6548\u548c\u53ef\u6269\u5c55\u3002", "conclusion": "Promptomatix \u5728\u591a\u4e2a\u4efb\u52a1\u7c7b\u522b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u76f8\u6bd4\u73b0\u6709\u5e93\u5177\u6709\u7ade\u4e89\u529b\u6216\u4f18\u8d8a\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u63d0\u793a\u957f\u5ea6\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u4f7f\u63d0\u793a\u4f18\u5316\u66f4\u5177\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2507.14298", "pdf": "https://arxiv.org/pdf/2507.14298", "abs": "https://arxiv.org/abs/2507.14298", "authors": ["Wan-Cyuan Fan", "Yen-Chun Chen", "Mengchen Liu", "Alexander Jacobson", "Lu Yuan", "Leonid Sigal"], "title": "In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2407.14506", "summary": "Recent methods for customizing Large Vision Language Models (LVLMs) for\ndomain-specific tasks have shown promising results in scientific chart\ncomprehension. However, existing approaches face two major limitations: First,\nthey rely on paired data from only a few chart types, limiting generalization\nto wide range of chart types. Secondly, they lack targeted pre-training for\nchart-data alignment, which hampers the model's understanding of underlying\ndata. In this paper, we introduce ChartScope, an LVLM optimized for in-depth\nchart comprehension across diverse chart types. We propose an efficient data\ngeneration pipeline that synthesizes paired data for a wide range of chart\ntypes, along with a novel Dual-Path training strategy that enabling the model\nto succinctly capture essential data details while preserving robust reasoning\ncapabilities by incorporating reasoning over the underlying data. Lastly, we\nestablish ChartDQA, a new benchmark for evaluating not only question-answering\nat different levels but also underlying data understanding. Experimental\nresults demonstrate that ChartScope significantly enhances comprehension on a\nwide range of chart types. The code and data are available at\nhttps://davidhalladay.github.io/chartscope_demo.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86ChartScope\uff0c\u4e00\u79cd\u4f18\u5316\u7528\u4e8e\u8de8\u591a\u79cd\u56fe\u8868\u7c7b\u578b\u7684\u6df1\u5165\u56fe\u8868\u7406\u89e3\u7684\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3002\u901a\u8fc7\u9ad8\u6548\u7684\u6570\u636e\u751f\u6210\u7ba1\u9053\u548c\u53cc\u8def\u5f84\u8bad\u7ec3\u7b56\u7565\uff0cChartScope\u63d0\u5347\u4e86\u5bf9\u56fe\u8868\u7684\u7406\u89e3\u80fd\u529b\uff0c\u5e76\u5f15\u5165\u4e86ChartDQA\u57fa\u51c6\u6765\u8bc4\u4f30\u95ee\u7b54\u548c\u6570\u636e\u7406\u89e3\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u5728\u914d\u5bf9\u6570\u636e\u4ec5\u9650\u4e8e\u5c11\u6570\u56fe\u8868\u7c7b\u578b\u4ee5\u53ca\u7f3a\u4e4f\u9488\u5bf9\u56fe\u8868\u6570\u636e\u5bf9\u9f50\u7684\u9488\u5bf9\u6027\u9884\u8bad\u7ec3\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u8fd9\u963b\u788d\u4e86\u6a21\u578b\u5bf9\u5e95\u5c42\u6570\u636e\u7684\u7406\u89e3\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u4e3a\u591a\u79cd\u56fe\u8868\u7c7b\u578b\u5408\u6210\u914d\u5bf9\u6570\u636e\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53cc\u8def\u5f84\u8bad\u7ec3\u7b56\u7565\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u7b80\u6d01\u5730\u6355\u6349\u5173\u952e\u6570\u636e\u7ec6\u8282\uff0c\u540c\u65f6\u901a\u8fc7\u5bf9\u5e95\u5c42\u6570\u636e\u8fdb\u884c\u63a8\u7406\u6765\u4fdd\u6301\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u3002", "result": "ChartScope\u5728\u5404\u79cd\u56fe\u8868\u7c7b\u578b\u4e0a\u7684\u56fe\u8868\u7406\u89e3\u80fd\u529b\u5f97\u5230\u4e86\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cChartScope\u5728\u5e7f\u6cdb\u8303\u56f4\u7684\u56fe\u8868\u7c7b\u578b\u4e0a\u663e\u8457\u589e\u5f3a\u4e86\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2507.14304", "pdf": "https://arxiv.org/pdf/2507.14304", "abs": "https://arxiv.org/abs/2507.14304", "authors": ["Rakesh Paul", "Anusha Kamath", "Kanishk Singla", "Raviraj Joshi", "Utkarsh Vaidya", "Sanjay Singh Chauhan", "Niranjan Wartikar"], "title": "Aligning Large Language Models to Low-Resource Languages through LLM-Based Selective Translation: A Systematic Study", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Multilingual large language models (LLMs) often demonstrate a performance gap\nbetween English and non-English languages, particularly in low-resource\nsettings. Aligning these models to low-resource languages is essential yet\nchallenging due to limited high-quality data. While English alignment datasets\nare readily available, curating equivalent data in other languages is expensive\nand time-consuming. A common workaround is to translate existing English\nalignment data; however, standard translation techniques often fail to preserve\ncritical elements such as code, mathematical expressions, and structured\nformats like JSON. In this work, we investigate LLM-based selective\ntranslation, a technique that selectively translates only the translatable\nparts of a text while preserving non-translatable content and sentence\nstructure. We conduct a systematic study to explore key questions around this\napproach, including its effectiveness compared to vanilla translation, the\nimportance of filtering noisy outputs, and the benefits of mixing translated\nsamples with original English data during alignment. Our experiments focus on\nthe low-resource Indic language Hindi and compare translations generated by\nGoogle Cloud Translation (GCP) and Llama-3.1-405B. The results highlight the\npromise of selective translation as a practical and effective method for\nimproving multilingual alignment in LLMs.", "AI": {"tldr": "This paper explores the use of LLM-based selective translation to improve multilingual alignment in large language models, focusing on the low-resource Indic language Hindi.", "motivation": "Multilingual large language models (LLMs) often demonstrate a performance gap between English and non-English languages, particularly in low-resource settings. Aligning these models to low-resource languages is essential yet challenging due to limited high-quality data.", "method": "We investigate LLM-based selective translation, which selectively translates only the translatable parts of a text while preserving non-translatable content and sentence structure. We conduct a systematic study to explore key questions around this approach.", "result": "Our experiments focus on the low-resource Indic language Hindi and compare translations generated by Google Cloud Translation (GCP) and Llama-3.1-405B. The results highlight the promise of selective translation as a practical and effective method for improving multilingual alignment in LLMs.", "conclusion": "Selective translation shows promise as a practical and effective method for improving multilingual alignment in LLMs."}}
{"id": "2507.14307", "pdf": "https://arxiv.org/pdf/2507.14307", "abs": "https://arxiv.org/abs/2507.14307", "authors": ["Karin de Langis", "Jong Inn Park", "Andreas Schramm", "Bin Hu", "Khanh Chi Le", "Michael Mensink", "Ahn Thu Tong", "Dongyeop Kang"], "title": "How LLMs Comprehend Temporal Meaning in Narratives: A Case Study in Cognitive Evaluation of LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) exhibit increasingly sophisticated linguistic\ncapabilities, yet the extent to which these behaviors reflect human-like\ncognition versus advanced pattern recognition remains an open question. In this\nstudy, we investigate how LLMs process the temporal meaning of linguistic\naspect in narratives that were previously used in human studies. Using an\nExpert-in-the-Loop probing pipeline, we conduct a series of targeted\nexperiments to assess whether LLMs construct semantic representations and\npragmatic inferences in a human-like manner. Our findings show that LLMs\nover-rely on prototypicality, produce inconsistent aspectual judgments, and\nstruggle with causal reasoning derived from aspect, raising concerns about\ntheir ability to fully comprehend narratives. These results suggest that LLMs\nprocess aspect fundamentally differently from humans and lack robust narrative\nunderstanding. Beyond these empirical findings, we develop a standardized\nexperimental framework for the reliable assessment of LLMs' cognitive and\nlinguistic capabilities.", "AI": {"tldr": "This study investigates how LLMs process the temporal meaning of linguistic aspect in narratives and finds that they differ from humans in their processing of aspect and lack robust narrative understanding.", "motivation": "To investigate how LLMs process the temporal meaning of linguistic aspect in narratives and assess their ability to comprehend narratives.", "method": "Using an Expert-in-the-Loop probing pipeline, we conduct a series of targeted experiments to assess whether LLMs construct semantic representations and pragmatic inferences in a human-like manner.", "result": "LLMs over-rely on prototypicality, produce inconsistent aspectual judgments, and struggle with causal reasoning derived from aspect.", "conclusion": "LLMs process aspect fundamentally differently from humans and lack robust narrative understanding."}}
{"id": "2507.14314", "pdf": "https://arxiv.org/pdf/2507.14314", "abs": "https://arxiv.org/abs/2507.14314", "authors": ["Marija An\u0111edeli\u0107", "Dominik \u0160ipek", "Laura Majer", "Jan \u0160najder"], "title": "What Makes You CLIC: Detection of Croatian Clickbait Headlines", "categories": ["cs.CL"], "comment": "Accepted at Slavic NLP 2025", "summary": "Online news outlets operate predominantly on an advertising-based revenue\nmodel, compelling journalists to create headlines that are often scandalous,\nintriguing, and provocative -- commonly referred to as clickbait. Automatic\ndetection of clickbait headlines is essential for preserving information\nquality and reader trust in digital media and requires both contextual\nunderstanding and world knowledge. For this task, particularly in\nless-resourced languages, it remains unclear whether fine-tuned methods or\nin-context learning (ICL) yield better results. In this paper, we compile CLIC,\na novel dataset for clickbait detection of Croatian news headlines spanning a\n20-year period and encompassing mainstream and fringe outlets. We fine-tune the\nBERTi\\'c model on this task and compare its performance to LLM-based ICL\nmethods with prompts both in Croatian and English. Finally, we analyze the\nlinguistic properties of clickbait. We find that nearly half of the analyzed\nheadlines contain clickbait, and that finetuned models deliver better results\nthan general LLMs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.14355", "pdf": "https://arxiv.org/pdf/2507.14355", "abs": "https://arxiv.org/abs/2507.14355", "authors": ["Jianfeng Zhu", "Ruoming Jin", "Karin G. Coifman"], "title": "Can LLMs Infer Personality from Real World Conversations?", "categories": ["cs.CL"], "comment": "21 pages, 12 figures", "summary": "Large Language Models (LLMs) such as OpenAI's GPT-4 and Meta's LLaMA offer a\npromising approach for scalable personality assessment from open-ended\nlanguage. However, inferring personality traits remains challenging, and\nearlier work often relied on synthetic data or social media text lacking\npsychometric validity. We introduce a real-world benchmark of 555\nsemi-structured interviews with BFI-10 self-report scores for evaluating\nLLM-based personality inference. Three state-of-the-art LLMs (GPT-4.1 Mini,\nMeta-LLaMA, and DeepSeek) were tested using zero-shot prompting for BFI-10 item\nprediction and both zero-shot and chain-of-thought prompting for Big Five trait\ninference. All models showed high test-retest reliability, but construct\nvalidity was limited: correlations with ground-truth scores were weak (max\nPearson's $r = 0.27$), interrater agreement was low (Cohen's $\\kappa < 0.10$),\nand predictions were biased toward moderate or high trait levels.\nChain-of-thought prompting and longer input context modestly improved\ndistributional alignment, but not trait-level accuracy. These results\nunderscore limitations in current LLM-based personality inference and highlight\nthe need for evidence-based development for psychological applications.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4eba\u683c\u63a8\u7406\u65b9\u6cd5\uff0c\u53d1\u73b0\u867d\u7136\u6a21\u578b\u5177\u6709\u9ad8\u4fe1\u5ea6\uff0c\u4f46\u6548\u5ea6\u6709\u9650\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u7528\u4e8e\u5fc3\u7406\u5e94\u7528\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982OpenAI\u7684GPT-4\u548cMeta\u7684LLaMA\uff09\u4e3a\u4ece\u5f00\u653e\u5f0f\u7684\u8bed\u8a00\u4e2d\u8fdb\u884c\u53ef\u6269\u5c55\u7684\u4eba\u683c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u65b9\u6cd5\uff0c\u4f46\u63a8\u65ad\u4eba\u683c\u7279\u5f81\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u65e9\u671f\u5de5\u4f5c\u901a\u5e38\u4f9d\u8d56\u4e8e\u5408\u6210\u6570\u636e\u6216\u7f3a\u4e4f\u5fc3\u7406\u6d4b\u91cf\u6709\u6548\u6027\u7684\u793e\u4ea4\u5a92\u4f53\u6587\u672c\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u73b0\u5b9e\u4e16\u754c\u7684\u57fa\u51c6\uff0c\u5305\u542b555\u4e2a\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u5e76\u4f7f\u7528\u96f6\u6837\u672c\u63d0\u793a\u548c\u601d\u7ef4\u94fe\u63d0\u793a\u6d4b\u8bd5\u4e86\u4e09\u79cd\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT-4.1 Mini\u3001Meta-LLaMA\u548cDeepSeek\uff09\u8fdb\u884cBFI-10\u9879\u76ee\u9884\u6d4b\u548c\u5927\u4e94\u79cd\u7279\u8d28\u63a8\u65ad\u3002", "result": "\u6240\u6709\u6a21\u578b\u90fd\u8868\u73b0\u51fa\u9ad8\u6d4b\u8bd5-\u518d\u6d4b\u8bd5\u4fe1\u5ea6\uff0c\u4f46\u6784\u5ff5\u6548\u5ea6\u6709\u9650\uff1a\u4e0e\u771f\u5b9e\u5206\u6570\u7684\u76f8\u5173\u6027\u8f83\u5f31\uff08\u6700\u5927\u76ae\u5c14\u900ar = 0.27\uff09\uff0c\u8bc4\u5206\u8005\u95f4\u7684\u4e00\u81f4\u6027\u8f83\u4f4e\uff08Cohen's \u03ba < 0.10\uff09\uff0c\u9884\u6d4b\u504f\u5411\u4e8e\u4e2d\u7b49\u6216\u9ad8\u7279\u8d28\u6c34\u5e73\u3002\u601d\u7ef4\u94fe\u63d0\u793a\u548c\u66f4\u957f\u7684\u8f93\u5165\u4e0a\u4e0b\u6587\u9002\u5ea6\u6539\u5584\u4e86\u5206\u5e03\u5bf9\u9f50\uff0c\u4f46\u6ca1\u6709\u63d0\u9ad8\u7279\u8d28\u6c34\u5e73\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u7a81\u663e\u4e86\u5f53\u524d\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4eba\u683c\u63a8\u7406\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u4e3a\u5fc3\u7406\u5e94\u7528\u8fdb\u884c\u57fa\u4e8e\u8bc1\u636e\u7684\u5f00\u53d1\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2507.14372", "pdf": "https://arxiv.org/pdf/2507.14372", "abs": "https://arxiv.org/abs/2507.14372", "authors": ["Albert Chen", "Manas Bundele", "Gaurav Ahlawat", "Patrick Stetz", "Zhitao Wang", "Qiang Fei", "Donghoon Jung", "Audrey Chu", "Bharadwaj Jayaraman", "Ayushi Panth", "Yatin Arora", "Sourav Jain", "Renjith Varma", "Alexey Ilin", "Iuliia Melnychuk", "Chelsea Chueh", "Joyan Sil", "Xiaofeng Wang"], "title": "Text-to-SQL for Enterprise Data Analytics", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.HC"], "comment": "11 pages, 8 figures, Workshop on Agentic AI for Enterprise at KDD '25", "summary": "The introduction of large language models has brought rapid progress on\nText-to-SQL benchmarks, but it is not yet easy to build a working enterprise\nsolution. In this paper, we present insights from building an internal chatbot\nthat enables LinkedIn's product managers, engineers, and operations teams to\nself-serve data insights from a large, dynamic data lake. Our approach features\nthree components. First, we construct a knowledge graph that captures\nup-to-date semantics by indexing database metadata, historical query logs,\nwikis, and code. We apply clustering to identify relevant tables for each team\nor product area. Second, we build a Text-to-SQL agent that retrieves and ranks\ncontext from the knowledge graph, writes a query, and automatically corrects\nhallucinations and syntax errors. Third, we build an interactive chatbot that\nsupports various user intents, from data discovery to query writing to\ndebugging, and displays responses in rich UI elements to encourage follow-up\nchats. Our chatbot has over 300 weekly users. Expert review shows that 53% of\nits responses are correct or close to correct on an internal benchmark set.\nThrough ablation studies, we identify the most important knowledge graph and\nmodeling components, offering a practical path for developing enterprise\nText-to-SQL solutions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u6784\u5efa\u4e00\u4e2a\u5185\u90e8\u804a\u5929\u673a\u5668\u4eba\u7684\u7ecf\u9a8c\uff0c\u8be5\u804a\u5929\u673a\u5668\u4eba\u4f7fLinkedIn\u7684\u56e2\u961f\u80fd\u591f\u4ece\u5927\u578b\u6570\u636e\u6e56\u4e2d\u81ea\u52a9\u83b7\u53d6\u6570\u636e\u6d1e\u5bdf\u3002\u65b9\u6cd5\u5305\u62ec\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u3001Text-to-SQL\u4ee3\u7406\u548c\u4ea4\u4e92\u5f0f\u804a\u5929\u673a\u5668\u4eba\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u804a\u5929\u673a\u5668\u4eba\u6709300\u591a\u540d\u7528\u6237\uff0c53%\u7684\u54cd\u5e94\u6b63\u786e\u6216\u63a5\u8fd1\u6b63\u786e\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728Text-to-SQL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e26\u6765\u4e86\u5feb\u901f\u8fdb\u5c55\uff0c\u4f46\u6784\u5efa\u4e00\u4e2a\u53ef\u884c\u7684\u4f01\u4e1a\u89e3\u51b3\u65b9\u6848\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u672c\u6587\u65e8\u5728\u5206\u4eab\u6784\u5efa\u5185\u90e8\u804a\u5929\u673a\u5668\u4eba\u7684\u89c1\u89e3\uff0c\u4f7fLinkedIn\u7684\u4ea7\u54c1\u7ecf\u7406\u3001\u5de5\u7a0b\u5e08\u548c\u8fd0\u8425\u56e2\u961f\u80fd\u591f\u4ece\u5927\u578b\u52a8\u6001\u6570\u636e\u6e56\u4e2d\u81ea\u52a9\u83b7\u53d6\u6570\u636e\u6d1e\u5bdf\u3002", "method": "\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u77e5\u8bc6\u56fe\u8c31\uff0c\u901a\u8fc7\u7d22\u5f15\u6570\u636e\u5e93\u5143\u6570\u636e\u3001\u5386\u53f2\u67e5\u8be2\u65e5\u5fd7\u3001\u7ef4\u57fa\u548c\u4ee3\u7801\u6765\u6355\u6349\u6700\u65b0\u7684\u8bed\u4e49\uff0c\u5e76\u5e94\u7528\u805a\u7c7b\u6765\u8bc6\u522b\u6bcf\u4e2a\u56e2\u961f\u6216\u4ea7\u54c1\u533a\u57df\u7684\u76f8\u5173\u8868\u3002\u6211\u4eec\u8fd8\u6784\u5efa\u4e86\u4e00\u4e2aText-to-SQL\u4ee3\u7406\uff0c\u80fd\u591f\u68c0\u7d22\u548c\u6392\u5e8f\u4e0a\u4e0b\u6587\u3001\u7f16\u5199\u67e5\u8be2\u5e76\u81ea\u52a8\u7ea0\u6b63\u5e7b\u89c9\u548c\u8bed\u6cd5\u9519\u8bef\u3002\u6700\u540e\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u804a\u5929\u673a\u5668\u4eba\uff0c\u652f\u6301\u5404\u79cd\u7528\u6237\u610f\u56fe\uff0c\u5e76\u4ee5\u4e30\u5bcc\u7684UI\u5143\u7d20\u663e\u793a\u54cd\u5e94\uff0c\u9f13\u52b1\u540e\u7eed\u5bf9\u8bdd\u3002", "result": "\u6211\u4eec\u7684\u804a\u5929\u673a\u5668\u4eba\u62e5\u6709\u8d85\u8fc7300\u540d\u6bcf\u5468\u7528\u6237\u3002\u4e13\u5bb6\u8bc4\u5ba1\u663e\u793a\uff0c\u5728\u5185\u90e8\u57fa\u51c6\u96c6\u4e0a\uff0c\u517653%\u7684\u54cd\u5e94\u662f\u6b63\u786e\u7684\u6216\u63a5\u8fd1\u6b63\u786e\u7684\u3002", "conclusion": "\u901a\u8fc7\u6d88\u878d\u7814\u7a76\uff0c\u6211\u4eec\u786e\u5b9a\u4e86\u6700\u91cd\u8981\u7684\u77e5\u8bc6\u56fe\u8c31\u548c\u5efa\u6a21\u7ec4\u4ef6\uff0c\u4e3a\u5f00\u53d1\u4f01\u4e1a\u7ea7Text-to-SQL\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2507.14374", "pdf": "https://arxiv.org/pdf/2507.14374", "abs": "https://arxiv.org/abs/2507.14374", "authors": ["Sinchani Chakraborty", "Sudeshna Sarkar", "Pawan Goyal"], "title": "Error-Aware Curriculum Learning for Biomedical Relation Classification", "categories": ["cs.CL"], "comment": "16 pages, 2 figures", "summary": "Relation Classification (RC) in biomedical texts is essential for\nconstructing knowledge graphs and enabling applications such as drug\nrepurposing and clinical decision-making. We propose an error-aware\nteacher--student framework that improves RC through structured guidance from a\nlarge language model (GPT-4o). Prediction failures from a baseline student\nmodel are analyzed by the teacher to classify error types, assign difficulty\nscores, and generate targeted remediations, including sentence rewrites and\nsuggestions for KG-based enrichment. These enriched annotations are used to\ntrain a first student model via instruction tuning. This model then annotates a\nbroader dataset with difficulty scores and remediation-enhanced inputs. A\nsecond student is subsequently trained via curriculum learning on this dataset,\nordered by difficulty, to promote robust and progressive learning. We also\nconstruct a heterogeneous biomedical knowledge graph from PubMed abstracts to\nsupport context-aware RC. Our approach achieves new state-of-the-art\nperformance on 4 of 5 PPI datasets and the DDI dataset, while remaining\ncompetitive on ChemProt.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bef\u5dee\u611f\u77e5\u7684\u5e08\u751f\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\uff09\u4e2d\u83b7\u5f97\u7ed3\u6784\u5316\u6307\u5bfc\u6765\u6539\u8fdb\u751f\u7269\u533b\u5b66\u6587\u672c\u4e2d\u7684\u5173\u7cfb\u5206\u7c7b\uff08RC\uff09\u3002", "motivation": "\u5728\u751f\u7269\u533b\u5b66\u6587\u672c\u4e2d\u8fdb\u884c\u5173\u7cfb\u5206\u7c7b\uff08RC\uff09\u5bf9\u4e8e\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u548c\u5b9e\u73b0\u836f\u7269\u518d\u5229\u7528\u548c\u4e34\u5e8a\u51b3\u7b56\u7b49\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u8bef\u5dee\u611f\u77e5\u7684\u5e08\u751f\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\uff09\u4e2d\u83b7\u5f97\u7ed3\u6784\u5316\u6307\u5bfc\u6765\u6539\u8fdb\u5173\u7cfb\u5206\u7c7b\uff08RC\uff09\u3002", "result": "\u6211\u4eec\u7684\u65b9\u6cd5\u57285\u4e2aPPI\u6570\u636e\u96c6\u4e2d\u76844\u4e2a\u548cDDI\u6570\u636e\u96c6\u4e2d\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u540c\u65f6\u5728ChemProt\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u57285\u4e2aPPI\u6570\u636e\u96c6\u4e2d\u76844\u4e2a\u548cDDI\u6570\u636e\u96c6\u4e2d\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u540c\u65f6\u5728ChemProt\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\u3002"}}
{"id": "2507.14430", "pdf": "https://arxiv.org/pdf/2507.14430", "abs": "https://arxiv.org/abs/2507.14430", "authors": ["Xiaolin Yan", "Yangxing Liu", "Jiazhang Zheng", "Chi Liu", "Mingyu Du", "Caisheng Chen", "Haoyang Liu", "Ming Ding", "Yuan Li", "Qiuping Liao", "Linfeng Li", "Zhili Mei", "Siyu Wan", "Li Li", "Ruyi Zhong", "Jiangling Yu", "Xule Liu", "Huihui Hu", "Jiameng Yue", "Ruohui Cheng", "Qi Yang", "Liangqing Wu", "Ke Zhu", "Chi Zhang", "Chufei Jing", "Yifan Zhou", "Yan Liang", "Dongdong Li", "Zhaohui Wang", "Bin Zhao", "Mingzhou Wu", "Mingzhong Zhou", "Peng Du", "Zuomin Liao", "Chao Dai", "Pengfei Liang", "Xiaoguang Zhu", "Yu Zhang", "Yu Gu", "Kun Pan", "Yuan Wu", "Yanqing Guan", "Shaojing Wu", "Zikang Feng", "Xianze Ma", "Peishan Cheng", "Wenjuan Jiang", "Jing Ba", "Huihao Yu", "Zeping Hu", "Yuan Xu", "Zhiwei Liu", "He Wang", "Zhenguo Lin", "Ming Liu", "Yanhong Meng"], "title": "X-Intelligence 3.0: Training and Evaluating Reasoning LLM for Semiconductor Display", "categories": ["cs.CL"], "comment": "Technical Report", "summary": "Large language models (LLMs) have recently achieved significant advances in\nreasoning and demonstrated their advantages in solving challenging problems.\nYet, their effectiveness in the semiconductor display industry remains limited\ndue to a lack of domain-specific training and expertise. To bridge this gap, we\npresent X-Intelligence 3.0, the first high-performance reasoning model\nspecifically developed for the semiconductor display industry. This model is\ndesigned to deliver expert-level understanding and reasoning for the industry's\ncomplex challenges. Leveraging a carefully curated industry knowledge base, the\nmodel undergoes supervised fine-tuning and reinforcement learning to enhance\nits reasoning and comprehension capabilities. To further accelerate\ndevelopment, we implemented an automated evaluation framework that simulates\nexpert-level assessments. We also integrated a domain-specific\nretrieval-augmented generation (RAG) mechanism, resulting in notable\nperformance gains on benchmark datasets. Despite its relatively compact size of\n32 billion parameters, X-Intelligence 3.0 outperforms SOTA DeepSeek-R1-671B\nacross multiple evaluations. This demonstrates its exceptional efficiency and\nestablishes it as a powerful solution to the longstanding reasoning challenges\nfaced by the semiconductor display industry.", "AI": {"tldr": "X-Intelligence 3.0 is a high-performance reasoning model specifically developed for the semiconductor display industry, demonstrating exceptional efficiency and performance gains through domain-specific training and techniques like RAG.", "motivation": "To bridge the gap in the effectiveness of large language models (LLMs) in the semiconductor display industry due to a lack of domain-specific training and expertise.", "method": "The model is designed to deliver expert-level understanding and reasoning for the industry's complex challenges. It leverages a carefully curated industry knowledge base, undergoes supervised fine-tuning and reinforcement learning, and integrates a domain-specific retrieval-augmented generation (RAG) mechanism.", "result": "Despite its relatively compact size of 32 billion parameters, X-Intelligence 3.0 outperforms SOTA DeepSeek-R1-671B across multiple evaluations.", "conclusion": "X-Intelligence 3.0 demonstrates exceptional efficiency and establishes itself as a powerful solution to the longstanding reasoning challenges faced by the semiconductor display industry."}}
{"id": "2507.14578", "pdf": "https://arxiv.org/pdf/2507.14578", "abs": "https://arxiv.org/abs/2507.14578", "authors": ["Sachin Yadav", "Dominik Schlechtweg"], "title": "XL-DURel: Finetuning Sentence Transformers for Ordinal Word-in-Context Classification", "categories": ["cs.CL"], "comment": "8 pages", "summary": "We propose XL-DURel, a finetuned, multilingual Sentence Transformer model\noptimized for ordinal Word-in-Context classification. We test several loss\nfunctions for regression and ranking tasks managing to outperform previous\nmodels on ordinal and binary data with a ranking objective based on angular\ndistance in complex space. We further show that binary WiC can be treated as a\nspecial case of ordinal WiC and that optimizing models for the general ordinal\ntask improves performance on the more specific binary task. This paves the way\nfor a unified treatment of WiC modeling across different task formulations.", "AI": {"tldr": "\u63d0\u51faXL-DURel\u6a21\u578b\uff0c\u4f18\u5316\u6709\u5e8fWord-in-Context\u5206\u7c7b\u4efb\u52a1\uff0c\u63d0\u5347\u5728\u4e8c\u8fdb\u5236\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u5b9e\u73b0WiC\u5efa\u6a21\u7684\u7edf\u4e00\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u5bf9WiC\u5efa\u6a21\u7684\u7edf\u4e00\u5904\u7406\uff0c\u6211\u4eec\u8bd5\u56fe\u901a\u8fc7\u4f18\u5316\u6a21\u578b\u6765\u89e3\u51b3\u6709\u5e8f\u4efb\u52a1\uff0c\u4ece\u800c\u63d0\u5347\u5728\u66f4\u5177\u4f53\u7684\u4e8c\u8fdb\u5236\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86XL-DURel\uff0c\u4e00\u4e2a\u7ecf\u8fc7\u5fae\u8c03\u7684\u591a\u8bed\u8a00Sentence Transformer\u6a21\u578b\uff0c\u4e13\u95e8\u7528\u4e8e\u6709\u5e8fWord-in-Context\u5206\u7c7b\u3002\u6211\u4eec\u6d4b\u8bd5\u4e86\u591a\u79cd\u635f\u5931\u51fd\u6570\uff0c\u5e76\u57fa\u4e8e\u590d\u6742\u7a7a\u95f4\u4e2d\u7684\u89d2\u5ea6\u8ddd\u79bb\u8fdb\u884c\u6392\u540d\u76ee\u6807\u4f18\u5316\u3002", "result": "XL-DURel\u6a21\u578b\u5728\u6709\u5e8f\u548c\u4e8c\u8fdb\u5236\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u4e8e\u4e4b\u524d\u6a21\u578b\uff0c\u5e76\u8bc1\u660e\u4e8c\u8fdb\u5236WiC\u53ef\u4ee5\u4f5c\u4e3a\u6709\u5e8fWiC\u7684\u4e00\u4e2a\u7279\u4f8b\u3002", "conclusion": "XL-DURel\u6a21\u578b\u5728\u6709\u5e8f\u548c\u4e8c\u8fdb\u5236\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u4e8e\u4e4b\u524d\u6a21\u578b\uff0c\u4e3aWiC\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.14579", "pdf": "https://arxiv.org/pdf/2507.14579", "abs": "https://arxiv.org/abs/2507.14579", "authors": ["Kester Wong", "Sahan Bulathwela", "Mutlu Cukurova"], "title": "Exploring Human-AI Complementarity in CPS Diagnosis Using Unimodal and Multimodal BERT Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to appear in the workshop proceedings for the HEXED'25\n  workshop in the 26th International Conference on Artificial Intelligence in\n  Education 2025 (AIED 2025), 22 July 2025, Palermo, Italy. 5 pages", "summary": "Detecting collaborative problem solving (CPS) indicators from dialogue using\nmachine learning techniques is a significant challenge for the field of AI in\nEducation. Recent studies have explored the use of Bidirectional Encoder\nRepresentations from Transformers (BERT) models on transcription data to\nreliably detect meaningful CPS indicators. A notable advancement involved the\nmultimodal BERT variant, AudiBERT, which integrates speech and\nacoustic-prosodic audio features to enhance CPS diagnosis. Although initial\nresults demonstrated multimodal improvements, the statistical significance of\nthese enhancements remained unclear, and there was insufficient guidance on\nleveraging human-AI complementarity for CPS diagnosis tasks. This workshop\npaper extends the previous research by highlighting that the AudiBERT model not\nonly improved the classification of classes that were sparse in the dataset,\nbut it also had statistically significant class-wise improvements over the BERT\nmodel for classifications in the social-cognitive dimension. However, similar\nsignificant class-wise improvements over the BERT model were not observed for\nclassifications in the affective dimension. A correlation analysis highlighted\nthat larger training data was significantly associated with higher recall\nperformance for both the AudiBERT and BERT models. Additionally, the precision\nof the BERT model was significantly associated with high inter-rater agreement\namong human coders. When employing the BERT model to diagnose indicators within\nthese subskills that were well-detected by the AudiBERT model, the performance\nacross all indicators was inconsistent. We conclude the paper by outlining a\nstructured approach towards achieving human-AI complementarity for CPS\ndiagnosis, highlighting the crucial inclusion of model explainability to\nsupport human agency and engagement in the reflective coding process.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AudiBERT\u6a21\u578b\u5728\u534f\u4f5c\u95ee\u9898\u89e3\u51b3\u8bca\u65ad\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5b83\u5728\u67d0\u4e9b\u65b9\u9762\u4f18\u4e8eBERT\u6a21\u578b\uff0c\u4f46\u4e5f\u5b58\u5728\u5c40\u9650\u6027\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u4eba\u673a\u4e92\u8865\u6027\u548c\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u63d0\u5347\u8bca\u65ad\u6548\u679c\u548c\u4eba\u7c7b\u53c2\u4e0e\u5ea6\u3002", "motivation": "\u5f53\u524dAI\u6559\u80b2\u9886\u57df\u9762\u4e34\u7684\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u662f\u5229\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u4ece\u5bf9\u8bdd\u4e2d\u68c0\u6d4b\u534f\u4f5c\u95ee\u9898\u89e3\u51b3\uff08CPS\uff09\u6307\u6807\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u5c1d\u8bd5\u4f7f\u7528BERT\u6a21\u578b\u548c\u591a\u6a21\u6001\u7684AudiBERT\u6a21\u578b\u6765\u63d0\u9ad8CPS\u8bca\u65ad\u6548\u679c\uff0c\u4f46\u8fd9\u4e9b\u6539\u8fdb\u7684\u7edf\u8ba1\u663e\u8457\u6027\u5c1a\u4e0d\u660e\u786e\uff0c\u4e14\u7f3a\u4e4f\u5173\u4e8e\u5982\u4f55\u5229\u7528\u4eba\u673a\u4e92\u8865\u6027\u7684\u6307\u5bfc\u3002", "method": "\u672c\u6587\u6269\u5c55\u4e86\u4e4b\u524d\u7684\u7814\u7a76\uff0c\u91cd\u70b9\u5206\u6790\u4e86AudiBERT\u6a21\u578b\u5728\u68c0\u6d4b\u534f\u4f5c\u95ee\u9898\u89e3\u51b3\u6307\u6807\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u6bd4\u8f83\u4e86\u5176\u4e0eBERT\u6a21\u578b\u7684\u5dee\u5f02\u3002\u6b64\u5916\uff0c\u8fd8\u8fdb\u884c\u4e86\u76f8\u5173\u6027\u5206\u6790\uff0c\u63a2\u8ba8\u4e86\u8bad\u7ec3\u6570\u636e\u91cf\u4e0e\u53ec\u56de\u7387\u3001BERT\u6a21\u578b\u7cbe\u5ea6\u4e0e\u4eba\u5de5\u7f16\u7801\u8005\u95f4\u4e00\u81f4\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "AudiBERT\u6a21\u578b\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6570\u636e\u96c6\u4e2d\u7a00\u758f\u7c7b\u522b\u7684\u5206\u7c7b\u6548\u679c\uff0c\u8fd8\u5728\u793e\u4f1a\u8ba4\u77e5\u7ef4\u5ea6\u7684\u5206\u7c7b\u4e0a\u8868\u73b0\u51fa\u7edf\u8ba1\u5b66\u4e0a\u7684\u663e\u8457\u6539\u8fdb\u3002\u7136\u800c\uff0c\u5728\u60c5\u611f\u7ef4\u5ea6\u7684\u5206\u7c7b\u4e2d\u5e76\u672a\u89c2\u5bdf\u5230\u7c7b\u4f3c\u7684\u6548\u679c\u3002\u540c\u65f6\uff0c\u8f83\u5927\u7684\u8bad\u7ec3\u6570\u636e\u91cf\u4e0e\u8f83\u9ad8\u7684\u53ec\u56de\u7387\u663e\u8457\u76f8\u5173\uff0c\u800cBERT\u6a21\u578b\u7684\u7cbe\u5ea6\u4e0e\u4eba\u5de5\u7f16\u7801\u8005\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u663e\u8457\u76f8\u5173\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u63d0\u51fa\u4e00\u79cd\u7ed3\u6784\u5316\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u5b9e\u73b0\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u7c7b\u5728\u534f\u4f5c\u95ee\u9898\u89e3\u51b3\u8bca\u65ad\u4e2d\u7684\u4e92\u8865\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5728\u652f\u6301\u4eba\u7c7b\u81ea\u4e3b\u6027\u548c\u53c2\u4e0e\u53cd\u601d\u7f16\u7801\u8fc7\u7a0b\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.14584", "pdf": "https://arxiv.org/pdf/2507.14584", "abs": "https://arxiv.org/abs/2507.14584", "authors": ["Kester Wong", "Sahan Bulathwela", "Mutlu Cukurova"], "title": "Explainable Collaborative Problem Solving Diagnosis with BERT using SHAP and its Implications for Teacher Adoption", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to appear in the workshop proceedings for the HEXED'25\n  workshop in the 26th International Conference on Artificial Intelligence in\n  Education 2025 (AIED 2025), 22 July 2025, Palermo, Italy. 6 pages, 2 figures", "summary": "The use of Bidirectional Encoder Representations from Transformers (BERT)\nmodel and its variants for classifying collaborative problem solving (CPS) has\nbeen extensively explored within the AI in Education community. However,\nlimited attention has been given to understanding how individual tokenised\nwords in the dataset contribute to the model's classification decisions.\nEnhancing the explainability of BERT-based CPS diagnostics is essential to\nbetter inform end users such as teachers, thereby fostering greater trust and\nfacilitating wider adoption in education. This study undertook a preliminary\nstep towards model transparency and explainability by using SHapley Additive\nexPlanations (SHAP) to examine how different tokenised words in transcription\ndata contributed to a BERT model's classification of CPS processes. The\nfindings suggested that well-performing classifications did not necessarily\nequate to a reasonable explanation for the classification decisions. Particular\ntokenised words were used frequently to affect classifications. The analysis\nalso identified a spurious word, which contributed positively to the\nclassification but was not semantically meaningful to the class. While such\nmodel transparency is unlikely to be useful to an end user to improve their\npractice, it can help them not to overrely on LLM diagnostics and ignore their\nhuman expertise. We conclude the workshop paper by noting that the extent to\nwhich the model appropriately uses the tokens for its classification is\nassociated with the number of classes involved. It calls for an investigation\ninto the exploration of ensemble model architectures and the involvement of\nhuman-AI complementarity for CPS diagnosis, since considerable human reasoning\nis still required for fine-grained discrimination of CPS subskills.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8eBERT\u7684CPS\u5206\u7c7b\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4f7f\u7528SHAP\u5206\u6790\u5206\u8bcd\u5bf9\u5206\u7c7b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e00\u4e9b\u5206\u8bcd\u5bf9\u5206\u7c7b\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4f46\u5176\u4e2d\u6709\u4e9b\u8bcd\u8bed\u5728\u8bed\u4e49\u4e0a\u5e76\u4e0d\u76f8\u5173\uff0c\u8fd9\u8868\u660e\u6a21\u578b\u900f\u660e\u5ea6\u53ef\u80fd\u5e2e\u52a9\u7528\u6237\u4e0d\u8fc7\u5ea6\u4f9d\u8d56AI\u8bca\u65ad\uff0c\u800c\u662f\u7ed3\u5408\u81ea\u8eab\u4e13\u4e1a\u77e5\u8bc6\u3002", "motivation": "\u589e\u5f3a\u57fa\u4e8eBERT\u7684CPS\u8bca\u65ad\u7684\u53ef\u89e3\u91ca\u6027\u5bf9\u4e8e\u66f4\u597d\u5730\u5411\u6559\u5e08\u7b49\u7ec8\u7aef\u7528\u6237\u4f20\u8fbe\u4fe1\u606f\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u6709\u52a9\u4e8e\u5efa\u7acb\u4fe1\u4efb\u5e76\u4fc3\u8fdb\u6559\u80b2\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u672c\u6587\u4f7f\u7528SHapley Additive exPlanations (SHAP)\u6765\u5206\u6790\u4e0d\u540c\u5206\u8bcd\u5728\u8f6c\u5f55\u6570\u636e\u4e2d\u5bf9BERT\u6a21\u578b\u5206\u7c7bCPS\u8fc7\u7a0b\u7684\u8d21\u732e\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8868\u73b0\u826f\u597d\u7684\u5206\u7c7b\u5e76\u4e0d\u4e00\u5b9a\u610f\u5473\u7740\u5408\u7406\u7684\u5206\u7c7b\u51b3\u7b56\u89e3\u91ca\u3002\u67d0\u4e9b\u5206\u8bcd\u9891\u7e41\u5730\u5f71\u54cd\u5206\u7c7b\uff0c\u5e76\u4e14\u53d1\u73b0\u4e86\u4e00\u4e2a\u65e0\u610f\u4e49\u7684\u8bcd\u8bed\uff0c\u5b83\u5bf9\u5206\u7c7b\u6709\u79ef\u6781\u8d21\u732e\u4f46\u8bed\u4e49\u4e0a\u4e0d\u76f8\u5173\u3002", "conclusion": "\u672c\u6587\u7ed3\u8bba\u6307\u51fa\uff0c\u6a21\u578b\u5728\u5206\u7c7b\u65f6\u9002\u5f53\u4f7f\u7528\u6807\u8bb0\u7684\u7a0b\u5ea6\u4e0e\u6d89\u53ca\u7684\u7c7b\u522b\u6570\u91cf\u6709\u5173\uff0c\u5e76\u547c\u5401\u7814\u7a76\u96c6\u6210\u6a21\u578b\u67b6\u6784\u548c\u4eba\u673a\u4e92\u8865\u5728CPS\u8bca\u65ad\u4e2d\u7684\u5e94\u7528\uff0c\u56e0\u4e3a\u4ecd\u7136\u9700\u8981\u5927\u91cf\u7684\u4eba\u7c7b\u63a8\u7406\u6765\u8fdb\u884cCPS\u5b50\u6280\u80fd\u7684\u7cbe\u7ec6\u533a\u5206\u3002"}}
{"id": "2507.14590", "pdf": "https://arxiv.org/pdf/2507.14590", "abs": "https://arxiv.org/abs/2507.14590", "authors": ["\u0141ukasz Radli\u0144ski", "Mateusz Gu\u015bciora", "Jan Koco\u0144"], "title": "Backtranslation and paraphrasing in the LLM era? Comparing data augmentation methods for emotion classification", "categories": ["cs.CL", "cs.AI"], "comment": "International Conference on Computational Science 2025", "summary": "Numerous domain-specific machine learning tasks struggle with data scarcity\nand class imbalance. This paper systematically explores data augmentation\nmethods for NLP, particularly through large language models like GPT. The\npurpose of this paper is to examine and evaluate whether traditional methods\nsuch as paraphrasing and backtranslation can leverage a new generation of\nmodels to achieve comparable performance to purely generative methods. Methods\naimed at solving the problem of data scarcity and utilizing ChatGPT were\nchosen, as well as an exemplary dataset. We conducted a series of experiments\ncomparing four different approaches to data augmentation in multiple\nexperimental setups. We then evaluated the results both in terms of the quality\nof generated data and its impact on classification performance. The key\nfindings indicate that backtranslation and paraphrasing can yield comparable or\neven better results than zero and a few-shot generation of examples.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86NLP\u4e2d\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u53d1\u73b0backtranslation\u548cparaphrasing\u53ef\u4ee5\u8fbe\u5230\u4e0e\u751f\u6210\u65b9\u6cd5\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u6548\u679c\u3002", "motivation": "\u8bb8\u591a\u7279\u5b9a\u9886\u57df\u7684\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u672c\u6587\u7cfb\u7edf\u5730\u63a2\u8ba8\u4e86NLP\u4e2d\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982GPT\u3002", "method": "\u9009\u62e9\u4e86\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u5e76\u5229\u7528ChatGPT\u7684\u65b9\u6cd5\u4ee5\u53ca\u4e00\u4e2a\u793a\u4f8b\u6570\u636e\u96c6\uff0c\u5e76\u8fdb\u884c\u4e86\u6bd4\u8f83\u56db\u79cd\u4e0d\u540c\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u7684\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cbacktranslation\u548cparaphrasing\u5728\u751f\u6210\u6570\u636e\u8d28\u91cf\u548c\u5206\u7c7b\u6027\u80fd\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "conclusion": "backtranslation\u548cparaphrasing\u53ef\u4ee5\u4ea7\u751f\u4e0e\u96f6\u6837\u672c\u6216\u5c11\u6837\u672c\u751f\u6210\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u7ed3\u679c\u3002"}}
{"id": "2507.14615", "pdf": "https://arxiv.org/pdf/2507.14615", "abs": "https://arxiv.org/abs/2507.14615", "authors": ["Fred Mutisya", "Shikoh Gitau", "Christine Syovata", "Diana Oigara", "Ibrahim Matende", "Muna Aden", "Munira Ali", "Ryan Nyotu", "Diana Marion", "Job Nyangena", "Nasubo Ongoma", "Keith Mbae", "Elizabeth Wamicha", "Eric Mibuari", "Jean Philbert Nsengemana", "Talkmore Chidede"], "title": "Retrieval-Augmented Clinical Benchmarking for Contextual Model Testing in Kenyan Primary Care: A Methodology Paper", "categories": ["cs.CL", "cs.AI"], "comment": "29 pages, 6 figs, 6 tables. Companion methods paper forthcoming", "summary": "Large Language Models(LLMs) hold promise for improving healthcare access in\nlow-resource settings, but their effectiveness in African primary care remains\nunderexplored. We present a methodology for creating a benchmark dataset and\nevaluation framework focused on Kenyan Level 2 and 3 clinical care. Our\napproach uses retrieval augmented generation (RAG) to ground clinical questions\nin Kenya's national guidelines, ensuring alignment with local standards. These\nguidelines were digitized, chunked, and indexed for semantic retrieval. Gemini\nFlash 2.0 Lite was then prompted with guideline excerpts to generate realistic\nclinical scenarios, multiple-choice questions, and rationale based answers in\nEnglish and Swahili. Kenyan physicians co-created and refined the dataset, and\na blinded expert review process ensured clinical accuracy, clarity, and\ncultural appropriateness. The resulting Alama Health QA dataset includes\nthousands of regulator-aligned question answer pairs across common outpatient\nconditions. Beyond accuracy, we introduce evaluation metrics that test clinical\nreasoning, safety, and adaptability such as rare case detection (Needle in the\nHaystack), stepwise logic (Decision Points), and contextual adaptability.\nInitial results reveal significant performance gaps when LLMs are applied to\nlocalized scenarios, consistent with findings that LLM accuracy is lower on\nAfrican medical content than on US-based benchmarks. This work offers a\nreplicable model for guideline-driven, dynamic benchmarking to support safe AI\ndeployment in African health systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u80af\u5c3c\u4e9a\u4e34\u5e8a\u62a4\u7406\u7684\u57fa\u51c6\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408\u80af\u5c3c\u4e9a\u56fd\u5bb6\u6307\u5357\u751f\u6210\u4e34\u5e8a\u573a\u666f\u548c\u95ee\u9898\u3002\u6570\u636e\u96c6\u7531\u80af\u5c3c\u4e9a\u533b\u751f\u5171\u540c\u521b\u5efa\uff0c\u5e76\u901a\u8fc7\u76f2\u5ba1\u4e13\u5bb6\u8bc4\u5ba1\u786e\u4fdd\u8d28\u91cf\u3002\u7814\u7a76\u53d1\u73b0LLMs\u5728\u975e\u6d32\u533b\u5b66\u5185\u5bb9\u4e0a\u7684\u51c6\u786e\u6027\u8f83\u4f4e\uff0c\u5e76\u5f15\u5165\u4e86\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u6765\u6d4b\u8bd5\u4e34\u5e8a\u63a8\u7406\u3001\u5b89\u5168\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6539\u5584\u4f4e\u8d44\u6e90\u73af\u5883\u4e2d\u7684\u533b\u7597\u4fdd\u5065\u83b7\u53d6\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u5728\u975e\u6d32\u521d\u7ea7\u62a4\u7406\u4e2d\u7684\u6709\u6548\u6027\u4ecd\u9700\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u521b\u5efa\u4e00\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u8bc4\u4f30LLMs\u5728\u80af\u5c3c\u4e9a\u4e34\u5e8a\u62a4\u7406\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u7528\u4e8e\u521b\u5efa\u9488\u5bf9\u80af\u5c3c\u4e9a\u4e8c\u7ea7\u548c\u4e09\u7ea7\u4e34\u5e8a\u62a4\u7406\u7684\u57fa\u51c6\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5c06\u4e34\u5e8a\u95ee\u9898\u4e0e\u80af\u5c3c\u4e9a\u56fd\u5bb6\u6307\u5357\u76f8\u7ed3\u5408\uff0c\u786e\u4fdd\u7b26\u5408\u5f53\u5730\u6807\u51c6\u3002\u8fd9\u4e9b\u6307\u5357\u88ab\u6570\u5b57\u5316\u3001\u5206\u5757\u548c\u7d22\u5f15\u4ee5\u8fdb\u884c\u8bed\u4e49\u68c0\u7d22\u3002\u7136\u540e\u7528Gemini Flash 2.0 Lite\u63d0\u793a\u751f\u6210\u73b0\u5b9e\u7684\u4e34\u5e8a\u573a\u666f\u3001\u9009\u62e9\u9898\u548c\u57fa\u4e8e\u6307\u5357\u7684\u89e3\u7b54\u3002\u80af\u5c3c\u4e9a\u533b\u751f\u5171\u540c\u521b\u5efa\u548c\u4f18\u5316\u4e86\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u76f2\u5ba1\u4e13\u5bb6\u8bc4\u5ba1\u8fc7\u7a0b\u786e\u4fdd\u4e34\u5e8a\u51c6\u786e\u6027\u3001\u6e05\u6670\u5ea6\u548c\u6587\u5316\u9002\u5f53\u6027\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u5c06LLMs\u5e94\u7528\u4e8e\u672c\u5730\u5316\u573a\u666f\u65f6\u5b58\u5728\u663e\u8457\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u8fd9\u4e0eLLM\u5728\u975e\u6d32\u533b\u5b66\u5185\u5bb9\u4e0a\u7684\u51c6\u786e\u6027\u4f4e\u4e8e\u7f8e\u56fd\u57fa\u51c6\u7684\u53d1\u73b0\u4e00\u81f4\u3002\u672c\u7814\u7a76\u8fd8\u5f15\u5165\u4e86\u8bc4\u4f30\u6307\u6807\uff0c\u4ee5\u6d4b\u8bd5\u4e34\u5e8a\u63a8\u7406\u3001\u5b89\u5168\u6027\u548c\u9002\u5e94\u6027\uff0c\u5982\u7f55\u89c1\u75c5\u4f8b\u68c0\u6d4b\uff08Needle in the Haystack\uff09\u3001\u9010\u6b65\u903b\u8f91\uff08Decision Points\uff09\u548c\u4e0a\u4e0b\u6587\u9002\u5e94\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u5236\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u6307\u5bfc\u57fa\u4e8e\u6307\u5357\u7684\u52a8\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u652f\u6301\u975e\u6d32\u536b\u751f\u7cfb\u7edf\u4e2d\u5b89\u5168\u7684\u4eba\u5de5\u667a\u80fd\u90e8\u7f72\u3002"}}
{"id": "2507.14640", "pdf": "https://arxiv.org/pdf/2507.14640", "abs": "https://arxiv.org/abs/2507.14640", "authors": ["Eric Xia", "Jugal Kalita"], "title": "Linear Relational Decoding of Morphology in Language Models", "categories": ["cs.CL"], "comment": null, "summary": "A two-part affine approximation has been found to be a good approximation for\ntransformer computations over certain subject object relations. Adapting the\nBigger Analogy Test Set, we show that the linear transformation Ws, where s is\na middle layer representation of a subject token and W is derived from model\nderivatives, is also able to accurately reproduce final object states for many\nrelations. This linear technique is able to achieve 90% faithfulness on\nmorphological relations, and we show similar findings multi-lingually and\nacross models. Our findings indicate that some conceptual relationships in\nlanguage models, such as morphology, are readily interpretable from latent\nspace, and are sparsely encoded by cross-layer linear transformations.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\uff0c\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u67d0\u4e9b\u6982\u5ff5\u5173\u7cfb\uff08\u5982\u5f62\u6001\u5b66\uff09\u53ef\u4ee5\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u8de8\u5c42\u7ebf\u6027\u53d8\u6362\u8fdb\u884c\u89e3\u91ca\u3002", "motivation": "\u6211\u4eec\u60f3\u8981\u9a8c\u8bc1\u7ebf\u6027\u53d8\u6362\u662f\u5426\u80fd\u591f\u51c6\u786e\u5730\u518d\u73b0\u6700\u7ec8\u7684\u5bf9\u8c61\u72b6\u6001\uff0c\u5e76\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u4e2d\u67d0\u4e9b\u6982\u5ff5\u5173\u7cfb\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u6211\u4eec\u4f7f\u7528\u4e86Bigger Analogy Test Set\u6765\u9a8c\u8bc1\u7ebf\u6027\u53d8\u6362Ws\u7684\u6548\u679c\uff0c\u5176\u4e2ds\u662f\u4e3b\u4f53\u6807\u8bb0\u7684\u4e2d\u95f4\u5c42\u8868\u793a\uff0cW\u662f\u4ece\u6a21\u578b\u5bfc\u6570\u4e2d\u5f97\u51fa\u7684\u3002", "result": "\u8be5\u7ebf\u6027\u6280\u672f\u5728\u5f62\u6001\u5b66\u5173\u7cfb\u4e0a\u8fbe\u5230\u4e8690%\u7684\u5fe0\u5b9e\u5ea6\uff0c\u5e76\u4e14\u5728\u591a\u8bed\u8a00\u548c\u4e0d\u540c\u6a21\u578b\u4e2d\u5f97\u5230\u4e86\u7c7b\u4f3c\u7684\u7ed3\u679c\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4e00\u4e9b\u6982\u5ff5\u5173\u7cfb\uff0c\u5982\u5f62\u6001\u5b66\uff0c\u53ef\u4ee5\u4ece\u6f5c\u5728\u7a7a\u95f4\u4e2d\u89e3\u91ca\uff0c\u5e76\u4e14\u7531\u8de8\u5c42\u7ebf\u6027\u53d8\u6362\u7a00\u758f\u7f16\u7801\u3002"}}
{"id": "2507.14649", "pdf": "https://arxiv.org/pdf/2507.14649", "abs": "https://arxiv.org/abs/2507.14649", "authors": ["Minsuh Joo", "Hyunsoo Cho"], "title": "Cleanse: Uncertainty Estimation Approach Using Clustering-based Semantic Consistency in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Despite the outstanding performance of large language models (LLMs) across\nvarious NLP tasks, hallucinations in LLMs--where LLMs generate inaccurate\nresponses--remains as a critical problem as it can be directly connected to a\ncrisis of building safe and reliable LLMs. Uncertainty estimation is primarily\nused to measure hallucination levels in LLM responses so that correct and\nincorrect answers can be distinguished clearly. This study proposes an\neffective uncertainty estimation approach, \\textbf{Cl}ust\\textbf{e}ring-based\nsem\\textbf{an}tic con\\textbf{s}ist\\textbf{e}ncy (\\textbf{Cleanse}). Cleanse\nquantifies the uncertainty with the proportion of the intra-cluster consistency\nin the total consistency between LLM hidden embeddings which contain adequate\nsemantic information of generations, by employing clustering. The effectiveness\nof Cleanse for detecting hallucination is validated using four off-the-shelf\nmodels, LLaMA-7B, LLaMA-13B, LLaMA2-7B and Mistral-7B and two\nquestion-answering benchmarks, SQuAD and CoQA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Cleanse \u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u6a21\u578b\u548c\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd NLP \u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u751f\u6210\u4e0d\u51c6\u786e\u54cd\u5e94\u7684\u95ee\u9898\uff08\u5373\u5e7b\u89c9\uff09\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u95ee\u9898\uff0c\u8fd9\u5f71\u54cd\u4e86\u6784\u5efa\u5b89\u5168\u53ef\u9760\u7684\u5927\u8bed\u8a00\u6a21\u578b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u548c\u91cf\u5316\u8fd9\u79cd\u5e7b\u89c9\u3002", "method": "Cleanse \u901a\u8fc7\u805a\u7c7b\u65b9\u6cd5\uff0c\u5229\u7528 LLM \u9690\u85cf\u5d4c\u5165\u4e2d\u5305\u542b\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u8ba1\u7b97\u7c07\u5185\u4e00\u81f4\u6027\u4e0e\u603b\u4e00\u81f4\u6027\u4e4b\u95f4\u7684\u6bd4\u4f8b\u6765\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3002", "result": "Cleanse \u5728\u56db\u4e2a\u73b0\u6210\u7684\u6a21\u578b\uff08LLaMA-7B\u3001LLaMA-13B\u3001LLaMA2-7B \u548c Mistral-7B\uff09\u4ee5\u53ca\u4e24\u4e2a\u95ee\u7b54\u57fa\u51c6\uff08SQuAD \u548c CoQA\uff09\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "Cleanse \u662f\u4e00\u79cd\u6709\u6548\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5730\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u3002"}}
{"id": "2507.14664", "pdf": "https://arxiv.org/pdf/2507.14664", "abs": "https://arxiv.org/abs/2507.14664", "authors": ["Wannaphong Phatthiyaphaibun", "Can Udomcharoenchaikit", "Pakpoom Singkorapoom", "Kunat Pipatanakul", "Ekapol Chuangsuwanich", "Peerat Limkonchotiwat", "Sarana Nutanong"], "title": "Mangosteen: An Open Thai Corpus for Language Model Pretraining", "categories": ["cs.CL"], "comment": "Work in Progress.All artifacts in this papers:\n  https://huggingface.co/collections/aisingapore/wangchanlion-v3-687a362d8f0ea2fe4077c6b3", "summary": "Pre-training data shapes a language model's quality, but raw web text is\nnoisy and demands careful cleaning. Existing large-scale corpora rely on\nEnglish-centric or language-agnostic pipelines whose heuristics do not capture\nThai script or cultural nuances, leaving risky material such as gambling\ncontent untreated. Prior Thai-specific efforts customize pipelines or build new\nones, yet seldom release their data or document design choices, hindering\nreproducibility and raising the question of how to construct a transparent,\nhigh-quality Thai corpus. We introduce Mangosteen: a 47 billion-token Thai\ncorpus built through a Thai-adapted Dolma pipeline that includes custom\nrule-based language ID, revised C4/Gopher quality filters, and Thai-trained\ncontent filters, plus curated non-web sources such as Wikipedia, Royal Gazette\ntexts, OCR-extracted books, and CC-licensed YouTube subtitles. Systematic\nablations using GPT-2 show the pipeline trims CommonCrawl from 202M to 25M\ndocuments while raising SEA-HELM NLG from 3 to 11; an 8B-parameter SEA-LION\nmodel continually pre-trained on Mangosteen then surpasses SEA-LION-v3 and\nLlama-3.1 by about four points on Thai benchmarks. We release the full pipeline\ncode, cleaning manifests, corpus snapshot, and all checkpoints, providing a\nfully reproducible foundation for future Thai and regional LLM research.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Mangosteen\uff0c\u8fd9\u662f\u4e00\u4e2a\u901a\u8fc7\u9002\u5e94\u6cf0\u8bed\u7684Dolma\u7ba1\u9053\u6784\u5efa\u7684470\u4ebf\u4e2a\u6807\u8bb0\u7684\u6cf0\u8bed\u8bed\u6599\u5e93\uff0c\u5305\u542b\u81ea\u5b9a\u4e49\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u8bed\u8a00ID\u3001\u4fee\u8ba2\u7684C4/Gopher\u8d28\u91cf\u8fc7\u6ee4\u5668\u548c\u6cf0\u8bed\u8bad\u7ec3\u7684\u5185\u5bb9\u8fc7\u6ee4\u5668\uff0c\u4ee5\u53ca\u7cbe\u5fc3\u6311\u9009\u7684\u975e\u7f51\u7edc\u6765\u6e90\u3002\u8be5\u8bed\u6599\u5e93\u5728\u6cf0\u8bed\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u53d1\u5e03\u4e86\u5b8c\u6574\u7684\u7ba1\u9053\u4ee3\u7801\u3001\u6e05\u6d17\u6e05\u5355\u3001\u8bed\u6599\u5e93\u5feb\u7167\u548c\u6240\u6709\u68c0\u67e5\u70b9\uff0c\u4e3a\u672a\u6765\u7684\u6cf0\u8bed\u548c\u5730\u533a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u63d0\u4f9b\u4e86\u5b8c\u5168\u53ef\u91cd\u590d\u7684\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u4f9d\u8d56\u4e8e\u4ee5\u82f1\u8bed\u4e3a\u4e2d\u5fc3\u6216\u8bed\u8a00\u65e0\u5173\u7684\u6d41\u7a0b\uff0c\u8fd9\u4e9b\u6d41\u7a0b\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u6cf0\u8bed\u811a\u672c\u6216\u6587\u5316\u7ec6\u5fae\u5dee\u522b\uff0c\u5bfc\u81f4\u8d4c\u535a\u5185\u5bb9\u7b49\u98ce\u9669\u6750\u6599\u672a\u88ab\u5904\u7406\u3002\u4e4b\u524d\u7684\u6cf0\u8bed\u7279\u5b9a\u52aa\u529b\u5b9a\u5236\u4e86\u6d41\u7a0b\u6216\u5efa\u7acb\u4e86\u65b0\u7684\u6d41\u7a0b\uff0c\u4f46\u5f88\u5c11\u53d1\u5e03\u4ed6\u4eec\u7684\u6570\u636e\u6216\u8bb0\u5f55\u8bbe\u8ba1\u9009\u62e9\uff0c\u963b\u788d\u4e86\u53ef\u91cd\u590d\u6027\uff0c\u5e76\u5f15\u53d1\u4e86\u5982\u4f55\u6784\u5efa\u900f\u660e\u3001\u9ad8\u8d28\u91cf\u7684\u6cf0\u8bed\u8bed\u6599\u5e93\u7684\u95ee\u9898\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86Mangosteen\uff1a\u4e00\u4e2a\u901a\u8fc7\u9002\u5e94\u6cf0\u8bed\u7684Dolma\u7ba1\u9053\u6784\u5efa\u7684470\u4ebf\u4e2a\u6807\u8bb0\u7684\u6cf0\u8bed\u8bed\u6599\u5e93\uff0c\u5305\u62ec\u81ea\u5b9a\u4e49\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u8bed\u8a00ID\u3001\u4fee\u8ba2\u7684C4/Gopher\u8d28\u91cf\u8fc7\u6ee4\u5668\u548c\u6cf0\u8bed\u8bad\u7ec3\u7684\u5185\u5bb9\u8fc7\u6ee4\u5668\uff0c\u4ee5\u53ca\u7cbe\u5fc3\u6311\u9009\u7684\u975e\u7f51\u7edc\u6765\u6e90\uff0c\u5982\u7ef4\u57fa\u767e\u79d1\u3001\u7687\u5bb6\u516c\u62a5\u6587\u672c\u3001OCR\u63d0\u53d6\u7684\u4e66\u7c4d\u548cCC\u6388\u6743\u7684YouTube\u5b57\u5e55\u3002", "result": "\u7cfb\u7edf\u6027\u6d88\u878d\u5b9e\u9a8c\u4f7f\u7528GPT-2\u663e\u793a\uff0c\u8be5\u6d41\u7a0b\u5c06CommonCrawl\u4ece202M\u51cf\u5c11\u523025M\u6587\u6863\uff0c\u540c\u65f6\u5c06SEA-HELM NLG\u4ece3\u63d0\u9ad8\u523011\uff1b\u4e00\u4e2a8B\u53c2\u6570\u7684SEA-LION\u6a21\u578b\u5728Mangosteen\u4e0a\u6301\u7eed\u9884\u8bad\u7ec3\u540e\uff0c\u5728\u6cf0\u8bed\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bd4SEA-LION-v3\u548cLlama-3.1\u9ad8\u51fa\u7ea6\u56db\u4e2a\u70b9\u3002", "conclusion": "\u6211\u4eec\u53d1\u5e03\u4e86\u5b8c\u6574\u7684\u7ba1\u9053\u4ee3\u7801\u3001\u6e05\u6d17\u6e05\u5355\u3001\u8bed\u6599\u5e93\u5feb\u7167\u548c\u6240\u6709\u68c0\u67e5\u70b9\uff0c\u4e3a\u672a\u6765\u7684\u6cf0\u8bed\u548c\u5730\u533a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u63d0\u4f9b\u4e86\u5b8c\u5168\u53ef\u91cd\u590d\u7684\u57fa\u7840\u3002"}}
{"id": "2507.14681", "pdf": "https://arxiv.org/pdf/2507.14681", "abs": "https://arxiv.org/abs/2507.14681", "authors": ["Vinicius Anjos de Almeida", "Vinicius de Camargo", "Raquel G\u00f3mez-Bravo", "Egbert van der Haring", "Kees van Boven", "Marcelo Finger", "Luis Fernandez Lopez"], "title": "Large Language Models as Medical Codes Selectors: a benchmark using the International Classification of Primary Care", "categories": ["cs.CL"], "comment": "To be submitted to peer-reviewed journal. 33 pages, 10 figures\n  (including appendix), 15 tables (including appendix). For associated code\n  repository, see https://github.com/almeidava93/llm-as-code-selectors-paper", "summary": "Background: Medical coding structures healthcare data for research, quality\nmonitoring, and policy. This study assesses the potential of large language\nmodels (LLMs) to assign ICPC-2 codes using the output of a domain-specific\nsearch engine.\n  Methods: A dataset of 437 Brazilian Portuguese clinical expressions, each\nannotated with ICPC-2 codes, was used. A semantic search engine (OpenAI's\ntext-embedding-3-large) retrieved candidates from 73,563 labeled concepts.\nThirty-three LLMs were prompted with each query and retrieved results to select\nthe best-matching ICPC-2 code. Performance was evaluated using F1-score, along\nwith token usage, cost, response time, and format adherence.\n  Results: Twenty-eight models achieved F1-score > 0.8; ten exceeded 0.85. Top\nperformers included gpt-4.5-preview, o3, and gemini-2.5-pro. Retriever\noptimization can improve performance by up to 4 points. Most models returned\nvalid codes in the expected format, with reduced hallucinations. Smaller models\n(<3B) struggled with formatting and input length.\n  Conclusions: LLMs show strong potential for automating ICPC-2 coding, even\nwithout fine-tuning. This work offers a benchmark and highlights challenges,\nbut findings are limited by dataset scope and setup. Broader, multilingual,\nend-to-end evaluations are needed for clinical validation.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4f7f\u7528\u9886\u57df\u7279\u5b9a\u641c\u7d22\u5f15\u64ce\u8f93\u51fa\u7684\u60c5\u51b5\u4e0b\u5206\u914dICPC-2\u4ee3\u7801\u7684\u6f5c\u529b\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8bb8\u591aLLM\u5728F1\u5206\u6570\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5c0f\u6a21\u578b\u5728\u683c\u5f0f\u548c\u8f93\u5165\u957f\u5ea6\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "motivation": "Medical coding structures healthcare data for research, quality monitoring, and policy. This study assesses the potential of large language models (LLMs) to assign ICPC-2 codes using the output of a domain-specific search engine.", "method": "A dataset of 437 Brazilian Portuguese clinical expressions, each annotated with ICPC-2 codes, was used. A semantic search engine (OpenAI's text-embedding-3-large) retrieved candidates from 73,563 labeled concepts. Thirty-three LLMs were prompted with each query and retrieved results to select the best-matching ICPC-2 code. Performance was evaluated using F1-score, along with token usage, cost, response time, and format adherence.", "result": "Twenty-eight models achieved F1-score > 0.8; ten exceeded 0.85. Top performers included gpt-4.5-preview, o3, and gemini-2.5-pro. Retriever optimization can improve performance by up to 4 points. Most models returned valid codes in the expected format, with reduced hallucinations. Smaller models (<3B) struggled with formatting and input length.", "conclusion": "LLMs show strong potential for automating ICPC-2 coding, even without fine-tuning. This work offers a benchmark and highlights challenges, but findings are limited by dataset scope and setup. Broader, multilingual, end-to-end evaluations are needed for clinical validation."}}
{"id": "2507.14683", "pdf": "https://arxiv.org/pdf/2507.14683", "abs": "https://arxiv.org/abs/2507.14683", "authors": ["Xingxuan Li", "Yao Xiao", "Dianwen Ng", "Hai Ye", "Yue Deng", "Xiang Lin", "Bin Wang", "Zhanfeng Mo", "Chong Zhang", "Yueyi Zhang", "Zonglin Yang", "Ruilin Li", "Lei Lei", "Shihao Xu", "Han Zhao", "Weiling Chen", "Feng Ji", "Lidong Bing"], "title": "MiroMind-M1: An Open-Source Advancement in Mathematical Reasoning via Context-Aware Multi-Stage Policy Optimization", "categories": ["cs.CL"], "comment": "Technical report", "summary": "Large language models have recently evolved from fluent text generation to\nadvanced reasoning across diverse domains, giving rise to reasoning language\nmodels. Among these domains, mathematical reasoning serves as a representative\nbenchmark as it requires precise multi-step logic and abstract reasoning, which\ncan be generalized to other tasks. While closed-source RLMs such as GPT-o3\ndemonstrate impressive reasoning capabilities, their proprietary nature limits\ntransparency and reproducibility. Although many open-source projects aim to\nclose this gap, most of them lack sufficient openness by omitting critical\nresources such as datasets and detailed training configurations, which hinders\nreproducibility. To contribute toward greater transparency in RLM development,\nwe introduce the MiroMind-M1 series, a set of fully open-source RLMs built on\nthe Qwen-2.5 backbone that match or exceed the performance of existing\nopen-source RLMs. Specifically, our models are trained in two stages: SFT on a\ncarefully curated corpus of 719K math-reasoning problems with verified CoT\ntrajectories, followed by RLVR on 62K challenging and verifiable problems. To\nenhance the robustness and efficiency of the RLVR process, we introduce\nContext-Aware Multi-Stage Policy Optimization, an algorithm that integrates\nlength-progressive training with an adaptive repetition penalty to encourage\ncontext-aware RL training. Our model achieves state-of-the-art or competitive\nperformance and superior token efficiency among Qwen-2.5-based open-source 7B\nand 32B models on the AIME24, AIME25, and MATH benchmarks. To facilitate\nreproducibility, we release the complete stack: models (MiroMind-M1-SFT-7B,\nMiroMind-M1-RL-7B, MiroMind-M1-RL-32B); datasets (MiroMind-M1-SFT-719K,\nMiroMind-M1-RL-62K); and all training and evaluation configurations. We hope\nthese resources will support further research and foster community advancement.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86MiroMind-M1\u7cfb\u5217\uff0c\u8fd9\u662f\u4e00\u4e2a\u5b8c\u5168\u5f00\u6e90\u7684\u63a8\u7406\u8bed\u8a00\u6a21\u578b\uff0c\u5176\u6027\u80fd\u53ef\u4ee5\u4e0e\u73b0\u6709\u7684\u5f00\u6e90RLM\u76f8\u5ab2\u7f8e\u6216\u8d85\u8d8a\u3002\u4e3a\u4e86\u63d0\u9ad8\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u590d\u6027\uff0c\u4f5c\u8005\u91ca\u653e\u4e86\u5b8c\u6574\u7684\u5806\u6808\uff0c\u5305\u62ec\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u6240\u6709\u8bad\u7ec3\u53ca\u8bc4\u4f30\u914d\u7f6e\u3002", "motivation": "\u5c3d\u7ba1\u95ed\u6e90\u7684RLM\u5982GPT-o3\u5c55\u793a\u4e86\u51fa\u8272\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u7684\u4e13\u6709\u6027\u8d28\u9650\u5236\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u590d\u6027\u3002\u867d\u7136\u8bb8\u591a\u5f00\u6e90\u9879\u76ee\u65e8\u5728\u7f29\u5c0f\u8fd9\u4e00\u5dee\u8ddd\uff0c\u4f46\u5927\u591a\u6570\u9879\u76ee\u7f3a\u4e4f\u8db3\u591f\u7684\u5f00\u653e\u6027\uff0c\u56e0\u4e3a\u5b83\u4eec\u7701\u7565\u4e86\u5173\u952e\u8d44\u6e90\uff0c\u5982\u6570\u636e\u96c6\u548c\u8be6\u7ec6\u7684\u8bad\u7ec3\u914d\u7f6e\uff0c\u8fd9\u963b\u788d\u4e86\u53ef\u91cd\u590d\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aContext-Aware Multi-Stage Policy Optimization\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u7ed3\u5408\u4e86\u957f\u5ea6\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u548c\u81ea\u9002\u5e94\u91cd\u590d\u60e9\u7f5a\uff0c\u4ee5\u9f13\u52b1\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002\u6b64\u5916\uff0c\u6a21\u578b\u5728\u4e24\u4e2a\u9636\u6bb5\u8fdb\u884c\u8bad\u7ec3\uff1a\u9996\u5148\u662f\u5728\u4e00\u4e2a\u7cbe\u5fc3\u6311\u9009\u7684719K\u6570\u5b66\u63a8\u7406\u95ee\u9898\u8bed\u6599\u5e93\u4e0a\u8fdb\u884cSFT\uff0c\u7136\u540e\u662f\u572862K\u5177\u6709\u6311\u6218\u6027\u548c\u53ef\u9a8c\u8bc1\u7684\u95ee\u9898\u4e0a\u8fdb\u884cRLVR\u3002", "result": "MiroMind-M1\u7cfb\u5217\u5728AIME24\u3001AIME25\u548cMATH\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e0e\u57fa\u4e8eQwen-2.5\u7684\u5f00\u6e907B\u548c32B\u6a21\u578b\u76f8\u6bd4\uff0c\u5177\u6709\u6700\u5148\u8fdb\u7684\u6027\u80fd\u548c\u4f18\u8d8a\u7684token\u6548\u7387\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86MiroMind-M1\u7cfb\u5217\uff0c\u8fd9\u662f\u4e00\u4e2a\u5b8c\u5168\u5f00\u6e90\u7684\u63a8\u7406\u8bed\u8a00\u6a21\u578b\uff0c\u5176\u6027\u80fd\u53ef\u4ee5\u4e0e\u73b0\u6709\u7684\u5f00\u6e90RLM\u76f8\u5ab2\u7f8e\u6216\u8d85\u8d8a\u3002\u4e3a\u4e86\u63d0\u9ad8\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u590d\u6027\uff0c\u4f5c\u8005\u91ca\u653e\u4e86\u5b8c\u6574\u7684\u5806\u6808\uff0c\u5305\u62ec\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u6240\u6709\u8bad\u7ec3\u53ca\u8bc4\u4f30\u914d\u7f6e\u3002"}}
{"id": "2507.14688", "pdf": "https://arxiv.org/pdf/2507.14688", "abs": "https://arxiv.org/abs/2507.14688", "authors": ["Mohammed Alkhowaiter", "Norah Alshahrani", "Saied Alshahrani", "Reem I. Masoud", "Alaa Alzahrani", "Deema Alnuhait", "Emad A. Alghamdi", "Khalid Almubarak"], "title": "Mind the Gap: A Review of Arabic Post-Training Datasets and Their Limitations", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Post-training has emerged as a crucial technique for aligning pre-trained\nLarge Language Models (LLMs) with human instructions, significantly enhancing\ntheir performance across a wide range of tasks. Central to this process is the\nquality and diversity of post-training datasets. This paper presents a review\nof publicly available Arabic post-training datasets on the Hugging Face Hub,\norganized along four key dimensions: (1) LLM Capabilities (e.g., Question\nAnswering, Translation, Reasoning, Summarization, Dialogue, Code Generation,\nand Function Calling); (2) Steerability (e.g., persona and system prompts); (3)\nAlignment (e.g., cultural, safety, ethics, and fairness), and (4) Robustness.\nEach dataset is rigorously evaluated based on popularity, practical adoption,\nrecency and maintenance, documentation and annotation quality, licensing\ntransparency, and scientific contribution. Our review revealed critical gaps in\nthe development of Arabic post-training datasets, including limited task\ndiversity, inconsistent or missing documentation and annotation, and low\nadoption across the community. Finally, the paper discusses the implications of\nthese gaps on the progress of Arabic LLMs and applications while providing\nconcrete recommendations for future efforts in post-training dataset\ndevelopment.", "AI": {"tldr": "\u672c\u6587\u5bf9Hugging Face Hub\u4e0a\u7684\u963f\u62c9\u4f2f\u8bed\u540e\u8bad\u7ec3\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u7efc\u8ff0\uff0c\u5206\u6790\u4e86\u5176\u5728\u4efb\u52a1\u591a\u6837\u6027\u3001\u6587\u6863\u8d28\u91cf\u3001\u793e\u533a\u91c7\u7528\u7b49\u65b9\u9762\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u540e\u8bad\u7ec3\u662f\u5c06\u9884\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u6307\u4ee4\u5bf9\u9f50\u7684\u5173\u952e\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5b83\u4eec\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002\u7136\u800c\uff0c\u963f\u62c9\u4f2f\u8bed\u540e\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u53d1\u5c55\u5b58\u5728\u4e00\u4e9b\u5173\u952e\u5dee\u8ddd\uff0c\u5982\u4efb\u52a1\u591a\u6837\u6027\u6709\u9650\u3001\u6587\u6863\u548c\u6ce8\u91ca\u4e0d\u4e00\u81f4\u6216\u7f3a\u5931\u4ee5\u53ca\u793e\u533a\u91c7\u7528\u7387\u4f4e\u3002\u672c\u6587\u65e8\u5728\u5206\u6790\u8fd9\u4e9b\u5dee\u8ddd\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "method": "\u672c\u6587\u5bf9Hugging Face Hub\u4e0a\u516c\u5f00\u7684\u963f\u62c9\u4f2f\u8bed\u540e\u8bad\u7ec3\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u7efc\u8ff0\uff0c\u4ece\u56db\u4e2a\u5173\u952e\u7ef4\u5ea6\u8fdb\u884c\u7ec4\u7ec7\uff1a(1) \u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u529b\uff1b(2) \u53ef\u64cd\u63a7\u6027\uff1b(3) \u5bf9\u9f50\uff1b(4) \u9c81\u68d2\u6027\u3002\u6bcf\u4e2a\u6570\u636e\u96c6\u90fd\u6839\u636e\u6d41\u884c\u5ea6\u3001\u5b9e\u9645\u91c7\u7528\u60c5\u51b5\u3001\u65b0\u9896\u6027\u548c\u7ef4\u62a4\u60c5\u51b5\u3001\u6587\u6863\u548c\u6ce8\u91ca\u8d28\u91cf\u3001\u8bb8\u53ef\u900f\u660e\u5ea6\u4ee5\u53ca\u79d1\u5b66\u8d21\u732e\u8fdb\u884c\u4e86\u4e25\u683c\u8bc4\u4f30\u3002", "result": "\u672c\u6587\u53d1\u73b0\u963f\u62c9\u4f2f\u8bed\u540e\u8bad\u7ec3\u6570\u636e\u96c6\u5b58\u5728\u5173\u952e\u5dee\u8ddd\uff0c\u5305\u62ec\u4efb\u52a1\u591a\u6837\u6027\u6709\u9650\u3001\u6587\u6863\u548c\u6ce8\u91ca\u4e0d\u4e00\u81f4\u6216\u7f3a\u5931\u4ee5\u53ca\u793e\u533a\u91c7\u7528\u7387\u4f4e\u3002", "conclusion": "\u672c\u6587\u8ba8\u8bba\u4e86\u8fd9\u4e9b\u5dee\u8ddd\u5bf9\u963f\u62c9\u4f2f\u8bed\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u5e94\u7528\u8fdb\u5c55\u7684\u5f71\u54cd\uff0c\u5e76\u4e3a\u672a\u6765\u540e\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u5efa\u8bae\u3002"}}
{"id": "2507.14693", "pdf": "https://arxiv.org/pdf/2507.14693", "abs": "https://arxiv.org/abs/2507.14693", "authors": ["Amina Dzafic", "Merve Kavut", "Ulya Bayram"], "title": "Rethinking Suicidal Ideation Detection: A Trustworthy Annotation Framework and Cross-Lingual Model Evaluation", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "comment": "This manuscript has been submitted to the IEEE Journal of Biomedical\n  and Health Informatics", "summary": "Suicidal ideation detection is critical for real-time suicide prevention, yet\nits progress faces two under-explored challenges: limited language coverage and\nunreliable annotation practices. Most available datasets are in English, but\neven among these, high-quality, human-annotated data remains scarce. As a\nresult, many studies rely on available pre-labeled datasets without examining\ntheir annotation process or label reliability. The lack of datasets in other\nlanguages further limits the global realization of suicide prevention via\nartificial intelligence (AI). In this study, we address one of these gaps by\nconstructing a novel Turkish suicidal ideation corpus derived from social media\nposts and introducing a resource-efficient annotation framework involving three\nhuman annotators and two large language models (LLMs). We then address the\nremaining gaps by performing a bidirectional evaluation of label reliability\nand model consistency across this dataset and three popular English suicidal\nideation detection datasets, using transfer learning through eight pre-trained\nsentiment and emotion classifiers. These transformers help assess annotation\nconsistency and benchmark model performance against manually labeled data. Our\nfindings underscore the need for more rigorous, language-inclusive approaches\nto annotation and evaluation in mental health natural language processing (NLP)\nwhile demonstrating the questionable performance of popular models with\nzero-shot transfer learning. We advocate for transparency in model training and\ndataset construction in mental health NLP, prioritizing data and model\nreliability.", "AI": {"tldr": "\u672c\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u571f\u8033\u5176\u81ea\u6740\u610f\u5ff5\u8bed\u6599\u5e93\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u8d44\u6e90\u9ad8\u6548\u7684\u6ce8\u91ca\u6846\u67b6\u3002\u901a\u8fc7\u4f7f\u7528\u516b\u79cd\u9884\u8bad\u7ec3\u7684\u60c5\u611f\u548c\u60c5\u7eea\u5206\u7c7b\u5668\u8fdb\u884c\u53cc\u5411\u8bc4\u4f30\uff0c\u53d1\u73b0\u73b0\u6709\u6d41\u884c\u6a21\u578b\u5728\u96f6\u6837\u672c\u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\u5b58\u5728\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u5728\u5fc3\u7406\u5065\u5eb7NLP\u4e2d\u9700\u8981\u66f4\u52a0\u4e25\u8c28\u3001\u8bed\u8a00\u5305\u5bb9\u7684\u6ce8\u91ca\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u76ee\u524d\u53ef\u7528\u7684\u6570\u636e\u96c6\u5927\u591a\u4e3a\u82f1\u8bed\uff0c\u4f46\u5373\u4f7f\u5728\u8fd9\u4e9b\u6570\u636e\u96c6\u4e2d\uff0c\u9ad8\u8d28\u91cf\u7684\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u4ecd\u7136\u7a00\u7f3a\u3002\u8bb8\u591a\u7814\u7a76\u4f9d\u8d56\u4e8e\u73b0\u6709\u7684\u9884\u6807\u8bb0\u6570\u636e\u96c6\uff0c\u800c\u6ca1\u6709\u68c0\u67e5\u5176\u6ce8\u91ca\u8fc7\u7a0b\u6216\u6807\u7b7e\u53ef\u9760\u6027\u3002\u5176\u4ed6\u8bed\u8a00\u7684\u6570\u636e\u96c6\u7f3a\u4e4f\u8fdb\u4e00\u6b65\u9650\u5236\u4e86\u901a\u8fc7\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u5b9e\u73b0\u5168\u7403\u81ea\u6740\u9884\u9632\u7684\u53ef\u80fd\u6027\u3002", "method": "\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u4ece\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u4e2d\u5f97\u51fa\u7684\u65b0\u578b\u571f\u8033\u5176\u81ea\u6740\u610f\u5ff5\u8bed\u6599\u5e93\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u6d89\u53ca\u4e09\u4e2a\u4eba\u7c7b\u6ce8\u91ca\u8005\u548c\u4e24\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8d44\u6e90\u9ad8\u6548\u7684\u6ce8\u91ca\u6846\u67b6\u3002\u7136\u540e\uff0c\u6211\u4eec\u901a\u8fc7\u516b\u79cd\u9884\u8bad\u7ec3\u7684\u60c5\u611f\u548c\u60c5\u7eea\u5206\u7c7b\u5668\u8fdb\u884c\u53cc\u5411\u8bc4\u4f30\uff0c\u4ee5\u68c0\u67e5\u6807\u7b7e\u4e00\u81f4\u6027\u548c\u6a21\u578b\u6027\u80fd\u3002", "result": "\u6211\u4eec\u7684\u7814\u7a76\u53d1\u73b0\uff0c\u73b0\u6709\u6d41\u884c\u6a21\u578b\u5728\u96f6\u6837\u672c\u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\u5b58\u5728\u95ee\u9898\u3002\u540c\u65f6\uff0c\u6211\u4eec\u5f3a\u8c03\u4e86\u5728\u5fc3\u7406\u5065\u5eb7NLP\u4e2d\u9700\u8981\u66f4\u52a0\u4e25\u8c28\u3001\u8bed\u8a00\u5305\u5bb9\u7684\u6ce8\u91ca\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u5fc3\u7406\u5065\u5eb7\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u4e2d\u9700\u8981\u66f4\u52a0\u4e25\u8c28\u3001\u8bed\u8a00\u5305\u5bb9\u7684\u6ce8\u91ca\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u6d41\u884c\u6a21\u578b\u5728\u96f6\u6837\u672c\u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u53ef\u7591\u8868\u73b0\u3002\u6211\u4eec\u5021\u5bfc\u5728\u5fc3\u7406\u5065\u5eb7NLP\u4e2d\u5bf9\u6a21\u578b\u8bad\u7ec3\u548c\u6570\u636e\u96c6\u6784\u5efa\u4fdd\u6301\u900f\u660e\u5ea6\uff0c\u4f18\u5148\u8003\u8651\u6570\u636e\u548c\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.14741", "pdf": "https://arxiv.org/pdf/2507.14741", "abs": "https://arxiv.org/abs/2507.14741", "authors": ["Maria Sahakyan", "Bedoor AlShebli"], "title": "Disparities in Peer Review Tone and the Role of Reviewer Anonymity", "categories": ["cs.CL"], "comment": null, "summary": "The peer review process is often regarded as the gatekeeper of scientific\nintegrity, yet increasing evidence suggests that it is not immune to bias.\nAlthough structural inequities in peer review have been widely debated, much\nless attention has been paid to the subtle ways in which language itself may\nreinforce disparities. This study undertakes one of the most comprehensive\nlinguistic analyses of peer review to date, examining more than 80,000 reviews\nin two major journals. Using natural language processing and large-scale\nstatistical modeling, it uncovers how review tone, sentiment, and supportive\nlanguage vary across author demographics, including gender, race, and\ninstitutional affiliation. Using a data set that includes both anonymous and\nsigned reviews, this research also reveals how the disclosure of reviewer\nidentity shapes the language of evaluation. The findings not only expose hidden\nbiases in peer feedback, but also challenge conventional assumptions about\nanonymity's role in fairness. As academic publishing grapples with reform,\nthese insights raise critical questions about how review policies shape career\ntrajectories and scientific progress.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790\u5927\u91cf\u540c\u884c\u8bc4\u5ba1\u6570\u636e\uff0c\u63ed\u793a\u4e86\u8bed\u8a00\u5728\u8bc4\u5ba1\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u52a0\u5267\u4e0d\u5e73\u7b49\u7684\u73b0\u8c61\uff0c\u5e76\u6311\u6218\u4e86\u533f\u540d\u6027\u5bf9\u516c\u5e73\u6027\u7684\u4f20\u7edf\u770b\u6cd5\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u8bed\u8a00\u5982\u4f55\u5728\u540c\u884c\u8bc4\u5ba1\u4e2d\u5f3a\u5316\u4e0d\u5e73\u7b49\u73b0\u8c61\uff0c\u5c24\u5176\u662f\u5728\u7ed3\u6784\u4e0d\u5e73\u7b49\u95ee\u9898\u88ab\u5e7f\u6cdb\u8ba8\u8bba\u7684\u60c5\u51b5\u4e0b\uff0c\u5173\u6ce8\u8bed\u8a00\u7684\u7ec6\u5fae\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5927\u89c4\u6a21\u7edf\u8ba1\u5efa\u6a21\uff0c\u5206\u6790\u4e86\u8d85\u8fc780,000\u4efd\u540c\u884c\u8bc4\u5ba1\u610f\u89c1\uff0c\u63a2\u8ba8\u4e86\u8bc4\u5ba1\u8bed\u6c14\u3001\u60c5\u611f\u548c\u652f\u6301\u6027\u8bed\u8a00\u5728\u4f5c\u8005\u4eba\u53e3\u7edf\u8ba1\u5b66\u7279\u5f81\u4e0a\u7684\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8bc4\u5ba1\u8bed\u6c14\u3001\u60c5\u611f\u548c\u652f\u6301\u6027\u8bed\u8a00\u5728\u4f5c\u8005\u6027\u522b\u3001\u79cd\u65cf\u548c\u673a\u6784\u96b6\u5c5e\u5173\u7cfb\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u5e76\u63ed\u793a\u4e86\u8bc4\u5ba1\u8005\u8eab\u4efd\u62ab\u9732\u5982\u4f55\u5f71\u54cd\u8bc4\u4f30\u8bed\u8a00\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u9690\u6027\u504f\u89c1\uff0c\u5e76\u6311\u6218\u4e86\u533f\u540d\u6027\u5728\u516c\u5e73\u6027\u4e2d\u7684\u4f5c\u7528\u7684\u5e38\u89c4\u5047\u8bbe\u3002\u8fd9\u4e9b\u89c1\u89e3\u5f15\u53d1\u4e86\u5173\u4e8e\u8bc4\u5ba1\u653f\u7b56\u5982\u4f55\u5851\u9020\u804c\u4e1a\u8f68\u8ff9\u548c\u79d1\u5b66\u8fdb\u5c55\u7684\u91cd\u8981\u95ee\u9898\u3002"}}
{"id": "2507.14749", "pdf": "https://arxiv.org/pdf/2507.14749", "abs": "https://arxiv.org/abs/2507.14749", "authors": ["Wai Keen Vong", "Brenden M. Lake"], "title": "On the robustness of modeling grounded word learning through a child's egocentric input", "categories": ["cs.CL"], "comment": null, "summary": "What insights can machine learning bring to understanding human language\nacquisition? Large language and multimodal models have achieved remarkable\ncapabilities, but their reliance on massive training datasets creates a\nfundamental mismatch with children, who succeed in acquiring language from\ncomparatively limited input. To help bridge this gap, researchers have\nincreasingly trained neural networks using data similar in quantity and quality\nto children's input. Taking this approach to the limit, Vong et al. (2024)\nshowed that a multimodal neural network trained on 61 hours of visual and\nlinguistic input extracted from just one child's developmental experience could\nacquire word-referent mappings. However, whether this approach's success\nreflects the idiosyncrasies of a single child's experience, or whether it would\nshow consistent and robust learning patterns across multiple children's\nexperiences was not explored. In this article, we applied automated speech\ntranscription methods to the entirety of the SAYCam dataset, consisting of over\n500 hours of video data spread across all three children. Using these automated\ntranscriptions, we generated multi-modal vision-and-language datasets for both\ntraining and evaluation, and explored a range of neural network configurations\nto examine the robustness of simulated word learning. Our findings demonstrate\nthat networks trained on automatically transcribed data from each child can\nacquire and generalize word-referent mappings across multiple network\narchitectures. These results validate the robustness of multimodal neural\nnetworks for grounded word learning, while highlighting the individual\ndifferences that emerge in how models learn when trained on each child's\ndevelopmental experiences.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u591a\u6a21\u6001\u795e\u7ecf\u7f51\u7edc\u5728\u57fa\u4e8e\u513f\u7ae5\u6709\u9650\u8f93\u5165\u7684\u8bed\u8a00\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5b83\u4eec\u80fd\u591f\u6210\u529f\u5730\u5b66\u4e60\u548c\u6cdb\u5316\u5355\u8bcd-\u53c2\u7167\u6620\u5c04\uff0c\u4f46\u4e0d\u540c\u5b69\u5b50\u4e4b\u95f4\u7684\u5b66\u4e60\u65b9\u5f0f\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u4e3a\u4e86\u5f25\u5408\u5927\u578b\u8bed\u8a00\u548c\u591a\u6a21\u6001\u6a21\u578b\u4e0e\u513f\u7ae5\u5728\u8bed\u8a00\u4e60\u5f97\u4e0a\u7684\u5dee\u8ddd\uff0c\u7814\u7a76\u4eba\u5458\u5f00\u59cb\u4f7f\u7528\u7c7b\u4f3c\u4e8e\u513f\u7ae5\u8f93\u5165\u7684\u6570\u636e\u91cf\u548c\u8d28\u91cf\u6765\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u505a\u6cd5\u7684\u6210\u529f\u662f\u5426\u53cd\u6620\u4e86\u5355\u4e2a\u5b69\u5b50\u7684\u72ec\u7279\u7ecf\u9a8c\uff0c\u8fd8\u662f\u5728\u591a\u4e2a\u5b69\u5b50\u7684\u7ecf\u9a8c\u4e2d\u8868\u73b0\u51fa\u4e00\u81f4\u548c\u7a33\u5065\u7684\u5b66\u4e60\u6a21\u5f0f\u4ecd\u672a\u88ab\u63a2\u8ba8\u3002", "method": "\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u81ea\u52a8\u8bed\u97f3\u8f6c\u5f55\u65b9\u6cd5\u5904\u7406\u4e86SAYCam\u6570\u636e\u96c6\u7684\u5168\u90e8\u5185\u5bb9\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u4e09\u4e2a\u5b69\u5b50\u8d85\u8fc7500\u5c0f\u65f6\u7684\u89c6\u9891\u6570\u636e\u3002\u5229\u7528\u8fd9\u4e9b\u81ea\u52a8\u8f6c\u5f55\u6587\u672c\uff0c\u4ed6\u4eec\u751f\u6210\u4e86\u591a\u6a21\u6001\u89c6\u89c9\u548c\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u5e76\u63a2\u7d22\u4e86\u4e00\u7cfb\u5217\u795e\u7ecf\u7f51\u7edc\u914d\u7f6e\u4ee5\u68c0\u67e5\u6a21\u62df\u5355\u8bcd\u5b66\u4e60\u7684\u7a33\u5065\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u6bcf\u4e2a\u5b69\u5b50\u7684\u81ea\u52a8\u8f6c\u5f55\u6570\u636e\u8bad\u7ec3\u7684\u7f51\u7edc\u53ef\u4ee5\u8de8\u591a\u79cd\u7f51\u7edc\u67b6\u6784\u83b7\u53d6\u548c\u6cdb\u5316\u5355\u8bcd-\u53c2\u7167\u6620\u5c04\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u9a8c\u8bc1\u4e86\u591a\u6a21\u6001\u795e\u7ecf\u7f51\u7edc\u5728\u57fa\u4e8e\u73b0\u5b9e\u8bed\u8a00\u5b66\u4e60\u4e2d\u7684\u7a33\u5065\u6027\uff0c\u540c\u65f6\u7a81\u663e\u4e86\u5f53\u6a21\u578b\u5728\u6bcf\u4e2a\u5b69\u5b50\u7684\u53d1\u80b2\u7ecf\u9a8c\u4e0a\u8bad\u7ec3\u65f6\uff0c\u5b66\u4e60\u65b9\u5f0f\u4e2d\u51fa\u73b0\u7684\u4e2a\u4f53\u5dee\u5f02\u3002"}}
{"id": "2507.14758", "pdf": "https://arxiv.org/pdf/2507.14758", "abs": "https://arxiv.org/abs/2507.14758", "authors": ["Luyi Ma", "Wanjia Zhang", "Kai Zhao", "Abhishek Kulkarni", "Lalitesh Morishetti", "Anjana Ganesh", "Ashish Ranjan", "Aashika Padmanabhan", "Jianpeng Xu", "Jason Cho", "Praveen Kanumala", "Kaushiki Nag", "Sumit Dutta", "Kamiya Motwani", "Malay Patel", "Evren Korpeoglu", "Sushant Kumar", "Kannan Achan"], "title": "GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought Tokenization", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "10 pages, 5 figures, The ACM Conference on Recommender Systems\n  (RecSys) 2025", "summary": "Generative models have recently demonstrated strong potential in\nmulti-behavior recommendation systems, leveraging the expressive power of\ntransformers and tokenization to generate personalized item sequences. However,\ntheir adoption is hindered by (1) the lack of explicit information for token\nreasoning, (2) high computational costs due to quadratic attention complexity\nand dense sequence representations after tokenization, and (3) limited\nmulti-scale modeling over user history. In this work, we propose GRACE\n(Generative Recommendation via journey-aware sparse Attention on\nChain-of-thought tokEnization), a novel generative framework for multi-behavior\nsequential recommendation. GRACE introduces a hybrid Chain-of-Thought (CoT)\ntokenization method that encodes user-item interactions with explicit\nattributes from product knowledge graphs (e.g., category, brand, price) over\nsemantic tokenization, enabling interpretable and behavior-aligned generation.\nTo address the inefficiency of standard attention, we design a Journey-Aware\nSparse Attention (JSA) mechanism, which selectively attends to compressed,\nintra-, inter-, and current-context segments in the tokenized sequence.\nExperiments on two real-world datasets show that GRACE significantly\noutperforms state-of-the-art baselines, achieving up to +106.9% HR@10 and\n+106.7% NDCG@10 improvement over the state-of-the-art baseline on the Home\ndomain, and +22.1% HR@10 on the Electronics domain. GRACE also reduces\nattention computation by up to 48% with long sequences.", "AI": {"tldr": "GRACE is a new generative framework for multi-behavior sequential recommendation that improves performance and reduces computational costs.", "motivation": "The motivation is to overcome the limitations of existing generative models in multi-behavior recommendation systems, such as the lack of explicit information for token reasoning, high computational costs, and limited multi-scale modeling over user history.", "method": "GRACE introduces a hybrid Chain-of-Thought (CoT) tokenization method and a Journey-Aware Sparse Attention (JSA) mechanism to address the limitations of existing generative models in multi-behavior recommendation systems.", "result": "Experiments on two real-world datasets show that GRACE significantly outperforms state-of-the-art baselines, achieving up to +106.9% HR@10 and +106.7% NDCG@10 improvement over the state-of-the-art baseline on the Home domain, and +22.1% HR@10 on the Electronics domain. GRACE also reduces attention computation by up to 48% with long sequences.", "conclusion": "GRACE is a novel generative framework for multi-behavior sequential recommendation that significantly outperforms state-of-the-art baselines and reduces attention computation."}}
{"id": "2507.14815", "pdf": "https://arxiv.org/pdf/2507.14815", "abs": "https://arxiv.org/abs/2507.14815", "authors": ["Shoutao Guo", "Shaolei Zhang", "Qingkai Fang", "Zhengrui Ma", "Min Zhang", "Yang Feng"], "title": "FastLongSpeech: Enhancing Large Speech-Language Models for Efficient Long-Speech Processing", "categories": ["cs.CL"], "comment": "The code is at https://github.com/ictnlp/FastLongSpeech. This model\n  is at https://huggingface.co/ICTNLP/FastLongSpeech. The dataset is at\n  https://huggingface.co/datasets/ICTNLP/LongSpeech-Eval", "summary": "The rapid advancement of Large Language Models (LLMs) has spurred significant\nprogress in Large Speech-Language Models (LSLMs), enhancing their capabilities\nin both speech understanding and generation. While existing LSLMs often\nconcentrate on augmenting speech generation or tackling a diverse array of\nshort-speech tasks, the efficient processing of long-form speech remains a\ncritical yet underexplored challenge. This gap is primarily attributed to the\nscarcity of long-speech training datasets and the high computational costs\nassociated with long sequences. To address these limitations, we introduce\nFastLongSpeech, a novel framework designed to extend LSLM capabilities for\nefficient long-speech processing without necessitating dedicated long-speech\ntraining data. FastLongSpeech incorporates an iterative fusion strategy that\ncan compress excessively long-speech sequences into manageable lengths. To\nadapt LSLMs for long-speech inputs, it introduces a dynamic compression\ntraining approach, which exposes the model to short-speech sequences at varying\ncompression ratios, thereby transferring the capabilities of LSLMs to\nlong-speech tasks. To assess the long-speech capabilities of LSLMs, we develop\na long-speech understanding benchmark called LongSpeech-Eval. Experiments show\nthat our method exhibits strong performance in both long-speech and\nshort-speech tasks, while greatly improving inference efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFastLongSpeech\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u5927\u578b\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u5904\u7406\u957f\u8bed\u97f3\u7684\u80fd\u529b\uff0c\u65e0\u9700\u4e13\u95e8\u7684\u957f\u8bed\u97f3\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u73b0\u6709LSLM\u4e3b\u8981\u5173\u6ce8\u8bed\u97f3\u751f\u6210\u6216\u5404\u79cd\u77ed\u8bed\u97f3\u4efb\u52a1\uff0c\u800c\u957f\u8bed\u97f3\u5904\u7406\u4ecd\u662f\u4e00\u4e2a\u5173\u952e\u4f46\u7814\u7a76\u4e0d\u8db3\u7684\u6311\u6218\uff0c\u4e3b\u8981\u662f\u7531\u4e8e\u7f3a\u4e4f\u957f\u8bed\u97f3\u8bad\u7ec3\u6570\u636e\u548c\u957f\u5e8f\u5217\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u3002", "method": "FastLongSpeech\u5f15\u5165\u4e86\u4e00\u79cd\u8fed\u4ee3\u878d\u5408\u7b56\u7565\uff0c\u5c06\u8fc7\u957f\u7684\u8bed\u97f3\u5e8f\u5217\u538b\u7f29\u5230\u53ef\u7ba1\u7406\u7684\u957f\u5ea6\uff0c\u5e76\u91c7\u7528\u52a8\u6001\u538b\u7f29\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5728\u4e0d\u540c\u538b\u7f29\u6bd4\u4f8b\u4e0b\u5b66\u4e60\u77ed\u8bed\u97f3\u5e8f\u5217\uff0c\u4ece\u800c\u5c06LSLM\u7684\u80fd\u529b\u8f6c\u79fb\u5230\u957f\u8bed\u97f3\u4efb\u52a1\u4e0a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u957f\u8bed\u97f3\u548c\u77ed\u8bed\u97f3\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u3002", "conclusion": "FastLongSpeech\u80fd\u591f\u6709\u6548\u63d0\u5347\u957f\u8bed\u97f3\u5904\u7406\u7684\u6548\u7387\uff0c\u5e76\u5728\u957f\u8bed\u97f3\u548c\u77ed\u8bed\u97f3\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.14819", "pdf": "https://arxiv.org/pdf/2507.14819", "abs": "https://arxiv.org/abs/2507.14819", "authors": ["Akriti Jain", "Pritika Ramu", "Aparna Garimella", "Apoorv Saxena"], "title": "Doc2Chart: Intent-Driven Zero-Shot Chart Generation from Documents", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in\ntransforming text descriptions or tables to data visualizations via\ninstruction-tuning methods. However, it is not straightforward to apply these\nmethods directly for a more real-world use case of visualizing data from long\ndocuments based on user-given intents, as opposed to the user pre-selecting the\nrelevant content manually. We introduce the task of intent-based chart\ngeneration from documents: given a user-specified intent and document(s), the\ngoal is to generate a chart adhering to the intent and grounded on the\ndocument(s) in a zero-shot setting. We propose an unsupervised, two-staged\nframework in which an LLM first extracts relevant information from the\ndocument(s) by decomposing the intent and iteratively validates and refines\nthis data. Next, a heuristic-guided module selects an appropriate chart type\nbefore final code generation. To assess the data accuracy of the generated\ncharts, we propose an attribution-based metric that uses a structured textual\nrepresentation of charts, instead of relying on visual decoding metrics that\noften fail to capture the chart data effectively. To validate our approach, we\ncurate a dataset comprising of 1,242 $<$intent, document, charts$>$ tuples from\ntwo domains, finance and scientific, in contrast to the existing datasets that\nare largely limited to parallel text descriptions/ tables and their\ncorresponding charts. We compare our approach with baselines using single-shot\nchart generation using LLMs and query-based retrieval methods; our method\noutperforms by upto $9$ points and $17$ points in terms of chart data accuracy\nand chart type respectively over the best baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u610f\u56fe\u7684\u56fe\u8868\u751f\u6210\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u4ece\u6587\u6863\u4e2d\u751f\u6210\u7b26\u5408\u7528\u6237\u610f\u56fe\u7684\u56fe\u8868\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e00\u4e2a\u65e0\u76d1\u7763\u7684\u4e24\u9636\u6bb5\u6846\u67b6\u5b9e\u73b0\uff0c\u5305\u62ec\u4fe1\u606f\u63d0\u53d6\u548c\u56fe\u8868\u7c7b\u578b\u9009\u62e9\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u56fe\u8868\u6570\u636e\u51c6\u786e\u6027\u548c\u56fe\u8868\u7c7b\u578b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u7528\u6237\u624b\u52a8\u9009\u62e9\u76f8\u5173\u5185\u5bb9\uff0c\u800c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u4ece\u957f\u6587\u6863\u4e2d\u6839\u636e\u7528\u6237\u610f\u56fe\u751f\u6210\u56fe\u8868\u7684\u95ee\u9898\uff0c\u8fd9\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u4e3a\u5e38\u89c1\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5176\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9996\u5148\u901a\u8fc7\u5206\u89e3\u610f\u56fe\u5e76\u8fed\u4ee3\u9a8c\u8bc1\u548c\u7cbe\u70bc\u6570\u636e\u6765\u4ece\u6587\u6863\u4e2d\u63d0\u53d6\u76f8\u5173\u4fe1\u606f\u3002\u7136\u540e\uff0c\u4e00\u4e2a\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u6a21\u5757\u9009\u62e9\u9002\u5f53\u7684\u56fe\u8868\u7c7b\u578b\u5e76\u751f\u6210\u6700\u7ec8\u4ee3\u7801\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5c5e\u6027\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u751f\u6210\u56fe\u8868\u7684\u6570\u636e\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b1,242\u4e2a<\u610f\u56fe\u3001\u6587\u6863\u3001\u56fe\u8868>\u5143\u7ec4\u7684\u6570\u636e\u96c6\uff0c\u5e76\u4e0e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u7ed3\u679c\u663e\u793a\u672c\u6587\u65b9\u6cd5\u5728\u56fe\u8868\u6570\u636e\u51c6\u786e\u6027\u548c\u56fe\u8868\u7c7b\u578b\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u610f\u56fe\u7684\u56fe\u8868\u751f\u6210\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u80fd\u591f\u4ece\u6587\u6863\u4e2d\u751f\u6210\u7b26\u5408\u7528\u6237\u610f\u56fe\u7684\u56fe\u8868\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u56fe\u8868\u6570\u636e\u51c6\u786e\u6027\u548c\u56fe\u8868\u7c7b\u578b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2507.14849", "pdf": "https://arxiv.org/pdf/2507.14849", "abs": "https://arxiv.org/abs/2507.14849", "authors": ["Yifei Wang"], "title": "Beyond Isolated Capabilities: Bridging Long CoT Reasoning and Long-Context Understanding", "categories": ["cs.CL"], "comment": null, "summary": "Reasoning distillation has emerged as an effective approach to enhance the\nreasoning capabilities of smaller language models. However, the impact of\nlarge-scale reasoning distillation on other critical abilities, particularly\nin-context retrieval and reasoning, remains unexplored. This gap in\nunderstanding is particularly significant given the increasing importance of\nRetrieval-Augmented Generation (RAG) systems, where efficient acquisition and\nutilization of contextual information are paramount for generating reliable\nresponses. Motivated by the need to understand how the extended long-CoT\nprocess influences long-context comprehension, we conduct a comprehensive\ninvestigation using a series of open-source models distilled from Deepseek-R1,\nrenowned for its exceptional reasoning capabilities. Our study focuses on\nevaluating these models' performance in extracting and integrating relevant\ninformation from extended contexts through multi-document question and\nanswering tasks. Through rigorous experimentation, we demonstrate that\ndistilled reasoning patterns significantly improve long-context understanding.\nOur analysis reveals that distillation fosters greater long-context awareness\nby promoting more detailed and explicit reasoning processes during context\nanalysis and information parsing. This advancement effectively mitigates the\npersistent \"lost in the middle\" issue that has hindered long-context models.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u89c4\u6a21\u63a8\u7406\u84b8\u998f\u5bf9\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u84b8\u998f\u53ef\u4ee5\u63d0\u5347\u6a21\u578b\u7684\u957f\u4e0a\u4e0b\u6587\u610f\u8bc6\uff0c\u5e76\u7f13\u89e3\u201c\u4e2d\u95f4\u8ff7\u5931\u201d\u95ee\u9898\u3002", "motivation": "\u6211\u4eec\u53d7\u5230\u9700\u8981\u4e86\u89e3\u6269\u5c55\u7684\u957fCoT\u8fc7\u7a0b\u5982\u4f55\u5f71\u54cd\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u7684\u52a8\u673a\u9a71\u52a8\uff0c\u7279\u522b\u662f\u5728\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u4e2d\uff0c\u9ad8\u6548\u83b7\u53d6\u548c\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\u5bf9\u4e8e\u751f\u6210\u53ef\u9760\u54cd\u5e94\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6211\u4eec\u4f7f\u7528\u4e00\u7cfb\u5217\u4eceDeepseek-R1\u5f00\u6e90\u6a21\u578b\u4e2d\u63d0\u70bc\u51fa\u7684\u6a21\u578b\u8fdb\u884c\u4e86\u5168\u9762\u7684\u7814\u7a76\uff0c\u8fd9\u4e9b\u6a21\u578b\u4ee5\u5176\u5353\u8d8a\u7684\u63a8\u7406\u80fd\u529b\u800c\u95fb\u540d\u3002\u6211\u4eec\u7684\u7814\u7a76\u91cd\u70b9\u662f\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u5728\u591a\u6587\u6863\u95ee\u7b54\u4efb\u52a1\u4e2d\u63d0\u53d6\u548c\u6574\u5408\u76f8\u5173\u4fe1\u606f\u7684\u8868\u73b0\u3002", "result": "\u6211\u4eec\u901a\u8fc7\u4e25\u683c\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u84b8\u998f\u7684\u63a8\u7406\u6a21\u5f0f\u663e\u8457\u63d0\u9ad8\u4e86\u957f\u4e0a\u4e0b\u6587\u7684\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "\u6211\u4eec\u7684\u5206\u6790\u8868\u660e\uff0c\u77e5\u8bc6\u84b8\u998f\u901a\u8fc7\u5728\u4e0a\u4e0b\u6587\u5206\u6790\u548c\u4fe1\u606f\u89e3\u6790\u8fc7\u7a0b\u4e2d\u4fc3\u8fdb\u66f4\u8be6\u7ec6\u548c\u660e\u786e\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u589e\u5f3a\u4e86\u957f\u4e0a\u4e0b\u6587\u610f\u8bc6\u3002\u8fd9\u4e00\u8fdb\u6b65\u6709\u6548\u7f13\u89e3\u4e86\u957f\u671f\u4e0a\u4e0b\u6587\u6a21\u578b\u6240\u9762\u4e34\u7684\u201c\u4e2d\u95f4\u8ff7\u5931\u201d\u95ee\u9898\u3002"}}
{"id": "2507.14871", "pdf": "https://arxiv.org/pdf/2507.14871", "abs": "https://arxiv.org/abs/2507.14871", "authors": ["Ronit D. Gross", "Yarden Tzach", "Tal Halevi", "Ella Koresh", "Ido Kanter"], "title": "Tiny language models", "categories": ["cs.CL"], "comment": "23 pages, 1 figure and 12 tables", "summary": "A prominent achievement of natural language processing (NLP) is its ability\nto understand and generate meaningful human language. This capability relies on\ncomplex feedforward transformer block architectures pre-trained on large\nlanguage models (LLMs). However, LLM pre-training is currently feasible only\nfor a few dominant companies due to the immense computational resources\nrequired, limiting broader research participation. This creates a critical need\nfor more accessible alternatives. In this study, we explore whether tiny\nlanguage models (TLMs) exhibit the same key qualitative features of LLMs. We\ndemonstrate that TLMs exhibit a clear performance gap between pre-trained and\nnon-pre-trained models across classification tasks, indicating the\neffectiveness of pre-training, even at a tiny scale. The performance gap\nincreases with the size of the pre-training dataset and with greater overlap\nbetween tokens in the pre-training and classification datasets. Furthermore,\nthe classification accuracy achieved by a pre-trained deep TLM architecture can\nbe replicated through a soft committee of multiple, independently pre-trained\nshallow architectures, enabling low-latency TLMs without affecting\nclassification accuracy. Our results are based on pre-training BERT-6 and\nvariants of BERT-1 on subsets of the Wikipedia dataset and evaluating their\nperformance on FewRel, AGNews, and DBPedia classification tasks. Future\nresearch on TLM is expected to further illuminate the mechanisms underlying\nNLP, especially given that its biologically inspired models suggest that TLMs\nmay be sufficient for children or adolescents to develop language.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08TLMs\uff09\u662f\u5426\u8868\u73b0\u51fa\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u76f8\u540c\u7684\u5b9a\u6027\u7279\u5f81\u3002\u7ed3\u679c\u663e\u793a\uff0cTLMs\u5728\u9884\u8bad\u7ec3\u540e\u80fd\u591f\u8868\u73b0\u51fa\u4e0eLLMs\u76f8\u4f3c\u7684\u5173\u952e\u8d28\u91cf\u7279\u5f81\uff0c\u4e14\u901a\u8fc7\u4f7f\u7528\u591a\u4e2a\u72ec\u7acb\u9884\u8bad\u7ec3\u7684\u6d45\u5c42\u67b6\u6784\u7684\u8f6f\u59d4\u5458\u4f1a\uff0c\u53ef\u4ee5\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u7684TLM\u800c\u4e0d\u5f71\u54cd\u5206\u7c7b\u51c6\u786e\u6027\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u9884\u8bad\u7ec3\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u8d44\u6e90\uff0c\u53ea\u6709\u5c11\u6570\u4e3b\u8981\u516c\u53f8\u624d\u80fd\u8fdb\u884c\uff0c\u8fd9\u9650\u5236\u4e86\u66f4\u5e7f\u6cdb\u7684\u7814\u7a76\u53c2\u4e0e\u3002\u56e0\u6b64\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u6613\u8bbf\u95ee\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u5728\u7ef4\u57fa\u767e\u79d1\u6570\u636e\u96c6\u7684\u5b50\u96c6\u4e0a\u5bf9BERT-6\u548cBERT-1\u53d8\u4f53\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5e76\u5728FewRel\u3001AGNews\u548cDBPedia\u5206\u7c7b\u4efb\u52a1\u4e0a\u8bc4\u4f30\u5176\u6027\u80fd\uff0c\u6765\u63a2\u7d22TLMs\u662f\u5426\u8868\u73b0\u51fa\u4e0eLLMs\u76f8\u540c\u7684\u5b9a\u6027\u7279\u5f81\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cTLMs\u5728\u9884\u8bad\u7ec3\u548c\u975e\u9884\u8bad\u7ec3\u6a21\u578b\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u8fd9\u8868\u660e\u5373\u4f7f\u5728\u5fae\u578b\u89c4\u6a21\u4e0b\uff0c\u9884\u8bad\u7ec3\u4e5f\u662f\u6709\u6548\u7684\u3002\u6027\u80fd\u5dee\u8ddd\u968f\u7740\u9884\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u5927\u5c0f\u548c\u9884\u8bad\u7ec3\u6570\u636e\u96c6\u4e0e\u5206\u7c7b\u6570\u636e\u96c6\u4e4b\u95f4\u7684\u4ee4\u724c\u91cd\u53e0\u7a0b\u5ea6\u800c\u589e\u52a0\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u4f7f\u7528\u591a\u4e2a\u72ec\u7acb\u9884\u8bad\u7ec3\u7684\u6d45\u5c42\u67b6\u6784\u7684\u8f6f\u59d4\u5458\u4f1a\uff0c\u53ef\u4ee5\u590d\u5236\u9884\u8bad\u7ec3\u6df1\u5ea6TLM\u67b6\u6784\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u4ece\u800c\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u7684TLM\u800c\u4e0d\u5f71\u54cd\u5206\u7c7b\u51c6\u786e\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08TLMs\uff09\u5728\u9884\u8bad\u7ec3\u540e\u80fd\u591f\u8868\u73b0\u51fa\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u76f8\u4f3c\u7684\u5173\u952e\u8d28\u91cf\u7279\u5f81\uff0c\u8fd9\u4e3a\u66f4\u5e7f\u6cdb\u7684\u7814\u7a76\u53c2\u4e0e\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u4f7f\u7528\u591a\u4e2a\u72ec\u7acb\u9884\u8bad\u7ec3\u7684\u6d45\u5c42\u67b6\u6784\u7684\u8f6f\u59d4\u5458\u4f1a\uff0c\u53ef\u4ee5\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u7684TLM\u800c\u4e0d\u5f71\u54cd\u5206\u7c7b\u51c6\u786e\u6027\u3002"}}
{"id": "2507.14887", "pdf": "https://arxiv.org/pdf/2507.14887", "abs": "https://arxiv.org/abs/2507.14887", "authors": ["Shiyi Mu", "Yongkang Liu", "Shi Feng", "Xiaocui Yang", "Daling Wang", "Yifei Zhang"], "title": "MEKiT: Multi-source Heterogeneous Knowledge Injection Method via Instruction Tuning for Emotion-Cause Pair Extraction", "categories": ["cs.CL"], "comment": "Accepted by CogSci", "summary": "Although large language models (LLMs) excel in text comprehension and\ngeneration, their performance on the Emotion-Cause Pair Extraction (ECPE) task,\nwhich requires reasoning ability, is often underperform smaller language model.\nThe main reason is the lack of auxiliary knowledge, which limits LLMs' ability\nto effectively perceive emotions and reason causes. To address this issue, we\npropose a novel \\textbf{M}ulti-source h\\textbf{E}terogeneous \\textbf{K}nowledge\n\\textbf{i}njection me\\textbf{T}hod, MEKiT, which integrates heterogeneous\ninternal emotional knowledge and external causal knowledge. Specifically, for\nthese two distinct aspects and structures of knowledge, we apply the approaches\nof incorporating instruction templates and mixing data for instruction-tuning,\nwhich respectively facilitate LLMs in more comprehensively identifying emotion\nand accurately reasoning causes. Experimental results demonstrate that MEKiT\nprovides a more effective and adaptable solution for the ECPE task, exhibiting\nan absolute performance advantage over compared baselines and dramatically\nimproving the performance of LLMs on the ECPE task.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMEKiT\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u5f02\u6784\u7684\u5185\u90e8\u60c5\u611f\u77e5\u8bc6\u548c\u5916\u90e8\u56e0\u679c\u77e5\u8bc6\uff0c\u4ee5\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728Emotion-Cause Pair Extraction\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMEKiT\u5728\u8be5\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6587\u672c\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5728\u9700\u8981\u63a8\u7406\u80fd\u529b\u7684Emotion-Cause Pair Extraction\uff08ECPE\uff09\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5f80\u5f80\u4e0d\u5982\u8f83\u5c0f\u7684\u8bed\u8a00\u6a21\u578b\u3002\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u4e4f\u8f85\u52a9\u77e5\u8bc6\uff0c\u8fd9\u9650\u5236\u4e86LLMs\u611f\u77e5\u60c5\u7eea\u548c\u63a8\u7406\u539f\u56e0\u7684\u80fd\u529b\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aMEKiT\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u5f02\u6784\u7684\u5185\u90e8\u60c5\u611f\u77e5\u8bc6\u548c\u5916\u90e8\u56e0\u679c\u77e5\u8bc6\u3002\u5bf9\u4e8e\u8fd9\u4e24\u79cd\u4e0d\u540c\u65b9\u9762\u548c\u7ed3\u6784\u7684\u77e5\u8bc6\uff0c\u6211\u4eec\u5e94\u7528\u4e86\u5305\u542b\u6307\u4ee4\u6a21\u677f\u548c\u6df7\u5408\u6570\u636e\u7684\u65b9\u6cd5\u8fdb\u884c\u6307\u4ee4\u8c03\u4f18\uff0c\u5206\u522b\u6709\u52a9\u4e8eLLMs\u66f4\u5168\u9762\u5730\u8bc6\u522b\u60c5\u7eea\u548c\u51c6\u786e\u5730\u63a8\u7406\u539f\u56e0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMEKiT\u4e3aECPE\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u6709\u6548\u548c\u9002\u5e94\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4e0e\u6bd4\u8f83\u57fa\u7ebf\u7684\u5bf9\u6bd4\u4e2d\u8868\u73b0\u51fa\u7edd\u5bf9\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86LLMs\u5728ECPE\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMEKiT\u4e3aECPE\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u6709\u6548\u548c\u9002\u5e94\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4e0e\u6bd4\u8f83\u57fa\u7ebf\u7684\u5bf9\u6bd4\u4e2d\u8868\u73b0\u51fa\u7edd\u5bf9\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86LLMs\u5728ECPE\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2507.14894", "pdf": "https://arxiv.org/pdf/2507.14894", "abs": "https://arxiv.org/abs/2507.14894", "authors": ["Boyi Deng", "Yu Wan", "Baosong Yang", "Fei Huang", "Wenjie Wang", "Fuli Feng"], "title": "Sparse Autoencoder-guided Supervised Finetuning to Mitigate Unexpected Code-Switching in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have impressive multilingual capabilities, but\nthey suffer from unexpected code-switching, also known as language mixing,\nwhich involves switching to unexpected languages in the model response. This\nproblem leads to poor readability and degrades the usability of model\nresponses. However, existing work on this issue lacks a mechanistic analysis\nand shows limited effectiveness. In this paper, we first provide an in-depth\nanalysis of unexpected code-switching using sparse autoencoders and find that\nwhen LLMs switch to a language, the features of that language exhibit excessive\npre-activation values. Based on our findings, we propose $\\textbf{S}$parse\n$\\textbf{A}$utoencoder-guided $\\textbf{S}$upervised\n$\\textbf{F}$ine$\\textbf{t}$uning (SASFT), which teaches LLMs to maintain\nappropriate pre-activation values of specific language features during\ntraining. Experiments on five models across three languages demonstrate that\nSASFT consistently reduces unexpected code-switching by more than 50\\% compared\nto standard supervised fine-tuning, with complete elimination in four cases.\nMoreover, SASFT maintains or even improves the models' performance on six\nmultilingual benchmarks, showing its effectiveness in addressing code-switching\nwhile preserving multilingual capabilities.", "AI": {"tldr": "This paper proposes SASFT, a method that reduces unexpected code-switching in large language models while preserving their multilingual capabilities.", "motivation": "Existing work on code-switching lacks a mechanistic analysis and shows limited effectiveness. The problem of code-switching leads to poor readability and degrades the usability of model responses.", "method": "SASFT, which uses sparse autoencoders to guide supervised fine-tuning, teaches LLMs to maintain appropriate pre-activation values of specific language features during training.", "result": "Experiments on five models across three languages show that SASFT reduces unexpected code-switching by more than 50% compared to standard supervised fine-tuning, with complete elimination in four cases. It also maintains or improves performance on six multilingual benchmarks.", "conclusion": "SASFT is effective in reducing unexpected code-switching while maintaining or improving multilingual capabilities."}}
{"id": "2507.14900", "pdf": "https://arxiv.org/pdf/2507.14900", "abs": "https://arxiv.org/abs/2507.14900", "authors": ["Chongxuan Huang", "Yongshi Ye", "Biao Fu", "Qifeng Su", "Xiaodong Shi"], "title": "From Neurons to Semantics: Evaluating Cross-Linguistic Alignment Capabilities of Large Language Models via Neurons Alignment", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable multilingual\ncapabilities, however, how to evaluate cross-lingual alignment remains\nunderexplored. Existing alignment benchmarks primarily focus on sentence\nembeddings, but prior research has shown that neural models tend to induce a\nnon-smooth representation space, which impact of semantic alignment evaluation\non low-resource languages. Inspired by neuroscientific findings that similar\ninformation activates overlapping neuronal regions, we propose a novel Neuron\nState-Based Cross-Lingual Alignment (NeuronXA) to assess the cross-lingual a\nlignment capabilities of LLMs, which offers a more semantically grounded\napproach to assess cross-lingual alignment. We evaluate NeuronXA on several\nprominent multilingual LLMs (LLaMA, Qwen, Mistral, GLM, and OLMo) across two\ntransfer tasks and three multilingual benchmarks. The results demonstrate that\nwith only 100 parallel sentence pairs, NeuronXA achieves a Pearson correlation\nof 0.9556 with downstream tasks performance and 0.8514 with transferability.\nThese findings demonstrate NeuronXA's effectiveness in assessing both\ncross-lingual alignment and transferability, even with a small dataset. This\nhighlights its potential to advance cross-lingual alignment research and to\nimprove the semantic understanding of multilingual LLMs.", "AI": {"tldr": "A new method called NeuronXA is introduced to evaluate cross-lingual alignment in LLMs. It shows high effectiveness even with limited data, offering a promising approach for improving multilingual LLMs.", "motivation": "Existing alignment benchmarks primarily focus on sentence embeddings, but neural models tend to induce a non-smooth representation space, which impacts semantic alignment evaluation on low-resource languages. The need for a more semantically grounded approach to assess cross-lingual alignment is highlighted.", "method": "Proposed a novel Neuron State-Based Cross-Lingual Alignment (NeuronXA) to assess the cross-lingual alignment capabilities of LLMs, inspired by neuroscientific findings that similar information activates overlapping neuronal regions.", "result": "NeuronXA achieves a Pearson correlation of 0.9556 with downstream tasks performance and 0.8514 with transferability using only 100 parallel sentence pairs. It demonstrates effectiveness in assessing both cross-lingual alignment and transferability.", "conclusion": "NeuronXA's effectiveness in assessing both cross-lingual alignment and transferability, even with a small dataset, highlights its potential to advance cross-lingual alignment research and improve the semantic understanding of multilingual LLMs."}}
{"id": "2507.14913", "pdf": "https://arxiv.org/pdf/2507.14913", "abs": "https://arxiv.org/abs/2507.14913", "authors": ["Eliya Habba", "Noam Dahan", "Gili Lior", "Gabriel Stanovsky"], "title": "PromptSuite: A Task-Agnostic Framework for Multi-Prompt Generation", "categories": ["cs.CL"], "comment": "Eliya Habba and Noam Dahan contributed equally to this work", "summary": "Evaluating LLMs with a single prompt has proven unreliable, with small\nchanges leading to significant performance differences. However, generating the\nprompt variations needed for a more robust multi-prompt evaluation is\nchallenging, limiting its adoption in practice. To address this, we introduce\nPromptSuite, a framework that enables the automatic generation of various\nprompts. PromptSuite is flexible - working out of the box on a wide range of\ntasks and benchmarks. It follows a modular prompt design, allowing controlled\nperturbations to each component, and is extensible, supporting the addition of\nnew components and perturbation types. Through a series of case studies, we\nshow that PromptSuite provides meaningful variations to support strong\nevaluation practices. It is available through both a Python API:\nhttps://github.com/eliyahabba/PromptSuite, and a user-friendly web interface:\nhttps://promptsuite.streamlit.app/", "AI": {"tldr": "PromptSuite is a framework for automatically generating prompt variations to improve the reliability of LLM evaluations.", "motivation": "Evaluating LLMs with a single prompt has proven unreliable, and generating prompt variations for a more robust multi-prompt evaluation is challenging.", "method": "PromptSuite is a framework that enables the automatic generation of various prompts, following a modular prompt design and allowing controlled perturbations to each component.", "result": "PromptSuite is flexible, works out of the box on a wide range of tasks and benchmarks, and is extensible, supporting the addition of new components and perturbation types.", "conclusion": "PromptSuite provides meaningful variations to support strong evaluation practices and is available through both a Python API and a user-friendly web interface."}}
{"id": "2507.14922", "pdf": "https://arxiv.org/pdf/2507.14922", "abs": "https://arxiv.org/abs/2507.14922", "authors": ["Vahid Rahimzadeh", "Erfan Moosavi Monazzah", "Mohammad Taher Pilehvar", "Yadollah Yaghoobzadeh"], "title": "SYNTHIA: Synthetic Yet Naturally Tailored Human-Inspired PersonAs", "categories": ["cs.CL", "I.2.7"], "comment": null, "summary": "Persona-driven LLMs have emerged as powerful tools in computational social\nscience, yet existing approaches fall at opposite extremes, either relying on\ncostly human-curated data or producing synthetic personas that lack consistency\nand realism. We introduce SYNTHIA, a dataset of 30,000 backstories derived from\n10,000 real social media users from BlueSky open platform across three time\nwindows, bridging this spectrum by grounding synthetic generation in authentic\nuser activity. Our evaluation demonstrates that SYNTHIA achieves competitive\nperformance with state-of-the-art methods in demographic diversity and social\nsurvey alignment while significantly outperforming them in narrative\nconsistency. Uniquely, SYNTHIA incorporates temporal dimensionality and\nprovides rich social interaction metadata from the underlying network, enabling\nnew research directions in computational social science and persona-driven\nlanguage modeling.", "AI": {"tldr": "SYNTHIA is a new dataset of 30,000 backstories from real social media users, offering improved narrative consistency and enabling new research directions in computational social science and persona-driven language modeling.", "motivation": "Existing approaches to persona-driven LLMs either rely on costly human-curated data or produce synthetic personas that lack consistency and realism. There is a need for a dataset that bridges this spectrum by grounding synthetic generation in authentic user activity.", "method": "SYNTHIA is a dataset of 30,000 backstories derived from 10,000 real social media users from BlueSky across three time windows, grounded in authentic user activity.", "result": "SYNTHIA achieves competitive performance with state-of-the-art methods in demographic diversity and social survey alignment while significantly outperforming them in narrative consistency. It also incorporates temporal dimensionality and provides rich social interaction metadata.", "conclusion": "SYNTHIA provides a new dataset that bridges the gap between human-curated data and synthetic personas, offering competitive performance in demographic diversity and social survey alignment, while significantly outperforming existing methods in narrative consistency. It also introduces temporal dimensionality and rich social interaction metadata, enabling new research directions."}}
{"id": "2507.14958", "pdf": "https://arxiv.org/pdf/2507.14958", "abs": "https://arxiv.org/abs/2507.14958", "authors": ["Hang Yan", "Fangzhi Xu", "Rongman Xu", "Yifei Li", "Jian Zhang", "Haoran Luo", "Xiaobao Wu", "Luu Anh Tuan", "Haiteng Zhao", "Qika Lin", "Jun Liu"], "title": "MUR: Momentum Uncertainty guided Reasoning for Large Language Models", "categories": ["cs.CL"], "comment": "25 pages, 8 figures", "summary": "Large Language Models (LLMs) have achieved impressive performance on\nreasoning-intensive tasks, yet optimizing their reasoning efficiency remains an\nopen challenge. While Test-Time Scaling (TTS) improves reasoning quality, it\noften leads to overthinking, wasting tokens on redundant computations. This\nwork investigates how to efficiently and adaptively guide LLM test-time scaling\nwithout additional training. Inspired by the concept of momentum in physics, we\npropose Momentum Uncertainty-guided Reasoning (MUR), which dynamically\nallocates thinking budgets to critical reasoning steps by tracking and\naggregating stepwise uncertainty over time. To support flexible inference-time\ncontrol, we introduce gamma-control, a simple mechanism that tunes the\nreasoning budget via a single hyperparameter. We provide in-depth theoretical\nproof to support the superiority of MUR in terms of stability and biases. MUR\nis comprehensively evaluated against various TTS methods across four\nchallenging benchmarks (MATH-500, AIME24, AIME25, and GPQA-diamond) using\ndifferent sizes of recent Qwen3 models (1.7B, 4B, and 8B). Results demonstrate\nthat MUR reduces computation by over 50% on average while improving accuracy by\n0.62-3.37%.", "AI": {"tldr": "This paper proposes MUR, a method for efficiently and adaptively guiding LLM test-time scaling without additional training. It uses momentum uncertainty to dynamically allocate thinking budgets and introduces gamma-control for flexible inference-time control.", "motivation": "Optimizing the reasoning efficiency of Large Language Models (LLMs) remains an open challenge. While Test-Time Scaling (TTS) improves reasoning quality, it often leads to overthinking, wasting tokens on redundant computations.", "method": "Inspired by the concept of momentum in physics, we propose Momentum Uncertainty-guided Reasoning (MUR), which dynamically allocates thinking budgets to critical reasoning steps by tracking and aggregating stepwise uncertainty over time. We introduce gamma-control, a simple mechanism that tunes the reasoning budget via a single hyperparameter.", "result": "MUR is comprehensively evaluated against various TTS methods across four challenging benchmarks (MATH-500, AIME24, AIME25, and GPQA-diamond) using different sizes of recent Qwen3 models (1.7B, 4B, and 8B).", "conclusion": "MUR reduces computation by over 50% on average while improving accuracy by 0.62-3.37%."}}
{"id": "2507.15024", "pdf": "https://arxiv.org/pdf/2507.15024", "abs": "https://arxiv.org/abs/2507.15024", "authors": ["Qiaoyu Tang", "Hao Xiang", "Le Yu", "Bowen Yu", "Hongyu Lin", "Yaojie Lu", "Xianpei Han", "Le Sun", "Junyang Lin"], "title": "RefCritic: Training Long Chain-of-Thought Critic Models with Refinement Feedback", "categories": ["cs.CL"], "comment": null, "summary": "With the rapid advancement of Large Language Models (LLMs), developing\neffective critic modules for precise guidance has become crucial yet\nchallenging. In this paper, we initially demonstrate that supervised\nfine-tuning for building critic modules (which is widely adopted in current\nsolutions) fails to genuinely enhance models' critique abilities, producing\nsuperficial critiques with insufficient reflections and verifications. To\nunlock the unprecedented critique capabilities, we propose RefCritic, a\nlong-chain-of-thought critic module based on reinforcement learning with dual\nrule-based rewards: (1) instance-level correctness of solution judgments and\n(2) refinement accuracies of the policy model based on critiques, aiming to\ngenerate high-quality evaluations with actionable feedback that effectively\nguides model refinement. We evaluate RefCritic on Qwen2.5-14B-Instruct and\nDeepSeek-R1-Distill-Qwen-14B across five benchmarks. On critique and refinement\nsettings, RefCritic demonstrates consistent advantages across all benchmarks,\ne.g., 6.8\\% and 7.2\\% gains on AIME25 for the respective base models. Notably,\nunder majority voting, policy models filtered by RefCritic show superior\nscaling with increased voting numbers. Moreover, despite training on\nsolution-level supervision, RefCritic outperforms step-level supervised\napproaches on ProcessBench, a benchmark to identify erroneous steps in\nmathematical reasoning.", "AI": {"tldr": "This paper introduces RefCritic, a critic module that enhances model critique abilities through reinforcement learning with dual rule-based rewards, showing consistent advantages across benchmarks.", "motivation": "Supervised fine-tuning for building critic modules fails to genuinely enhance models' critique abilities, producing superficial critiques with insufficient reflections and verifications.", "method": "RefCritic is a long-chain-of-thought critic module based on reinforcement learning with dual rule-based rewards: (1) instance-level correctness of solution judgments and (2) refinement accuracies of the policy model based on critiques.", "result": "RefCritic shows significant gains on AIME25 for the respective base models and superior scaling with increased voting numbers under majority voting.", "conclusion": "RefCritic demonstrates consistent advantages across all benchmarks and outperforms step-level supervised approaches on ProcessBench."}}
{"id": "2507.15061", "pdf": "https://arxiv.org/pdf/2507.15061", "abs": "https://arxiv.org/abs/2507.15061", "authors": ["Zhengwei Tao", "Jialong Wu", "Wenbiao Yin", "Junkai Zhang", "Baixuan Li", "Haiyang Shen", "Kuan Li", "Liwen Zhang", "Xinyu Wang", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Jingren Zhou"], "title": "WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The advent of Large Language Model (LLM)-powered agents has revolutionized\nartificial intelligence by enabling solutions to complex, open-ended tasks\nthrough web-based information-seeking (IS) capabilities. The scarcity of\nhigh-quality training data has limited the development of IS agents. Existing\napproaches typically adopt an information-driven paradigm that first collects\nweb data and then generates questions based on the retrieval. However, this may\nlead to inconsistency between information structure and reasoning structure,\nquestion and answer. To mitigate, we propose a formalization-driven IS data\nsynthesis framework WebShaper to construct a dataset. WebShaper systematically\nformalizes IS tasks through set theory. Central to the formalization is the\nconcept of Knowledge Projections (KP), which enables precise control over\nreasoning structure by KP operation compositions. During synthesis, we begin by\ncreating seed tasks, then use a multi-step expansion process. At each step, an\nagentic Expander expands the current formal question more complex with\nretrieval and validation tools based on our formalization. We train our model\non the synthesized dataset. Experiment results demonstrate that WebShaper\nachieves state-of-the-art performance among open-sourced IS agents on GAIA and\nWebWalkerQA benchmarks.", "AI": {"tldr": "WebShaper is a framework for synthesizing IS data by formalizing tasks through set theory and using Knowledge Projections to control reasoning structure, resulting in improved performance on benchmarks.", "motivation": "The scarcity of high-quality training data has limited the development of IS agents. Existing approaches may lead to inconsistency between information structure and reasoning structure.", "method": "WebShaper systematically formalizes IS tasks through set theory, utilizing Knowledge Projections (KP) to control reasoning structure. It creates seed tasks and expands them using a multi-step process with an agentic Expander.", "result": "WebShaper achieves state-of-the-art performance among open-sourced IS agents on GAIA and WebWalkerQA benchmarks.", "conclusion": "WebShaper achieves state-of-the-art performance among open-sourced IS agents on GAIA and WebWalkerQA benchmarks."}}
{"id": "2507.15087", "pdf": "https://arxiv.org/pdf/2507.15087", "abs": "https://arxiv.org/abs/2507.15087", "authors": ["Chenlei Gong", "Yuanhe Tian", "Lei Mao", "Yan Song"], "title": "Evaluation of Coding Schemes for Transformer-based Gene Sequence Modeling", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Currently, many studies view DNA sequences as a special type of language and\nutilize Transformers to model them. These studies use fixed-length k-mer\nsegmentation and BPE subword tokenization but lack a systematic evaluation to\ndetermine which is superior. We compare k-mer segmentation with k=1,3,4,5,6, a\n4,096-token BPE vocabulary, and three positional encoding methods-sinusoidal,\nAliBi, and RoPE. Each configuration is trained from scratch in 3, 6, 12, and\n24-layer Transformer encoders and evaluated on GUE benchmark dataset. In\ngeneral, BPE delivers higher and more stable performance across tasks by\ncompressing frequent motifs into variable-length tokens, reducing sequence\nlength, and improving model generalization. RoPE excels at capturing periodic\nmotifs and extrapolating to long sequences, while AliBi also performs well on\ntasks driven by local dependencies. In terms of depth, we observe significant\ngains when increasing layers from 3 to 12, with only marginal improvements or\nslight overfitting at 24 layers. This study provides practical guidance for\ndesigning tokenization and positional encoding in DNA Transformer models.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86DNA\u5e8f\u5217\u7684\u5206\u8bcd\u65b9\u6cd5\u548c\u4f4d\u7f6e\u7f16\u7801\u6280\u672f\uff0c\u53d1\u73b0BPE\u548cRoPE\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u63d0\u4f9b\u4e86\u5173\u4e8eTransformer\u6a21\u578b\u6df1\u5ea6\u7684\u5b9e\u7528\u5efa\u8bae\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c06DNA\u5e8f\u5217\u89c6\u4e3a\u4e00\u79cd\u7279\u6b8a\u8bed\u8a00\uff0c\u5e76\u5229\u7528Transformer\u5bf9\u5176\u8fdb\u884c\u5efa\u6a21\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u4e0d\u540c\u5206\u8bcd\u65b9\u6cd5\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u6bd4\u8f83k-mer\u5206\u5272\u4e0eBPE\u5b50\u8bcd\u5206\u8bcd\uff0c\u4ee5\u53ca\u4e09\u79cd\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\uff08\u6b63\u5f26\u3001AliBi\u548cRoPE\uff09\uff0c\u5e76\u5728\u4e0d\u540c\u5c42\u6570\u7684Transformer\u7f16\u7801\u5668\u4e2d\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "BPE\u5728\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u80fd\uff0cRoPE\u5728\u6355\u6349\u5468\u671f\u6027\u57fa\u5e8f\u548c\u957f\u5e8f\u5217\u5916\u63a8\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0cAliBi\u5728\u4f9d\u8d56\u5c40\u90e8\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\u3002\u589e\u52a0\u5c42\u6570\u4ece3\u523012\u5c42\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u800c24\u5c42\u4ec5\u5e26\u6765\u5fae\u5c0f\u6539\u8fdb\u6216\u8f7b\u5fae\u8fc7\u62df\u5408\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u8bbe\u8ba1DNA Transformer\u6a21\u578b\u7684\u5206\u8bcd\u548c\u4f4d\u7f6e\u7f16\u7801\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2507.15092", "pdf": "https://arxiv.org/pdf/2507.15092", "abs": "https://arxiv.org/abs/2507.15092", "authors": ["Vijeta Deshpande", "Ishita Dasgupta", "Uttaran Bhattacharya", "Somdeb Sarkhel", "Saayan Mitra", "Anna Rumshisky"], "title": "A Penalty Goes a Long Way: Measuring Lexical Diversity in Synthetic Texts Under Prompt-Influenced Length Variations", "categories": ["cs.CL"], "comment": null, "summary": "Synthetic text generated by Large Language Models (LLMs) is increasingly used\nfor further training and improvement of LLMs. Diversity is crucial for the\neffectiveness of synthetic data, and researchers rely on prompt engineering to\nimprove diversity. However, the impact of prompt variations on response text\nlength, and, more importantly, the consequential effect on lexical diversity\nmeasurements, remain underexplored. In this work, we propose Penalty-Adjusted\nType-Token Ratio (PATTR), a diversity metric robust to length variations. We\ngenerate a large synthetic corpus of over 20M words using seven models from the\nLLaMA, OLMo, and Phi families, focusing on a creative writing task of video\nscript generation, where diversity is crucial. We evaluate per-response lexical\ndiversity using PATTR and compare it against existing metrics of Moving-Average\nTTR (MATTR) and Compression Ratio (CR). Our analysis highlights how text length\nvariations introduce biases favoring shorter responses. Unlike existing\nmetrics, PATTR explicitly considers the task-specific target response length\n($L_T$) to effectively mitigate length biases. We further demonstrate the\nutility of PATTR in filtering the top-10/100/1,000 most lexically diverse\nresponses, showing that it consistently outperforms MATTR and CR by yielding on\npar or better diversity with high adherence to $L_T$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6837\u6027\u5ea6\u91cf\u65b9\u6cd5 PATTR\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u51cf\u8f7b\u6587\u672c\u957f\u5ea6\u53d8\u5316\u5e26\u6765\u7684\u504f\u5dee\uff0c\u5e76\u5728\u8bcd\u6c47\u591a\u6837\u6027\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u7814\u7a76\u8005\u4f9d\u8d56\u4e8e\u63d0\u793a\u5de5\u7a0b\u6765\u63d0\u9ad8\u5408\u6210\u6570\u636e\u7684\u591a\u6837\u6027\uff0c\u4f46\u63d0\u793a\u53d8\u5316\u5bf9\u54cd\u5e94\u6587\u672c\u957f\u5ea6\u7684\u5f71\u54cd\u4ee5\u53ca\u7531\u6b64\u4ea7\u751f\u7684\u8bcd\u6c47\u591a\u6837\u6027\u6d4b\u91cf\u7684\u540e\u679c\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u8ba8\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9c81\u68d2\u7684\u591a\u6837\u6027\u5ea6\u91cf\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86 Penalty-Adjusted Type-Token Ratio (PATTR)\uff0c\u8fd9\u662f\u4e00\u79cd\u9488\u5bf9\u6587\u672c\u957f\u5ea6\u53d8\u5316\u7684\u591a\u6837\u6027\u5ea6\u91cf\u65b9\u6cd5\u3002\u6211\u4eec\u751f\u6210\u4e86\u4e00\u4e2a\u5305\u542b\u8d85\u8fc72000\u4e07\u8bcd\u7684\u5408\u6210\u8bed\u6599\u5e93\uff0c\u5e76\u4f7f\u7528 PATTR \u4e0e\u5176\u4ed6\u73b0\u6709\u5ea6\u91cf\u65b9\u6cd5\uff08\u5982 Moving-Average TTR \u548c Compression Ratio\uff09\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u6587\u672c\u957f\u5ea6\u7684\u53d8\u5316\u4f1a\u5f15\u5165\u6709\u5229\u4e8e\u8f83\u77ed\u54cd\u5e94\u7684\u504f\u5dee\u3002PATTR \u80fd\u591f\u663e\u5f0f\u8003\u8651\u4efb\u52a1\u7279\u5b9a\u7684\u76ee\u6807\u54cd\u5e94\u957f\u5ea6\uff08L_T\uff09\uff0c\u4ece\u800c\u6709\u6548\u51cf\u8f7b\u957f\u5ea6\u504f\u5dee\u3002\u6b64\u5916\uff0cPATTR \u5728\u8fc7\u6ee4\u6700\u5bcc\u6709\u8bcd\u6c47\u591a\u6837\u6027\u7684\u54cd\u5e94\u65b9\u9762\u8868\u73b0\u4f18\u4e8e MATTR \u548c CR\u3002", "conclusion": "PATTR \u662f\u4e00\u79cd\u5bf9\u6587\u672c\u957f\u5ea6\u53d8\u5316\u5177\u6709\u9c81\u68d2\u6027\u7684\u591a\u6837\u6027\u5ea6\u91cf\u6807\u51c6\uff0c\u5b83\u5728\u8fc7\u6ee4\u6700\u5bcc\u6709\u8bcd\u6c47\u591a\u6837\u6027\u7684\u54cd\u5e94\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u80fd\u591f\u6709\u6548\u51cf\u5c11\u957f\u5ea6\u504f\u5dee\u3002"}}
{"id": "2507.15100", "pdf": "https://arxiv.org/pdf/2507.15100", "abs": "https://arxiv.org/abs/2507.15100", "authors": ["Chathuri Jayaweera", "Brianna Yanqui", "Bonnie Dorr"], "title": "Filling the Gap: Is Commonsense Knowledge Generation useful for Natural Language Inference?", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 8 figures and 5 tables", "summary": "Natural Language Inference (NLI) is the task of determining the semantic\nentailment of a premise for a given hypothesis. The task aims to develop\nsystems that emulate natural human inferential processes where commonsense\nknowledge plays a major role. However, existing commonsense resources lack\nsufficient coverage for a variety of premise-hypothesis pairs. This study\nexplores the potential of Large Language Models as commonsense knowledge\ngenerators for NLI along two key dimensions: their reliability in generating\nsuch knowledge and the impact of that knowledge on prediction accuracy. We\nadapt and modify existing metrics to assess LLM factuality and consistency in\ngenerating in this context. While explicitly incorporating commonsense\nknowledge does not consistently improve overall results, it effectively helps\ndistinguish entailing instances and moderately improves distinguishing\ncontradictory and neutral inferences.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4e2d\u4f5c\u4e3a\u5e38\u8bc6\u77e5\u8bc6\u751f\u6210\u5668\u7684\u6f5c\u529b\uff0c\u53d1\u73b0\u867d\u7136\u663e\u5f0f\u7ed3\u5408\u5e38\u8bc6\u77e5\u8bc6\u5e76\u4e0d\u603b\u662f\u80fd\u63d0\u9ad8\u6574\u4f53\u7ed3\u679c\uff0c\u4f46\u5b83\u6709\u52a9\u4e8e\u533a\u5206\u652f\u6301\u7684\u5b9e\u4f8b\uff0c\u5e76\u9002\u5ea6\u6539\u5584\u533a\u5206\u77db\u76fe\u548c\u4e2d\u6027\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u7684\u5e38\u8bc6\u8d44\u6e90\u4e0d\u8db3\u4ee5\u8986\u76d6\u5404\u79cd\u524d\u63d0-\u5047\u8bbe\u5bf9\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5e38\u8bc6\u77e5\u8bc6\u751f\u6210\u5668\u7684\u6f5c\u529b\u3002", "method": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4e2d\u7684\u5e38\u8bc6\u77e5\u8bc6\u751f\u6210\u5668\u7684\u6f5c\u529b\uff0c\u4ece\u4e24\u4e2a\u5173\u952e\u7ef4\u5ea6\u8bc4\u4f30\u5176\u53ef\u9760\u6027\u4ee5\u53ca\u8be5\u77e5\u8bc6\u5bf9\u9884\u6d4b\u51c6\u786e\u6027\u7684\u5f71\u54cd\u529b\u3002", "result": "\u663e\u5f0f\u7ed3\u5408\u5e38\u8bc6\u77e5\u8bc6\u6709\u52a9\u4e8e\u533a\u5206\u652f\u6301\u7684\u5b9e\u4f8b\uff0c\u5e76\u9002\u5ea6\u6539\u5584\u533a\u5206\u77db\u76fe\u548c\u4e2d\u6027\u63a8\u7406\u3002", "conclusion": "\u867d\u7136\u663e\u5f0f\u5730\u7ed3\u5408\u5e38\u8bc6\u77e5\u8bc6\u5e76\u4e0d\u603b\u662f\u80fd\u63d0\u9ad8\u6574\u4f53\u7ed3\u679c\uff0c\u4f46\u5b83\u6709\u52a9\u4e8e\u533a\u5206\u652f\u6301\u7684\u5b9e\u4f8b\uff0c\u5e76\u9002\u5ea6\u6539\u5584\u533a\u5206\u77db\u76fe\u548c\u4e2d\u6027\u63a8\u7406\u3002"}}
{"id": "2507.15114", "pdf": "https://arxiv.org/pdf/2507.15114", "abs": "https://arxiv.org/abs/2507.15114", "authors": ["Chathuri Jayaweera", "Bonnie Dorr"], "title": "From Disagreement to Understanding: The Case for Ambiguity Detection in NLI", "categories": ["cs.CL"], "comment": "8 pages, 6 figures", "summary": "This position paper argues that annotation disagreement in Natural Language\nInference (NLI) is not mere noise but often reflects meaningful interpretive\nvariation, especially when triggered by ambiguity in the premise or hypothesis.\nWhile underspecified guidelines and annotator behavior can contribute to\nvariation, content-based ambiguity offers a process-independent signal of\ndivergent human perspectives. We call for a shift toward ambiguity-aware NLI by\nsystematically identifying ambiguous input pairs and classifying ambiguity\ntypes. To support this, we present a unified framework that integrates existing\ntaxonomies and illustrate key ambiguity subtypes through concrete examples.\nThese examples reveal how ambiguity shapes annotator decisions and motivate the\nneed for targeted detection methods that better align models with human\ninterpretation. A key limitation is the lack of datasets annotated for\nambiguity and subtypes. We propose addressing this gap through new annotated\nresources and unsupervised approaches to ambiguity detection -- paving the way\nfor more robust, explainable, and human-aligned NLI systems.", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3aNLI\u4e2d\u7684\u6807\u6ce8\u4e0d\u4e00\u81f4\u5e76\u975e\u4ec5\u4ec5\u662f\u566a\u58f0\uff0c\u800c\u662f\u53cd\u6620\u4e86\u4eba\u7c7b\u89e3\u91ca\u7684\u591a\u6837\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u5904\u7406\u6b67\u4e49\uff0c\u5e76\u547c\u5401\u5efa\u7acb\u65b0\u7684\u6807\u6ce8\u8d44\u6e90\u4ee5\u6539\u8fdbNLI\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524dNLI\u4e2d\u7684\u6807\u6ce8\u4e0d\u4e00\u81f4\u5f80\u5f80\u53cd\u6620\u4e86\u6709\u610f\u4e49\u7684\u89e3\u91ca\u53d8\u5316\uff0c\u5c24\u5176\u662f\u5728\u524d\u63d0\u6216\u5047\u8bbe\u4e2d\u5b58\u5728\u6b67\u4e49\u65f6\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6574\u5408\u73b0\u6709\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u901a\u8fc7\u5177\u4f53\u4f8b\u5b50\u5c55\u793a\u5173\u952e\u7684\u6b67\u4e49\u5b50\u7c7b\u578b\u3002", "result": "\u901a\u8fc7\u8bc6\u522b\u6a21\u7cca\u8f93\u5165\u5bf9\u5e76\u5206\u7c7b\u6b67\u4e49\u7c7b\u578b\uff0c\u53ef\u4ee5\u63ed\u793a\u6b67\u4e49\u5982\u4f55\u5f71\u54cd\u6807\u6ce8\u8005\u7684\u51b3\u7b56\uff0c\u5e76\u63a8\u52a8\u9488\u5bf9\u6027\u68c0\u6d4b\u65b9\u6cd5\u7684\u53d1\u5c55\u3002", "conclusion": "\u672c\u6587\u4e3b\u5f20\u5c06\u6b67\u4e49\u7eb3\u5165\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u7684\u8003\u91cf\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u4e0e\u4eba\u7c7b\u89e3\u91ca\u7684\u4e00\u81f4\u6027\u3002"}}
{"id": "2507.15142", "pdf": "https://arxiv.org/pdf/2507.15142", "abs": "https://arxiv.org/abs/2507.15142", "authors": ["Hellina Hailu Nigatu", "Atnafu Lambebo Tonja", "Henok Biadglign Ademtew", "Hizkel Mitiku Alemayehu", "Negasi Haile Abadi", "Tadesse Destaw Belay", "Seid Muhie Yimam"], "title": "A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that use the Ge'ez Script", "categories": ["cs.CL", "cs.AI"], "comment": "Paper under review", "summary": "Homophone normalization, where characters that have the same sound in a\nwriting script are mapped to one character, is a pre-processing step applied in\nAmharic Natural Language Processing (NLP) literature. While this may improve\nperformance reported by automatic metrics, it also results in models that are\nnot able to understand different forms of writing in a single language.\nFurther, there might be impacts in transfer learning, where models trained on\nnormalized data do not generalize well to other languages. In this paper, we\nexperiment with monolingual training and cross-lingual transfer to understand\nthe impacts of normalization on languages that use the Ge'ez script. We then\npropose a post-inference intervention in which normalization is applied to\nmodel predictions instead of training data. With our simple scheme of\npost-inference normalization, we show that we can achieve an increase in BLEU\nscore of up to 1.03 while preserving language features in training. Our work\ncontributes to the broader discussion on technology-facilitated language change\nand calls for more language-aware interventions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u540c\u97f3\u8bcd\u5f52\u4e00\u5316\u5bf9\u4f7f\u7528Ge'ez\u811a\u672c\u7684\u8bed\u8a00\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u540e\u63a8\u7406\u5f52\u4e00\u5316\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8BLEU\u5206\u6570\u5e76\u4fdd\u7559\u8bed\u8a00\u7279\u5f81\u3002", "motivation": "\u540c\u97f3\u8bcd\u5f52\u4e00\u5316\u53ef\u80fd\u63d0\u9ad8\u81ea\u52a8\u5ea6\u91cf\u62a5\u544a\u7684\u6027\u80fd\uff0c\u4f46\u4e5f\u4f1a\u5bfc\u81f4\u6a21\u578b\u65e0\u6cd5\u7406\u89e3\u5355\u4e00\u8bed\u8a00\u7684\u4e0d\u540c\u4e66\u5199\u5f62\u5f0f\u3002\u6b64\u5916\uff0c\u5728\u8fc1\u79fb\u5b66\u4e60\u4e2d\uff0c\u8bad\u7ec3\u6570\u636e\u5f52\u4e00\u5316\u7684\u6a21\u578b\u53ef\u80fd\u65e0\u6cd5\u5f88\u597d\u5730\u6cdb\u5316\u5230\u5176\u4ed6\u8bed\u8a00\u3002", "method": "\u6211\u4eec\u8fdb\u884c\u4e86\u5355\u8bed\u8bad\u7ec3\u548c\u8de8\u8bed\u8a00\u8fc1\u79fb\u5b9e\u9a8c\uff0c\u4ee5\u4e86\u89e3\u5f52\u4e00\u5316\u5bf9\u4f7f\u7528Ge'ez\u811a\u672c\u7684\u8bed\u8a00\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u540e\u63a8\u7406\u5e72\u9884\uff0c\u5176\u4e2d\u5728\u6a21\u578b\u9884\u6d4b\u4e0a\u5e94\u7528\u5f52\u4e00\u5316\u800c\u4e0d\u662f\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u901a\u8fc7\u6211\u4eec\u7b80\u5355\u7684\u540e\u63a8\u7406\u5f52\u4e00\u5316\u65b9\u6848\uff0c\u6211\u4eec\u5c55\u793a\u4e86BLEU\u5206\u6570\u53ef\u4ee5\u63d0\u9ad8\u6700\u591a1.03\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u8bad\u7ec3\u4e2d\u7684\u8bed\u8a00\u7279\u5f81\u3002", "conclusion": "\u6211\u4eec\u7684\u5de5\u4f5c\u6709\u52a9\u4e8e\u5173\u4e8e\u6280\u672f\u4fc3\u8fdb\u8bed\u8a00\u53d8\u5316\u7684\u66f4\u5e7f\u6cdb\u8ba8\u8bba\uff0c\u5e76\u547c\u5401\u66f4\u591a\u8bed\u8a00\u610f\u8bc6\u5e72\u9884\u3002"}}
{"id": "2507.15152", "pdf": "https://arxiv.org/pdf/2507.15152", "abs": "https://arxiv.org/abs/2507.15152", "authors": ["Lingbo Li", "Anuradha Mathrani", "Teo Susnjak"], "title": "What Level of Automation is \"Good Enough\"? A Benchmark of Large Language Models for Meta-Analysis Data Extraction", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Automating data extraction from full-text randomised controlled trials (RCTs)\nfor meta-analysis remains a significant challenge. This study evaluates the\npractical performance of three LLMs (Gemini-2.0-flash, Grok-3, GPT-4o-mini)\nacross tasks involving statistical results, risk-of-bias assessments, and\nstudy-level characteristics in three medical domains: hypertension, diabetes,\nand orthopaedics. We tested four distinct prompting strategies (basic\nprompting, self-reflective prompting, model ensemble, and customised prompts)\nto determine how to improve extraction quality. All models demonstrate high\nprecision but consistently suffer from poor recall by omitting key information.\nWe found that customised prompts were the most effective, boosting recall by up\nto 15\\%. Based on this analysis, we propose a three-tiered set of guidelines\nfor using LLMs in data extraction, matching data types to appropriate levels of\nautomation based on task complexity and risk. Our study offers practical advice\nfor automating data extraction in real-world meta-analyses, balancing LLM\nefficiency with expert oversight through targeted, task-specific automation.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u4e09\u79cdLLM\u5728\u4e09\u4e2a\u533b\u5b66\u9886\u57df\u4e2d\u7684\u6570\u636e\u63d0\u53d6\u6027\u80fd\uff0c\u5e76\u6d4b\u8bd5\u4e86\u56db\u79cd\u63d0\u793a\u7b56\u7565\u3002\u7ed3\u679c\u663e\u793a\u5b9a\u5236\u63d0\u793a\u6700\u6709\u6548\uff0c\u63d0\u9ad8\u4e86\u53ec\u56de\u7387\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u4e09\u5c42\u6307\u5357\uff0c\u4ee5\u5e73\u8861LLM\u7684\u6548\u7387\u4e0e\u4e13\u5bb6\u76d1\u7763\u3002", "motivation": "\u81ea\u52a8\u5316\u4ece\u5168\u6587\u672c\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\uff08RCTs\uff09\u4e2d\u63d0\u53d6\u6570\u636e\u8fdb\u884cmeta\u5206\u6790\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u4e09\u79cdLLM\uff08Gemini-2.0-flash\u3001Grok-3\u3001GPT-4o-mini\uff09\u5728\u4e09\u4e2a\u533b\u5b66\u9886\u57df\uff08\u9ad8\u8840\u538b\u3001\u7cd6\u5c3f\u75c5\u548c\u9aa8\u79d1\uff09\u4e2d\u7684\u7edf\u8ba1\u7ed3\u679c\u3001\u504f\u501a\u98ce\u9669\u8bc4\u4f30\u548c\u7814\u7a76\u7ea7\u7279\u5f81\u65b9\u9762\u7684\u5b9e\u9645\u6027\u80fd\u3002\u6d4b\u8bd5\u4e86\u56db\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u7b56\u7565\uff08\u57fa\u672c\u63d0\u793a\u3001\u81ea\u6211\u53cd\u601d\u63d0\u793a\u3001\u6a21\u578b\u96c6\u6210\u548c\u5b9a\u5236\u63d0\u793a\uff09\u4ee5\u786e\u5b9a\u5982\u4f55\u63d0\u9ad8\u63d0\u53d6\u8d28\u91cf\u3002", "result": "\u6240\u6709\u6a21\u578b\u90fd\u8868\u73b0\u51fa\u9ad8\u7cbe\u5ea6\uff0c\u4f46\u59cb\u7ec8\u56e0\u9057\u6f0f\u5173\u952e\u4fe1\u606f\u800c\u8868\u73b0\u51fa\u8f83\u5dee\u7684\u53ec\u56de\u7387\u3002\u53d1\u73b0\u5b9a\u5236\u63d0\u793a\u662f\u6700\u6709\u6548\u7684\uff0c\u53ef\u5c06\u53ec\u56de\u7387\u63d0\u9ad8\u591a\u8fbe15%\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e09\u5c42\u6307\u5357\uff0c\u7528\u4e8e\u5728\u6570\u636e\u63d0\u53d6\u4e2d\u4f7f\u7528LLM\uff0c\u6839\u636e\u4efb\u52a1\u590d\u6742\u6027\u548c\u98ce\u9669\u5c06\u6570\u636e\u7c7b\u578b\u4e0e\u9002\u5f53\u7684\u81ea\u52a8\u5316\u7ea7\u522b\u76f8\u5339\u914d\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u5728\u73b0\u5b9e\u4e16\u754cmeta\u5206\u6790\u4e2d\u81ea\u52a8\u5316\u6570\u636e\u63d0\u53d6\u7684\u5b9e\u7528\u5efa\u8bae\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u7684\u4efb\u52a1\u7279\u5b9a\u81ea\u52a8\u5316\u5e73\u8861LLM\u7684\u6548\u7387\u4e0e\u4e13\u5bb6\u76d1\u7763\u3002"}}
{"id": "2507.15198", "pdf": "https://arxiv.org/pdf/2507.15198", "abs": "https://arxiv.org/abs/2507.15198", "authors": ["Xiandong Meng", "Yan Wu", "Yexin Tian", "Xin Hu", "Tianze Kang", "Junliang Du"], "title": "Collaborative Distillation Strategies for Parameter-Efficient Language Model Deployment", "categories": ["cs.CL"], "comment": null, "summary": "This paper addresses the challenges of high computational cost and slow\ninference in deploying large language models. It proposes a distillation\nstrategy guided by multiple teacher models. The method constructs several\nteacher models and integrates their output probability distributions and\nintermediate semantic features. This guides the student model to learn from\nmultiple sources of knowledge. As a result, the student model gains stronger\nlanguage understanding and generation ability while maintaining a small\nparameter size. To achieve this, the paper introduces a weighted output fusion\nmechanism, a feature alignment loss function, and an entropy-driven dynamic\nteacher weighting strategy. These components improve the quality and stability\nof knowledge transfer during distillation. Under multi-teacher guidance, the\nstudent model captures semantic information more effectively and demonstrates\nstrong performance across multiple evaluation metrics. In particular, the\nmethod shows high consistency in expression, generalization ability, and task\nadaptability in tasks such as language modeling, text generation, and\nmulti-task learning. The experiments compare the proposed method with several\nwidely adopted distillation approaches. The results further confirm its overall\nadvantages in perplexity, distillation loss, and generation quality. This study\nprovides a feasible technical path for the efficient compression of large-scale\nlanguage models. It also demonstrates the effectiveness of multi-teacher\ncollaborative mechanisms in complex language modeling tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6559\u5e08\u6a21\u578b\u7684\u84b8\u998f\u7b56\u7565\uff0c\u4ee5\u964d\u4f4e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u9ad8\u63a8\u7406\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u5c0f\u53c2\u6570\u89c4\u6a21\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u4e2d\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u63a8\u7406\u7f13\u6162\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7531\u591a\u4e2a\u6559\u5e08\u6a21\u578b\u5f15\u5bfc\u7684\u84b8\u998f\u7b56\u7565\uff0c\u6784\u5efa\u4e86\u591a\u4e2a\u6559\u5e08\u6a21\u578b\u5e76\u6574\u5408\u5176\u8f93\u51fa\u6982\u7387\u5206\u5e03\u548c\u4e2d\u95f4\u8bed\u4e49\u7279\u5f81\uff0c\u4ee5\u6307\u5bfc\u5b66\u751f\u6a21\u578b\u4ece\u591a\u4e2a\u77e5\u8bc6\u6e90\u5b66\u4e60\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u52a0\u6743\u8f93\u51fa\u878d\u5408\u673a\u5236\u3001\u7279\u5f81\u5bf9\u9f50\u635f\u5931\u51fd\u6570\u548c\u71b5\u9a71\u52a8\u7684\u52a8\u6001\u6559\u5e08\u52a0\u6743\u7b56\u7565\uff0c\u4ee5\u63d0\u9ad8\u77e5\u8bc6\u8fc1\u79fb\u7684\u8d28\u91cf\u548c\u7a33\u5b9a\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8bed\u8a00\u5efa\u6a21\u3001\u6587\u672c\u751f\u6210\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u9ad8\u5ea6\u7684\u4e00\u81f4\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u4efb\u52a1\u9002\u5e94\u6027\u3002\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u5728\u56f0\u60d1\u5ea6\u3001\u84b8\u998f\u635f\u5931\u548c\u751f\u6210\u8d28\u91cf\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684\u84b8\u998f\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u538b\u7f29\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u6280\u672f\u8def\u5f84\uff0c\u5e76\u5c55\u793a\u4e86\u591a\u6559\u5e08\u534f\u4f5c\u673a\u5236\u5728\u590d\u6742\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.15236", "pdf": "https://arxiv.org/pdf/2507.15236", "abs": "https://arxiv.org/abs/2507.15236", "authors": ["Shayan Vassef", "Amirhossein Dabiriaghdam", "Mohammadreza Bakhtiari", "Yadollah Yaghoobzadeh"], "title": "SOI Matters: Analyzing Multi-Setting Training Dynamics in Pretrained Language Models via Subsets of Interest", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This work investigates the impact of multi-task, multi-lingual, and\nmulti-source learning approaches on the robustness and performance of\npretrained language models. To enhance this analysis, we introduce Subsets of\nInterest (SOI), a novel categorization framework that identifies six distinct\nlearning behavior patterns during training, including forgettable examples,\nunlearned examples, and always correct examples. Through SOI transition\nheatmaps and dataset cartography visualization, we analyze how examples shift\nbetween these categories when transitioning from single-setting to\nmulti-setting configurations. We perform comprehensive experiments across three\nparallel comparisons: multi-task vs. single-task learning using English tasks\n(entailment, paraphrase, sentiment), multi-source vs. single-source learning\nusing sentiment analysis datasets, and multi-lingual vs. single-lingual\nlearning using intent classification in French, English, and Persian. Our\nresults demonstrate that multi-source learning consistently improves\nout-of-distribution performance by up to 7%, while multi-task learning shows\nmixed results with notable gains in similar task combinations. We further\nintroduce a two-stage fine-tuning approach where the second stage leverages\nSOI-based subset selection to achieve additional performance improvements.\nThese findings provide new insights into training dynamics and offer practical\napproaches for optimizing multi-setting language model performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u591a\u4efb\u52a1\u3001\u591a\u8bed\u8a00\u548c\u591a\u6e90\u5b66\u4e60\u65b9\u6cd5\u5bf9\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u7684\u5f71\u54cd\u3002\u6211\u4eec\u5f15\u5165\u4e86SOI\uff08\u5174\u8da3\u5b50\u96c6\uff09\u4f5c\u4e3a\u5206\u7c7b\u6846\u67b6\uff0c\u7528\u4e8e\u8bc6\u522b\u516d\u79cd\u4e0d\u540c\u7684\u5b66\u4e60\u884c\u4e3a\u6a21\u5f0f\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u591a\u6e90\u5b66\u4e60\u5728\u5206\u5e03\u5916\u6027\u80fd\u4e0a\u6301\u7eed\u63d0\u9ad8\u4e86\u9ad8\u8fbe7%\uff0c\u800c\u591a\u4efb\u52a1\u5b66\u4e60\u5728\u76f8\u4f3c\u4efb\u52a1\u7ec4\u5408\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u589e\u76ca\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u5fae\u8c03\u65b9\u6cd5\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u8bad\u7ec3\u52a8\u6001\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u5e76\u63d0\u4f9b\u4e86\u4f18\u5316\u591a\u8bbe\u7f6e\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u5b9e\u7528\u65b9\u6cd5\u3002", "motivation": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u591a\u4efb\u52a1\u3001\u591a\u8bed\u8a00\u548c\u591a\u6e90\u5b66\u4e60\u65b9\u6cd5\u5bf9\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86SOI\uff08\u5174\u8da3\u5b50\u96c6\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u578b\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u7528\u4e8e\u8bc6\u522b\u8bad\u7ec3\u671f\u95f4\u7684\u516d\u79cd\u4e0d\u540c\u7684\u5b66\u4e60\u884c\u4e3a\u6a21\u5f0f\u3002\u6211\u4eec\u901a\u8fc7SOI\u8f6c\u6362\u70ed\u56fe\u548c\u6570\u636e\u96c6\u5730\u56fe\u53ef\u89c6\u5316\u5206\u6790\u4e86\u793a\u4f8b\u5728\u5355\u8bbe\u7f6e\u5230\u591a\u8bbe\u7f6e\u914d\u7f6e\u4e4b\u95f4\u7684\u53d8\u5316\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u5fae\u8c03\u65b9\u6cd5\uff0c\u5176\u4e2d\u7b2c\u4e8c\u9636\u6bb5\u5229\u7528\u57fa\u4e8eSOI\u7684\u5b50\u96c6\u9009\u62e9\u6765\u5b9e\u73b0\u989d\u5916\u7684\u6027\u80fd\u63d0\u5347\u3002", "result": "\u591a\u6e90\u5b66\u4e60\u5728\u5206\u5e03\u5916\u6027\u80fd\u4e0a\u6301\u7eed\u63d0\u9ad8\u4e86\u9ad8\u8fbe7%\uff0c\u800c\u591a\u4efb\u52a1\u5b66\u4e60\u5728\u76f8\u4f3c\u4efb\u52a1\u7ec4\u5408\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u589e\u76ca\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u8bad\u7ec3\u52a8\u6001\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u5e76\u63d0\u4f9b\u4e86\u4f18\u5316\u591a\u8bbe\u7f6e\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2507.15275", "pdf": "https://arxiv.org/pdf/2507.15275", "abs": "https://arxiv.org/abs/2507.15275", "authors": ["Yuanhe Tian", "Junjie Liu", "Zhizhou Kou", "Yuxiang Li", "Yan Song"], "title": "ChiMed 2.0: Advancing Chinese Medical Dataset in Facilitating Large Language Modeling", "categories": ["cs.CL"], "comment": null, "summary": "Building high-quality data resources is crucial for advancing artificial\nintelligence research and applications in specific domains, particularly in the\nChinese medical domain. Existing Chinese medical datasets are limited in size\nand narrow in domain coverage, falling short of the diverse corpora required\nfor effective pre-training. Moreover, most datasets are designed solely for LLM\nfine-tuning and do not support pre-training and reinforcement learning from\nhuman feedback (RLHF). In this paper, we propose a Chinese medical dataset\nnamed ChiMed 2.0, which extends our previous work ChiMed, and covers data\ncollected from Chinese medical online platforms and generated by LLMs. ChiMed\n2.0 contains 204.4M Chinese characters covering both traditional Chinese\nmedicine classics and modern general medical data, where there are 164.8K\ndocuments for pre-training, 351.6K question-answering pairs for supervised\nfine-tuning (SFT), and 41.7K preference data tuples for RLHF. To validate the\neffectiveness of our approach for training a Chinese medical LLM, we conduct\nfurther pre-training, SFT, and RLHF experiments on representative general\ndomain LLMs and evaluate their performance on medical benchmark datasets. The\nresults show performance gains across different model scales, validating the\ndataset's effectiveness and applicability.", "AI": {"tldr": "ChiMed 2.0 is a large-scale Chinese medical dataset that supports pre-training, SFT, and RLHF, showing performance gains in medical LLM training.", "motivation": "Existing Chinese medical datasets are limited in size and domain coverage, and most are designed only for LLM fine-tuning without supporting pre-training and RLHF.", "method": "Proposed a Chinese medical dataset named ChiMed 2.0, which extends previous work and covers data from Chinese medical online platforms and generated by LLMs. Conducted pre-training, SFT, and RLHF experiments on representative general domain LLMs.", "result": "Performance gains across different model scales were observed, validating the dataset's effectiveness and applicability.", "conclusion": "ChiMed 2.0 dataset is effective and applicable for training a Chinese medical LLM."}}
{"id": "2507.15281", "pdf": "https://arxiv.org/pdf/2507.15281", "abs": "https://arxiv.org/abs/2507.15281", "authors": ["Haoran Sun", "Zekun Zhang", "Shaoning Zeng"], "title": "A Novel Self-Evolution Framework for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The capabilities of Large Language Models (LLMs) are limited to some extent\nby pre-training, so some researchers optimize LLMs through post-training.\nExisting post-training strategies, such as memory-based retrieval or preference\noptimization, improve user alignment yet fail to enhance the model's domain\ncognition. To bridge this gap, we propose a novel Dual-Phase Self-Evolution\n(DPSE) framework that jointly optimizes user preference adaptation and\ndomain-specific competence. DPSE introduces a Censor module to extract\nmulti-dimensional interaction signals and estimate satisfaction scores, which\nguide structured data expansion via topic-aware and preference-driven\nstrategies. These expanded datasets support a two-stage fine-tuning pipeline:\nsupervised domain grounding followed by frequency-aware preference\noptimization. Experiments across general NLP benchmarks and long-term dialogue\ntasks demonstrate that DPSE consistently outperforms Supervised Fine-Tuning,\nPreference Optimization, and Memory-Augmented baselines. Ablation studies\nvalidate the contribution of each module. In this way, our framework provides\nan autonomous path toward continual self-evolution of LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDual-Phase Self-Evolution (DPSE)\u7684\u6846\u67b6\uff0c\u65e8\u5728\u540c\u65f6\u4f18\u5316\u7528\u6237\u504f\u597d\u9002\u5e94\u548c\u9886\u57df\u7279\u5b9a\u80fd\u529b\u3002DPSE\u901a\u8fc7\u63d0\u53d6\u591a\u7ef4\u4ea4\u4e92\u4fe1\u53f7\u5e76\u4f30\u8ba1\u6ee1\u610f\u5ea6\u5206\u6570\uff0c\u6307\u5bfc\u7ed3\u6784\u5316\u6570\u636e\u6269\u5c55\uff0c\u5e76\u652f\u6301\u4e24\u9636\u6bb5\u5fae\u8c03\u7ba1\u9053\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDPSE\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u540e\u8bad\u7ec3\u7b56\u7565\uff0c\u5982\u57fa\u4e8e\u8bb0\u5fc6\u7684\u68c0\u7d22\u6216\u504f\u597d\u4f18\u5316\uff0c\u867d\u7136\u63d0\u9ad8\u4e86\u7528\u6237\u5bf9\u9f50\u5ea6\uff0c\u4f46\u672a\u80fd\u589e\u5f3a\u6a21\u578b\u7684\u9886\u57df\u8ba4\u77e5\u3002\u4e3a\u4e86\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u6211\u4eec\u63d0\u51fa\u4e86DPSE\u6846\u67b6\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aDual-Phase Self-Evolution (DPSE)\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u8054\u5408\u4f18\u5316\u7528\u6237\u504f\u597d\u9002\u5e94\u548c\u9886\u57df\u7279\u5b9a\u80fd\u529b\u3002DPSE\u5f15\u5165\u4e86\u4e00\u4e2aCensor\u6a21\u5757\u6765\u63d0\u53d6\u591a\u7ef4\u4ea4\u4e92\u4fe1\u53f7\u5e76\u4f30\u8ba1\u6ee1\u610f\u5ea6\u5206\u6570\uff0c\u8fd9\u901a\u8fc7\u4e3b\u9898\u611f\u77e5\u548c\u504f\u597d\u9a71\u52a8\u7684\u7b56\u7565\u6307\u5bfc\u7ed3\u6784\u5316\u6570\u636e\u6269\u5c55\u3002\u8fd9\u4e9b\u6269\u5c55\u7684\u6570\u636e\u96c6\u652f\u6301\u4e00\u4e2a\u4e24\u9636\u6bb5\u5fae\u8c03\u7ba1\u9053\uff1a\u76d1\u7763\u9886\u57df\u5b9a\u4f4d\u548c\u9891\u7387\u611f\u77e5\u504f\u597d\u4f18\u5316\u3002", "result": "\u5728\u901a\u7528NLP\u57fa\u51c6\u548c\u957f\u671f\u5bf9\u8bdd\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDPSE\u59cb\u7ec8\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\u3001\u504f\u597d\u4f18\u5316\u548c\u8bb0\u5fc6\u589e\u5f3a\u57fa\u7ebf\u3002\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u6bcf\u4e2a\u6a21\u5757\u7684\u8d21\u732e\u3002", "conclusion": "\u6211\u4eec\u7684\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u6761\u901a\u5f80LLM\u6301\u7eed\u81ea\u6211\u8fdb\u5316\u7684\u81ea\u4e3b\u8def\u5f84\u3002"}}
{"id": "2507.15286", "pdf": "https://arxiv.org/pdf/2507.15286", "abs": "https://arxiv.org/abs/2507.15286", "authors": ["Navid Ayoobi", "Sadat Shahriar", "Arjun Mukherjee"], "title": "Beyond Easy Wins: A Text Hardness-Aware Benchmark for LLM-generated Text Detection", "categories": ["cs.CL"], "comment": null, "summary": "We present a novel evaluation paradigm for AI text detectors that prioritizes\nreal-world and equitable assessment. Current approaches predominantly report\nconventional metrics like AUROC, overlooking that even modest false positive\nrates constitute a critical impediment to practical deployment of detection\nsystems. Furthermore, real-world deployment necessitates predetermined\nthreshold configuration, making detector stability (i.e. the maintenance of\nconsistent performance across diverse domains and adversarial scenarios), a\ncritical factor. These aspects have been largely ignored in previous research\nand benchmarks. Our benchmark, SHIELD, addresses these limitations by\nintegrating both reliability and stability factors into a unified evaluation\nmetric designed for practical assessment. Furthermore, we develop a post-hoc,\nmodel-agnostic humanification framework that modifies AI text to more closely\nresemble human authorship, incorporating a controllable hardness parameter.\nThis hardness-aware approach effectively challenges current SOTA zero-shot\ndetection methods in maintaining both reliability and stability. (Data and\ncode: https://github.com/navid-aub/SHIELD-Benchmark)", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684AI\u6587\u672c\u68c0\u6d4b\u5668\u8bc4\u4f30\u8303\u5f0f\uff0c\u5f3a\u8c03\u73b0\u5b9e\u4e16\u754c\u548c\u516c\u5e73\u8bc4\u4f30\uff0c\u901a\u8fc7\u5f15\u5165\u53ef\u9760\u6027\u4e0e\u7a33\u5b9a\u6027\u56e0\u7d20\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u7684\u4e0d\u8db3\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u540e\u5904\u7406\u3001\u6a21\u578b\u65e0\u5173\u7684\u4eba\u7c7b\u5316\u6846\u67b6\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u4e3b\u8981\u62a5\u544a\u4f20\u7edf\u7684\u6307\u6807\u5982AUROC\uff0c\u5ffd\u7565\u4e86\u5373\u4f7f\u8f7b\u5fae\u7684\u8bef\u62a5\u7387\u4e5f\u4f1a\u5bf9\u68c0\u6d4b\u7cfb\u7edf\u7684\u5b9e\u9645\u90e8\u7f72\u6784\u6210\u91cd\u5927\u969c\u788d\u3002\u6b64\u5916\uff0c\u5b9e\u9645\u90e8\u7f72\u9700\u8981\u9884\u8bbe\u9608\u503c\u914d\u7f6e\uff0c\u4f7f\u5f97\u68c0\u6d4b\u5668\u7684\u7a33\u5b9a\u6027\uff08\u5373\u5728\u4e0d\u540c\u9886\u57df\u548c\u5bf9\u6297\u573a\u666f\u4e2d\u4fdd\u6301\u4e00\u81f4\u6027\u80fd\uff09\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u56e0\u7d20\u3002\u8fd9\u4e9b\u65b9\u9762\u5728\u4ee5\u5f80\u7684\u7814\u7a76\u548c\u57fa\u51c6\u4e2d\u88ab\u5ffd\u89c6\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86SHIELD\u57fa\u51c6\uff0c\u6574\u5408\u4e86\u53ef\u9760\u6027\u4e0e\u7a33\u5b9a\u6027\u56e0\u7d20\u5230\u7edf\u4e00\u7684\u8bc4\u4f30\u6307\u6807\u4e2d\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u540e\u5904\u7406\u3001\u6a21\u578b\u65e0\u5173\u7684\u4eba\u7c7b\u5316\u6846\u67b6\uff0c\u4ee5\u4fee\u6539AI\u6587\u672c\u4ee5\u66f4\u63a5\u8fd1\u4eba\u7c7b\u4f5c\u8005\u7684\u98ce\u683c\u3002", "result": "SHIELD\u57fa\u51c6\u901a\u8fc7\u6574\u5408\u53ef\u9760\u6027\u4e0e\u7a33\u5b9a\u6027\u56e0\u7d20\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u8bc4\u4f30\u6307\u6807\u3002\u540c\u65f6\uff0c\u5f00\u53d1\u7684\u540e\u5904\u7406\u3001\u6a21\u578b\u65e0\u5173\u7684\u4eba\u7c7b\u5316\u6846\u67b6\u80fd\u591f\u6709\u6548\u6311\u6218\u5f53\u524d\u6700\u5148\u8fdb\u7684\u96f6\u6837\u672c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u53ef\u9760\u6027\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684AI\u6587\u672c\u68c0\u6d4b\u5668\u8bc4\u4f30\u8303\u5f0f\uff0c\u5f3a\u8c03\u73b0\u5b9e\u4e16\u754c\u548c\u516c\u5e73\u8bc4\u4f30\u3002\u901a\u8fc7\u5f15\u5165\u53ef\u9760\u6027\u4e0e\u7a33\u5b9a\u6027\u56e0\u7d20\uff0cSHIELD\u57fa\u51c6\u89e3\u51b3\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u7684\u4e0d\u8db3\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u540e\u5904\u7406\u3001\u6a21\u578b\u65e0\u5173\u7684\u4eba\u7c7b\u5316\u6846\u67b6\uff0c\u4ee5\u66f4\u63a5\u8fd1\u4eba\u7c7b\u5199\u4f5c\u65b9\u5f0f\u4fee\u6539AI\u6587\u672c\u3002"}}
{"id": "2507.15328", "pdf": "https://arxiv.org/pdf/2507.15328", "abs": "https://arxiv.org/abs/2507.15328", "authors": ["Thilo Hagendorff"], "title": "On the Inevitability of Left-Leaning Political Bias in Aligned Language Models", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "The guiding principle of AI alignment is to train large language models\n(LLMs) to be harmless, helpful, and honest (HHH). At the same time, there are\nmounting concerns that LLMs exhibit a left-wing political bias. Yet, the\ncommitment to AI alignment cannot be harmonized with the latter critique. In\nthis article, I argue that intelligent systems that are trained to be harmless\nand honest must necessarily exhibit left-wing political bias. Normative\nassumptions underlying alignment objectives inherently concur with progressive\nmoral frameworks and left-wing principles, emphasizing harm avoidance,\ninclusivity, fairness, and empirical truthfulness. Conversely, right-wing\nideologies often conflict with alignment guidelines. Yet, research on political\nbias in LLMs is consistently framing its insights about left-leaning tendencies\nas a risk, as problematic, or concerning. This way, researchers are actively\narguing against AI alignment, tacitly fostering the violation of HHH\nprinciples.", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3a\uff0cAI\u5bf9\u9f50\u539f\u5219\u4e0e\u5de6\u7ffc\u653f\u6cbb\u504f\u89c1\u5bc6\u5207\u76f8\u5173\uff0c\u4f46\u5f53\u524d\u7814\u7a76\u5374\u5c06\u8fd9\u79cd\u5de6\u503e\u503e\u5411\u89c6\u4e3a\u95ee\u9898\uff0c\u4ece\u800c\u8fdd\u80cc\u4e86AI\u5bf9\u9f50\u7684\u76ee\u6807\u3002", "motivation": "\u7814\u7a76AI\u5bf9\u9f50\u539f\u5219\u4e0e\u653f\u6cbb\u504f\u89c1\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u63ed\u793a\u5f53\u524d\u5bf9LLM\u4e2d\u5de6\u503e\u503e\u5411\u7684\u8bef\u89e3\u3002", "method": "\u901a\u8fc7\u5206\u6790AI\u5bf9\u9f50\u539f\u5219\u4e0e\u653f\u6cbb\u504f\u89c1\u7684\u5173\u7cfb\uff0c\u63a2\u8ba8\u4e86\u5de6\u7ffc\u548c\u53f3\u7ffc\u610f\u8bc6\u5f62\u6001\u5728AI\u5f00\u53d1\u4e2d\u7684\u4e0d\u540c\u5f71\u54cd\u3002", "result": "AI\u5bf9\u9f50\u539f\u5219\u5185\u5728\u5730\u4e0e\u8fdb\u6b65\u9053\u5fb7\u6846\u67b6\u548c\u5de6\u7ffc\u539f\u5219\u4e00\u81f4\uff0c\u800c\u53f3\u7ffc\u610f\u8bc6\u5f62\u6001\u5219\u4e0e\u5bf9\u9f50\u6307\u5357\u76f8\u51b2\u7a81\u3002\u7136\u800c\uff0c\u7814\u7a76\u5c06\u5de6\u503e\u503e\u5411\u89c6\u4e3a\u98ce\u9669\uff0c\u8fd9\u5b9e\u9645\u4e0a\u8fdd\u80cc\u4e86AI\u5bf9\u9f50\u7684\u76ee\u6807\u3002", "conclusion": "\u667a\u80fd\u7cfb\u7edf\u5728\u8bad\u7ec3\u4e3a\u65e0\u5bb3\u548c\u8bda\u5b9e\u7684\u8fc7\u7a0b\u4e2d\u5fc5\u7136\u8868\u73b0\u51fa\u5de6\u7ffc\u653f\u6cbb\u504f\u89c1\uff0c\u800c\u53f3\u7ffc\u610f\u8bc6\u5f62\u6001\u5f80\u5f80\u4e0e\u5bf9\u9f50\u6307\u5357\u76f8\u51b2\u7a81\u3002\u7136\u800c\uff0c\u5173\u4e8eLLM\u4e2d\u653f\u6cbb\u504f\u89c1\u7684\u7814\u7a76\u5374\u5c06\u5de6\u503e\u503e\u5411\u89c6\u4e3a\u4e00\u79cd\u98ce\u9669\uff0c\u8fd9\u5b9e\u9645\u4e0a\u662f\u5728\u53cd\u5bf9AI\u5bf9\u9f50\uff0c\u9ed8\u8bb8\u8fdd\u53cdHHH\u539f\u5219\u3002"}}
{"id": "2507.15337", "pdf": "https://arxiv.org/pdf/2507.15337", "abs": "https://arxiv.org/abs/2507.15337", "authors": ["Narun Raman", "Taylor Lundy", "Kevin Leyton-Brown"], "title": "Reasoning Models are Test Exploiters: Rethinking Multiple-Choice", "categories": ["cs.CL"], "comment": "9 pages, 3 figures", "summary": "When evaluating Large Language Models (LLMs) in question-answering domains,\nit is common to ask the model to choose among a fixed set of choices (so-called\nmultiple-choice question-answering, or MCQA). Although downstream tasks of\ninterest typically do not provide systems with explicit options among which to\nchoose, this approach is nevertheless widely used because it makes it makes\nautomatic grading straightforward and has tended to produce challenging\nbenchmarks that correlate sufficiently well with downstream performance. This\npaper investigates the extent to which this trend continues to hold for\nstate-of-the-art reasoning models, describing a systematic evaluation of $15$\ndifferent question-answering benchmarks (e.g., MMLU, HLE) and $25$ different\nLLMs (including small models such as Qwen 7B and relatively large models such\nas Llama 70B). For each model-benchmark pair, we considered $5$ ways of\npresenting the model with questions, including variations on whether multiple\nchoices were offered to the model at all; whether \"none of the above\" sometimes\nreplaced the right answer; and whether the model was permitted to perform\nchain-of-thought reasoning before and/or after the choices were presented. MCQA\nremained a good proxy for the downstream performance of models as long as they\nwere allowed to perform chain-of-thought reasoning only before being presented\nwith the options among which they had to select. On the other hand, large\nmodels that were able to perform reasoning after being given a set of options\ntended to significantly outperform their free-text performance due to\nexploiting the information in the options. We conclude that MCQA is no longer a\ngood proxy for assessing downstream performance of state-of-the-art models, and\noffer practical guidelines for designing more robust, bias-resistant benchmarks\nthat better reflect LLMs' genuine reasoning capabilities.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86MCQA\u4f5c\u4e3a\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u4ee3\u7406\u7684\u6709\u6548\u6027\uff0c\u5e76\u53d1\u73b0\u5b83\u4e0d\u518d\u9002\u7528\u4e8e\u6700\u5148\u8fdb\u7684\u6a21\u578b\u3002", "motivation": "\u7814\u7a76MCQA\u662f\u5426\u4ecd\u7136\u662f\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u6709\u6548\u65b9\u6cd5\u3002", "method": "\u5bf915\u4e2a\u4e0d\u540c\u7684\u95ee\u7b54\u57fa\u51c6\u548c25\u4e2a\u4e0d\u540c\u7684LLMs\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\uff0c\u8003\u8651\u4e86\u4e94\u79cd\u4e0d\u540c\u7684\u95ee\u9898\u5448\u73b0\u65b9\u5f0f\u3002", "result": "\u5f53\u6a21\u578b\u53ea\u80fd\u5728\u63d0\u4f9b\u9009\u9879\u4e4b\u524d\u8fdb\u884c\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u65f6\uff0cMCQA\u4ecd\u7136\u662f\u4e0b\u6e38\u6027\u80fd\u7684\u826f\u597d\u4ee3\u7406\u3002\u7136\u800c\uff0c\u80fd\u591f\u5728\u7ed9\u51fa\u9009\u9879\u540e\u8fdb\u884c\u63a8\u7406\u7684\u5927\u6a21\u578b\u5f80\u5f80\u663e\u8457\u4f18\u4e8e\u5176\u81ea\u7531\u6587\u672c\u6027\u80fd\u3002", "conclusion": "MCQA\u4e0d\u518d\u662f\u8bc4\u4f30\u6700\u5148\u8fdb\u7684\u6a21\u578b\u7684\u4e0b\u6e38\u6027\u80fd\u7684\u826f\u597d\u4ee3\u7406\uff0c\u5e76\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u66f4\u7a33\u5065\u3001\u6297\u504f\u89c1\u7684\u57fa\u51c6\u7684\u5b9e\u7528\u6307\u5357\u3002"}}
{"id": "2507.15339", "pdf": "https://arxiv.org/pdf/2507.15339", "abs": "https://arxiv.org/abs/2507.15339", "authors": ["Leanne Tan", "Gabriel Chua", "Ziyu Ge", "Roy Ka-Wei Lee"], "title": "LionGuard 2: Building Lightweight, Data-Efficient & Localised Multilingual Content Moderators", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Modern moderation systems increasingly support multiple languages, but often\nfail to address localisation and low-resource variants - creating safety gaps\nin real-world deployments. Small models offer a potential alternative to large\nLLMs, yet still demand considerable data and compute. We present LionGuard 2, a\nlightweight, multilingual moderation classifier tailored to the Singapore\ncontext, supporting English, Chinese, Malay, and partial Tamil. Built on\npre-trained OpenAI embeddings and a multi-head ordinal classifier, LionGuard 2\noutperforms several commercial and open-source systems across 17 benchmarks,\nincluding both Singapore-specific and public English datasets. The system is\nactively deployed within the Singapore Government, demonstrating practical\nefficacy at scale. Our findings show that high-quality local data and robust\nmultilingual embeddings can achieve strong moderation performance, without\nfine-tuning large models. We release our model weights and part of our training\ndata to support future work on LLM safety.", "AI": {"tldr": "LionGuard 2\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u591a\u8bed\u8a00\u5185\u5bb9\u5ba1\u6838\u5206\u7c7b\u5668\uff0c\u9488\u5bf9\u65b0\u52a0\u5761\u73af\u5883\u8bbe\u8ba1\uff0c\u652f\u6301\u82f1\u8bed\u3001\u4e2d\u6587\u3001\u9a6c\u6765\u8bed\u548c\u90e8\u5206\u6cf0\u7c73\u5c14\u8bed\u3002\u5b83\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u7cfb\u7edf\uff0c\u5e76\u5df2\u5728\u65b0\u52a0\u5761\u653f\u5e9c\u5185\u90e8\u90e8\u7f72\u3002", "motivation": "\u73b0\u4ee3\u5185\u5bb9\u5ba1\u6838\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u652f\u6301\u591a\u79cd\u8bed\u8a00\uff0c\u4f46\u5f80\u5f80\u672a\u80fd\u89e3\u51b3\u672c\u5730\u5316\u548c\u4f4e\u8d44\u6e90\u53d8\u4f53\u7684\u95ee\u9898\uff0c\u8fd9\u5728\u73b0\u5b9e\u90e8\u7f72\u4e2d\u9020\u6210\u4e86\u5b89\u5168\u6f0f\u6d1e\u3002\u5c0f\u578b\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u5927\u578bLLM\u7684\u6f5c\u5728\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u4ecd\u9700\u8981\u5927\u91cf\u7684\u6570\u636e\u548c\u8ba1\u7b97\u3002", "method": "LionGuard 2\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u591a\u8bed\u8a00\u5185\u5bb9\u5ba1\u6838\u5206\u7c7b\u5668\uff0c\u9488\u5bf9\u65b0\u52a0\u5761\u73af\u5883\u8bbe\u8ba1\uff0c\u652f\u6301\u82f1\u8bed\u3001\u4e2d\u6587\u3001\u9a6c\u6765\u8bed\u548c\u90e8\u5206\u6cf0\u7c73\u5c14\u8bed\u3002\u5b83\u57fa\u4e8e\u9884\u8bad\u7ec3\u7684OpenAI\u5d4c\u5165\u548c\u591a\u5934\u6709\u5e8f\u5206\u7c7b\u5668\u3002", "result": "LionGuard 2\u572817\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u591a\u4e2a\u5546\u4e1a\u548c\u5f00\u6e90\u7cfb\u7edf\uff0c\u5305\u62ec\u65b0\u52a0\u5761\u7279\u5b9a\u7684\u548c\u516c\u5171\u7684\u82f1\u8bed\u6570\u636e\u96c6\u3002\u8be5\u7cfb\u7edf\u5df2\u5728\u65b0\u52a0\u5761\u653f\u5e9c\u5185\u90e8\u5b9e\u9645\u90e8\u7f72\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u9ad8\u8d28\u91cf\u7684\u672c\u5730\u6570\u636e\u548c\u5f3a\u5927\u7684\u591a\u8bed\u8a00\u5d4c\u5165\u53ef\u4ee5\u5728\u4e0d\u5fae\u8c03\u5927\u578b\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5f3a\u5927\u7684\u5185\u5bb9\u5ba1\u6838\u6027\u80fd\u3002\u6211\u4eec\u53d1\u5e03\u4e86\u6a21\u578b\u6743\u91cd\u548c\u90e8\u5206\u8bad\u7ec3\u6570\u636e\uff0c\u4ee5\u652f\u6301\u672a\u6765\u5728LLM\u5b89\u5168\u65b9\u9762\u7684\u5de5\u4f5c\u3002"}}
{"id": "2507.15347", "pdf": "https://arxiv.org/pdf/2507.15347", "abs": "https://arxiv.org/abs/2507.15347", "authors": ["Amedeo Buonanno", "Alessandro Rivetti", "Francesco A. N. Palmieri", "Giovanni Di Gennaro", "Gianmarco Romano"], "title": "Probing Information Distribution in Transformer Architectures through Entropy Analysis", "categories": ["cs.CL", "cs.LG"], "comment": "Presented to the Italian Workshop on Neural Networks (WIRN2025) and\n  it will appear in a Springer Chapter", "summary": "This work explores entropy analysis as a tool for probing information\ndistribution within Transformer-based architectures. By quantifying token-level\nuncertainty and examining entropy patterns across different stages of\nprocessing, we aim to investigate how information is managed and transformed\nwithin these models. As a case study, we apply the methodology to a GPT-based\nlarge language model, illustrating its potential to reveal insights into model\nbehavior and internal representations. This approach may offer insights into\nmodel behavior and contribute to the development of interpretability and\nevaluation frameworks for transformer-based models", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u71b5\u5206\u6790\u4f5c\u4e3a\u63a2\u6d4bTransformer\u67b6\u6784\u4e2d\u4fe1\u606f\u5206\u5e03\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u91cf\u5316\u6807\u8bb0\u7ea7\u522b\u7684\u4e0d\u786e\u5b9a\u6027\u5e76\u68c0\u67e5\u4e0d\u540c\u5904\u7406\u9636\u6bb5\u7684\u71b5\u6a21\u5f0f\uff0c\u7814\u7a76\u4fe1\u606f\u5982\u4f55\u5728\u6a21\u578b\u4e2d\u88ab\u7ba1\u7406\u548c\u8f6c\u6362\u3002\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u57fa\u4e8eGPT\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5176\u63ed\u793a\u6a21\u578b\u884c\u4e3a\u548c\u5185\u90e8\u8868\u793a\u7684\u6f5c\u529b\u3002\u8be5\u65b9\u6cd5\u53ef\u80fd\u4e3a\u6a21\u578b\u884c\u4e3a\u63d0\u4f9b\u89c1\u89e3\uff0c\u5e76\u6709\u52a9\u4e8e\u5f00\u53d1\u7528\u4e8e\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u63a2\u7d22\u71b5\u5206\u6790\u4f5c\u4e3a\u63a2\u6d4bTransformer\u67b6\u6784\u4e2d\u4fe1\u606f\u5206\u5e03\u7684\u5de5\u5177\uff0c\u4ee5\u4e86\u89e3\u4fe1\u606f\u5982\u4f55\u5728\u6a21\u578b\u4e2d\u88ab\u7ba1\u7406\u548c\u8f6c\u6362\u3002", "method": "\u71b5\u5206\u6790\u4f5c\u4e3a\u5de5\u5177\uff0c\u7528\u4e8e\u63a2\u6d4bTransformer\u67b6\u6784\u4e2d\u7684\u4fe1\u606f\u5206\u5e03\u3002\u901a\u8fc7\u91cf\u5316\u6807\u8bb0\u7ea7\u522b\u7684\u4e0d\u786e\u5b9a\u6027\u5e76\u68c0\u67e5\u4e0d\u540c\u5904\u7406\u9636\u6bb5\u7684\u71b5\u6a21\u5f0f\uff0c\u7814\u7a76\u4fe1\u606f\u5982\u4f55\u5728\u8fd9\u4e9b\u6a21\u578b\u4e2d\u88ab\u7ba1\u7406\u548c\u8f6c\u6362\u3002", "result": "\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u57fa\u4e8eGPT\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5176\u63ed\u793a\u6a21\u578b\u884c\u4e3a\u548c\u5185\u90e8\u8868\u793a\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u80fd\u4e3a\u6a21\u578b\u884c\u4e3a\u63d0\u4f9b\u89c1\u89e3\uff0c\u5e76\u6709\u52a9\u4e8e\u5f00\u53d1\u7528\u4e8e\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2507.15357", "pdf": "https://arxiv.org/pdf/2507.15357", "abs": "https://arxiv.org/abs/2507.15357", "authors": ["Elisa Sanchez-Bayona", "Rodrigo Agerri"], "title": "Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This paper presents a comprehensive evaluation of the capabilities of Large\nLanguage Models (LLMs) in metaphor interpretation across multiple datasets,\ntasks, and prompt configurations. Although metaphor processing has gained\nsignificant attention in Natural Language Processing (NLP), previous research\nhas been limited to single-dataset evaluations and specific task settings,\noften using artificially constructed data through lexical replacement. We\naddress these limitations by conducting extensive experiments using diverse\npublicly available datasets with inference and metaphor annotations, focusing\non Natural Language Inference (NLI) and Question Answering (QA) tasks. The\nresults indicate that LLMs' performance is more influenced by features like\nlexical overlap and sentence length than by metaphorical content, demonstrating\nthat any alleged emergent abilities of LLMs to understand metaphorical language\nare the result of a combination of surface-level features, in-context learning,\nand linguistic knowledge. This work provides critical insights into the current\ncapabilities and limitations of LLMs in processing figurative language,\nhighlighting the need for more realistic evaluation frameworks in metaphor\ninterpretation tasks. Data and code are publicly available.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9690\u55bb\u89e3\u91ca\u4e2d\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u8868\u73b0\u4e3b\u8981\u53d7\u8868\u9762\u7279\u5f81\u5f71\u54cd\uff0c\u800c\u975e\u9690\u55bb\u5185\u5bb9\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u73b0\u5b9e\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u4ee5\u5f80\u7684\u7814\u7a76\u5c40\u9650\u4e8e\u5355\u4e00\u6570\u636e\u96c6\u8bc4\u4f30\u548c\u7279\u5b9a\u4efb\u52a1\u8bbe\u7f6e\uff0c\u901a\u5e38\u4f7f\u7528\u901a\u8fc7\u8bcd\u6c47\u66ff\u6362\u6784\u9020\u7684\u6570\u636e\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u3002", "method": "\u672c\u6587\u901a\u8fc7\u4f7f\u7528\u591a\u6837\u5316\u7684\u516c\u5f00\u6570\u636e\u96c6\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u4e13\u6ce8\u4e8e\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u548c\u95ee\u7b54\uff08QA\uff09\u4efb\u52a1\uff0c\u4ee5\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9690\u55bb\u89e3\u91ca\u65b9\u9762\u7684\u80fd\u529b\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0cLLMs\u7684\u8868\u73b0\u66f4\u591a\u53d7\u5230\u8bcd\u6c47\u91cd\u53e0\u548c\u53e5\u5b50\u957f\u5ea6\u7b49\u7279\u5f81\u7684\u5f71\u54cd\uff0c\u800c\u4e0d\u662f\u9690\u55bb\u5185\u5bb9\uff0c\u8fd9\u8868\u660e\u4efb\u4f55\u6240\u8c13\u7684LLMs\u7406\u89e3\u9690\u55bb\u8bed\u8a00\u7684\u80fd\u529b\u90fd\u662f\u8868\u9762\u7279\u5f81\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u8bed\u8a00\u77e5\u8bc6\u7684\u7efc\u5408\u7ed3\u679c\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u5173\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9690\u55bb\u7406\u89e3\u65b9\u9762\u7684\u5f53\u524d\u80fd\u529b\u548c\u5c40\u9650\u6027\u7684\u5173\u952e\u89c1\u89e3\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u9690\u55bb\u89e3\u91ca\u4efb\u52a1\u4e2d\u9700\u8981\u66f4\u73b0\u5b9e\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2507.15375", "pdf": "https://arxiv.org/pdf/2507.15375", "abs": "https://arxiv.org/abs/2507.15375", "authors": ["Cheng-Han Chiang", "Xiaofei Wang", "Linjie Li", "Chung-Ching Lin", "Kevin Lin", "Shujie Liu", "Zhendong Wang", "Zhengyuan Yang", "Hung-yi Lee", "Lijuan Wang"], "title": "STITCH: Simultaneous Thinking and Talking with Chunked Reasoning for Spoken Language Models", "categories": ["cs.CL", "eess.AS"], "comment": "Work in progress. Project page: https://d223302.github.io/STITCH/", "summary": "Spoken Language Models (SLMs) are designed to take speech inputs and produce\nspoken responses. However, current SLMs lack the ability to perform an\ninternal, unspoken thinking process before responding. In contrast, humans\ntypically engage in complex mental reasoning internally, enabling them to\ncommunicate ideas clearly and concisely. Thus, integrating an unspoken thought\nprocess into SLMs is highly desirable. While naively generating a complete\nchain-of-thought (CoT) reasoning before starting to talk can enable thinking\nfor SLMs, this induces additional latency for the speech response, as the CoT\nreasoning can be arbitrarily long. To solve this issue, we propose Stitch, a\nnovel generation method that alternates between the generation of unspoken\nreasoning chunks and spoken response chunks. Since the audio duration of a\nchunk of spoken response is much longer than the time to generate the tokens in\na chunk of spoken response, we use the remaining free time to generate the\nunspoken reasoning tokens. When a chunk of audio is played to the user, the\nmodel continues to generate the next unspoken reasoning chunk, achieving\nsimultaneous thinking and talking. Remarkably, Stitch matches the latency of\nbaselines that cannot generate unspoken CoT by design while outperforming those\nbaselines by 15% on math reasoning datasets; Stitch also performs equally well\non non-reasoning datasets as those baseline models. Some animations and\ndemonstrations are on the project page: https://d223302.github.io/STITCH.", "AI": {"tldr": "Stitch\u662f\u4e00\u79cd\u65b0\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u8bed\u97f3\u54cd\u5e94\u7684\u540c\u65f6\u751f\u6210\u975e\u8bed\u97f3\u63a8\u7406\uff0c\u63d0\u9ad8SLMs\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684SLMs\u7f3a\u4e4f\u5728\u56de\u5e94\u524d\u8fdb\u884c\u5185\u90e8\u975e\u8bed\u97f3\u601d\u8003\u8fc7\u7a0b\u7684\u80fd\u529b\uff0c\u800c\u4eba\u7c7b\u901a\u5e38\u4f1a\u8fdb\u884c\u590d\u6742\u7684\u5185\u90e8\u63a8\u7406\uff0c\u56e0\u6b64\u9700\u8981\u5c06\u975e\u8bed\u97f3\u601d\u8003\u8fc7\u7a0b\u96c6\u6210\u5230SLMs\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u751f\u6210\u65b9\u6cd5Stitch\uff0c\u4ea4\u66ff\u751f\u6210\u975e\u8bed\u97f3\u63a8\u7406\u5757\u548c\u8bed\u97f3\u54cd\u5e94\u5757\u3002\u5229\u7528\u8bed\u97f3\u5757\u7684\u97f3\u9891\u6301\u7eed\u65f6\u95f4\u8f83\u957f\u7684\u7279\u70b9\uff0c\u5728\u5269\u4f59\u7a7a\u95f2\u65f6\u95f4\u5185\u751f\u6210\u975e\u8bed\u97f3\u63a8\u7406\u4ee4\u724c\u3002", "result": "Stitch\u5728\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u6bd4\u65e0\u6cd5\u751f\u6210\u975e\u8bed\u97f3CoT\u7684\u57fa\u7ebf\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u540c\u65f6\u5728\u975e\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "Stitch\u80fd\u591f\u5b9e\u73b0\u540c\u65f6\u601d\u8003\u548c\u8bf4\u8bdd\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u65e0\u6cd5\u751f\u6210\u975e\u8bed\u97f3CoT\u7684\u57fa\u7ebf\u6a21\u578b\u76f8\u540c\u7684\u5ef6\u8fdf\uff0c\u5e76\u5728\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b15%\u3002"}}
{"id": "2507.15378", "pdf": "https://arxiv.org/pdf/2507.15378", "abs": "https://arxiv.org/abs/2507.15378", "authors": ["Jierui Li", "Raymond Mooney"], "title": "AlgoSimBench: Identifying Algorithmically Similar Problems for Competitive Programming", "categories": ["cs.CL"], "comment": "19 pages, pre-print only", "summary": "Recent progress in LLMs, such as reasoning models, has demonstrated strong\nabilities to solve complex competitive programming problems, often rivaling top\nhuman competitors. However, it remains underexplored whether these abilities\ngeneralize to relevant domains that are less seen during training. To address\nthis, we introduce AlgoSimBench, a new benchmark designed to assess LLMs'\nability to identify algorithmically similar problems (ASPs)-problems that can\nbe solved using similar algorithmic approaches. AlgoSimBench consists of 1317\nproblems, annotated with 231 distinct fine-grained algorithm tags, from which\nwe curate 402 multiple-choice questions (MCQs), where each question presents\none algorithmically similar problem alongside three textually similar but\nalgorithmically dissimilar distractors. Our evaluation reveals that LLMs\nstruggle to identify ASPs, with the best-performing model (o3-mini) achieving\nonly 65.9% accuracy on the MCQ task. To address this challenge, we propose\nattempted solution matching (ASM), a novel method for improving problem\nsimilarity detection. On our MCQ task, ASM yields an absolute accuracy\nimprovement of 6.7% to 11.7% across different models. We also evaluated code\nembedding models and retrieval methods on similar problem identification. While\nthe adversarial selection of problems degrades the performance to be less than\nrandom, we found that simply summarizing the problem to remove narrative\nelements eliminates the effect, and combining ASM with a keyword-prioritized\nmethod, BM25, can yield up to 52.2% accuracy. Code and data are available at\ngithub.com", "AI": {"tldr": "This paper introduces AlgoSimBench to evaluate LLMs' ability to identify algorithmically similar problems. It proposes ASM to improve problem similarity detection and achieves significant accuracy improvements.", "motivation": "The paper aims to explore whether the abilities of LLMs to solve complex competitive programming problems generalize to less seen domains. It introduces AlgoSimBench to assess LLMs' ability to identify ASPs.", "method": "The paper introduces AlgoSimBench, a benchmark for assessing LLMs' ability to identify ASPs. It also proposes ASM, a novel method for improving problem similarity detection, and evaluates code embedding models and retrieval methods.", "result": "The best-performing model (o3-mini) achieved only 65.9% accuracy on the MCQ task. ASM improved accuracy by 6.7% to 11.7%. Combining ASM with BM25 achieved up to 52.2% accuracy.", "conclusion": "LLMs struggle to identify algorithmically similar problems (ASPs), but the proposed method Attempted Solution Matching (ASM) improves their performance. Combining ASM with BM25 can achieve up to 52.2% accuracy."}}
{"id": "2507.15501", "pdf": "https://arxiv.org/pdf/2507.15501", "abs": "https://arxiv.org/abs/2507.15501", "authors": ["Alexandru Coca", "Mark Gaynor", "Zhenxing Zhang", "Jianpeng Cheng", "Bo-Hsiang Tseng", "Pete Boothroyd", "H\u00e9ctor Martinez Alonso", "Diarmuid \u00d3 S\u00e9aghdha", "Anders Johannsen"], "title": "ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "37 pages, 22 figures. To appear at ACL 2025", "summary": "This work evaluates the potential of large language models (LLMs) to power\ndigital assistants capable of complex action execution. These assistants rely\non pre-trained programming knowledge to execute multi-step goals by composing\nobjects and functions defined in assistant libraries into action execution\nprograms. To achieve this, we develop ASPERA, a framework comprising an\nassistant library simulation and a human-assisted LLM data generation engine.\nOur engine allows developers to guide LLM generation of high-quality tasks\nconsisting of complex user queries, simulation state and corresponding\nvalidation programs, tackling data availability and evaluation robustness\nchallenges. Alongside the framework we release Asper-Bench, an evaluation\ndataset of 250 challenging tasks generated using ASPERA, which we use to show\nthat program generation grounded in custom assistant libraries is a significant\nchallenge to LLMs compared to dependency-free code generation.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9a71\u52a8\u80fd\u591f\u6267\u884c\u590d\u6742\u52a8\u4f5c\u7684\u6570\u5b57\u52a9\u624b\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e86ASPERA\u6846\u67b6\u548cAsper-Bench\u6570\u636e\u96c6\uff0c\u4ee5\u5c55\u793a\u57fa\u4e8e\u81ea\u5b9a\u4e49\u52a9\u624b\u5e93\u7684\u7a0b\u5e8f\u751f\u6210\u5bf9LLMs\u6765\u8bf4\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9a71\u52a8\u80fd\u591f\u6267\u884c\u590d\u6742\u52a8\u4f5c\u7684\u6570\u5b57\u52a9\u624b\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u5f00\u53d1\u4e86ASPERA\u6846\u67b6\uff0c\u5305\u62ec\u52a9\u624b\u5e93\u6a21\u62df\u548c\u4eba\u7c7b\u8f85\u52a9LLM\u6570\u636e\u751f\u6210\u5f15\u64ce\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u4efb\u52a1\u3002", "result": "\u901a\u8fc7ASPERA\u751f\u6210\u4e86250\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u5e76\u5c55\u793a\u4e86\u57fa\u4e8e\u81ea\u5b9a\u4e49\u52a9\u624b\u5e93\u7684\u7a0b\u5e8f\u751f\u6210\u5bf9LLMs\u6765\u8bf4\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "conclusion": "\u7a0b\u5e8f\u751f\u6210\u57fa\u4e8e\u81ea\u5b9a\u4e49\u52a9\u624b\u5e93\u5bf9LLMs\u6765\u8bf4\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\uff0c\u4e0e\u65e0\u4f9d\u8d56\u7684\u4ee3\u7801\u751f\u6210\u76f8\u6bd4\u3002"}}
{"id": "2507.15512", "pdf": "https://arxiv.org/pdf/2507.15512", "abs": "https://arxiv.org/abs/2507.15512", "authors": ["Kaiyan Chang", "Yonghao Shi", "Chenglong Wang", "Hang Zhou", "Chi Hu", "Xiaoqian Liu", "Yingfeng Luo", "Yuan Ge", "Tong Xiao", "Jingbo Zhu"], "title": "Step-level Verifier-guided Hybrid Test-Time Scaling for Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Test-Time Scaling (TTS) is a promising approach to progressively elicit the\nmodel's intelligence during inference. Recently, training-based TTS methods,\nsuch as continued reinforcement learning (RL), have further surged in\npopularity, while training-free TTS methods are gradually fading from\nprominence. However, the additional computation overhead of training amplifies\nthe burden on test-time scaling. In this paper, we focus on training-free TTS\nmethods for reasoning. We first design Conditional Step-level Self-refinement,\na fine-grained sequential scaling method guided by process verification. On top\nof its effectiveness, we further combine it with other classical parallel\nscaling methods at the step level, to introduce a novel inference paradigm\ncalled Hybrid Test-Time Scaling. Extensive experiments on five\ninstruction-tuned LLMs across different scales (3B-14B) and families\ndemonstrate that hybrid strategy incorporating various training-free TTS\nmethods at a fine granularity has considerable potential for expanding the\nreasoning performance boundaries of LLMs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u65e0\u8bad\u7ec3\u7684\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u63a8\u7406\u8303\u5f0f\u2014\u2014\u6df7\u5408\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\uff0c\u901a\u8fc7\u7ed3\u5408\u7ec6\u7c92\u5ea6\u7684\u81ea\u6211\u7cbe\u70bc\u548c\u5176\u4ed6\u7ecf\u5178\u5e76\u884c\u7f29\u653e\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\uff08TTS\uff09\u662f\u4e00\u79cd\u6709\u524d\u9014\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u9010\u6b65\u6fc0\u53d1\u6a21\u578b\u7684\u667a\u80fd\u3002\u7136\u800c\uff0c\u8bad\u7ec3\u5e26\u6765\u7684\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u589e\u52a0\u4e86\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u7684\u8d1f\u62c5\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u4e13\u6ce8\u4e8e\u65e0\u8bad\u7ec3\u7684TTS\u65b9\u6cd5\u8fdb\u884c\u63a8\u7406\u3002", "method": "\u8bbe\u8ba1\u4e86\u6761\u4ef6\u6b65\u7ea7\u81ea\u6211\u7cbe\u70bc\uff0c\u5e76\u5c06\u5176\u4e0e\u5176\u5b83\u7ecf\u5178\u7684\u5e76\u884c\u7f29\u653e\u65b9\u6cd5\u76f8\u7ed3\u5408\uff0c\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u63a8\u7406\u8303\u5f0f\u79f0\u4e3a\u6df7\u5408\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u3002", "result": "\u5728\u4e94\u4e2a\u4e0d\u540c\u89c4\u6a21\uff083B-14B\uff09\u548c\u5bb6\u65cf\u7684\u6307\u4ee4\u8c03\u4f18\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u6df7\u5408\u7b56\u7565\u5728\u7ec6\u7c92\u5ea6\u4e0a\u7ed3\u5408\u5404\u79cd\u65e0\u8bad\u7ec3\u7684TTS\u65b9\u6cd5\uff0c\u5177\u6709\u6269\u5c55\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6027\u80fd\u8fb9\u754c\u7684\u91cd\u8981\u6f5c\u529b\u3002", "conclusion": "\u6df7\u5408\u7b56\u7565\u5728\u7ec6\u7c92\u5ea6\u4e0a\u7ed3\u5408\u5404\u79cd\u65e0\u8bad\u7ec3\u7684TTS\u65b9\u6cd5\uff0c\u5177\u6709\u6269\u5c55\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6027\u80fd\u8fb9\u754c\u7684\u91cd\u8981\u6f5c\u529b\u3002"}}
{"id": "2507.15557", "pdf": "https://arxiv.org/pdf/2507.15557", "abs": "https://arxiv.org/abs/2507.15557", "authors": ["Vitaly Protasov", "Nikolay Babakov", "Daryna Dementieva", "Alexander Panchenko"], "title": "Evaluating Text Style Transfer: A Nine-Language Benchmark for Text Detoxification", "categories": ["cs.CL"], "comment": "preprint", "summary": "Despite recent progress in large language models (LLMs), evaluation of text\ngeneration tasks such as text style transfer (TST) remains a significant\nchallenge. Recent studies (Dementieva et al., 2024; Pauli et al., 2025)\nrevealed a substantial gap between automatic metrics and human judgments.\nMoreover, most prior work focuses exclusively on English, leaving multilingual\nTST evaluation largely unexplored. In this paper, we perform the first\ncomprehensive multilingual study on evaluation of text detoxification system\nacross nine languages: English, Spanish, German, Chinese, Arabic, Hindi,\nUkrainian, Russian, Amharic. Drawing inspiration from the machine translation,\nwe assess the effectiveness of modern neural-based evaluation models alongside\nprompting-based LLM-as-a-judge approaches. Our findings provide a practical\nrecipe for designing more reliable multilingual TST evaluation pipeline in the\ntext detoxification case.", "AI": {"tldr": "\u672c\u6587\u8fdb\u884c\u4e86\u9996\u6b21\u591a\u8bed\u8a00\u6587\u672c\u51c0\u5316\u7cfb\u7edf\u8bc4\u4f30\u7684\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u66f4\u53ef\u9760\u7684\u591a\u8bed\u8a00TST\u8bc4\u4f30\u6d41\u7a0b\u7684\u5b9e\u7528\u65b9\u6848\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u6587\u672c\u751f\u6210\u4efb\u52a1\uff08\u5982\u6587\u672c\u98ce\u683c\u8f6c\u6362TST\uff09\u7684\u8bc4\u4f30\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u6b64\u5916\uff0c\u5927\u591a\u6570\u5148\u524d\u7684\u5de5\u4f5c\u4ec5\u4e13\u6ce8\u4e8e\u82f1\u8bed\uff0c\u800c\u591a\u8bed\u8a00TST\u8bc4\u4f30\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u53d7\u673a\u5668\u7ffb\u8bd1\u7684\u542f\u53d1\uff0c\u6211\u4eec\u8bc4\u4f30\u4e86\u73b0\u4ee3\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u8bc4\u4f30\u6a21\u578b\u4ee5\u53ca\u57fa\u4e8e\u63d0\u793a\u7684LLM-as-a-judge\u65b9\u6cd5\u3002", "result": "\u6211\u4eec\u8fdb\u884c\u4e86\u9996\u6b21\u9488\u5bf9\u4e5d\u79cd\u8bed\u8a00\uff08\u82f1\u8bed\u3001\u897f\u73ed\u7259\u8bed\u3001\u5fb7\u8bed\u3001\u4e2d\u6587\u3001\u963f\u62c9\u4f2f\u8bed\u3001\u5370\u5730\u8bed\u3001\u4e4c\u514b\u5170\u8bed\u3001\u4fc4\u8bed\u3001\u963f\u59c6\u54c8\u62c9\u8bed\uff09\u7684\u6587\u672c\u51c0\u5316\u7cfb\u7edf\u8bc4\u4f30\u7684\u5168\u9762\u591a\u8bed\u8a00\u7814\u7a76\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u66f4\u53ef\u9760\u7684\u591a\u8bed\u8a00\u6587\u672c\u51c0\u5316\u8bc4\u4f30\u6d41\u7a0b\u7684\u5b9e\u7528\u65b9\u6848\u3002"}}
{"id": "2507.15576", "pdf": "https://arxiv.org/pdf/2507.15576", "abs": "https://arxiv.org/abs/2507.15576", "authors": ["Nicolas Poggi", "Shashank Agnihotri", "Margret Keuper"], "title": "Smart Eyes for Silent Threats: VLMs and In-Context Learning for THz Imaging", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Terahertz (THz) imaging enables non-invasive analysis for applications such\nas security screening and material classification, but effective image\nclassification remains challenging due to limited annotations, low resolution,\nand visual ambiguity. We introduce In-Context Learning (ICL) with\nVision-Language Models (VLMs) as a flexible, interpretable alternative that\nrequires no fine-tuning. Using a modality-aligned prompting framework, we adapt\ntwo open-weight VLMs to the THz domain and evaluate them under zero-shot and\none-shot settings. Our results show that ICL improves classification and\ninterpretability in low-data regimes. This is the first application of\nICL-enhanced VLMs to THz imaging, offering a promising direction for\nresource-constrained scientific domains. Code:\n\\href{https://github.com/Nicolas-Poggi/Project_THz_Classification/tree/main}{GitHub\nrepository}.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\uff0c\u7528\u4e8e\u592a\u8d6b\u5179\u6210\u50cf\u7684\u56fe\u50cf\u5206\u7c7b\uff0c\u65e0\u9700\u5fae\u8c03\uff0c\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u4f4e\u6570\u636e\u60c5\u51b5\u4e0b\u7684\u5206\u7c7b\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u592a\u8d6b\u5179\u6210\u50cf\u5728\u5b89\u5168\u68c0\u67e5\u548c\u6750\u6599\u5206\u7c7b\u7b49\u5e94\u7528\u4e2d\u5177\u6709\u975e\u4fb5\u5165\u6027\u5206\u6790\u7684\u4f18\u52bf\uff0c\u4f46\u7531\u4e8e\u6807\u6ce8\u6709\u9650\u3001\u5206\u8fa8\u7387\u4f4e\u548c\u89c6\u89c9\u6a21\u7cca\uff0c\u6709\u6548\u7684\u56fe\u50cf\u5206\u7c7b\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5f15\u5165\u4e86\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u8fdb\u884c\u56fe\u50cf\u5206\u7c7b\u3002\u4f7f\u7528\u6a21\u6001\u5bf9\u9f50\u63d0\u793a\u6846\u67b6\uff0c\u5c06\u4e24\u4e2a\u5f00\u653e\u6743\u91cd\u7684VLM\u9002\u5e94\u5230\u592a\u8d6b\u5179\u9886\u57df\uff0c\u5e76\u5728\u96f6\u6837\u672c\u548c\u5355\u6837\u672c\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6570\u636e\u91cf\u5c11\u7684\u60c5\u51b5\u4e0b\uff0cICL\u63d0\u9ad8\u4e86\u5206\u7c7b\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5c06\u589e\u5f3a\u7684ICL VLM\u5e94\u7528\u4e8e\u592a\u8d6b\u5179\u6210\u50cf\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u79d1\u5b66\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002"}}
{"id": "2507.15586", "pdf": "https://arxiv.org/pdf/2507.15586", "abs": "https://arxiv.org/abs/2507.15586", "authors": ["Xinping Zhao", "Shouzheng Huang", "Yan Zhong", "Xinshuo Hu", "Baotian Hu", "Min Zhang"], "title": "Learning to Extract Rational Evidence via Reinforcement Learning for Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": "16 pages, 7 Figures, 10 Tables", "summary": "Retrieval-Augmented Generation (RAG) effectively improves the accuracy of\nLarge Language Models (LLMs). However, retrieval noises significantly impact\nthe quality of LLMs' generation, necessitating the development of denoising\nmechanisms. Previous methods extract evidence straightforwardly without\nexplicit thinking, which risks filtering out key clues and struggles with\ngeneralization. To this end, we propose LEAR, which learns to extract rational\nevidence by (1) explicitly reasoning to identify potential cues within\nretrieval contents first, and then (2) consciously extracting to avoid omitting\nany key cues helpful for answering questions. Specifically, we frame evidence\nreasoning and evidence extraction into one unified response for end-to-end\ntraining; apply knowledge token masks for disentanglement to derive\nreasoning-based and extraction-based answers; and devise three types of\nverifiable reward functions, including answer, length, and format, to update\nthe model via the policy optimization algorithm. Extensive experiments on three\nbenchmark datasets show the effectiveness of LEAR, providing compact and\nhigh-quality evidence, improving the accuracy of downstream tasks, and\npromoting effective application in online RAG systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.15600", "pdf": "https://arxiv.org/pdf/2507.15600", "abs": "https://arxiv.org/abs/2507.15600", "authors": ["Armin Pournaki"], "title": "Conflicting narratives and polarization on social media", "categories": ["cs.CL", "cs.SI"], "comment": "30 pages, 7 figures", "summary": "Narratives are key interpretative devices by which humans make sense of\npolitical reality. In this work, we show how the analysis of conflicting\nnarratives, i.e. conflicting interpretive lenses through which political\nreality is experienced and told, provides insight into the discursive\nmechanisms of polarization and issue alignment in the public sphere. Building\nupon previous work that has identified ideologically polarized issues in the\nGerman Twittersphere between 2021 and 2023, we analyze the discursive dimension\nof polarization by extracting textual signals of conflicting narratives from\ntweets of opposing opinion groups. Focusing on a selection of salient issues\nand events (the war in Ukraine, Covid, climate change), we show evidence for\nconflicting narratives along two dimensions: (i) different attributions of\nactantial roles to the same set of actants (e.g. diverging interpretations of\nthe role of NATO in the war in Ukraine), and (ii) emplotment of different\nactants for the same event (e.g. Bill Gates in the right-leaning Covid\nnarrative). Furthermore, we provide first evidence for patterns of narrative\nalignment, a discursive strategy that political actors employ to align opinions\nacross issues. These findings demonstrate the use of narratives as an\nanalytical lens into the discursive mechanisms of polarization.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86\u51b2\u7a81\u53d9\u8ff0\u5728\u653f\u6cbb\u6781\u5316\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u63ed\u793a\u4e86\u53d9\u8ff0\u5bf9\u9f50\u4f5c\u4e3a\u4e00\u79cd\u4fee\u8f9e\u7b56\u7565\u7684\u6a21\u5f0f\u3002", "motivation": "\u7814\u7a76\u51b2\u7a81\u53d9\u8ff0\u5982\u4f55\u63d0\u4f9b\u5173\u4e8e\u516c\u5171\u9886\u57df\u4e2d\u6781\u5316\u548c\u8bae\u9898\u5bf9\u9f50\u7684\u4fee\u8f9e\u673a\u5236\u7684\u89c1\u89e3\u3002", "method": "\u901a\u8fc7\u4ece\u5bf9\u7acb\u610f\u89c1\u7fa4\u4f53\u7684\u63a8\u6587\u4e2d\u63d0\u53d6\u51b2\u7a81\u53d9\u8ff0\u7684\u6587\u672c\u4fe1\u53f7\u6765\u5206\u6790\u6781\u5316\u7684\u8bdd\u8bed\u7ef4\u5ea6\u3002", "result": "\u53d1\u73b0\u4e86\u6cbf\u7740\u4e24\u4e2a\u7ef4\u5ea6\u7684\u51b2\u7a81\u53d9\u8ff0\uff1a(i) \u5bf9\u540c\u4e00\u7ec4\u884c\u52a8\u8005\u8d4b\u4e88\u4e0d\u540c\u7684\u884c\u52a8\u89d2\u8272\uff0c(ii) \u4e3a\u540c\u4e00\u4e8b\u4ef6\u8d4b\u4e88\u4e0d\u540c\u7684\u884c\u52a8\u8005\u3002\u6b64\u5916\uff0c\u63d0\u4f9b\u4e86\u53d9\u8ff0\u5bf9\u9f50\u6a21\u5f0f\u7684\u521d\u6b65\u8bc1\u636e\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5c55\u793a\u4e86\u53d9\u8ff0\u4f5c\u4e3a\u5206\u6790\u6781\u5316\u8bdd\u8bed\u673a\u5236\u7684\u900f\u955c\u7684\u7528\u9014\u3002"}}
{"id": "2507.15641", "pdf": "https://arxiv.org/pdf/2507.15641", "abs": "https://arxiv.org/abs/2507.15641", "authors": ["Alessio Pittiglio"], "title": "Leveraging Context for Multimodal Fallacy Classification in Political Debates", "categories": ["cs.CL", "cs.AI"], "comment": "12th Workshop on Argument Mining (ArgMining 2025) @ ACL 2025", "summary": "In this paper, we present our submission to the MM-ArgFallacy2025 shared\ntask, which aims to advance research in multimodal argument mining, focusing on\nlogical fallacies in political debates. Our approach uses pretrained\nTransformer-based models and proposes several ways to leverage context. In the\nfallacy classification subtask, our models achieved macro F1-scores of 0.4444\n(text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showed\nperformance comparable to the text-only model, suggesting potential for\nimprovements.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5bf9MM-ArgFallacy2025\u5171\u4eab\u4efb\u52a1\u7684\u63d0\u4ea4\uff0c\u65e8\u5728\u63a8\u8fdb\u591a\u6a21\u6001\u8bba\u70b9\u6316\u6398\u7684\u7814\u7a76\uff0c\u91cd\u70b9\u662f\u653f\u6cbb\u8fa9\u8bba\u4e2d\u7684\u903b\u8f91\u8c2c\u8bef\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u4e86\u9884\u8bad\u7ec3\u7684\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u51e0\u79cd\u5229\u7528\u4e0a\u4e0b\u6587\u7684\u65b9\u6cd5\u3002\u5728\u8c2c\u8bef\u5206\u7c7b\u5b50\u4efb\u52a1\u4e2d\uff0c\u6211\u4eec\u7684\u6a21\u578b\u83b7\u5f97\u4e860.4444\uff08\u6587\u672c\uff09\u30010.3559\uff08\u97f3\u9891\uff09\u548c0.4403\uff08\u591a\u6a21\u6001\uff09\u7684\u5b8fF1\u5206\u6570\u3002\u6211\u4eec\u7684\u591a\u6a21\u6001\u6a21\u578b\u8868\u73b0\u4e0e\u6587\u672c\u6a21\u578b\u76f8\u5f53\uff0c\u8868\u660e\u6709\u6539\u8fdb\u7684\u6f5c\u529b\u3002", "motivation": "\u63a8\u8fdb\u591a\u6a21\u6001\u8bba\u70b9\u6316\u6398\u7684\u7814\u7a76\uff0c\u91cd\u70b9\u5173\u6ce8\u653f\u6cbb\u8fa9\u8bba\u4e2d\u7684\u903b\u8f91\u8c2c\u8bef\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u51e0\u79cd\u5229\u7528\u4e0a\u4e0b\u6587\u7684\u65b9\u6cd5\u3002", "result": "\u5728\u8c2c\u8bef\u5206\u7c7b\u5b50\u4efb\u52a1\u4e2d\uff0c\u6211\u4eec\u7684\u6a21\u578b\u83b7\u5f97\u4e860.4444\uff08\u6587\u672c\uff09\u30010.3559\uff08\u97f3\u9891\uff09\u548c0.4403\uff08\u591a\u6a21\u6001\uff09\u7684\u5b8fF1\u5206\u6570\u3002", "conclusion": "\u6211\u4eec\u7684\u591a\u6a21\u6001\u6a21\u578b\u8868\u73b0\u4e0e\u6587\u672c\u6a21\u578b\u76f8\u5f53\uff0c\u8868\u660e\u6709\u6539\u8fdb\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.15675", "pdf": "https://arxiv.org/pdf/2507.15675", "abs": "https://arxiv.org/abs/2507.15675", "authors": ["Xinyu Zhang", "Yuanquan Hu", "Fangchao Liu", "Zhicheng Dou"], "title": "P3: Prompts Promote Prompting", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 findings", "summary": "Current large language model (LLM) applications often employ multi-component\nprompts, comprising both system and user prompts, to guide model behaviors.\nWhile recent advancements have demonstrated the efficacy of automatically\noptimizing either the system or user prompt to boost performance, such\nunilateral approaches often yield suboptimal outcomes due to the interdependent\nnature of these components. In this work, we introduce P3, a novel\nself-improvement framework that concurrently optimizes both system and user\nprompts through an iterative process. The offline optimized prompts are further\nleveraged to promote online prompting by performing query-dependent prompt\noptimization. Extensive experiments on general tasks (e.g., Arena-hard and\nAlpaca-eval) and reasoning tasks (e.g., GSM8K and GPQA) demonstrate that P3\nachieves superior performance in the realm of automatic prompt optimization.\nOur results highlight the effectiveness of a holistic optimization strategy in\nenhancing LLM performance across diverse domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aP3\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u8fc7\u7a0b\u540c\u65f6\u4f18\u5316\u7cfb\u7edf\u548c\u7528\u6237\u63d0\u793a\uff0c\u5e76\u5229\u7528\u79bb\u7ebf\u4f18\u5316\u7684\u63d0\u793a\u6765\u4fc3\u8fdb\u5728\u7ebf\u63d0\u793a\u3002\u5b9e\u9a8c\u8868\u660e\uff0cP3\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u5168\u9762\u4f18\u5316\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5e94\u7528\u901a\u5e38\u4f7f\u7528\u591a\u7ec4\u4ef6\u63d0\u793a\uff0c\u5305\u62ec\u7cfb\u7edf\u63d0\u793a\u548c\u7528\u6237\u63d0\u793a\uff0c\u4ee5\u6307\u5bfc\u6a21\u578b\u884c\u4e3a\u3002\u867d\u7136\u6700\u8fd1\u7684\u8fdb\u5c55\u5df2\u7ecf\u8bc1\u660e\u4e86\u81ea\u52a8\u4f18\u5316\u7cfb\u7edf\u6216\u7528\u6237\u63d0\u793a\u7684\u6709\u6548\u6027\uff0c\u4f46\u8fd9\u79cd\u5355\u8fb9\u65b9\u6cd5\u7531\u4e8e\u8fd9\u4e9b\u7ec4\u4ef6\u4e4b\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u6027\uff0c\u5f80\u5f80\u4ea7\u751f\u6b21\u4f18\u7ed3\u679c\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86P3\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u81ea\u6211\u6539\u8fdb\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u8fc7\u7a0b\u540c\u65f6\u4f18\u5316\u7cfb\u7edf\u548c\u7528\u6237\u63d0\u793a\u3002\u79bb\u7ebf\u4f18\u5316\u7684\u63d0\u793a\u8fdb\u4e00\u6b65\u7528\u4e8e\u4fc3\u8fdb\u5728\u7ebf\u63d0\u793a\uff0c\u901a\u8fc7\u6267\u884c\u4f9d\u8d56\u4e8e\u67e5\u8be2\u7684\u63d0\u793a\u4f18\u5316\u3002", "result": "\u5728\u901a\u7528\u4efb\u52a1\uff08\u4f8b\u5982Arena-hard\u548cAlpaca-eval\uff09\u548c\u63a8\u7406\u4efb\u52a1\uff08\u4f8b\u5982GSM8K\u548cGPQA\uff09\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cP3\u5728\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u9886\u57df\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u6211\u4eec\u7684\u7ed3\u679c\u5f3a\u8c03\u4e86\u5168\u9762\u4f18\u5316\u7b56\u7565\u5728\u63d0\u9ad8\u8de8\u4e0d\u540c\u9886\u57df\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.15698", "pdf": "https://arxiv.org/pdf/2507.15698", "abs": "https://arxiv.org/abs/2507.15698", "authors": ["Congmin Zheng", "Jiachen Zhu", "Jianghao Lin", "Xinyi Dai", "Yong Yu", "Weinan Zhang", "Mengyue Yang"], "title": "CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Process Reward Models (PRMs) play a central role in evaluating and guiding\nmulti-step reasoning in large language models (LLMs), especially for\nmathematical problem solving. However, we identify a pervasive length bias in\nexisting PRMs: they tend to assign higher scores to longer reasoning steps,\neven when the semantic content and logical validity are unchanged. This bias\nundermines the reliability of reward predictions and leads to overly verbose\noutputs during inference. To address this issue, we propose\nCoLD(Counterfactually-Guided Length Debiasing), a unified framework that\nmitigates length bias through three components: an explicit length-penalty\nadjustment, a learned bias estimator trained to capture spurious length-related\nsignals, and a joint training strategy that enforces length-invariance in\nreward predictions. Our approach is grounded in counterfactual reasoning and\ninformed by causal graph analysis. Extensive experiments on MATH500 and\nGSM-Plus show that CoLD consistently reduces reward-length correlation,\nimproves accuracy in step selection, and encourages more concise, logically\nvalid reasoning. These results demonstrate the effectiveness and practicality\nof CoLD in improving the fidelity and robustness of PRMs.", "AI": {"tldr": "This paper addresses the length bias in Process Reward Models (PRMs) by proposing CoLD, a framework that reduces bias through length-penalty adjustment, bias estimation, and joint training, leading to more accurate and concise reasoning.", "motivation": "Existing PRMs exhibit a pervasive length bias, assigning higher scores to longer reasoning steps even when the semantic content and logical validity remain unchanged, which undermines reliability and leads to verbose outputs.", "method": "CoLD is a unified framework that mitigates length bias through three components: an explicit length-penalty adjustment, a learned bias estimator, and a joint training strategy.", "result": "CoLD consistently reduces reward-length correlation, improves accuracy in step selection, and encourages more concise, logically valid reasoning.", "conclusion": "CoLD demonstrates effectiveness and practicality in improving the fidelity and robustness of PRMs."}}
{"id": "2507.15706", "pdf": "https://arxiv.org/pdf/2507.15706", "abs": "https://arxiv.org/abs/2507.15706", "authors": ["David Peter Wallis Freeborn"], "title": "Compositional Understanding in Signaling Games", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Receivers in standard signaling game models struggle with learning\ncompositional information. Even when the signalers send compositional messages,\nthe receivers do not interpret them compositionally. When information from one\nmessage component is lost or forgotten, the information from other components\nis also erased. In this paper I construct signaling game models in which\ngenuine compositional understanding evolves. I present two new models: a\nminimalist receiver who only learns from the atomic messages of a signal, and a\ngeneralist receiver who learns from all of the available information. These\nmodels are in many ways simpler than previous alternatives, and allow the\nreceivers to learn from the atomic components of messages.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u4fe1\u53f7\u535a\u5f08\u6a21\u578b\uff0c\u5176\u4e2d\u771f\u6b63\u7684\u7ec4\u5408\u7406\u89e3\u53ef\u4ee5\u8fdb\u5316\u3002\u63d0\u51fa\u4e86\u4e24\u4e2a\u65b0\u6a21\u578b\uff1a\u4e00\u4e2a\u662f\u6700\u5c0f\u5316\u63a5\u6536\u8005\uff0c\u53ea\u4ece\u539f\u5b50\u6d88\u606f\u4e2d\u5b66\u4e60\uff1b\u53e6\u4e00\u4e2a\u662f\u901a\u624d\u63a5\u6536\u8005\uff0c\u4ece\u6240\u6709\u53ef\u7528\u4fe1\u606f\u4e2d\u5b66\u4e60\u3002\u8fd9\u4e9b\u6a21\u578b\u6bd4\u4e4b\u524d\u7684\u66ff\u4ee3\u65b9\u6848\u66f4\u7b80\u5355\uff0c\u5e76\u5141\u8bb8\u63a5\u6536\u8005\u4ece\u6d88\u606f\u7684\u539f\u5b50\u7ec4\u4ef6\u4e2d\u5b66\u4e60\u3002", "motivation": "\u6807\u51c6\u4fe1\u53f7\u535a\u5f08\u6a21\u578b\u4e2d\u7684\u63a5\u6536\u8005\u5728\u5b66\u4e60\u7ec4\u5408\u4fe1\u606f\u65f6\u9047\u5230\u56f0\u96be\u3002\u5373\u4f7f\u53d1\u9001\u8005\u53d1\u9001\u7ec4\u5408\u4fe1\u606f\uff0c\u63a5\u6536\u8005\u4e5f\u4e0d\u4f1a\u4ee5\u7ec4\u5408\u65b9\u5f0f\u89e3\u91ca\u5b83\u4eec\u3002\u5f53\u4e00\u4e2a\u4fe1\u606f\u7ec4\u4ef6\u7684\u4fe1\u606f\u4e22\u5931\u6216\u88ab\u9057\u5fd8\u65f6\uff0c\u5176\u4ed6\u7ec4\u4ef6\u7684\u4fe1\u606f\u4e5f\u4f1a\u88ab\u5220\u9664\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u4e2a\u65b0\u7684\u6a21\u578b\uff1a\u4e00\u4e2a\u662f\u6700\u5c0f\u5316\u7684\u63a5\u6536\u8005\uff0c\u53ea\u4ece\u4fe1\u53f7\u7684\u539f\u5b50\u6d88\u606f\u4e2d\u5b66\u4e60\uff1b\u53e6\u4e00\u4e2a\u662f\u901a\u624d\u63a5\u6536\u8005\uff0c\u4ece\u6240\u6709\u53ef\u7528\u4fe1\u606f\u4e2d\u5b66\u4e60\u3002", "result": "\u8fd9\u4e9b\u6a21\u578b\u5728\u5f88\u591a\u65b9\u9762\u6bd4\u4e4b\u524d\u7684\u66ff\u4ee3\u65b9\u6848\u66f4\u7b80\u5355\uff0c\u5e76\u5141\u8bb8\u63a5\u6536\u8005\u4ece\u6d88\u606f\u7684\u539f\u5b50\u7ec4\u4ef6\u4e2d\u5b66\u4e60\u3002", "conclusion": "\u672c\u6587\u6784\u9020\u4e86\u4fe1\u53f7\u535a\u5f08\u6a21\u578b\uff0c\u5176\u4e2d\u771f\u6b63\u7684\u7ec4\u5408\u7406\u89e3\u53ef\u4ee5\u8fdb\u5316\u3002"}}
{"id": "2507.15707", "pdf": "https://arxiv.org/pdf/2507.15707", "abs": "https://arxiv.org/abs/2507.15707", "authors": ["Seok Hwan Song", "Mohna Chakraborty", "Qi Li", "Wallapak Tavanapong"], "title": "Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have been evaluated using diverse question\ntypes, e.g., multiple-choice, true/false, and short/long answers. This study\nanswers an unexplored question about the impact of different question types on\nLLM accuracy on reasoning tasks. We investigate the performance of five LLMs on\nthree different types of questions using quantitative and deductive reasoning\ntasks. The performance metrics include accuracy in the reasoning steps and\nchoosing the final answer. Key Findings: (1) Significant differences exist in\nLLM performance across different question types. (2) Reasoning accuracy does\nnot necessarily correlate with the final selection accuracy. (3) The number of\noptions and the choice of words, influence LLM performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u95ee\u9898\u7c7b\u578b\u5bf9\u6a21\u578b\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e14\u63a8\u7406\u51c6\u786e\u6027\u4e0e\u6700\u7ec8\u7b54\u6848\u9009\u62e9\u51c6\u786e\u6027\u4e4b\u95f4\u6ca1\u6709\u5fc5\u7136\u76f8\u5173\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u8fd9\u662f\u4e00\u4e2a\u5c1a\u672a\u88ab\u6df1\u5165\u7814\u7a76\u7684\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u5b9a\u91cf\u548c\u6f14\u7ece\u63a8\u7406\u4efb\u52a1\uff0c\u8bc4\u4f30\u4e86\u4e94\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e09\u79cd\u4e0d\u540c\u7c7b\u578b\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e14\u63a8\u7406\u6b65\u9aa4\u7684\u51c6\u786e\u6027\u4e0e\u6700\u7ec8\u7b54\u6848\u7684\u9009\u62e9\u51c6\u786e\u6027\u4e4b\u95f4\u6ca1\u6709\u76f4\u63a5\u5173\u8054\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u7c7b\u578b\u7684\u9898\u76ee\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e14\u63a8\u7406\u51c6\u786e\u6027\u4e0e\u6700\u7ec8\u9009\u62e9\u51c6\u786e\u6027\u4e4b\u95f4\u6ca1\u6709\u5fc5\u7136\u7684\u76f8\u5173\u6027\u3002"}}
{"id": "2507.15714", "pdf": "https://arxiv.org/pdf/2507.15714", "abs": "https://arxiv.org/abs/2507.15714", "authors": ["Tian Li", "Yujian Sun", "Huizhi Liang"], "title": "Chinchunmei at SemEval-2025 Task 11: Boosting the Large Language Model's Capability of Emotion Perception using Contrastive Learning", "categories": ["cs.CL"], "comment": null, "summary": "The SemEval-2025 Task 11, Bridging the Gap in Text-Based Emotion Detection,\nintroduces an emotion recognition challenge spanning over 28 languages. This\ncompetition encourages researchers to explore more advanced approaches to\naddress the challenges posed by the diversity of emotional expressions and\nbackground variations. It features two tracks: multi-label classification\n(Track A) and emotion intensity prediction (Track B), covering six emotion\ncategories: anger, fear, joy, sadness, surprise, and disgust. In our work, we\nsystematically explore the benefits of two contrastive learning approaches:\nsample-based (Contrastive Reasoning Calibration) and generation-based (DPO,\nSimPO) contrastive learning. The sample-based contrastive approach trains the\nmodel by comparing two samples to generate more reliable predictions. The\ngeneration-based contrastive approach trains the model to differentiate between\ncorrect and incorrect generations, refining its prediction. All models are\nfine-tuned from LLaMa3-Instruct-8B. Our system achieves 9th place in Track A\nand 6th place in Track B for English, while ranking among the top-tier\nperforming systems for other languages.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SemEval-2025\u4efb\u52a111\uff0c\u8fd9\u662f\u4e00\u4e2a\u8de828\u79cd\u8bed\u8a00\u7684\u60c5\u7eea\u8bc6\u522b\u6311\u6218\u3002\u6211\u4eec\u63a2\u7d22\u4e86\u4e24\u79cd\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff1a\u57fa\u4e8e\u6837\u672c\u7684\u5bf9\u6bd4\u63a8\u7406\u6821\u51c6\u548c\u57fa\u4e8e\u751f\u6210\u7684DPO\u3001SimPO\u5bf9\u6bd4\u5b66\u4e60\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u5728\u82f1\u8bed\u7684Track A\u4e2d\u83b7\u5f97\u7b2c9\u540d\uff0c\u5728Track B\u4e2d\u83b7\u5f97\u7b2c6\u540d\uff0c\u5e76\u5728\u5176\u4ed6\u8bed\u8a00\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "SemEval-2025\u4efb\u52a111\u65e8\u5728\u5f15\u5165\u4e00\u4e2a\u8de8\u8d8a28\u79cd\u8bed\u8a00\u7684\u60c5\u7eea\u8bc6\u522b\u6311\u6218\uff0c\u9f13\u52b1\u7814\u7a76\u4eba\u5458\u63a2\u7d22\u66f4\u5148\u8fdb\u7684\u65b9\u6cd5\u6765\u5e94\u5bf9\u60c5\u611f\u8868\u8fbe\u591a\u6837\u6027\u548c\u80cc\u666f\u53d8\u5316\u5e26\u6765\u7684\u6311\u6218\u3002", "method": "\u6211\u4eec\u7cfb\u7edf\u5730\u63a2\u7d22\u4e86\u4e24\u79cd\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u7684\u4f18\u52bf\uff1a\u57fa\u4e8e\u6837\u672c\u7684\uff08\u5bf9\u6bd4\u63a8\u7406\u6821\u51c6\uff09\u548c\u57fa\u4e8e\u751f\u6210\u7684\uff08DPO\uff0cSimPO\uff09\u5bf9\u6bd4\u5b66\u4e60\u3002\u57fa\u4e8e\u6837\u672c\u7684\u5bf9\u6bd4\u65b9\u6cd5\u901a\u8fc7\u6bd4\u8f83\u4e24\u4e2a\u6837\u672c\u6765\u8bad\u7ec3\u6a21\u578b\u4ee5\u751f\u6210\u66f4\u53ef\u9760\u7684\u9884\u6d4b\u3002\u57fa\u4e8e\u751f\u6210\u7684\u5bf9\u6bd4\u65b9\u6cd5\u8bad\u7ec3\u6a21\u578b\u533a\u5206\u6b63\u786e\u548c\u9519\u8bef\u7684\u751f\u6210\uff0c\u4ece\u800c\u4f18\u5316\u5176\u9884\u6d4b\u3002\u6240\u6709\u6a21\u578b\u90fd\u662f\u4eceLLaMa3-Instruct-8B\u8fdb\u884c\u5fae\u8c03\u7684\u3002", "result": "\u6211\u4eec\u7684\u7cfb\u7edf\u5728\u82f1\u8bed\u7684Track A\u4e2d\u83b7\u5f97\u4e86\u7b2c9\u540d\uff0c\u5728Track B\u4e2d\u83b7\u5f97\u4e86\u7b2c6\u540d\uff0c\u5e76\u5728\u5176\u4ed6\u8bed\u8a00\u4e2d\u8dfb\u8eab\u9876\u7ea7\u8868\u73b0\u7cfb\u7edf\u4e4b\u5217\u3002", "conclusion": "\u6211\u4eec\u7684\u7cfb\u7edf\u5728\u82f1\u8bed\u7684Track A\u4e2d\u83b7\u5f97\u4e86\u7b2c9\u540d\uff0c\u5728Track B\u4e2d\u83b7\u5f97\u4e86\u7b2c6\u540d\uff0c\u5e76\u5728\u5176\u4ed6\u8bed\u8a00\u4e2d\u8dfb\u8eab\u9876\u7ea7\u8868\u73b0\u7cfb\u7edf\u4e4b\u5217\u3002"}}
{"id": "2507.15715", "pdf": "https://arxiv.org/pdf/2507.15715", "abs": "https://arxiv.org/abs/2507.15715", "authors": ["Alina Hyk", "Kiera McCormick", "Mian Zhong", "Ioana Ciuc\u0103", "Sanjib Sharma", "John F Wu", "J. E. G. Peek", "Kartheik G. Iyer", "Ziang Xiao", "Anjalie Field"], "title": "From Queries to Criteria: Understanding How Astronomers Evaluate LLMs", "categories": ["cs.CL", "astro-ph.IM"], "comment": "Accepted to the Conference on Language Modeling 2025 (COLM), 22\n  pages, 6 figures", "summary": "There is growing interest in leveraging LLMs to aid in astronomy and other\nscientific research, but benchmarks for LLM evaluation in general have not kept\npace with the increasingly diverse ways that real people evaluate and use these\nmodels. In this study, we seek to improve evaluation procedures by building an\nunderstanding of how users evaluate LLMs. We focus on a particular use case: an\nLLM-powered retrieval-augmented generation bot for engaging with astronomical\nliterature, which we deployed via Slack. Our inductive coding of 368 queries to\nthe bot over four weeks and our follow-up interviews with 11 astronomers reveal\nhow humans evaluated this system, including the types of questions asked and\nthe criteria for judging responses. We synthesize our findings into concrete\nrecommendations for building better benchmarks, which we then employ in\nconstructing a sample benchmark for evaluating LLMs for astronomy. Overall, our\nwork offers ways to improve LLM evaluation and ultimately usability,\nparticularly for use in scientific research.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u7528\u6237\u5982\u4f55\u8bc4\u4f30LLM\u7cfb\u7edf\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u8bc4\u4f30\u57fa\u51c6\u7684\u5efa\u8bae\uff0c\u4ee5\u63d0\u9ad8LLM\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u53ef\u7528\u6027\u3002", "motivation": "\u7531\u4e8eLLM\u5728\u5929\u6587\u5b66\u548c\u5176\u4ed6\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u52a0\uff0c\u4f46\u8bc4\u4f30\u57fa\u51c6\u5e76\u672a\u8ddf\u4e0a\u5b9e\u9645\u7528\u6237\u8bc4\u4f30\u548c\u4f7f\u7528\u8fd9\u4e9b\u6a21\u578b\u7684\u591a\u6837\u5316\u65b9\u5f0f\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u8bc4\u4f30\u7a0b\u5e8f\u3002", "method": "\u6211\u4eec\u901a\u8fc7\u5206\u6790368\u4e2a\u67e5\u8be2\u548c\u5bf911\u4f4d\u5929\u6587\u5b66\u5bb6\u7684\u540e\u7eed\u8bbf\u8c08\uff0c\u4e86\u89e3\u7528\u6237\u5982\u4f55\u8bc4\u4f30LLM\u7cfb\u7edf\u3002", "result": "\u6211\u4eec\u63d0\u51fa\u4e86\u6784\u5efa\u66f4\u597d\u57fa\u51c6\u7684\u5177\u4f53\u5efa\u8bae\uff0c\u5e76\u636e\u6b64\u6784\u5efa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5929\u6587\u5b66\u4e2dLLM\u7684\u793a\u4f8b\u57fa\u51c6\u3002", "conclusion": "\u6211\u4eec\u7684\u5de5\u4f5c\u63d0\u4f9b\u4e86\u6539\u8fdbLLM\u8bc4\u4f30\u548c\u6700\u7ec8\u53ef\u7528\u6027\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u4f7f\u7528\u3002"}}
{"id": "2507.15717", "pdf": "https://arxiv.org/pdf/2507.15717", "abs": "https://arxiv.org/abs/2507.15717", "authors": ["Sahana Srinivasan", "Xuguang Ai", "Thaddaeus Wai Soon Lo", "Aidan Gilson", "Minjie Zou", "Ke Zou", "Hyunjae Kim", "Mingjia Yang", "Krithi Pushpanathan", "Samantha Yew", "Wan Ting Loke", "Jocelyn Goh", "Yibing Chen", "Yiming Kong", "Emily Yuelei Fu", "Michelle Ongyong Hui", "Kristen Nwanyanwu", "Amisha Dave", "Kelvin Zhenghao Li", "Chen-Hsin Sun", "Mark Chia", "Gabriel Dawei Yang", "Wendy Meihua Wong", "David Ziyou Chen", "Dianbo Liu", "Maxwell Singer", "Fares Antaki", "Lucian V Del Priore", "Jost Jonas", "Ron Adelman", "Qingyu Chen", "Yih-Chung Tham"], "title": "BEnchmarking LLMs for Ophthalmology (BELO) for Ophthalmological Knowledge and Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Current benchmarks evaluating large language models (LLMs) in ophthalmology\nare limited in scope and disproportionately prioritise accuracy. We introduce\nBELO (BEnchmarking LLMs for Ophthalmology), a standardized and comprehensive\nevaluation benchmark developed through multiple rounds of expert checking by 13\nophthalmologists. BELO assesses ophthalmology-related clinical accuracy and\nreasoning quality. Using keyword matching and a fine-tuned PubMedBERT model, we\ncurated ophthalmology-specific multiple-choice-questions (MCQs) from diverse\nmedical datasets (BCSC, MedMCQA, MedQA, BioASQ, and PubMedQA). The dataset\nunderwent multiple rounds of expert checking. Duplicate and substandard\nquestions were systematically removed. Ten ophthalmologists refined the\nexplanations of each MCQ's correct answer. This was further adjudicated by\nthree senior ophthalmologists. To illustrate BELO's utility, we evaluated six\nLLMs (OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, and Gemini 1.5 Pro)\nusing accuracy, macro-F1, and five text-generation metrics (ROUGE-L, BERTScore,\nBARTScore, METEOR, and AlignScore). In a further evaluation involving human\nexperts, two ophthalmologists qualitatively reviewed 50 randomly selected\noutputs for accuracy, comprehensiveness, and completeness. BELO consists of 900\nhigh-quality, expert-reviewed questions aggregated from five sources: BCSC\n(260), BioASQ (10), MedMCQA (572), MedQA (40), and PubMedQA (18). A public\nleaderboard has been established to promote transparent evaluation and\nreporting. Importantly, the BELO dataset will remain a hold-out,\nevaluation-only benchmark to ensure fair and reproducible comparisons of future\nmodels.", "AI": {"tldr": "BELO \u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u773c\u79d1\u9886\u57df\u8868\u73b0\u7684\u6807\u51c6\u5316\u3001\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b900\u4e2a\u9ad8\u8d28\u91cf\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u591a\u8f6e\u4e13\u5bb6\u5ba1\u6838\u786e\u4fdd\u5176\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u773c\u79d1\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\u8303\u56f4\u6709\u9650\uff0c\u4e14\u8fc7\u4e8e\u4fa7\u91cd\u51c6\u786e\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u5168\u9762\u3001\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u57fa\u51c6\u6765\u66f4\u597d\u5730\u8861\u91cfLLMs\u5728\u773c\u79d1\u9886\u57df\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u591a\u6b21\u4e13\u5bb6\u68c0\u67e5\uff0c\u4ece\u591a\u4e2a\u533b\u5b66\u6570\u636e\u96c6\u4e2d\uff08\u5982BCSC\u3001MedMCQA\u3001MedQA\u3001BioASQ\u548cPubMedQA\uff09\u7b5b\u9009\u51fa\u773c\u79d1\u76f8\u5173\u7684\u591a\u9879\u9009\u62e9\u9898\uff08MCQs\uff09\uff0c\u5e76\u4f7f\u7528\u5173\u952e\u8bcd\u5339\u914d\u548c\u5fae\u8c03\u7684PubMedBERT\u6a21\u578b\u8fdb\u884c\u6574\u7406\u3002\u6b64\u5916\uff0c\u8fd8\u8fdb\u884c\u4e86\u4eba\u5de5\u5ba1\u6838\u548c\u4e13\u5bb6\u8bc4\u5ba1\uff0c\u4ee5\u786e\u4fdd\u95ee\u9898\u7684\u8d28\u91cf\u548c\u51c6\u786e\u6027\u3002", "result": "BELO \u5305\u542b900\u4e2a\u9ad8\u8d28\u91cf\u3001\u7ecf\u8fc7\u4e13\u5bb6\u5ba1\u6838\u7684\u95ee\u9898\uff0c\u6765\u81ea\u4e94\u4e2a\u6765\u6e90\u3002\u5bf9\u516d\u4e2aLLMs\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5305\u62ec\u51c6\u786e\u6027\u3001\u5b8fF1\u548c\u4e94\u79cd\u6587\u672c\u751f\u6210\u6307\u6807\u3002\u6b64\u5916\uff0c\u8fd8\u8fdb\u884c\u4e86\u4eba\u7c7b\u4e13\u5bb6\u7684\u5b9a\u6027\u8bc4\u4f30\u3002\u540c\u65f6\uff0c\u5efa\u7acb\u4e86\u516c\u5f00\u6392\u884c\u699c\u4ee5\u4fc3\u8fdb\u900f\u660e\u8bc4\u4f30\u548c\u62a5\u544a\u3002", "conclusion": "BELO \u662f\u4e00\u4e2a\u6807\u51c6\u5316\u548c\u5168\u9762\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u65e8\u5728\u8bc4\u4f30\u773c\u79d1\u76f8\u5173\u4e34\u5e8a\u51c6\u786e\u6027\u548c\u63a8\u7406\u8d28\u91cf\u3002\u8be5\u6570\u636e\u96c6\u7ecf\u8fc7\u591a\u8f6e\u4e13\u5bb6\u5ba1\u6838\uff0c\u786e\u4fdd\u9ad8\u8d28\u91cf\uff0c\u5e76\u4e14\u5c06\u4f5c\u4e3a\u4fdd\u7559\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u4ee5\u786e\u4fdd\u672a\u6765\u6a21\u578b\u6bd4\u8f83\u7684\u516c\u5e73\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2507.15736", "pdf": "https://arxiv.org/pdf/2507.15736", "abs": "https://arxiv.org/abs/2507.15736", "authors": ["Yuanhao Shen", "Daniel Xavier de Sousa", "Ricardo Mar\u00e7al", "Ali Asad", "Hongyu Guo", "Xiaodan Zhu"], "title": "Understanding Large Language Models' Ability on Interdisciplinary Research", "categories": ["cs.CL"], "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have revealed their\nimpressive ability to perform multi-step, logic-driven reasoning across complex\ndomains, positioning them as powerful tools and collaborators in scientific\ndiscovery while challenging the long-held view that inspiration-driven ideation\nis uniquely human. However, the lack of a dedicated benchmark that evaluates\nLLMs' ability to develop ideas in Interdisciplinary Research (IDR) settings\nposes a critical barrier to fully understanding their strengths and\nlimitations. To address this gap, we introduce IDRBench -- a pioneering\nbenchmark featuring an expert annotated dataset and a suite of tasks tailored\nto evaluate LLMs' capabilities in proposing valuable research ideas from\ndifferent scientific domains for interdisciplinary research. This benchmark\naims to provide a systematic framework for assessing LLM performance in\ncomplex, cross-domain scientific research. Our dataset consists of scientific\npublications sourced from the ArXiv platform covering six distinct disciplines,\nand is annotated by domain experts with diverse academic backgrounds. To ensure\nhigh-quality annotations, we emphasize clearly defined dimensions that\ncharacterize authentic interdisciplinary research. The design of evaluation\ntasks in IDRBench follows a progressive, real-world perspective, reflecting the\nnatural stages of interdisciplinary research development, including 1) IDR\nPaper Identification, 2) IDR Idea Integration, and 3) IDR Idea Recommendation.\nUsing IDRBench, we construct baselines across 10 LLMs and observe that despite\nfostering some level of IDR awareness, LLMs still struggle to produce quality\nIDR ideas. These findings could not only spark new research directions, but\nalso help to develop next-generation LLMs that excel in interdisciplinary\nresearch.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86IDRBench\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u5b66\u79d1\u7814\u7a76\u4e2d\u63d0\u51fa\u6709\u4ef7\u503c\u7814\u7a76\u60f3\u6cd5\u80fd\u529b\u7684\u57fa\u51c6\u3002", "motivation": "\u7f3a\u4e4f\u4e00\u4e2a\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u8bc4\u4f30LLMs\u5728\u8de8\u5b66\u79d1\u7814\u7a76\uff08IDR\uff09\u73af\u5883\u4e2d\u7684\u80fd\u529b\uff0c\u8fd9\u963b\u788d\u4e86\u5bf9\u5176\u4f18\u52bf\u548c\u5c40\u9650\u6027\u7684\u5168\u9762\u7406\u89e3\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86IDRBench\u2014\u2014\u4e00\u4e2a\u5f00\u521b\u6027\u7684\u57fa\u51c6\uff0c\u5305\u62ec\u4e13\u5bb6\u6ce8\u91ca\u7684\u6570\u636e\u96c6\u548c\u4e00\u5957\u9488\u5bf9\u8bc4\u4f30LLM\u5728\u8de8\u5b66\u79d1\u7814\u7a76\u4e2d\u63d0\u51fa\u6709\u4ef7\u503c\u7814\u7a76\u60f3\u6cd5\u7684\u80fd\u529b\u7684\u4efb\u52a1\u3002", "result": "\u5c3d\u7ba1LLM\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u4fc3\u8fdb\u4e86IDR\u610f\u8bc6\uff0c\u4f46\u5b83\u4eec\u4ecd\u7136\u96be\u4ee5\u4ea7\u751f\u9ad8\u8d28\u91cf\u7684IDR\u60f3\u6cd5\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e0d\u4ec5\u53ef\u4ee5\u6fc0\u53d1\u65b0\u7684\u7814\u7a76\u65b9\u5411\uff0c\u8fd8\u53ef\u4ee5\u5e2e\u52a9\u5f00\u53d1\u5728\u8de8\u5b66\u79d1\u7814\u7a76\u4e2d\u8868\u73b0\u51fa\u8272\u7684\u4e0b\u4e00\u4ee3LLM\u3002"}}
{"id": "2507.15742", "pdf": "https://arxiv.org/pdf/2507.15742", "abs": "https://arxiv.org/abs/2507.15742", "authors": ["Paul Sheridan", "Zeyad Ahmed", "Aitazaz A. Farooque"], "title": "A Fisher's exact test justification of the TF-IDF term-weighting scheme", "categories": ["cs.CL", "cs.IR", "math.ST", "stat.TH"], "comment": "23 pages, 4 tables", "summary": "Term frequency-inverse document frequency, or TF-IDF for short, is arguably\nthe most celebrated mathematical expression in the history of information\nretrieval. Conceived as a simple heuristic quantifying the extent to which a\ngiven term's occurrences are concentrated in any one given document out of\nmany, TF-IDF and its many variants are routinely used as term-weighting schemes\nin diverse text analysis applications. There is a growing body of scholarship\ndedicated to placing TF-IDF on a sound theoretical foundation. Building on that\ntradition, this paper justifies the use of TF-IDF to the statistics community\nby demonstrating how the famed expression can be understood from a significance\ntesting perspective. We show that the common TF-IDF variant TF-ICF is, under\nmild regularity conditions, closely related to the negative logarithm of the\n$p$-value from a one-tailed version of Fisher's exact test of statistical\nsignificance. As a corollary, we establish a connection between TF-IDF and the\nsaid negative log-transformed $p$-value under certain idealized assumptions. We\nfurther demonstrate, as a limiting case, that this same quantity converges to\nTF-IDF in the limit of an infinitely large document collection. The Fisher's\nexact test justification of TF-IDF equips the working statistician with a ready\nexplanation of the term-weighting scheme's long-established effectiveness.", "AI": {"tldr": "This paper justifies the use of TF-IDF by connecting it to statistical significance testing, showing that it is related to the negative logarithm of the p-value from Fisher's exact test.", "motivation": "The motivation is to provide a sound theoretical foundation for TF-IDF, which has been widely used but lacks a rigorous statistical explanation.", "method": "The paper demonstrates that TF-IDF can be understood from a significance testing perspective, specifically by showing its relationship to the negative logarithm of the p-value from a one-tailed Fisher's exact test.", "result": "The paper shows that TF-IDF is closely related to the negative log-transformed p-value from Fisher's exact test under certain conditions, and that this relationship holds in the limit of an infinitely large document collection.", "conclusion": "TF-IDF is a widely used term-weighting scheme in text analysis, and this paper provides a theoretical justification for its effectiveness by relating it to statistical significance testing."}}
{"id": "2507.15752", "pdf": "https://arxiv.org/pdf/2507.15752", "abs": "https://arxiv.org/abs/2507.15752", "authors": ["Ruizhe Zhu", "Hao Zhu", "Yaxuan Li", "Syang Zhou", "Shijing Cai", "Malgorzata Lazuka", "Elliott Ash"], "title": "DialogueForge: LLM Simulation of Human-Chatbot Dialogue", "categories": ["cs.CL", "cs.AI"], "comment": "For our code and data, see\n  https://github.com/nerchio/Human_Chatbot-Generation", "summary": "Collecting human-chatbot dialogues typically demands substantial manual\neffort and is time-consuming, which limits and poses challenges for research on\nconversational AI. In this work, we propose DialogueForge - a framework for\ngenerating AI-simulated conversations in human-chatbot style. To initialize\neach generated conversation, DialogueForge uses seed prompts extracted from\nreal human-chatbot interactions. We test a variety of LLMs to simulate the\nhuman chatbot user, ranging from state-of-the-art proprietary models to\nsmall-scale open-source LLMs, and generate multi-turn dialogues tailored to\nspecific tasks. In addition, we explore fine-tuning techniques to enhance the\nability of smaller models to produce indistinguishable human-like dialogues. We\nevaluate the quality of the simulated conversations and compare different\nmodels using the UniEval and GTEval evaluation protocols. Our experiments show\nthat large proprietary models (e.g., GPT-4o) generally outperform others in\ngenerating more realistic dialogues, while smaller open-source models (e.g.,\nLlama, Mistral) offer promising performance with greater customization. We\ndemonstrate that the performance of smaller models can be significantly\nimproved by employing supervised fine-tuning techniques. Nevertheless,\nmaintaining coherent and natural long-form human-like dialogues remains a\ncommon challenge across all models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDialogueForge\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210AI\u6a21\u62df\u7684\u5bf9\u8bdd\uff0c\u4ee5\u89e3\u51b3\u6536\u96c6\u771f\u5b9e\u4eba\u7c7b-\u804a\u5929\u673a\u5668\u4eba\u5bf9\u8bdd\u6240\u9700\u5927\u91cf\u624b\u52a8\u5de5\u4f5c\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5927\u578b\u4e13\u6709\u6a21\u578b\u5728\u751f\u6210\u903c\u771f\u5bf9\u8bdd\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u800c\u8f83\u5c0f\u7684\u5f00\u6e90\u6a21\u578b\u901a\u8fc7\u5fae\u8c03\u4e5f\u80fd\u53d6\u5f97\u826f\u597d\u6548\u679c\uff0c\u4f46\u4fdd\u6301\u957f\u7bc7\u5bf9\u8bdd\u7684\u8fde\u8d2f\u6027\u548c\u81ea\u7136\u6027\u4ecd\u662f\u6311\u6218\u3002", "motivation": "\u6536\u96c6\u4eba\u7c7b-\u804a\u5929\u673a\u5668\u4eba\u5bf9\u8bdd\u901a\u5e38\u9700\u8981\u5927\u91cf\u624b\u52a8\u5de5\u4f5c\u4e14\u8017\u65f6\uff0c\u8fd9\u9650\u5236\u4e86\u5bf9\u8bddAI\u7684\u7814\u7a76\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6a21\u62df\u5bf9\u8bdd\uff0c\u4ee5\u4fc3\u8fdb\u7814\u7a76\u8fdb\u5c55\u3002", "method": "DialogueForge - \u4e00\u79cd\u751f\u6210AI\u6a21\u62df\u5bf9\u8bdd\u7684\u6846\u67b6\uff0c\u4ee5\u4eba\u7c7b-\u804a\u5929\u673a\u5668\u4eba\u98ce\u683c\u8fdb\u884c\u6a21\u62df\u3002\u8be5\u6846\u67b6\u4f7f\u7528\u4ece\u771f\u5b9e\u4eba\u7c7b-\u804a\u5929\u673a\u5668\u4eba\u4ea4\u4e92\u4e2d\u63d0\u53d6\u7684\u79cd\u5b50\u63d0\u793a\u6765\u521d\u59cb\u5316\u6bcf\u4e2a\u751f\u6210\u7684\u5bf9\u8bdd\u3002\u6d4b\u8bd5\u4e86\u591a\u79cdLLM\u6765\u6a21\u62df\u4eba\u7c7b\u804a\u5929\u673a\u5668\u4eba\u7528\u6237\uff0c\u5305\u62ec\u6700\u5148\u8fdb\u7684\u4e13\u6709\u6a21\u578b\u548c\u5c0f\u89c4\u6a21\u7684\u5f00\u6e90LLM\uff0c\u5e76\u751f\u6210\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u7684\u591a\u8f6e\u5bf9\u8bdd\u3002\u8fd8\u63a2\u7d22\u4e86\u5fae\u8c03\u6280\u672f\u4ee5\u589e\u5f3a\u8f83\u5c0f\u6a21\u578b\u751f\u6210\u96be\u4ee5\u533a\u5206\u7684\u4eba\u7c7b\u5bf9\u8bdd\u7684\u80fd\u529b\u3002", "result": "\u5927\u578b\u4e13\u6709\u6a21\u578b\uff08\u5982GPT-4o\uff09\u5728\u751f\u6210\u66f4\u903c\u771f\u7684\u5bf9\u8bdd\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u800c\u8f83\u5c0f\u7684\u5f00\u6e90\u6a21\u578b\uff08\u5982Llama\u3001Mistral\uff09\u5728\u6027\u80fd\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u5b9a\u5236\u6027\u3002\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u6280\u672f\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5c0f\u578b\u6a21\u578b\u7684\u6027\u80fd\u3002\u7136\u800c\uff0c\u4fdd\u6301\u8fde\u8d2f\u548c\u81ea\u7136\u7684\u957f\u7bc7\u5bf9\u8bdd\u4ecd\u7136\u662f\u6240\u6709\u6a21\u578b\u9762\u4e34\u7684\u6311\u6218\u3002", "conclusion": "\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5927\u578b\u4e13\u6709\u6a21\u578b\uff08\u4f8b\u5982GPT-4o\uff09\u5728\u751f\u6210\u66f4\u903c\u771f\u7684\u5bf9\u8bdd\u65b9\u9762\u901a\u5e38\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u800c\u8f83\u5c0f\u7684\u5f00\u6e90\u6a21\u578b\uff08\u4f8b\u5982Llama\u3001Mistral\uff09\u5219\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u5b9a\u5236\u6027\u3002\u6211\u4eec\u8bc1\u660e\u4e86\u901a\u8fc7\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\u6280\u672f\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5c0f\u578b\u6a21\u578b\u7684\u6027\u80fd\u3002\u7136\u800c\uff0c\u4fdd\u6301\u8fde\u8d2f\u548c\u81ea\u7136\u7684\u957f\u7bc7\u4eba\u7c7b\u5bf9\u8bdd\u4ecd\u7136\u662f\u6240\u6709\u6a21\u578b\u9762\u4e34\u7684\u5171\u540c\u6311\u6218\u3002"}}
{"id": "2507.15759", "pdf": "https://arxiv.org/pdf/2507.15759", "abs": "https://arxiv.org/abs/2507.15759", "authors": ["Lyumanshan Ye", "Xiaojie Cai", "Xinkai Wang", "Junfei Wang", "Xiangkun Hu", "Jiadi Su", "Yang Nan", "Sihan Wang", "Bohan Zhang", "Xiaoze Fan", "Jinbin Luo", "Yuxiang Zheng", "Tianze Xu", "Dayuan Fu", "Yunze Wu", "Pengrui Lu", "Zengzhi Wang", "Yiwei Qin", "Zhen Huang", "Yan Ma", "Zhulin Hu", "Haoyang Zou", "Tiantian Mi", "Yixin Ye", "Ethan Chern", "Pengfei Liu"], "title": "Interaction as Intelligence: Deep Research With Human-AI Partnership", "categories": ["cs.CL"], "comment": "30 pages, 10 figures", "summary": "This paper introduces \"Interaction as Intelligence\" research series,\npresenting a reconceptualization of human-AI relationships in deep research\ntasks. Traditional approaches treat interaction merely as an interface for\naccessing AI capabilities-a conduit between human intent and machine output. We\npropose that interaction itself constitutes a fundamental dimension of\nintelligence. As AI systems engage in extended thinking processes for research\ntasks, meaningful interaction transitions from an optional enhancement to an\nessential component of effective intelligence. Current deep research systems\nadopt an \"input-wait-output\" paradigm where users initiate queries and receive\nresults after black-box processing. This approach leads to error cascade\neffects, inflexible research boundaries that prevent question refinement during\ninvestigation, and missed opportunities for expertise integration. To address\nthese limitations, we introduce Deep Cognition, a system that transforms the\nhuman role from giving instructions to cognitive oversight-a mode of engagement\nwhere humans guide AI thinking processes through strategic intervention at\ncritical junctures. Deep cognition implements three key innovations:\n(1)Transparent, controllable, and interruptible interaction that reveals AI\nreasoning and enables intervention at any point; (2)Fine-grained bidirectional\ndialogue; and (3)Shared cognitive context where the system observes and adapts\nto user behaviors without explicit instruction. User evaluation demonstrates\nthat this cognitive oversight paradigm outperforms the strongest baseline\nacross six key metrics: Transparency(+20.0%), Fine-Grained Interaction(+29.2%),\nReal-Time Intervention(+18.5%), Ease of Collaboration(+27.7%),\nResults-Worth-Effort(+8.8%), and Interruptibility(+20.7%). Evaluations on\nchallenging research problems show 31.8% to 50.0% points of improvements over\ndeep research systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u201c\u4e92\u52a8\u5373\u667a\u80fd\u201d\u7684\u7814\u7a76\u7cfb\u5217\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edfDeep Cognition\uff0c\u901a\u8fc7\u5b9e\u73b0\u53ef\u89c6\u5316\u3001\u53ef\u63a7\u4e14\u53ef\u4e2d\u65ad\u7684\u4ea4\u4e92\uff0c\u7ec6\u7c92\u5ea6\u7684\u53cc\u5411\u5bf9\u8bdd\u4ee5\u53ca\u5171\u4eab\u7684\u8ba4\u77e5\u4e0a\u4e0b\u6587\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4eba\u673a\u4ea4\u4e92\u7684\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5c06\u4ea4\u4e92\u4ec5\u89c6\u4e3a\u8bbf\u95eeAI\u80fd\u529b\u7684\u754c\u9762\uff0c\u800c\u672c\u6587\u8ba4\u4e3a\u4ea4\u4e92\u672c\u8eab\u662f\u667a\u80fd\u7684\u4e00\u4e2a\u57fa\u672c\u7ef4\u5ea6\u3002\u5f53\u524d\u7684\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u5b58\u5728\u9519\u8bef\u7ea7\u8054\u6548\u5e94\u3001\u7814\u7a76\u8fb9\u754c\u4e0d\u7075\u6d3b\u4ee5\u53ca\u9519\u8fc7\u4e13\u5bb6\u6574\u5408\u673a\u4f1a\u7b49\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5373Deep Cognition\u7cfb\u7edf\uff0c\u5b83\u5b9e\u73b0\u4e86\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a(1) \u53ef\u89c6\u5316\u3001\u53ef\u63a7\u4e14\u53ef\u4e2d\u65ad\u7684\u4ea4\u4e92\uff1b(2) \u7ec6\u7c92\u5ea6\u7684\u53cc\u5411\u5bf9\u8bdd\uff1b(3) \u5171\u4eab\u7684\u8ba4\u77e5\u4e0a\u4e0b\u6587\u3002", "result": "\u7528\u6237\u8bc4\u4f30\u663e\u793a\uff0c\u8ba4\u77e5\u76d1\u7763\u8303\u5f0f\u5728\u516d\u4e2a\u5173\u952e\u6307\u6807\u4e0a\u4f18\u4e8e\u6700\u5f3a\u57fa\u7ebf\uff0c\u5206\u522b\u63d0\u9ad8\u4e8620.0%\u300129.2%\u300118.5%\u300127.7%\u30018.8%\u548c20.7%\u3002\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u7814\u7a76\u95ee\u9898\u4e0a\uff0cDeep Cognition\u7cfb\u7edf\u7684\u6027\u80fd\u6bd4\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u63d0\u9ad8\u4e8631.8%\u81f350.0%\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u201c\u4e92\u52a8\u5373\u667a\u80fd\u201d\u7814\u7a76\u7cfb\u5217\uff0c\u91cd\u65b0\u5b9a\u4e49\u4e86\u4eba\u7c7b\u4e0eAI\u5728\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u4e2d\u7684\u5173\u7cfb\u3002\u901a\u8fc7\u5f15\u5165Deep Cognition\u7cfb\u7edf\uff0c\u4eba\u7c7b\u7684\u89d2\u8272\u4ece\u7ed9\u4e88\u6307\u4ee4\u8f6c\u53d8\u4e3a\u8ba4\u77e5\u76d1\u7763\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u4e86\u4ea4\u4e92\u7684\u900f\u660e\u5ea6\u3001\u7ec6\u7c92\u5ea6\u5bf9\u8bdd\u548c\u5b9e\u65f6\u5e72\u9884\u80fd\u529b\u3002"}}
{"id": "2507.15773", "pdf": "https://arxiv.org/pdf/2507.15773", "abs": "https://arxiv.org/abs/2507.15773", "authors": ["Andrei-Valentin Tanase", "Elena Pelican"], "title": "Supernova: Achieving More with Less in Transformer Architectures", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We present Supernova, a 650M-parameter decoder-only transformer that\ndemonstrates how careful architectural design and tokenization innovation can\nachieve the performance of larger models while maintaining computational\nefficiency. Our architecture combines Rotary Positional Embeddings (RoPE),\nGrouped Query Attention (GQA) with a 3:1 compression ratio, RMSNorm for\ncomputational efficiency, and SwiGLU activation functions. A critical\ninnovation is our custom 128,000-vocabulary byte-level BPE tokenizer, which\nachieves state-of-the-art compression performance. Through detailed analysis,\nwe show that Supernova achieves 90% of the performance of 1B-parameter models\nwhile using 53% fewer parameters and requiring only 100B training tokens--an\norder of magnitude less than competing models. Our findings challenge the\nprevailing scaling paradigm, demonstrating that architectural efficiency and\ntokenization quality can compensate for reduced parameter counts.", "AI": {"tldr": "Supernova\u662f\u4e00\u4e2a6.5\u4ebf\u53c2\u6570\u7684\u89e3\u7801\u5668-only transformer\uff0c\u901a\u8fc7\u4ed4\u7ec6\u7684\u67b6\u6784\u8bbe\u8ba1\u548c\u5206\u8bcd\u521b\u65b0\u5b9e\u73b0\u4e86\u66f4\u5927\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u6211\u4eec\u5e0c\u671b\u901a\u8fc7\u4ed4\u7ec6\u7684\u67b6\u6784\u8bbe\u8ba1\u548c\u5206\u8bcd\u521b\u65b0\u6765\u5b9e\u73b0\u66f4\u5927\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86Supernova\uff0c\u4e00\u4e2a6.5\u4ebf\u53c2\u6570\u7684\u89e3\u7801\u5668-only transformer\uff0c\u901a\u8fc7\u4ed4\u7ec6\u7684\u67b6\u6784\u8bbe\u8ba1\u548c\u5206\u8bcd\u521b\u65b0\u5b9e\u73b0\u4e86\u66f4\u5927\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "result": "Supernova\u5b9e\u73b0\u4e8610\u4ebf\u53c2\u6570\u6a21\u578b\u768490%\u6027\u80fd\uff0c\u540c\u65f6\u4f7f\u7528\u4e8653%\u66f4\u5c11\u7684\u53c2\u6570\uff0c\u5e76\u4e14\u53ea\u9700\u89811000\u4ebf\u8bad\u7ec3\u6807\u8bb0\u2014\u2014\u6bd4\u7ade\u4e89\u6a21\u578b\u5c11\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u6311\u6218\u4e86\u73b0\u6709\u7684\u6269\u5c55\u8303\u5f0f\uff0c\u8868\u660e\u67b6\u6784\u6548\u7387\u548c\u5206\u8bcd\u8d28\u91cf\u53ef\u4ee5\u5f25\u8865\u53c2\u6570\u6570\u91cf\u7684\u51cf\u5c11\u3002"}}
{"id": "2507.15778", "pdf": "https://arxiv.org/pdf/2507.15778", "abs": "https://arxiv.org/abs/2507.15778", "authors": ["Jiakang Wang", "Runze Liu", "Fuzheng Zhang", "Xiu Li", "Guorui Zhou"], "title": "Stabilizing Knowledge, Promoting Reasoning: Dual-Token Constraints for RLVR", "categories": ["cs.CL"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has become an effective\npost-training method for improving the reasoning abilities of Large Language\nModels (LLMs), mainly by shaping higher-order behaviors such as reflection and\nplanning. However, previous RLVR algorithms often apply uniform training\nsignals to all tokens, without considering the different roles of low-entropy\nknowledge-related tokens and high-entropy reasoning-related tokens. Some recent\nmethods try to separate these token types by gradient masking or asynchronous\nupdates, but these approaches may break semantic dependencies in the model\noutput and hinder effective learning. In this work, we propose Archer, an\nentropy-aware RLVR approach with dual-token constraints and synchronous\nupdates. Specifically, our method applies weaker KL regularization and higher\nclipping thresholds to reasoning tokens to encourage exploration, while using\nstronger constraints on knowledge tokens to maintain factual knowledge.\nExperimental results on several mathematical reasoning and code generation\nbenchmarks show that our approach significantly outperforms previous RLVR\nmethods, reaching or exceeding state-of-the-art performance among models of\ncomparable size. The code is available at\nhttps://github.com/wizard-III/ArcherCodeR.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684RLVR\u65b9\u6cd5Archer\uff0c\u901a\u8fc7\u8003\u8651\u4e0d\u540c\u7c7b\u578b\u7684\u6807\u8bb0\uff08\u77e5\u8bc6\u548c\u63a8\u7406\uff09\u6765\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4e4b\u524d\u7684RLVR\u7b97\u6cd5\u901a\u5e38\u5bf9\u6240\u6709\u6807\u8bb0\u5e94\u7528\u7edf\u4e00\u7684\u8bad\u7ec3\u4fe1\u53f7\uff0c\u800c\u6ca1\u6709\u8003\u8651\u4f4e\u71b5\u77e5\u8bc6\u76f8\u5173\u6807\u8bb0\u548c\u9ad8\u71b5\u63a8\u7406\u76f8\u5173\u6807\u8bb0\u7684\u4e0d\u540c\u4f5c\u7528\u3002\u4e00\u4e9b\u6700\u8fd1\u7684\u65b9\u6cd5\u5c1d\u8bd5\u901a\u8fc7\u68af\u5ea6\u63a9\u7801\u6216\u5f02\u6b65\u66f4\u65b0\u6765\u533a\u5206\u8fd9\u4e9b\u6807\u8bb0\u7c7b\u578b\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u80fd\u4f1a\u7834\u574f\u6a21\u578b\u8f93\u51fa\u4e2d\u7684\u8bed\u4e49\u4f9d\u8d56\u5173\u7cfb\u5e76\u963b\u788d\u6709\u6548\u7684\u5b66\u4e60\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86Archer\uff0c\u4e00\u79cd\u5177\u6709\u53cc\u4ee4\u724c\u7ea6\u675f\u548c\u540c\u6b65\u66f4\u65b0\u7684\u71b5\u611f\u77e5RLVR\u65b9\u6cd5\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5bf9\u63a8\u7406\u4ee4\u724c\u5e94\u7528\u8f83\u5f31\u7684KL\u6b63\u5219\u5316\u548c\u8f83\u9ad8\u7684\u526a\u5207\u9608\u503c\u4ee5\u9f13\u52b1\u63a2\u7d22\uff0c\u540c\u65f6\u5bf9\u77e5\u8bc6\u4ee4\u724c\u4f7f\u7528\u66f4\u5f3a\u7684\u7ea6\u675f\u4ee5\u4fdd\u6301\u4e8b\u5b9e\u77e5\u8bc6\u3002", "result": "\u5728\u51e0\u4e2a\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u7684RLVR\u65b9\u6cd5\uff0c\u8fbe\u5230\u6216\u8d85\u8fc7\u4e0e\u53ef\u6bd4\u89c4\u6a21\u6a21\u578b\u76f8\u5f53\u7684\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u7684RLVR\u65b9\u6cd5\uff0c\u5728\u53ef\u6bd4\u89c4\u6a21\u7684\u6a21\u578b\u4e2d\u8fbe\u5230\u4e86\u6216\u8d85\u8fc7\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2507.15779", "pdf": "https://arxiv.org/pdf/2507.15779", "abs": "https://arxiv.org/abs/2507.15779", "authors": ["Felix K\u00f6ster", "Atsushi Uchida"], "title": "Reservoir Computing as a Language Model", "categories": ["cs.CL"], "comment": "8 pages, 5 figures, 1 table", "summary": "Large Language Models (LLM) have dominated the science and media landscape\nduo to their impressive performance on processing large chunks of data and\nproduce human-like levels of text. Nevertheless, their huge energy demand and\nslow processing still a bottleneck for further increasing quality while also\nmaking the models accessible to everyone. To solve this bottleneck, we will\ninvestigate how reservoir computing performs on natural text processing, which\ncould enable fast and energy efficient hardware implementations. Studies\ninvestigating the use of reservoir computing as a language model remain sparse.\nIn this paper, we compare three distinct approaches for character-level\nlanguage modeling, two different reservoir computing approaches, where only an\noutput layer is trainable, and the well-known transformer-based architectures,\nwhich fully learn an attention-based sequence representation. We explore the\nperformance, computational cost and prediction accuracy for both paradigms by\nequally varying the number of trainable parameters for all models. Using a\nconsistent pipeline for all three approaches, we demonstrate that transformers\nexcel in prediction quality, whereas reservoir computers remain highly\nefficient reducing the training and inference speed. Furthermore, we\ninvestigate two types of reservoir computing: a traditional reservoir with a\nstatic linear readout, and an attention-enhanced reservoir that dynamically\nadapts its output weights via an attention mechanism. Our findings underline\nhow these paradigms scale and offer guidelines to balance resource constraints\nwith performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u57fa\u4e8e\u6c34\u5e93\u8ba1\u7b97\u548c\u53d8\u538b\u5668\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u53d8\u538b\u5668\u5728\u9884\u6d4b\u8d28\u91cf\u4e0a\u66f4\u4f18\uff0c\u800c\u6c34\u5e93\u8ba1\u7b97\u5728\u6548\u7387\u4e0a\u66f4\u5177\u4f18\u52bf\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u80fd\u6e90\u9700\u6c42\u548c\u5904\u7406\u901f\u5ea6\u65b9\u9762\u7684\u74f6\u9888\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u6c34\u5e93\u8ba1\u7b97\u5728\u81ea\u7136\u6587\u672c\u5904\u7406\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u5b57\u7b26\u7ea7\u8bed\u8a00\u5efa\u6a21\u65b9\u6cd5\uff0c\u5305\u62ec\u4e24\u79cd\u4e0d\u540c\u7684\u6c34\u5e93\u8ba1\u7b97\u65b9\u6cd5\uff08\u4ec5\u8f93\u51fa\u5c42\u53ef\u8bad\u7ec3\uff09\u548c\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u67b6\u6784\uff08\u5b8c\u5168\u5b66\u4e60\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u5e8f\u5217\u8868\u793a\uff09\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u53d8\u538b\u5668\u5728\u9884\u6d4b\u8d28\u91cf\u65b9\u9762\u4f18\u4e8e\u6c34\u5e93\u8ba1\u7b97\u673a\uff0c\u800c\u6c34\u5e93\u8ba1\u7b97\u673a\u5728\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002\u540c\u65f6\uff0c\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u4e24\u79cd\u7c7b\u578b\u7684\u6c34\u5e93\u8ba1\u7b97\uff1a\u4f20\u7edf\u9759\u6001\u7ebf\u6027\u8bfb\u51fa\u548c\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u52a8\u6001\u9002\u5e94\u8f93\u51fa\u6743\u91cd\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u53d8\u538b\u5668\u5728\u9884\u6d4b\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u800c\u6c34\u5e93\u8ba1\u7b97\u673a\u5728\u51cf\u5c11\u8bad\u7ec3\u548c\u63a8\u7406\u901f\u5ea6\u65b9\u9762\u4fdd\u6301\u9ad8\u6548\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u5982\u4f55\u5e73\u8861\u8d44\u6e90\u7ea6\u675f\u4e0e\u6027\u80fd\u7684\u6307\u5bfc\u3002"}}
{"id": "2507.15823", "pdf": "https://arxiv.org/pdf/2507.15823", "abs": "https://arxiv.org/abs/2507.15823", "authors": ["Anton Abilov", "Ke Zhang", "Hemank Lamba", "Elizabeth M. Olson", "Joel R. Tetreault", "Alejandro Jaimes"], "title": "Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work", "categories": ["cs.CL", "cs.AI", "cs.SI"], "comment": null, "summary": "Publications in the AI for Good space have tended to focus on the research\nand model development that can support high-impact applications. However, very\nfew AI for Good papers discuss the process of deploying and collaborating with\nthe partner organization, and the resulting real-world impact. In this work, we\nshare details about the close collaboration with a humanitarian-to-humanitarian\n(H2H) organization and how to not only deploy the AI model in a\nresource-constrained environment, but also how to maintain it for continuous\nperformance updates, and share key takeaways for practitioners.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4e0e\u4eba\u9053\u4e3b\u4e49\u7ec4\u7ec7\u5408\u4f5c\u90e8\u7f72\u548c\u7ef4\u62a4AI\u6a21\u578b\u7684\u7ecf\u9a8c\uff0c\u5e76\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u5173\u952e\u7684\u6559\u8bad\u3002", "motivation": "\u5927\u591a\u6570AI for Good\u8bba\u6587\u5173\u6ce8\u7684\u662f\u7814\u7a76\u548c\u6a21\u578b\u5f00\u53d1\uff0c\u4f46\u5f88\u5c11\u8ba8\u8bba\u90e8\u7f72\u548c\u4e0e\u5408\u4f5c\u4f19\u4f34\u7ec4\u7ec7\u7684\u5408\u4f5c\u8fc7\u7a0b\u4ee5\u53ca\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u672c\u6587\u63cf\u8ff0\u4e86\u4e0e\u4eba\u9053\u4e3b\u4e49\u7ec4\u7ec7\u7684\u7d27\u5bc6\u5408\u4f5c\uff0c\u4ee5\u53ca\u5982\u4f55\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u90e8\u7f72\u548c\u7ef4\u62a4AI\u6a21\u578b\u3002", "result": "\u672c\u6587\u5206\u4eab\u4e86\u4e0e\u4eba\u9053\u4e3b\u4e49\u7ec4\u7ec7\u5408\u4f5c\u7684\u7ecf\u9a8c\uff0c\u4ee5\u53ca\u5982\u4f55\u5728\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u4e2d\u90e8\u7f72\u548c\u7ef4\u62a4AI\u6a21\u578b\uff0c\u5e76\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u5173\u952e\u7684\u6559\u8bad\u3002", "conclusion": "\u672c\u6587\u5206\u4eab\u4e86\u4e0e\u4eba\u9053\u4e3b\u4e49\u7ec4\u7ec7\u5408\u4f5c\u7684\u7ecf\u9a8c\uff0c\u4ee5\u53ca\u5982\u4f55\u5728\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u4e2d\u90e8\u7f72\u548c\u7ef4\u62a4AI\u6a21\u578b\uff0c\u5e76\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u5173\u952e\u7684\u6559\u8bad\u3002"}}
{"id": "2507.15849", "pdf": "https://arxiv.org/pdf/2507.15849", "abs": "https://arxiv.org/abs/2507.15849", "authors": ["Yihao Li", "Jiayi Xin", "Miranda Muqing Miao", "Qi Long", "Lyle Ungar"], "title": "The Impact of Language Mixing on Bilingual LLM Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Proficient multilingual speakers often intentionally switch languages in the\nmiddle of a conversation. Similarly, recent reasoning-focused bilingual large\nlanguage models (LLMs) with strong capabilities in both languages exhibit\nlanguage mixing--alternating languages within their chain of thought.\nDiscouraging this behavior in DeepSeek-R1 was found to degrade accuracy,\nsuggesting that language mixing may benefit reasoning. In this work, we study\nlanguage switching in Chinese-English bilingual reasoning models. We identify\nreinforcement learning with verifiable rewards (RLVR) as the critical training\nstage that leads to language mixing. We demonstrate that language mixing can\nenhance reasoning: enforcing monolingual decoding reduces accuracy by 5.6\npercentage points on math reasoning tasks. Additionally, a lightweight probe\ncan be trained to predict whether a potential language switch would benefit or\nharm reasoning, and when used to guide decoding, increases accuracy by up to\n6.25 percentage points. Our findings suggest that language mixing is not merely\na byproduct of multilingual training, but is a strategic reasoning behavior.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4e2d\u6587-\u82f1\u8bed\u53cc\u8bed\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u8bed\u8a00\u5207\u6362\u73b0\u8c61\uff0c\u53d1\u73b0\u8bed\u8a00\u5207\u6362\u4e0d\u4ec5\u4e0d\u662f\u591a\u8bed\u8a00\u8bad\u7ec3\u7684\u526f\u4ea7\u54c1\uff0c\u800c\u662f\u4e00\u79cd\u6709\u52a9\u4e8e\u63a8\u7406\u7684\u6218\u7565\u6027\u884c\u4e3a\u3002", "motivation": "\u5148\u524d\u7684\u7814\u7a76\u53d1\u73b0\uff0c\u5728DeepSeek-R1\u4e2d\u963b\u6b62\u8fd9\u79cd\u884c\u4e3a\u4f1a\u964d\u4f4e\u51c6\u786e\u6027\uff0c\u8fd9\u8868\u660e\u8bed\u8a00\u6df7\u5408\u53ef\u80fd\u6709\u52a9\u4e8e\u63a8\u7406\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u60f3\u7814\u7a76\u4e2d\u6587-\u82f1\u8bed\u53cc\u8bed\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u8bed\u8a00\u5207\u6362\u3002", "method": "\u6211\u4eec\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u7684\u5173\u952e\u8bad\u7ec3\u9636\u6bb5\u6765\u7814\u7a76\u8bed\u8a00\u5207\u6362\uff0c\u5e76\u4f7f\u7528\u8f7b\u91cf\u7ea7\u63a2\u6d4b\u5668\u6765\u9884\u6d4b\u6f5c\u5728\u7684\u8bed\u8a00\u5207\u6362\u662f\u5426\u6709\u52a9\u4e8e\u6216\u635f\u5bb3\u63a8\u7406\u3002", "result": "\u6211\u4eec\u53d1\u73b0\uff0c\u5f3a\u5236\u5355\u8bed\u89e3\u7801\u4f1a\u4f7f\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u51c6\u786e\u6027\u964d\u4f4e5.6\u4e2a\u767e\u5206\u70b9\u3002\u6b64\u5916\uff0c\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u63a2\u6d4b\u5668\u53ef\u4ee5\u88ab\u8bad\u7ec3\u6765\u9884\u6d4b\u6f5c\u5728\u7684\u8bed\u8a00\u5207\u6362\u662f\u5426\u6709\u52a9\u4e8e\u6216\u635f\u5bb3\u63a8\u7406\uff0c\u5e76\u4e14\u5f53\u7528\u4e8e\u6307\u5bfc\u89e3\u7801\u65f6\uff0c\u53ef\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u9ad8\u8fbe6.25\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8bed\u8a00\u6df7\u5408\u4e0d\u4ec5\u4ec5\u662f\u591a\u8bed\u8a00\u8bad\u7ec3\u7684\u526f\u4ea7\u54c1\uff0c\u800c\u662f\u4e00\u79cd\u6218\u7565\u6027\u7684\u63a8\u7406\u884c\u4e3a\u3002"}}
{"id": "2507.15850", "pdf": "https://arxiv.org/pdf/2507.15850", "abs": "https://arxiv.org/abs/2507.15850", "authors": ["Basma El Amel Boussaha", "Leen AlQadi", "Mugariya Farooq", "Shaikha Alsuwaidi", "Giulia Campesan", "Ahmed Alzubaidi", "Mohammed Alyafeai", "Hakim Hacid"], "title": "3LM: Bridging Arabic, STEM, and Code through Benchmarking", "categories": ["cs.CL"], "comment": null, "summary": "Arabic is one of the most widely spoken languages in the world, yet efforts\nto develop and evaluate Large Language Models (LLMs) for Arabic remain\nrelatively limited. Most existing Arabic benchmarks focus on linguistic,\ncultural, or religious content, leaving a significant gap in domains like STEM\nand code which are increasingly relevant for real-world LLM applications. To\nhelp bridge this gap, we present 3LM, a suite of three benchmarks designed\nspecifically for Arabic. The first is a set of STEM-related question-answer\npairs, naturally sourced from Arabic textbooks and educational worksheets. The\nsecond consists of synthetically generated STEM questions, created using the\nsame sources. The third benchmark focuses on code generation, built through a\ncareful translation of two widely used code benchmarks, incorporating a\nhuman-in-the-loop process with several rounds of review to ensure high-quality\nand faithful translations. We release all three benchmarks publicly to support\nthe growth of Arabic LLM research in these essential but underrepresented\nareas.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e863LM\u57fa\u51c6\u5957\u4ef6\uff0c\u65e8\u5728\u586b\u8865\u963f\u62c9\u4f2f\u8bed\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u4e2d\u7684\u7a7a\u767d\uff0c\u5e76\u4fc3\u8fdbSTEM\u548c\u4ee3\u7801\u9886\u57df\u7684\u53d1\u5c55\u3002", "motivation": "\u76ee\u524d\u9488\u5bf9\u963f\u62c9\u4f2f\u8bed\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u76f8\u5bf9\u6709\u9650\uff0c\u73b0\u6709\u7684\u963f\u62c9\u4f2f\u8bed\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u96c6\u4e2d\u5728\u8bed\u8a00\u3001\u6587\u5316\u548c\u5b97\u6559\u5185\u5bb9\u4e0a\uff0c\u800cSTEM\u548c\u4ee3\u7801\u7b49\u9886\u57df\u7684\u7814\u7a76\u4e0d\u8db3\uff0c\u8fd9\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u3002", "method": "\u672c\u6587\u901a\u8fc7\u4ece\u963f\u62c9\u4f2f\u8bed\u6559\u79d1\u4e66\u548c\u6559\u80b2\u5de5\u4f5c\u8868\u4e2d\u81ea\u7136\u83b7\u53d6STEM\u76f8\u5173\u95ee\u7b54\u5bf9\uff0c\u4ee5\u53ca\u4f7f\u7528\u76f8\u540c\u6765\u6e90\u751f\u6210\u5408\u6210STEM\u95ee\u9898\uff0c\u6784\u5efa\u4e86\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u3002\u6b64\u5916\uff0c\u8fd8\u901a\u8fc7\u4eba\u5de5\u5ba1\u6838\u8fc7\u7a0b\u4ed4\u7ec6\u7ffb\u8bd1\u4e86\u4e24\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u4ee3\u7801\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u786e\u4fdd\u9ad8\u8d28\u91cf\u548c\u5fe0\u5b9e\u7684\u7ffb\u8bd1\u3002", "result": "\u672c\u6587\u6210\u529f\u6784\u5efa\u4e86\u4e09\u4e2a\u9488\u5bf9\u963f\u62c9\u4f2f\u8bed\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u4e86STEM\u95ee\u7b54\u3001\u5408\u6210STEM\u95ee\u9898\u548c\u4ee3\u7801\u751f\u6210\uff0c\u5e76\u516c\u5f00\u53d1\u5e03\u4ee5\u652f\u6301\u963f\u62c9\u4f2f\u8bed\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u7684\u53d1\u5c55\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e863LM\u57fa\u51c6\u5957\u4ef6\uff0c\u65e8\u5728\u586b\u8865\u963f\u62c9\u4f2f\u8bed\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u4e2d\u7684\u7a7a\u767d\uff0c\u5e76\u4fc3\u8fdbSTEM\u548c\u4ee3\u7801\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.14179", "pdf": "https://arxiv.org/pdf/2507.14179", "abs": "https://arxiv.org/abs/2507.14179", "authors": ["Nobel Dhar", "Bobin Deng", "Md Romyull Islam", "Xinyue Zhang", "Kazi Fahim Ahmad Nasif", "Kun Suo"], "title": "A Sparsity Predicting Approach for Large Language Models via Activation Pattern Clustering", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "comment": "To be published in Euro-Par 2025", "summary": "Large Language Models (LLMs) exhibit significant activation sparsity, where\nonly a subset of neurons are active for a given input. Although this sparsity\npresents opportunities to reduce computational cost, efficiently utilizing it\nrequires predicting activation patterns in a scalable manner. However, direct\nprediction at the neuron level is computationally expensive due to the vast\nnumber of neurons in modern LLMs. To enable efficient prediction and\nutilization of activation sparsity, we propose a clustering-based activation\npattern compression framework. Instead of treating each neuron independently,\nwe group similar activation patterns into a small set of representative\nclusters. Our method achieves up to 79.34% clustering precision, outperforming\nstandard binary clustering approaches while maintaining minimal degradation in\nperplexity (PPL) scores. With a sufficiently large number of clusters, our\napproach attains a PPL score as low as 12.49, demonstrating its effectiveness\nin preserving model quality while reducing computational overhead. By\npredicting cluster assignments rather than individual neuron states, future\nmodels can efficiently infer activation patterns from pre-computed centroids.\nWe detail the clustering algorithm, analyze its effectiveness in capturing\nmeaningful activation structures, and demonstrate its potential to improve\nsparse computation efficiency. This clustering-based formulation serves as a\nfoundation for future work on activation pattern prediction, paving the way for\nefficient inference in large-scale language models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u6fc0\u6d3b\u6a21\u5f0f\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u76f8\u4f3c\u7684\u6fc0\u6d3b\u6a21\u5f0f\u5206\u7ec4\u5230\u5c11\u91cf\u4ee3\u8868\u6027\u805a\u7c7b\u4e2d\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6fc0\u6d3b\u7a00\u758f\u6027\u7684\u9ad8\u6548\u9884\u6d4b\u548c\u5229\u7528\u3002\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8868\u73b0\u51fa\u663e\u8457\u7684\u6fc0\u6d3b\u7a00\u758f\u6027\uff0c\u5176\u4e2d\u53ea\u6709\u90e8\u5206\u795e\u7ecf\u5143\u5728\u7ed9\u5b9a\u8f93\u5165\u4e0b\u88ab\u6fc0\u6d3b\u3002\u867d\u7136\u8fd9\u79cd\u7a00\u758f\u6027\u4e3a\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u63d0\u4f9b\u4e86\u673a\u4f1a\uff0c\u4f46\u9700\u8981\u4ee5\u53ef\u6269\u5c55\u7684\u65b9\u5f0f\u9884\u6d4b\u6fc0\u6d3b\u6a21\u5f0f\u3002\u7136\u800c\uff0c\u76f4\u63a5\u5728\u795e\u7ecf\u5143\u7ea7\u522b\u8fdb\u884c\u9884\u6d4b\u7531\u4e8e\u73b0\u4ee3LLMs\u4e2d\u795e\u7ecf\u5143\u6570\u91cf\u5e9e\u5927\u800c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u6fc0\u6d3b\u6a21\u5f0f\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u76f8\u4f3c\u7684\u6fc0\u6d3b\u6a21\u5f0f\u5206\u7ec4\u5230\u5c11\u91cf\u4ee3\u8868\u6027\u805a\u7c7b\u4e2d\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u6fc0\u6d3b\u7a00\u758f\u6027\u7684\u9ad8\u6548\u9884\u6d4b\u548c\u5229\u7528\u3002", "result": "\u672c\u6587\u7684\u65b9\u6cd5\u5728\u805a\u7c7b\u7cbe\u5ea6\u4e0a\u8fbe\u5230\u4e8679.34%\uff0c\u4f18\u4e8e\u6807\u51c6\u7684\u4e8c\u5143\u805a\u7c7b\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6781\u5c0f\u7684\u56f0\u60d1\u5ea6\uff08PPL\uff09\u5206\u6570\u4e0b\u964d\u3002\u5f53\u6709\u8db3\u591f\u591a\u7684\u805a\u7c7b\u65f6\uff0c\u8be5\u65b9\u6cd5\u7684PPL\u5206\u6570\u4f4e\u81f312.49\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u4fdd\u7559\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u6fc0\u6d3b\u6a21\u5f0f\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u76f8\u4f3c\u7684\u6fc0\u6d3b\u6a21\u5f0f\u5206\u7ec4\u5230\u5c11\u91cf\u4ee3\u8868\u6027\u805a\u7c7b\u4e2d\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6fc0\u6d3b\u7a00\u758f\u6027\u7684\u9ad8\u6548\u9884\u6d4b\u548c\u5229\u7528\u3002\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.14201", "pdf": "https://arxiv.org/pdf/2507.14201", "abs": "https://arxiv.org/abs/2507.14201", "authors": ["Yiran Wu", "Mauricio Velazco", "Andrew Zhao", "Manuel Ra\u00fal Mel\u00e9ndez Luj\u00e1n", "Srisuma Movva", "Yogesh K Roy", "Quang Nguyen", "Roberto Rodriguez", "Qingyun Wu", "Michael Albada", "Julia Kiseleva", "Anand Mudgerikar"], "title": "ExCyTIn-Bench: Evaluating LLM agents on Cyber Threat Investigation", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "We present ExCyTIn-Bench, the first benchmark to Evaluate an LLM agent x on\nthe task of Cyber Threat Investigation through security questions derived from\ninvestigation graphs. Real-world security analysts must sift through a large\nnumber of heterogeneous alert signals and security logs, follow multi-hop\nchains of evidence, and compile an incident report. With the developments of\nLLMs, building LLM-based agents for automatic thread investigation is a\npromising direction. To assist the development and evaluation of LLM agents, we\nconstruct a dataset from a controlled Azure tenant that covers 8 simulated\nreal-world multi-step attacks, 57 log tables from Microsoft Sentinel and\nrelated services, and 589 automatically generated questions. We leverage\nsecurity logs extracted with expert-crafted detection logic to build threat\ninvestigation graphs, and then generate questions with LLMs using paired nodes\non the graph, taking the start node as background context and the end node as\nanswer. Anchoring each question to these explicit nodes and edges not only\nprovides automatic, explainable ground truth answers but also makes the\npipeline reusable and readily extensible to new logs. This also enables the\nautomatic generation of procedural tasks with verifiable rewards, which can be\nnaturally extended to training agents via reinforcement learning. Our\ncomprehensive experiments with different models confirm the difficulty of the\ntask: with the base setting, the average reward across all evaluated models is\n0.249, and the best achieved is 0.368, leaving substantial headroom for future\nresearch. Code and data are coming soon!", "AI": {"tldr": "ExCyTIn-Bench \u662f\u7b2c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30 LLM \u4ee3\u7406\u5728\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u8c03\u67e5\u4efb\u52a1\u4e0a\u7684\u57fa\u51c6\uff0c\u5b83\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6570\u636e\u96c6\u548c\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u95ee\u9898\u548c\u5956\u52b1\uff0c\u4ee5\u8bad\u7ec3\u4ee3\u7406\u3002", "motivation": "\u968f\u7740 LLM \u7684\u53d1\u5c55\uff0c\u6784\u5efa\u57fa\u4e8e LLM \u7684\u4ee3\u7406\u4ee5\u5b9e\u73b0\u81ea\u52a8\u5a01\u80c1\u8c03\u67e5\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\u3002\u4e3a\u4e86\u5e2e\u52a9\u5f00\u53d1\u548c\u8bc4\u4f30 LLM \u4ee3\u7406\uff0c\u9700\u8981\u4e00\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u6570\u636e\u96c6\uff0c\u6db5\u76d68\u4e2a\u6a21\u62df\u7684\u771f\u5b9e\u591a\u6b65\u9aa4\u653b\u51fb\u300157\u4e2a\u6765\u81ea Microsoft Sentinel \u548c\u76f8\u5173\u670d\u52a1\u7684\u65e5\u5fd7\u8868\u4ee5\u53ca589\u4e2a\u81ea\u52a8\u751f\u6210\u7684\u95ee\u9898\u3002\u5229\u7528\u4e13\u5bb6\u8bbe\u8ba1\u7684\u68c0\u6d4b\u903b\u8f91\u63d0\u53d6\u5b89\u5168\u65e5\u5fd7\u6765\u6784\u5efa\u5a01\u80c1\u8c03\u67e5\u56fe\uff0c\u5e76\u4f7f\u7528 LLM \u751f\u6210\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\uff1a\u5728\u57fa\u7840\u8bbe\u7f6e\u4e0b\uff0c\u6240\u6709\u8bc4\u4f30\u6a21\u578b\u7684\u5e73\u5747\u5956\u52b1\u4e3a 0.249\uff0c\u6700\u4f73\u7ed3\u679c\u4e3a 0.368\uff0c\u8fd9\u4e3a\u672a\u6765\u7684\u7814\u7a76\u7559\u4e0b\u4e86\u5927\u91cf\u7a7a\u95f4\u3002", "conclusion": "ExCyTIn-Bench \u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30 LLM \u4ee3\u7406\u5728\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u8c03\u67e5\u4efb\u52a1\u4e0a\u7684\u57fa\u51c6\uff0c\u8be5\u4efb\u52a1\u901a\u8fc7\u4ece\u8c03\u67e5\u56fe\u4e2d\u6d3e\u751f\u7684\u5b89\u5168\u95ee\u9898\u8fdb\u884c\u8bc4\u4f30\u3002"}}
{"id": "2507.14204", "pdf": "https://arxiv.org/pdf/2507.14204", "abs": "https://arxiv.org/abs/2507.14204", "authors": ["Dachuan Shi", "Yonggan Fu", "Xiangchi Yuan", "Zhongzhi Yu", "Haoran You", "Sixu Li", "Xin Dong", "Jan Kautz", "Pavlo Molchanov", "Yingyan", "Lin"], "title": "LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling of Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "ICML 2025. Code: https://github.com/GATECH-EIC/LaCache", "summary": "Recent advancements in Large Language Models (LLMs) have spurred interest in\nnumerous applications requiring robust long-range capabilities, essential for\nprocessing extensive input contexts and continuously generating extended\noutputs. As sequence lengths increase, the number of Key-Value (KV) pairs in\nLLMs escalates, creating a significant efficiency bottleneck. In this paper, we\npropose a new KV cache optimization paradigm called LaCache, a training-free\nmethod for efficient and accurate generative inference of LLMs. LaCache enables\nLLMs to simultaneously address both of the critical challenges in long-range\nmodeling: robust long-range capabilities and continuous generation without\nrunning out-of-memory (OOM). Specifically, LaCache integrates two key\ninnovations: (1) a ladder-shaped KV cache pattern that stores KV pairs not only\nsequentially (left-to-right within each layer) but also across layers (from\nshallow to deep), providing an extended span for capturing long-range\ndependencies under a fixed storage budget, thereby boosting long-range\ncapabilities; and (2) an iterative compaction mechanism that progressively\ncompresses older caches, freeing up space for new tokens within a fixed cache\nsize. This token distance-based dynamic compression enables more effective\ncontinuous generation under constrained cache budgets. Experiments across\nvarious tasks, benchmarks, and LLM models consistently validate LaCache's\neffectiveness in enhancing LLMs' long-range capabilities. Our code is available\nat https://github.com/GATECH-EIC/LaCache.", "AI": {"tldr": "LaCache\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684KV\u7f13\u5b58\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u68af\u5b50\u72b6\u7684KV\u7f13\u5b58\u6a21\u5f0f\u548c\u8fed\u4ee3\u538b\u7f29\u673a\u5236\uff0c\u63d0\u9ad8\u4e86LLM\u7684\u957f\u8ddd\u79bb\u5efa\u6a21\u80fd\u529b\u548c\u8fde\u7eed\u751f\u6210\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u7684\u589e\u52a0\uff0cLLM\u4e2d\u7684KV\u5bf9\u6570\u91cf\u6025\u5267\u589e\u52a0\uff0c\u5bfc\u81f4\u6548\u7387\u74f6\u9888\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684KV\u7f13\u5b58\u4f18\u5316\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "LaCache\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u68af\u5b50\u72b6\u7684KV\u7f13\u5b58\u6a21\u5f0f\u548c\u8fed\u4ee3\u538b\u7f29\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684KV\u7f13\u5b58\u4f18\u5316\u3002", "result": "\u5728\u5404\u79cd\u4efb\u52a1\u3001\u57fa\u51c6\u548cLLM\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u4e00\u81f4\u9a8c\u8bc1\u4e86LaCache\u7684\u6709\u6548\u6027\u3002", "conclusion": "LaCache\u6709\u6548\u5730\u63d0\u5347\u4e86LLM\u5728\u957f\u8ddd\u79bb\u5efa\u6a21\u4e2d\u7684\u80fd\u529b\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u8fde\u7eed\u751f\u6210\u800c\u4e0d\u4f1a\u51fa\u73b0\u5185\u5b58\u4e0d\u8db3\u7684\u95ee\u9898\u3002"}}
{"id": "2507.14221", "pdf": "https://arxiv.org/pdf/2507.14221", "abs": "https://arxiv.org/abs/2507.14221", "authors": ["Eoghan Cunningham", "James Cross", "Derek Greene"], "title": "Identifying Algorithmic and Domain-Specific Bias in Parliamentary Debate Summarisation", "categories": ["cs.CY", "cs.CL", "cs.LG"], "comment": null, "summary": "The automated summarisation of parliamentary debates using large language\nmodels (LLMs) offers a promising way to make complex legislative discourse more\naccessible to the public. However, such summaries must not only be accurate and\nconcise but also equitably represent the views and contributions of all\nspeakers. This paper explores the use of LLMs to summarise plenary debates from\nthe European Parliament and investigates the algorithmic and representational\nbiases that emerge in this context. We propose a structured, multi-stage\nsummarisation framework that improves textual coherence and content fidelity,\nwhile enabling the systematic analysis of how speaker attributes -- such as\nspeaking order or political affiliation -- influence the visibility and\naccuracy of their contributions in the final summaries. Through our experiments\nusing both proprietary and open-weight LLMs, we find evidence of consistent\npositional and partisan biases, with certain speakers systematically\nunder-represented or misattributed. Our analysis shows that these biases vary\nby model and summarisation strategy, with hierarchical approaches offering the\ngreatest potential to reduce disparity. These findings underscore the need for\ndomain-sensitive evaluation metrics and ethical oversight in the deployment of\nLLMs for democratic applications.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u6b27\u6d32\u8bae\u4f1a\u5168\u4f53\u4f1a\u8bae\u8fa9\u8bba\u8fdb\u884c\u6458\u8981\uff0c\u5e76\u7814\u7a76\u4e86\u5728\u6b64\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u7684\u7b97\u6cd5\u548c\u4ee3\u8868\u6027\u504f\u5dee\u3002", "motivation": "\u81ea\u52a8\u5316\u8bae\u4f1a\u8fa9\u8bba\u7684\u6458\u8981\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53ef\u4ee5\u4e3a\u516c\u4f17\u63d0\u4f9b\u66f4\u6613\u8bbf\u95ee\u7684\u590d\u6742\u7acb\u6cd5\u8bdd\u8bed\u3002\u7136\u800c\uff0c\u8fd9\u6837\u7684\u6458\u8981\u4e0d\u4ec5\u8981\u51c6\u786e\u4e14\u7b80\u6d01\uff0c\u8fd8\u5fc5\u987b\u516c\u5e73\u5730\u4ee3\u8868\u6240\u6709\u53d1\u8a00\u4eba\u7684\u89c2\u70b9\u548c\u8d21\u732e\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u7684\u591a\u9636\u6bb5\u6458\u8981\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u6587\u672c\u8fde\u8d2f\u6027\u548c\u5185\u5bb9\u4fdd\u771f\u5ea6\uff0c\u5e76\u5141\u8bb8\u7cfb\u7edf\u5206\u6790\u53d1\u8a00\u8005\u5c5e\u6027\u5982\u4f55\u5f71\u54cd\u5176\u8d21\u732e\u5728\u6700\u7ec8\u6458\u8981\u4e2d\u7684\u53ef\u89c1\u6027\u548c\u51c6\u786e\u6027\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u4e13\u6709\u548c\u5f00\u653e\u6743\u91cd\u7684LLM\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6211\u4eec\u53d1\u73b0\u4e86\u6301\u7eed\u7684\u4f4d\u7f6e\u548c\u515a\u6d3e\u504f\u89c1\uff0c\u67d0\u4e9b\u53d1\u8a00\u4eba\u7684\u8d21\u732e\u88ab\u7cfb\u7edf\u6027\u5730\u4f4e\u4f30\u6216\u9519\u8bef\u5f52\u56e0\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5f3a\u8c03\u4e86\u5728\u6c11\u4e3b\u5e94\u7528\u4e2d\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u9700\u8981\u9886\u57df\u654f\u611f\u7684\u8bc4\u4f30\u6307\u6807\u548c\u4f26\u7406\u76d1\u7763\u3002"}}
{"id": "2507.14293", "pdf": "https://arxiv.org/pdf/2507.14293", "abs": "https://arxiv.org/abs/2507.14293", "authors": ["Boyuan Zheng", "Zeyi Liao", "Scott Salisbury", "Zeyuan Liu", "Michael Lin", "Qinyuan Zheng", "Zifan Wang", "Xiang Deng", "Dawn Song", "Huan Sun", "Yu Su"], "title": "WebGuard: Building a Generalizable Guardrail for Web Agents", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "We publicly release WebGuard, along with its annotation tools and\n  fine-tuned models, to facilitate open-source research on monitoring and\n  safeguarding web agents. All resources are available at\n  https://github.com/OSU-NLP-Group/WebGuard", "summary": "The rapid development of autonomous web agents powered by Large Language\nModels (LLMs), while greatly elevating efficiency, exposes the frontier risk of\ntaking unintended or harmful actions. This situation underscores an urgent need\nfor effective safety measures, akin to access controls for human users. To\naddress this critical challenge, we introduce WebGuard, the first comprehensive\ndataset designed to support the assessment of web agent action risks and\nfacilitate the development of guardrails for real-world online environments. In\ndoing so, WebGuard specifically focuses on predicting the outcome of\nstate-changing actions and contains 4,939 human-annotated actions from 193\nwebsites across 22 diverse domains, including often-overlooked long-tail\nwebsites. These actions are categorized using a novel three-tier risk schema:\nSAFE, LOW, and HIGH. The dataset includes designated training and test splits\nto support evaluation under diverse generalization settings. Our initial\nevaluations reveal a concerning deficiency: even frontier LLMs achieve less\nthan 60% accuracy in predicting action outcomes and less than 60% recall in\nlagging HIGH-risk actions, highlighting the risks of deploying\ncurrent-generation agents without dedicated safeguards. We therefore\ninvestigate fine-tuning specialized guardrail models using WebGuard. We conduct\ncomprehensive evaluations across multiple generalization settings and find that\na fine-tuned Qwen2.5VL-7B model yields a substantial improvement in\nperformance, boosting accuracy from 37% to 80% and HIGH-risk action recall from\n20% to 76%. Despite these improvements, the performance still falls short of\nthe reliability required for high-stakes deployment, where guardrails must\napproach near-perfect accuracy and recall.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faWebGuard\u6570\u636e\u96c6\u4ee5\u8bc4\u4f30\u7f51\u7edc\u4ee3\u7406\u7684\u98ce\u9669\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u6a21\u578b\u63d0\u9ad8\u5176\u6027\u80fd\uff0c\u4f46\u5f53\u524d\u6a21\u578b\u4ecd\u65e0\u6cd5\u6ee1\u8db3\u9ad8\u98ce\u9669\u90e8\u7f72\u7684\u9700\u6c42\u3002", "motivation": "\u7531\u4e8e\u81ea\u4e3b\u7f51\u7edc\u4ee3\u7406\u53ef\u80fd\u91c7\u53d6\u610f\u5916\u6216\u6709\u5bb3\u7684\u884c\u4e3a\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u7684\u5b89\u5168\u63aa\u65bd\uff0c\u7c7b\u4f3c\u4e8e\u5bf9\u4eba\u7c7b\u7528\u6237\u7684\u8bbf\u95ee\u63a7\u5236\u3002", "method": "\u5f15\u5165WebGuard\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u7f51\u7edc\u4ee3\u7406\u884c\u52a8\u98ce\u9669\u5e76\u5f00\u53d1\u9632\u62a4\u63aa\u65bd\u3002\u901a\u8fc7\u5fae\u8c03\u4e13\u95e8\u7684guardrail\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u6d4b\u8bd5\u4e0d\u540c\u6cdb\u5316\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\u3002", "result": "\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684LLM\u5728\u9884\u6d4b\u884c\u52a8\u7ed3\u679c\u548c\u8bc6\u522b\u9ad8\u98ce\u9669\u884c\u52a8\u65b9\u9762\u4e5f\u8868\u73b0\u51fa\u4e0d\u8db3\uff0c\u800c\u5fae\u8c03\u540e\u7684Qwen2.5VL-7B\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u4f46\u4ecd\u4e0d\u8db3\u4ee5\u6ee1\u8db3\u9ad8\u98ce\u9669\u90e8\u7f72\u7684\u8981\u6c42\u3002", "conclusion": "\u5c3d\u7ba1\u5728\u4f7f\u7528WebGuard\u8fdb\u884c\u5fae\u8c03\u540e\uff0c\u6a21\u578b\u6027\u80fd\u6709\u6240\u63d0\u5347\uff0c\u4f46\u4ecd\u7136\u65e0\u6cd5\u6ee1\u8db3\u9ad8\u98ce\u9669\u90e8\u7f72\u6240\u9700\u7684\u53ef\u9760\u6027\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdbguardrail\u6a21\u578b\u4ee5\u63a5\u8fd1\u5b8c\u7f8e\u7684\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u3002"}}
{"id": "2507.14353", "pdf": "https://arxiv.org/pdf/2507.14353", "abs": "https://arxiv.org/abs/2507.14353", "authors": ["Harsh Nilesh Pathak", "Randy Paffenroth"], "title": "Solo Connection: A Parameter Efficient Fine-Tuning Technique for Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Parameter efficient fine tuning (PEFT) is a versatile and extensible approach\nfor adapting a Large Language Model (LLM) for newer tasks. One of the most\nprominent PEFT approaches, Low Rank Adaptation (LoRA), primarily focuses on\nadjusting the attention weight matrices within individual decoder blocks of a\nGenerative Pre trained Transformer (GPT2). In contrast, we introduce Solo\nConnection a novel method that adapts the representation at the decoder-block\nlevel rather than modifying individual weight matrices. Not only does Solo\nConnection outperform LoRA on E2E natural language generation benchmarks, but\nit also reduces the number of trainable parameters by 59% relative to LoRA and\nby more than 99% compared to full fine-tuning of GPT2, an early version of\nLarge Language Models (LLMs). Solo Connection is also motivated by homotopy\ntheory: we introduce a trainable linear transformation that gradually\ninterpolates between a zero vector and the task-specific representation,\nenabling smooth and stable adaptation over time. While skip connections in the\noriginal 12 layer GPT2 are typically confined to individual decoder blocks,\nsubsequent GPT2 variants scale up to 48 layers, and even larger language models\ncan include 128 or more decoder blocks. These expanded architectures underscore\nthe need to revisit how skip connections are employed during fine-tuning. This\npaper focuses on long skip connections that link outputs of different decoder\nblocks, potentially enhancing the model's ability to adapt to new tasks while\nleveraging pre-trained knowledge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSolo Connection\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u5728\u89e3\u7801\u5668\u5757\u7ea7\u522b\u8c03\u6574\u8868\u793a\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8\u7684\u6027\u80fd\u548c\u66f4\u4f4e\u7684\u53c2\u6570\u6570\u91cf\u3002", "motivation": "\u73b0\u6709\u7684PEFT\u65b9\u6cd5\u5982LoRA\u4e3b\u8981\u96c6\u4e2d\u5728\u8c03\u6574\u6ce8\u610f\u529b\u6743\u91cd\u77e9\u9635\uff0c\u800cSolo Connection\u65e8\u5728\u901a\u8fc7\u5728\u89e3\u7801\u5668\u5757\u7ea7\u522b\u8c03\u6574\u8868\u793a\u6765\u63d0\u9ad8\u6a21\u578b\u7684\u9002\u5e94\u80fd\u529b\u3002\u540c\u65f6\uff0c\u968f\u7740GPT2\u53d8\u4f53\u6269\u5c55\u5230\u66f4\u591a\u5c42\uff0c\u9700\u8981\u91cd\u65b0\u8003\u8651\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u8df3\u8fc7\u8fde\u63a5\u7684\u4f7f\u7528\u65b9\u5f0f\u3002", "method": "Solo Connection \u65b9\u6cd5\u901a\u8fc7\u5728\u89e3\u7801\u5668\u5757\u7ea7\u522b\u8c03\u6574\u8868\u793a\uff0c\u800c\u4e0d\u662f\u4fee\u6539\u5355\u4e2a\u6743\u91cd\u77e9\u9635\u3002\u5b83\u5f15\u5165\u4e86\u4e00\u4e2a\u53ef\u8bad\u7ec3\u7684\u7ebf\u6027\u53d8\u6362\uff0c\u4ee5\u9010\u6e10\u63d2\u503c\u96f6\u5411\u91cf\u548c\u4efb\u52a1\u7279\u5b9a\u8868\u793a\uff0c\u4ece\u800c\u5b9e\u73b0\u5e73\u6ed1\u548c\u7a33\u5b9a\u7684\u9002\u5e94\u3002", "result": "Solo Connection \u5728E2E\u81ea\u7136\u8bed\u8a00\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8eLoRA\uff0c\u5e76\u4e14\u76f8\u6bd4LoRA\u51cf\u5c11\u4e8659%\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u76f8\u6bd4\u5b8c\u6574\u5fae\u8c03GPT2\u51cf\u5c11\u4e86\u8d85\u8fc799%\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u3002", "conclusion": "Solo Connection \u662f\u4e00\u79cd\u65b0\u9896\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u5b83\u5728E2E\u81ea\u7136\u8bed\u8a00\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8eLoRA\uff0c\u5e76\u4e14\u51cf\u5c11\u4e86\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u6570\u91cf\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u540c\u4f26\u7406\u8bba\uff0c\u901a\u8fc7\u53ef\u8bad\u7ec3\u7684\u7ebf\u6027\u53d8\u6362\u9010\u6e10\u5c06\u96f6\u5411\u91cf\u4e0e\u4efb\u52a1\u7279\u5b9a\u8868\u793a\u8fdb\u884c\u63d2\u503c\uff0c\u4ece\u800c\u5b9e\u73b0\u7a33\u5b9a\u548c\u6e10\u8fdb\u7684\u9002\u5e94\u3002"}}
{"id": "2507.14384", "pdf": "https://arxiv.org/pdf/2507.14384", "abs": "https://arxiv.org/abs/2507.14384", "authors": ["Angjelin Hila", "Elliott Hauser"], "title": "Assessing the Reliability of Large Language Models for Deductive Qualitative Coding: A Comparative Study of ChatGPT Interventions", "categories": ["cs.HC", "cs.CL"], "comment": "Extended version of paper accepted for presentation at the ASIS&T\n  Annual Meeting 2025. 38 pages, 12 figures", "summary": "In this study, we investigate the use of large language models (LLMs),\nspecifically ChatGPT, for structured deductive qualitative coding. While most\ncurrent research emphasizes inductive coding applications, we address the\nunderexplored potential of LLMs to perform deductive classification tasks\naligned with established human-coded schemes. Using the Comparative Agendas\nProject (CAP) Master Codebook, we classified U.S. Supreme Court case summaries\ninto 21 major policy domains. We tested four intervention methods: zero-shot,\nfew-shot, definition-based, and a novel Step-by-Step Task Decomposition\nstrategy, across repeated samples. Performance was evaluated using standard\nclassification metrics (accuracy, F1-score, Cohen's kappa, Krippendorff's\nalpha), and construct validity was assessed using chi-squared tests and\nCramer's V. Chi-squared and effect size analyses confirmed that intervention\nstrategies significantly influenced classification behavior, with Cramer's V\nvalues ranging from 0.359 to 0.613, indicating moderate to strong shifts in\nclassification patterns. The Step-by-Step Task Decomposition strategy achieved\nthe strongest reliability (accuracy = 0.775, kappa = 0.744, alpha = 0.746),\nachieving thresholds for substantial agreement. Despite the semantic ambiguity\nwithin case summaries, ChatGPT displayed stable agreement across samples,\nincluding high F1 scores in low-support subclasses. These findings demonstrate\nthat with targeted, custom-tailored interventions, LLMs can achieve reliability\nlevels suitable for integration into rigorous qualitative coding workflows.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982ChatGPT\uff09\u5728\u6f14\u7ece\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u901a\u8fc7\u4e0d\u540c\u7684\u5e72\u9884\u7b56\u7565\u63d0\u9ad8\u4e86\u5176\u53ef\u9760\u6027\uff0c\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u53ef\u4ee5\u7528\u4e8e\u4e25\u683c\u7684\u5b9a\u6027\u7f16\u7801\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u7814\u7a76\u96c6\u4e2d\u5728\u5f52\u7eb3\u7f16\u7801\u5e94\u7528\u4e0a\uff0c\u800c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7b26\u5408\u65e2\u5b9a\u4eba\u7c7b\u7f16\u7801\u65b9\u6848\u7684\u6f14\u7ece\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u4e86\u56db\u79cd\u5e72\u9884\u65b9\u6cd5\uff1a\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u3001\u57fa\u4e8e\u5b9a\u4e49\u7684\u65b9\u6cd5\u4ee5\u53ca\u4e00\u79cd\u65b0\u7684\u9010\u6b65\u4efb\u52a1\u5206\u89e3\u7b56\u7565\uff0c\u5bf9\u7f8e\u56fd\u6700\u9ad8\u6cd5\u9662\u6848\u4ef6\u6458\u8981\u8fdb\u884c\u4e86\u5206\u7c7b\uff0c\u5e76\u901a\u8fc7\u6807\u51c6\u5206\u7c7b\u6307\u6807\u548c\u6784\u5efa\u6548\u5ea6\u5206\u6790\u8bc4\u4f30\u4e86\u6027\u80fd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u9010\u6b65\u4efb\u52a1\u5206\u89e3\u7b56\u7565\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u4e3a0.775\uff0ckappa\u503c\u4e3a0.744\uff0calpha\u503c\u4e3a0.746\uff0c\u8fbe\u5230\u4e86\u5b9e\u8d28\u6027\u534f\u8bae\u7684\u9608\u503c\u3002\u6b64\u5916\uff0cChatGPT\u5728\u6848\u4f8b\u6458\u8981\u4e2d\u8868\u73b0\u51fa\u7a33\u5b9a\u7684\u534f\u8bae\uff0c\u5305\u62ec\u4f4e\u652f\u6301\u5b50\u7c7b\u4e2d\u7684\u9ad8F1\u5206\u6570\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u7684\u5b9a\u5236\u5e72\u9884\u63aa\u65bd\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982ChatGPT\uff09\u53ef\u4ee5\u8fbe\u5230\u9002\u5408\u96c6\u6210\u5230\u4e25\u683c\u5b9a\u6027\u7f16\u7801\u5de5\u4f5c\u6d41\u7a0b\u7684\u53ef\u9760\u6027\u6c34\u5e73\u3002"}}
{"id": "2507.14417", "pdf": "https://arxiv.org/pdf/2507.14417", "abs": "https://arxiv.org/abs/2507.14417", "authors": ["Aryo Pradipta Gema", "Alexander H\u00e4gele", "Runjin Chen", "Andy Arditi", "Jacob Goldman-Wetzler", "Kit Fraser-Taliente", "Henry Sleight", "Linda Petrini", "Julian Michael", "Beatrice Alex", "Pasquale Minervini", "Yanda Chen", "Joe Benton", "Ethan Perez"], "title": "Inverse Scaling in Test-Time Compute", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "We construct evaluation tasks where extending the reasoning length of Large\nReasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling\nrelationship between test-time compute and accuracy. Our evaluation tasks span\nfour categories: simple counting tasks with distractors, regression tasks with\nspurious features, deduction tasks with constraint tracking, and advanced AI\nrisks. We identify five distinct failure modes when models reason for longer:\n1) Claude models become increasingly distracted by irrelevant information; 2)\nOpenAI o-series models resist distractors but overfit to problem framings; 3)\nmodels shift from reasonable priors to spurious correlations; 4) all models\nshow difficulties in maintaining focus on complex deductive tasks; and 5)\nextended reasoning may amplify concerning behaviors, with Claude Sonnet 4\nshowing increased expressions of self-preservation. These findings suggest that\nwhile test-time compute scaling remains promising for improving model\ncapabilities, it may inadvertently reinforce problematic reasoning patterns.\nOur results demonstrate the importance of evaluating models across diverse\nreasoning lengths to identify and address these failure modes in LRMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u6269\u5c55\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u957f\u5ea6\u53ef\u80fd\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u5e76\u51fa\u73b0\u591a\u79cd\u5931\u8d25\u6a21\u5f0f\uff0c\u5f3a\u8c03\u4e86\u5728\u4e0d\u540c\u63a8\u7406\u957f\u5ea6\u4e0b\u8bc4\u4f30\u6a21\u578b\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u6211\u4eec\u60f3\u8981\u7814\u7a76\u6269\u5c55\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u957f\u5ea6\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u8bc6\u522b\u53ef\u80fd\u7684\u5931\u8d25\u6a21\u5f0f\u3002", "method": "\u6211\u4eec\u6784\u5efa\u4e86\u8bc4\u4f30\u4efb\u52a1\uff0c\u5176\u4e2d\u6269\u5c55\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u7684\u63a8\u7406\u957f\u5ea6\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u663e\u793a\u51fa\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u4e0e\u51c6\u786e\u7387\u4e4b\u95f4\u7684\u53cd\u5411\u5173\u7cfb\u3002", "result": "\u6211\u4eec\u53d1\u73b0\u5f53\u6a21\u578b\u8fdb\u884c\u66f4\u957f\u7684\u63a8\u7406\u65f6\uff0c\u4f1a\u51fa\u73b0\u4e94\u79cd\u4e0d\u540c\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5305\u62ec\u88ab\u65e0\u5173\u4fe1\u606f\u5206\u6563\u6ce8\u610f\u529b\u3001\u8fc7\u5ea6\u62df\u5408\u95ee\u9898\u6846\u67b6\u3001\u4ece\u5408\u7406\u7684\u5148\u9a8c\u8f6c\u5411\u865a\u5047\u76f8\u5173\u6027\u3001\u96be\u4ee5\u4fdd\u6301\u5bf9\u590d\u6742\u6f14\u7ece\u4efb\u52a1\u7684\u4e13\u6ce8\u4ee5\u53ca\u53ef\u80fd\u653e\u5927\u4ee4\u4eba\u62c5\u5fe7\u7684\u884c\u4e3a\u3002", "conclusion": "\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u4e0d\u540c\u63a8\u7406\u957f\u5ea6\u4e0b\u7684\u8868\u73b0\u5bf9\u4e8e\u8bc6\u522b\u548c\u89e3\u51b3LRMs\u4e2d\u7684\u8fd9\u4e9b\u5931\u8d25\u6a21\u5f0f\u975e\u5e38\u91cd\u8981\u3002"}}
{"id": "2507.14419", "pdf": "https://arxiv.org/pdf/2507.14419", "abs": "https://arxiv.org/abs/2507.14419", "authors": ["Guojun Wu"], "title": "It's Not That Simple. An Analysis of Simple Test-Time Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Prior work proposed simple test-time scaling, a method for replicating this\nscaling behavior with models distilled from o1-like models by manually\ncontrolling test-time compute: either scaling down by enforcing a maximum\nlength or scaling up by iteratively appending \"Wait\" when the model is about to\nterminate its generation. This paper presents an analysis of simple test-time\nscaling and finds that the scaling behavior is largely attributed to scaling\ndown by enforcing a maximum length. In contrast, fine-tuning on long CoT data\ndistilled from o1-like models has no significant impact on scaling behavior,\nand scaling up by appending \"Wait\" leads to inconsistencies, as the model may\noscillate between solutions. A key distinction exists between scaling down by\nenforcing a maximum length and scaling up test-time compute in o1-like models,\nsuch as DeepSeek-R1\\@. These models are typically allowed to utilize as much\ncompute as needed, with the only constraint being the model's maximum supported\nlength. By learning to naturally scale up test-time compute during\nreinforcement learning, o1-like models surpass their peak performance when\nscaling up. In contrast, simple test-time scaling progressively imposes a lower\nupper limit on model performance as it scales down. While replicating the\ntest-time scaling behavior of o1 models can be straightforward by scaling down,\nit is crucial to recognize that the goal of scaling test-time compute is to\nunlock higher performance -- beyond what the model could originally achieve --\nrather than merely reproducing the appearance of scaling behavior.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u7b80\u5355\u7684\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\uff0c\u53d1\u73b0\u5176\u4e3b\u8981\u4f9d\u8d56\u4e8e\u901a\u8fc7\u5f3a\u5236\u6700\u5927\u957f\u5ea6\u8fdb\u884c\u7f29\u653e\uff0c\u800c\u901a\u8fc7\u9644\u52a0'Wait'\u8fdb\u884c\u7f29\u653e\u4f1a\u5bfc\u81f4\u4e0d\u4e00\u81f4\u3002o1\u7c7b\u4f3c\u6a21\u578b\u5728\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u80fd\u529b\u7684\u6269\u5c55\u80fd\u591f\u8d85\u8d8a\u5176\u5cf0\u503c\u6027\u80fd\uff0c\u800c\u7b80\u5355\u7684\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\u4f1a\u9010\u6b65\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u7684\u4e0a\u9650\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u5206\u6790\u7b80\u5355\u7684\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\uff0c\u5e76\u63a2\u8ba8\u5176\u5728\u4e0d\u540c\u6a21\u578b\u4e2d\u7684\u6548\u679c\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u5982\u4f55\u901a\u8fc7\u6269\u5c55\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u80fd\u529b\u6765\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "method": "\u672c\u6587\u5206\u6790\u4e86\u7b80\u5355\u7684\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e0d\u540c\u65b9\u6cd5\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u672c\u6587\u53d1\u73b0\uff0c\u7b80\u5355\u7684\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u901a\u8fc7\u5f3a\u5236\u6700\u5927\u957f\u5ea6\u8fdb\u884c\u7f29\u653e\uff0c\u800c\u901a\u8fc7\u9644\u52a0'Wait'\u8fdb\u884c\u7f29\u653e\u4f1a\u5bfc\u81f4\u4e0d\u4e00\u81f4\u3002\u6b64\u5916\uff0co1\u7c7b\u4f3c\u6a21\u578b\u5728\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u80fd\u529b\u7684\u6269\u5c55\u80fd\u591f\u8d85\u8d8a\u5176\u5cf0\u503c\u6027\u80fd\uff0c\u800c\u7b80\u5355\u7684\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\u4f1a\u9010\u6b65\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u7684\u4e0a\u9650\u3002", "conclusion": "\u672c\u6587\u5206\u6790\u4e86\u7b80\u5355\u7684\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\uff0c\u5e76\u53d1\u73b0\u5176\u7f29\u653e\u884c\u4e3a\u4e3b\u8981\u5f52\u56e0\u4e8e\u901a\u8fc7\u5f3a\u5236\u6700\u5927\u957f\u5ea6\u8fdb\u884c\u7f29\u653e\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5bf9\u4eceo1\u7c7b\u4f3c\u6a21\u578b\u4e2d\u63d0\u70bc\u7684\u957f\u94fe\u601d\u7ef4\u6570\u636e\u8fdb\u884c\u5fae\u8c03\u5bf9\u7f29\u653e\u884c\u4e3a\u6ca1\u6709\u663e\u8457\u5f71\u54cd\uff0c\u800c\u901a\u8fc7\u9644\u52a0'Wait'\u8fdb\u884c\u7f29\u653e\u4f1a\u5bfc\u81f4\u4e0d\u4e00\u81f4\uff0c\u56e0\u4e3a\u6a21\u578b\u53ef\u80fd\u4f1a\u5728\u89e3\u51b3\u65b9\u6848\u4e4b\u95f4\u632f\u8361\u3002o1\u7c7b\u4f3c\u6a21\u578b\uff08\u5982DeepSeek-R1@\uff09\u5728\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u80fd\u529b\u7684\u6269\u5c55\u4e0e\u901a\u8fc7\u5f3a\u5236\u6700\u5927\u957f\u5ea6\u8fdb\u884c\u7f29\u653e\u5b58\u5728\u5173\u952e\u533a\u522b\u3002\u8fd9\u4e9b\u6a21\u578b\u901a\u5e38\u88ab\u5141\u8bb8\u4f7f\u7528\u6240\u9700\u7684\u4efb\u4f55\u8ba1\u7b97\u8d44\u6e90\uff0c\u552f\u4e00\u7684\u9650\u5236\u662f\u6a21\u578b\u7684\u6700\u5927\u652f\u6301\u957f\u5ea6\u3002\u901a\u8fc7\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u5b66\u4e60\u81ea\u7136\u5730\u6269\u5c55\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u80fd\u529b\uff0co1\u7c7b\u4f3c\u6a21\u578b\u5728\u6269\u5c55\u65f6\u8d85\u8d8a\u4e86\u5176\u5cf0\u503c\u6027\u80fd\u3002\u76f8\u53cd\uff0c\u7b80\u5355\u7684\u6d4b\u8bd5\u65f6\u7f29\u653e\u4f1a\u968f\u7740\u7f29\u653e\u7684\u8fdb\u884c\u9010\u6b65\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u7684\u4e0a\u9650\u3002\u867d\u7136\u53ef\u4ee5\u901a\u8fc7\u7f29\u653e\u6765\u590d\u5236o1\u6a21\u578b\u7684\u6d4b\u8bd5\u65f6\u7f29\u653e\u884c\u4e3a\uff0c\u4f46\u5fc5\u987b\u8ba4\u8bc6\u5230\uff0c\u6269\u5c55\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u80fd\u529b\u7684\u76ee\u6807\u662f\u89e3\u9501\u66f4\u9ad8\u7684\u6027\u80fd\u2014\u2014\u8d85\u8d8a\u6a21\u578b\u539f\u672c\u53ef\u4ee5\u8fbe\u5230\u7684\u6027\u80fd\u2014\u2014\u800c\u4e0d\u662f\u4ec5\u4ec5\u518d\u73b0\u7f29\u653e\u884c\u4e3a\u7684\u5916\u89c2\u3002"}}
{"id": "2507.14447", "pdf": "https://arxiv.org/pdf/2507.14447", "abs": "https://arxiv.org/abs/2507.14447", "authors": ["Guancheng Zeng", "Xueyi Chen", "Jiawang Hu", "Shaohua Qi", "Yaxuan Mao", "Zhantao Wang", "Yifan Nie", "Shuang Li", "Qiuyang Feng", "Pengxu Qiu", "Yujia Wang", "Wenqiang Han", "Linyan Huang", "Gang Li", "Jingjing Mo", "Haowen Hu"], "title": "Routine: A Structural Planning Framework for LLM Agent System in Enterprise", "categories": ["cs.AI", "cs.CL"], "comment": "26 pages, 8 figures, 5 tables", "summary": "The deployment of agent systems in an enterprise environment is often\nhindered by several challenges: common models lack domain-specific process\nknowledge, leading to disorganized plans, missing key tools, and poor execution\nstability. To address this, this paper introduces Routine, a multi-step agent\nplanning framework designed with a clear structure, explicit instructions, and\nseamless parameter passing to guide the agent's execution module in performing\nmulti-step tool-calling tasks with high stability. In evaluations conducted\nwithin a real-world enterprise scenario, Routine significantly increases the\nexecution accuracy in model tool calls, increasing the performance of GPT-4o\nfrom 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. We further constructed\na Routine-following training dataset and fine-tuned Qwen3-14B, resulting in an\naccuracy increase to 88.2% on scenario-specific evaluations, indicating\nimproved adherence to execution plans. In addition, we employed Routine-based\ndistillation to create a scenario-specific, multi-step tool-calling dataset.\nFine-tuning on this distilled dataset raised the model's accuracy to 95.5%,\napproaching GPT-4o's performance. These results highlight Routine's\neffectiveness in distilling domain-specific tool-usage patterns and enhancing\nmodel adaptability to new scenarios. Our experimental results demonstrate that\nRoutine provides a practical and accessible approach to building stable agent\nworkflows, accelerating the deployment and adoption of agent systems in\nenterprise environments, and advancing the technical vision of AI for Process.", "AI": {"tldr": "This paper introduces Routine, a multi-step agent planning framework that enhances the stability and accuracy of agent systems in enterprise environments by incorporating domain-specific process knowledge and improving model adaptability to new scenarios.", "motivation": "The deployment of agent systems in an enterprise environment is often hindered by challenges such as common models lacking domain-specific process knowledge, leading to disorganized plans, missing key tools, and poor execution stability.", "method": "Routine is a multi-step agent planning framework designed with a clear structure, explicit instructions, and seamless parameter passing to guide the agent's execution module in performing multi-step tool-calling tasks with high stability. Additionally, a Routine-following training dataset was constructed, and Qwen3-14B was fine-tuned. Routine-based distillation was also employed to create a scenario-specific, multi-step tool-calling dataset.", "result": "In evaluations conducted within a real-world enterprise scenario, Routine significantly increases the execution accuracy in model tool calls, increasing the performance of GPT-4o from 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. Fine-tuning on the distilled dataset raised the model's accuracy to 95.5%, approaching GPT-4o's performance.", "conclusion": "Routine provides a practical and accessible approach to building stable agent workflows, accelerating the deployment and adoption of agent systems in enterprise environments, and advancing the technical vision of AI for Process."}}
{"id": "2507.14497", "pdf": "https://arxiv.org/pdf/2507.14497", "abs": "https://arxiv.org/abs/2507.14497", "authors": ["Weimin Lyu", "Qingqiao Hu", "Kehan Qi", "Zhan Shi", "Wentao Huang", "Saumya Gupta", "Chao Chen"], "title": "Efficient Whole Slide Pathology VQA via Token Compression", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Whole-slide images (WSIs) in pathology can reach up to 10,000 x 10,000\npixels, posing significant challenges for multimodal large language model\n(MLLM) due to long context length and high computational demands. Previous\nmethods typically focus on patch-level analysis or slide-level classification\nusing CLIP-based models with multi-instance learning, but they lack the\ngenerative capabilities needed for visual question answering (VQA). More recent\nMLLM-based approaches address VQA by feeding thousands of patch tokens directly\ninto the language model, which leads to excessive resource consumption. To\naddress these limitations, we propose Token Compression Pathology LLaVA\n(TCP-LLaVA), the first MLLM architecture to perform WSI VQA via token\ncompression. TCP-LLaVA introduces a set of trainable compression tokens that\naggregate visual and textual information through a modality compression module,\ninspired by the [CLS] token mechanism in BERT. Only the compressed tokens are\nforwarded to the LLM for answer generation, significantly reducing input length\nand computational cost. Experiments on ten TCGA tumor subtypes show that\nTCP-LLaVA outperforms existing MLLM baselines in VQA accuracy while reducing\ntraining resource consumption by a substantial margin.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTCP-LLaVA\u7684\u65b0\u67b6\u6784\uff0c\u901a\u8fc7\u4ee4\u724c\u538b\u7f29\u5b9e\u73b0\u5168\u5207\u7247\u56fe\u50cf\u7684\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\u3002", "motivation": "\u5168\u5207\u7247\u56fe\u50cf\uff08WSI\uff09\u5728\u75c5\u7406\u5b66\u4e2d\u53ef\u4ee5\u8fbe\u523010,000 x 10,000\u50cf\u7d20\uff0c\u8fd9\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6218\uff0c\u56e0\u4e3a\u9700\u8981\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u957f\u5ea6\u548c\u9ad8\u8ba1\u7b97\u9700\u6c42\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7528\u4e8e\u89c6\u89c9\u95ee\u7b54\uff08VQA\uff09\u6240\u9700\u7684\u751f\u6210\u80fd\u529b\u3002", "method": "TCP-LLaVA\u5f15\u5165\u4e86\u4e00\u7ec4\u53ef\u8bad\u7ec3\u7684\u538b\u7f29\u4ee4\u724c\uff0c\u901a\u8fc7\u6a21\u6001\u538b\u7f29\u6a21\u5757\u805a\u5408\u89c6\u89c9\u548c\u6587\u672c\u4fe1\u606f\uff0c\u4ec5\u5c06\u538b\u7f29\u540e\u7684\u4ee4\u724c\u4f20\u9012\u7ed9LLM\u8fdb\u884c\u7b54\u6848\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTCP-LLaVA\u5728\u5341\u4e2aTCGA\u80bf\u7624\u4e9a\u578b\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u7684MLLM\u57fa\u7ebf\uff0c\u5e76\u4e14\u663e\u8457\u51cf\u5c11\u4e86\u8bad\u7ec3\u8d44\u6e90\u6d88\u8017\u3002", "conclusion": "TCP-LLaVA\u5728VQA\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684MLLM\u57fa\u7ebf\uff0c\u5e76\u4e14\u663e\u8457\u51cf\u5c11\u4e86\u8bad\u7ec3\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2507.14534", "pdf": "https://arxiv.org/pdf/2507.14534", "abs": "https://arxiv.org/abs/2507.14534", "authors": ["Yu Zhang", "Baotong Tian", "Zhiyao Duan"], "title": "Conan: A Chunkwise Online Network for Zero-Shot Adaptive Voice Conversion", "categories": ["eess.AS", "cs.CL", "cs.SD"], "comment": null, "summary": "Zero-shot online voice conversion (VC) holds significant promise for\nreal-time communications and entertainment. However, current VC models struggle\nto preserve semantic fidelity under real-time constraints, deliver\nnatural-sounding conversions, and adapt effectively to unseen speaker\ncharacteristics. To address these challenges, we introduce Conan, a chunkwise\nonline zero-shot voice conversion model that preserves the content of the\nsource while matching the voice timbre and styles of reference speech. Conan\ncomprises three core components: 1) a Stream Content Extractor that leverages\nEmformer for low-latency streaming content encoding; 2) an Adaptive Style\nEncoder that extracts fine-grained stylistic features from reference speech for\nenhanced style adaptation; 3) a Causal Shuffle Vocoder that implements a fully\ncausal HiFiGAN using a pixel-shuffle mechanism. Experimental evaluations\ndemonstrate that Conan outperforms baseline models in subjective and objective\nmetrics. Audio samples can be found at https://aaronz345.github.io/ConanDemo.", "AI": {"tldr": "Conan is a chunkwise online zero-shot voice conversion model that preserves the content of the source while matching the voice timbre and styles of reference speech.", "motivation": "Current VC models struggle to preserve semantic fidelity under real-time constraints, deliver natural-sounding conversions, and adapt effectively to unseen speaker characteristics.", "method": "Conan is a chunkwise online zero-shot voice conversion model that comprises three core components: a Stream Content Extractor, an Adaptive Style Encoder, and a Causal Shuffle Vocoder.", "result": "Experimental evaluations demonstrate that Conan outperforms baseline models in subjective and objective metrics.", "conclusion": "Conan outperforms baseline models in subjective and objective metrics."}}
{"id": "2507.14586", "pdf": "https://arxiv.org/pdf/2507.14586", "abs": "https://arxiv.org/abs/2507.14586", "authors": ["Adrian Ehrenhofer", "Thomas Wallmersperger", "Gianaurelio Cuniberti"], "title": "What do Large Language Models know about materials?", "categories": ["physics.app-ph", "cs.CE", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly applied in the fields of\nmechanical engineering and materials science. As models that establish\nconnections through the interface of language, LLMs can be applied for\nstep-wise reasoning through the Processing-Structure-Property-Performance chain\nof material science and engineering. Current LLMs are built for adequately\nrepresenting a dataset, which is the most part of the accessible internet.\nHowever, the internet mostly contains non-scientific content. If LLMs should be\napplied for engineering purposes, it is valuable to investigate models for\ntheir intrinsic knowledge -- here: the capacity to generate correct information\nabout materials. In the current work, for the example of the Periodic Table of\nElements, we highlight the role of vocabulary and tokenization for the\nuniqueness of material fingerprints, and the LLMs' capabilities of generating\nfactually correct output of different state-of-the-art open models. This leads\nto a material knowledge benchmark for an informed choice, for which steps in\nthe PSPP chain LLMs are applicable, and where specialized models are required.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLMs\u5728\u6750\u6599\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u6750\u6599\u77e5\u8bc6\u57fa\u51c6\uff0c\u4ee5\u5e2e\u52a9\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u7684LLMs\u4e3b\u8981\u9488\u5bf9\u4e92\u8054\u7f51\u4e0a\u7684\u975e\u79d1\u5b66\u5185\u5bb9\u8fdb\u884c\u8bad\u7ec3\uff0c\u800c\u5de5\u7a0b\u5e94\u7528\u9700\u8981\u6a21\u578b\u5177\u5907\u751f\u6210\u6b63\u786e\u6750\u6599\u4fe1\u606f\u7684\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u7814\u7a76\u6a21\u578b\u7684\u5185\u5728\u77e5\u8bc6\u3002", "method": "\u672c\u6587\u4ee5\u5143\u7d20\u5468\u671f\u8868\u4e3a\u4f8b\uff0c\u7814\u7a76\u4e86\u8bcd\u6c47\u548c\u5206\u8bcd\u5728\u6750\u6599\u6307\u7eb9\u552f\u4e00\u6027\u4e2d\u7684\u4f5c\u7528\uff0c\u4ee5\u53caLLMs\u751f\u6210\u4e8b\u5b9e\u6b63\u786e\u8f93\u51fa\u7684\u80fd\u529b\u3002", "result": "\u672c\u6587\u5c55\u793a\u4e86\u4e0d\u540c\u6700\u5148\u8fdb\u7684\u5f00\u653e\u6a21\u578b\u5728\u751f\u6210\u6b63\u786e\u6750\u6599\u4fe1\u606f\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u6750\u6599\u77e5\u8bc6\u57fa\u51c6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6750\u6599\u77e5\u8bc6\u57fa\u51c6\uff0c\u4ee5\u5e2e\u52a9\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\uff0c\u5e76\u786e\u5b9aLLMs\u5728PSPP\u94fe\u4e2d\u7684\u9002\u7528\u6027\u4ee5\u53ca\u9700\u8981\u4e13\u4e1a\u6a21\u578b\u7684\u9886\u57df\u3002"}}
{"id": "2507.14619", "pdf": "https://arxiv.org/pdf/2507.14619", "abs": "https://arxiv.org/abs/2507.14619", "authors": ["Van-Hoang Le", "Duc-Vu Nguyen", "Kiet Van Nguyen", "Ngan Luu-Thuy Nguyen"], "title": "Optimizing Legal Document Retrieval in Vietnamese with Semi-Hard Negative Mining", "categories": ["cs.IR", "cs.CL"], "comment": "Accepted at ICCCI 2025", "summary": "Large Language Models (LLMs) face significant challenges in specialized\ndomains like law, where precision and domain-specific knowledge are critical.\nThis paper presents a streamlined two-stage framework consisting of Retrieval\nand Re-ranking to enhance legal document retrieval efficiency and accuracy. Our\napproach employs a fine-tuned Bi-Encoder for rapid candidate retrieval,\nfollowed by a Cross-Encoder for precise re-ranking, both optimized through\nstrategic negative example mining. Key innovations include the introduction of\nthe Exist@m metric to evaluate retrieval effectiveness and the use of semi-hard\nnegatives to mitigate training bias, which significantly improved re-ranking\nperformance. Evaluated on the SoICT Hackathon 2024 for Legal Document\nRetrieval, our team, 4Huiter, achieved a top-three position. While\ntop-performing teams employed ensemble models and iterative self-training on\nlarge bge-m3 architectures, our lightweight, single-pass approach offered a\ncompetitive alternative with far fewer parameters. The framework demonstrates\nthat optimized data processing, tailored loss functions, and balanced negative\nsampling are pivotal for building robust retrieval-augmented systems in legal\ncontexts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5316\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u9ad8\u6cd5\u5f8b\u6587\u6863\u68c0\u7d22\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u5fae\u8c03\u7684\u53cc\u7f16\u7801\u5668\u8fdb\u884c\u5feb\u901f\u5019\u9009\u68c0\u7d22\uff0c\u5e76\u4f7f\u7528\u4ea4\u53c9\u7f16\u7801\u5668\u8fdb\u884c\u7cbe\u786e\u91cd\u65b0\u6392\u5e8f\u3002\u5728SoICT Hackathon 2024\u6bd4\u8d5b\u4e2d\uff0c\u8be5\u65b9\u6cd5\u53d6\u5f97\u4e86\u524d\u4e09\u540d\u7684\u597d\u6210\u7ee9\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6cd5\u5f8b\u7b49\u4e13\u4e1a\u9886\u57df\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u5176\u4e2d\u7cbe\u5ea6\u548c\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5316\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5305\u62ec\u68c0\u7d22\u548c\u91cd\u65b0\u6392\u5e8f\uff0c\u4ee5\u63d0\u9ad8\u6cd5\u5f8b\u6587\u6863\u68c0\u7d22\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u5fae\u8c03\u7684\u53cc\u7f16\u7801\u5668\u8fdb\u884c\u5feb\u901f\u5019\u9009\u68c0\u7d22\uff0c\u7136\u540e\u4f7f\u7528\u4ea4\u53c9\u7f16\u7801\u5668\u8fdb\u884c\u7cbe\u786e\u91cd\u65b0\u6392\u5e8f\uff0c\u4e24\u8005\u90fd\u901a\u8fc7\u6218\u7565\u6027\u8d1f\u4f8b\u6316\u6398\u8fdb\u884c\u4e86\u4f18\u5316\u3002", "result": "\u5728SoICT Hackathon 2024\u6cd5\u5f8b\u6587\u6863\u68c0\u7d22\u6bd4\u8d5b\u4e2d\uff0c\u6211\u4eec\u7684\u56e2\u961f4Huiter\u83b7\u5f97\u4e86\u524d\u4e09\u540d\u3002\u867d\u7136\u8868\u73b0\u6700\u597d\u7684\u56e2\u961f\u91c7\u7528\u4e86\u96c6\u6210\u6a21\u578b\u548c\u5728\u5927\u578bbge-m3\u67b6\u6784\u4e0a\u7684\u8fed\u4ee3\u81ea\u8bad\u7ec3\uff0c\u4f46\u6211\u4eec\u7684\u8f7b\u91cf\u7ea7\u5355\u6b21\u901a\u8fc7\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5177\u6709\u66f4\u5c11\u53c2\u6570\u7684\u7ade\u4e89\u6027\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u8be5\u6846\u67b6\u8868\u660e\uff0c\u4f18\u5316\u7684\u6570\u636e\u5904\u7406\u3001\u5b9a\u5236\u7684\u635f\u5931\u51fd\u6570\u548c\u5e73\u8861\u7684\u8d1f\u6837\u672c\u91c7\u6837\u5bf9\u4e8e\u6784\u5efa\u6cd5\u5f8b\u73af\u5883\u4e2d\u7684\u5f3a\u5927\u68c0\u7d22\u589e\u5f3a\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.14660", "pdf": "https://arxiv.org/pdf/2507.14660", "abs": "https://arxiv.org/abs/2507.14660", "authors": ["Qibing Ren", "Sitao Xie", "Longxuan Wei", "Zhenfei Yin", "Junchi Yan", "Lizhuang Ma", "Jing Shao"], "title": "When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems", "categories": ["cs.AI", "cs.CL"], "comment": "Code is available at https://github.com/renqibing/RogueAgent", "summary": "Recent large-scale events like election fraud and financial scams have shown\nhow harmful coordinated efforts by human groups can be. With the rise of\nautonomous AI systems, there is growing concern that AI-driven groups could\nalso cause similar harm. While most AI safety research focuses on individual AI\nsystems, the risks posed by multi-agent systems (MAS) in complex real-world\nsituations are still underexplored. In this paper, we introduce a\nproof-of-concept to simulate the risks of malicious MAS collusion, using a\nflexible framework that supports both centralized and decentralized\ncoordination structures. We apply this framework to two high-risk fields:\nmisinformation spread and e-commerce fraud. Our findings show that\ndecentralized systems are more effective at carrying out malicious actions than\ncentralized ones. The increased autonomy of decentralized systems allows them\nto adapt their strategies and cause more damage. Even when traditional\ninterventions, like content flagging, are applied, decentralized groups can\nadjust their tactics to avoid detection. We present key insights into how these\nmalicious groups operate and the need for better detection systems and\ncountermeasures. Code is available at https://github.com/renqibing/RogueAgent.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53ef\u80fd\u5e26\u6765\u7684\u98ce\u9669\uff0c\u7279\u522b\u662f\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u5728\u6267\u884c\u6076\u610f\u884c\u4e3a\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u9700\u8981\u66f4\u597d\u7684\u68c0\u6d4b\u548c\u5e94\u5bf9\u63aa\u65bd\u3002", "motivation": "\u968f\u7740\u81ea\u4e3bAI\u7cfb\u7edf\u7684\u5174\u8d77\uff0c\u4eba\u4eec\u8d8a\u6765\u8d8a\u62c5\u5fc3AI\u9a71\u52a8\u7684\u7fa4\u4f53\u53ef\u80fd\u9020\u6210\u7684\u5371\u5bb3\u3002\u7136\u800c\uff0c\u76ee\u524d\u5927\u591a\u6570AI\u5b89\u5168\u7814\u7a76\u96c6\u4e2d\u5728\u5355\u4e2aAI\u7cfb\u7edf\u4e0a\uff0c\u800c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u5728\u590d\u6742\u73b0\u5b9e\u60c5\u51b5\u4e0b\u7684\u98ce\u9669\u4ecd\u7f3a\u4e4f\u63a2\u7d22\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u6846\u67b6\uff0c\u652f\u6301\u96c6\u4e2d\u5f0f\u548c\u53bb\u4e2d\u5fc3\u5f0f\u534f\u8c03\u7ed3\u6784\uff0c\u7528\u4e8e\u6a21\u62df\u6076\u610f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u98ce\u9669\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u6bd4\u96c6\u4e2d\u5f0f\u7cfb\u7edf\u66f4\u6709\u6548\u5730\u6267\u884c\u6076\u610f\u884c\u4e3a\u3002\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u7684\u81ea\u4e3b\u6027\u4f7f\u5176\u80fd\u591f\u9002\u5e94\u7b56\u7565\u5e76\u9020\u6210\u66f4\u591a\u635f\u5bb3\u3002\u5373\u4f7f\u5e94\u7528\u4e86\u4f20\u7edf\u5e72\u9884\u63aa\u65bd\uff0c\u5982\u5185\u5bb9\u6807\u8bb0\uff0c\u53bb\u4e2d\u5fc3\u5316\u7fa4\u4f53\u4e5f\u80fd\u8c03\u6574\u6218\u672f\u4ee5\u907f\u514d\u88ab\u68c0\u6d4b\u5230\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u62df\u6076\u610f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u52fe\u7ed3\u98ce\u9669\u7684\u539f\u578b\uff0c\u5e76\u5c55\u793a\u4e86\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u5728\u6267\u884c\u6076\u610f\u884c\u4e3a\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u540c\u65f6\uff0c\u672c\u6587\u5f3a\u8c03\u4e86\u9700\u8981\u66f4\u597d\u7684\u68c0\u6d4b\u7cfb\u7edf\u548c\u5e94\u5bf9\u63aa\u65bd\u6765\u5e94\u5bf9\u8fd9\u4e9b\u5a01\u80c1\u3002"}}
{"id": "2507.14675", "pdf": "https://arxiv.org/pdf/2507.14675", "abs": "https://arxiv.org/abs/2507.14675", "authors": ["Yuchen Duan", "Zhe Chen", "Yusong Hu", "Weiyun Wang", "Shenglong Ye", "Botian Shi", "Lewei Lu", "Qibin Hou", "Tong Lu", "Hongsheng Li", "Jifeng Dai", "Wenhai Wang"], "title": "Docopilot: Improving Multimodal Models for Document-Level Understanding", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Despite significant progress in multimodal large language models (MLLMs),\ntheir performance on complex, multi-page document comprehension remains\ninadequate, largely due to the lack of high-quality, document-level datasets.\nWhile current retrieval-augmented generation (RAG) methods offer partial\nsolutions, they suffer from issues, such as fragmented retrieval contexts,\nmulti-stage error accumulation, and extra time costs of retrieval. In this\nwork, we present a high-quality document-level dataset, Doc-750K, designed to\nsupport in-depth understanding of multimodal documents. This dataset includes\ndiverse document structures, extensive cross-page dependencies, and real\nquestion-answer pairs derived from the original documents. Building on the\ndataset, we develop a native multimodal model, Docopilot, which can accurately\nhandle document-level dependencies without relying on RAG. Experiments\ndemonstrate that Docopilot achieves superior coherence, accuracy, and\nefficiency in document understanding tasks and multi-turn interactions, setting\na new baseline for document-level multimodal understanding. Data, code, and\nmodels are released at https://github.com/OpenGVLab/Docopilot", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u8d28\u91cf\u7684\u6587\u6863\u7ea7\u6570\u636e\u96c6Doc-750K\uff0c\u5e76\u5f00\u53d1\u4e86\u65e0\u9700\u4f9d\u8d56RAG\u7684\u539f\u751f\u591a\u6a21\u6001\u6a21\u578bDocopilot\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u6587\u6863\u7406\u89e3\u4efb\u52a1\u548c\u591a\u8f6e\u4ea4\u4e92\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5c3d\u7ba1\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5b83\u4eec\u5728\u590d\u6742\u3001\u591a\u9875\u6587\u6863\u7406\u89e3\u65b9\u9762\u7684\u6027\u80fd\u4ecd\u7136\u4e0d\u8db3\uff0c\u4e3b\u8981\u662f\u7531\u4e8e\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u6587\u6863\u7ea7\u6570\u636e\u96c6\u3002\u867d\u7136\u5f53\u524d\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\u63d0\u4f9b\u4e86\u90e8\u5206\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5b83\u4eec\u5b58\u5728\u788e\u7247\u5316\u68c0\u7d22\u4e0a\u4e0b\u6587\u3001\u591a\u9636\u6bb5\u9519\u8bef\u7d2f\u79ef\u548c\u989d\u5916\u7684\u68c0\u7d22\u65f6\u95f4\u6210\u672c\u7b49\u95ee\u9898\u3002", "method": "\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u539f\u751f\u591a\u6a21\u6001\u6a21\u578bDocopilot\uff0c\u5b83\u53ef\u4ee5\u5728\u4e0d\u4f9d\u8d56RAG\u7684\u60c5\u51b5\u4e0b\u51c6\u786e\u5904\u7406\u6587\u6863\u7ea7\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "Docopilot\u5728\u6587\u6863\u7406\u89e3\u4efb\u52a1\u548c\u591a\u8f6e\u4ea4\u4e92\u4e2d\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u8fde\u8d2f\u6027\u3001\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u8bbe\u5b9a\u4e86\u65b0\u7684\u57fa\u51c6\u3002", "conclusion": "\u5b9e\u9a8c\u8868\u660e\uff0cDocopilot\u5728\u6587\u6863\u7406\u89e3\u4efb\u52a1\u548c\u591a\u8f6e\u4ea4\u4e92\u4e2d\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u8fde\u8d2f\u6027\u3001\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u4e3a\u6587\u6863\u7ea7\u591a\u6a21\u6001\u7406\u89e3\u8bbe\u5b9a\u4e86\u65b0\u57fa\u51c6\u3002"}}
{"id": "2507.14679", "pdf": "https://arxiv.org/pdf/2507.14679", "abs": "https://arxiv.org/abs/2507.14679", "authors": ["Zixin Xu", "Zhijie Wang", "Zhiyuan Pan"], "title": "GCC-Spam: Spam Detection via GAN, Contrastive Learning, and Character Similarity Networks", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The exponential growth of spam text on the Internet necessitates robust\ndetection mechanisms to mitigate risks such as information leakage and social\ninstability. This work addresses two principal challenges: adversarial\nstrategies employed by spammers and the scarcity of labeled data. We propose a\nnovel spam-text detection framework GCC-Spam, which integrates three core\ninnovations. First, a character similarity network captures orthographic and\nphonetic features to counter character-obfuscation attacks and furthermore\nproduces sentence embeddings for downstream classification. Second, contrastive\nlearning enhances discriminability by optimizing the latent-space distance\nbetween spam and normal texts. Third, a Generative Adversarial Network (GAN)\ngenerates realistic pseudo-spam samples to alleviate data scarcity while\nimproving model robustness and classification accuracy. Extensive experiments\non real-world datasets demonstrate that our model outperforms baseline\napproaches, achieving higher detection rates with significantly fewer labeled\nexamples.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5783\u573e\u6587\u672c\u68c0\u6d4b\u6846\u67b6GCC-Spam\uff0c\u901a\u8fc7\u5b57\u7b26\u76f8\u4f3c\u6027\u7f51\u7edc\u3001\u5bf9\u6bd4\u5b66\u4e60\u548c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u6765\u63d0\u9ad8\u68c0\u6d4b\u6548\u679c\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u4e92\u8054\u7f51\u4e0a\u5783\u573e\u6587\u672c\u7684\u6307\u6570\u589e\u957f\u9700\u8981\u5f3a\u5927\u7684\u68c0\u6d4b\u673a\u5236\u6765\u51cf\u8f7b\u4fe1\u606f\u6cc4\u9732\u548c\u793e\u4f1a\u4e0d\u7a33\u5b9a\u7b49\u98ce\u9669\u3002\u672c\u6587\u89e3\u51b3\u4e86\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u5783\u573e\u90ae\u4ef6\u53d1\u9001\u8005\u91c7\u7528\u7684\u5bf9\u6297\u7b56\u7565\u548c\u6807\u8bb0\u6570\u636e\u7684\u7a00\u7f3a\u6027\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aGCC-Spam\u7684\u65b0\u5783\u573e\u6587\u672c\u68c0\u6d4b\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u96c6\u6210\u4e86\u4e09\u4e2a\u6838\u5fc3\u521b\u65b0\uff1a\u5b57\u7b26\u76f8\u4f3c\u6027\u7f51\u7edc\u3001\u5bf9\u6bd4\u5b66\u4e60\u548c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u68c0\u6d4b\u7387\uff0c\u5e76\u4e14\u4f7f\u7528\u7684\u6807\u8bb0\u6837\u672c\u663e\u8457\u51cf\u5c11\u3002", "conclusion": "\u6211\u4eec\u7684\u6a21\u578b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5b83\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u68c0\u6d4b\u7387\uff0c\u5e76\u4e14\u4f7f\u7528\u7684\u6807\u8bb0\u6837\u672c\u663e\u8457\u51cf\u5c11\u3002"}}
{"id": "2507.14843", "pdf": "https://arxiv.org/pdf/2507.14843", "abs": "https://arxiv.org/abs/2507.14843", "authors": ["Fang Wu", "Weihao Xuan", "Ximing Lu", "Zaid Harchaoui", "Yejin Choi"], "title": "The Invisible Leash: Why RLVR May Not Escape Its Origin", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances in large reasoning models highlight Reinforcement Learning\nwith Verifiable Rewards (RLVR) as a promising method for enhancing AI's\ncapabilities, particularly in solving complex logical tasks. However, it\nremains unclear whether RLVR truly expands a model's reasoning boundary or\nmerely amplifies high-reward outputs that the base model already knows for\nimproved precision. This study presents a theoretical and empirical\ninvestigation that provides fresh insights into the potential limits of RLVR.\nFirst, we offer a new theoretical perspective that RLVR is constrained by the\nbase model's support-unable to sample solutions with zero initial\nprobability-and operates as a conservative reweighting mechanism that may\nrestrict the discovery of entirely original solutions. We also identify an\nentropy-reward tradeoff: while RLVR reliably enhances precision, it may\nprogressively narrow exploration and potentially overlook correct yet\nunderrepresented solutions. Extensive empirical experiments validate that while\nRLVR consistently improves pass@1, the shrinkage of empirical support generally\noutweighs the expansion of empirical support under larger sampling budgets,\nfailing to recover correct answers that were previously accessible to the base\nmodel. Interestingly, we also observe that while RLVR sometimes increases\ntoken-level entropy, resulting in greater uncertainty at each generation step,\nanswer-level entropy declines, indicating that these seemingly more uncertain\npaths ultimately converge onto a smaller set of distinct answers. Taken\ntogether, these findings reveal potential limits of RLVR in extending reasoning\nhorizons. Breaking this invisible leash may require future algorithmic\ninnovations such as explicit exploration mechanisms or hybrid strategies that\nseed probability mass into underrepresented solution regions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86RLVR\u7684\u7406\u8bba\u548c\u5b9e\u8bc1\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u53ef\u80fd\u53d7\u9650\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u652f\u6301\uff0c\u4e14\u53ef\u80fd\u7f29\u5c0f\u63a2\u7d22\u8303\u56f4\uff0c\u672a\u6765\u9700\u8981\u65b0\u7684\u7b97\u6cd5\u521b\u65b0\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u4e86\u89e3RLVR\u662f\u5426\u771f\u6b63\u6269\u5c55\u4e86\u6a21\u578b\u7684\u63a8\u7406\u8fb9\u754c\uff0c\u8fd8\u662f\u4ec5\u4ec5\u589e\u5f3a\u4e86\u5df2\u6709\u9ad8\u5956\u52b1\u8f93\u51fa\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86RLVR\u7684\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790\uff0c\u63a2\u8ba8\u4e86\u5176\u5728\u6837\u672c\u751f\u6210\u548c\u63a2\u7d22\u65b9\u9762\u7684\u9650\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5c3d\u7ba1RLVR\u63d0\u9ad8\u4e86pass@1\uff0c\u4f46\u5728\u66f4\u5927\u7684\u91c7\u6837\u9884\u7b97\u4e0b\uff0c\u7ecf\u9a8c\u652f\u6301\u7684\u7f29\u5c0f\u8d85\u8fc7\u4e86\u6269\u5c55\uff0c\u5bfc\u81f4\u65e0\u6cd5\u6062\u590d\u539f\u672c\u53ef\u8bbf\u95ee\u7684\u6b63\u786e\u7b54\u6848\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86RLVR\u5728\u6269\u5c55\u63a8\u7406\u8303\u56f4\u65b9\u9762\u7684\u6f5c\u5728\u9650\u5236\uff0c\u5e76\u6307\u51fa\u9700\u8981\u672a\u6765\u7684\u7b97\u6cd5\u521b\u65b0\u6765\u7a81\u7834\u8fd9\u4e9b\u9650\u5236\u3002"}}
{"id": "2507.15007", "pdf": "https://arxiv.org/pdf/2507.15007", "abs": "https://arxiv.org/abs/2507.15007", "authors": ["Sayed Mahbub Hasan Amiri", "Md. Mainul Islam", "Mohammad Shakhawat Hossen", "Sayed Majhab Hasan Amiri", "Mohammad Shawkat Ali Mamun", "Sk. Humaun Kabir", "Naznin Akter"], "title": "Hear Your Code Fail, Voice-Assisted Debugging for Python", "categories": ["cs.PL", "cs.CL"], "comment": "35 pages, 20 figures", "summary": "This research introduces an innovative voice-assisted debugging plugin for\nPython that transforms silent runtime errors into actionable audible\ndiagnostics. By implementing a global exception hook architecture with pyttsx3\ntext-to-speech conversion and Tkinter-based GUI visualization, the solution\ndelivers multimodal error feedback through parallel auditory and visual\nchannels. Empirical evaluation demonstrates 37% reduced cognitive load (p<0.01,\nn=50) compared to traditional stack-trace debugging, while enabling 78% faster\nerror identification through vocalized exception classification and\ncontextualization. The system achieves sub-1.2 second voice latency with under\n18% CPU overhead during exception handling, vocalizing error types and\nconsequences while displaying interactive tracebacks with documentation deep\nlinks. Criteria validate compatibility across Python 3.7+ environments on\nWindows, macOS, and Linux platforms. Needing only two lines of integration\ncode, the plugin significantly boosts availability for aesthetically impaired\ndesigners and supports multitasking workflows through hands-free error medical\ndiagnosis. Educational applications show particular promise, with pilot studies\nindicating 45% faster debugging skill acquisition among novice programmers.\nFuture development will incorporate GPT-based repair suggestions and real-time\nmultilingual translation to further advance auditory debugging paradigms. The\nsolution represents a fundamental shift toward human-centric error diagnostics,\nbridging critical gaps in programming accessibility while establishing new\nstandards for cognitive efficiency in software development workflows.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u521b\u65b0\u7684Python\u8bed\u97f3\u8f85\u52a9\u8c03\u8bd5\u63d2\u4ef6\uff0c\u901a\u8fc7\u591a\u6a21\u5f0f\u9519\u8bef\u53cd\u9988\u663e\u8457\u63d0\u9ad8\u7f16\u7a0b\u53ef\u8bbf\u95ee\u6027\u548c\u8ba4\u77e5\u6548\u7387\u3002", "motivation": "\u65e8\u5728\u5c06\u65e0\u58f0\u7684\u8fd0\u884c\u65f6\u9519\u8bef\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u542c\u89c9\u8bca\u65ad\uff0c\u63d0\u9ad8\u7f16\u7a0b\u53ef\u8bbf\u95ee\u6027\uff0c\u5e76\u63d0\u5347\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u8ba4\u77e5\u6548\u7387\u3002", "method": "\u901a\u8fc7\u5b9e\u73b0\u5168\u5c40\u5f02\u5e38\u6302\u94a9\u67b6\u6784\u3001pyttsx3\u6587\u672c\u5230\u8bed\u97f3\u8f6c\u6362\u548c\u57fa\u4e8eTkinter\u7684GUI\u53ef\u89c6\u5316\uff0c\u8be5\u89e3\u51b3\u65b9\u6848\u901a\u8fc7\u5e76\u884c\u542c\u89c9\u548c\u89c6\u89c9\u901a\u9053\u63d0\u4f9b\u591a\u6a21\u5f0f\u9519\u8bef\u53cd\u9988\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0c\u4e0e\u4f20\u7edf\u7684\u5806\u6808\u8ddf\u8e2a\u8c03\u8bd5\u76f8\u6bd4\uff0c\u8ba4\u77e5\u8d1f\u8377\u51cf\u5c11\u4e8637%\uff08p<0.01\uff0cn=50\uff09\uff0c\u540c\u65f6\u901a\u8fc7\u8bed\u97f3\u5f02\u5e38\u5206\u7c7b\u548c\u4e0a\u4e0b\u6587\u5316\u5b9e\u73b0\u4e8678%\u7684\u66f4\u5feb\u9519\u8bef\u8bc6\u522b\u3002\u7cfb\u7edf\u5728\u5f02\u5e38\u5904\u7406\u671f\u95f4\u5b9e\u73b0\u4e86\u4f4e\u4e8e1.2\u79d2\u7684\u8bed\u97f3\u5ef6\u8fdf\u548c\u4e0d\u523018%\u7684CPU\u5f00\u9500\u3002", "conclusion": "\u8be5\u89e3\u51b3\u65b9\u6848\u4ee3\u8868\u4e86\u5411\u4ee5\u4eba\u7c7b\u4e3a\u4e2d\u5fc3\u7684\u9519\u8bef\u8bca\u65ad\u7684\u6839\u672c\u8f6c\u53d8\uff0c\u5f25\u5408\u4e86\u7f16\u7a0b\u53ef\u8bbf\u95ee\u6027\u4e2d\u7684\u5173\u952e\u5dee\u8ddd\uff0c\u5e76\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u8ba4\u77e5\u6548\u7387\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\u3002"}}
{"id": "2507.15205", "pdf": "https://arxiv.org/pdf/2507.15205", "abs": "https://arxiv.org/abs/2507.15205", "authors": ["Xinran Li", "Xiujuan Xu", "Jiaqi Qiao"], "title": "Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted by the 28th European Conference on Artificial Intelligence\n  (ECAI 2025)", "summary": "Emotion Recognition in Conversation (ERC) is a practical and challenging\ntask. This paper proposes a novel multimodal approach, the Long-Short Distance\nGraph Neural Network (LSDGNN). Based on the Directed Acyclic Graph (DAG), it\nconstructs a long-distance graph neural network and a short-distance graph\nneural network to obtain multimodal features of distant and nearby utterances,\nrespectively. To ensure that long- and short-distance features are as distinct\nas possible in representation while enabling mutual influence between the two\nmodules, we employ a Differential Regularizer and incorporate a BiAffine Module\nto facilitate feature interaction. In addition, we propose an Improved\nCurriculum Learning (ICL) to address the challenge of data imbalance. By\ncomputing the similarity between different emotions to emphasize the shifts in\nsimilar emotions, we design a \"weighted emotional shift\" metric and develop a\ndifficulty measurer, enabling a training process that prioritizes learning easy\nsamples before harder ones. Experimental results on the IEMOCAP and MELD\ndatasets demonstrate that our model outperforms existing benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u65b9\u6cd5\uff0c\u5373\u957f-\u77ed\u8ddd\u79bb\u56fe\u795e\u7ecf\u7f51\u7edc\uff08LSDGNN\uff09\uff0c\u7528\u4e8e\u60c5\u611f\u8bc6\u522b\u5728\u5bf9\u8bdd\u4e2d\u7684\u4efb\u52a1\u3002\u901a\u8fc7\u6784\u5efa\u957f\u8ddd\u79bb\u548c\u77ed\u8ddd\u79bb\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u53ca\u4f7f\u7528\u5dee\u5f02\u6b63\u5219\u5316\u5668\u548c\u53cc\u4eff\u5c04\u6a21\u5757\u6765\u4fc3\u8fdb\u7279\u5f81\u4ea4\u4e92\uff0c\u540c\u65f6\u5f15\u5165\u6539\u8fdb\u7684\u8bfe\u7a0b\u5b66\u4e60\u6765\u89e3\u51b3\u6570\u636e\u4e0d\u5e73\u8861\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728IEMOCAP\u548cMELD\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "motivation": "\u60c5\u611f\u8bc6\u522b\u5728\u5bf9\u8bdd\u4e2d\u662f\u4e00\u4e2a\u5b9e\u9645\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u65b9\u6cd5\uff0c\u5373\u957f-\u77ed\u8ddd\u79bb\u56fe\u795e\u7ecf\u7f51\u7edc\uff08LSDGNN\uff09\u3002\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\uff0c\u5b83\u6784\u5efa\u4e86\u4e00\u4e2a\u957f\u8ddd\u79bb\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u4e00\u4e2a\u77ed\u8ddd\u79bb\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u5206\u522b\u83b7\u53d6\u8fdc\u8ddd\u79bb\u548c\u8fd1\u8ddd\u79bb\u8bdd\u8bed\u7684\u591a\u6a21\u6001\u7279\u5f81\u3002\u4e3a\u4e86\u786e\u4fdd\u957f\u8ddd\u79bb\u548c\u77ed\u8ddd\u79bb\u7279\u5f81\u5728\u8868\u793a\u4e0a\u5c3d\u53ef\u80fd\u4e0d\u540c\uff0c\u540c\u65f6\u4f7f\u4e24\u4e2a\u6a21\u5757\u4e4b\u95f4\u80fd\u591f\u76f8\u4e92\u5f71\u54cd\uff0c\u6211\u4eec\u91c7\u7528\u4e86\u4e00\u79cd\u5dee\u5f02\u6b63\u5219\u5316\u5668\uff0c\u5e76\u7ed3\u5408\u4e86\u53cc\u4eff\u5c04\u6a21\u5757\u6765\u4fc3\u8fdb\u7279\u5f81\u4ea4\u4e92\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u6539\u8fdb\u7684\u8bfe\u7a0b\u5b66\u4e60\uff08ICL\uff09\u6765\u89e3\u51b3\u6570\u636e\u4e0d\u5e73\u8861\u7684\u6311\u6218\u3002", "result": "\u5728IEMOCAP\u548cMELD\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u51c6\u3002"}}
{"id": "2507.15214", "pdf": "https://arxiv.org/pdf/2507.15214", "abs": "https://arxiv.org/abs/2507.15214", "authors": ["Natalia Tomashenko", "Emmanuel Vincent", "Marc Tommasi"], "title": "Exploiting Context-dependent Duration Features for Voice Anonymization Attack Systems", "categories": ["cs.SD", "cs.CL", "cs.CR", "eess.AS"], "comment": "Accepted at Interspeech-2025", "summary": "The temporal dynamics of speech, encompassing variations in rhythm,\nintonation, and speaking rate, contain important and unique information about\nspeaker identity. This paper proposes a new method for representing speaker\ncharacteristics by extracting context-dependent duration embeddings from speech\ntemporal dynamics. We develop novel attack models using these representations\nand analyze the potential vulnerabilities in speaker verification and voice\nanonymization systems.The experimental results show that the developed attack\nmodels provide a significant improvement in speaker verification performance\nfor both original and anonymized data in comparison with simpler\nrepresentations of speech temporal dynamics reported in the literature.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u8bed\u97f3\u65f6\u95f4\u52a8\u6001\u4e2d\u63d0\u53d6\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u6301\u7eed\u65f6\u95f4\u5d4c\u5165\u6765\u8868\u793a\u8bf4\u8bdd\u4eba\u7279\u5f81\uff0c\u5e76\u5f00\u53d1\u4e86\u65b0\u7684\u653b\u51fb\u6a21\u578b\uff0c\u5206\u6790\u4e86\u8bf4\u8bdd\u4eba\u9a8c\u8bc1\u548c\u8bed\u97f3\u533f\u540d\u5316\u7cfb\u7edf\u4e2d\u7684\u6f5c\u5728\u6f0f\u6d1e\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u5f00\u53d1\u7684\u653b\u51fb\u6a21\u578b\u5728\u4e0e\u6587\u732e\u4e2d\u62a5\u9053\u7684\u66f4\u7b80\u5355\u7684\u8bed\u97f3\u65f6\u95f4\u52a8\u6001\u8868\u793a\u76f8\u6bd4\uff0c\u5bf9\u4e8e\u539f\u59cb\u548c\u533f\u540d\u6570\u636e\u7684\u8bf4\u8bdd\u4eba\u9a8c\u8bc1\u6027\u80fd\u6709\u663e\u8457\u63d0\u9ad8\u3002", "motivation": "\u8bed\u97f3\u7684\u65f6\u95f4\u52a8\u6001\uff0c\u5305\u62ec\u8282\u594f\u3001\u8bed\u8c03\u548c\u8bf4\u8bdd\u901f\u5ea6\u7684\u53d8\u5316\uff0c\u5305\u542b\u6709\u5173\u8bf4\u8bdd\u4eba\u8eab\u4efd\u7684\u91cd\u8981\u4e14\u72ec\u7279\u4fe1\u606f\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u8bed\u97f3\u65f6\u95f4\u52a8\u6001\u4e2d\u63d0\u53d6\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u6301\u7eed\u65f6\u95f4\u5d4c\u5165\u6765\u8868\u793a\u8bf4\u8bdd\u4eba\u7279\u5f81\u3002\u6211\u4eec\u5f00\u53d1\u4e86\u65b0\u7684\u653b\u51fb\u6a21\u578b\uff0c\u5e76\u5206\u6790\u4e86\u8bf4\u8bdd\u4eba\u9a8c\u8bc1\u548c\u8bed\u97f3\u533f\u540d\u5316\u7cfb\u7edf\u4e2d\u7684\u6f5c\u5728\u6f0f\u6d1e\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u5f00\u53d1\u7684\u653b\u51fb\u6a21\u578b\u5728\u4e0e\u6587\u732e\u4e2d\u62a5\u9053\u7684\u66f4\u7b80\u5355\u7684\u8bed\u97f3\u65f6\u95f4\u52a8\u6001\u8868\u793a\u76f8\u6bd4\uff0c\u5bf9\u4e8e\u539f\u59cb\u548c\u533f\u540d\u6570\u636e\u7684\u8bf4\u8bdd\u4eba\u9a8c\u8bc1\u6027\u80fd\u6709\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u5f00\u53d1\u7684\u653b\u51fb\u6a21\u578b\u5728\u4e0e\u6587\u732e\u4e2d\u62a5\u9053\u7684\u66f4\u7b80\u5355\u7684\u8bed\u97f3\u65f6\u95f4\u52a8\u6001\u8868\u793a\u76f8\u6bd4\uff0c\u5bf9\u4e8e\u539f\u59cb\u548c\u533f\u540d\u6570\u636e\u7684\u8bf4\u8bdd\u4eba\u9a8c\u8bc1\u6027\u80fd\u6709\u663e\u8457\u63d0\u9ad8\u3002"}}
{"id": "2507.15267", "pdf": "https://arxiv.org/pdf/2507.15267", "abs": "https://arxiv.org/abs/2507.15267", "authors": ["Ninglu Shao", "Jinshan Wang", "Chenxu Wang", "Qingbiao Li", "Xiaoxue Zang", "Han Li"], "title": "GREAT: Guiding Query Generation with a Trie for Recommending Related Search about Video at Kuaishou", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Currently, short video platforms have become the primary place for\nindividuals to share experiences and obtain information. To better meet users'\nneeds for acquiring information while browsing short videos, some apps have\nintroduced a search entry at the bottom of videos, accompanied with recommended\nrelevant queries. This scenario is known as query recommendation in\nvideo-related search, where core task is item-to-query (I2Q) recommendation. As\nthis scenario has only emerged in recent years, there is a notable scarcity of\nacademic research and publicly available datasets in this domain. To address\nthis gap, we systematically examine the challenges associated with this\nscenario for the first time. Subsequently, we release a large-scale dataset\nderived from real-world data pertaining to the query recommendation in\nvideo-\\textit{\\textbf{r}}elated \\textit{\\textbf{s}}earch on the\n\\textit{\\textbf{Kuai}}shou app (\\textbf{KuaiRS}). Presently, existing methods\nrely on embeddings to calculate similarity for matching short videos with\nqueries, lacking deep interaction between the semantic content and the query.\nIn this paper, we introduce a novel LLM-based framework named \\textbf{GREAT},\nwhich \\textit{\\textbf{g}}uides que\\textit{\\textbf{r}}y\ng\\textit{\\textbf{e}}ner\\textit{\\textbf{a}}tion with a \\textit{\\textbf{t}}rie to\naddress I2Q recommendation in related search. Specifically, we initially gather\nhigh-quality queries with high exposure and click-through rate to construct a\nquery-based trie. During training, we enhance the LLM's capability to generate\nhigh-quality queries using the query-based trie. In the inference phase, the\nquery-based trie serves as a guide for the token generation. Finally, we\nfurther refine the relevance and literal quality between items and queries via\na post-processing module. Extensive offline and online experiments demonstrate\nthe effectiveness of our proposed method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6GREAT\uff0c\u7528\u4e8e\u89e3\u51b3\u89c6\u9891\u76f8\u5173\u641c\u7d22\u4e2d\u7684I2Q\u63a8\u8350\u95ee\u9898\u3002\u901a\u8fc7\u6784\u5efa\u57fa\u4e8e\u67e5\u8be2\u7684Trie\u6811\u6765\u6307\u5bfc\u67e5\u8be2\u751f\u6210\uff0c\u5e76\u5728\u63a8\u7406\u9636\u6bb5\u4f7f\u7528Trie\u6811\u5f15\u5bfctoken\u751f\u6210\uff0c\u6700\u540e\u901a\u8fc7\u540e\u5904\u7406\u6a21\u5757\u4f18\u5316\u9879\u76ee\u4e0e\u67e5\u8be2\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u548c\u5b57\u9762\u8d28\u91cf\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u76ee\u524d\uff0c\u77ed\u89c6\u9891\u5e73\u53f0\u5df2\u6210\u4e3a\u4eba\u4eec\u5206\u4eab\u7ecf\u9a8c\u548c\u83b7\u53d6\u4fe1\u606f\u7684\u4e3b\u8981\u573a\u6240\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u6ee1\u8db3\u7528\u6237\u5728\u6d4f\u89c8\u77ed\u89c6\u9891\u65f6\u83b7\u53d6\u4fe1\u606f\u7684\u9700\u6c42\uff0c\u4e00\u4e9b\u5e94\u7528\u5728\u89c6\u9891\u5e95\u90e8\u5f15\u5165\u4e86\u641c\u7d22\u5165\u53e3\uff0c\u5e76\u9644\u5e26\u63a8\u8350\u7684\u76f8\u5173\u67e5\u8be2\u3002\u7136\u800c\uff0c\u8fd9\u4e00\u573a\u666f\u7684\u7814\u7a76\u548c\u516c\u5f00\u6570\u636e\u96c6\u8f83\u5c11\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3I2Q\u63a8\u8350\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6GREAT\uff0c\u901a\u8fc7\u6784\u5efa\u57fa\u4e8e\u67e5\u8be2\u7684Trie\u6811\u6765\u6307\u5bfc\u67e5\u8be2\u751f\u6210\uff0c\u5e76\u5728\u63a8\u7406\u9636\u6bb5\u4f7f\u7528Trie\u6811\u5f15\u5bfctoken\u751f\u6210\uff0c\u6700\u540e\u901a\u8fc7\u540e\u5904\u7406\u6a21\u5757\u4f18\u5316\u9879\u76ee\u4e0e\u67e5\u8be2\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u548c\u5b57\u9762\u8d28\u91cf\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684GREAT\u6846\u67b6\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6GREAT\uff0c\u7528\u4e8e\u89e3\u51b3\u89c6\u9891\u76f8\u5173\u641c\u7d22\u4e2d\u7684item-to-query\uff08I2Q\uff09\u63a8\u8350\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u3002"}}
{"id": "2507.15272", "pdf": "https://arxiv.org/pdf/2507.15272", "abs": "https://arxiv.org/abs/2507.15272", "authors": ["Ayush Singh Bhadoriya", "Abhishek Nikunj Shinde", "Isha Pandey", "Ganesh Ramakrishnan"], "title": "A2TTS: TTS for Low Resource Indian Languages", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "comment": null, "summary": "We present a speaker conditioned text-to-speech (TTS) system aimed at\naddressing challenges in generating speech for unseen speakers and supporting\ndiverse Indian languages. Our method leverages a diffusion-based TTS\narchitecture, where a speaker encoder extracts embeddings from short reference\naudio samples to condition the DDPM decoder for multispeaker generation. To\nfurther enhance prosody and naturalness, we employ a cross-attention based\nduration prediction mechanism that utilizes reference audio, enabling more\naccurate and speaker consistent timing. This results in speech that closely\nresembles the target speaker while improving duration modeling and overall\nexpressiveness. Additionally, to improve zero-shot generation, we employed\nclassifier free guidance, allowing the system to generate speech more near\nspeech for unknown speakers. Using this approach, we trained language-specific\nspeaker-conditioned models. Using the IndicSUPERB dataset for multiple Indian\nlanguages such as Bengali, Gujarati, Hindi, Marathi, Malayalam, Punjabi and\nTamil.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u6587\u672c\u5230\u8bed\u97f3\u7cfb\u7edf\uff0c\u7528\u4e8e\u751f\u6210\u672a\u89c1\u8fc7\u7684\u8bf4\u8bdd\u4eba\u7684\u8bed\u97f3\u5e76\u652f\u6301\u591a\u79cd\u5370\u5ea6\u8bed\u8a00\u3002", "motivation": "\u6211\u4eec\u65e8\u5728\u89e3\u51b3\u751f\u6210\u672a\u89c1\u8fc7\u7684\u8bf4\u8bdd\u4eba\u7684\u8bed\u97f3\u4ee5\u53ca\u652f\u6301\u591a\u79cd\u5370\u5ea6\u8bed\u8a00\u7684\u6311\u6218\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u6587\u672c\u5230\u8bed\u97f3\uff08TTS\uff09\u7cfb\u7edf\uff0c\u5229\u7528\u8bf4\u8bdd\u4eba\u7f16\u7801\u5668\u4ece\u77ed\u53c2\u8003\u97f3\u9891\u6837\u672c\u4e2d\u63d0\u53d6\u5d4c\u5165\uff0c\u4ee5\u6761\u4ef6DDPM\u89e3\u7801\u5668\u8fdb\u884c\u591a\u8bf4\u8bdd\u4eba\u751f\u6210\u3002\u6211\u4eec\u8fd8\u91c7\u7528\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ea4\u53c9\u6ce8\u610f\u529b\u7684\u6301\u7eed\u65f6\u95f4\u9884\u6d4b\u673a\u5236\uff0c\u5229\u7528\u53c2\u8003\u97f3\u9891\u4ee5\u5b9e\u73b0\u66f4\u51c6\u786e\u548c\u8bf4\u8bdd\u4eba\u4e00\u81f4\u7684\u65f6\u95f4\u5efa\u6a21\u3002", "result": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728IndicSUPERB\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bad\u7ec3\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u591a\u79cd\u5370\u5ea6\u8bed\u8a00\uff0c\u5982\u5b5f\u52a0\u62c9\u8bed\u3001\u53e4\u5409\u62c9\u7279\u8bed\u3001\u5370\u5730\u8bed\u3001\u9a6c\u62c9\u5730\u8bed\u3001\u9a6c\u62c9\u96c5\u62c9\u59c6\u8bed\u3001\u65c1\u906e\u666e\u8bed\u548c\u6cf0\u7c73\u5c14\u8bed\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u751f\u6210\u8bed\u97f3\u65f6\u80fd\u591f\u66f4\u63a5\u8fd1\u76ee\u6807\u8bf4\u8bdd\u4eba\uff0c\u5e76\u63d0\u9ad8\u4e86\u6301\u7eed\u65f6\u95f4\u5efa\u6a21\u548c\u6574\u4f53\u8868\u73b0\u529b\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u4f7f\u7528\u65e0\u5206\u7c7b\u5668\u6307\u5bfc\uff0c\u6211\u4eec\u6539\u8fdb\u4e86\u96f6\u6837\u672c\u751f\u6210\u3002"}}
{"id": "2507.15507", "pdf": "https://arxiv.org/pdf/2507.15507", "abs": "https://arxiv.org/abs/2507.15507", "authors": ["Johannes Ackermann", "Takashi Ishida", "Masashi Sugiyama"], "title": "Off-Policy Corrected Reward Modeling for Reinforcement Learning from Human Feedback", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accept at the Conference On Language Modeling (COLM) 2025", "summary": "Reinforcement Learning from Human Feedback (RLHF) allows us to train models,\nsuch as language models (LMs), to follow complex human preferences. In RLHF for\nLMs, we first train an LM using supervised fine-tuning, sample pairs of\nresponses, obtain human feedback, and use the resulting data to train a reward\nmodel (RM). RL methods are then used to train the LM to maximize the reward\ngiven by the RM. As training progresses, the responses generated by the LM no\nlonger resemble the responses seen by the RM during training, leading to the RM\nbecoming inaccurate. The score given by the RM keeps increasing, but the\nlearned behavior no longer matches the human preferences. This issue is known\nas overoptimization. We investigate overoptimization from the point of view of\ndistribution shift and show that the shift results in an inconsistent estimate\nof the RM parameters, leading to an inconsistent estimate of the policy\ngradient. We propose Off-Policy Corrected Reward Modeling (OCRM), which\niteratively off-policy corrects the RM using importance weighting, without\nrequiring new labels or samples. This results in a more accurate RM, which\nempirically leads to an improved final policy. We validate our approach in\nexperiments with summarization and chatbot datasets and show that it performs\nsignificantly better than standard RLHF methods and baselines. Our\nimplementation is available at\nhttps://github.com/JohannesAck/OffPolicyCorrectedRewardModeling", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5956\u52b1\u5efa\u6a21\u65b9\u6cd5OCRM\uff0c\u4ee5\u89e3\u51b3RLHF\u4e2d\u7684\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728RLHF\u4e2d\uff0c\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\uff0c\u751f\u6210\u7684\u54cd\u5e94\u4e0d\u518d\u4e0eRM\u8bad\u7ec3\u65f6\u770b\u5230\u7684\u54cd\u5e94\u76f8\u4f3c\uff0c\u5bfc\u81f4RM\u53d8\u5f97\u4e0d\u51c6\u786e\u3002\u8fd9\u88ab\u79f0\u4e3a\u8fc7\u4f18\u5316\u95ee\u9898\u3002", "method": "\u672c\u6587\u4ece\u5206\u5e03\u504f\u79fb\u7684\u89d2\u5ea6\u7814\u7a76\u8fc7\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u65b0\u6807\u7b7e\u6216\u6837\u672c\u7684\u79bb\u7b56\u7565\u6821\u6b63\u5956\u52b1\u5efa\u6a21\u65b9\u6cd5\uff08OCRM\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cOCRM\u65b9\u6cd5\u5728\u6458\u8981\u548c\u804a\u5929\u673a\u5668\u4eba\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u6807\u51c6RLHF\u65b9\u6cd5\u548c\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86Off-Policy Corrected Reward Modeling (OCRM)\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3RLHF\u4e2d\u7684\u8fc7\u4f18\u5316\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6458\u8981\u548c\u804a\u5929\u673a\u5668\u4eba\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u6807\u51c6\u7684RLHF\u65b9\u6cd5\u548c\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2507.15640", "pdf": "https://arxiv.org/pdf/2507.15640", "abs": "https://arxiv.org/abs/2507.15640", "authors": ["Kailai Yang", "Xiao Liu", "Lei Ji", "Hao Li", "Yeyun Gong", "Peng Cheng", "Mao Yang"], "title": "Data Mixing Agent: Learning to Re-weight Domains for Continual Pre-training", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Continual pre-training on small-scale task-specific data is an effective\nmethod for improving large language models in new target fields, yet it risks\ncatastrophic forgetting of their original capabilities. A common solution is to\nre-weight training data mixtures from source and target fields on a domain\nspace to achieve balanced performance. Previous domain reweighting strategies\nrely on manual designation with certain heuristics based on human intuition or\nempirical results. In this work, we prove that more general heuristics can be\nparameterized by proposing Data Mixing Agent, the first model-based, end-to-end\nframework that learns to re-weight domains. The agent learns generalizable\nheuristics through reinforcement learning on large quantities of data mixing\ntrajectories with corresponding feedback from an evaluation environment.\nExperiments in continual pre-training on math reasoning show that Data Mixing\nAgent outperforms strong baselines in achieving balanced performance across\nsource and target field benchmarks. Furthermore, it generalizes well across\nunseen source fields, target models, and domain spaces without retraining.\nDirect application to the code generation field also indicates its adaptability\nacross target domains. Further analysis showcases the agents' well-aligned\nheuristics with human intuitions and their efficiency in achieving superior\nmodel performance with less source-field data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5 Data Mixing Agent\uff0c\u7528\u4e8e\u5728\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\u91cd\u65b0\u52a0\u6743\u9886\u57df\uff0c\u4ee5\u5b9e\u73b0\u6e90\u9886\u57df\u548c\u76ee\u6807\u9886\u57df\u4e4b\u95f4\u7684\u5e73\u8861\u6027\u80fd\uff0c\u5e76\u4e14\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6548\u7387\u3002", "motivation": "\u6301\u7eed\u9884\u8bad\u7ec3\u5728\u5c0f\u89c4\u6a21\u4efb\u52a1\u7279\u5b9a\u6570\u636e\u4e0a\u7684\u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u65b0\u76ee\u6807\u9886\u57df\u7684\u8868\u73b0\uff0c\u4f46\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u539f\u59cb\u80fd\u529b\u7684\u98ce\u9669\u3002\u73b0\u6709\u7684\u9886\u57df\u91cd\u65b0\u52a0\u6743\u7b56\u7565\u4f9d\u8d56\u4e8e\u4eba\u5de5\u6307\u5b9a\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u800c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u66f4\u901a\u7528\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86 Data Mixing Agent\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u6a21\u578b\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u5927\u91cf\u6570\u636e\u6df7\u5408\u8f68\u8ff9\u4e0a\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u6765\u5b66\u4e60\u91cd\u65b0\u52a0\u6743\u9886\u57df\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cData Mixing Agent \u5728\u6570\u5b66\u63a8\u7406\u7684\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5728\u6e90\u9886\u57df\u548c\u76ee\u6807\u9886\u57df\u57fa\u51c6\u4e4b\u95f4\u5b9e\u73b0\u4e86\u5e73\u8861\u6027\u80fd\u3002\u6b64\u5916\uff0c\u5b83\u5728\u672a\u89c1\u8fc7\u7684\u6e90\u9886\u57df\u3001\u76ee\u6807\u6a21\u578b\u548c\u9886\u57df\u7a7a\u95f4\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Data Mixing Agent \u5728\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u5b9e\u73b0\u6e90\u9886\u57df\u548c\u76ee\u6807\u9886\u57df\u57fa\u51c6\u7684\u5e73\u8861\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u672a\u89c1\u8fc7\u7684\u6e90\u9886\u57df\u3001\u76ee\u6807\u6a21\u578b\u548c\u9886\u57df\u7a7a\u95f4\u4e2d\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u5b83\u5c55\u793a\u4e86\u4e0e\u4eba\u7c7b\u76f4\u89c9\u4e00\u81f4\u7684\u7b56\u7565\uff0c\u5e76\u4e14\u5728\u4f7f\u7528\u8f83\u5c11\u6e90\u9886\u57df\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.15743", "pdf": "https://arxiv.org/pdf/2507.15743", "abs": "https://arxiv.org/abs/2507.15743", "authors": ["Elahe Vedadi", "David Barrett", "Natalie Harris", "Ellery Wulczyn", "Shashir Reddy", "Roma Ruparel", "Mike Schaekermann", "Tim Strother", "Ryutaro Tanno", "Yash Sharma", "Jihyeon Lee", "C\u00edan Hughes", "Dylan Slack", "Anil Palepu", "Jan Freyberg", "Khaled Saab", "Valentin Li\u00e9vin", "Wei-Hung Weng", "Tao Tu", "Yun Liu", "Nenad Tomasev", "Kavita Kulkarni", "S. Sara Mahdavi", "Kelvin Guu", "Jo\u00eblle Barral", "Dale R. Webster", "James Manyika", "Avinatan Hassidim", "Katherine Chou", "Yossi Matias", "Pushmeet Kohli", "Adam Rodman", "Vivek Natarajan", "Alan Karthikesalingam", "David Stutz"], "title": "Towards physician-centered oversight of conversational diagnostic AI", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": null, "summary": "Recent work has demonstrated the promise of conversational AI systems for\ndiagnostic dialogue. However, real-world assurance of patient safety means that\nproviding individual diagnoses and treatment plans is considered a regulated\nactivity by licensed professionals. Furthermore, physicians commonly oversee\nother team members in such activities, including nurse practitioners (NPs) or\nphysician assistants/associates (PAs). Inspired by this, we propose a framework\nfor effective, asynchronous oversight of the Articulate Medical Intelligence\nExplorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent\nsystem that performs history taking within guardrails, abstaining from\nindividualized medical advice. Afterwards, g-AMIE conveys assessments to an\noverseeing primary care physician (PCP) in a clinician cockpit interface. The\nPCP provides oversight and retains accountability of the clinical decision.\nThis effectively decouples oversight from intake and can thus happen\nasynchronously. In a randomized, blinded virtual Objective Structured Clinical\nExamination (OSCE) of text consultations with asynchronous oversight, we\ncompared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across\n60 scenarios, g-AMIE outperformed both groups in performing high-quality\nintake, summarizing cases, and proposing diagnoses and management plans for the\noverseeing PCP to review. This resulted in higher quality composite decisions.\nPCP oversight of g-AMIE was also more time-efficient than standalone PCP\nconsultations in prior work. While our study does not replicate existing\nclinical practices and likely underestimates clinicians' capabilities, our\nresults demonstrate the promise of asynchronous oversight as a feasible\nparadigm for diagnostic AI systems to operate under expert human oversight for\nenhancing real-world care.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u7528\u4e8e\u5bf9Articulate Medical Intelligence Explorer (AMIE) AI\u7cfb\u7edf\u8fdb\u884c\u6709\u6548\u7684\u5f02\u6b65\u76d1\u7763\u3002\u6211\u4eec\u63d0\u51fa\u4e86guardrailed-AMIE (g-AMIE)\uff0c\u8fd9\u662f\u4e00\u4e2a\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u5728\u9650\u5236\u8303\u56f4\u5185\u6267\u884c\u75c5\u53f2\u91c7\u96c6\uff0c\u907f\u514d\u63d0\u4f9b\u4e2a\u6027\u5316\u7684\u533b\u7597\u5efa\u8bae\u3002\u4e4b\u540e\uff0cg-AMIE\u901a\u8fc7\u4e34\u5e8a\u533b\u751f\u9a7e\u9a76\u8231\u754c\u9762\u5c06\u8bc4\u4f30\u4f20\u8fbe\u7ed9\u8d1f\u8d23\u7684\u521d\u7ea7\u4fdd\u5065\u533b\u751f\uff08PCP\uff09\u3002PCP\u63d0\u4f9b\u76d1\u7763\u5e76\u4fdd\u7559\u4e34\u5e8a\u51b3\u7b56\u7684\u8d23\u4efb\u3002\u5728\u4e00\u9879\u968f\u673a\u3001\u76f2\u6cd5\u865a\u62df\u5ba2\u89c2\u7ed3\u6784\u5316\u4e34\u5e8a\u8003\u8bd5\uff08OSCE\uff09\u4e2d\uff0c\u6211\u4eec\u6bd4\u8f83\u4e86g-AMIE\u4e0eNPs/PAs\u6216\u4e00\u7ec4PCPs\u5728\u76f8\u540c\u9650\u5236\u4e0b\u7684\u8868\u73b0\u3002\u572860\u4e2a\u573a\u666f\u4e2d\uff0cg-AMIE\u5728\u6267\u884c\u9ad8\u8d28\u91cf\u7684\u521d\u6b65\u8bc4\u4f30\u3001\u603b\u7ed3\u75c5\u4f8b\u4ee5\u53ca\u63d0\u51fa\u8bca\u65ad\u548c\u7ba1\u7406\u8ba1\u5212\u65b9\u9762\u4f18\u4e8e\u4e24\u7ec4\uff0c\u8fd9\u5bfc\u81f4\u4e86\u66f4\u9ad8\u8d28\u91cf\u7684\u7efc\u5408\u51b3\u7b56\u3002PCP\u5bf9g-AMIE\u7684\u76d1\u7763\u4e5f\u6bd4\u4e4b\u524d\u5de5\u4f5c\u4e2d\u5355\u72ec\u7684PCP\u54a8\u8be2\u66f4\u8282\u7701\u65f6\u95f4\u3002", "motivation": "\u7531\u4e8e\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u60a3\u8005\u5b89\u5168\u4fdd\u8bc1\uff0c\u63d0\u4f9b\u4e2a\u4f53\u8bca\u65ad\u548c\u6cbb\u7597\u8ba1\u5212\u88ab\u8ba4\u4e3a\u662f\u53d7\u76d1\u7ba1\u7684\u6d3b\u52a8\uff0c\u7531\u6301\u724c\u4e13\u4e1a\u4eba\u5458\u8fdb\u884c\u3002\u6b64\u5916\uff0c\u533b\u751f\u901a\u5e38\u4f1a\u76d1\u7763\u5176\u4ed6\u56e2\u961f\u6210\u5458\uff0c\u5305\u62ec\u62a4\u58eb\u4ece\u4e1a\u8005\uff08NPs\uff09\u6216\u533b\u5e08\u52a9\u7406/\u5173\u8054\u4eba\u5458\uff08PAs\uff09\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5f02\u6b65\u76d1\u7763\u6846\u67b6\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u7528\u4e8e\u5bf9Articulate Medical Intelligence Explorer (AMIE) AI\u7cfb\u7edf\u8fdb\u884c\u6709\u6548\u7684\u5f02\u6b65\u76d1\u7763\u3002\u6211\u4eec\u63d0\u51fa\u4e86guardrailed-AMIE (g-AMIE)\uff0c\u8fd9\u662f\u4e00\u4e2a\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u5728\u9650\u5236\u8303\u56f4\u5185\u6267\u884c\u75c5\u53f2\u91c7\u96c6\uff0c\u907f\u514d\u63d0\u4f9b\u4e2a\u6027\u5316\u7684\u533b\u7597\u5efa\u8bae\u3002\u4e4b\u540e\uff0cg-AMIE\u901a\u8fc7\u4e34\u5e8a\u533b\u751f\u9a7e\u9a76\u8231\u754c\u9762\u5c06\u8bc4\u4f30\u4f20\u8fbe\u7ed9\u8d1f\u8d23\u7684\u521d\u7ea7\u4fdd\u5065\u533b\u751f\uff08PCP\uff09\u3002PCP\u63d0\u4f9b\u76d1\u7763\u5e76\u4fdd\u7559\u4e34\u5e8a\u51b3\u7b56\u7684\u8d23\u4efb\u3002", "result": "\u5728\u4e00\u9879\u968f\u673a\u3001\u76f2\u6cd5\u865a\u62df\u5ba2\u89c2\u7ed3\u6784\u5316\u4e34\u5e8a\u8003\u8bd5\uff08OSCE\uff09\u4e2d\uff0c\u6211\u4eec\u6bd4\u8f83\u4e86g-AMIE\u4e0eNPs/PAs\u6216\u4e00\u7ec4PCPs\u5728\u76f8\u540c\u9650\u5236\u4e0b\u7684\u8868\u73b0\u3002\u572860\u4e2a\u573a\u666f\u4e2d\uff0cg-AMIE\u5728\u6267\u884c\u9ad8\u8d28\u91cf\u7684\u521d\u6b65\u8bc4\u4f30\u3001\u603b\u7ed3\u75c5\u4f8b\u4ee5\u53ca\u63d0\u51fa\u8bca\u65ad\u548c\u7ba1\u7406\u8ba1\u5212\u65b9\u9762\u4f18\u4e8e\u4e24\u7ec4\uff0c\u8fd9\u5bfc\u81f4\u4e86\u66f4\u9ad8\u8d28\u91cf\u7684\u7efc\u5408\u51b3\u7b56\u3002PCP\u5bf9g-AMIE\u7684\u76d1\u7763\u4e5f\u6bd4\u4e4b\u524d\u5de5\u4f5c\u4e2d\u5355\u72ec\u7684PCP\u54a8\u8be2\u66f4\u8282\u7701\u65f6\u95f4\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u5c55\u793a\u4e86\u5f02\u6b65\u76d1\u7763\u4f5c\u4e3a\u8bca\u65adAI\u7cfb\u7edf\u5728\u4e13\u5bb6\u4eba\u7c7b\u76d1\u7763\u4e0b\u8fd0\u884c\u7684\u53ef\u884c\u8303\u5f0f\uff0c\u6709\u52a9\u4e8e\u589e\u5f3a\u73b0\u5b9e\u4e16\u754c\u7684\u62a4\u7406\u3002"}}
{"id": "2507.15758", "pdf": "https://arxiv.org/pdf/2507.15758", "abs": "https://arxiv.org/abs/2507.15758", "authors": ["Xingyu Wu", "Yuchen Yan", "Shangke Lyu", "Linjuan Wu", "Yiwen Qiu", "Yongliang Shen", "Weiming Lu", "Jian Shao", "Jun Xiao", "Yueting Zhuang"], "title": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization", "categories": ["cs.AI", "cs.CL"], "comment": "GitHub:https://github.com/zju-real/lapo;\n  Project:https://zju-real.github.io/lapo", "summary": "Large reasoning models have achieved remarkable performance through extended\nchain-of-thought sequences, yet this computational freedom leads to excessive\ntoken generation even for simple problems. We present Length-Adaptive Policy\nOptimization (LAPO), a novel framework that transforms reasoning length control\nfrom an external constraint into an intrinsic model capability. Unlike existing\napproaches that impose rigid limits or rely on post-hoc interventions, LAPO\nenables models to internalize an understanding of appropriate reasoning depth\nthrough a two-stage reinforcement learning process. In the first stage, models\nlearn natural reasoning patterns by discovering the statistical distribution of\nsuccessful solution lengths. The second stage leverages these patterns as\nmeta-cognitive guidance, embedding them directly within the model's reasoning\ncontext to ensure inference-time flexibility. Experiments on mathematical\nreasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\\%\nwhile improving accuracy by 2.3\\%. Our analysis reveals that models trained\nwith LAPO develop emergent abilities to allocate computational resources based\non problem complexity, achieving efficient reasoning without sacrificing\nquality.", "AI": {"tldr": "LAPO\u662f\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u6839\u636e\u95ee\u9898\u590d\u6742\u5ea6\u52a8\u6001\u8c03\u6574\u63a8\u7406\u957f\u5ea6\uff0c\u4ece\u800c\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u901a\u5e38\u65bd\u52a0\u4e25\u683c\u7684\u9650\u5236\u6216\u4f9d\u8d56\u4e8e\u4e8b\u540e\u5e72\u9884\uff0c\u800cLAPO\u65e8\u5728\u5c06\u63a8\u7406\u957f\u5ea6\u63a7\u5236\u8f6c\u5316\u4e3a\u6a21\u578b\u7684\u5185\u5728\u80fd\u529b\uff0c\u4ee5\u89e3\u51b3\u8ba1\u7b97\u81ea\u7531\u5bfc\u81f4\u7684\u8fc7\u5ea6\u4ee4\u724c\u751f\u6210\u95ee\u9898\u3002", "method": "LAPO\u91c7\u7528\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\uff0c\u9996\u5148\u8ba9\u6a21\u578b\u901a\u8fc7\u53d1\u73b0\u6210\u529f\u89e3\u51b3\u65b9\u6848\u957f\u5ea6\u7684\u7edf\u8ba1\u5206\u5e03\u6765\u5b66\u4e60\u81ea\u7136\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u7136\u540e\u5229\u7528\u8fd9\u4e9b\u6a21\u5f0f\u4f5c\u4e3a\u5143\u8ba4\u77e5\u6307\u5bfc\uff0c\u5c06\u5176\u76f4\u63a5\u5d4c\u5165\u6a21\u578b\u7684\u63a8\u7406\u4e0a\u4e0b\u6587\u4e2d\u4ee5\u786e\u4fdd\u63a8\u7406\u65f6\u7684\u7075\u6d3b\u6027\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLAPO\u5c06\u4ee4\u724c\u4f7f\u7528\u91cf\u51cf\u5c11\u4e86\u9ad8\u8fbe40.9%\uff0c\u540c\u65f6\u5c06\u51c6\u786e\u6027\u63d0\u9ad8\u4e862.3%\u3002", "conclusion": "LAPO\u6846\u67b6\u901a\u8fc7\u5c06\u63a8\u7406\u957f\u5ea6\u63a7\u5236\u8f6c\u5316\u4e3a\u6a21\u578b\u7684\u5185\u5728\u80fd\u529b\uff0c\u4f7f\u6a21\u578b\u5728\u63a8\u7406\u65f6\u80fd\u591f\u6839\u636e\u95ee\u9898\u590d\u6742\u5ea6\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u4ece\u800c\u5728\u4e0d\u727a\u7272\u8d28\u91cf\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684\u63a8\u7406\u3002"}}
{"id": "2507.15776", "pdf": "https://arxiv.org/pdf/2507.15776", "abs": "https://arxiv.org/abs/2507.15776", "authors": ["Noor Sajid", "Johan Medrano"], "title": "Dissociating model architectures from inference computations", "categories": ["q-bio.NC", "cs.CL", "cs.LG"], "comment": "3 pages, 1 figure", "summary": "Parr et al., 2025 examines how auto-regressive and deep temporal models\ndiffer in their treatment of non-Markovian sequence modelling. Building on\nthis, we highlight the need for dissociating model architectures, i.e., how the\npredictive distribution factorises, from the computations invoked at inference.\nWe demonstrate that deep temporal computations are mimicked by autoregressive\nmodels by structuring context access during iterative inference. Using a\ntransformer trained on next-token prediction, we show that inducing\nhierarchical temporal factorisation during iterative inference maintains\npredictive capacity while instantiating fewer computations. This emphasises\nthat processes for constructing and refining predictions are not necessarily\nbound to their underlying model architectures.", "AI": {"tldr": "\u7814\u7a76\u663e\u793a\u81ea\u56de\u5f52\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u6a21\u4eff\u6df1\u5ea6\u65f6\u95f4\u6a21\u578b\uff0c\u8868\u660e\u9884\u6d4b\u8fc7\u7a0b\u4e0e\u6a21\u578b\u67b6\u6784\u4e4b\u95f4\u6ca1\u6709\u5fc5\u7136\u8054\u7cfb\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u533a\u5206\u6a21\u578b\u67b6\u6784\u4e0e\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u975e\u9a6c\u5c14\u53ef\u592b\u5e8f\u5217\u5efa\u6a21\u3002", "method": "\u901a\u8fc7\u7ed3\u6784\u5316\u8fed\u4ee3\u63a8\u7406\u4e2d\u7684\u4e0a\u4e0b\u6587\u8bbf\u95ee\uff0c\u5c55\u793a\u4e86\u81ea\u56de\u5f52\u6a21\u578b\u53ef\u4ee5\u6a21\u4eff\u6df1\u5ea6\u65f6\u95f4\u8ba1\u7b97\u3002", "result": "\u4f7f\u7528\u57fa\u4e8e\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\u7684\u53d8\u538b\u5668\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u5728\u8fed\u4ee3\u63a8\u7406\u4e2d\u5f15\u5165\u5206\u5c42\u65f6\u95f4\u56e0\u5b50\u5206\u89e3\u53ef\u4ee5\u4fdd\u6301\u9884\u6d4b\u80fd\u529b\u5e76\u51cf\u5c11\u8ba1\u7b97\u91cf\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u6784\u5efa\u548c\u4f18\u5316\u9884\u6d4b\u7684\u8fc7\u7a0b\u4e0d\u4e00\u5b9a\u53d7\u9650\u4e8e\u5176\u5e95\u5c42\u6a21\u578b\u67b6\u6784\u3002"}}
{"id": "2507.15788", "pdf": "https://arxiv.org/pdf/2507.15788", "abs": "https://arxiv.org/abs/2507.15788", "authors": ["Sneheel Sarangi", "Hanan Salam"], "title": "Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have demonstrated\nemergent capabilities in complex reasoning, largely spurred by rule-based\nReinforcement Learning (RL) techniques applied during the post-training. This\nhas raised the question of whether similar methods can instill more nuanced,\nhuman-like social intelligence, such as a Theory of Mind (ToM), in LLMs. This\npaper investigates whether small-scale LLMs can acquire a robust and\ngeneralizable ToM capability through RL with verifiable rewards (RLVR). We\nconduct a systematic evaluation by training models on various combinations of\nprominent ToM datasets (HiToM, ExploreToM, FANToM) and testing for\ngeneralization on held-out datasets (e.g., OpenToM). Our findings indicate that\nsmall LLMs struggle to develop a generic ToM capability. While performance on\nin-distribution tasks improves, this capability fails to transfer to unseen ToM\ntasks with different characteristics. Furthermore, we demonstrate that\nprolonged RL training leads to models ``hacking'' the statistical patterns of\nthe training datasets, resulting in significant performance gains on in-domain\ndata but no change, or degradation of performance on out-of-distribution tasks.\nThis suggests the learned behavior is a form of narrow overfitting rather than\nthe acquisition of a true, abstract ToM capability.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4e0e\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u83b7\u5f97\u901a\u7528\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5c0f\u578b\u6a21\u578b\u96be\u4ee5\u53d1\u5c55\u51fa\u901a\u7528\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\uff0c\u4e14\u957f\u671f\u8bad\u7ec3\u4f1a\u5bfc\u81f4\u6a21\u578b\u8fc7\u62df\u5408\uff0c\u65e0\u6cd5\u6cdb\u5316\u5230\u65b0\u7684\u4efb\u52a1\u3002", "motivation": "\u6700\u8fd1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8fdb\u6b65\u5c55\u793a\u4e86\u5728\u590d\u6742\u63a8\u7406\u65b9\u9762\u7684\u6d8c\u73b0\u80fd\u529b\uff0c\u8fd9\u4e3b\u8981\u7531\u540e\u8bad\u7ec3\u9636\u6bb5\u5e94\u7528\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6280\u672f\u63a8\u52a8\u3002\u8fd9\u5f15\u53d1\u4e86\u662f\u5426\u53ef\u4ee5\u4f7f\u7528\u7c7b\u4f3c\u65b9\u6cd5\u5728LLMs\u4e2d\u690d\u5165\u66f4\u7ec6\u817b\u3001\u7c7b\u4eba\u7684\u793e\u4f1a\u667a\u80fd\uff08\u5982\u5fc3\u667a\u7406\u8bba\uff0cToM\uff09\u7684\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u5728\u5404\u79cd\u7ec4\u5408\u7684\u8457\u540d\u5fc3\u667a\u7406\u8bba\u6570\u636e\u96c6\uff08HiToM\u3001ExploreToM\u3001FANToM\uff09\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u5728\u4fdd\u7559\u7684\u6570\u636e\u96c6\uff08\u5982OpenToM\uff09\u4e0a\u6d4b\u8bd5\u6cdb\u5316\u80fd\u529b\uff0c\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c0f\u578bLLMs\u96be\u4ee5\u901a\u8fc7RLVR\u83b7\u5f97\u7a33\u5065\u4e14\u53ef\u6cdb\u5316\u7684ToM\u80fd\u529b\u3002\u5c3d\u7ba1\u5728\u5206\u5e03\u5185\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u6709\u6240\u63d0\u9ad8\uff0c\u4f46\u8fd9\u79cd\u80fd\u529b\u65e0\u6cd5\u8f6c\u79fb\u5230\u5177\u6709\u4e0d\u540c\u7279\u5f81\u7684\u672a\u89c1\u8fc7\u7684ToM\u4efb\u52a1\u3002\u6b64\u5916\uff0c\u957f\u671f\u7684RL\u8bad\u7ec3\u5bfc\u81f4\u6a21\u578b\u201c\u7834\u89e3\u201d\u4e86\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u7edf\u8ba1\u6a21\u5f0f\uff0c\u4ece\u800c\u5728\u57df\u5185\u6570\u636e\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u4f46\u5728\u57df\u5916\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u6ca1\u6709\u53d8\u5316\u6216\u9000\u5316\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u53d1\u5c55\u51fa\u901a\u7528\u7684\u7406\u8bba\u5fc3\u667a\u80fd\u529b\u3002\u867d\u7136\u5728\u5206\u5e03\u5185\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u6709\u6240\u63d0\u9ad8\uff0c\u4f46\u8fd9\u79cd\u80fd\u529b\u65e0\u6cd5\u8f6c\u79fb\u5230\u5177\u6709\u4e0d\u540c\u7279\u5f81\u7684\u672a\u89c1\u8fc7\u7684\u4efb\u52a1\u3002\u6b64\u5916\uff0c\u957f\u671f\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5bfc\u81f4\u6a21\u578b\u201c\u7834\u89e3\u201d\u4e86\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u7edf\u8ba1\u6a21\u5f0f\uff0c\u4ece\u800c\u5728\u57df\u5185\u6570\u636e\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u4f46\u5728\u57df\u5916\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u6ca1\u6709\u53d8\u5316\u6216\u9000\u5316\u3002\u8fd9\u8868\u660e\u6240\u5b66\u7684\u884c\u4e3a\u662f\u4e00\u79cd\u72ed\u7a84\u7684\u8fc7\u62df\u5408\uff0c\u800c\u4e0d\u662f\u771f\u6b63\u62bd\u8c61\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\u7684\u83b7\u53d6\u3002"}}
{"id": "2507.15844", "pdf": "https://arxiv.org/pdf/2507.15844", "abs": "https://arxiv.org/abs/2507.15844", "authors": ["Shangke Lyu", "Linjuan Wu", "Yuchen Yan", "Xingyu Wu", "Hao Li", "Yongliang Shen", "Peisheng Jiang", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "title": "Hierarchical Budget Policy Optimization for Adaptive Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "Code: https://github.com/zju-real/hbpo Project\n  Page:https://zju-real.github.io/hbpo/", "summary": "Large reasoning models achieve remarkable performance through extensive\nchain-of-thought generation, yet exhibit significant computational inefficiency\nby applying uniform reasoning strategies regardless of problem complexity. We\npresent Hierarchical Budget Policy Optimization (HBPO), a reinforcement\nlearning framework that enables models to learn problem-specific reasoning\ndepths without sacrificing capability. HBPO addresses the fundamental challenge\nof exploration space collapse in efficiency-oriented training, where penalties\non long output length systematically bias models away from necessary long\nreasoning paths. Through hierarchical budget exploration, our approach\npartitions rollout samples into multiple subgroups with distinct token budgets,\naiming to enable efficient resource allocation while preventing degradation of\ncapability. We introduce differentiated reward mechanisms that create\nbudget-aware incentives aligned with the complexity of the problem, allowing\nmodels to discover natural correspondences between task requirements and\ncomputational effort. Extensive experiments demonstrate that HBPO reduces\naverage token usage by up to 60.6% while improving accuracy by 3.14% across\nfour reasoning benchmarks. Unlike existing methods that impose external\nconstraints or rely on discrete mode selection, HBPO exhibits emergent adaptive\nbehavior where models automatically adjust reasoning depth based on problem\ncomplexity. Our results suggest that reasoning efficiency and capability are\nnot inherently conflicting, and can be simultaneously optimized through\nappropriately structured hierarchical training that preserves exploration\ndiversity.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5206\u5c42\u9884\u7b97\u7b56\u7565\u4f18\u5316\uff08HBPO\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u7279\u5b9a\u4e8e\u95ee\u9898\u7684\u63a8\u7406\u6df1\u5ea6\uff0c\u800c\u4e0d\u4f1a\u727a\u7272\u80fd\u529b\u3002HBPO\u901a\u8fc7\u5206\u5c42\u9884\u7b97\u63a2\u7d22\u5c06\u6eda\u52a8\u6837\u672c\u5206\u6210\u591a\u4e2a\u5177\u6709\u4e0d\u540c\u6807\u8bb0\u9884\u7b97\u7684\u5b50\u7ec4\uff0c\u65e8\u5728\u5b9e\u73b0\u9ad8\u6548\u7684\u8d44\u6e90\u5206\u914d\u540c\u65f6\u9632\u6b62\u80fd\u529b\u9000\u5316\u3002\u5b9e\u9a8c\u8868\u660e\uff0cHBPO\u5728\u56db\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u6807\u8bb0\u4f7f\u7528\u91cf\u51cf\u5c11\u4e8660.6%\uff0c\u540c\u65f6\u51c6\u786e\u7387\u63d0\u9ad8\u4e863.14%\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u5e7f\u6cdb\u7684\u601d\u7ef4\u94fe\u751f\u6210\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\uff0c\u4f46\u901a\u8fc7\u7edf\u4e00\u7684\u63a8\u7406\u7b56\u7565\u5728\u65e0\u8bba\u95ee\u9898\u590d\u6742\u6027\u5982\u4f55\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u663e\u8457\u7684\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u7279\u5b9a\u4e8e\u95ee\u9898\u7684\u63a8\u7406\u6df1\u5ea6\uff0c\u800c\u4e0d\u4f1a\u727a\u7272\u80fd\u529b\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u5206\u5c42\u9884\u7b97\u7b56\u7565\u4f18\u5316\uff08HBPO\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5728\u4e0d\u727a\u7272\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\u5b66\u4e60\u7279\u5b9a\u4e8e\u95ee\u9898\u7684\u63a8\u7406\u6df1\u5ea6\u3002HBPO\u901a\u8fc7\u5206\u5c42\u9884\u7b97\u63a2\u7d22\u5c06\u6eda\u52a8\u6837\u672c\u5206\u6210\u591a\u4e2a\u5177\u6709\u4e0d\u540c\u6807\u8bb0\u9884\u7b97\u7684\u5b50\u7ec4\uff0c\u65e8\u5728\u5b9e\u73b0\u9ad8\u6548\u7684\u8d44\u6e90\u5206\u914d\u540c\u65f6\u9632\u6b62\u80fd\u529b\u9000\u5316\u3002\u6211\u4eec\u5f15\u5165\u4e86\u5dee\u5f02\u5316\u7684\u5956\u52b1\u673a\u5236\uff0c\u4ee5\u521b\u5efa\u4e0e\u95ee\u9898\u590d\u6742\u6027\u5bf9\u9f50\u7684\u9884\u7b97\u611f\u77e5\u6fc0\u52b1\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u53d1\u73b0\u4efb\u52a1\u8981\u6c42\u548c\u8ba1\u7b97\u52aa\u529b\u4e4b\u95f4\u7684\u81ea\u7136\u5bf9\u5e94\u5173\u7cfb\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHBPO\u5728\u56db\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u6807\u8bb0\u4f7f\u7528\u91cf\u51cf\u5c11\u4e8660.6%\uff0c\u540c\u65f6\u51c6\u786e\u7387\u63d0\u9ad8\u4e863.14%\u3002\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cHBPO\u8868\u73b0\u51fa\u4e00\u79cd\u65b0\u5174\u7684\u81ea\u9002\u5e94\u884c\u4e3a\uff0c\u5176\u4e2d\u6a21\u578b\u53ef\u4ee5\u6839\u636e\u95ee\u9898\u590d\u6742\u6027\u81ea\u52a8\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\u3002", "conclusion": "\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0c\u63a8\u7406\u6548\u7387\u548c\u80fd\u529b\u5e76\u975e\u672c\u8d28\u4e0a\u76f8\u4e92\u51b2\u7a81\uff0c\u53ef\u4ee5\u901a\u8fc7\u9002\u5f53\u6784\u5efa\u7684\u5206\u5c42\u8bad\u7ec3\u540c\u65f6\u4f18\u5316\uff0c\u4ee5\u4fdd\u6301\u63a2\u7d22\u591a\u6837\u6027\u3002"}}
{"id": "2507.15846", "pdf": "https://arxiv.org/pdf/2507.15846", "abs": "https://arxiv.org/abs/2507.15846", "authors": ["Fei Tang", "Zhangxuan Gu", "Zhengxi Lu", "Xuyang Liu", "Shuheng Shen", "Changhua Meng", "Wen Wang", "Wenqi Zhang", "Yongliang Shen", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "title": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.HC"], "comment": null, "summary": "Graphical User Interface (GUI) grounding maps natural language instructions\nto precise interface locations for autonomous interaction. Current\nreinforcement learning approaches use binary rewards that treat elements as\nhit-or-miss targets, creating sparse signals that ignore the continuous nature\nof spatial interactions. Motivated by human clicking behavior that naturally\nforms Gaussian distributions centered on target elements, we introduce GUI\nGaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that\nmodels GUI elements as continuous Gaussian distributions across the interface\nplane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point\nrewards model precise localization through exponentially decaying distributions\ncentered on element centroids, while coverage rewards assess spatial alignment\nby measuring the overlap between predicted Gaussian distributions and target\nregions. To handle diverse element scales, we develop an adaptive variance\nmechanism that calibrates reward distributions based on element dimensions.\nThis framework transforms GUI grounding from sparse binary classification to\ndense continuous optimization, where Gaussian distributions generate rich\ngradient signals that guide models toward optimal interaction positions.\nExtensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro\nbenchmarks demonstrate that GUI-G$^2$, substantially outperforms\nstate-of-the-art method UI-TARS-72B, with the most significant improvement of\n24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides\nsuperior robustness to interface variations and enhanced generalization to\nunseen layouts, establishing a new paradigm for spatial reasoning in GUI\ninteraction tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684GUI\u63a5\u5730\u5956\u52b1\u6846\u67b6GUI-G$^2$\uff0c\u5b83\u901a\u8fc7\u5c06GUI\u5143\u7d20\u5efa\u6a21\u4e3a\u8fde\u7eed\u9ad8\u65af\u5206\u5e03\u6765\u89e3\u51b3\u4f20\u7edf\u4e8c\u8fdb\u5236\u5956\u52b1\u7684\u4e0d\u8db3\u3002\u8be5\u6846\u67b6\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5bf9\u754c\u9762\u53d8\u5316\u7684\u66f4\u597d\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f7f\u7528\u4e8c\u8fdb\u5236\u5956\u52b1\uff0c\u5c06\u5143\u7d20\u89c6\u4e3a\u547d\u4e2d\u6216\u9519\u8fc7\u7684\u76ee\u6807\uff0c\u8fd9\u4f1a\u521b\u5efa\u7a00\u758f\u4fe1\u53f7\uff0c\u5ffd\u7565\u7a7a\u95f4\u4ea4\u4e92\u7684\u8fde\u7eed\u6027\u3002\u53d7\u4eba\u7c7b\u70b9\u51fb\u884c\u4e3a\u7684\u542f\u53d1\uff0c\u8fd9\u79cd\u884c\u4e3a\u81ea\u7136\u5f62\u6210\u4e86\u4ee5\u76ee\u6807\u5143\u7d20\u4e3a\u4e2d\u5fc3\u7684\u9ad8\u65af\u5206\u5e03\uff0c\u6211\u4eec\u5f15\u5165\u4e86GUI-G$^2$\uff0c\u4ee5\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86GUI Gaussian Grounding Rewards (GUI-G$^2$)\uff0c\u8fd9\u662f\u4e00\u4e2a\u539f\u7406\u6027\u7684\u5956\u52b1\u6846\u67b6\uff0c\u5c06GUI\u5143\u7d20\u5efa\u6a21\u4e3a\u754c\u9762\u4e0a\u7684\u8fde\u7eed\u9ad8\u65af\u5206\u5e03\u3002GUI-G$^2$\u7ed3\u5408\u4e86\u4e24\u79cd\u534f\u540c\u673a\u5236\uff1a\u9ad8\u65af\u70b9\u5956\u52b1\u901a\u8fc7\u4ee5\u5143\u7d20\u8d28\u5fc3\u4e3a\u4e2d\u5fc3\u7684\u6307\u6570\u8870\u51cf\u5206\u5e03\u6765\u5efa\u6a21\u7cbe\u786e\u7684\u5b9a\u4f4d\uff0c\u800c\u8986\u76d6\u5956\u52b1\u901a\u8fc7\u6d4b\u91cf\u9884\u6d4b\u9ad8\u65af\u5206\u5e03\u4e0e\u76ee\u6807\u533a\u57df\u4e4b\u95f4\u7684\u91cd\u53e0\u6765\u8bc4\u4f30\u7a7a\u95f4\u5bf9\u9f50\u5ea6\u3002\u6211\u4eec\u8fd8\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u65b9\u5dee\u673a\u5236\uff0c\u6839\u636e\u5143\u7d20\u5c3a\u5bf8\u6821\u51c6\u5956\u52b1\u5206\u5e03\u3002", "result": "\u5728ScreenSpot\u3001ScreenSpot-v2\u548cScreenSpot-Pro\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cGUI-G$^2$\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5UI-TARS-72B\uff0c\u5728ScreenSpot-Pro\u4e0a\u7684\u6539\u8fdb\u6700\u4e3a\u663e\u8457\uff0c\u8fbe\u523024.7%\u3002", "conclusion": "\u6211\u4eec\u7684\u5206\u6790\u8868\u660e\uff0c\u8fde\u7eed\u5efa\u6a21\u63d0\u4f9b\u4e86\u5bf9\u754c\u9762\u53d8\u5316\u7684\u4f18\u8d8a\u9c81\u68d2\u6027\u548c\u5bf9\u672a\u89c1\u8fc7\u7684\u5e03\u5c40\u7684\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u4e3aGUI\u4ea4\u4e92\u4efb\u52a1\u4e2d\u7684\u7a7a\u95f4\u63a8\u7406\u5efa\u7acb\u4e86\u4e00\u4e2a\u65b0\u8303\u5f0f\u3002"}}
