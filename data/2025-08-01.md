<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 67]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.HC](#cs.HC) [Total: 3]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.AI](#cs.AI) [Total: 5]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Large Language Models in the Travel Domain: An Industrial Experience](https://arxiv.org/abs/2507.22910)
*Sergio Di Meglio,Aniello Somma,Luigi Libero Lucio Starace,Fabio Scippacercola,Giancarlo Sperlì,Sergio Di Martino*

Main category: cs.CL

TL;DR: 本文研究了在房产预订平台中集成大型语言模型的效果，发现Mixtral 8x7B在性能上优于Mistral 7B，但计算成本更高。


<details>
  <summary>Details</summary>
Motivation: 在线房产预订平台依赖于一致、最新的住宿设施信息，但这些外部数据源经常受到不完整或不一致的细节影响，这会令用户感到沮丧并导致市场损失。

Method: 我们进行了一个工业案例研究，将大型语言模型（LLMs）集成到FERVENTO开发的CALEIDOHOTELS房产预订平台中。评估了两种著名的LLMs：使用QLoRA微调的Mistral 7B和使用优化系统提示的Mixtral 8x7B。

Result: Mixtral 8x7B在完整性（99.6% vs. 93%）、精确度（98.8% vs. 96%）和幻觉率（1.2% vs. 4%）方面优于Mistral 7B，生成的内容更短且更简洁（平均249 vs. 277个词）。然而，这需要显著更高的计算成本：50GB VRAM和1.61美元/小时，而Mistral 7B只需要5GB和0.16美元/小时。

Conclusion: 我们的研究提供了关于模型质量和资源效率之间权衡的实际见解，为在生产环境中部署大型语言模型提供了指导，并展示了它们在提高住宿数据一致性和可靠性方面的有效性。

Abstract: Online property booking platforms are widely used and rely heavily on
consistent, up-to-date information about accommodation facilities, often
sourced from third-party providers. However, these external data sources are
frequently affected by incomplete or inconsistent details, which can frustrate
users and result in a loss of market. In response to these challenges, we
present an industrial case study involving the integration of Large Language
Models (LLMs) into CALEIDOHOTELS, a property reservation platform developed by
FERVENTO. We evaluate two well-known LLMs in this context: Mistral 7B,
fine-tuned with QLoRA, and Mixtral 8x7B, utilized with a refined system prompt.
Both models were assessed based on their ability to generate consistent and
homogeneous descriptions while minimizing hallucinations. Mixtral 8x7B
outperformed Mistral 7B in terms of completeness (99.6% vs. 93%), precision
(98.8% vs. 96%), and hallucination rate (1.2% vs. 4%), producing shorter yet
more concise content (249 vs. 277 words on average). However, this came at a
significantly higher computational cost: 50GB VRAM and $1.61/hour versus 5GB
and $0.16/hour for Mistral 7B. Our findings provide practical insights into the
trade-offs between model quality and resource efficiency, offering guidance for
deploying LLMs in production environments and demonstrating their effectiveness
in enhancing the consistency and reliability of accommodation data.

</details>


### [2] [ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing](https://arxiv.org/abs/2507.22911)
*Jinzhi Wang,Qingke Peng,Haozhou Li,Zeyuan Zeng,Qinfeng Song,Kaixuan Yang,Jiangbo Zhang,Yaoying Wang,Ruimeng Li,Biyi Zhou*

Main category: cs.CL

TL;DR: This paper introduces ElectriQ, a benchmark for evaluating and enhancing LLMs in electric power marketing scenarios. It includes a dialogue dataset, four evaluation metrics, and a knowledge augmentation method. Experiments show that smaller models can outperform larger ones in specific aspects.


<details>
  <summary>Details</summary>
Motivation: Current systems, such as China's 95598 hotline, often struggle with slow response times, inflexible procedures, and limited accuracy in domain-specific tasks. While large language models (LLMs) demonstrate strong general capabilities, they lack the domain expertise and empathy required in this field.

Method: Introduce ElectriQ, a benchmark designed to evaluate and enhance LLMs in electric power marketing scenarios. It consists of a dialogue dataset covering six key service categories and introduces four evaluation metrics: professionalism, popularity, readability, and user-friendliness. A domain-specific knowledge base is incorporated, and a knowledge augmentation method is proposed.

Result: Experiments on 13 LLMs reveal that smaller models such as LLama3-8B, when fine-tuned and augmented, can surpass GPT-4o in terms of professionalism and user-friendliness.

Conclusion: ElectriQ establishes a comprehensive foundation for developing LLMs tailored to the needs of power marketing services.

Abstract: Electric power marketing customer service plays a critical role in addressing
inquiries, complaints, and service requests. However, current systems, such as
China's 95598 hotline, often struggle with slow response times, inflexible
procedures, and limited accuracy in domain-specific tasks. While large language
models (LLMs) like GPT-4o and Claude 3 demonstrate strong general capabilities,
they lack the domain expertise and empathy required in this field. To bridge
this gap, we introduce ElectriQ, the first benchmark designed to evaluate and
enhance LLMs in electric power marketing scenarios. ElectriQ consists of a
dialogue dataset covering six key service categories and introduces four
evaluation metrics: professionalism, popularity, readability, and
user-friendliness. We further incorporate a domain-specific knowledge base and
propose a knowledge augmentation method to boost model performance. Experiments
on 13 LLMs reveal that smaller models such as LLama3-8B, when fine-tuned and
augmented, can surpass GPT-4o in terms of professionalism and
user-friendliness. ElectriQ establishes a comprehensive foundation for
developing LLMs tailored to the needs of power marketing services.

</details>


### [3] [A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms](https://arxiv.org/abs/2507.22912)
*Navid Yazdanjue,Morteza Rakhshaninejad,Hossein Yazdanjouei,Mohammad Sadegh Khorshidi,Mikko S. Niemela,Fang Chen,Amir H. Gandomi*

Main category: cs.CL

TL;DR: 本文提出了一种分层分类框架，结合微调的语言模型和半监督集成学习策略，以检测和分类跨多种平台的非法市场内容。该方法在多个数据集上表现优异，证明了其在现实世界非法内容检测中的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于标记数据有限、非法语言的不断演变以及在线来源的结构异质性，检测和分类非法市场内容仍然具有挑战性。因此，需要一种有效的方法来应对这些挑战。

Method: 本文提出了一种分层分类框架，结合了微调的语言模型和半监督集成学习策略，以检测和分类跨多种平台的非法市场内容。该框架使用ModernBERT（一种用于长文档的Transformer模型）提取语义表示，并结合手动工程特征，如文档结构、嵌入模式和元数据。分类流程分为两个阶段：第一阶段使用基于熵的加权投票的半监督集成XGBoost、随机森林和SVM来检测销售相关文档；第二阶段进一步将这些文档分类为毒品、武器或凭证销售。

Result: 在三个数据集上的实验，包括我们的多源语料库、DUTA和CoDA，显示我们的模型优于几种基线模型，包括BERT、ModernBERT、DarkBERT、ALBERT、Longformer和BigBird。模型实现了0.96489的准确率、0.93467的F1分数和0.95388的TMCC，证明了其在现实世界非法内容检测中的有效性。

Conclusion: 本文提出的模型在检测和分类非法市场内容方面表现出色，具有强大的泛化能力、在有限监督下的鲁棒性以及在现实世界非法内容检测中的有效性。

Abstract: Illegal marketplaces have increasingly shifted to concealed parts of the
internet, including the deep and dark web, as well as platforms such as
Telegram, Reddit, and Pastebin. These channels enable the anonymous trade of
illicit goods including drugs, weapons, and stolen credentials. Detecting and
categorizing such content remains challenging due to limited labeled data, the
evolving nature of illicit language, and the structural heterogeneity of online
sources. This paper presents a hierarchical classification framework that
combines fine-tuned language models with a semi-supervised ensemble learning
strategy to detect and classify illicit marketplace content across diverse
platforms. We extract semantic representations using ModernBERT, a transformer
model for long documents, finetuned on domain-specific data from deep and dark
web pages, Telegram channels, Subreddits, and Pastebin pastes to capture
specialized jargon and ambiguous linguistic patterns. In addition, we
incorporate manually engineered features such as document structure, embedded
patterns including Bitcoin addresses, emails, and IPs, and metadata, which
complement language model embeddings. The classification pipeline operates in
two stages. The first stage uses a semi-supervised ensemble of XGBoost, Random
Forest, and SVM with entropy-based weighted voting to detect sales-related
documents. The second stage further classifies these into drug, weapon, or
credential sales. Experiments on three datasets, including our multi-source
corpus, DUTA, and CoDA, show that our model outperforms several baselines,
including BERT, ModernBERT, DarkBERT, ALBERT, Longformer, and BigBird. The
model achieves an accuracy of 0.96489, an F1-score of 0.93467, and a TMCC of
0.95388, demonstrating strong generalization, robustness under limited
supervision, and effectiveness in real-world illicit content detection.

</details>


### [4] [A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models](https://arxiv.org/abs/2507.22913)
*Jinyu Liu,Xiaoying Song,Diana Zhang,Jason Thomale,Daqing He,Lingzi Hong*

Main category: cs.CL

TL;DR: 本文提出了一种混合框架，结合基于嵌入的ML模型和LLM，以改进主题分析。通过预测最佳的LCSH标签数量和后期编辑预测的术语，实验结果表明这种方法能产生更受控且与词汇对齐的输出。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在分类和摘要任务中已被广泛使用，但它们在执行主题分析方面的能力尚未得到充分探索。传统的机器学习（ML）模型用于多标签分类进行主题分析，但在处理未见过的情况时存在困难。LLMs提供了另一种选择，但常常过度生成和幻觉。

Method: 提出了一种混合框架，将基于嵌入的ML模型与LLM集成。该方法使用ML模型来(1)预测最佳的LCSH标签数量以指导LLM预测，并(2)用实际的LCSH术语对预测的术语进行后期编辑以减轻幻觉。

Result: 实验结果表明，提供初始预测来引导LLM生成并施加后期编辑可以产生更受控且与词汇对齐的输出。

Conclusion: 实验结果表明，提供初始预测来引导LLM生成并施加后期编辑可以产生更受控且与词汇对齐的输出。

Abstract: Providing subject access to information resources is an essential function of
any library management system. Large language models (LLMs) have been widely
used in classification and summarization tasks, but their capability to perform
subject analysis is underexplored. Multi-label classification with traditional
machine learning (ML) models has been used for subject analysis but struggles
with unseen cases. LLMs offer an alternative but often over-generate and
hallucinate. Therefore, we propose a hybrid framework that integrates
embedding-based ML models with LLMs. This approach uses ML models to (1)
predict the optimal number of LCSH labels to guide LLM predictions and (2)
post-edit the predicted terms with actual LCSH terms to mitigate
hallucinations. We experimented with LLMs and the hybrid framework to predict
the subject terms of books using the Library of Congress Subject Headings
(LCSH). Experiment results show that providing initial predictions to guide LLM
generations and imposing post-edits result in more controlled and
vocabulary-aligned outputs.

</details>


### [5] [Full Triple Matcher: Integrating all triple elements between heterogeneous Knowledge Graphs](https://arxiv.org/abs/2507.22914)
*Victor Eiti Yamamoto,Hideaki Takeda*

Main category: cs.CL

TL;DR: 本文提出了一种新的知识图谱集成方法，通过标签匹配和三元组匹配来提高实体匹配的准确性，并引入了一个新的数据集来评估三元组匹配步骤。


<details>
  <summary>Details</summary>
Motivation: 由于现实世界的KG在来源、大小和信息密度方面差异很大，而这些因素通常不在当前实体匹配方法评估的数据集中体现，因此现有的方法可能在需要整合多样和复杂上下文的场景中表现不足。

Method: 我们提出了一个由标签匹配和三元组匹配组成的新型KG集成方法，使用字符串操作、模糊匹配和向量相似性技术对实体和谓词标签进行对齐，并通过识别传达相似信息的三元组映射来提高实体匹配的准确性。

Result: 我们的方法在OAEI竞赛和监督方法中表现出色，实现了高准确性，并且我们引入了一个新的数据集来更全面地评估三元组匹配步骤。

Conclusion: 我们的方法在OAEI竞赛和监督方法中表现出色，实现了高准确性，并且我们引入了一个新的数据集来更全面地评估三元组匹配步骤。

Abstract: Knowledge graphs (KGs) are powerful tools for representing and reasoning over
structured information. Their main components include schema, identity, and
context. While schema and identity matching are well-established in ontology
and entity matching research, context matching remains largely unexplored. This
is particularly important because real-world KGs often vary significantly in
source, size, and information density - factors not typically represented in
the datasets on which current entity matching methods are evaluated. As a
result, existing approaches may fall short in scenarios where diverse and
complex contexts need to be integrated.
  To address this gap, we propose a novel KG integration method consisting of
label matching and triple matching. We use string manipulation, fuzzy matching,
and vector similarity techniques to align entity and predicate labels. Next, we
identify mappings between triples that convey comparable information, using
these mappings to improve entity-matching accuracy. Our approach demonstrates
competitive performance compared to leading systems in the OAEI competition and
against supervised methods, achieving high accuracy across diverse test cases.
Additionally, we introduce a new dataset derived from the benchmark dataset to
evaluate the triple-matching step more comprehensively.

</details>


### [6] [Theoretical Foundations and Mitigation of Hallucination in Large Language Models](https://arxiv.org/abs/2507.22915)
*Esmail Gumaan*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型中的幻觉问题，通过理论分析和实践方法提供了检测和缓解幻觉的全面方案。


<details>
  <summary>Details</summary>
Motivation: 幻觉是大型语言模型生成的内容与输入或现实世界事实不一致的现象，这影响了模型的可靠性和实用性。因此，需要对幻觉进行严谨的研究，以提供有效的检测和缓解方法。

Method: 本文通过学习理论框架（如PAC-Bayes和Rademacher复杂度）推导了幻觉风险的界限，并调查了检测策略，如token级别的不确定性估计、置信度校准和注意力对齐检查。同时讨论了缓解方法，包括检索增强生成、幻觉感知微调、logit校准以及事实验证模块的整合。

Result: 本文提出了一个统一的检测和缓解工作流程，并概述了评估幻觉的协议，推荐了数据集、指标和实验设置来量化和减少幻觉。

Conclusion: 本文为解决大型语言模型中的幻觉问题提供了理论基础和实践指南。

Abstract: Hallucination in Large Language Models (LLMs) refers to the generation of
content that is not faithful to the input or the real-world facts. This paper
provides a rigorous treatment of hallucination in LLMs, including formal
definitions and theoretical analyses. We distinguish between intrinsic and
extrinsic hallucinations, and define a \textit{hallucination risk} for models.
We derive bounds on this risk using learning-theoretic frameworks (PAC-Bayes
and Rademacher complexity). We then survey detection strategies for
hallucinations, such as token-level uncertainty estimation, confidence
calibration, and attention alignment checks. On the mitigation side, we discuss
approaches including retrieval-augmented generation, hallucination-aware
fine-tuning, logit calibration, and the incorporation of fact-verification
modules. We propose a unified detection and mitigation workflow, illustrated
with a diagram, to integrate these strategies. Finally, we outline evaluation
protocols for hallucination, recommending datasets, metrics, and experimental
setups to quantify and reduce hallucinations. Our work lays a theoretical
foundation and practical guidelines for addressing the crucial challenge of
hallucination in LLMs.

</details>


### [7] [Reading Between the Timelines: RAG for Answering Diachronic Questions](https://arxiv.org/abs/2507.22917)
*Kwun Hang Lau,Ruiyuan Zhang,Weijie Shi,Xiaofang Zhou,Xiaojun Cheng*

Main category: cs.CL

TL;DR: 本文提出了一种新的RAG框架，通过引入时间逻辑来解决处理长期查询的问题，并在金融新闻数据集上进行了评估，显示出显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于语义的检索方法无法收集既主题相关又时间连贯的证据，因此需要一种新的方法来处理需要跟踪实体和现象随时间变化的长期查询。

Method: 本文提出了一种新的框架，从根本上重新设计RAG管道以注入时间逻辑。方法包括将用户查询分解为核心主题和时间窗口，并使用专门的检索器校准语义匹配与时间相关性，确保收集到跨越整个查询时期的连续证据集。

Result: 在ADQAB上的实验结果表明，该方法在答案准确性上取得了显著提升，超越了标准RAG实现13%至27%。

Conclusion: 本文提供了一种验证的路径，使RAG系统能够执行复杂现实问题所需的细微和演变分析。

Abstract: While Retrieval-Augmented Generation (RAG) excels at injecting static,
factual knowledge into Large Language Models (LLMs), it exhibits a critical
deficit in handling longitudinal queries that require tracking entities and
phenomena across time. This blind spot arises because conventional,
semantically-driven retrieval methods are not equipped to gather evidence that
is both topically relevant and temporally coherent for a specified duration. We
address this challenge by proposing a new framework that fundamentally
redesigns the RAG pipeline to infuse temporal logic. Our methodology begins by
disentangling a user's query into its core subject and its temporal window. It
then employs a specialized retriever that calibrates semantic matching against
temporal relevance, ensuring the collection of a contiguous evidence set that
spans the entire queried period. To enable rigorous evaluation of this
capability, we also introduce the Analytical Diachronic Question Answering
Benchmark (ADQAB), a challenging evaluation suite grounded in a hybrid corpus
of real and synthetic financial news. Empirical results on ADQAB show that our
approach yields substantial gains in answer accuracy, surpassing standard RAG
implementations by 13% to 27%. This work provides a validated pathway toward
RAG systems capable of performing the nuanced, evolutionary analysis required
for complex, real-world questions. The dataset and code for this study are
publicly available at https://github.com/kwunhang/TA-RAG.

</details>


### [8] [Semantic Convergence: Investigating Shared Representations Across Scaled LLMs](https://arxiv.org/abs/2507.22918)
*Daniel Son,Sanjana Rathore,Andrew Rufail,Adrian Simon,Daniel Zhang,Soham Dave,Cole Blondin,Kevin Zhu,Sean O'Brien*

Main category: cs.CL

TL;DR: 研究大型语言模型的特征通用性，发现不同规模的模型在中间层具有高度相似的特征空间，支持通用性作为跨模型可解释性的基础。


<details>
  <summary>Details</summary>
Motivation: 研究Gemma-2语言模型（Gemma-2-2B和Gemma-2-9B）中的特征通用性，探讨规模相差四倍的模型是否仍会收敛到类似的内部概念。

Method: 使用稀疏自编码器（SAE）字典学习流程，在每个模型的残差流激活上使用SAE，通过激活相关性对产生的单义特征进行对齐，并通过SVCCA和RSA比较匹配的特征空间。

Result: 中间层产生最强的重叠，而早期和晚期层显示较少的相似性。初步实验将分析从单个标记扩展到多标记子空间，表明语义相似的子空间与语言模型的交互方式类似。

Conclusion: 大型语言模型即使在规模差异较大的情况下，也会形成广泛相似且可解释的特征，这加强了通用性作为跨模型可解释性基础的论点。

Abstract: We investigate feature universality in Gemma-2 language models (Gemma-2-2B
and Gemma-2-9B), asking whether models with a four-fold difference in scale
still converge on comparable internal concepts. Using the Sparse Autoencoder
(SAE) dictionary-learning pipeline, we utilize SAEs on each model's
residual-stream activations, align the resulting monosemantic features via
activation correlation, and compare the matched feature spaces with SVCCA and
RSA. Middle layers yield the strongest overlap, while early and late layers
show far less similarity. Preliminary experiments extend the analysis from
single tokens to multi-token subspaces, showing that semantically similar
subspaces interact similarly with language models. These results strengthen the
case that large language models carve the world into broadly similar,
interpretable features despite size differences, reinforcing universality as a
foundation for cross-model interpretability.

</details>


### [9] [A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations](https://arxiv.org/abs/2507.22919)
*Qixuan Hu,Xumou Zhang,Jinman Kim,Florence Bourgeois,Adam G. Dunn*

Main category: cs.CL

TL;DR: 本文评估了利用临床试验注册信息预测严重不良事件（SAE）结果的方法。通过使用预训练语言模型和滑动窗口方法，开发了两种预测模型，取得了良好的预测效果。研究发现，总结结果数据在ClinicalTrials.gov中仍被低估利用，这为改进试验设计和标记预期与报告的安全结果之间的差异提供了机会。


<details>
  <summary>Details</summary>
Motivation: 准确估计预期安全结果可以帮助设计临床试验以避免终止并限制参与者暴露于不必要的风险。

Method: 我们分析了22,107个双臂平行干预性临床试验，使用了结构化摘要结果。开发了两种预测模型：一个分类器用于预测实验组是否有更高的SAE率，以及一个回归模型用于预测对照组中SAE的比例。使用预训练语言模型（如ClinicalT5、BioBERT）进行特征提取，并结合下游模型进行预测。为了保持超出局部语言模型输入限制的长试验文本的语义表示，开发了一种滑动窗口方法进行嵌入提取。

Result: 最佳模型（ClinicalT5+Transformer+MLP）在预测哪个试验组有更高比例的SAE患者方面达到了77.6%的AUC。当预测对照组中经历SAE的参与者比例时，同一模型实现了18.6%的RMSE。滑动窗口方法始终优于没有该方法的方法。在12个分类器中，平均绝对AUC增加了2.00%；在12个回归器中，平均绝对RMSE减少了1.58%。

Conclusion: 总结结果数据在ClinicalTrials.gov中仍被低估利用。在试验开始前估计试验结果的潜力为改进试验设计和标记预期与报告的安全结果之间的差异提供了机会。

Abstract: Objectives: With accurate estimates of expected safety results, clinical
trials could be designed to avoid terminations and limit exposing participants
to unnecessary risks. We evaluated methods for predicting serious adverse event
(SAE) results in clinical trials using information only from their
registrations prior to the trial. Material and Methods: We analysed 22,107
two-arm parallel interventional clinical trials from ClinicalTrials.gov with
structured summary results. Two prediction models were developed: a classifier
predicting will experimental arm have higher SAE rates (area under the receiver
operating characteristic curve; AUC) than control arm, and a regression model
to predict the proportion of SAEs in control arms (root mean squared error;
RMSE). A transfer learning approach using pretrained language models (e.g.,
ClinicalT5, BioBERT) was used for feature extraction, combined with downstream
model for prediction. To maintain semantic representation in long trial texts
exceeding localised language model input limits, a sliding window method was
developed for embedding extraction. Results: The best model
(ClinicalT5+Transformer+MLP) had 77.6% AUC predicting which trial arm has a
higher proportion of patients with SAEs. When predicting proportion of
participants experiencing SAE in the control arm, the same model achieved RMSE
of 18.6%. The sliding window approach consistently outperformed methods without
it. Across 12 classifiers, the average absolute AUC increase was 2.00%; across
12 regressors, the average absolute RMSE reduction was 1.58%. Discussion:
Summary results data available at ClinicalTrials.gov remains underutilised. The
potential to estimate results of trials before they start is an opportunity to
improve trial design and flag discrepancies between expected and reported
safety results.

</details>


### [10] [Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey](https://arxiv.org/abs/2507.22920)
*Jindong Li,Yali Fu,Jiahong Liu,Linxiao Cao,Wei Ji,Menglin Yang,Irwin King,Ming-Hsuan Yang*

Main category: cs.CL

TL;DR: 本文是对LLM中离散标记化方法的首次结构化分类和分析，涵盖了算法原理、训练动态和集成挑战，并讨论了量化策略的影响以及未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 由于LLM的快速发展，需要有效的机制将连续的多模态数据转换为适合语言处理的离散表示。尽管离散标记化的重要性日益增加，但缺乏全面的调查来系统地审视LLM系统中的VQ技术。

Method: 本文对8种代表性的VQ变体进行了分类，并分析了它们的算法原理、训练动态和与LLM流水线的集成挑战。此外，还讨论了现有研究在无LLMs的经典应用、基于LLM的单模态系统和基于LLM的多模态系统中的情况。

Result: 本文提出了第一个针对LLM的离散标记化方法的结构化分类和分析，讨论了量化策略如何影响对齐、推理和生成性能，并指出了关键挑战和新兴研究方向。

Conclusion: 本文通过构建第一个结构化的分类和分析，填补了现有研究的空白，为高效且可推广的多模态系统的发展提供了基础参考。

Abstract: The rapid advancement of large language models (LLMs) has intensified the
need for effective mechanisms to transform continuous multimodal data into
discrete representations suitable for language-based processing. Discrete
tokenization, with vector quantization (VQ) as a central approach, offers both
computational efficiency and compatibility with LLM architectures. Despite its
growing importance, there is a lack of a comprehensive survey that
systematically examines VQ techniques in the context of LLM-based systems. This
work fills this gap by presenting the first structured taxonomy and analysis of
discrete tokenization methods designed for LLMs. We categorize 8 representative
VQ variants that span classical and modern paradigms and analyze their
algorithmic principles, training dynamics, and integration challenges with LLM
pipelines. Beyond algorithm-level investigation, we discuss existing research
in terms of classical applications without LLMs, LLM-based single-modality
systems, and LLM-based multimodal systems, highlighting how quantization
strategies influence alignment, reasoning, and generation performance. In
addition, we identify key challenges including codebook collapse, unstable
gradient estimation, and modality-specific encoding constraints. Finally, we
discuss emerging research directions such as dynamic and task-adaptive
quantization, unified tokenization frameworks, and biologically inspired
codebook learning. This survey bridges the gap between traditional vector
quantization and modern LLM applications, serving as a foundational reference
for the development of efficient and generalizable multimodal systems. A
continuously updated version is available at:
https://github.com/jindongli-Ai/LLM-Discrete-Tokenization-Survey.

</details>


### [11] [Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers](https://arxiv.org/abs/2507.22921)
*Lee Harris*

Main category: cs.CL

TL;DR: 本文提出了语言模型链(LMC)算法，以解决语言模型成本高和产生幻觉的问题。通过将错误响应输入到更可预测但更慢的语言模型中，LMC算法显著提高了预测速度和准确性，并减少了幻觉数量。


<details>
  <summary>Details</summary>
Motivation: 语言模型可以捕捉给定文本中的复杂关系，但它们以成本高和产生不存在的信息（即幻觉）而闻名。此外，投入生产这些信息的资源如果错误的话就会被浪费。我们通过提出、实现和应用语言模型链(LMC)算法来解决这些问题。

Method: 我们提出了语言模型链(LMC)算法，其中语言模型对给定提示的响应只有在存在于可能的答案集合中时才是正确的，并且将对应于错误响应的文本输入到更可预测（但更慢）的语言模型中。这个过程重复进行一组语言模型，或者直到所有关于文本的预测都是正确的。

Result: 我们使用LMC算法从医疗文档中提取患者出生日期，并将一组语言模型组合成多阶段级联，显著提高了预测速度和准确性，同时大大减少了相应的幻觉数量。

Conclusion: 我们认为，新颖的LMC算法对知识提取领域有显著贡献，并且应在未来进一步探索。

Abstract: Language models can capture complex relationships in given text, but these
are notorious for being costly and for producing information that does not
exist (i.e., hallucinations). Furthermore, the resources invested into
producing this information would be wasted if it were incorrect. We address
these issues by proposing, implementing, and applying the Language Model Chain
(LMC) algorithm. In this, a language model's response to a given prompt about
given text is only correct if it exists in the collection of possible (i.e.,
candidate) answers, and text corresponding to incorrect responses is fed into a
more predictive (but slower) language model. This process is repeated for a
collection of language models, or until all predictions about the text are
correct. We used the LMC algorithm to extract patient dates of birth from
medical documents, and combining a collection of language models in a
multi-stage cascade significantly increased prediction speed and accuracy over
individual language models, while greatly reducing the number of corresponding
hallucinations. We believe that the novel LMC algorithm significantly
contributes to the knowledge extraction field, and that this should be explored
much further in the future.

</details>


### [12] [Predicting stock prices with ChatGPT-annotated Reddit sentiment](https://arxiv.org/abs/2507.22922)
*Mateusz Kmak,Kamil Chmurzyński,Kamil Matejuk,Paweł Kotzbach,Jan Kocoń*

Main category: cs.CL

TL;DR: 本研究分析了社交媒体情感对股票价格的影响，发现其相关性较弱，而评论数量和谷歌搜索趋势等简单指标更具预测能力。


<details>
  <summary>Details</summary>
Motivation: 2021年GameStop做空挤兑事件引发了对在线情绪如何影响股票价格的关注。本研究旨在探讨从社交媒体讨论中得出的情绪是否能有意义地预测股市波动。

Method: 本研究聚焦于Reddit的r/wallstreetbets，分析与GameStop（GME）和AMC Entertainment（AMC）相关的社交媒体情感。我们采用了两种现有的基于文本的情感分析方法，并引入了一种新的基于ChatGPT标注和微调的RoBERTa模型，以更好地理解社交媒体讨论中的非正式语言和表情符号。我们使用相关性和因果度量来确定这些模型的预测能力。

Result: 研究发现，社交媒体情绪与股价之间的相关性较弱。同时，简单的指标如评论数量和谷歌搜索趋势显示出更强的预测信号。

Conclusion: 研究结果表明，社交媒体情感与股价之间的相关性较弱，而简单的指标如评论数量和谷歌搜索趋势则表现出更强的预测信号。这突显了零售投资者行为的复杂性，并表明传统的情感分析可能无法完全捕捉市场动向的细微差别。

Abstract: The surge of retail investor activity on social media, exemplified by the
2021 GameStop short squeeze, raised questions about the influence of online
sentiment on stock prices. This paper explores whether sentiment derived from
social media discussions can meaningfully predict stock market movements. We
focus on Reddit's r/wallstreetbets and analyze sentiment related to two
companies: GameStop (GME) and AMC Entertainment (AMC). To assess sentiment's
role, we employ two existing text-based sentiment analysis methods and
introduce a third, a ChatGPT-annotated and fine-tuned RoBERTa-based model
designed to better interpret the informal language and emojis prevalent in
social media discussions. We use correlation and causality metrics to determine
these models' predictive power. Surprisingly, our findings suggest that social
media sentiment has only a weak correlation with stock prices. At the same
time, simpler metrics, such as the volume of comments and Google search trends,
exhibit stronger predictive signals. These results highlight the complexity of
retail investor behavior and suggest that traditional sentiment analysis may
not fully capture the nuances of market-moving online discussions.

</details>


### [13] [How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting](https://arxiv.org/abs/2507.22923)
*Aman Gupta,Yingying Zhuang,Zhou Yu,Ziji Zhang,Anurag Beniwal*

Main category: cs.CL

TL;DR: 本文研究了多语言系统中不同提示翻译策略对增强RAG的LLMs进行分类任务的影响，并发现优化的提示策略可以显著提高跨语言的知识共享和任务性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在多语言能力方面取得了进展，但它们在不同语言和任务中的表现差异很大。在基于多语言检索增强生成（RAG）的系统中，知识库（KB）通常从高资源语言（如英语）共享到低资源语言，导致从KB中检索的信息与上下文的语言不同。然而，这些选择的影响仍然不清楚。

Method: 本文系统评估了不同提示翻译策略对多语言系统中增强RAG的LLMs进行分类任务的影响。

Result: 实验结果表明，优化的提示策略可以显著提高跨语言的知识共享，从而提高下游分类任务的性能。

Conclusion: 研究结果表明，优化的提示策略可以显著提高跨语言的知识共享，从而提高下游分类任务的性能。研究倡导更广泛地利用多语言资源共享和跨语言提示优化，尤其是对于非英语语言，特别是资源较少的语言。

Abstract: Despite advances in the multilingual capabilities of Large Language Models
(LLMs), their performance varies substantially across different languages and
tasks. In multilingual retrieval-augmented generation (RAG)-based systems,
knowledge bases (KB) are often shared from high-resource languages (such as
English) to low-resource ones, resulting in retrieved information from the KB
being in a different language than the rest of the context. In such scenarios,
two common practices are pre-translation to create a mono-lingual prompt and
cross-lingual prompting for direct inference. However, the impact of these
choices remains unclear. In this paper, we systematically evaluate the impact
of different prompt translation strategies for classification tasks with
RAG-enhanced LLMs in multilingual systems. Experimental results show that an
optimized prompting strategy can significantly improve knowledge sharing across
languages, therefore improve the performance on the downstream classification
task. The findings advocate for a broader utilization of multilingual resource
sharing and cross-lingual prompt optimization for non-English languages,
especially the low-resource ones.

</details>


### [14] [Using Sentiment Analysis to Investigate Peer Feedback by Native and Non-Native English Speakers](https://arxiv.org/abs/2507.22924)
*Brittney Exline,Melanie Duffin,Brittany Harbison,Chrissa da Gomez,David Joyner*

Main category: cs.CL

TL;DR: 研究分析了在线美国计算机课程中，母语与非母语英语使用者对同伴反馈体验的影响，发现语言背景在其中扮演了适度但复杂的角色。


<details>
  <summary>Details</summary>
Motivation: 研究母语与非母语英语使用者状态如何影响在线美国计算机课程中的同伴反馈体验的三个指标。

Method: 使用基于Twitter-roBERTa的模型分析了500名学生的随机样本的同伴评审的情感。然后将情感评分和同伴反馈评分与学生的语言背景相关联。

Result: 结果显示，母语为英语的学生对反馈的评价较低，而非母语者写得更积极但得到的积极情感较少。当控制性别和年龄时，出现了显著的交互作用，表明语言背景在塑造同伴反馈体验中起着适度但复杂的作用。

Conclusion: 研究发现，母语为英语的学生对反馈的评价较低，而非母语者写得更积极但得到的积极情感较少。当控制性别和年龄时，出现了显著的交互作用，表明语言背景在塑造同伴反馈体验中起着适度但复杂的作用。

Abstract: Graduate-level CS programs in the U.S. increasingly enroll international
students, with 60.2 percent of master's degrees in 2023 awarded to non-U.S.
students. Many of these students take online courses, where peer feedback is
used to engage students and improve pedagogy in a scalable manner. Since these
courses are conducted in English, many students study in a language other than
their first. This paper examines how native versus non-native English speaker
status affects three metrics of peer feedback experience in online U.S.-based
computing courses. Using the Twitter-roBERTa-based model, we analyze the
sentiment of peer reviews written by and to a random sample of 500 students. We
then relate sentiment scores and peer feedback ratings to students' language
background. Results show that native English speakers rate feedback less
favorably, while non-native speakers write more positively but receive less
positive sentiment in return. When controlling for sex and age, significant
interactions emerge, suggesting that language background plays a modest but
complex role in shaping peer feedback experiences.

</details>


### [15] [Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents](https://arxiv.org/abs/2507.22925)
*Haoran Sun,Shaoning Zeng*

Main category: cs.CL

TL;DR: 本文提出了一种分层记忆架构（H-MEM），用于大型语言模型代理，以提高长期记忆的组织和检索效率。实验结果表明，该方法在长期对话场景中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 长期记忆是影响大型语言模型代理（LLM代理）推理能力的关键因素。整合有效的过去交互记忆可以显著增强LLM代理的决策能力和上下文连贯性。尽管最近的工作在记忆存储和检索方面取得了进展，如将记忆编码为密集向量进行基于相似性的搜索或以图的形式组织知识，但这些方法在结构化记忆组织和高效检索方面往往不足。

Method: 我们提出了一个分层记忆（H-MEM）架构，该架构基于语义抽象程度以多级方式组织和更新记忆。每个记忆向量都嵌入了一个位置索引编码，指向下一层中语义相关的子记忆。在推理阶段，基于索引的路由机制实现了高效的逐层检索，而无需进行广泛的相似性计算。

Result: 我们在LoCoMo数据集的五个任务设置上评估了我们的方法。实验结果表明，我们的方法始终优于五种基线方法，证明了其在长期对话场景中的有效性。

Conclusion: 我们的方法在长期对话场景中表现出色，优于五种基线方法。

Abstract: Long-term memory is one of the key factors influencing the reasoning
capabilities of Large Language Model Agents (LLM Agents). Incorporating a
memory mechanism that effectively integrates past interactions can
significantly enhance decision-making and contextual coherence of LLM Agents.
While recent works have made progress in memory storage and retrieval, such as
encoding memory into dense vectors for similarity-based search or organizing
knowledge in the form of graph, these approaches often fall short in structured
memory organization and efficient retrieval. To address these limitations, we
propose a Hierarchical Memory (H-MEM) architecture for LLM Agents that
organizes and updates memory in a multi-level fashion based on the degree of
semantic abstraction. Each memory vector is embedded with a positional index
encoding pointing to its semantically related sub-memories in the next layer.
During the reasoning phase, an index-based routing mechanism enables efficient,
layer-by-layer retrieval without performing exhaustive similarity computations.
We evaluate our method on five task settings from the LoCoMo dataset.
Experimental results show that our approach consistently outperforms five
baseline methods, demonstrating its effectiveness in long-term dialogue
scenarios.

</details>


### [16] [Multi-Relation Extraction in Entity Pairs using Global Context](https://arxiv.org/abs/2507.22926)
*Nilesh,Atul Gupta,Avinash C Panday*

Main category: cs.CL

TL;DR: 本文提出了一种新的输入嵌入方法，以捕捉文档中实体的位置，从而提升文档级关系抽取的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的做法只关注提到实体的句子，无法捕捉完整的文档上下文，因此需要一种新的方法来准确预测文档中两个实体之间的关系。

Method: 该论文引入了一种新的输入嵌入方法，通过将实体表示为独立的段落，而不是仅关注它们出现的范围，从而捕捉整个文档中的全局关系和多句推理。

Result: 在三个基准数据集DocRED、Re-DocRED和REBEL上测试了所提出的方法，实验结果表明该方法能准确预测文档级实体之间的关系。

Conclusion: 该研究在文档级关系抽取任务中具有理论和实际意义，能够提升真实世界自然语言处理应用中的性能。

Abstract: In document-level relation extraction, entities may appear multiple times in
a document, and their relationships can shift from one context to another.
Accurate prediction of the relationship between two entities across an entire
document requires building a global context spanning all relevant sentences.
Previous approaches have focused only on the sentences where entities are
mentioned, which fails to capture the complete document context necessary for
accurate relation extraction. Therefore, this paper introduces a novel input
embedding approach to capture the positions of mentioned entities throughout
the document rather than focusing solely on the span where they appear. The
proposed input encoding approach leverages global relationships and
multi-sentence reasoning by representing entities as standalone segments,
independent of their positions within the document. The performance of the
proposed method has been tested on three benchmark relation extraction
datasets, namely DocRED, Re-DocRED, and REBEL. The experimental results
demonstrated that the proposed method accurately predicts relationships between
entities in a document-level setting. The proposed research also has
theoretical and practical implications. Theoretically, it advances global
context modeling and multi-sentence reasoning in document-level relation
extraction. Practically, it enhances relationship detection, enabling improved
performance in real-world NLP applications requiring comprehensive entity-level
insights and interpretability.

</details>


### [17] [PRGB Benchmark: A Robust Placeholder-Assisted Algorithm for Benchmarking Retrieval-Augmented Generation](https://arxiv.org/abs/2507.22927)
*Zhehao Tan,Yihan Jiao,Dan Yang,Lei Liu,Jie Feng,Duolin Sun,Yue Shen,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: 本文介绍了一个名为	extit{Placeholder-RAG-Benchmark}的多级细粒度基准，用于评估RAG系统中LLM的能力。通过引入基于占位符的方法，我们能够更好地理解LLM在RAG系统中的作用，并展示了当前LLM在生成能力上的局限性。


<details>
  <summary>Details</summary>
Motivation: 目前的基准主要关注整体RAG系统性能，很少评估LLM特定能力。当前基准强调诸如噪声鲁棒性等广泛方面，但缺乏对文档利用的系统性和细致的评估框架。

Method: 我们引入了	extit{Placeholder-RAG-Benchmark}，这是一个多级细粒度基准，强调以下渐进维度：(1) 多级过滤能力，(2) 组合能力，以及(3) 参考推理。我们提出了一个基于占位符的方法，以解耦LLM的参数化知识和外部知识的贡献。

Result: 实验表明，代表性LLM在RAG系统的生成能力上存在局限性，特别是在错误弹性性和上下文忠实性方面。

Conclusion: 我们的基准提供了一个可重复的框架，用于开发更可靠和高效的RAG系统。

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
integrating external knowledge, where the LLM's ability to generate responses
based on the combination of a given query and retrieved documents is crucial.
However, most benchmarks focus on overall RAG system performance, rarely
assessing LLM-specific capabilities. Current benchmarks emphasize broad aspects
such as noise robustness, but lack a systematic and granular evaluation
framework on document utilization. To this end, we introduce
\textit{Placeholder-RAG-Benchmark}, a multi-level fine-grained benchmark,
emphasizing the following progressive dimensions: (1) multi-level filtering
abilities, (2) combination abilities, and (3) reference reasoning. To provide a
more nuanced understanding of LLMs' roles in RAG systems, we formulate an
innovative placeholder-based approach to decouple the contributions of the
LLM's parametric knowledge and the external knowledge. Experiments demonstrate
the limitations of representative LLMs in the RAG system's generation
capabilities, particularly in error resilience and context faithfulness. Our
benchmark provides a reproducible framework for developing more reliable and
efficient RAG systems. Our code is available in
https://github.com/Alipay-Med/PRGB.

</details>


### [18] [How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding](https://arxiv.org/abs/2507.22928)
*Xi Chen,Aske Plaat,Niki van Stein*

Main category: cs.CL

TL;DR: 本文研究了CoT提示在大型语言模型中的有效性，发现CoT可以引发更可解释的内部结构，特别是在高容量模型中。


<details>
  <summary>Details</summary>
Motivation: Chain-of-thought (CoT) prompting 提高了大型语言模型在多步骤任务中的准确性，但生成的“想法”是否反映真实的内部推理过程尚不清楚。

Method: 结合稀疏自编码器和激活补丁，我们从Pythia-70M和Pythia-2.8B中提取单义特征，同时它们在CoT和plain（noCoT）提示下解决GSM8K数学问题。

Result: 将一小部分CoT推理特征交换到noCoT运行中，显著提高了2.8B模型的答案log-probabilities，但在70M中没有可靠的效果，揭示了一个清晰的规模阈值。CoT还导致更大的模型中激活稀疏性和特征可解释性评分显著提高，表明内部计算更加模块化。

Conclusion: 我们的结果表明，CoT可以在高容量的LLM中引发更可解释的内部结构，验证了其作为结构化提示方法的作用。

Abstract: Chain-of-thought (CoT) prompting boosts Large Language Models accuracy on
multi-step tasks, yet whether the generated "thoughts" reflect the true
internal reasoning process is unresolved. We present the first feature-level
causal study of CoT faithfulness. Combining sparse autoencoders with activation
patching, we extract monosemantic features from Pythia-70M and Pythia-2.8B
while they tackle GSM8K math problems under CoT and plain (noCoT) prompting.
Swapping a small set of CoT-reasoning features into a noCoT run raises answer
log-probabilities significantly in the 2.8B model, but has no reliable effect
in 70M, revealing a clear scale threshold. CoT also leads to significantly
higher activation sparsity and feature interpretability scores in the larger
model, signalling more modular internal computation. For example, the model's
confidence in generating correct answers improves from 1.2 to 4.3. We introduce
patch-curves and random-feature patching baselines, showing that useful CoT
information is not only present in the top-K patches but widely distributed.
Overall, our results indicate that CoT can induce more interpretable internal
structures in high-capacity LLMs, validating its role as a structured prompting
method.

</details>


### [19] [EH-Benchmark Ophthalmic Hallucination Benchmark and Agent-Driven Top-Down Traceable Reasoning Workflow](https://arxiv.org/abs/2507.22929)
*Xiaoyu Pan,Yang Bai,Ke Zou,Yang Zhou,Jun Zhou,Huazhu Fu,Yih-Chung Tham,Yong Liu*

Main category: cs.CL

TL;DR: 本文介绍了EH-Benchmark，一个用于评估医学大语言模型幻觉的新眼科基准，并提出了一种多智能体框架来减少幻觉，提高诊断的准确性、可解释性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的医学基准无法有效评估各种类型的幻觉或提供缓解它们的可行解决方案。

Method: 我们提出了一种以代理为中心的三阶段框架，包括知识级检索阶段、任务级案例研究阶段和结果级验证阶段。

Result: 实验结果表明，我们的多智能体框架显著减少了两种类型的幻觉，提高了准确性、可解释性和可靠性。

Conclusion: 我们的多智能体框架显著减少了两种类型的幻觉，提高了准确性、可解释性和可靠性。

Abstract: Medical Large Language Models (MLLMs) play a crucial role in ophthalmic
diagnosis, holding significant potential to address vision-threatening
diseases. However, their accuracy is constrained by hallucinations stemming
from limited ophthalmic knowledge, insufficient visual localization and
reasoning capabilities, and a scarcity of multimodal ophthalmic data, which
collectively impede precise lesion detection and disease diagnosis.
Furthermore, existing medical benchmarks fail to effectively evaluate various
types of hallucinations or provide actionable solutions to mitigate them. To
address the above challenges, we introduce EH-Benchmark, a novel ophthalmology
benchmark designed to evaluate hallucinations in MLLMs. We categorize MLLMs'
hallucinations based on specific tasks and error types into two primary
classes: Visual Understanding and Logical Composition, each comprising multiple
subclasses. Given that MLLMs predominantly rely on language-based reasoning
rather than visual processing, we propose an agent-centric, three-phase
framework, including the Knowledge-Level Retrieval stage, the Task-Level Case
Studies stage, and the Result-Level Validation stage. Experimental results show
that our multi-agent framework significantly mitigates both types of
hallucinations, enhancing accuracy, interpretability, and reliability. Our
project is available at https://github.com/ppxy1/EH-Benchmark.

</details>


### [20] [Protecting Vulnerable Voices: Synthetic Dataset Generation for Self-Disclosure Detection](https://arxiv.org/abs/2507.22930)
*Shalini Jangra,Suparna De,Nishanth Sastry,Saeed Fadaei*

Main category: cs.CL

TL;DR: 本文提出了一种新的方法来创建合成的PII泄露数据，以促进可重复的研究。我们创建了一个包含19个PII泄露类别的分类法，并生成和发布了从三个大型语言模型生成的合成PII标记的多文本跨度数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的公开标注数据集缺乏，阻碍了对PII泄露文本检测的研究。为了促进可重复的研究，我们需要一种安全共享的合成数据集。

Method: 本文提出了一种新的方法来创建合成的PII泄露数据，以促进可重复的研究。我们使用三个大型语言模型（Llama2-7B、Llama3-8B和zephyr-7b-beta）生成合成数据，并通过顺序指令提示使其类似于原始Reddit帖子。

Result: 我们创建了一个包含19个PII泄露类别的分类法，并生成和发布了从三个大型语言模型生成的合成PII标记的多文本跨度数据集。我们的方法在可重复性、不可链接性和不可区分性方面进行了评估。

Conclusion: 本文提出了一种新的方法来创建合成的PII泄露数据，以促进可重复的研究。我们创建了一个包含19个PII泄露类别的分类法，并生成和发布了从三个大型语言模型生成的合成PII标记的多文本跨度数据集。我们的方法在可重复性、不可链接性和不可区分性方面进行了评估，并发布了数据集和代码以促进在线社交媒体中的PII隐私风险研究。

Abstract: Social platforms such as Reddit have a network of communities of shared
interests, with a prevalence of posts and comments from which one can infer
users' Personal Information Identifiers (PIIs). While such self-disclosures can
lead to rewarding social interactions, they pose privacy risks and the threat
of online harms. Research into the identification and retrieval of such risky
self-disclosures of PIIs is hampered by the lack of open-source labeled
datasets. To foster reproducible research into PII-revealing text detection, we
develop a novel methodology to create synthetic equivalents of PII-revealing
data that can be safely shared. Our contributions include creating a taxonomy
of 19 PII-revealing categories for vulnerable populations and the creation and
release of a synthetic PII-labeled multi-text span dataset generated from 3
text generation Large Language Models (LLMs), Llama2-7B, Llama3-8B, and
zephyr-7b-beta, with sequential instruction prompting to resemble the original
Reddit posts. The utility of our methodology to generate this synthetic dataset
is evaluated with three metrics: First, we require reproducibility equivalence,
i.e., results from training a model on the synthetic data should be comparable
to those obtained by training the same models on the original posts. Second, we
require that the synthetic data be unlinkable to the original users, through
common mechanisms such as Google Search. Third, we wish to ensure that the
synthetic data be indistinguishable from the original, i.e., trained humans
should not be able to tell them apart. We release our dataset and code at
https://netsys.surrey.ac.uk/datasets/synthetic-self-disclosure/ to foster
reproducible research into PII privacy risks in online social media.

</details>


### [21] [Enhancing RAG Efficiency with Adaptive Context Compression](https://arxiv.org/abs/2507.22931)
*Shuyu Guo,Zhaochun Ren*

Main category: cs.CL

TL;DR: ACC-RAG是一种自适应上下文压缩框架，能根据输入复杂度动态调整压缩率，在提升推理速度的同时保持或提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法应用固定的压缩率，导致简单查询过度压缩或复杂查询压缩不足，从而影响推理效率和准确性。

Method: 提出了一种自适应上下文压缩框架ACC-RAG，结合分层压缩器和上下文选择器，根据输入复杂度动态调整压缩率。

Result: 在Wikipedia和五个QA数据集上的评估显示，ACC-RAG优于固定率方法，并实现了超过4倍的推理速度提升。

Conclusion: ACC-RAG在保持或提高准确性的同时，显著提升了推理速度。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs)
with external knowledge but incurs significant inference costs due to lengthy
retrieved contexts. While context compression mitigates this issue, existing
methods apply fixed compression rates, over-compressing simple queries or
under-compressing complex ones. We propose Adaptive Context Compression for RAG
(ACC-RAG), a framework that dynamically adjusts compression rates based on
input complexity, optimizing inference efficiency without sacrificing accuracy.
ACC-RAG combines a hierarchical compressor (for multi-granular embeddings) with
a context selector to retain minimal sufficient information, akin to human
skimming. Evaluated on Wikipedia and five QA datasets, ACC-RAG outperforms
fixed-rate methods and matches/unlocks over 4 times faster inference versus
standard RAG while maintaining or improving accuracy.

</details>


### [22] [FinMarBa: A Market-Informed Dataset for Financial Sentiment Classification](https://arxiv.org/abs/2507.22932)
*Baptiste Lefort,Eric Benhamou,Beatrice Guez,Jean-Jacques Ohana,Ethan Setrouk,Alban Etienne*

Main category: cs.CL

TL;DR: 本文提出了一种分层框架，结合轻量级大型语言模型和深度强化学习，以提高投资组合优化的效果。该框架在实证测试中表现出色，优于传统基准。


<details>
  <summary>Details</summary>
Motivation: 为了提高投资组合优化的效果，结合情感信号和传统市场指标，同时提升系统的稳定性和可扩展性。

Method: 该论文提出了一种分层框架，结合轻量级大型语言模型（LLM）和深度强化学习（DRL），将金融新闻的情感信号与传统市场指标相结合。其三层架构包括基础RL代理、元代理和超级代理，分别处理混合数据、聚合决策和基于市场数据和情感分析的决策融合。

Result: 该框架在2018年至2024年的数据上实现了26%的年化收益率和1.2的夏普比率，优于均等加权和标普500基准。

Conclusion: 该框架在2018年至2024年的数据上表现出色，实现了26%的年化收益率和1.2的夏普比率，优于均等加权和标普500基准。

Abstract: This paper presents a novel hierarchical framework for portfolio
optimization, integrating lightweight Large Language Models (LLMs) with Deep
Reinforcement Learning (DRL) to combine sentiment signals from financial news
with traditional market indicators. Our three-tier architecture employs base RL
agents to process hybrid data, meta-agents to aggregate their decisions, and a
super-agent to merge decisions based on market data and sentiment analysis.
Evaluated on data from 2018 to 2024, after training on 2000-2017, the framework
achieves a 26% annualized return and a Sharpe ratio of 1.2, outperforming
equal-weighted and S&P 500 benchmarks. Key contributions include scalable
cross-modal integration, a hierarchical RL structure for enhanced stability,
and open-source reproducibility.

</details>


### [23] [Augmented Vision-Language Models: A Systematic Review](https://arxiv.org/abs/2507.22933)
*Anthony C Davis,Burhan Sadiq,Tianmin Shu,Chien-Ming Huang*

Main category: cs.CL

TL;DR: 本文综述了如何通过与外部符号信息系统的交互来改进视觉-语言模型的理解能力，强调了神经符号系统的优势。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言机器学习模型在解释输出、整合新信息和逻辑推理方面存在不足，因此需要一种更有效的解决方案。

Method: 本文采用系统文献综述的方法，对相关研究进行了分类和分析。

Result: 本文总结了多种通过与外部符号信息系统交互来提升视觉-语言理解的技术方法，并探讨了神经符号系统的潜在优势。

Conclusion: 本文综述了通过与外部符号信息系统的交互来改善视觉-语言理解的技术，强调了神经符号系统的优势，如可解释性、适应新信息的能力和推理能力。

Abstract: Recent advances in visual-language machine learning models have demonstrated
exceptional ability to use natural language and understand visual scenes by
training on large, unstructured datasets. However, this training paradigm
cannot produce interpretable explanations for its outputs, requires retraining
to integrate new information, is highly resource-intensive, and struggles with
certain forms of logical reasoning. One promising solution involves integrating
neural networks with external symbolic information systems, forming neural
symbolic systems that can enhance reasoning and memory abilities. These neural
symbolic systems provide more interpretable explanations to their outputs and
the capacity to assimilate new information without extensive retraining.
Utilizing powerful pre-trained Vision-Language Models (VLMs) as the core neural
component, augmented by external systems, offers a pragmatic approach to
realizing the benefits of neural-symbolic integration. This systematic
literature review aims to categorize techniques through which visual-language
understanding can be improved by interacting with external symbolic information
systems.

</details>


### [24] [Deep Learning Approaches for Multimodal Intent Recognition: A Survey](https://arxiv.org/abs/2507.22934)
*Jingwei Zhao,Yuhua Wen,Qifei Li,Minchi Hu,Yingying Zhou,Jingyao Xue,Junyang Wu,Yingming Gao,Zhengqi Wen,Jianhua Tao,Ya Li*

Main category: cs.CL

TL;DR: 本文综述了深度学习在多模态意图识别中的应用，包括技术演变、数据集、方法、应用和挑战，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着对自然人机交互需求的增长，意图识别领域通过深度学习和多模态方法得到了发展，结合了音频、视觉和生理信号等数据。

Method: 本文综述了深度学习方法在意图识别中的应用，涵盖了从单模态到多模态技术的转变、相关数据集、方法论、应用和当前挑战。

Result: 本文总结了多模态意图识别（MIR）的最新进展，并为研究人员提供了未来研究的方向。

Conclusion: 本文提供了关于多模态意图识别的最新发展和未来研究方向的见解。

Abstract: Intent recognition aims to identify users' underlying intentions,
traditionally focusing on text in natural language processing. With growing
demands for natural human-computer interaction, the field has evolved through
deep learning and multimodal approaches, incorporating data from audio, vision,
and physiological signals. Recently, the introduction of Transformer-based
models has led to notable breakthroughs in this domain. This article surveys
deep learning methods for intent recognition, covering the shift from unimodal
to multimodal techniques, relevant datasets, methodologies, applications, and
current challenges. It provides researchers with insights into the latest
developments in multimodal intent recognition (MIR) and directions for future
research.

</details>


### [25] [Trusted Knowledge Extraction for Operations and Maintenance Intelligence](https://arxiv.org/abs/2507.22935)
*Kathleen Mealey,Jonathan A. Karr Jr.,Priscila Saboia Moreira,Paul R. Brenner,Charles F. Vardeman II*

Main category: cs.CL

TL;DR: 本文探讨了如何从组织数据仓库中获取操作智能，分析了NLP和LLM工具的性能，并提出了改进可信工具的建议。


<details>
  <summary>Details</summary>
Motivation: 从组织数据仓库中获取操作智能是一个关键挑战，因为数据保密性与数据集成目标之间的二元性，以及自然语言处理（NLP）工具在特定领域知识结构方面的局限性。

Method: 我们讨论了知识图谱的构建，并将知识提取过程分解为命名实体识别、共指消解、命名实体链接和关系提取的功能组件。然后，我们评估了十六种NLP工具，并与大型语言模型（LLMs）的能力进行了比较。

Result: 我们发现NLP和LLM工具在零样本性能方面存在显著的限制，并讨论了可信NLP和LLM工具的技术成熟度水平。

Conclusion: 我们得出结论，需要改进可信的NLP和LLM工具，并提供了开源的经过整理的数据集以支持进一步的基准测试和评估。

Abstract: Deriving operational intelligence from organizational data repositories is a
key challenge due to the dichotomy of data confidentiality vs data integration
objectives, as well as the limitations of Natural Language Processing (NLP)
tools relative to the specific knowledge structure of domains such as
operations and maintenance. In this work, we discuss Knowledge Graph
construction and break down the Knowledge Extraction process into its Named
Entity Recognition, Coreference Resolution, Named Entity Linking, and Relation
Extraction functional components. We then evaluate sixteen NLP tools in concert
with or in comparison to the rapidly advancing capabilities of Large Language
Models (LLMs). We focus on the operational and maintenance intelligence use
case for trusted applications in the aircraft industry. A baseline dataset is
derived from a rich public domain US Federal Aviation Administration dataset
focused on equipment failures or maintenance requirements. We assess the
zero-shot performance of NLP and LLM tools that can be operated within a
controlled, confidential environment (no data is sent to third parties). Based
on our observation of significant performance limitations, we discuss the
challenges related to trusted NLP and LLM tools as well as their Technical
Readiness Level for wider use in mission-critical industries such as aviation.
We conclude with recommendations to enhance trust and provide our open-source
curated dataset to support further baseline testing and evaluation.

</details>


### [26] [Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis](https://arxiv.org/abs/2507.22936)
*Md Talha Mohsin*

Main category: cs.CL

TL;DR: 本研究对五种领先的LLMs进行了全面的比较评估，使用了'Magnificent Seven'科技公司的10-K文件。结果显示，GPT在回答的连贯性、语义对齐和上下文相关性方面表现最佳，其次是Claude和Perplexity。Gemini和DeepSeek则表现出更多的变异性且一致性较低。此外，输出的相似性和稳定性因公司而异，并随时间变化，表明它们对提示的编写方式和使用的源材料敏感。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在金融自然语言处理（FinNLP）任务中表现出色，但对广泛使用的LLMs进行系统比较的研究仍然不足。鉴于LLMs在金融分析中的快速发展和日益增长的影响，本研究旨在进行全面的比较评估。

Method: 本研究对五种领先的LLMs（GPT、Claude、Perplexity、Gemini和DeepSeek）进行了全面的比较评估，使用了'Magnificent Seven'科技公司的10-K文件。创建了一组领域特定的提示，并使用三种方法评估模型性能：人工标注、自动词法-语义度量（ROUGE、余弦相似度、Jaccard）以及模型行为诊断（提示级方差和跨模型相似性）。

Result: 结果表明，GPT提供了最连贯、语义对齐和上下文相关的答案；其次是Claude和Perplexity。Gemini和DeepSeek则表现出更多的变异性且一致性较低。此外，输出的相似性和稳定性因公司而异，并随时间变化，表明它们对提示的编写方式和使用的源材料敏感。

Conclusion: 研究发现，GPT在回答的连贯性、语义对齐和上下文相关性方面表现最佳；其次是Claude和Perplexity。Gemini和DeepSeek则表现出更多的变异性且一致性较低。此外，输出的相似性和稳定性因公司而异，并随时间变化，表明它们对提示的编写方式和使用的源材料敏感。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
a wide variety of Financial Natural Language Processing (FinNLP) tasks.
However, systematic comparisons among widely used LLMs remain underexplored.
Given the rapid advancement and growing influence of LLMs in financial
analysis, this study conducts a thorough comparative evaluation of five leading
LLMs, GPT, Claude, Perplexity, Gemini and DeepSeek, using 10-K filings from the
'Magnificent Seven' technology companies. We create a set of domain-specific
prompts and then use three methodologies to evaluate model performance: human
annotation, automated lexical-semantic metrics (ROUGE, Cosine Similarity,
Jaccard), and model behavior diagnostics (prompt-level variance and
across-model similarity). The results show that GPT gives the most coherent,
semantically aligned, and contextually relevant answers; followed by Claude and
Perplexity. Gemini and DeepSeek, on the other hand, have more variability and
less agreement. Also, the similarity and stability of outputs change from
company to company and over time, showing that they are sensitive to how
prompts are written and what source material is used.

</details>


### [27] [CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering](https://arxiv.org/abs/2507.22937)
*Jinkun Zhao,Yuanshuai Wang,Xingjian Zhang,Ruibo Chen,Xingchuang Liao,Junle Wang,Lei Huang,Kui Zhang,Wenjun Wu*

Main category: cs.CL

TL;DR: 本文提出了一种协作专家框架(CoE-Ops)，结合了一个通用的大语言模型任务分类器，并引入了检索增强生成机制，以提高框架在处理高、低层次AIOps任务的能力。实验结果表明，CoE-Ops在准确性方面优于现有方法和模型。


<details>
  <summary>Details</summary>
Motivation: 由于领域特定知识的限制，单一模型只能处理特定任务，而结合多个模型可以实现更高效的结果。因此，本文旨在通过协作专家框架来解决AIOps中的类似挑战。

Method: 本文提出了一种协作专家框架(CoE-Ops)，结合了一个通用的大语言模型任务分类器，并引入了检索增强生成机制，以提高框架在处理高层次和低层次AIOps任务的能力。

Result: 实验结果表明，CoE-Ops在高层次AIOps任务的路由准确性上比现有CoE方法提高了72%，在DevOps问题解决中比单一AIOps模型提高了高达8%的准确率，并且在准确性上超过了更大规模的Mixture-of-Experts (MoE)模型高达14%。

Conclusion: 本文提出的CoE-Ops方法在AIOps领域中表现出色，相较于现有的CoE方法、单一AIOps模型以及更大规模的Mixture-of-Experts (MoE)模型，在准确率上有显著提升。

Abstract: With the rapid evolution of artificial intelligence, AIOps has emerged as a
prominent paradigm in DevOps. Lots of work has been proposed to improve the
performance of different AIOps phases. However, constrained by domain-specific
knowledge, a single model can only handle the operation requirement of a
specific task,such as log parser,root cause analysis. Meanwhile, combining
multiple models can achieve more efficient results, which have been proved in
both previous ensemble learning and the recent LLM training domain. Inspired by
these works,to address the similar challenges in AIOPS, this paper first
proposes a collaboration-of-expert framework(CoE-Ops) incorporating a
general-purpose large language model task classifier. A retrieval-augmented
generation mechanism is introduced to improve the framework's capability in
handling both Question-Answering tasks with high-level(Code,build,Test,etc.)
and low-level(fault analysis,anomaly detection,etc.). Finally, the proposed
method is implemented in the AIOps domain, and extensive experiments are
conducted on the DevOps-EVAL dataset. Experimental results demonstrate that
CoE-Ops achieves a 72% improvement in routing accuracy for high-level AIOps
tasks compared to existing CoE methods, delivers up to 8% accuracy enhancement
over single AIOps models in DevOps problem resolution, and outperforms
larger-scale Mixture-of-Experts (MoE) models by up to 14% in accuracy.

</details>


### [28] [A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents](https://arxiv.org/abs/2507.22938)
*Sumit Soman,H. G. Ranjani,Sujoy Roychowdhury,Venkata Dharma Surya Narayana Sastry,Akshat Jain,Pranav Gangrade,Ayaaz Khan*

Main category: cs.CL

TL;DR: 本文提出了一种结合图表示和文本RAG系统的问答方法，用于电信领域的问题解答。该方法通过使用微调的VLM模型生成流程图的图表示，提高了问答性能，并减少了对VLM在推理中的需求。


<details>
  <summary>Details</summary>
Motivation: 问答（QA）从技术文档中经常涉及答案存在于图表中的问题，例如流程图或流程图。基于文本的检索增强生成（RAG）系统可能无法回答这些问题。

Method: 我们利用从视觉大语言模型（VLMs）获得的流程图的图表示，并将其整合到基于文本的RAG系统中，以展示这种方法可以实现电信领域的问答图像检索。

Result: 结果表明，使用微调的VLM模型获得的图表示与真实情况的编辑距离较低，这说明了这些表示对于流程图图像的鲁棒性。此外，使用这些表示的问答方法在使用基于文本的嵌入模型时表现出良好的检索性能，包括一个适应电信领域的模型。

Conclusion: 我们的方法减少了对VLM在推理中的需求，这对于部署的QA系统来说是一个重要的成本优势。

Abstract: Question-Answering (QA) from technical documents often involves questions
whose answers are present in figures, such as flowcharts or flow diagrams.
Text-based Retrieval Augmented Generation (RAG) systems may fail to answer such
questions. We leverage graph representations of flowcharts obtained from Visual
large Language Models (VLMs) and incorporate them in a text-based RAG system to
show that this approach can enable image retrieval for QA in the telecom
domain. We present the end-to-end approach from processing technical documents,
classifying image types, building graph representations, and incorporating them
with the text embedding pipeline for efficient retrieval. We benchmark the same
on a QA dataset created based on proprietary telecom product information
documents. Results show that the graph representations obtained using a
fine-tuned VLM model have lower edit distance with respect to the ground truth,
which illustrate the robustness of these representations for flowchart images.
Further, the approach for QA using these representations gives good retrieval
performance using text-based embedding models, including a telecom-domain
adapted one. Our approach also alleviates the need for a VLM in inference,
which is an important cost benefit for deployed QA systems.

</details>


### [29] [PARROT: An Open Multilingual Radiology Reports Dataset](https://arxiv.org/abs/2507.22939)
*Bastien Le Guellec,Kokou Adambounou,Lisa C Adams,Thibault Agripnidis,Sung Soo Ahn,Radhia Ait Chalal,Tugba Akinci D Antonoli,Philippe Amouyel,Henrik Andersson,Raphael Bentegeac,Claudio Benzoni,Antonino Andrea Blandino,Felix Busch,Elif Can,Riccardo Cau,Armando Ugo Cavallo,Christelle Chavihot,Erwin Chiquete,Renato Cuocolo,Eugen Divjak,Gordana Ivanac,Barbara Dziadkowiec Macek,Armel Elogne,Salvatore Claudio Fanni,Carlos Ferrarotti,Claudia Fossataro,Federica Fossataro,Katarzyna Fulek,Michal Fulek,Pawel Gac,Martyna Gachowska,Ignacio Garcia Juarez,Marco Gatti,Natalia Gorelik,Alexia Maria Goulianou,Aghiles Hamroun,Nicolas Herinirina,Krzysztof Kraik,Dominik Krupka,Quentin Holay,Felipe Kitamura,Michail E Klontzas,Anna Kompanowska,Rafal Kompanowski,Alexandre Lefevre,Tristan Lemke,Maximilian Lindholz,Lukas Muller,Piotr Macek,Marcus Makowski,Luigi Mannacio,Aymen Meddeb,Antonio Natale,Beatrice Nguema Edzang,Adriana Ojeda,Yae Won Park,Federica Piccione,Andrea Ponsiglione,Malgorzata Poreba,Rafal Poreba,Philipp Prucker,Jean Pierre Pruvo,Rosa Alba Pugliesi,Feno Hasina Rabemanorintsoa,Vasileios Rafailidis,Katarzyna Resler,Jan Rotkegel,Luca Saba,Ezann Siebert,Arnaldo Stanzione,Ali Fuat Tekin,Liz Toapanta Yanchapaxi,Matthaios Triantafyllou,Ekaterini Tsaoulia,Evangelia Vassalou,Federica Vernuccio,Johan Wasselius,Weilang Wang,Szymon Urban,Adrian Wlodarczak,Szymon Wlodarczak,Andrzej Wysocki,Lina Xu,Tomasz Zatonski,Shuhang Zhang,Sebastian Ziegelmayer,Gregory Kuchcinski,Keno K Bressem*

Main category: cs.CL

TL;DR: PARROT is a large, multicentric, open-access dataset of fictional radiology reports in multiple languages for testing natural language processing applications in radiology.


<details>
  <summary>Details</summary>
Motivation: To develop and validate PARROT (Polyglottal Annotated Radiology Reports for Open Testing), a large, multicentric, open-access dataset of fictional radiology reports spanning multiple languages for testing natural language processing applications in radiology.

Method: From May to September 2024, radiologists were invited to contribute fictional radiology reports following their standard reporting practices. Contributors provided at least 20 reports with associated metadata including anatomical region, imaging modality, clinical context, and for non-English reports, English translations. All reports were assigned ICD-10 codes. A human vs. AI report differentiation study was conducted with 154 participants (radiologists, healthcare professionals, and non-healthcare professionals) assessing whether reports were human-authored or AI-generated.

Result: The dataset comprises 2,658 radiology reports from 76 authors across 21 countries and 13 languages. Reports cover multiple imaging modalities (CT: 36.1%, MRI: 22.8%, radiography: 19.0%, ultrasound: 16.8%) and anatomical regions, with chest (19.9%), abdomen (18.6%), head (17.3%), and pelvis (14.1%) being most prevalent. In the differentiation study, participants achieved 53.9% accuracy (95% CI: 50.7%-57.1%) in distinguishing between human and AI-generated reports, with radiologists performing significantly better (56.9%, 95% CI: 53.3%-60.6%, p<0.05) than other groups.

Conclusion: PARROT represents the largest open multilingual radiology report dataset, enabling development and validation of natural language processing applications across linguistic, geographic, and clinical boundaries without privacy constraints.

Abstract: Rationale and Objectives: To develop and validate PARROT (Polyglottal
Annotated Radiology Reports for Open Testing), a large, multicentric,
open-access dataset of fictional radiology reports spanning multiple languages
for testing natural language processing applications in radiology. Materials
and Methods: From May to September 2024, radiologists were invited to
contribute fictional radiology reports following their standard reporting
practices. Contributors provided at least 20 reports with associated metadata
including anatomical region, imaging modality, clinical context, and for
non-English reports, English translations. All reports were assigned ICD-10
codes. A human vs. AI report differentiation study was conducted with 154
participants (radiologists, healthcare professionals, and non-healthcare
professionals) assessing whether reports were human-authored or AI-generated.
Results: The dataset comprises 2,658 radiology reports from 76 authors across
21 countries and 13 languages. Reports cover multiple imaging modalities (CT:
36.1%, MRI: 22.8%, radiography: 19.0%, ultrasound: 16.8%) and anatomical
regions, with chest (19.9%), abdomen (18.6%), head (17.3%), and pelvis (14.1%)
being most prevalent. In the differentiation study, participants achieved 53.9%
accuracy (95% CI: 50.7%-57.1%) in distinguishing between human and AI-generated
reports, with radiologists performing significantly better (56.9%, 95% CI:
53.3%-60.6%, p<0.05) than other groups. Conclusion: PARROT represents the
largest open multilingual radiology report dataset, enabling development and
validation of natural language processing applications across linguistic,
geographic, and clinical boundaries without privacy constraints.

</details>


### [30] [Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes](https://arxiv.org/abs/2507.22940)
*Rui Jiao,Yue Zhang,Jinku Li*

Main category: cs.CL

TL;DR: RELIANCE is a framework that addresses factual inaccuracies in LLMs by integrating a fact-checking classifier, a reinforcement learning approach, and an interpretability module, leading to significant improvements in factual robustness.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the critical vulnerability in Large Language Models (LLMs): the prevalence of factual inaccuracies within intermediate reasoning steps despite correct final answers, which poses substantial risks in high-stakes domains.

Method: RELIANCE integrates three core components: a specialized fact-checking classifier, a Group Relative Policy Optimization (GRPO) reinforcement learning approach, and a mechanistic interpretability module.

Result: Extensive evaluation across ten state-of-the-art models reveals concerning patterns, with even leading models like Claude-3.7 and GPT-o1 demonstrating reasoning factual accuracy of only 81.93% and 82.57% respectively. RELIANCE significantly enhances factual robustness (up to 49.90% improvement).

Conclusion: RELIANCE significantly enhances factual robustness while maintaining or improving performance on challenging benchmarks, and provides insights into how factual enhancements reshape reasoning trajectories within model architectures.

Abstract: We present RELIANCE (Reasoning Evaluation with Logical Integrity and Accuracy
for Confidence Enhancement), a novel framework addressing a critical
vulnerability in Large Language Models (LLMs): the prevalence of factual
inaccuracies within intermediate reasoning steps despite correct final answers.
This phenomenon poses substantial risks in high-stakes domains including
healthcare, legal analysis, and scientific research, where erroneous yet
confidently presented reasoning can mislead users into dangerous decisions. Our
framework integrates three core components: (1) a specialized fact-checking
classifier trained on counterfactually augmented data to detect subtle factual
inconsistencies within reasoning chains; (2) a Group Relative Policy
Optimization (GRPO) reinforcement learning approach that balances factuality,
coherence, and structural correctness through multi-dimensional rewards; and
(3) a mechanistic interpretability module examining how factuality improvements
manifest in model activations during reasoning processes. Extensive evaluation
across ten state-of-the-art models reveals concerning patterns: even leading
models like Claude-3.7 and GPT-o1 demonstrate reasoning factual accuracy of
only 81.93% and 82.57% respectively. RELIANCE significantly enhances factual
robustness (up to 49.90% improvement) while maintaining or improving
performance on challenging benchmarks including Math-500, AIME-2024, and GPQA.
Furthermore, our activation-level analysis provides actionable insights into
how factual enhancements reshape reasoning trajectories within model
architectures, establishing foundations for future training methodologies that
explicitly target factual robustness through activation-guided optimization.

</details>


### [31] [SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology](https://arxiv.org/abs/2507.22941)
*Paul Minchella,Loïc Verlingue,Stéphane Chrétien,Rémi Vaucher,Guillaume Metzler*

Main category: cs.CL

TL;DR: SigBERT is a temporal survival analysis framework that processes clinical reports to enhance risk estimation by capturing complex temporal dynamics through geometric features derived from sentence embeddings.


<details>
  <summary>Details</summary>
Motivation: Existing survival analysis methods often struggle to effectively handle the complexity of textual data, particularly in its sequential form.

Method: SigBERT processes timestamped medical reports by extracting and averaging word embeddings into sentence embeddings. It applies signature extraction from rough path theory to derive geometric features for each patient, which are then integrated into a LASSO-penalized Cox model to estimate patient-specific risk scores.

Result: The model was trained and evaluated on a real-world oncology dataset from the L'eon B'erard Center corpus, with a C-index score of 0.75 (sd 0.014) on the independent test cohort.

Conclusion: SigBERT integrates sequential medical data to enhance risk estimation, advancing narrative-based survival analysis.

Abstract: Electronic medical reports (EHR) contain a vast amount of information that
can be leveraged for machine learning applications in healthcare. However,
existing survival analysis methods often struggle to effectively handle the
complexity of textual data, particularly in its sequential form. Here, we
propose SigBERT, an innovative temporal survival analysis framework designed to
efficiently process a large number of clinical reports per patient. SigBERT
processes timestamped medical reports by extracting and averaging word
embeddings into sentence embeddings. To capture temporal dynamics from the time
series of sentence embedding coordinates, we apply signature extraction from
rough path theory to derive geometric features for each patient, which
significantly enhance survival model performance by capturing complex temporal
dynamics. These features are then integrated into a LASSO-penalized Cox model
to estimate patient-specific risk scores. The model was trained and evaluated
on a real-world oncology dataset from the L\'eon B\'erard Center corpus, with a
C-index score of 0.75 (sd 0.014) on the independent test cohort. SigBERT
integrates sequential medical data to enhance risk estimation, advancing
narrative-based survival analysis.

</details>


### [32] [A chart review process aided by natural language processing and multi-wave adaptive sampling to expedite validation of code-based algorithms for large database studies](https://arxiv.org/abs/2507.22943)
*Shirley V Wang,Georg Hahn,Sushama Kattinakere Sreedhara,Mufaddal Mahesri,Haritha S. Pillai,Rajendra Aldis,Joyce Lii,Sarah K. Dutcher,Rhoda Eniafe,Jamal T. Jones,Keewan Kim,Jiwei He,Hana Lee,Sengwee Toh,Rishi J Desai,Jie Yang*

Main category: cs.CL

TL;DR: 本文介绍了一种加快验证研究的方法，通过使用自然语言处理和多波适应性抽样方法，以减少时间和资源消耗，同时保持精度。


<details>
  <summary>Details</summary>
Motivation: 通过手动审查链接的电子健康记录中的自由文本笔记创建参考标准标签通常需要大量的时间和资源分配，因此需要一种更有效的方法来进行验证研究。

Method: 我们描述了一种加快验证研究的过程，使用两种不同的机制：1）使用自然语言处理（NLP）来减少人类评审员审查每张病历的时间，2）一种多波适应性抽样方法，具有预定义的标准，在性能特征被识别出足够精确时停止验证研究。

Result: 我们实证证明，NLP辅助的注释过程将每张病历的审查时间减少了40%，使用预定义的停止规则和多波样本可以防止审查77%的患者病历，而对推导出的测量特征的精度影响有限。

Conclusion: 这种方法可以促进对用于定义关键研究参数的代码基础算法的更常规验证，最终提高对从数据库研究中得出的发现的可靠性理解。

Abstract: Background: One of the ways to enhance analyses conducted with large claims
databases is by validating the measurement characteristics of code-based
algorithms used to identify health outcomes or other key study parameters of
interest. These metrics can be used in quantitative bias analyses to assess the
robustness of results for an inferential study given potential bias from
outcome misclassification. However, extensive time and resource allocation are
typically re-quired to create reference-standard labels through manual chart
review of free-text notes from linked electronic health records. Methods: We
describe an expedited process that introduces efficiency in a validation study
us-ing two distinct mechanisms: 1) use of natural language processing (NLP) to
reduce time spent by human reviewers to review each chart, and 2) a multi-wave
adaptive sampling approach with pre-defined criteria to stop the validation
study once performance characteristics are identified with sufficient
precision. We illustrate this process in a case study that validates the
performance of a claims-based outcome algorithm for intentional self-harm in
patients with obesity. Results: We empirically demonstrate that the
NLP-assisted annotation process reduced the time spent on review per chart by
40% and use of the pre-defined stopping rule with multi-wave samples would have
prevented review of 77% of patient charts with limited compromise to precision
in derived measurement characteristics. Conclusion: This approach could
facilitate more routine validation of code-based algorithms used to define key
study parameters, ultimately enhancing understanding of the reliability of
find-ings derived from database studies.

</details>


### [33] [Opacity as Authority: Arbitrariness and the Preclusion of Contestation](https://arxiv.org/abs/2507.22944)
*Naomi Omeonga wa Kayembe*

Main category: cs.CL

TL;DR: 本文重新定义了任意性，认为其是一种结构功能机制，用于分析法律、社会系统以及人工智能的可解释性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在重新定义任意性，将其视为一种结构功能机制，而非规范缺陷或统治的症候。

Method: 本文基于索绪尔的'符号任意性'概念，扩展了这一原则到法律和社会动态等领域，并引入了'Motivation -> Constatability -> Contestability'链来分析任意性的结构。

Result: 本文提出了一个现代的任意性理论，将其视为一种中性操作符，同时揭示了其在法律和社会系统中的应用，并为人工智能系统的可解释性分析提供了新路径。

Conclusion: 本文提出了一种新的关于任意性的理论，将其视为一种中性的操作符，对于控制和关怀都至关重要，并为分析先进人工智能系统的可解释性提供了新途径。

Abstract: This article redefines arbitrariness not as a normative flaw or a symptom of
domination, but as a foundational functional mechanism structuring human
systems and interactions. Diverging from critical traditions that conflate
arbitrariness with injustice, it posits arbitrariness as a semiotic trait: a
property enabling systems - linguistic, legal, or social - to operate
effectively while withholding their internal rationale. Building on Ferdinand
de Saussure's concept of l'arbitraire du signe, the analysis extends this
principle beyond language to demonstrate its cross-domain applicability,
particularly in law and social dynamics. The paper introduces the "Motivation
-> Constatability -> Contestability" chain, arguing that motivation functions
as a crucial interface rendering an act's logic vulnerable to intersubjective
contestation. When this chain is broken through mechanisms like
"immotivization" or "Conflict Lateralization" (exemplified by "the blur of the
wolf drowned in the fish"), acts produce binding effects without exposing their
rationale, thus precluding justiciability. This structural opacity, while
appearing illogical, is a deliberate design protecting authority from
accountability. Drawing on Shannon's entropy model, the paper formalizes
arbitrariness as A = H(L|M) (conditional entropy). It thereby proposes a modern
theory of arbitrariness as a neutral operator central to control as well as
care, an overlooked dimension of interpersonal relations. While primarily
developed through human social systems, this framework also illuminates a new
pathway for analyzing explainability in advanced artificial intelligence
systems.

</details>


### [34] [C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations](https://arxiv.org/abs/2507.22968)
*Chengqian Ma,Wei Tao,Yiwen Guo*

Main category: cs.CL

TL;DR: 本文介绍了针对语音对话模型的基准数据集和评估方法，旨在提升其在理解和模拟人类对话方面的性能。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对SDM在理解和模拟人类对话方面的实际效果的全面研究，尤其是在与文本型大型语言模型（LLMs）相比时。

Method: 本文提出了一种基于LLM的评估方法，该方法与人类判断紧密对齐，并构建了一个包含1,079个实例的基准数据集。

Result: 该数据集和评估方法有助于全面探索SDMs在应对这些实际挑战中的性能。

Conclusion: 本文提出了一个基准数据集，以阐明当前SDM的发展现状并解决这些挑战。

Abstract: Spoken Dialogue Models (SDMs) have recently attracted significant attention
for their ability to generate voice responses directly to users' spoken
queries. Despite their increasing popularity, there exists a gap in research
focused on comprehensively understanding their practical effectiveness in
comprehending and emulating human conversations. This is especially true
compared to text-based Large Language Models (LLMs), which benefit from
extensive benchmarking. Human voice interactions are inherently more complex
than text due to characteristics unique to spoken dialogue. Ambiguity poses one
challenge, stemming from semantic factors like polysemy, as well as
phonological aspects such as heterograph, heteronyms, and stress patterns.
Additionally, context-dependency, like omission, coreference, and multi-turn
interaction, adds further complexity to human conversational dynamics. To
illuminate the current state of SDM development and to address these
challenges, we present a benchmark dataset in this paper, which comprises 1,079
instances in English and Chinese. Accompanied by an LLM-based evaluation method
that closely aligns with human judgment, this dataset facilitates a
comprehensive exploration of the performance of SDMs in tackling these
practical challenges.

</details>


### [35] [Math Natural Language Inference: this should be easy!](https://arxiv.org/abs/2507.23063)
*Valeria de Paiva,Qiyue Gao,Hai Hu,Pavel Kovalev,Yikang Liu,Lawrence S. Moss,Zhiheng Qian*

Main category: cs.CL

TL;DR: This paper explores the ability of LLMs to perform NLI on mathematical texts, finding both positive and negative results, and provides a corpus for future research.


<details>
  <summary>Details</summary>
Motivation: To investigate whether contemporary LLMs can perform natural language inference (NLI) tasks on mathematical texts and assess the quality of corpora generated by LLMs.

Method: The study constructs a corpus of Math NLI pairs with human-labeled hypotheses and evaluates LLMs' performance and consistency, comparing them to human-labeled data.

Result: In some settings, using a majority vote of LLMs is approximately equivalent to using human-labeled data in the Math NLI area. However, LLMs still struggle with mathematical language and basic inferences.

Conclusion: LLMs show some capability in Math NLI tasks but still struggle with mathematical language and basic inferences. They are less prone to hypothesis-only 'inference' compared to previous generations.

Abstract: We ask whether contemporary LLMs are able to perform natural language
inference (NLI) tasks on mathematical texts. We call this the Math NLI problem.
We construct a corpus of Math NLI pairs whose premises are from extant
mathematical text and whose hypotheses and gold labels were provided by people
with experience in both research-level mathematics and also in the NLI field.
We also investigate the quality of corpora using the same premises but whose
hypotheses are provided by LLMs themselves. We not only investigate the
performance but also the inter-group consistency of the diverse group of LLMs.
We have both positive and negative findings. Among our positive findings: in
some settings, using a majority vote of LLMs is approximately equivalent to
using human-labeled data in the Math NLI area. On the negative side: LLMs still
struggle with mathematical language. They occasionally fail at even basic
inferences. Current models are not as prone to hypothesis-only "inference" in
our data the way the previous generation had been. In addition to our findings,
we also provide our corpora as data to support future work on Math NLI.

</details>


### [36] [Exploring In-Context Learning for Frame-Semantic Parsing](https://arxiv.org/abs/2507.23082)
*Diego Garat,Guillermo Moncecchi,Dina Wonsever*

Main category: cs.CL

TL;DR: 本文研究了使用In-Context Learning (ICL)与大型语言模型（LLMs）进行无需模型微调的Frame Semantic Parsing (FSP)。提出的方法通过自动生成特定任务的提示来完成Frame Identification (FI)和Frame Semantic Role Labeling (FSRL)子任务，并在与暴力事件相关的框架子集上取得了有竞争力的结果。研究结果表明，ICL为特定领域的FSP任务提供了一种实用且有效的传统微调替代方案。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索使用In-Context Learning (ICL)与大型语言模型（LLMs）进行无需模型微调的Frame Semantic Parsing (FSP)。

Method: 本文提出了一种方法，该方法自动为Frame Identification (FI)和Frame Semantic Role Labeling (FSRL)子任务生成特定于任务的提示，仅依赖于FrameNet数据库。这些提示由框架定义和注释示例构建，并用于指导六种不同的LLM。

Result: 在与暴力事件相关的框架子集上进行的实验取得了有竞争力的结果，FI的F1得分为94.3%，FSRL的F1得分为77.4%。

Conclusion: 研究结果表明，ICL为特定领域的FSP任务提供了一种实用且有效的传统微调替代方案。

Abstract: Frame Semantic Parsing (FSP) entails identifying predicates and labeling
their arguments according to Frame Semantics. This paper investigates the use
of In-Context Learning (ICL) with Large Language Models (LLMs) to perform FSP
without model fine-tuning. We propose a method that automatically generates
task-specific prompts for the Frame Identification (FI) and Frame Semantic Role
Labeling (FSRL) subtasks, relying solely on the FrameNet database. These
prompts, constructed from frame definitions and annotated examples, are used to
guide six different LLMs. Experiments are conducted on a subset of frames
related to violent events. The method achieves competitive results, with F1
scores of 94.3% for FI and 77.4% for FSRL. The findings suggest that ICL offers
a practical and effective alternative to traditional fine-tuning for
domain-specific FSP tasks.

</details>


### [37] [Context-aware Rotary Position Embedding](https://arxiv.org/abs/2507.23083)
*Ali Veisi,Delaram Fartoot,Hamidreza Amirzadeh*

Main category: cs.CL

TL;DR: CARoPE is a novel generalization of RoPE that dynamically generates head-specific frequency patterns conditioned on token embeddings, improving performance and efficiency in Transformer models.


<details>
  <summary>Details</summary>
Motivation: RoPE relies on static, input-independent sinusoidal frequency patterns, limiting its ability to model context-sensitive relationships. CARoPE aims to address this limitation by introducing token- and context-sensitive positional representations while preserving RoPE efficiency and architectural simplicity.

Method: CARoPE dynamically generates head-specific frequency patterns conditioned on token embeddings, using a bounded transformation of token embeddings to compute input-dependent phase shifts integrated into the rotary mechanism across attention heads.

Result: CARoPE consistently outperforms RoPE and other common positional encoding baselines, achieving significantly lower perplexity, even at longer context lengths. Additionally, CARoPE enables faster training throughput without sacrificing model stability.

Conclusion: CARoPE offers a scalable, expressive, and efficient upgrade to existing positional encoding strategies in Transformer models.

Abstract: Positional encoding is a vital component of Transformer architectures,
enabling models to incorporate sequence order into self-attention mechanisms.
Rotary Positional Embeddings (RoPE) have become a widely adopted solution due
to their compatibility with relative position encoding and computational
efficiency. However, RoPE relies on static, input-independent sinusoidal
frequency patterns, limiting its ability to model context-sensitive
relationships. In this work, we propose CARoPE (Context-Aware Rotary Positional
Embedding), a novel generalization of RoPE that dynamically generates
head-specific frequency patterns conditioned on token embeddings. This design
introduces token- and context-sensitive positional representations while
preserving RoPE efficiency and architectural simplicity. CARoPE computes
input-dependent phase shifts using a bounded transformation of token embeddings
and integrates them into the rotary mechanism across attention heads. We
evaluate CARoPE on the FineWeb-Edu-10B dataset using GPT-2 variants trained on
next-token prediction tasks. Experimental results show that CARoPE consistently
outperforms RoPE and other common positional encoding baselines, achieving
significantly lower perplexity, even at longer context lengths. Additionally,
CARoPE enables faster training throughput without sacrificing model stability.
These findings demonstrate that CARoPE offers a scalable, expressive, and
efficient upgrade to existing positional encoding strategies in Transformer
models.

</details>


### [38] [SMART-Editor: A Multi-Agent Framework for Human-Like Design Editing with Structural Integrity](https://arxiv.org/abs/2507.23095)
*Ishani Mondal,Meera Bharadwaj,Ayush Roy,Aparna Garimella,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: SMART-Editor是一种用于跨结构化和非结构化领域布局和内容编辑的框架，通过奖励引导的方法提升了全局连贯性，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有模型主要进行局部编辑，而SMART-Editor旨在通过保留全局连贯性来改进跨结构化和非结构化领域的布局和内容编辑。

Method: SMART-Editor采用了两种策略：Reward-Refine（一种推理时的奖励引导优化方法）和RewardDPO（一种使用奖励对齐布局对的训练时偏好优化方法）。

Result: SMART-Editor在SMARTEdit-Bench基准测试中优于InstructPix2Pix和HIVE等强基线模型，在结构化设置中RewardDPO实现了高达15%的提升，而Reward-Refine在自然图像上表现出优势。

Conclusion: SMART-Editor在结构化和非结构化领域中表现出色，证明了基于奖励的规划在生成语义一致和视觉对齐编辑中的价值。

Abstract: We present SMART-Editor, a framework for compositional layout and content
editing across structured (posters, websites) and unstructured (natural images)
domains. Unlike prior models that perform local edits, SMART-Editor preserves
global coherence through two strategies: Reward-Refine, an inference-time
rewardguided refinement method, and RewardDPO, a training-time preference
optimization approach using reward-aligned layout pairs. To evaluate model
performance, we introduce SMARTEdit-Bench, a benchmark covering multi-domain,
cascading edit scenarios. SMART-Editor outperforms strong baselines like
InstructPix2Pix and HIVE, with RewardDPO achieving up to 15% gains in
structured settings and Reward-Refine showing advantages on natural images.
Automatic and human evaluations confirm the value of reward-guided planning in
producing semantically consistent and visually aligned edits.

</details>


### [39] [RASL: Retrieval Augmented Schema Linking for Massive Database Text-to-SQL](https://arxiv.org/abs/2507.23104)
*Jeffrey Eben,Aitzaz Ahmad,Stephen Lau*

Main category: cs.CL

TL;DR: 本文提出了一种基于组件的检索架构，通过分解数据库模式和元数据为离散的语义单元，实现了高效的文本到SQL系统，无需专门微调即可在各种企业环境中部署。


<details>
  <summary>Details</summary>
Motivation: 现有的工作依赖于领域特定的微调，这使得部署复杂化，并且未能利用数据库元数据中的重要语义上下文。

Method: 我们引入了一种基于组件的检索架构，将数据库模式和元数据分解为离散的语义单元，并分别进行索引以实现有针对性的检索。

Result: 实验表明，我们的方法保持了高召回率和准确性，在具有不同结构和可用元数据的大型数据库上，我们的系统优于基线方法。

Conclusion: 我们的解决方案能够在不需要专门微调的情况下，在各种企业环境中部署实用的文本到SQL系统，解决了自然语言数据库接口中的关键可扩展性差距。

Abstract: Despite advances in large language model (LLM)-based natural language
interfaces for databases, scaling to enterprise-level data catalogs remains an
under-explored challenge. Prior works addressing this challenge rely on
domain-specific fine-tuning - complicating deployment - and fail to leverage
important semantic context contained within database metadata. To address these
limitations, we introduce a component-based retrieval architecture that
decomposes database schemas and metadata into discrete semantic units, each
separately indexed for targeted retrieval. Our approach prioritizes effective
table identification while leveraging column-level information, ensuring the
total number of retrieved tables remains within a manageable context budget.
Experiments demonstrate that our method maintains high recall and accuracy,
with our system outperforming baselines over massive databases with varying
structure and available metadata. Our solution enables practical text-to-SQL
systems deployable across diverse enterprise settings without specialized
fine-tuning, addressing a critical scalability gap in natural language database
interfaces.

</details>


### [40] [Uncovering the Fragility of Trustworthy LLMs through Chinese Textual Ambiguity](https://arxiv.org/abs/2507.23121)
*Xinwei Wu,Haojie Li,Hongyu Liu,Xinyu Ji,Ruohan Li,Yule Chen,Yigeng Zhang*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型在处理中文模糊文本时的表现，发现它们在处理语言歧义方面存在显著缺陷，并提出了一个基准数据集以促进未来的研究。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在遇到模糊叙述文本时的行为，特别是中文文本的模糊性，以了解其在现实世界应用中的可靠性问题。

Method: 我们通过收集和生成带有上下文的模糊句子及其对应的消歧对，创建了一个基准数据集，并系统地将其分为3个主要类别和9个子类别。

Result: 实验发现大型语言模型在处理模糊性时表现出显著的脆弱性，行为与人类有显著差异，包括无法可靠地区分模糊文本和非模糊文本、在解释模糊文本时过于自信、以及在尝试理解各种可能含义时表现出过度思考。

Conclusion: 我们的研究揭示了当前大型语言模型在处理语言歧义方面的根本性局限，这对其在现实世界应用中的部署具有重要意义，并呼吁改进处理语言理解中不确定性的方法。

Abstract: In this work, we study a critical research problem regarding the
trustworthiness of large language models (LLMs): how LLMs behave when
encountering ambiguous narrative text, with a particular focus on Chinese
textual ambiguity. We created a benchmark dataset by collecting and generating
ambiguous sentences with context and their corresponding disambiguated pairs,
representing multiple possible interpretations. These annotated examples are
systematically categorized into 3 main categories and 9 subcategories. Through
experiments, we discovered significant fragility in LLMs when handling
ambiguity, revealing behavior that differs substantially from humans.
Specifically, LLMs cannot reliably distinguish ambiguous text from unambiguous
text, show overconfidence in interpreting ambiguous text as having a single
meaning rather than multiple meanings, and exhibit overthinking when attempting
to understand the various possible meanings. Our findings highlight a
fundamental limitation in current LLMs that has significant implications for
their deployment in real-world applications where linguistic ambiguity is
common, calling for improved approaches to handle uncertainty in language
understanding. The dataset and code are publicly available at this GitHub
repository: https://github.com/ictup/LLM-Chinese-Textual-Disambiguation.

</details>


### [41] [ISO-Bench: Benchmarking Multimodal Causal Reasoning in Visual-Language Models through Procedural Plans](https://arxiv.org/abs/2507.23135)
*Ananya Sadana,Yash Kumar Lal,Jiawei Zhou*

Main category: cs.CL

TL;DR: 本文介绍了一个名为ISO-Bench的基准，用于评估模型是否能推断视觉观察与程序文本之间的因果关系。评估结果显示当前模型表现不佳，远低于人类水平，并指出了改进的方向。


<details>
  <summary>Details</summary>
Motivation: 理解跨模态的因果关系是多模态模型在现实环境中操作的核心挑战。

Method: 我们引入了ISO-Bench，这是一个评估模型能否推断视觉观察和程序文本之间因果依赖关系的基准。

Result: 对十种前沿视觉-语言模型的评估结果显示出令人失望的表现：最好的零样本F1仅为0.57，链式思维推理仅带来适度的提升（最高0.62 F1），远低于人类（0.98 F1）。

Conclusion: 我们的分析进一步指出了改进多模态模型因果理解的具体方向。

Abstract: Understanding causal relationships across modalities is a core challenge for
multimodal models operating in real-world environments. We introduce ISO-Bench,
a benchmark for evaluating whether models can infer causal dependencies between
visual observations and procedural text. Each example presents an image of a
task step and a text snippet from a plan, with the goal of deciding whether the
visual step occurs before or after the referenced text step. Evaluation results
on ten frontier vision-language models show underwhelming performance: the best
zero-shot F1 is only 0.57, and chain-of-thought reasoning yields only modest
gains (up to 0.62 F1), largely behind humans (0.98 F1). Our analysis further
highlights concrete directions for improving causal understanding in multimodal
models.

</details>


### [42] [User Feedback in Human-LLM Dialogues: A Lens to Understand Users But Noisy as a Learning Signal](https://arxiv.org/abs/2507.23158)
*Yuhan Liu,Michael J. Q. Zhang,Eunsol Choi*

Main category: cs.CL

TL;DR: 本文研究了从用户-语言模型交互日志中提取隐式用户反馈的效果，发现反馈内容比极性更能提升模型性能，但效果受限于用户初始提示的质量。


<details>
  <summary>Details</summary>
Motivation: 用户反馈可以提高模型性能，但直接请求反馈可能具有干扰性，因此研究如何从交互日志中提取隐式反馈。

Method: 本文研究了从用户-语言模型交互日志中提取隐式用户反馈，并分析了用户反馈在不同场景下的效果。

Result: 研究发现，用户反馈的内容（如用户想要澄清）可以提高模型在简短问题上的性能，但在长而复杂的问题上效果不佳。此外，用户反馈的有用性与用户初始提示的质量密切相关。

Conclusion: 本文对隐式用户反馈进行了深入研究，展示了其潜力和局限性。

Abstract: Once language models (LMs) are deployed, they can interact with users
long-term, ideally evolving continuously based on their feedback. Asking for
direct user feedback can be disruptive; thus, we study harvesting user feedback
from user-LM interaction logs. We study implicit user feedback in two user-LM
interaction datasets (WildChat and LMSYS). First, we analyze user feedback in
the user-LLM conversation trajectory, providing insights into when and why such
feedback occurs. Second, we study harvesting learning signals from such
implicit user feedback. We find that the contents of user feedback (e.g., user
wanted clarification), not just the polarity (e.g., users were unhappy with the
previous model response), can improve model performance in short human-designed
questions (MTBench) but not on longer and more complex questions (WildBench).
We also find that the usefulness of user feedback is largely tied to the
quality of the user's initial prompt. Together, we provide an in-depth study of
implicit user feedback, showing its potential and limitations.

</details>


### [43] [LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration](https://arxiv.org/abs/2507.23167)
*Jizhou Guo*

Main category: cs.CL

TL;DR: 本文提出了一种名为LENS的新方法，通过分析内部表示来学习估计模型置信度。实验结果表明，LENS在多项选择和布尔问答任务上显著优于传统的集成方法。


<details>
  <summary>Details</summary>
Motivation: 有效结合多个LLM的预测对于提高系统鲁棒性和性能至关重要。然而，现有的集成方法通常依赖于简单的技术，如投票或logits集成，这忽略了模型在不同上下文中不同的置信度和可靠性。

Method: 我们提出了一种名为LENS的新方法，该方法通过分析内部表示来学习估计模型置信度。对于每个LLM，我们训练了一个轻量级的线性置信度预测器，该预测器利用逐层隐藏状态和归一化概率作为输入。

Result: 实验结果表明，LENS在多项选择和布尔问答任务上显著优于传统的集成方法。

Conclusion: 我们的研究结果表明，内部表示提供了确定模型置信度的有价值信号，并可以有效地用于集成学习。

Abstract: Large Language Models (LLMs) have demonstrated impressive performance across
various tasks, with different models excelling in distinct domains and specific
abilities. Effectively combining the predictions of multiple LLMs is crucial
for enhancing system robustness and performance. However, existing ensemble
methods often rely on simple techniques like voting or logits ensembling, which
overlook the varying confidence and reliability of models in different
contexts. In this work, we propose LENS (Learning ENsemble confidence from
Neural States), a novel approach that learns to estimate model confidence by
analyzing internal representations. For each LLM, we train a lightweight linear
confidence predictor that leverages layer-wise hidden states and normalized
probabilities as inputs. This allows for more nuanced weighting of model
predictions based on their context-dependent reliability. Our method does not
require modifying the model parameters and requires negligible additional
computation. Experimental results on multiple-choice and boolean
question-answering tasks demonstrate that LENS outperforms traditional ensemble
methods by a substantial margin. Our findings suggest that internal
representations provide valuable signals for determining model confidence and
can be effectively leveraged for ensemble learning.

</details>


### [44] [Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks](https://arxiv.org/abs/2507.23194)
*Jianghui Wang,Vinay Joshi,Saptarshi Majumder,Xu Chao,Bin Ding,Ziqiong Liu,Pratik Prabhanjan Brahma,Dong Li,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: GEAK is a framework that uses cutting-edge LLMs to generate performant Triton code for AMD GPUs, showing significant improvements over existing methods.


<details>
  <summary>Details</summary>
Motivation: The demand for AI-generated GPU kernels is rapidly growing, influenced by the need for scalable, hardware-optimized solutions in both industry and academia. As deep learning workloads grow in complexity and diversity, it is imperative to automate low-level kernel development to meet performance and productivity demands.

Method: GEAK leverages inference-time compute scaling to produce Triton-based GPU kernels using a reasoning loop adapted from Reflexion-style feedback mechanisms.

Result: On two evaluation benchmarks, GEAK significantly outperformed the baselines of directly prompting frontier LLMs as well as Reflexion-based generation pipelines by achieving correctness up to 63% and execution speed up of up to 2.59X.

Conclusion: GEAK-like agentic code generation shows promise for accelerating the adoption of diverse hardware platforms and democratizing access to expert-level kernel performance.

Abstract: The demand for AI-generated GPU kernels is rapidly growing, influenced by the
need for scalable, hardware-optimized solutions in both industry and academia.
As deep learning workloads grow in complexity and diversity, it is imperative
to automate low-level kernel development to meet performance and productivity
demands. Major cloud providers, semiconductor companies, and research
institutions are now investing heavily in AI-driven code generation for GPUs,
aiming to reduce manual optimization efforts while achieving near-expert
performance on hardware like AMD MI300X. The Triton language, a Python-based
DSL for GPU programming, has emerged as a popular target for such AI-generated
kernels due to its balance of performance and ease-of-coding. In this work, we
present an evaluation suite for Triton-based GPU kernels and GEAK (Generating
Efficient AI-centric GPU Kernels)-a framework that leverages cutting-edge LLMs
to generate performant Triton code specifically for AMD GPUs, including the AMD
MI300X and MI250. GEAK leverages inference-time compute scaling to produce
Triton-based GPU kernels using a reasoning loop adapted from Reflexion-style
feedback mechanisms. On two evaluation benchmarks, GEAK significantly
outperformed the baselines of directly prompting frontier LLMs as well as
Reflexion-based generation pipelines by achieving correctness up to $63$% and
execution speed up of up to $2.59$X. These results highlight the promise of
GEAK-like agentic code generation for accelerating the adoption of diverse
hardware platforms and democratizing access to expert-level kernel performance.

</details>


### [45] [Failures Are the Stepping Stones to Success: Enhancing Few-Shot In-Context Learning by Leveraging Negative Samples](https://arxiv.org/abs/2507.23211)
*Yunhao Liang,Ruixuan Ying,Takuya Taniguchi,Zhe Cui*

Main category: cs.CL

TL;DR: 本文提出了一种新方法，利用负例来更好地选择正例，从而提高少样本ICL的性能。通过构建正负例语料库，并基于语义相似性选择示例，实验结果证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 最近的研究主要集中在利用正例，而忽视了负例中的额外信息对于上下文学习的潜在价值。

Method: 我们首先基于Zero-Shot-Cot构建正例和负例语料库。然后，在推理过程中，我们采用基于语义相似性的方法从正例和负例语料库中选择与给定查询最相似的示例。接着，我们进一步从正例语料库中根据与负例的语义相似性检索正例，然后将它们与之前选择的正例拼接起来作为ICL演示。

Result: 实验结果表明，我们的方法优于仅依赖最相似正例的方法，验证了负例中的额外信息通过改进正例选择来增强ICL性能。

Conclusion: 实验结果表明，我们的方法优于仅依赖最相似正例的方法，验证了负例中的额外信息通过改进正例选择来增强ICL性能。

Abstract: Large Language Models exhibit powerful few-shot in-context learning (ICL)
capabilities, but the performance is highly sensitive to provided examples.
  Recent research has focused on retrieving corresponding examples for each
input query, not only enhancing the efficiency and scalability of the learning
process but also mitigating inherent biases in manual example selection.
  However, these studies have primarily emphasized leveraging Positive samples
while overlooking the additional information within Negative samples for
contextual learning.
  We propose a novel method that utilizes Negative samples to better select
Positive sample examples, thereby enhancing the performance of few-shot ICL.
Initially, we construct Positive and Negative sample corpora based on
Zero-Shot-Cot. Then, during inference, we employ a semantic similarity-based
approach to select the most similar examples from both the Positive and
Negative corpora for a given query. Subsequently, we further retrieve Positive
examples from the Positive sample corpus based on semantic similarity to the
Negative examples, then concatenating them with the previously selected
Positive examples to serve as ICL demonstrations. Experimental results
demonstrate that our approach surpasses methods solely relying on the most
similar positive examples for context, validating that the additional
information in negative samples aids in enhancing ICL performance through
improved Positive sample selection.

</details>


### [46] [Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders](https://arxiv.org/abs/2507.23220)
*Carolina Zheng,Nicolas Beltran-Velez,Sweta Karlekar,Claudia Shi,Achille Nazaret,Asif Mallik,Amir Feder,David M. Blei*

Main category: cs.CL

TL;DR: 本文介绍了机制主题模型(MTMs)，它利用稀疏自编码器学习的可解释特征来定义主题，从而揭示更深层次的概念主题，并支持基于主题的可控文本生成。在多个数据集上，MTMs表现优于传统和神经基线。


<details>
  <summary>Details</summary>
Motivation: 传统主题模型依赖于词袋表示，难以捕捉语义抽象特征。虽然一些神经变体使用了更丰富的表示，但它们同样受限于将主题表示为词列表，这限制了它们表达复杂主题的能力。

Method: 引入了机制主题模型(MTMs)，这是一种基于稀疏自编码器(SAEs)学习的可解释特征的主题模型。通过在语义丰富的空间上定义主题，MTMs可以揭示更深层次的概念主题。此外，MTMs可以通过基于主题的引导向量进行可控文本生成。

Result: 在五个数据集上，MTMs在连贯性指标上与传统和神经基线相当或超越，并且始终受到主题法官的青睐，能够有效引导LLM输出。

Conclusion: MTMs可以揭示更深层次的概念主题，并且能够通过基于主题的引导向量进行可控文本生成。在五个数据集上，MTMs在连贯性指标上与传统和神经基线相当或超越，并且始终受到主题法官的青睐，能够有效引导LLM输出。

Abstract: Traditional topic models are effective at uncovering latent themes in large
text collections. However, due to their reliance on bag-of-words
representations, they struggle to capture semantically abstract features. While
some neural variants use richer representations, they are similarly constrained
by expressing topics as word lists, which limits their ability to articulate
complex topics. We introduce Mechanistic Topic Models (MTMs), a class of topic
models that operate on interpretable features learned by sparse autoencoders
(SAEs). By defining topics over this semantically rich space, MTMs can reveal
deeper conceptual themes with expressive feature descriptions. Moreover,
uniquely among topic models, MTMs enable controllable text generation using
topic-based steering vectors. To properly evaluate MTM topics against
word-list-based approaches, we propose \textit{topic judge}, an LLM-based
pairwise comparison evaluation framework. Across five datasets, MTMs match or
exceed traditional and neural baselines on coherence metrics, are consistently
preferred by topic judge, and enable effective steering of LLM outputs.

</details>


### [47] [Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs](https://arxiv.org/abs/2507.23227)
*Sophie Kearney,Shu Yang,Zixuan Wen,Bojian Hou,Duy Duong-Tran,Tianlong Chen,Jason Moore,Marylyn Ritchie,Li Shen*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Early and accurate diagnosis of Alzheimer's disease (AD), a complex
neurodegenerative disorder, requires analysis of heterogeneous biomarkers
(e.g., neuroimaging, genetic risk factors, cognitive tests, and cerebrospinal
fluid proteins) typically represented in a tabular format. With flexible
few-shot reasoning, multimodal integration, and natural-language-based
interpretability, large language models (LLMs) offer unprecedented
opportunities for prediction with structured biomedical data. We propose a
novel framework called TAP-GPT, Tabular Alzheimer's Prediction GPT, that adapts
TableGPT2, a multimodal tabular-specialized LLM originally developed for
business intelligence tasks, for AD diagnosis using structured biomarker data
with small sample sizes. Our approach constructs few-shot tabular prompts using
in-context learning examples from structured biomedical data and finetunes
TableGPT2 using the parameter-efficient qLoRA adaption for a clinical binary
classification task of AD or cognitively normal (CN). The TAP-GPT framework
harnesses the powerful tabular understanding ability of TableGPT2 and the
encoded prior knowledge of LLMs to outperform more advanced general-purpose
LLMs and a tabular foundation model (TFM) developed for prediction tasks. To
our knowledge, this is the first application of LLMs to the prediction task
using tabular biomarker data, paving the way for future LLM-driven multi-agent
frameworks in biomedical informatics.

</details>


### [48] [P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication](https://arxiv.org/abs/2507.23247)
*Sneha Oram,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型在心理健康领域的实用推理能力，并提出了一个新的数据集和任务来评估这些模型。结果表明，某些模型在处理心理健康相关任务时表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管最近在可解释性和个性化心理健康聊天机器人的开发方面取得了进展，但解释性和对话话语方面的推理方面尚未被探索。因此，我们正在研究大型语言模型（LLMs）在这一领域的实用推理能力。

Method: 引入了P-ReMe数据集，并提出了对心理健康的语用现象（暗示和预设）的修改定义。根据定义，制定了两个暗示任务和一个预设任务。考虑了四个模型（Llama3.1、Mistral、MentaLLaMa和Qwen）进行基准测试。还提出了StiPRompts来研究心理健康污名，并评估了GPT-4o mini、Deepseek-chat和Claude-3.5-haiku的表现。

Result: 实验结果表明，Mistral和Qwen在该领域表现出显著的推理能力。此外，Claude-3.5-haiku在处理心理健康污名方面比其他两个LLM更负责任。

Conclusion: 研究结果表明，Mistral和Qwen在心理健康领域表现出显著的推理能力。此外，Claude-3.5-haiku在处理心理健康污名方面比其他两个LLM更负责任。

Abstract: There has been an increase in recent advancements in the explainability and
development of personalized chatbots for mental health. However, the reasoning
aspects for explainability and dialogue discourse have not been explored
previously for mental health. Hence, we are investigating the pragmatic
reasoning capability of large language models (LLMs) in this domain. We
introduce P-ReMe dataset, and propose a modified definition for the pragmatic
phenomena of implicature (implied meaning) and presupposition (implicit
assumption) in mental health. Following the definition, we formulate two tasks
in implicature and one task in presupposition. To benchmark the dataset and the
presented tasks, we consider four models - Llama3.1, Mistral, MentaLLaMa, and
Qwen. The results of the experiments suggest that Mistral and Qwen show
substantial reasoning capabilities in the domain. In addition, we also propose
StiPRompts to study the stigma around mental health with the state-of-the-art
LLMs, GPT-4o mini, Deepseek-chat, and Claude-3.5-haiku. Our evaluated findings
show that Claude-3.5-haiku deals with the stigma more responsibly compared to
the other two LLMs.

</details>


### [49] [Evaluating LLMs' Multilingual Capabilities for Bengali: Benchmark Creation and Performance Analysis](https://arxiv.org/abs/2507.23248)
*Shimanto Bhowmik,Tawsif Tashwar Dipto,Md Sazzad Islam,Sheryl Hsu,Tahsin Reasat*

Main category: cs.CL

TL;DR: 本研究分析了 Bengali 语言在 NLP 中的挑战，评估了多个大型语言模型的表现，并发现了分词效率与模型准确性之间的关系。研究强调了改进数据集质量和评估方法的重要性，以促进对资源匮乏语言的研究。


<details>
  <summary>Details</summary>
Motivation: Bengali 是 NLP 研究中资源匮乏的语言，由于其独特的语言结构和计算限制，仍然面临挑战。缺乏标准化评估基准是影响性能的关键因素。

Method: 本研究系统地调查了阻碍 Bengali NLP 性能的挑战，重点是缺乏标准化评估基准。然后评估了 10 个最近的开源大型语言模型 (LLMs) 在 8 个翻译数据集上的表现，并进行了全面的错误分析以确定其主要失败模式。

Result: 研究结果表明，与英语相比，Bengali 表现出一致的性能差距，特别是对于小型模型和特定模型家族如 Mistral。同时，某些架构如 DeepSeek 展现出了良好的鲁棒性，能够在多种语言中保持更稳定的性能。此外，发现分词效率与 LLM 准确性之间存在反比关系。

Conclusion: 本研究揭示了当前模型在 Bengali 语言上的不足，并强调了改进数据集质量和评估方法的必要性。这项工作将促进对资源匮乏语言 NLP 的进一步研究，有助于在全球范围内普及先进的语言技术。

Abstract: Bengali is an underrepresented language in NLP research. However, it remains
a challenge due to its unique linguistic structure and computational
constraints. In this work, we systematically investigate the challenges that
hinder Bengali NLP performance by focusing on the absence of standardized
evaluation benchmarks. We then evaluated 10 recent open source Large Language
Models (LLMs) in 8 of the translated datasets and performed a comprehensive
error analysis to pinpoint their primary failure modes. Our findings reveal
consistent performance gaps for Bengali compared to English, particularly for
smaller models and specific model families like Mistral. We also identified
promising robustness in certain architectures, such as DeepSeek, that maintain
more stable performance across languages. Our analysis reveals an inverse
relationship between tokenization efficiency and LLM accuracy where models tend
to perform worse when inputs are excessively tokenized, whereas more efficient
\& concise tokenization results in improved performance. These findings
highlight critical areas where current models fall short and underscore the
need for improved dataset quality and evaluation methodologies tailored to
multilingual contexts. This work will catalyze further research on NLP for
underrepresented languages, helping to democratize access to advanced language
technologies worldwide. The code and dataset used in this research is publicly
available at https://github.com/BengaliAI/bn-llm-benchmark.

</details>


### [50] [Unveiling Super Experts in Mixture-of-Experts Large Language Models](https://arxiv.org/abs/2507.23279)
*Zunhai Su,Qingyuan Li,Hao Zhang,YuLei Qian,Yuchen Xie,Kehong Yuan*

Main category: cs.CL

TL;DR: 本文首次发现并研究了在 MoE LLMs 中起关键作用的 Super Experts (SEs)，揭示了它们在模型性能中的重要性以及修剪它们对模型的影响。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖经验标准来识别关键专家，缺乏对专家异质性重要性的深入探索。本文旨在揭示 SEs 的作用及其对模型性能的影响。

Method: 通过分析 SEs 在模型前向推理中的作用，研究者发现了 SEs 的特征，并通过修剪 SEs 来评估其对模型性能的影响。

Result: SEs 在开放源码 MoE LLMs 中普遍存在，尽管数量有限，但修剪它们会导致模型性能显著下降，例如修剪三个 SEs 会导致 Qwen3-30B-A3B 产生重复和无信息的输出。

Conclusion: 研究发现，MoE LLMs 依赖 Super Experts (SEs) 来诱导注意力焦点，这对于注意力分数的分布至关重要，但 SEs 的修剪会显著破坏这一过程。

Abstract: Sparsely activated Mixture-of-Experts (MoE) models have shown promise in
enhancing the learning capacity of large language models (LLMs). Leveraging the
intrinsic importance differences among experts, recent research has explored
expert-level compression techniques to improve the efficiency of MoE LLMs.
However, existing approaches often rely on empirical criteria to identify
critical experts, lacking a deeper exploration and understanding of the
heterogeneous importance of experts. In this study, we present the first
discovery and investigation of a distinct subset of experts that play a crucial
role in the underlying mechanisms during the model's forward inference. These
experts are prevalent in open-source MoE LLMs, and despite their limited
number, pruning them leads to a significant decline in model performance (e.g.,
pruning three causes Qwen3-30B-A3B to produce repetitive and uninformative
outputs). We refer to these experts as Super Experts (SEs). Our comprehensive
analysis provides progressively deeper insights into SEs. (i) SEs are
characterized by rare but extreme activation outliers in the output of the
down_proj, which give rise to massive activations in the hidden states between
decoder layers. Moreover, the distribution of SEs remains model-specific and is
unaffected by post-training processes. (ii) By pruning SEs, we assess their
significance across a variety of tasks, revealing their considerable impact on
the model's overall performance, particularly in mathematical reasoning. (iii)
We further enhance our understanding of the influence of SEs compression. Our
findings confirm that MoE LLMs rely on SEs to induce attention sinks, which are
crucial for the distribution of attention scores but are significantly
disrupted by SE pruning. The code is available at
https://github.com/ZunhaiSu/Super-Experts-Profilling.

</details>


### [51] [What's Taboo for You? - An Empirical Evaluation of LLMs Behavior Toward Sensitive Content](https://arxiv.org/abs/2507.23319)
*Alfio Ferrara,Sergio Picascia,Laura Pinnavaia,Vojimir Ranitovic,Elisabetta Rocchetti,Alice Tuveri*

Main category: cs.CL

TL;DR: 本研究分析了GPT-4o-mini在改写敏感内容时的隐式调节行为，发现其能够显著减少侮辱性和禁忌语言。同时，评估了LLMs在零样本分类句子敏感性方面的能力，并与传统方法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 尽管之前的研究主要集中在显式训练模型来调节和净化敏感内容，但很少有研究探讨LLMs是否在没有明确指令的情况下隐式净化语言。本研究旨在填补这一空白，探索LLMs在隐式调节敏感内容方面的潜力。

Method: 本研究通过实验分析了GPT-4o-mini在改写敏感内容时的隐式调节行为，并评估了敏感性变化的程度。同时，还评估了LLMs在零样本分类句子敏感性方面的能力，并将其性能与传统方法进行比较。

Result: 实验结果表明，GPT-4o-mini在改写敏感内容时会系统性地将其转向更不敏感的类别，显著减少了侮辱性和禁忌语言。此外，LLMs在零样本分类句子敏感性方面表现出色，与传统方法相比具有竞争力。

Conclusion: 研究发现GPT-4o-mini在改写敏感内容时会系统性地将内容转向更不敏感的类别，显著减少了侮辱性和禁忌语言。此外，研究还评估了LLMs在零样本分类句子敏感性方面的表现，并与传统方法进行了比较。

Abstract: Proprietary Large Language Models (LLMs) have shown tendencies toward
politeness, formality, and implicit content moderation. While previous research
has primarily focused on explicitly training models to moderate and detoxify
sensitive content, there has been limited exploration of whether LLMs
implicitly sanitize language without explicit instructions. This study
empirically analyzes the implicit moderation behavior of GPT-4o-mini when
paraphrasing sensitive content and evaluates the extent of sensitivity shifts.
Our experiments indicate that GPT-4o-mini systematically moderates content
toward less sensitive classes, with substantial reductions in derogatory and
taboo language. Also, we evaluate the zero-shot capabilities of LLMs in
classifying sentence sensitivity, comparing their performances against
traditional methods.

</details>


### [52] [MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation](https://arxiv.org/abs/2507.23334)
*Daeyong Kwon,SeungHeon Doh,Juhan Nam*

Main category: cs.CL

TL;DR: 本文提出了一种基于检索增强生成（RAG）的框架MusT-RAG，用于将通用大语言模型（LLM）适应于文本音乐问答（MQA）任务。通过构建专门的音乐向量数据库MusWikiDB，并在推理和微调过程中利用上下文信息，MusT-RAG在音乐领域适应能力上显著优于传统微调方法，并且MusWikiDB比通用维基百科语料库更有效。


<details>
  <summary>Details</summary>
Motivation: LLMs' effectiveness in music-related applications remains limited due to the relatively small proportion of music-specific knowledge in their training data.

Method: We propose MusT-RAG, a comprehensive framework based on Retrieval Augmented Generation (RAG) to adapt general-purpose LLMs for text-only music question answering (MQA) tasks. To optimize RAG for the music domain, we (1) propose MusWikiDB, a music-specialized vector database for the retrieval stage, and (2) utilize context information during both inference and fine-tuning processes to effectively transform general-purpose LLMs into music-specific models.

Result: Our experiment demonstrates that MusT-RAG significantly outperforms traditional fine-tuning approaches in enhancing LLMs' music domain adaptation capabilities, showing consistent improvements across both in-domain and out-of-domain MQA benchmarks. Additionally, our MusWikiDB proves substantially more effective than general Wikipedia corpora, delivering superior performance and computational efficiency.

Conclusion: MusT-RAG significantly outperforms traditional fine-tuning approaches in enhancing LLMs' music domain adaptation capabilities, showing consistent improvements across both in-domain and out-of-domain MQA benchmarks. Additionally, our MusWikiDB proves substantially more effective than general Wikipedia corpora, delivering superior performance and computational efficiency.

Abstract: Recent advancements in Large language models (LLMs) have demonstrated
remarkable capabilities across diverse domains. While they exhibit strong
zero-shot performance on various tasks, LLMs' effectiveness in music-related
applications remains limited due to the relatively small proportion of
music-specific knowledge in their training data. To address this limitation, we
propose MusT-RAG, a comprehensive framework based on Retrieval Augmented
Generation (RAG) to adapt general-purpose LLMs for text-only music question
answering (MQA) tasks. RAG is a technique that provides external knowledge to
LLMs by retrieving relevant context information when generating answers to
questions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a
music-specialized vector database for the retrieval stage, and (2) utilizes
context information during both inference and fine-tuning processes to
effectively transform general-purpose LLMs into music-specific models. Our
experiment demonstrates that MusT-RAG significantly outperforms traditional
fine-tuning approaches in enhancing LLMs' music domain adaptation capabilities,
showing consistent improvements across both in-domain and out-of-domain MQA
benchmarks. Additionally, our MusWikiDB proves substantially more effective
than general Wikipedia corpora, delivering superior performance and
computational efficiency.

</details>


### [53] [Text-to-SQL Task-oriented Dialogue Ontology Construction](https://arxiv.org/abs/2507.23358)
*Renato Vukovic,Carel van Niekerk,Michael Heck,Benjamin Ruppik,Hsien-Chin Lin,Shutong Feng,Nurul Lubis,Milica Gasic*

Main category: cs.CL

TL;DR: TeQoDO 是一种无需监督的构建任务导向对话本体的方法，利用大型语言模型的 SQL 编程能力和对话理论，提高了可解释性并展示了其在更大本体构建中的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的任务导向对话系统依赖于外部数据库和显式本体，但构建这些本体需要手动标签或监督训练。为了提高可解释性和可控性，需要一种无需监督的方法来构建本体。

Method: TeQoDO 方法利用大型语言模型的内在 SQL 编程能力结合对话理论，在没有监督的情况下自主构建任务导向对话本体。

Result: TeQoDO 在下游对话状态跟踪任务中表现优于迁移学习方法，并且能够构建更大的本体，在维基百科和 ArXiv 数据集上进行了验证。

Conclusion: TeQoDO 是一种无需监督即可构建任务导向对话本体的方法，展示了其在下游对话状态跟踪任务中的竞争力，并且可以扩展到构建更大的本体，为提高大型语言模型的可解释性提供了一种途径。

Abstract: Large language models (LLMs) are widely used as general-purpose knowledge
sources, but they rely on parametric knowledge, limiting explainability and
trustworthiness. In task-oriented dialogue (TOD) systems, this separation is
explicit, using an external database structured by an explicit ontology to
ensure explainability and controllability. However, building such ontologies
requires manual labels or supervised training. We introduce TeQoDO: a
Text-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM
autonomously builds a TOD ontology from scratch without supervision using its
inherent SQL programming capabilities combined with dialogue theory provided in
the prompt. We show that TeQoDO outperforms transfer learning approaches, and
its constructed ontology is competitive on a downstream dialogue state tracking
task. Ablation studies demonstrate the key role of dialogue theory. TeQoDO also
scales to allow construction of much larger ontologies, which we investigate on
a Wikipedia and ArXiv dataset. We view this as a step towards broader
application of ontologies to increase LLM explainability.

</details>


### [54] [MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models](https://arxiv.org/abs/2507.23382)
*Yiyan Ji,Haoran Chen,Qiguang Chen,Chengyue Wu,Libo Qin,Wanxiang Che*

Main category: cs.CL

TL;DR: 本文提出了MPCC基准，用于评估多模态大语言模型在处理多约束场景下的规划能力，并揭示了当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的基准无法直接评估多模态现实规划能力，且缺乏跨模态的约束或隐式约束，因此需要一个新的评估框架来解决这些问题。

Method: 本文引入了MPCC基准，通过三个现实任务（航班规划、日历规划和会议规划）以及不同难度级别的复杂约束来评估多模态大语言模型的能力。

Result: 实验显示，闭源模型仅能生成21.3%的可行计划，而开源模型平均低于11%。此外，多模态大语言模型对约束复杂性高度敏感，传统多模态提示策略在多约束场景中失效。

Conclusion: 本文提出了一个评估多模态约束下规划能力的基准MPCC，并展示了当前多模态大语言模型在处理多约束场景中的挑战，强调了需要改进约束感知推理的重要性。

Abstract: Multimodal planning capabilities refer to the ability to predict, reason, and
design steps for task execution with multimodal context, which is essential for
complex reasoning and decision-making across multiple steps. However, current
benchmarks face two key challenges: (1) they cannot directly assess multimodal
real-world planning capabilities, and (2) they lack constraints or implicit
constraints across modalities. To address these issues, we introduce Multimodal
Planning with Complex Constraints (MPCC), the first benchmark to systematically
evaluate MLLMs' ability to handle multimodal constraints in planning. To
address the first challenge, MPCC focuses on three real-world tasks: Flight
Planning, Calendar Planning, and Meeting Planning. To solve the second
challenge, we introduce complex constraints (e.g. budget, temporal, and
spatial) in these tasks, with graded difficulty levels (EASY, MEDIUM, HARD) to
separate constraint complexity from search space expansion. Experiments on 13
advanced MLLMs reveal significant challenges: closed-source models achieve only
21.3% feasible plans, while open-source models average below 11%. Additionally,
we observe that MLLMs are highly sensitive to constraint complexity and that
traditional multimodal prompting strategies fail in multi-constraint scenarios.
Our work formalizes multimodal constraints in planning, provides a rigorous
evaluation framework, and highlights the need for advancements in
constraint-aware reasoning for real-world MLLM applications.

</details>


### [55] [Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models](https://arxiv.org/abs/2507.23386)
*Ailiang Lin,Zhuoyun Li,Kotaro Funakoshi*

Main category: cs.CL

TL;DR: Causal2Vec是一种通用的嵌入模型，旨在增强解码器-only LLMs的性能，而无需更改其原始架构或引入显著的计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要关注移除LLM中的因果注意力掩码以实现双向注意力，这可能削弱模型在预训练期间获得的语义信息提取能力。此外，领先的单向方法通常依赖于额外的输入文本来克服因果注意力的固有局限性，从而增加了计算成本。

Method: Causal2Vec采用了一个轻量级的BERT风格模型来预编码输入文本为单个上下文标记，并将其附加到LLM的输入序列中，以允许每个标记捕获上下文信息。此外，为了减轻最后标记池引入的近期偏差，将上下文标记和EOS标记的最后隐藏状态进行拼接作为最终文本嵌入。

Result: Causal2Vec在MTEB上实现了最先进的性能，同时减少了所需的序列长度和推理时间。

Conclusion: Causal2Vec在仅使用公开检索数据集训练的模型中，在MTEB上实现了最先进的性能，同时减少了所需的序列长度和推理时间。

Abstract: Decoder-only large language models (LLMs) are increasingly used to build
embedding models that effectively encode the semantic information of natural
language texts into dense vector representations for various embedding tasks.
However, many existing methods primarily focus on removing the causal attention
mask in LLMs to enable bidirectional attention, potentially undermining the
model's ability to extract semantic information acquired during pretraining.
Additionally, leading unidirectional approaches often rely on extra input text
to overcome the inherent limitations of causal attention, inevitably increasing
computational costs. In this work, we propose Causal2Vec, a general-purpose
embedding model tailored to enhance the performance of decoder-only LLMs
without altering their original architectures or introducing significant
computational overhead. Specifically, we first employ a lightweight BERT-style
model to pre-encode the input text into a single Contextual token, which is
then prepended to the LLM's input sequence, allowing each token to capture
contextualized information even without attending to future tokens.
Furthermore, to mitigate the recency bias introduced by last-token pooling and
help LLMs better leverage the semantic information encoded in the Contextual
token, we concatenate the last hidden states of Contextual and EOS tokens as
the final text embedding. In practice, Causal2Vec achieves state-of-the-art
performance on the Massive Text Embeddings Benchmark (MTEB) among models
trained solely on publicly available retrieval datasets, while reducing the
required sequence length by up to 85% and inference time by up to 82% compared
to best-performing methods.

</details>


### [56] [Beyond the Cloud: Assessing the Benefits and Drawbacks of Local LLM Deployment for Translators](https://arxiv.org/abs/2507.23399)
*Peter Sandrini*

Main category: cs.CL

TL;DR: 本研究探讨了本地部署的开源语言模型作为商业云服务的可行替代方案，评估了其功能性能，并强调了其在数据控制、隐私保护和减少云服务依赖方面的优势。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的迅速普及，翻译领域面临机遇和挑战。虽然商业云服务AI聊天机器人引起了广泛关注，但数据隐私、安全性和公平访问的问题需要探索替代的部署模式。因此，本研究旨在探讨本地可部署的免费语言模型作为商业云服务的可行替代方案。

Method: 本研究评估了三种安装在基于CPU的平台上的开源语言模型，并将其与商用在线聊天机器人进行了比较。评估重点在于功能性能，而非人机翻译质量的比较分析。

Result: 研究发现，本地部署的开源语言模型在功能性能方面表现良好，尽管存在自身的挑战，但其在数据控制、隐私保护和减少对云服务依赖方面的优势是显著的。

Conclusion: 本研究的结论表明，本地部署的开源语言模型在功能性能方面可以作为商业云服务的可行替代方案。研究强调了增强数据控制、提高隐私性和减少对云服务的依赖等优势，为人工智能技术的民主化做出了贡献，并为未来的研究和开发提供了方向，特别是针对个人翻译者和小企业的需求。

Abstract: The rapid proliferation of Large Language Models presents both opportunities
and challenges for the translation field. While commercial, cloud-based AI
chatbots have garnered significant attention in translation studies, concerns
regarding data privacy, security, and equitable access necessitate exploration
of alternative deployment models. This paper investigates the feasibility and
performance of locally deployable, free language models as a viable alternative
to proprietary, cloud-based AI solutions. This study evaluates three
open-source models installed on CPU-based platforms and compared against
commercially available online chat-bots. The evaluation focuses on functional
performance rather than a comparative analysis of human-machine translation
quality, an area already subject to extensive research. The platforms assessed
were chosen for their accessibility and ease of use across various operating
systems. While local deployment introduces its own challenges, the benefits of
enhanced data control, improved privacy, and reduced dependency on cloud
services are compelling. The findings of this study contribute to a growing
body of knowledge concerning the democratization of AI technology and inform
future research and development efforts aimed at making LLMs more accessible
and practical for a wider range of users, specifically focusing on the needs of
individual translators and small businesses.

</details>


### [57] [MRGSEM-Sum: An Unsupervised Multi-document Summarization Framework based on Multi-Relational Graphs and Structural Entropy Minimization](https://arxiv.org/abs/2507.23400)
*Yongbing Zhang,Fang Nan,Shengxiang Gao,Yuxin Huang,Kaiwen Tan,Zhengtao Yu*

Main category: cs.CL

TL;DR: 提出一种基于多关系图和结构熵最小化的无监督多文档摘要框架MRGSEM-Sum，能够自动确定最佳聚类数并生成高质量摘要。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只考虑单关系图并需要预定义聚类数量，这限制了它们全面表示丰富关系信息和自适应划分句子组的能力。

Method: 提出了一种基于多关系图和结构熵最小化的无监督多文档摘要框架MRGSEM-Sum。构建了一个整合语义和话语关系的多关系图，并应用二维结构熵最小化算法进行聚类，最后引入位置感知压缩机制生成摘要。

Result: 在四个基准数据集（Multi-News、DUC-2004、PubMed和WikiSum）上的实验表明，该方法优于之前的无监督方法，在某些情况下性能可与监督模型和大语言模型相媲美。人类评估显示生成的摘要具有高一致性与覆盖度。

Conclusion: MRGSEM-Sum在多个基准数据集上表现出色，生成的摘要具有高一致性与覆盖度，接近人类水平。

Abstract: The core challenge faced by multi-document summarization is the complexity of
relationships among documents and the presence of information redundancy. Graph
clustering is an effective paradigm for addressing this issue, as it models the
complex relationships among documents using graph structures and reduces
information redundancy through clustering, achieving significant research
progress. However, existing methods often only consider single-relational
graphs and require a predefined number of clusters, which hinders their ability
to fully represent rich relational information and adaptively partition
sentence groups to reduce redundancy. To overcome these limitations, we propose
MRGSEM-Sum, an unsupervised multi-document summarization framework based on
multi-relational graphs and structural entropy minimization. Specifically, we
construct a multi-relational graph that integrates semantic and discourse
relations between sentences, comprehensively modeling the intricate and dynamic
connections among sentences across documents. We then apply a two-dimensional
structural entropy minimization algorithm for clustering, automatically
determining the optimal number of clusters and effectively organizing sentences
into coherent groups. Finally, we introduce a position-aware compression
mechanism to distill each cluster, generating concise and informative
summaries. Extensive experiments on four benchmark datasets (Multi-News,
DUC-2004, PubMed, and WikiSum) demonstrate that our approach consistently
outperforms previous unsupervised methods and, in several cases, achieves
performance comparable to supervised models and large language models. Human
evaluation demonstrates that the summaries generated by MRGSEM-Sum exhibit high
consistency and coverage, approaching human-level quality.

</details>


### [58] [Enhanced Arabic Text Retrieval with Attentive Relevance Scoring](https://arxiv.org/abs/2507.23404)
*Salah Eddine Bekhouche,Azeddine Benlamoudi,Yazid Bounab,Fadi Dornaika,Abdenour Hadid*

Main category: cs.CL

TL;DR: 本文提出了一种增强的密集段落检索（DPR）框架，专门针对阿拉伯语。核心是一种新颖的注意相关性评分（ARS），它用自适应评分函数替代了标准的交互机制，更有效地建模问题和段落之间的语义相关性。该方法结合了预训练的阿拉伯语语言模型和架构改进，提高了检索性能，并显著提高了回答阿拉伯语问题的排名准确性。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语由于其复杂的形态、可选的变音符号以及现代标准阿拉伯语（MSA）和各种方言共存，对自然语言处理（NLP）和信息检索（IR）提出了特殊的挑战。尽管阿拉伯语在全球的重要性日益增加，但在NLP研究和基准资源中仍处于欠代表状态。

Method: 本文提出了一种增强的密集段落检索（DPR）框架，专门针对阿拉伯语。核心是一种新颖的注意相关性评分（ARS），它用自适应评分函数替代了标准的交互机制，更有效地建模问题和段落之间的语义相关性。该方法结合了预训练的阿拉伯语语言模型和架构改进，提高了检索性能，并显著提高了回答阿拉伯语问题的排名准确性。

Result: 本文提出的增强的密集段落检索（DPR）框架在阿拉伯语任务中表现出色，通过引入注意相关性评分（ARS）和预训练的阿拉伯语语言模型，显著提高了检索性能和排名准确性。

Conclusion: 本文提出了一种增强的密集段落检索（DPR）框架，专门针对阿拉伯语。核心是一种新颖的注意相关性评分（ARS），它用自适应评分函数替代了标准的交互机制，更有效地建模问题和段落之间的语义相关性。该方法结合了预训练的阿拉伯语语言模型和架构改进，提高了检索性能，并显著提高了回答阿拉伯语问题的排名准确性。

Abstract: Arabic poses a particular challenge for natural language processing (NLP) and
information retrieval (IR) due to its complex morphology, optional diacritics
and the coexistence of Modern Standard Arabic (MSA) and various dialects.
Despite the growing global significance of Arabic, it is still underrepresented
in NLP research and benchmark resources. In this paper, we present an enhanced
Dense Passage Retrieval (DPR) framework developed specifically for Arabic. At
the core of our approach is a novel Attentive Relevance Scoring (ARS) that
replaces standard interaction mechanisms with an adaptive scoring function that
more effectively models the semantic relevance between questions and passages.
Our method integrates pre-trained Arabic language models and architectural
refinements to improve retrieval performance and significantly increase ranking
accuracy when answering Arabic questions. The code is made publicly available
at \href{https://github.com/Bekhouche/APR}{GitHub}.

</details>


### [59] [Beyond Passive Critical Thinking: Fostering Proactive Questioning to Enhance Human-AI Collaboration](https://arxiv.org/abs/2507.23407)
*Ante Wang,Yujie Lin,Jingyao Liu,Suhang Wu,Hao Liu,Xinyan Xiao,Jinsong Su*

Main category: cs.CL

TL;DR: 本文介绍了主动批判性思维的概念，并提出了新的基准来评估模型在不完整或误导条件下的数学推理能力。实验显示，强化学习可以显著提升模型在这方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的研究主要集中在被动批判性思维上，而主动批判性思维能够更好地解决用户的问题，因此需要进行研究。

Method: 本文引入了主动批判性思维的概念，并提出了两个新的基准GSM-MC和GSM-MCE来评估数学推理能力。此外，还使用强化学习算法提升了模型的能力。

Result: 实验表明，尽管这些模型在传统推理任务中表现出色，但在主动批判性思维方面存在困难。然而，通过强化学习可以显著提高这一能力。

Conclusion: 本文希望推动通过主动批判性思维更有效地与用户协作解决问题的模型发展。

Abstract: Critical thinking is essential for building robust AI systems, preventing
them from blindly accepting flawed data or biased reasoning. However, prior
work has primarily focused on passive critical thinking, where models simply
reject problematic queries without taking constructive steps to address user
requests. In this work, we introduce proactive critical thinking, a paradigm
where models actively seek missing or clarifying information from users to
resolve their queries better. To evaluate this capability, we present GSM-MC
and GSM-MCE, two novel benchmarks based on GSM8K for assessing mathematical
reasoning under incomplete or misleading conditions. GSM-MC contains 1,368 math
problems with a key variable deliberately removed, requiring models to identify
and request the missing information. GSM-MCE further increases the difficulty
by introducing irrelevant details to test robustness against distractions.
Experiments on Qwen3 and Llama series models show that, while these models
excel in traditional reasoning tasks due to extensive post-training and
inference-time scaling, they struggle with proactive critical thinking,
especially smaller ones. However, we demonstrate that reinforcement learning
(RL) can significantly improve this ability. Using our enhanced RL algorithm,
we achieve substantial gains, boosting the Qwen3-1.7B's accuracy from 0.15% to
73.98% on GSM-MC. We hope this work advances models that collaborate more
effectively with users in problem-solving through proactive critical thinking.

</details>


### [60] [Role-Aware Language Models for Secure and Contextualized Access Control in Organizations](https://arxiv.org/abs/2507.23465)
*Saeed Almheiri,Yerulan Kongrat,Adrian Santosh,Ruslan Tasmukhanov,Josemaria Vera,Muhammad Dehan Al Kautsar,Fajri Koto*

Main category: cs.CL

TL;DR: 本文研究了如何通过微调大型语言模型（LLMs）来生成符合不同组织角色访问权限的响应，并提出了三种建模策略。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在企业环境中的广泛应用，根据用户角色控制模型行为变得至关重要。现有的安全方法通常假设统一的访问权限，并专注于防止有害或有毒的输出，而没有解决特定角色的访问限制问题。

Method: 本文探讨了三种建模策略：基于BERT的分类器、基于LLM的分类器和角色条件生成。此外，还构建了两个互补的数据集来评估这些方法。

Result: 本文评估了模型在不同组织结构下的性能，并分析了对提示注入、角色不匹配和越狱尝试的鲁棒性。

Conclusion: 本文结论是，通过微调大型语言模型（LLMs）可以生成反映不同组织角色访问权限的响应。

Abstract: As large language models (LLMs) are increasingly deployed in enterprise
settings, controlling model behavior based on user roles becomes an essential
requirement. Existing safety methods typically assume uniform access and focus
on preventing harmful or toxic outputs, without addressing role-specific access
constraints. In this work, we investigate whether LLMs can be fine-tuned to
generate responses that reflect the access privileges associated with different
organizational roles. We explore three modeling strategies: a BERT-based
classifier, an LLM-based classifier, and role-conditioned generation. To
evaluate these approaches, we construct two complementary datasets. The first
is adapted from existing instruction-tuning corpora through clustering and role
labeling, while the second is synthetically generated to reflect realistic,
role-sensitive enterprise scenarios. We assess model performance across varying
organizational structures and analyze robustness to prompt injection, role
mismatch, and jailbreak attempts.

</details>


### [61] [A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains](https://arxiv.org/abs/2507.23486)
*Shirui Wang,Zhihui Tang,Huaxia Yang,Qiuhong Gong,Tiantian Gu,Hongyang Ma,Yongxin Wang,Wubin Sun,Zeliang Lian,Kehang Mao,Yinan Jiang,Zhicheng Huang,Lingyun Ma,Wenjie Shen,Yajie Ji,Yunhui Tan,Chunbo Wang,Yunlu Gao,Qianling Ye,Rui Lin,Mingyu Chen,Lijuan Niu,Zhihao Wang,Peng Yu,Mengran Lang,Yue Liu,Huimin Zhang,Haitao Shen,Long Chen,Qiguang Zhao,Si-Xuan Liu,Lina Zhou,Hua Gao,Dongqiang Ye,Lingmin Meng,Youtao Yu,Naixin Liang,Jianxiong Wu*

Main category: cs.CL

TL;DR: 本研究开发了临床安全-效果双轨基准（CSEDB），用于评估医疗大语言模型的安全性和有效性。测试结果显示大语言模型在临床应用中存在一定的性能问题，特别是高风险场景下的表现较差。领域特定的医疗大语言模型在安全性和有效性方面表现更好。研究结果有助于推动大语言模型在医疗环境中的更安全和有效的部署。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在临床决策支持中具有潜力，但在安全评估和效果验证方面面临重大挑战。需要一种标准化的评估方法来促进比较分析、风险暴露识别和改进方向的确定。

Method: 我们开发了临床安全-效果双轨基准（CSEDB），这是一个基于临床专家共识的多维框架，包含30个涵盖关键领域的标准，如危重疾病识别、指南遵循和药物安全，并带有加权后果测量。32名专科医生开发并审查了2,069个与这些标准对齐的开放性问答项目，覆盖26个临床部门以模拟现实场景。对六种大语言模型的基准测试显示总体表现中等（平均总分57.2%），安全性能54.7%，有效性62.3%。在高风险场景中性能下降显著（p < 0.0001）。领域特定的医疗大语言模型在安全性（0.912）和有效性（0.861）方面表现出相对较高的最高分数。

Result: 对六种大语言模型的基准测试显示总体表现中等（平均总分57.2%），安全性能54.7%，有效性62.3%。在高风险场景中性能下降显著（p < 0.0001）。领域特定的医疗大语言模型在安全性（0.912）和有效性（0.861）方面表现出相对较高的最高分数。

Conclusion: 本研究的发现不仅为评估医疗大语言模型的临床应用提供了标准化指标，还促进了不同场景下比较分析、风险暴露识别和改进方向的确定，并有望推动大语言模型在医疗环境中的更安全和有效的部署。

Abstract: Large language models (LLMs) hold promise in clinical decision support but
face major challenges in safety evaluation and effectiveness validation. We
developed the Clinical Safety-Effectiveness Dual-Track Benchmark (CSEDB), a
multidimensional framework built on clinical expert consensus, encompassing 30
criteria covering critical areas like critical illness recognition, guideline
adherence, and medication safety, with weighted consequence measures.
Thirty-two specialist physicians developed and reviewed 2,069 open-ended Q&A
items aligned with these criteria, spanning 26 clinical departments to simulate
real-world scenarios. Benchmark testing of six LLMs revealed moderate overall
performance (average total score 57.2%, safety 54.7%, effectiveness 62.3%),
with a significant 13.3% performance drop in high-risk scenarios (p < 0.0001).
Domain-specific medical LLMs showed consistent performance advantages over
general-purpose models, with relatively higher top scores in safety (0.912) and
effectiveness (0.861). The findings of this study not only provide a
standardized metric for evaluating the clinical application of medical LLMs,
facilitating comparative analyses, risk exposure identification, and
improvement directions across different scenarios, but also hold the potential
to promote safer and more effective deployment of large language models in
healthcare environments.

</details>


### [62] [Med-R$^3$: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via Progressive Reinforcement Learning](https://arxiv.org/abs/2507.23541)
*Keer Lu,Zheng Liang,Youquan Li,Jiejun Tan,Da Pan,Shusen Zhang,Guosheng Dong,Huang Leng*

Main category: cs.CL

TL;DR: 本文提出了 Med-R$^3$，一个基于渐进式强化学习的医学检索增强推理框架，解决了现有方法在检索和推理联合优化、泛化能力和医学领域特定需求方面的不足，并实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要集中在增强模型的检索或推理能力，而很少关注两者的联合优化，导致两个过程之间的协调有限。此外，当前方法严重依赖监督微调，可能导致模型记忆现有的解决问题路径，从而限制其在新问题情境中的泛化能力。虽然一些研究探索了通过强化学习改进一般领域的检索增强推理，但其奖励函数设计未能充分捕捉医学领域的特定需求。

Method: 引入了 Med-R$^3$，这是一个基于渐进式强化学习的医学检索增强推理框架。首先开发模型在医学问题上的逻辑推理能力，然后在此基础上自适应优化检索能力，以更好地与知识语料库和外部信息利用相匹配，最后进行检索和推理协调的联合优化。

Result: Med-R$^3$ 实现了最先进的性能，LLaMA3.1-8B-Instruct + Med-R$^3$ 超越了封闭的 GPT-4o-mini 3.93%，而 Qwen2.5-14B 增强的 Med-R$^3$ 显示出更大的优势，提升了 13.53%。

Conclusion: Med-R$^3$ 可以实现最先进的性能，LLaMA3.1-8B-Instruct + Med-R$^3$ 在参数规模相当的情况下超越了封闭的 GPT-4o-mini 3.93%，而 Qwen2.5-14B 增强的 Med-R$^3$ 显示出更大的优势，提升了 13.53%。

Abstract: In medical scenarios, effectively retrieving external knowledge and
leveraging it for rigorous logical reasoning is of significant importance.
Despite their potential, existing work has predominantly focused on enhancing
either retrieval or reasoning capabilities of the models in isolation, with
little attention given to their joint optimization, which leads to limited
coordination between the two processes. Additionally, current methods rely
heavily on supervised fine-tuning (SFT), which can cause models to memorize
existing problem-solving pathways, thereby restricting their generalization
ability when confronted with novel problem contexts. Furthermore, while some
studies have explored to improve retrieval-augmented reasoning in general
domains via reinforcement learning, their reward function designs do not
adequately capture the specific demands of the medical domain. To address these
challenges, we introduce **Med-R$^3$**, a **Med**ical **R**etrieval-augmented
**R**easoning framework driven by progressive **R**einforcement learning. In
this framework, we first develop the model's ability to perform logical
reasoning over medical problems. Subsequently, on the basis of this foundation,
we adaptively optimize the retrieval capability to better align with the
characteristics of knowledge corpus and external information utilization
throughout the reasoning process. Finally, we conduct joint optimization of the
model's retrieval and reasoning coordination. Extensive experiments indicate
that **Med-R$^3$** could achieve state-of-the-art performances, with
LLaMA3.1-8B-Instruct + Med-R$^3$ surpassing closed-sourced GPT-4o-mini by
3.93\% at a comparable parameter scale, while Qwen2.5-14B augmented with
Med-R$^3$ shows a more substantial gain of 13.53\%.

</details>


### [63] [T-Detect: Tail-Aware Statistical Normalization for Robust Detection of Adversarial Machine-Generated Text](https://arxiv.org/abs/2507.23577)
*Alva West,Luodan Zhang,Liuliu Zhang,Minjun Zhu,Yixuan Weng,Yue Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种新的文本检测方法T-Detect，通过使用重尾分布来提高对抗性文本检测的鲁棒性，并在多个基准测试中取得了优异的表现。


<details>
  <summary>Details</summary>
Motivation: 现有零样本检测器通常依赖于假设高斯分布的统计度量，这在面对对抗性或非母语英语文本的重尾统计特征时失效。因此，需要一种更鲁棒的检测方法。

Method: T-Detect方法通过将文本的对数似然与t分布的期望矩进行归一化，计算检测分数，从而提高对统计异常值的鲁棒性。

Result: T-Detect在RAID基准和HART数据集上进行了验证，实验结果显示其性能优于强基线，特别是在目标领域中AUROC提高了3.9%。当集成到二维检测框架中时，T-Detect在Books领域达到了0.926的AUROC。

Conclusion: 本文提出了T-Detect方法，该方法通过使用来自学生t分布的重尾差异分数替代标准高斯归一化，为文本检测提供了新的理论基础，并在对抗性文本检测任务中表现出色。

Abstract: The proliferation of sophisticated text generation models necessitates the
development of robust detection methods capable of identifying
machine-generated content, particularly text designed to evade detection
through adversarial perturbations. Existing zero-shot detectors often rely on
statistical measures that implicitly assume Gaussian distributions, a premise
that falters when confronted with the heavy-tailed statistical artifacts
characteristic of adversarial or non-native English texts. This paper
introduces T-Detect, a novel detection method that fundamentally redesigns the
statistical core of curvature-based detectors. Our primary innovation is the
replacement of standard Gaussian normalization with a heavy-tailed discrepancy
score derived from the Student's t-distribution. This approach is theoretically
grounded in the empirical observation that adversarial texts exhibit
significant leptokurtosis, rendering traditional statistical assumptions
inadequate. T-Detect computes a detection score by normalizing the
log-likelihood of a passage against the expected moments of a t-distribution,
providing superior resilience to statistical outliers. We validate our approach
on the challenging RAID benchmark for adversarial text and the comprehensive
HART dataset. Experiments show that T-Detect provides a consistent performance
uplift over strong baselines, improving AUROC by up to 3.9\% in targeted
domains. When integrated into a two-dimensional detection framework (CT), our
method achieves state-of-the-art performance, with an AUROC of 0.926 on the
Books domain of RAID. Our contributions are a new, theoretically-justified
statistical foundation for text detection, an ablation-validated method that
demonstrates superior robustness, and a comprehensive analysis of its
performance under adversarial conditions. Ours code are released at
https://github.com/ResearAI/t-detect.

</details>


### [64] [DiffLoRA: Differential Low-Rank Adapters for Large Language Models](https://arxiv.org/abs/2507.23588)
*Alexandre Misrahi,Nadezhda Chirkova,Maxime Louis,Vassilina Nikoulina*

Main category: cs.CL

TL;DR: DiffLoRA是一种结合差分注意力和低秩适配器的参数高效微调方法，在某些任务中表现优于LoRA。


<details>
  <summary>Details</summary>
Motivation: 改进Transformer模型的性能，通过消除噪声并保持LoRA的效率，同时利用差分注意力的优势。

Method: 引入DiffLoRA，这是一种参数高效的微调方法，结合了差分注意力机制和低秩适配器。

Result: DiffLoRA在多数评估任务中表现不如其他方法，但在某些领域显示出显著提升。

Conclusion: DiffLoRA虽然在大多数评估任务中不如其他参数高效的微调方法，但在某些领域表现出色，如HumanEval中比LoRA高出11分。

Abstract: Differential Transformer has recently been proposed to improve performance in
Transformer models by canceling out noise through a denoiser attention
mechanism. In this work, we introduce DiffLoRA, a parameter-efficient
adaptation of the differential attention mechanism, with low-rank adapters on
both positive and negative attention terms. This approach retains the
efficiency of LoRA while aiming to benefit from the performance gains of
differential attention. We evaluate DiffLoRA across a broad range of NLP tasks,
including general benchmarks, many-shot in-context learning, RAG, and
long-context tests. We observe that, although DiffLoRA falls short of other
parameter-efficient fine-tuning methods in most evaluation tasks, it shows
interesting results in certain domains (+11 pts on LoRA for HumanEval). We
analyze the attention patterns post-finetuning to identify the reasons for this
behavior.

</details>


### [65] [Arabic Hate Speech Identification and Masking in Social Media using Deep Learning Models and Pre-trained Models Fine-tuning](https://arxiv.org/abs/2507.23661)
*Salam Thabet Doghmash,Motaz Saad*

Main category: cs.CL

TL;DR: 本文研究了阿拉伯语文本中的仇恨言论识别和清理问题，并提出了两种方法。实验结果表明，所提出的模型在两个任务中都取得了良好的性能。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体上仇恨言论的增加，识别和清理仇恨言论变得越来越重要。本文旨在解决阿拉伯语文本中的这两个问题。

Method: 针对第一个问题，我们使用深度学习模型和变压器进行了多个实验，以确定最佳模型。针对第二个问题，我们将任务视为机器翻译任务，输入是包含脏话的句子，输出是掩码后的句子。

Result: 在仇恨言论检测任务中，所提出的模型取得了92%的宏F1分数和95%的准确率。在文本清理任务中，最佳模型在BLEU得分上达到了0.3。

Conclusion: 本文提出了两种方法来解决阿拉伯语文本中的仇恨言论识别和清理问题。实验结果表明，所提出的模型在仇恨言论检测中取得了92%的宏F1分数和95%的准确率，在文本清理任务中，最佳模型在BLEU得分上达到了0.3。

Abstract: Hate speech identification in social media has become an increasingly
important issue in recent years. In this research, we address two problems: 1)
to detect hate speech in Arabic text, 2) to clean a given text from hate
speech. The meaning of cleaning here is replacing each bad word with stars
based on the number of letters for each word. Regarding the first problem, we
conduct several experiments using deep learning models and transformers to
determine the best model in terms of the F1 score. Regarding second problem, we
consider it as a machine translation task, where the input is a sentence
containing dirty text and the output is the same sentence with masking the
dirty text. The presented methods achieve the best model in hate speech
detection with a 92\% Macro F1 score and 95\% accuracy. Regarding the text
cleaning experiment, the best result in the hate speech masking model reached
0.3 in BLEU score with 1-gram, which is a good result compared with the state
of the art machine translation systems.

</details>


### [66] [Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs](https://arxiv.org/abs/2507.23740)
*Nasim Shirvani-Mahdavi,Devin Wingfield,Amin Ghasemi,Chengkai Li*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型生成知识图谱逻辑规则自然语言解释的能力，并展示了其在正确性和清晰度方面的良好表现。


<details>
  <summary>Details</summary>
Motivation: 知识图谱（KGs）通常包含足够的信息来支持新事实的推断。识别逻辑规则不仅可以提高知识图谱的完整性，还可以检测潜在错误，揭示细微的数据模式，并增强整体的推理和解释能力。然而，这些规则的复杂性以及每个KG的独特标记约定可能使它们对人类难以理解。因此，本文探索了大型语言模型生成自然语言解释的潜力。

Method: 本文使用AMIE 3.5.1规则发现算法从基准数据集FB15k-237和两个大规模数据集FB-CVT-REV和FB+CVT-REV中提取逻辑规则，并探讨了各种提示策略，包括零次和少量提示、变量实体类型以及思维链推理。

Result: 本文的结果表明，在解释的正确性和清晰度方面表现出色，但未来的研究仍需解决一些挑战。

Conclusion: 本文展示了大型语言模型在生成逻辑规则的自然语言解释方面具有良好的表现，但仍存在一些挑战需要未来研究解决。

Abstract: Knowledge graphs (KGs) often contain sufficient information to support the
inference of new facts. Identifying logical rules not only improves the
completeness of a knowledge graph but also enables the detection of potential
errors, reveals subtle data patterns, and enhances the overall capacity for
reasoning and interpretation. However, the complexity of such rules, combined
with the unique labeling conventions of each KG, can make them difficult for
humans to understand. In this paper, we explore the potential of large language
models to generate natural language explanations for logical rules.
Specifically, we extract logical rules using the AMIE 3.5.1 rule discovery
algorithm from the benchmark dataset FB15k-237 and two large-scale datasets,
FB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including
zero- and few-shot prompting, including variable entity types, and
chain-of-thought reasoning. We conduct a comprehensive human evaluation of the
generated explanations based on correctness, clarity, and hallucination, and
also assess the use of large language models as automatic judges. Our results
demonstrate promising performance in terms of explanation correctness and
clarity, although several challenges remain for future research. All scripts
and data used in this study are publicly available at
https://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.

</details>


### [67] [Cascaded Information Disclosure for Generalized Evaluation of Problem Solving Capabilities](https://arxiv.org/abs/2507.23776)
*Yunxiang Yan,Tomohiro Sawada,Kartik Goyal*

Main category: cs.CL

TL;DR: 本文提出了一种基于级联问题披露的框架，以更准确地评估LLM的问题解决能力，同时保持可扩展性和自动化。该方法通过分阶段揭示问题的部分信息来激发通用推理，并在多个数据集上验证了其有效性。结果表明，该方法能更好地比较LLM，并减少标准QA评估中的性能差距。


<details>
  <summary>Details</summary>
Motivation: 虽然问答（QA）基准性能是一种自动且可扩展的方法来比较LLM，但它是一种间接的方法来评估其底层问题解决能力。

Method: 我们提出了一个基于级联问题披露的全面且可推广的框架，以提供对模型解决问题能力的更准确估计，同时保持可扩展性和自动化。这种方法以分阶段的方式收集模型响应，每个阶段揭示关于问题的部分信息，旨在激发LLM的通用推理。

Result: 我们的方法不仅提供了LLM之间更好的比较，而且与标准QA范式相比，诱导了更好的中间痕迹。我们在各种推理和知识密集型QA数据集上通过比较不同大小和家族的LLM来验证这一行为。

Conclusion: 我们的方法缩小了在标准QA评估设置中观察到的表现差距，表明普遍的间接QA评估范式高估了模型之间的表现差异。

Abstract: While question-answering~(QA) benchmark performance is an automatic and
scalable method to compare LLMs, it is an indirect method of evaluating their
underlying problem-solving capabilities. Therefore, we propose a holistic and
generalizable framework based on \emph{cascaded question disclosure} that
provides a more accurate estimate of the models' problem-solving capabilities
while maintaining the scalability and automation. This approach collects model
responses in a stagewise manner with each stage revealing partial information
about the question designed to elicit generalized reasoning in LLMs. We find
that our approach not only provides a better comparison between LLMs, but also
induces better intermediate traces in models compared to the standard QA
paradigm. We empirically verify this behavior on diverse reasoning and
knowledge-heavy QA datasets by comparing LLMs of varying sizes and families.
Our approach narrows the performance gap observed in the standard QA evaluation
settings, indicating that the prevalent indirect QA paradigm of evaluation
overestimates the differences in performance between models. We further
validate our findings by extensive ablation studies.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [68] [ELMES: An Automated Framework for Evaluating Large Language Models in Educational Scenarios](https://arxiv.org/abs/2507.22947)
*Shou'ang Wei,Xinyun Wang,Shuzhen Bi,Jian Chen,Ruijia Li,Bo Jiang,Xin Lin,Min Zhang,Yu Song,BingDong Li,Aimin Zhou,Hao Hao*

Main category: cs.CY

TL;DR: 本文介绍了ELMES，一个开源的自动化评估框架，旨在评估教育环境中大型语言模型的能力。该框架通过模块化架构和混合评估引擎，解决了现有评估指标不足的问题，并展示了不同模型在教育场景中的能力分布。


<details>
  <summary>Details</summary>
Motivation: 当前基准主要衡量一般智能而非教学能力，而许多新兴场景缺乏适当的评估指标。因此，需要一种专门针对教育场景的评估框架。

Method: 引入ELMES，一个开源的自动化评估框架，专门设计用于评估教育环境中的LLMs。该框架具有模块化架构，允许研究人员通过简单的配置文件创建动态、多代理对话，同时结合混合评估引擎，使用LLM-as-a-Judge方法客观量化传统上主观的教育指标。

Result: 系统基准测试表明，不同模型在能力分布上存在显著差异，揭示了特定上下文中的优势和局限性。

Conclusion: ELMES为教育者和研究人员提供了一个可访问的评估框架，显著降低了多样化教育应用的适应障碍，同时推动了LLMs在教学中的实际应用。

Abstract: The emergence of Large Language Models (LLMs) presents transformative
opportunities for education, generating numerous novel application scenarios.
However, significant challenges remain: evaluation metrics vary substantially
across different educational scenarios, while many emerging scenarios lack
appropriate assessment metrics. Current benchmarks predominantly measure
general intelligence rather than pedagogical capabilities. To address this gap,
we introduce ELMES, an open-source automated evaluation framework specifically
designed for assessing LLMs in educational settings. ELMES features a modular
architecture that enables researchers to create dynamic, multi-agent dialogues
through simple configuration files, facilitating flexible scenario design
without requiring extensive programming expertise. The framework incorporates a
hybrid evaluation engine that objectively quantifies traditionally subjective
pedagogical metrics using an LLM-as-a-Judge methodology. We conduct systematic
benchmarking of state-of-the-art LLMs across four critical educational
scenarios: Knowledge Point Explanation, Guided Problem-Solving Teaching,
Interdisciplinary Lesson Plan Generation, and Contextualized Question
Generation, employing fine-grained metrics developed in collaboration with
education specialists. Our results demonstrate distinct capability
distributions among models, revealing context-specific strengths and
limitations. ELMES provides educators and researchers with an accessible
evaluation framework that significantly reduces adaptation barriers for diverse
educational applications while advancing the practical implementation of LLMs
in pedagogy. The framework is publicly available at
\emph{https://github.com/sii-research/elmes.git}.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [69] [SequenceLayers: Sequence Processing and Streaming Neural Networks Made Easy](https://arxiv.org/abs/2507.23292)
*RJ Skerry-Ryan,Julian Salazar,Soroosh Mariooryad,David Kao,Daisy Stanton,Eric Battenberg,Matt Shannon,Ron J. Weiss,Robin Scheibler,Jonas Rothfuss,Tom Bagby*

Main category: cs.LG

TL;DR: 本文介绍了一个用于序列建模的神经网络层 API 和库，支持流式处理和并行处理，提高了模型的灵活性和正确性。


<details>
  <summary>Details</summary>
Motivation: 为了实现序列模型在逐层（如教师强制训练）和逐步（如自回归采样）执行之间的灵活切换，同时减少流式处理和并行序列处理中的常见错误。

Method: 通过定义显式的随时间变化的状态（例如 Transformer KV 缓存、卷积缓冲区、RNN 隐藏状态）以及一个演进该状态的步骤方法，实现了序列模型的流式处理。

Result: SequenceLayers 能够立即实现复杂模型的流式处理，并且可以在任何深度学习库中实现。

Conclusion: SequenceLayers 提供了一种可组合和声明式的 API，使从简单的流式组件构建生产规模的模型变得更加容易，同时保持强大的正确性保证。

Abstract: We introduce a neural network layer API and library for sequence modeling,
designed for easy creation of sequence models that can be executed both
layer-by-layer (e.g., teacher-forced training) and step-by-step (e.g.,
autoregressive sampling). To achieve this, layers define an explicit
representation of their state over time (e.g., a Transformer KV cache, a
convolution buffer, an RNN hidden state), and a step method that evolves that
state, tested to give identical results to a stateless layer-wise invocation.
This and other aspects of the SequenceLayers contract enables complex models to
be immediately streamable, mitigates a wide range of common bugs arising in
both streaming and parallel sequence processing, and can be implemented in any
deep learning library. A composable and declarative API, along with a
comprehensive suite of layers and combinators, streamlines the construction of
production-scale models from simple streamable components while preserving
strong correctness guarantees. Our current implementations of SequenceLayers
(JAX, TensorFlow 2) are available at https://github.com/google/sequence-layers.

</details>


### [70] [Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates](https://arxiv.org/abs/2507.23607)
*Tien Huu Do,Antoine Masquelier,Nae Eoun Lee,Jonathan Crowther*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的方法，利用预训练语言模型和概率层来提高临床试验中患者招募预测的准确性，并在实际数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 临床试验需要大量的资金投入和细致的规划，因此准确预测试验结果至关重要。其中，准确预测患者招募是试验成功的关键挑战之一。

Method: 本文提出了一种基于神经网络模型的方法，利用预训练语言模型（PLMs）捕捉临床文档的复杂性和细微差别，并通过注意力机制将这些表示与编码的表格特征结合。此外，还通过基于Gamma分布的概率层来处理招募预测中的不确定性。

Result: 本文在真实世界的临床试验数据上进行了广泛的实验，结果表明所提出的方法能够有效预测给定临床试验中多个站点的患者招募数量，并且优于现有的基线模型。

Conclusion: 本文提出了一种基于深度学习的新方法，用于预测临床试验中的患者招募情况，该方法在实际数据上表现出优于现有基线模型的性能。

Abstract: Clinical trials are a systematic endeavor to assess the safety and efficacy
of new drugs or treatments. Conducting such trials typically demands
significant financial investment and meticulous planning, highlighting the need
for accurate predictions of trial outcomes. Accurately predicting patient
enrollment, a key factor in trial success, is one of the primary challenges
during the planning phase. In this work, we propose a novel deep learning-based
method to address this critical challenge. Our method, implemented as a neural
network model, leverages pre-trained language models (PLMs) to capture the
complexities and nuances of clinical documents, transforming them into
expressive representations. These representations are then combined with
encoded tabular features via an attention mechanism. To account for
uncertainties in enrollment prediction, we enhance the model with a
probabilistic layer based on the Gamma distribution, which enables range
estimation. We apply the proposed model to predict clinical trial duration,
assuming site-level enrollment follows a Poisson-Gamma process. We carry out
extensive experiments on real-world clinical trial data, and show that the
proposed method can effectively predict the number of patients enrolled at a
number of sites for a given clinical trial, outperforming established baseline
models.

</details>


### [71] [TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached Responses](https://arxiv.org/abs/2507.23674)
*Muhammad Taha Cheema,Abeer Aamir,Khawaja Gul Muhammad,Naveed Anwar Bhatti,Ihsan Ayyub Qazi,Zafar Ayyub Qazi*

Main category: cs.LG

TL;DR: TweakLLM 是一种新型的路由架构，利用轻量级 LLM 动态调整缓存响应，从而在保持响应质量的同时提高缓存效果。


<details>
  <summary>Details</summary>
Motivation: 由于聊天机器人的个性化互动和语义相似性搜索的有限准确性，使用响应缓存来保持与用户查询的相关性具有挑战性。

Method: TweakLLM 是一种新颖的路由架构，利用轻量级 LLM 动态调整缓存响应以适应传入提示。

Result: 通过全面的评估，包括用户研究、并排比较、满意度投票以及多代理 LLM 辩论，我们证明 TweakLLM 在保持响应质量方面与前沿模型相当，同时显著提高了缓存效果。

Conclusion: TweakLLM 是一种可扩展且资源高效的缓存解决方案，能够在不牺牲用户体验的情况下处理高吞吐量的 LLM 部署。

Abstract: Large Language Models (LLMs) process millions of queries daily, making
efficient response caching a compelling optimization for reducing cost and
latency. However, preserving relevance to user queries using this approach
proves difficult due to the personalized nature of chatbot interactions and the
limited accuracy of semantic similarity search. To address this, we present
TweakLLM, a novel routing architecture that employs a lightweight LLM to
dynamically adapt cached responses to incoming prompts. Through comprehensive
evaluation, including user studies with side-by-side comparisons, satisfaction
voting, as well as multi-agent LLM debates, we demonstrate that TweakLLM
maintains response quality comparable to frontier models while significantly
improving cache effectiveness. Our results across real-world datasets highlight
TweakLLM as a scalable, resource-efficient caching solution for high-volume LLM
deployments without compromising user experience.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [72] [SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution](https://arxiv.org/abs/2507.23348)
*Han Li,Yuling Shi,Shaoxin Lin,Xiaodong Gu,Heng Lian,Xin Wang,Yantao Jia,Tao Huang,Qianxiang Wang*

Main category: cs.SE

TL;DR: SWE-Debate is a competitive multi-agent debate framework that improves issue resolution by encouraging diverse reasoning paths and achieving more consolidated issue localization.


<details>
  <summary>Details</summary>
Motivation: Existing agent-based issue resolution approaches often get stuck in local solutions and fail to identify issue patterns that span across different parts of the codebase. To address this limitation, SWE-Debate is proposed to encourage diverse reasoning paths and achieve more consolidated issue localization.

Method: SWE-Debate is a competitive multi-agent debate framework that encourages diverse reasoning paths and achieves more consolidated issue localization. It creates multiple fault propagation traces as localization proposals by traversing a code dependency graph, organizes a three-round debate among specialized agents, and integrates the consolidated fix plan into an MCTS-based code modification agent for patch generation.

Result: Experiments on the SWE-bench benchmark show that SWE-Debate achieves new state-of-the-art results in open-source agent frameworks and outperforms baselines by a large margin.

Conclusion: SWE-Debate achieves new state-of-the-art results in open-source agent frameworks and outperforms baselines by a large margin.

Abstract: Issue resolution has made remarkable progress thanks to the advanced
reasoning capabilities of large language models (LLMs). Recently, agent-based
frameworks such as SWE-agent have further advanced this progress by enabling
autonomous, tool-using agents to tackle complex software engineering tasks.
While existing agent-based issue resolution approaches are primarily based on
agents' independent explorations, they often get stuck in local solutions and
fail to identify issue patterns that span across different parts of the
codebase. To address this limitation, we propose SWE-Debate, a competitive
multi-agent debate framework that encourages diverse reasoning paths and
achieves more consolidated issue localization. SWE-Debate first creates
multiple fault propagation traces as localization proposals by traversing a
code dependency graph. Then, it organizes a three-round debate among
specialized agents, each embodying distinct reasoning perspectives along the
fault propagation trace. This structured competition enables agents to
collaboratively converge on a consolidated fix plan. Finally, this consolidated
fix plan is integrated into an MCTS-based code modification agent for patch
generation. Experiments on the SWE-bench benchmark show that SWE-Debate
achieves new state-of-the-art results in open-source agent frameworks and
outperforms baselines by a large margin.

</details>


### [73] [SWE-Exp: Experience-Driven Software Issue Resolution](https://arxiv.org/abs/2507.23361)
*Silin Chen,Shaoxin Lin,Xiaodong Gu,Yuling Shi,Heng Lian,Longfei Yun,Dong Chen,Weiguo Sun,Lin Cao,Qianxiang Wang*

Main category: cs.SE

TL;DR: 本文提出SWE-Exp，一种通过从先前代理轨迹中提炼经验来实现跨问题持续学习的方法，实验显示其在SWE-bench-Verified上的解决率达到了41.6% Pass@1。


<details>
  <summary>Details</summary>
Motivation: 当前的代理作为无记忆的探索者，处理每个问题时不会保留或重用之前修复经验的知识，导致冗余探索失败轨迹并错过将成功的解决方案方法适应到类似问题的机会。

Method: 我们引入了SWE-Exp，这是一种增强经验的方法，能够从先前的代理轨迹中提炼出简洁且可操作的经验，从而实现跨问题的持续学习。我们的方法引入了一个多方面的经验库，捕捉成功和失败的修复尝试，并在不同层次上提取可重用的问题解决知识。

Result: 实验表明，SWE-Exp在SWE-bench-Verified上实现了最先进的解决率（41.6% Pass@1）。

Conclusion: 我们的方法建立了一种新范式，其中自动化软件工程代理系统地积累和利用修复专业知识，从根本上从试错探索转向战略性的、以经验为驱动的问题解决。

Abstract: Recent advances in large language model (LLM) agents have shown remarkable
progress in software issue resolution, leveraging advanced techniques such as
multi-agent collaboration and Monte Carlo Tree Search (MCTS). However, current
agents act as memoryless explorers - treating each problem separately without
retaining or reusing knowledge from previous repair experiences. This leads to
redundant exploration of failed trajectories and missed chances to adapt
successful issue resolution methods to similar problems. To address this
problem, we introduce SWE-Exp, an experience - enhanced approach that distills
concise and actionable experience from prior agent trajectories, enabling
continuous learning across issues. Our method introduces a multi-faceted
experience bank that captures both successful and failed repair attempts.
Specifically, it extracts reusable issue resolution knowledge at different
levels - from high-level problem comprehension to specific code changes.
Experiments show that SWE-Exp achieves state-of-the-art resolution rate (41.6%
Pass@1) on SWE-bench-Verified under open-source agent frameworks. Our approach
establishes a new paradigm in which automated software engineering agents
systematically accumulate and leverage repair expertise, fundamentally shifting
from trial-and-error exploration to strategic, experience-driven issue
resolution.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [74] [Hybrid EEG--Driven Brain--Computer Interface: A Large Language Model Framework for Personalized Language Rehabilitation](https://arxiv.org/abs/2507.22892)
*Ismail Hossain,Mridul Banik*

Main category: cs.HC

TL;DR: 本文提出了一种结合EEG和LLM的新框架，以实现实时适应用户需求的语言康复系统。


<details>
  <summary>Details</summary>
Motivation: 传统辅助和替代通信（AAC）系统和语言学习平台在适应用户实时认知和语言需求方面存在不足，特别是在中风后失语症或肌萎缩侧索硬化症等神经疾病情况下。

Method: 本文结合了非侵入性脑电图（EEG）脑机接口（BCI）和基于变压器的大型语言模型（LLM），以实现实时适应用户认知和语言需求的语言学习系统。

Result: 该系统能够使严重言语或运动障碍的用户通过心理命令导航语言学习模块，动态个性化词汇、句子构造练习和纠正反馈，并监测认知努力的神经标记以实时调整任务难度。

Conclusion: 本文提出了一种新的混合框架，利用实时EEG信号驱动基于LLM的语言康复助手，以实现更有效的语言学习和沟通。

Abstract: Conventional augmentative and alternative communication (AAC) systems and
language-learning platforms often fail to adapt in real time to the user's
cognitive and linguistic needs, especially in neurological conditions such as
post-stroke aphasia or amyotrophic lateral sclerosis. Recent advances in
noninvasive electroencephalography (EEG)--based brain-computer interfaces
(BCIs) and transformer--based large language models (LLMs) offer complementary
strengths: BCIs capture users' neural intent with low fatigue, while LLMs
generate contextually tailored language content. We propose and evaluate a
novel hybrid framework that leverages real-time EEG signals to drive an
LLM-powered language rehabilitation assistant. This system aims to: (1) enable
users with severe speech or motor impairments to navigate language-learning
modules via mental commands; (2) dynamically personalize vocabulary,
sentence-construction exercises, and corrective feedback; and (3) monitor
neural markers of cognitive effort to adjust task difficulty on the fly.

</details>


### [75] [Voice-guided Orchestrated Intelligence for Clinical Evaluation (VOICE): A Voice AI Agent System for Prehospital Stroke Assessment](https://arxiv.org/abs/2507.22898)
*Julian Acosta,Scott Adams,Julius Kernbach,Romain Hardy,Sung Eun Kim,Luyang Luo,Xiaoman Zhang,Shreya Johri,Mohammed Baharoon,Pranav Rajpurkar*

Main category: cs.HC

TL;DR: 开发了一个由语音驱动的人工智能系统，用于指导任何人进行专家级中风评估，并允许使用智能手机视频捕捉关键检查组件。该系统在测试中表现出较高的准确性，但需要人工监督。


<details>
  <summary>Details</summary>
Motivation: 当前的第一响应者中风识别不一致且经常不准确，检测中风的敏感性低至58%，导致治疗延误。

Method: 开发了一个由语音驱动的人工智能（AI）系统，该系统通过自然对话引导任何人进行专家级中风评估，并允许使用智能手机视频捕捉关键检查组件以进行记录和潜在专家审查。

Result: AI系统正确识别了84%的个体中风迹象，并检测到了75%的可能大血管阻塞（LVO）中风，完成评估仅需6分钟多一点。用户报告了高信心（中位数4.5/5）和易用性（平均4.67/5）。系统成功识别了86%的实际中风，但也错误地将3个非中风案例中的2个标记为中风。当专家医生审查AI报告和视频时，他们正确诊断了所有病例，但由于观察到的AI错误，只在40%的病例中足够有信心做出初步治疗决定。

Conclusion: 虽然当前系统需要人工监督，但语音到语音AI模型的快速进步表明，未来版本有望实现高度准确的评估。实现人类水平的语音交互可能会改变紧急医疗服务，将专家指导的评估能力带给每个人。

Abstract: We developed a voice-driven artificial intelligence (AI) system that guides
anyone - from paramedics to family members - through expert-level stroke
evaluations using natural conversation, while also enabling smartphone video
capture of key examination components for documentation and potential expert
review. This addresses a critical gap in emergency care: current stroke
recognition by first responders is inconsistent and often inaccurate, with
sensitivity for stroke detection as low as 58%, causing life-threatening delays
in treatment. Three non-medical volunteers used our AI system to assess ten
simulated stroke patients, including cases with likely large vessel occlusion
(LVO) strokes and stroke-like conditions, while we measured diagnostic
accuracy, completion times, user confidence, and expert physician review of the
AI-generated reports. The AI system correctly identified 84% of individual
stroke signs and detected 75% of likely LVOs, completing evaluations in just
over 6 minutes. Users reported high confidence (median 4.5/5) and ease of use
(mean 4.67/5). The system successfully identified 86% of actual strokes but
also incorrectly flagged 2 of 3 non-stroke cases as strokes. When an expert
physician reviewed the AI reports with videos, they identified the correct
diagnosis in 100% of cases, but felt confident enough to make preliminary
treatment decisions in only 40% of cases due to observed AI errors including
incorrect scoring and false information. While the current system's limitations
necessitate human oversight, ongoing rapid advancements in speech-to-speech AI
models suggest that future versions are poised to enable highly accurate
assessments. Achieving human-level voice interaction could transform emergency
medical care, putting expert-informed assessment capabilities in everyone's
hands.

</details>


### [76] [Toward the Autonomous AI Doctor: Quantitative Benchmarking of an Autonomous Agentic AI Versus Board-Certified Clinicians in a Real World Setting](https://arxiv.org/abs/2507.22902)
*Hashim Hayat,Maksim Kudrautsau,Evgeniy Makarov,Vlad Melnichenko,Tim Tsykunou,Piotr Varaksin,Matt Pavelle,Adam Z. Oskowitz*

Main category: cs.HC

TL;DR: 本研究评估了一个基于多代理LLM的AI框架是否可以在虚拟紧急护理环境中自主作为AI医生运行。结果表明，AI在诊断和治疗计划方面与人类临床医生具有高度一致性，有时甚至表现更优，这表明多代理AI系统可以实现与人类提供者相当的临床决策，并可能成为解决医疗人力资源短缺的一种解决方案。


<details>
  <summary>Details</summary>
Motivation: 全球面临到2030年预计有1100万医疗从业者短缺的问题，而行政负担消耗了50%的临床时间。人工智能（AI）有潜力帮助缓解这些问题。然而，还没有经过严格评估的端到端自主大型语言模型（LLM）为基础的AI系统在现实世界临床实践中使用。

Method: 我们回顾性地比较了多代理AI系统Doctronic和董事会认证的临床医生在500次连续的紧急护理远程医疗会诊中的表现。主要终点：诊断一致性、治疗方案一致性和安全指标，通过盲法LLM基于判定和专家人工评审进行评估。

Result: Doctronic和临床医生的最高诊断在81%的病例中匹配，治疗方案在99.2%的病例中一致。没有发生临床幻觉（例如，诊断或治疗未得到临床发现的支持）。在对不一致案例的专家评审中，AI表现优于36.1%，人类表现优于9.3%；其余案例的诊断是等效的。

Conclusion: 在对自主AI医生的首次大规模验证中，我们展示了与人类临床医生强诊断和治疗计划一致性，AI的表现与实践中的临床医生相当，在某些情况下甚至超过了他们。这些发现表明，多代理AI系统可以实现与人类提供者相当的临床决策，并可能成为解决医疗人力资源短缺的一种解决方案。

Abstract: Background: Globally we face a projected shortage of 11 million healthcare
practitioners by 2030, and administrative burden consumes 50% of clinical time.
Artificial intelligence (AI) has the potential to help alleviate these
problems. However, no end-to-end autonomous large language model (LLM)-based AI
system has been rigorously evaluated in real-world clinical practice. In this
study, we evaluated whether a multi-agent LLM-based AI framework can function
autonomously as an AI doctor in a virtual urgent care setting. Methods: We
retrospectively compared the performance of the multi-agent AI system Doctronic
and board-certified clinicians across 500 consecutive urgent-care telehealth
encounters. The primary end points: diagnostic concordance, treatment plan
consistency, and safety metrics, were assessed by blinded LLM-based
adjudication and expert human review. Results: The top diagnosis of Doctronic
and clinician matched in 81% of cases, and the treatment plan aligned in 99.2%
of cases. No clinical hallucinations occurred (e.g., diagnosis or treatment not
supported by clinical findings). In an expert review of discordant cases, AI
performance was superior in 36.1%, and human performance was superior in 9.3%;
the diagnoses were equivalent in the remaining cases. Conclusions: In this
first large-scale validation of an autonomous AI doctor, we demonstrated strong
diagnostic and treatment plan concordance with human clinicians, with AI
performance matching and in some cases exceeding that of practicing clinicians.
These findings indicate that multi-agent AI systems achieve comparable clinical
decision-making to human providers and offer a potential solution to healthcare
workforce shortages.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [77] [Generalized Reinforcement Learning for Retriever-Specific Query Rewriter with Unstructured Real-World Documents](https://arxiv.org/abs/2507.23242)
*Sungguk Cha,DongWook Kim,Taeseung Hahn,Mintae Kim,Youngsub Han,Byoung-Ki Jeon*

Main category: cs.CV

TL;DR: 本文介绍了RL-QR，这是一种用于特定检索器的查询重写强化学习框架，它可以不用人工标注数据集，并适用于文本和多模态数据库。实验显示，RL-QR在多模态和词汇检索器中分别取得了显著的性能提升，但在语义和混合检索器中效果不佳，这可能是因为训练不一致。研究结果表明，RL-QR有潜力彻底改变RAG系统的查询优化，提供一种可扩展的、无需注释的解决方案，同时指出在语义检索环境中需要进一步改进。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）系统严重依赖有效的查询制定来解锁外部知识，但优化多样化的、非结构化的现实世界文档中的查询仍然是一个挑战。

Method: 我们引入了RL-QR，这是一个强化学习框架，用于特定检索器的查询重写，它消除了对人工标注数据集的需求，并扩展了对文本-only和多模态数据库的适用性。通过合成场景-问题对并利用广义奖励策略优化（GRPO），RL-QR训练针对特定检索器的查询重写器，从而提高各种领域中的检索性能。

Result: 在工业内部数据上的实验表明，显著的改进，其中RL-QR_{multi-modal}在多模态RAG中实现了NDCG@3的11%相对增长，而RL-QR_{lexical}则为词汇检索器带来了9%的增长。然而，在语义和混合检索器方面仍然存在挑战，其中重写器未能提高性能，这可能是因为训练不一致。

Conclusion: 我们的研究结果表明，RL-QR有潜力彻底改变RAG系统的查询优化，为现实世界的检索任务提供一种可扩展的、无需注释的解决方案，同时在语义检索环境中指明了进一步改进的方向。

Abstract: Retrieval-Augmented Generation (RAG) systems rely heavily on effective query
formulation to unlock external knowledge, yet optimizing queries for diverse,
unstructured real-world documents remains a challenge. We introduce
\textbf{RL-QR}, a reinforcement learning framework for retriever-specific query
rewriting that eliminates the need for human-annotated datasets and extends
applicability to both text-only and multi-modal databases. By synthesizing
scenario-question pairs and leveraging Generalized Reward Policy Optimization
(GRPO), RL-QR trains query rewriters tailored to specific retrievers, enhancing
retrieval performance across varied domains. Experiments on industrial in-house
data demonstrate significant improvements, with
$\text{RL-QR}_{\text{multi-modal}}$ achieving an 11\% relative gain in NDCG@3
for multi-modal RAG and $\text{RL-QR}_{\text{lexical}}$ yielding a 9\% gain for
lexical retrievers. However, challenges persist with semantic and hybrid
retrievers, where rewriters failed to improve performance, likely due to
training misalignments. Our findings highlight RL-QR's potential to
revolutionize query optimization for RAG systems, offering a scalable,
annotation-free solution for real-world retrieval tasks, while identifying
avenues for further refinement in semantic retrieval contexts.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [78] [DSBC : Data Science task Benchmarking with Context engineering](https://arxiv.org/abs/2507.23336)
*Ram Mohan Rao Kadiyala,Siddhant Gupta,Jebish Purbey,Giulio Martini,Suman Debnath,Hamza Farooq*

Main category: cs.AI

TL;DR: 本文介绍了一个针对数据科学代理的全面基准测试，评估了三种大型语言模型在不同方法下的表现，并探讨了温度参数和提示问题对结果的影响。研究结果揭示了模型间的性能差异，并为未来研究提供了基础。


<details>
  <summary>Details</summary>
Motivation: 尽管数据科学代理已被广泛采用，但系统性的基准测试仍较为缺乏。本文旨在填补这一空白，提供一个全面的基准测试来评估这些代理的有效性和局限性。

Method: 本文通过观察商业应用中的使用情况，构建了一个反映真实用户交互的基准测试。评估了三种大型语言模型（Claude-4.0-Sonnet、Gemini-2.5-Flash 和 OpenAI-o4-Mini）在三种方法下的表现：零样本上下文工程、多步骤上下文工程以及使用 SmolAgent。此外，还探讨了温度参数对整体和任务特定结果的影响。

Result: 研究结果揭示了不同模型和方法之间的显著性能差异，并强调了影响实际部署的关键因素。同时，还发现模型对常见的提示问题（如数据泄露和略微模糊的指令）具有敏感性。

Conclusion: 本文引入了一个全面的基准测试，旨在评估数据科学代理的有效性和局限性。研究结果揭示了不同模型和方法之间的显著性能差异，并强调了影响实际部署的关键因素。该基准数据集和评估框架为未来更强大和有效的数据科学代理研究提供了基础。

Abstract: Recent advances in large language models (LLMs) have significantly impacted
data science workflows, giving rise to specialized data science agents designed
to automate analytical tasks. Despite rapid adoption, systematic benchmarks
evaluating the efficacy and limitations of these agents remain scarce. In this
paper, we introduce a comprehensive benchmark specifically crafted to reflect
real-world user interactions with data science agents by observing usage of our
commercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,
Gemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with
context engineering, multi-step with context engineering, and with SmolAgent.
Our benchmark assesses performance across a diverse set of eight data science
task categories, additionally exploring the sensitivity of models to common
prompting issues, such as data leakage and slightly ambiguous instructions. We
further investigate the influence of temperature parameters on overall and
task-specific outcomes for each model and approach. Our findings reveal
distinct performance disparities among the evaluated models and methodologies,
highlighting critical factors that affect practical deployment. The benchmark
dataset and evaluation framework introduced herein aim to provide a foundation
for future research of more robust and effective data science agents.

</details>


### [79] [TextQuests: How Good are LLMs at Text-Based Video Games?](https://arxiv.org/abs/2507.23701)
*Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks*

Main category: cs.AI

TL;DR: 本文提出了一种新的基准TextQuests，用于评估AI代理在需要长期上下文推理的探索性环境中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有代理基准无法充分捕捉代理在需要持续、自主推理的探索性环境中操作的能力，因此需要一个更有效的评估方法。

Method: 基于Infocom互动小说游戏套件，创建了一个文本基准，用于评估大型语言模型代理的自我包含问题解决能力。

Result: TextQuests基准能够有效评估AI代理在需要试错学习和持续解决问题的单个交互会话中的内在长期上下文推理能力。

Conclusion: 本文介绍了TextQuests基准，旨在评估AI代理在需要长期上下文推理的探索性环境中的自主操作能力。

Abstract: Evaluating AI agents within complex, interactive environments that mirror
real-world challenges is critical for understanding their practical
capabilities. While existing agent benchmarks effectively assess skills like
tool use or performance on structured tasks, they often do not fully capture an
agent's ability to operate autonomously in exploratory environments that demand
sustained, self-directed reasoning over a long and growing context. To spur the
development of agents capable of more robust intrinsic reasoning over long
horizons, we introduce TextQuests, a benchmark based on the Infocom suite of
interactive fiction games. These text-based adventures, which can take human
players over 30 hours and require hundreds of precise actions to solve, serve
as an effective proxy for evaluating AI agents on focused, stateful tasks. The
benchmark is specifically designed to assess an LLM agent's capacity for
self-contained problem-solving by precluding the use of external tools, thereby
focusing on intrinsic long-context reasoning capabilities in an exploratory
environment characterized by the need for trial-and-error learning and
sustained problem-solving within a single interactive session. We release
TextQuests at https://textquests.ai.

</details>


### [80] [Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving](https://arxiv.org/abs/2507.23726)
*Luoxin Chen,Jinming Gu,Liankai Huang,Wenhao Huang,Zhicheng Jiang,Allan Jie,Xiaoran Jin,Xing Jin,Chenggang Li,Kaijing Ma,Cheng Ren,Jiawei Shen,Wenlei Shi,Tong Sun,He Sun,Jiahui Wang,Siran Wang,Zhihong Wang,Chenrui Wei,Shufa Wei,Yonghui Wu,Yuchen Wu,Yihang Xia,Huajian Xin,Fan Yang,Huaiyuan Ying,Hongyi Yuan,Zheng Yuan,Tianyang Zhan,Chi Zhang,Yue Zhang,Ge Zhang,Tianyun Zhao,Jianqiu Zhao,Yichi Zhou,Thomas Hanwen Zhu*

Main category: cs.AI

TL;DR: 本文介绍了一种新的数学推理模型Seed-Prover和一个几何推理引擎Seed-Geometry，它们在多个数学竞赛问题上表现出色，代表了自动化数学推理的重大进步。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在利用强化学习进行长链式思维推理方面表现出强大的数学推理能力，但它们在定理证明方面仍然面临挑战，因为仅使用自然语言时缺乏明确的监督信号。

Method: 提出了一种基于引理风格的完整证明推理模型Seed-Prover，并设计了三种测试时推理策略以解决IMO级别的竞赛问题。此外，还引入了一个几何推理引擎Seed-Geometry来解决Lean中缺乏几何支持的问题。

Result: Seed-Prover证明了78.1%的正式化过去IMO问题，达到了MiniF2F的饱和状态，并在PutnamBench上超过了50%，显著优于之前的最先进水平。Seed-Geometry在形式化几何引擎中表现优于之前的方法。使用这两个系统参加了IMO 2025并成功证明了6个问题中的5个。

Conclusion: 本工作在自动化数学推理方面取得了重大进展，展示了形式化验证与长链式思维推理的有效性。

Abstract: LLMs have demonstrated strong mathematical reasoning abilities by leveraging
reinforcement learning with long chain-of-thought, yet they continue to
struggle with theorem proving due to the lack of clear supervision signals when
solely using natural language. Dedicated domain-specific languages like Lean
provide clear supervision via formal verification of proofs, enabling effective
training through reinforcement learning. In this work, we propose
\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover
can iteratively refine its proof based on Lean feedback, proved lemmas, and
self-summarization. To solve IMO-level contest problems, we design three
test-time inference strategies that enable both deep and broad reasoning.
Seed-Prover proves $78.1\%$ of formalized past IMO problems, saturates MiniF2F,
and achieves over 50\% on PutnamBench, outperforming the previous
state-of-the-art by a large margin. To address the lack of geometry support in
Lean, we introduce a geometry reasoning engine \textbf{Seed-Geometry}, which
outperforms previous formal geometry engines. We use these two systems to
participate in IMO 2025 and fully prove 5 out of 6 problems. This work
represents a significant advancement in automated mathematical reasoning,
demonstrating the effectiveness of formal verification with long
chain-of-thought reasoning.

</details>


### [81] [CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks](https://arxiv.org/abs/2507.23751)
*Ping Yu,Jack Lanchantin,Tianlu Wang,Weizhe Yuan,Olga Golovneva,Ilia Kulikov,Sainbayar Sukhbaatar,Jason Weston,Jing Xu*

Main category: cs.AI

TL;DR: CoT-Self-Instruct是一种合成数据生成方法，通过Chain-of-Thought引导LLMs生成高质量、复杂度相似的新提示，并通过自动指标过滤。该方法在多个任务中表现优于现有数据集和方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高LLM训练数据的质量和复杂度，需要一种有效的合成数据生成方法。

Method: CoT-Self-Instruct是一种合成数据生成方法，通过Chain-of-Thought（CoT）引导LLMs进行推理和规划，然后生成高质量、复杂度相似的新合成提示，并使用自动指标进行过滤。

Result: 在可验证推理任务中，CoT-Self-Instruct生成的合成数据在MATH500、AMC23、AIME24和GPQA-Diamond上显著优于现有数据集；在非可验证指令遵循任务中，其性能超过了人类或标准自指导提示。

Conclusion: CoT-Self-Instruct生成的合成数据在可验证推理和非可验证指令遵循任务中均表现出色，优于现有数据集和方法。

Abstract: We propose CoT-Self-Instruct, a synthetic data generation method that
instructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the
given seed tasks, and then to generate a new synthetic prompt of similar
quality and complexity for use in LLM training, followed by filtering for
high-quality data with automatic metrics. In verifiable reasoning, our
synthetic data significantly outperforms existing training datasets, such as
s1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For
non-verifiable instruction-following tasks, our method surpasses the
performance of human or standard self-instruct prompts on both AlpacaEval 2.0
and Arena-Hard.

</details>


### [82] [SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model](https://arxiv.org/abs/2507.23773)
*Mingkai Deng,Jinyu Hou,Yilin Shen,Hongxia Jin,Graham Neubig,Zhiting Hu,Eric Xing*

Main category: cs.AI

TL;DR: 本文介绍了SimuRA，一种基于世界模型的通用代理推理架构，能够克服自回归LLM的局限性，并在网页浏览任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前的AI代理方法在可扩展性和通用性方面存在不足，并且受到自回归LLM的根本限制。而人类是能够通过心理模拟行动和计划结果的通用代理，因此需要一种更通用和强大的AI代理。

Method: 引入了SimuRA，这是一种目标导向的通用代理推理架构，基于任何环境中的最优代理原则，并通过引入世界模型进行规划来克服自回归推理的局限性。

Result: 实验表明，SimuRA在困难的网页浏览任务中显著提高了飞行搜索的成功率，并且基于世界模型的规划显示出相对于自回归规划的优势。

Conclusion: 我们对基于LLMs训练单一、通用的智能体模型的可能性感到兴奋，这种模型可以在所有环境中表现出超智能的行为。

Abstract: AI agents built on large language models (LLMs) hold enormous promise, but
current practice focuses on a one-task-one-agent approach, which not only falls
short of scalability and generality, but also suffers from the fundamental
limitations of autoregressive LLMs. On the other hand, humans are general
agents who reason by mentally simulating the outcomes of their actions and
plans. Moving towards a more general and powerful AI agent, we introduce
SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based
on a principled formulation of optimal agent in any environment, \modelname
overcomes the limitations of autoregressive reasoning by introducing a world
model for planning via simulation. The generalized world model is implemented
using LLM, which can flexibly plan in a wide range of environments using the
concept-rich latent space of natural language. Experiments on difficult web
browsing tasks show that \modelname improves the success of flight search from
0\% to 32.2\%. World-model-based planning, in particular, shows consistent
advantage of up to 124\% over autoregressive planning, demonstrating the
advantage of world model simulation as a reasoning paradigm. We are excited
about the possibility for training a single, general agent model based on LLMs
that can act superintelligently in all environments. To start, we make SimuRA,
a web-browsing agent built on \modelname with pretrained LLMs, available as a
research demo for public testing.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [83] [Exploring Dynamic Parameters for Vietnamese Gender-Independent ASR](https://arxiv.org/abs/2507.22964)
*Sotheara Leang,Éric Castelli,Dominique Vaufreydaz,Sethserey Sam*

Main category: eess.AS

TL;DR: 本研究通过在频谱子带重心频率的比率平面上使用极坐标参数来捕捉语音的动态特性，并将其与Mel频率倒谱系数结合，以提高越南语自动语音识别的性能。结果表明，所提出的参数能够显著降低词错误率，并表现出更好的性别独立性。


<details>
  <summary>Details</summary>
Motivation: 语音信号的动态特性提供了时间信息，在增强自动语音识别（ASR）中起着重要作用。

Method: 使用极坐标参数在频谱子带重心频率（SSCFs）的比率平面上表征声学过渡，以捕捉语音的动态特性并最小化频谱变化。这些动态参数与Mel频率倒谱系数（MFCCs）结合用于越南语自动语音识别，以捕获更详细的频谱信息。SSCF0被用作基频（F0）的伪特征来稳健地描述调制信息。

Result: 提出的参数显著降低了词错误率，并且比基线MFCCs具有更大的性别独立性。

Conclusion: 提出的参数显著降低了词错误率，并且比基线MFCCs具有更大的性别独立性。

Abstract: The dynamic characteristics of speech signal provides temporal information
and play an important role in enhancing Automatic Speech Recognition (ASR). In
this work, we characterized the acoustic transitions in a ratio plane of
Spectral Subband Centroid Frequencies (SSCFs) using polar parameters to capture
the dynamic characteristics of the speech and minimize spectral variation.
These dynamic parameters were combined with Mel-Frequency Cepstral Coefficients
(MFCCs) in Vietnamese ASR to capture more detailed spectral information. The
SSCF0 was used as a pseudo-feature for the fundamental frequency (F0) to
describe the tonal information robustly. The findings showed that the proposed
parameters significantly reduce word error rates and exhibit greater gender
independence than the baseline MFCCs.

</details>


### [84] [MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks](https://arxiv.org/abs/2507.23511)
*Yadong Niu,Tianzi Wang,Heinrich Dinkel,Xingwei Sun,Jiahao Zhou,Gang Li,Jizhong Liu,Xunying Liu,Junbo Zhang,Jian Luan*

Main category: eess.AS

TL;DR: 本文提出MECAT基准和DATE评估指标，以改进音频模型的细粒度理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前基准由于数据标注和评估指标的限制，无法可靠地区分通用和高度详细的模型输出，因此需要一种更精细的评估方法和基准。

Method: MECAT是通过一个集成专业专家模型分析与思维链大型语言模型推理的管道生成的。DATE指标通过结合单样本语义相似性和跨样本区分性来惩罚通用术语并奖励详细描述。

Result: 本文提出了MECAT基准和DATE指标，并对最先进的音频模型进行了全面评估，提供了关于它们当前能力和限制的新见解。

Conclusion: 本文介绍了MECAT，这是一个用于细粒度音频理解任务的多专家构建基准。同时提出了一种新的评估指标DATE，以更好地衡量模型输出的详细程度。实验结果揭示了当前最先进的音频模型的能力和局限性。

Abstract: While large audio-language models have advanced open-ended audio
understanding, they still fall short of nuanced human-level comprehension. This
gap persists largely because current benchmarks, limited by data annotations
and evaluation metrics, fail to reliably distinguish between generic and highly
detailed model outputs. To this end, this work introduces MECAT, a Multi-Expert
Constructed Benchmark for Fine-Grained Audio Understanding Tasks. Generated via
a pipeline that integrates analysis from specialized expert models with
Chain-of-Thought large language model reasoning, MECAT provides
multi-perspective, fine-grained captions and open-set question-answering pairs.
The benchmark is complemented by a novel metric: DATE (Discriminative-Enhanced
Audio Text Evaluation). This metric penalizes generic terms and rewards
detailed descriptions by combining single-sample semantic similarity with
cross-sample discriminability. A comprehensive evaluation of state-of-the-art
audio models is also presented, providing new insights into their current
capabilities and limitations. The data and code are available at
https://github.com/xiaomi-research/mecat

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [85] [Counterfactual Evaluation for Blind Attack Detection in LLM-based Evaluation Systems](https://arxiv.org/abs/2507.23453)
*Lijia Liu,Takumi Kondo,Kyohei Atarashi,Koh Takeuchi,Jiyi Li,Shigeru Saito,Hisashi Kashima*

Main category: cs.CR

TL;DR: 本文研究了针对基于LLM的评估系统的防御措施，提出了SE+CFE框架，通过反事实评估提高安全性。


<details>
  <summary>Details</summary>
Motivation: 本文研究了针对基于LLM的评估系统的防御措施，以应对提示注入攻击。我们形式化了一类称为盲攻击的威胁，其中候选答案是独立于真实答案构造的，以欺骗评估者。

Method: 我们提出了一种框架，将标准评估（SE）与反事实评估（CFE）相结合，该框架会针对一个故意错误的基准答案重新评估提交内容。

Result: 实验表明，标准评估极易受到攻击，而我们的SE+CFE框架在最小性能损失的情况下显著提高了攻击检测能力。

Conclusion: 实验表明，虽然标准评估极易受到攻击，但我们的SE+CFE框架通过最小的性能损失显著提高了安全性。

Abstract: This paper investigates defenses for LLM-based evaluation systems against
prompt injection. We formalize a class of threats called blind attacks, where a
candidate answer is crafted independently of the true answer to deceive the
evaluator. To counter such attacks, we propose a framework that augments
Standard Evaluation (SE) with Counterfactual Evaluation (CFE), which
re-evaluates the submission against a deliberately false ground-truth answer.
An attack is detected if the system validates an answer under both standard and
counterfactual conditions. Experiments show that while standard evaluation is
highly vulnerable, our SE+CFE framework significantly improves security by
boosting attack detection with minimal performance trade-offs.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [86] [Holistic Evaluations of Topic Models](https://arxiv.org/abs/2507.23364)
*Thomas Compton*

Main category: cs.IR

TL;DR: 本文从数据库的角度评估了主题模型，通过分析1140次BERTopic模型运行，识别了优化模型参数的权衡，并反思了这些发现对主题模型解释和负责任使用的意义。


<details>
  <summary>Details</summary>
Motivation: 主题模型在商业和学术界越来越受欢迎，但它们可能成为'黑箱'，用户输入数据并接受输出作为准确的摘要而不进行审查。因此，需要评估主题模型以了解其优缺点。

Method: 本文通过分析1140次BERTopic模型运行，从数据库的角度评估了主题模型。

Result: 本文通过分析1140次BERTopic模型运行，识别了优化模型参数的权衡，并反思了这些发现对主题模型解释和负责任使用的意义。

Conclusion: 本文从数据库的角度评估了主题模型，旨在识别优化模型参数的权衡，并反思这些发现对主题模型解释和负责任使用的意义。

Abstract: Topic models are gaining increasing commercial and academic interest for
their ability to summarize large volumes of unstructured text. As unsupervised
machine learning methods, they enable researchers to explore data and help
general users understand key themes in large text collections. However, they
risk becoming a 'black box', where users input data and accept the output as an
accurate summary without scrutiny. This article evaluates topic models from a
database perspective, drawing insights from 1140 BERTopic model runs. The goal
is to identify trade-offs in optimizing model parameters and to reflect on what
these findings mean for the interpretation and responsible use of topic models

</details>
