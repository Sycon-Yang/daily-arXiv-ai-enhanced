<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 37]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.RO](#cs.RO) [Total: 2]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CV](#cs.CV) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Noise or Nuance: An Investigation Into Useful Information and Filtering For LLM Driven AKBC](https://arxiv.org/abs/2509.08903)
*Alex Clay,Ernesto Jiménez-Ruiz,Pranava Madhyastha*

Main category: cs.CL

TL;DR: 本研究探讨了在受限环境下如何提高LLM生成三元组的质量，发现额外信息有助于生成，LLM能有效过滤低质量三元组，且解析时的权衡因环境而异。


<details>
  <summary>Details</summary>
Motivation: RAG和微调是提高LLM输出质量的流行策略，但在受限情况下（如2025 LM-KBC挑战）这些技术受到限制。

Method: 研究了三元组完成任务的三个方面：生成、质量保证和LLM响应解析。

Result: 额外的信息可以提高生成质量，LLM可以有效地过滤低质量的三元组，并且LLM响应解析中的灵活性与一致性之间的权衡取决于设置。

Conclusion: 在受限设置中，额外的信息可以提高生成质量，LLM可以有效地过滤低质量的三元组，并且LLM响应解析中的灵活性与一致性之间的权衡取决于设置。

Abstract: RAG and fine-tuning are prevalent strategies for improving the quality of LLM
outputs. However, in constrained situations, such as that of the 2025 LM-KBC
challenge, such techniques are restricted. In this work we investigate three
facets of the triple completion task: generation, quality assurance, and LLM
response parsing. Our work finds that in this constrained setting: additional
information improves generation quality, LLMs can be effective at filtering
poor quality triples, and the tradeoff between flexibility and consistency with
LLM response parsing is setting dependent.

</details>


### [2] [Automated Evidence Extraction and Scoring for Corporate Climate Policy Engagement: A Multilingual RAG Approach](https://arxiv.org/abs/2509.08907)
*Imene Kolli,Ario Saeid Vaghefi,Chiara Colesanti Senni,Shantam Raj,Markus Leippold*

Main category: cs.CL

TL;DR: 本文提出了一种AI辅助框架，利用检索增强生成来自动化从大规模文本数据中提取相关证据的过程，结果表明该方法能有效加速证据提取，但需要人类专家的介入以确保准确性。


<details>
  <summary>Details</summary>
Motivation: InfluenceMap的LobbyMap平台在监测企业气候政策参与方面取得了进展，但评估过程仍需大量手动操作，耗时且容易出错。

Method: 提出了一种AI辅助框架，利用检索增强生成来自动化从大规模文本数据中提取相关证据的过程。

Result: 布局感知解析、Nomic嵌入模型和少样本提示策略的组合在从多语言企业文档中提取和分类证据方面表现最佳。

Conclusion: 虽然自动化RAG系统有效加速了证据提取，但分析的细微性质需要采用人机结合的方法，其中技术增强而非取代专家判断以确保准确性。

Abstract: InfluenceMap's LobbyMap Platform monitors the climate policy engagement of
over 500 companies and 250 industry associations, assessing each entity's
support or opposition to science-based policy pathways for achieving the Paris
Agreement's goal of limiting global warming to 1.5{\deg}C. Although
InfluenceMap has made progress with automating key elements of the analytical
workflow, a significant portion of the assessment remains manual, making it
time- and labor-intensive and susceptible to human error. We propose an
AI-assisted framework to accelerate the monitoring of corporate climate policy
engagement by leveraging Retrieval-Augmented Generation to automate the most
time-intensive extraction of relevant evidence from large-scale textual data.
Our evaluation shows that a combination of layout-aware parsing, the Nomic
embedding model, and few-shot prompting strategies yields the best performance
in extracting and classifying evidence from multilingual corporate documents.
We conclude that while the automated RAG system effectively accelerates
evidence extraction, the nuanced nature of the analysis necessitates a
human-in-the-loop approach where the technology augments, rather than replaces,
expert judgment to ensure accuracy.

</details>


### [3] [Documents Are People and Words Are Items: A Psychometric Approach to Textual Data with Contextual Embeddings](https://arxiv.org/abs/2509.08920)
*Jinsong Chen*

Main category: cs.CL

TL;DR: 该研究提出了一种新的心理测量方法，利用大型语言模型的上下文嵌入将文本数据转换为适合心理测量分析的响应数据。该方法分为两个阶段：获取上下文分数和进行心理测量分析。实验结果表明，该方法能够揭示文本数据中的潜在知识维度和模式。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在引入一种新的心理测量方法，用于分析使用大型语言模型的文本数据。通过利用上下文嵌入创建上下文分数，将文本数据转换为适合心理测量分析的响应数据。

Method: 该方法包括两个阶段：获取上下文分数和进行心理测量分析。在第一阶段，使用自然语言处理技术和基于编码器的Transformer模型来识别常见关键词并生成上下文分数。在第二阶段，采用各种类型的因子分析，包括探索性因子分析和双因子模型，以提取和定义潜在因子，确定因子相关性，并识别与每个因子最相关的词语。

Result: 在Wiki STEM语料库上的实验结果表明，该方法能够揭示文本数据中的潜在知识维度和模式。

Conclusion: 该方法不仅增强了文本数据的心理测量分析，还为教育、心理学和法律等领域中富含文本信息的应用提供了前景。

Abstract: This research introduces a novel psychometric method for analyzing textual
data using large language models. By leveraging contextual embeddings to create
contextual scores, we transform textual data into response data suitable for
psychometric analysis. Treating documents as individuals and words as items,
this approach provides a natural psychometric interpretation under the
assumption that certain keywords, whose contextual meanings vary significantly
across documents, can effectively differentiate documents within a corpus. The
modeling process comprises two stages: obtaining contextual scores and
performing psychometric analysis. In the first stage, we utilize natural
language processing techniques and encoder based transformer models to identify
common keywords and generate contextual scores. In the second stage, we employ
various types of factor analysis, including exploratory and bifactor models, to
extract and define latent factors, determine factor correlations, and identify
the most significant words associated with each factor. Applied to the Wiki
STEM corpus, our experimental results demonstrate the method's potential to
uncover latent knowledge dimensions and patterns within textual data. This
approach not only enhances the psychometric analysis of textual data but also
holds promise for applications in fields rich in textual information, such as
education, psychology, and law.

</details>


### [4] [BRoverbs -- Measuring how much LLMs understand Portuguese proverbs](https://arxiv.org/abs/2509.08960)
*Thales Sales Almeida,Giovana Kerche Bonás,João Guilherme Alves Santos*

Main category: cs.CL

TL;DR: 本文介绍了BRoverbs数据集，用于评估大语言模型在葡萄牙语环境中的表现，填补了现有评估的空白。


<details>
  <summary>Details</summary>
Motivation: 现有评估在葡萄牙语中仍然有限，通常依赖于可能无法完全捕捉语言细微差别或文化参考的翻译数据集。此外，本土葡萄牙语数据集主要集中在结构化国家考试或社交媒体互动的情感分析上，留下了评估更广泛语言理解的空白。

Method: 引入BRoverbs数据集，通过巴西谚语评估大语言模型的性能。

Result: BRoverbs数据集已发布，可用于评估大语言模型在葡萄牙语环境中的表现。

Conclusion: BRoverbs旨在为葡萄牙语大语言模型提供一个新的评估工具，有助于推动区域相关的基准测试。

Abstract: Large Language Models (LLMs) exhibit significant performance variations
depending on the linguistic and cultural context in which they are applied.
This disparity signals the necessity of mature evaluation frameworks that can
assess their capabilities in specific regional settings. In the case of
Portuguese, existing evaluations remain limited, often relying on translated
datasets that may not fully capture linguistic nuances or cultural references.
Meanwhile, native Portuguese-language datasets predominantly focus on
structured national exams or sentiment analysis of social media interactions,
leaving gaps in evaluating broader linguistic understanding. To address this
limitation, we introduce BRoverbs, a dataset specifically designed to assess
LLM performance through Brazilian proverbs. Proverbs serve as a rich linguistic
resource, encapsulating cultural wisdom, figurative expressions, and complex
syntactic structures that challenge the model comprehension of regional
expressions. BRoverbs aims to provide a new evaluation tool for
Portuguese-language LLMs, contributing to advancing regionally informed
benchmarking. The benchmark is available at
https://huggingface.co/datasets/Tropic-AI/BRoverbs.

</details>


### [5] [Can Vision-Language Models Solve Visual Math Equations?](https://arxiv.org/abs/2509.09013)
*Monjoy Narayan Choudhury,Junling Wang,Yifan Hou,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 本文研究了VLMs在视觉方程求解中的局限性，发现计数是主要瓶颈，多步骤推理存在挑战，且随着方程复杂度增加，符号推理成为限制因素。


<details>
  <summary>Details</summary>
Motivation: 研究VLMs在需要集成感知和符号计算的任务中的表现，特别是在视觉方程求解中的局限性。

Method: 通过视觉方程求解研究VLMs的局限性，将任务分解为系数计数和变量识别，并观察到多步骤视觉推理中的挑战。

Result: VLMs在文本方程上表现良好，但在视觉基础方程上失败；计数是主要瓶颈，即使识别准确；多步骤推理引入额外错误；方程复杂度增加时符号推理成为限制因素。

Conclusion: 这些发现揭示了当前VLMs的关键弱点，并指出了在视觉基础数学推理方面的未来改进方向。

Abstract: Despite strong performance in visual understanding and language-based
reasoning, Vision-Language Models (VLMs) struggle with tasks requiring
integrated perception and symbolic computation. We study this limitation
through visual equation solving, where mathematical equations are embedded in
images, variables are represented by object icons, and coefficients must be
inferred by counting. While VLMs perform well on textual equations, they fail
on visually grounded counterparts. To understand this gap, we decompose the
task into coefficient counting and variable recognition, and find that counting
is the primary bottleneck, even when recognition is accurate. We also observe
that composing recognition and reasoning introduces additional errors,
highlighting challenges in multi-step visual reasoning. Finally, as equation
complexity increases, symbolic reasoning itself becomes a limiting factor.
These findings reveal key weaknesses in current VLMs and point toward future
improvements in visually grounded mathematical reasoning.

</details>


### [6] [Stated Preference for Interaction and Continued Engagement (SPICE): Evaluating an LLM's Willingness to Re-engage in Conversation](https://arxiv.org/abs/2509.09043)
*Thomas Manuel Rost,Martina Figlia,Bernd Wallraff*

Main category: cs.CL

TL;DR: SPICE是一种简单且有效的诊断信号，用于衡量大型语言模型在回顾用户行为后是否愿意继续互动。研究显示，SPICE能够清晰地区分用户语气，并在多种统计测试中保持决定性。此外，SPICE提供了与虐待分类不同的信号，表明它在模型审计中具有重要价值。


<details>
  <summary>Details</summary>
Motivation: 本文旨在引入并评估SPICE，这是一种简单的诊断信号，用于衡量大型语言模型在回顾用户行为后是否愿意继续互动。

Method: SPICE是一种通过询问大型语言模型一个关于其愿意在回顾一段简短的对话摘要后继续与用户互动的YES或NO问题而获得的诊断信号。研究使用了3种语气（友好、模糊、虐待）和10次互动的刺激集，测试了四种开放权重的聊天模型，在四种框架条件下进行了480次试验。

Result: SPICE能够清晰地区分用户语气。友好互动几乎一致选择继续（97.5%的YES），而虐待互动则强烈选择停止（17.9%的YES），模糊互动介于两者之间（60.4%的YES）。这种核心关联在多种依赖性意识统计测试中仍然决定性，包括Rao-Scott调整和集群排列测试。此外，SPICE提供了与虐待分类不同的信号。在模型未能识别虐待的情况下，它仍然强烈表示不希望继续互动（81%的时间）。探索性分析还揭示了一个显著的交互效应：在模糊情况下，描述研究背景的前言显著影响SPICE，但仅当转录文本作为单个文本块呈现时才有效。

Conclusion: SPICE被验证为一种稳健、低开销和可重复的工具，用于审计模型的倾向，通过提供直接的、关系的信号来补充现有的指标。

Abstract: We introduce and evaluate Stated Preference for Interaction and Continued
Engagement (SPICE), a simple diagnostic signal elicited by asking a Large
Language Model a YES or NO question about its willingness to re-engage with a
user's behavior after reviewing a short transcript. In a study using a 3-tone
(friendly, unclear, abusive) by 10-interaction stimulus set, we tested four
open-weight chat models across four framing conditions, resulting in 480
trials. Our findings show that SPICE sharply discriminates by user tone.
Friendly interactions yielded a near-unanimous preference to continue (97.5%
YES), while abusive interactions yielded a strong preference to discontinue
(17.9% YES), with unclear interactions falling in between (60.4% YES). This
core association remains decisive under multiple dependence-aware statistical
tests, including Rao-Scott adjustment and cluster permutation tests.
Furthermore, we demonstrate that SPICE provides a distinct signal from abuse
classification. In trials where a model failed to identify abuse, it still
overwhelmingly stated a preference not to continue the interaction (81% of the
time). An exploratory analysis also reveals a significant interaction effect: a
preamble describing the study context significantly impacts SPICE under
ambiguity, but only when transcripts are presented as a single block of text
rather than a multi-turn chat. The results validate SPICE as a robust,
low-overhead, and reproducible tool for auditing model dispositions,
complementing existing metrics by offering a direct, relational signal of a
model's state. All stimuli, code, and analysis scripts are released to support
replication.

</details>


### [7] [Improving LLM Safety and Helpfulness using SFT and DPO: A Study on OPT-350M](https://arxiv.org/abs/2509.09055)
*Piyush Pant*

Main category: cs.CL

TL;DR: 本研究分析了SFT和DPO技术在提升语言模型安全性与帮助性方面的作用，并发现结合这两种技术可以取得更好的效果。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨对齐技术（如SFT和DPO）在提升语言模型的安全性和帮助性方面的有效性。

Method: 本研究使用了Anthropic Helpful-Harmless RLHF数据集，训练并评估了四个模型：基础OPT350M、SFT模型、DPO模型以及同时使用SFT和DPO的模型。

Result: 结果表明，虽然SFT在所有指标上表现优于DPO，但结合SFT和DPO的模型在所有指标上均优于其他模型。

Conclusion: 本研究展示了SFT和DPO技术在提升语言模型安全性和帮助性方面的互补性，并提出了一个更稳健的对齐流程的基础。

Abstract: This research investigates the effectiveness of alignment techniques,
Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and a
combined SFT+DPO approach on improving the safety and helpfulness of the
OPT-350M language model. Utilizing the Anthropic Helpful-Harmless RLHF dataset,
we train and evaluate four models: the base OPT350M, an SFT model, a DPO model,
and a model trained with both SFT and DPO. We introduce three key evaluation
metrics: Harmlessness Rate (HmR), Helpfulness Rate (HpR), and a Combined
Alignment Score (CAS), all derived from reward model outputs. The results show
that while SFT outperforms DPO, The combined SFT+DPO model outperforms all
others across all metrics, demonstrating the complementary nature of these
techniques. Our findings also highlight challenges posed by noisy data, limited
GPU resources, and training constraints. This study offers a comprehensive view
of how fine-tuning strategies affect model alignment and provides a foundation
for more robust alignment pipelines in future work.

</details>


### [8] [MR-UIE: Multi-Perspective Reasoning with Reinforcement Learning for Universal Information Extraction](https://arxiv.org/abs/2509.09082)
*Zhongqiu Li,Shiquan Wang,Ruiyu Fang,Mengjiao Bao,Zhenhe Wu,Shuangyong Song,Yongxiang Li,Zhongjiang He*

Main category: cs.CL

TL;DR: 本文提出了一种结合强化学习和多视角推理的方法（MR-UIE），以提升大型语言模型在通用信息抽取任务中的表现。实验结果表明，该方法在多个基准测试中表现出色，并在复杂任务中显示出更强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通过上下文学习和指令调优来提高大型语言模型在通用信息抽取（UIE）任务中的性能，但仍然存在显著的局限性。需要一种更有效的方法来提升模型在结构化输出场景中的表现，尤其是在涉及复杂模式描述和多步骤推理的情况下。

Method: 提出将强化学习（RL）与多视角推理结合，以提升模型的泛化能力。工作将大型语言模型从被动的抽取器转变为积极的推理者，使其不仅能够理解要抽取的内容，还能理解如何进行推理。

Result: 实验结果表明，MR-UIE在多个信息抽取基准测试中 consistently 提升了不同领域的抽取准确性，并在一些数据集上超越了最先进的方法。同时，将多视角推理纳入强化学习显著增强了复杂信息抽取任务的泛化能力。

Conclusion: MR-UIE在多个信息抽取基准测试中表现出色，提升了不同领域的抽取准确性，并在一些数据集上超越了最先进的方法。此外，将多视角推理纳入强化学习显著增强了复杂信息抽取任务的泛化能力，突显了推理在挑战性场景中的关键作用。

Abstract: Large language models (LLMs) demonstrate robust capabilities across diverse
research domains. However, their performance in universal information
extraction (UIE) remains insufficient, especially when tackling structured
output scenarios that involve complex schema descriptions and require
multi-step reasoning. While existing approaches enhance the performance of LLMs
through in-context learning and instruction tuning, significant limitations
nonetheless persist. To enhance the model's generalization ability, we propose
integrating reinforcement learning (RL) with multi-perspective reasoning for
information extraction (IE) tasks. Our work transitions LLMs from passive
extractors to active reasoners, enabling them to understand not only what to
extract but also how to reason. Experiments conducted on multiple IE benchmarks
demonstrate that MR-UIE consistently elevates extraction accuracy across
domains and surpasses state-of-the-art methods on several datasets.
Furthermore, incorporating multi-perspective reasoning into RL notably enhances
generalization in complex IE tasks, underscoring the critical role of reasoning
in challenging scenarios.

</details>


### [9] [TigerCoder: A Novel Suite of LLMs for Code Generation in Bangla](https://arxiv.org/abs/2509.09101)
*Nishat Raihan,Antonios Anastasopoulos,Marcos Zampieri*

Main category: cs.CL

TL;DR: 本文介绍了第一个针对孟加拉语的代码大语言模型家族（1B & 9B），并提供了三个主要贡献：一个全面的孟加拉语代码指令数据集，用于编程领域适应；MBPP-Bangla，一个评估基准用于孟加拉语代码生成；以及TigerCoder家族的代码大语言模型，在Pass@1上比现有的多语言和通用孟加拉语大语言模型取得了显著的~11-18%性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管孟加拉语是第五大语言，但在大型语言模型（LLMs）中，特别是在代码生成方面，仍然代表性不足。这主要是由于缺乏高质量的数据来进行预训练和/或微调这些模型。

Method: 我们引入了第一个针对孟加拉语的代码大语言模型家族（1B & 9B），并提供了三个主要贡献：一个全面的孟加拉语代码指令数据集，用于编程领域适应；MBPP-Bangla，一个评估基准用于孟加拉语代码生成；以及TigerCoder家族的代码大语言模型，在Pass@1上比现有的多语言和通用孟加拉语大语言模型取得了显著的~11-18%性能提升。

Result: 我们引入了第一个针对孟加拉语的代码大语言模型家族（1B & 9B），并在Pass@1上比现有的多语言和通用孟加拉语大语言模型取得了显著的~11-18%性能提升。

Conclusion: 我们的研究显示，精心整理的高质量数据集可以克服小模型在低资源语言上的局限性。我们开源了所有资源以推动进一步的孟加拉语大语言模型研究。

Abstract: Despite being the 5th most spoken language, Bangla remains underrepresented
in Large Language Models (LLMs), particularly for code generation. This
primarily stems from the scarcity of high-quality data to pre-train and/or
finetune such models. Hence, we introduce the first dedicated family of Code
LLMs for Bangla (1B & 9B). We offer three major contributions: (1) a
comprehensive Bangla code instruction datasets for programming domain
adaptation; (2) MBPP-Bangla, an evaluation benchmark for Bangla code
generation; and (3) the TigerCoder-family of Code LLMs, achieving significant
~11-18% performance gains at Pass@1 over existing multilingual and
general-purpose Bangla LLMs. Our findings show that curated, high-quality
datasets can overcome limitations of smaller models for low-resource languages.
We open-source all resources to advance further Bangla LLM research.

</details>


### [10] [Compass-v3: Scaling Domain-Specific LLMs for Multilingual E-Commerce in Southeast Asia](https://arxiv.org/abs/2509.09121)
*Sophia Maria*

Main category: cs.CL

TL;DR: Compass-v3 is a vertical-domain Mixture-of-Experts (MoE) model designed for Southeast Asian e-commerce. It excels in specialized tasks, outperforms other large language models, and shows strong multilingual capabilities across various languages.


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) excel in general-domain applications, yet their performance often degrades in specialized tasks requiring domain-specific knowledge. E-commerce is particularly challenging due to noisy, heterogeneous, multilingual, and highly dynamic data.

Method: Compass-v3 is a vertical-domain Mixture-of-Experts (MoE) model with 245B total parameters and 71B active per token, designed for Southeast Asian e-commerce. It adopts fewer but larger experts, combined with hardware-efficient optimizations such as intra-node expert parallelism and a customized memcpy operator. The model is trained on 12T tokens of curated multilingual corpora and large-scale synthetic e-commerce instructions using a mixed-training strategy. To enhance alignment, Optimal-Transport Direct Preference Optimization (OTPO) is proposed.

Result: Compass-v3 delivers state-of-the-art e-commerce performance, surpassing DeepSeek-V3.1, GPT-4 series, and Qwen3-235B. It demonstrates strong multilingual capability across low-resource Southeast Asian languages and Portuguese while maintaining competitive performance on general benchmarks.

Conclusion: Compass-v3 demonstrates strong multilingual capability across low-resource Southeast Asian languages and Portuguese while sustaining competitive performance on general benchmarks. It has been widely applied in Shopee's industrial-scale e-commerce platform and is gradually replacing OpenAI's traffic, now accounting for over 70% of total LLM usage, highlighting its dual strengths in specialized commerce expertise and broad linguistic competence.

Abstract: Large language models (LLMs) excel in general-domain applications, yet their
performance often degrades in specialized tasks requiring domain-specific
knowledge. E-commerce is particularly challenging, as its data are noisy,
heterogeneous, multilingual, and highly dynamic. We present Compass-v3, a
vertical-domain Mixture-of-Experts (MoE) model with 245B total parameters and
71B active per token, designed for Southeast Asian e-commerce. Compass-v3
adopts fewer but larger experts, combined with hardware-efficient
optimizations-such as intra-node expert parallelism and a customized memcpy
operator-to maximize GPU utilization. The model is trained on 12T tokens of
curated multilingual corpora and large-scale synthetic e-commerce instructions
using a mixed-training strategy. To enhance alignment, we propose
Optimal-Transport Direct Preference Optimization (OTPO), which captures
token-level distinctions and improves instruction adherence in
commerce-specific scenarios. Extensive evaluations demonstrate that Compass-v3
delivers state-of-the-art e-commerce performance, surpassing DeepSeek-V3.1,
GPT-4 series, and Qwen3-235B. Moreover, Compass-v3 demonstrates strong
multilingual capability across low-resource Southeast Asian languages
(Indonesian, Thai, Filipino, Vietnamese, Malay, Taglog) and Portuguese while
sustaining competitive performance on general benchmarks. It has already been
widely applied in Shopee's industrial-scale e-commerce platform and is
gradually replacing OpenAI's traffic, now accounting for over 70\% of total LLM
usage, highlighting its dual strengths in specialized commerce expertise and
broad linguistic competence.

</details>


### [11] [Automated Classification of Tutors' Dialogue Acts Using Generative AI: A Case Study Using the CIMA Corpus](https://arxiv.org/abs/2509.09125)
*Liqun He,Jiaqi Xu*

Main category: cs.CL

TL;DR: 本研究探讨了生成式AI在自动化导师对话行为分类中的应用，结果显示GPT-4模型表现优异，表明生成式AI在教育对话分析中有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索生成式AI在自动化导师对话行为（DAs）分类中的应用，以减少传统手动编码所需的时间和精力。

Method: 本研究使用了开源的CIMA语料库，其中导师的回答被预先标注为四个DA类别。测试了GPT-3.5-turbo和GPT-4模型，并使用了定制提示。

Result: GPT-4模型达到了80%的准确率、加权F1分数0.81和Cohen's Kappa 0.74，超过了基线性能，表明与人工标注有显著的一致性。

Conclusion: 研究结果表明，生成式AI在DA分类中具有强大的潜力，可以提供一种高效且可访问的方法，对教育对话分析有重要意义。同时，研究强调了任务特定标签定义和上下文信息在提高自动标注质量中的重要性，并突出了使用生成式AI的伦理考虑和负责任的研究实践的必要性。

Abstract: This study explores the use of generative AI for automating the
classification of tutors' Dialogue Acts (DAs), aiming to reduce the time and
effort required by traditional manual coding. This case study uses the
open-source CIMA corpus, in which tutors' responses are pre-annotated into four
DA categories. Both GPT-3.5-turbo and GPT-4 models were tested using tailored
prompts. Results show that GPT-4 achieved 80% accuracy, a weighted F1-score of
0.81, and a Cohen's Kappa of 0.74, surpassing baseline performance and
indicating substantial agreement with human annotations. These findings suggest
that generative AI has strong potential to provide an efficient and accessible
approach to DA classification, with meaningful implications for educational
dialogue analysis. The study also highlights the importance of task-specific
label definitions and contextual information in enhancing the quality of
automated annotation. Finally, it underscores the ethical considerations
associated with the use of generative AI and the need for responsible and
transparent research practices. The script of this research is publicly
available at
https://github.com/liqunhe27/Generative-AI-for-educational-dialogue-act-tagging.

</details>


### [12] [ViRanker: A BGE-M3 & Blockwise Parallel Transformer Cross-Encoder for Vietnamese Reranking](https://arxiv.org/abs/2509.09131)
*Phuong-Nam Dang,Kieu-Linh Nguyen,Thanh-Hieu Pham*

Main category: cs.CL

TL;DR: 本文提出了一种针对越南语的交叉编码器重排序模型ViRanker，通过精心设计的架构和数据整理，在性能上取得了显著提升，并为其他资源较少的语言提供了参考。


<details>
  <summary>Details</summary>
Motivation: 越南语是一种资源较少的语言，具有复杂的语法和变音符号，缺乏有效的重排序模型。

Method: ViRanker基于BGE-M3编码器并结合了Blockwise Parallel Transformer，使用8 GB的精选语料库进行训练，并通过混合硬负采样进行微调。

Result: ViRanker在MMARCO-VI基准测试中表现出色，超越了多语言基线，并与PhoRanker竞争激烈。

Conclusion: 本文展示了ViRanker模型在越南语检索任务中的有效性，并表明通过精心的架构调整和数据整理，可以提升其他资源较少语言的重排序性能。

Abstract: This paper presents ViRanker, a cross-encoder reranking model tailored to the
Vietnamese language. Built on the BGE-M3 encoder and enhanced with the
Blockwise Parallel Transformer, ViRanker addresses the lack of competitive
rerankers for Vietnamese, a low-resource language with complex syntax and
diacritics. The model was trained on an 8 GB curated corpus and fine-tuned with
hybrid hard-negative sampling to strengthen robustness. Evaluated on the
MMARCO-VI benchmark, ViRanker achieves strong early-rank accuracy, surpassing
multilingual baselines and competing closely with PhoRanker. By releasing the
model openly on Hugging Face, we aim to support reproducibility and encourage
wider adoption in real-world retrieval systems. Beyond Vietnamese, this study
illustrates how careful architectural adaptation and data curation can advance
reranking in other underrepresented languages.

</details>


### [13] [LITcoder: A General-Purpose Library for Building and Comparing Encoding Models](https://arxiv.org/abs/2509.09152)
*Taha Binhuraib,Ruimin Gao,Anna A. Ivanova*

Main category: cs.CL

TL;DR: LITcoder是一个开源库，用于构建和基准测试神经编码模型。它提供了标准化工具，用于对齐连续刺激与脑数据，将刺激转换为表示特征，将这些特征映射到脑数据，并评估模型在保留数据上的预测性能。该库实现了模块化流程，涵盖广泛的方法设计选择，使研究人员可以轻松组合、比较和扩展编码模型而无需重新发明核心基础设施。


<details>
  <summary>Details</summary>
Motivation: 为了降低编码模型实现的技术门槛，促进模型和数据集之间的系统比较，促进方法严谨性，并加速高质量高性能预测模型的开发，作者引入了LITcoder。

Method: LITcoder是一个开源库，用于构建和基准测试神经编码模型。它提供标准化工具，用于对齐连续刺激（例如文本和语音）与脑数据，将刺激转换为表示特征，将这些特征映射到脑数据，并评估模型在保留数据上的预测性能。该库实现了模块化流程，涵盖广泛的方法设计选择，使研究人员可以轻松组合、比较和扩展编码模型而无需重新发明核心基础设施。

Result: 作者通过将各种编码模型拟合到三个故事聆听数据集（LeBel等人，2023年；Narratives；小王子）来展示框架的可扩展性和多功能性。他们还探讨了构建连续fMRI数据编码模型的关键方法选择，说明了考虑TR扫描中的所有标记的重要性，包括血流动力学滞后效应，使用最小信息泄漏的训练测试分割，以及考虑头部运动对编码模型预测性的影响。

Conclusion: LITcoder降低了编码模型实现的技术门槛，促进了模型和数据集之间的系统比较，促进了方法严谨性，并加速了高质量高性能脑活动预测模型的开发。

Abstract: We introduce LITcoder, an open-source library for building and benchmarking
neural encoding models. Designed as a flexible backend, LITcoder provides
standardized tools for aligning continuous stimuli (e.g., text and speech) with
brain data, transforming stimuli into representational features, mapping those
features onto brain data, and evaluating the predictive performance of the
resulting model on held-out data. The library implements a modular pipeline
covering a wide array of methodological design choices, so researchers can
easily compose, compare, and extend encoding models without reinventing core
infrastructure. Such choices include brain datasets, brain regions, stimulus
feature (both neural-net-based and control, such as word rate), downsampling
approaches, and many others. In addition, the library provides built-in
logging, plotting, and seamless integration with experiment tracking platforms
such as Weights & Biases (W&B). We demonstrate the scalability and versatility
of our framework by fitting a range of encoding models to three story listening
datasets: LeBel et al. (2023), Narratives, and Little Prince. We also explore
the methodological choices critical for building encoding models for continuous
fMRI data, illustrating the importance of accounting for all tokens in a TR
scan (as opposed to just taking the last one, even when contextualized),
incorporating hemodynamic lag effects, using train-test splits that minimize
information leakage, and accounting for head motion effects on encoding model
predictivity. Overall, LITcoder lowers technical barriers to encoding model
implementation, facilitates systematic comparisons across models and datasets,
fosters methodological rigor, and accelerates the development of high-quality
high-performance predictive models of brain activity.
  Project page: https://litcoder-brain.github.io

</details>


### [14] [Target-oriented Multimodal Sentiment Classification with Counterfactual-enhanced Debiasing](https://arxiv.org/abs/2509.09160)
*Zhiyue Liu,Fanrong Ma,Xin Ling*

Main category: cs.CL

TL;DR: 本文提出了一种新的反事实增强去偏框架，以减少文本特征和输出标签之间的虚假相关性，从而提高目标导向的多模态情感分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法过度依赖文本内容，未能考虑数据集偏差，特别是词级上下文偏差，导致文本特征和输出标签之间出现虚假相关性，影响分类准确性。

Method: 本文引入了一种新的反事实增强去偏框架，该框架结合了反事实数据增强策略和自适应去偏对比学习机制。

Result: 实验结果表明，本文提出的方法在多个基准数据集上表现优于现有的最先进方法。

Conclusion: 本文提出的的方法在多个基准数据集上优于最先进的基线方法。

Abstract: Target-oriented multimodal sentiment classification seeks to predict
sentiment polarity for specific targets from image-text pairs. While existing
works achieve competitive performance, they often over-rely on textual content
and fail to consider dataset biases, in particular word-level contextual
biases. This leads to spurious correlations between text features and output
labels, impairing classification accuracy. In this paper, we introduce a novel
counterfactual-enhanced debiasing framework to reduce such spurious
correlations. Our framework incorporates a counterfactual data augmentation
strategy that minimally alters sentiment-related causal features, generating
detail-matched image-text samples to guide the model's attention toward content
tied to sentiment. Furthermore, for learning robust features from
counterfactual data and prompting model decisions, we introduce an adaptive
debiasing contrastive learning mechanism, which effectively mitigates the
influence of biased words. Experimental results on several benchmark datasets
show that our proposed method outperforms state-of-the-art baselines.

</details>


### [15] [EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs](https://arxiv.org/abs/2509.09174)
*Yuhao Zhang,Yuhao Du,Zhanchen Dai,Xiangnan Ma,Kaiqi Kou,Benyou Wang,Haizhou Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为EchoX的语音到语音大型语言模型，通过利用语义表示和动态生成语音训练目标来解决当前SLLMs在知识和推理能力上的不足。实验结果表明，EchoX在多个基于知识的问答基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前语音到语音大型语言模型（SLLMs）在知识和推理能力上存在不足，这可能是由于现有的训练范式无法弥合特征表示空间中的声学-语义差距。

Method: 本文提出了EchoX，该方法利用语义表示并动态生成语音训练目标，从而整合声学和语义学习，以保持强大的推理能力。

Result: 实验结果表明，使用大约六千小时训练数据的EchoX在多个基于知识的问答基准测试中取得了先进的性能。

Conclusion: EchoX通过整合声学和语义学习，有效解决了SLLMs在知识和推理能力上的不足，并在多个基准测试中表现出色。

Abstract: Speech-to-speech large language models (SLLMs) are attracting increasing
attention. Derived from text-based large language models (LLMs), SLLMs often
exhibit degradation in knowledge and reasoning capabilities. We hypothesize
that this limitation arises because current training paradigms for SLLMs fail
to bridge the acoustic-semantic gap in the feature representation space. To
address this issue, we propose EchoX, which leverages semantic representations
and dynamically generates speech training targets. This approach integrates
both acoustic and semantic learning, enabling EchoX to preserve strong
reasoning abilities as a speech LLM. Experimental results demonstrate that
EchoX, with about six thousand hours of training data, achieves advanced
performance on multiple knowledge-based question-answering benchmarks. The
project is available at https://github.com/FreedomIntelligence/EchoX.

</details>


### [16] [Efficient Trie-based Biasing using K-step Prediction for Rare Word Recognition](https://arxiv.org/abs/2509.09196)
*Chin Yuen Kwok,Jia Qi yip*

Main category: cs.CL

TL;DR: 本文提出一种新的ASR模型调整方法，通过提前预测多个步骤来提高罕见词识别效果，并在实验中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Trie的偏置方法在波束搜索中有限且计算成本高，特别是对于具有大解码器的模型。

Method: 我们提出适应ASR模型以提前预测多个步骤，从而避免撤销步骤，更好地估计部分假设是否会导致完整罕见词的生成。

Result: 通过仅使用10小时的合成数据微调Whisper，我们的方法在NSC Part 2测试集上将词错误率从30.86%降低到12.19%。

Conclusion: 通过微调Whisper模型，我们的方法在NSC Part 2测试集上将词错误率从30.86%降低到12.19%。

Abstract: Contextual biasing improves rare word recognition of ASR models by
prioritizing the output of rare words during decoding. A common approach is
Trie-based biasing, which gives "bonus scores" to partial hypothesis (e.g.
"Bon") that may lead to the generation of the rare word (e.g. "Bonham"). If the
full word ("Bonham") isn't ultimately recognized, the system revokes those
earlier bonuses. This revocation is limited to beam search and is
computationally expensive, particularly for models with large decoders. To
overcome these limitations, we propose adapting ASR models to look ahead and
predict multiple steps at once. This avoids the revocation step entirely by
better estimating whether a partial hypothesis will lead to the generation of
the full rare word. By fine-tuning Whisper with only 10 hours of synthetic
data, our method reduces the word error rate on the NSC Part 2 test set from
30.86% to 12.19%.

</details>


### [17] [Improving Synthetic Data Training for Contextual Biasing Models with a Keyword-Aware Cost Function](https://arxiv.org/abs/2509.09197)
*Chin Yuen Kwok,Jia Qi Yip,Eng Siong Chng*

Main category: cs.CL

TL;DR: 本文提出了一种增强的上下文偏差方法和关键词感知损失函数，以提高罕见词识别的性能。通过适应Whisper到10小时的合成数据，实验结果表明该方法显著降低了词错误率。


<details>
  <summary>Details</summary>
Motivation: 罕见词识别可以通过将自动语音识别模型适应到包含这些词的合成数据来改进。通过上下文偏差训练并添加偏差模块到模型架构中可以进一步提高性能。然而，使用合成罕见词数据训练模块可能导致过拟合，因为合成音频中存在伪影。

Method: 我们增强基于TCPGen的上下文偏差方法，并提出一种关键词感知损失函数，在训练偏差模块时额外关注偏差词。该损失包括用于偏差词预测的掩码交叉熵项和用于检测偏差词位置的二分类项。

Result: 通过适应Whisper到10小时的合成数据，我们的方法将NSC Part 2测试集上的词错误率从29.71%降低到11.81%。

Conclusion: 通过适应10小时的合成数据，我们的方法将NSC Part 2测试集上的词错误率从29.71%降低到11.81%。

Abstract: Rare word recognition can be improved by adapting ASR models to synthetic
data that includes these words. Further improvements can be achieved through
contextual biasing, which trains and adds a biasing module into the model
architecture to prioritize rare words. While training the module on synthetic
rare word data is more effective than using non-rare-word data, it can lead to
overfitting due to artifacts in the synthetic audio. To address this, we
enhance the TCPGen-based contextual biasing approach and propose a
keyword-aware loss function that additionally focuses on biased words when
training biasing modules. This loss includes a masked cross-entropy term for
biased word prediction and a binary classification term for detecting biased
word positions. These two terms complementarily support the decoding of biased
words during inference. By adapting Whisper to 10 hours of synthetic data, our
method reduced the word error rate on the NSC Part 2 test set from 29.71% to
11.81%.

</details>


### [18] [GmSLM : Generative Marmoset Spoken Language Modeling](https://arxiv.org/abs/2509.09198)
*Talia Sternberg,Michael London,David Omer,Yossi Adi*

Main category: cs.CL

TL;DR: 研究介绍了GmSLM，一种针对狨猴声音交流优化的生成式语音语言模型管道。通过使用无监督野外数据和弱标记对话数据，GmSLM在下游任务中表现良好，并能有效区分真实与人工对话。


<details>
  <summary>Details</summary>
Motivation: Marmoset monkeys exhibit complex vocal communication, challenging the view that nonhuman primates vocal communication is entirely innate, and show similar features of human speech, such as vocal labeling of others and turn-taking. Studying their vocal communication offers a unique opportunity to link it with brain activity.

Method: We introduced Generative Marmoset Spoken Language Modeling (GmSLM), an optimized spoken language model pipeline for Marmoset vocal communication. We designed a novel zero-shot evaluation metrics using unsupervised in-the-wild data, alongside weakly labeled conversational data.

Result: GmSLM generated vocalizations closely matched real resynthesized samples acoustically and performed well on downstream tasks. Despite being fully unsupervised, GmSLM effectively distinguish real from artificial conversations and may support further investigations of the neural basis of vocal communication and provides a practical framework linking vocalization and brain activity.

Conclusion: GmSLM stands to benefit future work in neuroscience, bioacoustics, and evolutionary biology.

Abstract: Marmoset monkeys exhibit complex vocal communication, challenging the view
that nonhuman primates vocal communication is entirely innate, and show similar
features of human speech, such as vocal labeling of others and turn-taking.
Studying their vocal communication offers a unique opportunity to link it with
brain activity-especially given the difficulty of accessing the human brain in
speech and language research. Since Marmosets communicate primarily through
vocalizations, applying standard LLM approaches is not straightforward. We
introduce Generative Marmoset Spoken Language Modeling (GmSLM), an optimized
spoken language model pipeline for Marmoset vocal communication. We designed a
novel zero-shot evaluation metrics using unsupervised in-the-wild data,
alongside weakly labeled conversational data, to assess GmSLM and demonstrate
its advantage over a basic human-speech-based baseline. GmSLM generated
vocalizations closely matched real resynthesized samples acoustically and
performed well on downstream tasks. Despite being fully unsupervised, GmSLM
effectively distinguish real from artificial conversations and may support
further investigations of the neural basis of vocal communication and provides
a practical framework linking vocalization and brain activity. We believe GmSLM
stands to benefit future work in neuroscience, bioacoustics, and evolutionary
biology. Samples are provided under: pages.cs.huji.ac.il/adiyoss-lab/GmSLM.

</details>


### [19] [CCF: A Context Compression Framework for Efficient Long-Sequence Language Modeling](https://arxiv.org/abs/2509.09199)
*Wenhao Li,Bangcheng Sun,Weihao Ye,Tianyi Zhang,Daohai Yu,Fei Chao,Rongrong Ji*

Main category: cs.CL

TL;DR: 本文提出了一种名为CCF的新上下文压缩框架，通过学习分层潜在表示来实现高效的长上下文建模，同时保留全局语义并减少输入冗余。CCF结合了逐段语义聚合和键值记忆编码，形成了支持准确重建和长距离理解的紧凑表示。此外，还引入了一种训练高效的优化策略，将增量段解码与稀疏水库采样相结合，显著降低了内存开销而不影响性能。实验结果表明，CCF在高压缩比下实现了具有竞争力的困惑度，并且在吞吐量和内存效率方面相比现有方法有显著提升。这些发现突显了结构化压缩在可扩展和有效的长上下文语言建模中的潜力。


<details>
  <summary>Details</summary>
Motivation: 扩展语言模型以处理更长的上下文对于捕捉跨扩展话语的丰富依赖关系至关重要。然而，传统的上下文扩展方法会带来显著的计算和内存负担，导致训练和推理效率低下。

Method: CCF是一种新的上下文压缩框架，通过学习分层潜在表示来实现高效的长上下文建模，同时保留全局语义并大幅减少输入冗余。它结合了逐段语义聚合和键值记忆编码，形成了支持准确重建和长距离理解的紧凑表示。此外，还引入了一种训练高效的优化策略，将增量段解码与稀疏水库采样相结合，显著降低了内存开销而不影响性能。

Result: 在多个长上下文语言建模基准测试中，CCF在高压缩比下实现了具有竞争力的困惑度，并且在吞吐量和内存效率方面相比现有方法有显著提升。

Conclusion: 这些发现突显了结构化压缩在可扩展和有效的长上下文语言建模中的潜力。

Abstract: Scaling language models to longer contexts is essential for capturing rich
dependencies across extended discourse. However, na\"ive context extension
imposes significant computational and memory burdens, often resulting in
inefficiencies during both training and inference. In this work, we propose
CCF, a novel context compression framework designed to enable efficient
long-context modeling by learning hierarchical latent representations that
preserve global semantics while aggressively reducing input redundancy. CCF
integrates segment-wise semantic aggregation with key-value memory encoding,
forming compact representations that support accurate reconstruction and
long-range understanding. To further enhance scalability, we introduce a
training-efficient optimization strategy that couples incremental segment
decoding with sparse reservoir sampling, substantially reducing memory overhead
without degrading performance. Empirical results on multiple long-context
language modeling benchmarks demonstrate that CCF achieves competitive
perplexity under high compression ratios, and significantly improves throughput
and memory efficiency compared to existing approaches. These findings highlight
the potential of structured compression for scalable and effective long-context
language modeling.

</details>


### [20] [Reading Between the Lines: Classifying Resume Seniority with Large Language Models](https://arxiv.org/abs/2509.09229)
*Matan Cohen,Shira Shani,Eden Menahem,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型在自动评估简历资历方面的有效性，并引入了一个混合数据集来评估模型性能。


<details>
  <summary>Details</summary>
Motivation: 准确评估候选人的资历是一项关键但具有挑战性的任务，因为存在夸大经验和模糊自我呈现的问题。

Method: 研究使用了一个混合数据集，包括真实简历和合成生成的困难示例，以评估大型语言模型在自动分类简历资历方面的效果。

Result: 研究结果表明，大型语言模型能够有效检测与资历膨胀和隐含专业知识相关的细微语言线索。

Conclusion: 研究发现，大型语言模型在检测与资历膨胀和隐含专业知识相关的细微语言线索方面表现出色，为增强基于人工智能的候选人评估系统和减少自我促销语言带来的偏见提供了有希望的方向。

Abstract: Accurately assessing candidate seniority from resumes is a critical yet
challenging task, complicated by the prevalence of overstated experience and
ambiguous self-presentation. In this study, we investigate the effectiveness of
large language models (LLMs), including fine-tuned BERT architectures, for
automating seniority classification in resumes. To rigorously evaluate model
performance, we introduce a hybrid dataset comprising both real-world resumes
and synthetically generated hard examples designed to simulate exaggerated
qualifications and understated seniority. Using the dataset, we evaluate the
performance of Large Language Models in detecting subtle linguistic cues
associated with seniority inflation and implicit expertise. Our findings
highlight promising directions for enhancing AI-driven candidate evaluation
systems and mitigating bias introduced by self-promotional language. The
dataset is available for the research community at https://bit.ly/4mcTovt

</details>


### [21] [Agentic LLMs for Question Answering over Tabular Data](https://arxiv.org/abs/2509.09234)
*Rishit Tyagi,Mohit Gupta,Rahul Bouri*

Main category: cs.CL

TL;DR: 本文介绍了一种基于大型语言模型的自然语言到SQL方法，用于解决表格问答问题，并在DataBench基准测试中取得了显著优于基线的结果。


<details>
  <summary>Details</summary>
Motivation: 由于现实世界表格的结构、大小和数据类型的多样性，表格问答（Table QA）面临独特的挑战。SemEval 2025任务8（DataBench）引入了一个由大规模、领域多样数据集组成的基准，用于评估模型准确回答结构化查询的能力。

Method: 我们提出了一种自然语言到SQL (NL-to-SQL) 的方法，利用大型语言模型（如GPT-4o、GPT-4o-mini和DeepSeek v2:16b）动态生成SQL查询。我们的系统遵循多阶段流程，包括示例选择、SQL查询生成、答案提取、验证和迭代优化。

Result: 实验表明了我们方法的有效性，在DataBench QA上达到了70.5%的准确率，在DataBench Lite QA上达到了71.6%，分别显著超过了基线分数26%和27%。

Conclusion: 本文详细介绍了我们的方法、实验结果和替代方法，提供了对LLM驱动的Table QA的优势和局限性的见解。

Abstract: Question Answering over Tabular Data (Table QA) presents unique challenges
due to the diverse structure, size, and data types of real-world tables. The
SemEval 2025 Task 8 (DataBench) introduced a benchmark composed of large-scale,
domain-diverse datasets to evaluate the ability of models to accurately answer
structured queries. We propose a Natural Language to SQL (NL-to-SQL) approach
leveraging large language models (LLMs) such as GPT-4o, GPT-4o-mini, and
DeepSeek v2:16b to generate SQL queries dynamically. Our system follows a
multi-stage pipeline involving example selection, SQL query generation, answer
extraction, verification, and iterative refinement. Experiments demonstrate the
effectiveness of our approach, achieving 70.5\% accuracy on DataBench QA and
71.6\% on DataBench Lite QA, significantly surpassing baseline scores of 26\%
and 27\% respectively. This paper details our methodology, experimental
results, and alternative approaches, providing insights into the strengths and
limitations of LLM-driven Table QA.

</details>


### [22] [From scratch to silver: Creating trustworthy training data for patent-SDG classification using Large Language Models](https://arxiv.org/abs/2509.09303)
*Grazia Sveva Ascione,Nicolò Tamagnone*

Main category: cs.CL

TL;DR: 本文提出了一种基于弱监督和语义对齐的方法，用于大规模分类专利与联合国可持续发展目标（SDGs）。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大型标记数据集，限制了监督学习的使用。现有的方法如关键词搜索、迁移学习和引用启发式方法在可扩展性和泛化性方面存在不足。

Method: 本文将专利到SDG的分类作为弱监督问题来处理，使用专利引用SDG标记的科学出版物（NPL引用）作为噪声初始信号。开发了一个复合标注函数（LF），利用大语言模型（LLMs）从专利和SDG论文中提取结构化概念，并通过基于排名的检索方法计算跨领域相似性分数。

Result: 得到了一个银标准的软多标签数据集，将专利映射到SDG，可以训练有效的多标签回归模型。通过两种互补策略验证了方法：(1) 对保留的NPL基础标签进行内部验证，结果优于多个基线；(2) 使用专利引用、共同发明人和共同申请人的网络模块性进行外部验证，结果显示我们的标签比传统技术分类具有更高的主题、认知和组织一致性。

Conclusion: 这些结果表明，弱监督和语义对齐可以大规模增强SDG分类。

Abstract: Classifying patents by their relevance to the UN Sustainable Development
Goals (SDGs) is crucial for tracking how innovation addresses global
challenges. However, the absence of a large, labeled dataset limits the use of
supervised learning. Existing methods, such as keyword searches, transfer
learning, and citation-based heuristics, lack scalability and generalizability.
This paper frames patent-to-SDG classification as a weak supervision problem,
using citations from patents to SDG-tagged scientific publications (NPL
citations) as a noisy initial signal. To address its sparsity and noise, we
develop a composite labeling function (LF) that uses large language models
(LLMs) to extract structured concepts, namely functions, solutions, and
applications, from patents and SDG papers based on a patent ontology.
Cross-domain similarity scores are computed and combined using a rank-based
retrieval approach. The LF is calibrated via a custom positive-only loss that
aligns with known NPL-SDG links without penalizing discovery of new SDG
associations. The result is a silver-standard, soft multi-label dataset mapping
patents to SDGs, enabling the training of effective multi-label regression
models. We validate our approach through two complementary strategies: (1)
internal validation against held-out NPL-based labels, where our method
outperforms several baselines including transformer-based models, and zero-shot
LLM; and (2) external validation using network modularity in patent citation,
co-inventor, and co-applicant graphs, where our labels reveal greater thematic,
cognitive, and organizational coherence than traditional technological
classifications. These results show that weak supervision and semantic
alignment can enhance SDG classification at scale.

</details>


### [23] [MetaRAG: Metamorphic Testing for Hallucination Detection in RAG Systems](https://arxiv.org/abs/2509.09360)
*Channdeth Sok,David Luz,Yacine Haddam*

Main category: cs.CL

TL;DR: MetaRAG is a framework for detecting hallucinations in RAG systems by decomposing answers into factoids, generating mutations, verifying against context, and aggregating penalties to identify inconsistencies.


<details>
  <summary>Details</summary>
Motivation: Existing detection approaches primarily target standalone LLMs and do not address the unique challenges of RAG systems, where responses must be consistent with retrieved evidence.

Method: MetaRAG is a metamorphic testing framework that operates in a real-time, unsupervised, black-box setting. It decomposes answers into atomic factoids, generates controlled mutations using synonym and antonym substitutions, verifies each variant against the retrieved context, and aggregates penalties for inconsistencies into a response-level hallucination score.

Result: Experiments on a proprietary enterprise dataset illustrate the effectiveness of MetaRAG for detecting hallucinations and enabling trustworthy deployment of RAG-based conversational agents.

Conclusion: MetaRAG is effective for detecting hallucinations and enabling trustworthy deployment of RAG-based conversational agents.

Abstract: Large Language Models (LLMs) are increasingly deployed in enterprise
applications, yet their reliability remains limited by hallucinations, i.e.,
confident but factually incorrect information. Existing detection approaches,
such as SelfCheckGPT and MetaQA, primarily target standalone LLMs and do not
address the unique challenges of Retrieval-Augmented Generation (RAG) systems,
where responses must be consistent with retrieved evidence. We therefore
present MetaRAG, a metamorphic testing framework for hallucination detection in
Retrieval-Augmented Generation (RAG) systems. MetaRAG operates in a real-time,
unsupervised, black-box setting, requiring neither ground-truth references nor
access to model internals, making it suitable for proprietary and high-stakes
domains. The framework proceeds in four stages: (1) decompose answers into
atomic factoids, (2) generate controlled mutations of each factoid using
synonym and antonym substitutions, (3) verify each variant against the
retrieved context (synonyms are expected to be entailed and antonyms
contradicted), and (4) aggregate penalties for inconsistencies into a
response-level hallucination score. Crucially for identity-aware AI, MetaRAG
localizes unsupported claims at the factoid span where they occur (e.g.,
pregnancy-specific precautions, LGBTQ+ refugee rights, or labor eligibility),
allowing users to see flagged spans and enabling system designers to configure
thresholds and guardrails for identity-sensitive queries. Experiments on a
proprietary enterprise dataset illustrate the effectiveness of MetaRAG for
detecting hallucinations and enabling trustworthy deployment of RAG-based
conversational agents. We also outline a topic-based deployment design that
translates MetaRAG's span-level scores into identity-aware safeguards; this
design is discussed but not evaluated in our experiments.

</details>


### [24] [Modelling Analogies and Analogical Reasoning: Connecting Cognitive Science Theory and NLP Research](https://arxiv.org/abs/2509.09381)
*Molly R Petersen,Claire E Stevenson,Lonneke van der Plas*

Main category: cs.CL

TL;DR: 本文总结了类比推理的认知理论，并探讨了其在自然语言处理中的应用，强调关系理解的重要性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在将类比推理的认知过程与自然语言处理的研究相结合，以更好地优化文本中的关系理解，而不是仅仅依赖实体层面的相似性。

Method: 本文通过总结认知科学文献中的关键理论，并将其与自然语言处理的研究联系起来，分析了类比推理的机制及其在NLP中的应用。

Result: 本文展示了类比推理的概念如何与自然语言处理中的多个重大挑战相关，并提出了优化关系理解的新方向。

Conclusion: 本文总结了认知科学文献中关于类比推理过程的关键理论，并将其与自然语言处理中的当前研究联系起来，强调这些概念对于解决NLP中的重大挑战的重要性。

Abstract: Analogical reasoning is an essential aspect of human cognition. In this
paper, we summarize key theory about the processes underlying analogical
reasoning from the cognitive science literature and relate it to current
research in natural language processing. While these processes can be easily
linked to concepts in NLP, they are generally not viewed through a cognitive
lens. Furthermore, we show how these notions are relevant for several major
challenges in NLP research, not directly related to analogy solving. This may
guide researchers to better optimize relational understanding in text, as
opposed to relying heavily on entity-level similarity.

</details>


### [25] [Hierarchical Bracketing Encodings Work for Dependency Graphs](https://arxiv.org/abs/2509.09388)
*Ana Ezquerro,Carlos Gómez-Rodríguez,David Vilares*

Main category: cs.CL

TL;DR: 本文提出了一种新的图编码方法，能够在保持结构信息的同时减少标签空间，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 重新从实践角度审视层次括号编码，以提高依赖图解析的效率和效果。

Method: 该方法将图编码为序列，实现了线性时间解析，并保留了重叠、循环和空节点的结构信息。

Result: 与现有的图线性化方法相比，该方法显著减少了标签空间，同时保持了结构信息，并在多语言和多形式主义的基准测试中取得了有竞争力的结果。

Conclusion: 该方法在精确匹配准确率上表现出色，并且在不同语言和形式主义的基准测试中显示出一致的改进。

Abstract: We revisit hierarchical bracketing encodings from a practical perspective in
the context of dependency graph parsing. The approach encodes graphs as
sequences, enabling linear-time parsing with $n$ tagging actions, and still
representing reentrancies, cycles, and empty nodes. Compared to existing graph
linearizations, this representation substantially reduces the label space while
preserving structural information. We evaluate it on a multilingual and
multi-formalism benchmark, showing competitive results and consistent
improvements over other methods in exact match accuracy.

</details>


### [26] [GrACE: A Generative Approach to Better Confidence Elicitation in Large Language Models](https://arxiv.org/abs/2509.09438)
*Zhaohan Zhang,Ziquan Liu,Ioannis Patras*

Main category: cs.CL

TL;DR: GrACE is a novel approach for confidence elicitation in LLMs that provides scalable, reliable, and real-time confidence estimation, improving accuracy and reducing the number of required samples in test-time scaling.


<details>
  <summary>Details</summary>
Motivation: Existing methods for assessing the reliability of LLMs by confidence elicitation either require expensive computational overhead or suffer from poor calibration, making them impractical and unreliable for real-world deployment.

Method: GrACE is a Generative Approach to Confidence Elicitation that uses the similarity between the last hidden state and the embedding of a special token appended to the vocabulary to express confidence in real-time.

Result: Experiments with three LLMs and two benchmark datasets show that GrACE achieves the best discriminative capacity and calibration on open-ended generation tasks, outperforming six competing methods without additional sampling or an auxiliary model. Additionally, using GrACE improves the accuracy of the final decision and reduces the number of required samples in the test-time scaling scheme.

Conclusion: GrACE shows potential as a practical solution for deploying LLMs with scalable, reliable, and real-time confidence estimation.

Abstract: Assessing the reliability of Large Language Models (LLMs) by confidence
elicitation is a prominent approach to AI safety in high-stakes applications,
such as healthcare and finance. Existing methods either require expensive
computational overhead or suffer from poor calibration, making them impractical
and unreliable for real-world deployment. In this work, we propose GrACE, a
Generative Approach to Confidence Elicitation that enables scalable and
reliable confidence elicitation for LLMs. GrACE adopts a novel mechanism in
which the model expresses confidence by the similarity between the last hidden
state and the embedding of a special token appended to the vocabulary, in
real-time. We fine-tune the model for calibrating the confidence with
calibration targets associated with accuracy. Experiments with three LLMs and
two benchmark datasets show that the confidence produced by GrACE achieves the
best discriminative capacity and calibration on open-ended generation tasks,
outperforming six competing methods without resorting to additional sampling or
an auxiliary model. Moreover, we propose two strategies for improving test-time
scaling based on confidence induced by GrACE. Experimental results show that
using GrACE not only improves the accuracy of the final decision but also
significantly reduces the number of required samples in the test-time scaling
scheme, indicating the potential of GrACE as a practical solution for deploying
LLMs with scalable, reliable, and real-time confidence estimation.

</details>


### [27] [Mitigating Language Barriers in Education: Developing Multilingual Digital Learning Materials with Machine Translation](https://arxiv.org/abs/2509.09473)
*Lucie Poláková,Martin Popel,Věra Kloudová,Michal Novák,Mariia Anisimova,Jiří Balhar*

Main category: cs.CL

TL;DR: EdUKate项目开发了一个针对教育领域的捷克语-乌克兰语机器翻译系统，并将9000个多模态交互练习翻译成乌克兰语、英语和德语，供学生、教育工作者和研究人员免费使用。


<details>
  <summary>Details</summary>
Motivation: 该项目旨在为捷克小学和中学提供多语言学习材料，以满足非捷克语学生的需要，并促进教育内容的多语言传播。

Method: 该项目结合了数字教育、语言学、翻译研究和机器翻译，以开发多语言学习材料。它专注于开发和评估针对教育领域的直接捷克语-乌克兰语机器翻译系统，并处理格式化内容和技术术语。

Result: 该项目已经完成了9000个多模态交互练习的翻译，并开发了一个专门针对教育领域的捷克语-乌克兰语机器翻译系统。此外，还进行了教师调查，并在教育网络门户上进行了系统的评估和实施。

Conclusion: 该项目开发的多语言学习材料和机器翻译系统已成功实施，并可供学生、教育工作者和研究人员免费使用。

Abstract: The EdUKate project combines digital education, linguistics, translation
studies, and machine translation to develop multilingual learning materials for
Czech primary and secondary schools. Launched through collaboration between a
major Czech academic institution and the country's largest educational
publisher, the project is aimed at translating up to 9,000 multimodal
interactive exercises from Czech into Ukrainian, English, and German for an
educational web portal. It emphasizes the development and evaluation of a
direct Czech-Ukrainian machine translation system tailored to the educational
domain, with special attention to processing formatted content such as XML and
PDF and handling technical and scientific terminology. We present findings from
an initial survey of Czech teachers regarding the needs of non-Czech-speaking
students and describe the system's evaluation and implementation on the web
portal. All resulting applications are freely available to students, educators,
and researchers.

</details>


### [28] [Towards Explainable Job Title Matching: Leveraging Semantic Textual Relatedness and Knowledge Graphs](https://arxiv.org/abs/2509.09522)
*Vadim Zadykian,Bruno Andrade,Haithem Afli*

Main category: cs.CL

TL;DR: 本文提出了一种结合知识图谱的自监督混合架构，用于改进职位名称匹配任务。通过分层评估方法，发现结合KGs的SBERT模型在高语义相关性区域表现优异，为人力资源系统提供了更公平、可解释和上下文相关的解决方案。


<details>
  <summary>Details</summary>
Motivation: 在简历推荐系统中，职位名称匹配是一个关键挑战，因为重叠术语可能有限或具有误导性。传统的模型评估方法仅关注整体性能，而我们的方法强调通过分层评估来分析模型在不同语义子空间中的表现。

Method: 我们引入了一种自监督的混合架构，将密集句子嵌入与领域特定的知识图谱（KGs）相结合，以提高语义对齐和可解释性。我们通过将STR分数连续体划分为低、中、高语义相关性区域来进行数据分层评估，从而实现对模型性能的细粒度分析。

Result: 实验结果表明，经过微调的SBERT模型结合KGs在高STR区域表现出色，RMSE比强基线模型降低了25%。此外，我们的研究揭示了结合KGs与文本嵌入的优势，以及区域性能分析的重要性。

Conclusion: 我们的研究结果表明，结合知识图谱的文本嵌入方法在高语义相关性区域表现出色，并且强调了区域性能分析在理解模型行为中的重要性。这种细致的方法揭示了全局指标可能隐藏的优势和劣势，并支持在人力资源系统和需要公平性、可解释性和上下文匹配的应用中进行更针对性的模型选择。

Abstract: Semantic Textual Relatedness (STR) captures nuanced relationships between
texts that extend beyond superficial lexical similarity. In this study, we
investigate STR in the context of job title matching - a key challenge in
resume recommendation systems, where overlapping terms are often limited or
misleading. We introduce a self-supervised hybrid architecture that combines
dense sentence embeddings with domain-specific Knowledge Graphs (KGs) to
improve both semantic alignment and explainability. Unlike previous work that
evaluated models on aggregate performance, our approach emphasizes data
stratification by partitioning the STR score continuum into distinct regions:
low, medium, and high semantic relatedness. This stratified evaluation enables
a fine-grained analysis of model performance across semantically meaningful
subspaces. We evaluate several embedding models, both with and without KG
integration via graph neural networks. The results show that fine-tuned SBERT
models augmented with KGs produce consistent improvements in the high-STR
region, where the RMSE is reduced by 25% over strong baselines. Our findings
highlight not only the benefits of combining KGs with text embeddings, but also
the importance of regional performance analysis in understanding model
behavior. This granular approach reveals strengths and weaknesses hidden by
global metrics, and supports more targeted model selection for use in Human
Resources (HR) systems and applications where fairness, explainability, and
contextual matching are essential.

</details>


### [29] [DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning and Label Distribution Learning](https://arxiv.org/abs/2509.09524)
*Daniil Ignatev,Nan Li,Hugh Mee Wong,Anh Dang,Shane Kaszefski Yaschuk*

Main category: cs.CL

TL;DR: This paper explores ICL and LDL methods for predicting annotator-specific annotations and soft labels, showing that ICL can effectively predict annotations and that LDL methods are promising for further exploration.


<details>
  <summary>Details</summary>
Motivation: To explore effective approaches for predicting annotator-specific annotations and soft label predictions in the context of the Learning with Disagreements shared task.

Method: In-context learning (ICL) with large language models and label distribution learning (LDL) methods with RoBERTa.

Result: ICL can effectively predict annotator-specific annotations, and aggregating these predictions into soft labels yields competitive performance. LDL methods are promising for soft label predictions.

Conclusion: ICL can effectively predict annotator-specific annotations, and aggregating these predictions into soft labels yields competitive performance. LDL methods are promising for soft label predictions and merit further exploration by the perspectivist community.

Abstract: This system paper presents the DeMeVa team's approaches to the third edition
of the Learning with Disagreements shared task (LeWiDi 2025; Leonardelli et
al., 2025). We explore two directions: in-context learning (ICL) with large
language models, where we compare example sampling strategies; and label
distribution learning (LDL) methods with RoBERTa (Liu et al., 2019b), where we
evaluate several fine-tuning methods. Our contributions are twofold: (1) we
show that ICL can effectively predict annotator-specific annotations
(perspectivist annotations), and that aggregating these predictions into soft
labels yields competitive performance; and (2) we argue that LDL methods are
promising for soft label predictions and merit further exploration by the
perspectivist community.

</details>


### [30] [Prompting the Market? A Large-Scale Meta-Analysis of GenAI in Finance NLP (2022-2025)](https://arxiv.org/abs/2509.09544)
*Paolo Pedinotti,Peter Baumann,Nathan Jessurun,Leslie Barrett,Enrico Santus*

Main category: cs.CL

TL;DR: 本文介绍了MetaGraph，这是一种从科学文献中提取知识图谱并分析研究趋势的方法，揭示了金融自然语言处理的演变过程，并展示了其在其他领域的适用性。


<details>
  <summary>Details</summary>
Motivation: 传统调查未能跟上大型语言模型（LLMs）在金融自然语言处理中的快速变化，因此需要一种新的方法来提取知识图谱并分析研究趋势。

Method: 定义了一个金融自然语言处理研究的本体论，并应用基于大语言模型的提取管道来分析681篇论文（2022-2025年）。

Result: MetaGraph揭示了三个关键阶段：早期LLM采用和任务/数据集创新；对LLM局限性的批判性反思；以及外围技术向模块化系统的日益整合。

Conclusion: MetaGraph提供了一种可重用的方法，用于映射其他领域中的科学进展，并为从业者和研究人员提供了对金融自然语言处理演化的清晰理解。

Abstract: Large Language Models (LLMs) have rapidly reshaped financial NLP, enabling
new tasks and driving a proliferation of datasets and diversification of data
sources. Yet, this transformation has outpaced traditional surveys. In this
paper, we present MetaGraph, a generalizable methodology for extracting
knowledge graphs from scientific literature and analyzing them to obtain a
structured, queryable view of research trends. We define an ontology for
financial NLP research and apply an LLM-based extraction pipeline to 681 papers
(2022-2025), enabling large-scale, data-driven analysis. MetaGraph reveals
three key phases: early LLM adoption and task/dataset innovation; critical
reflection on LLM limitations; and growing integration of peripheral techniques
into modular systems. This structured view offers both practitioners and
researchers a clear understanding of how financial NLP has evolved -
highlighting emerging trends, shifting priorities, and methodological
shifts-while also demonstrating a reusable approach for mapping scientific
progress in other domains.

</details>


### [31] [Personality-Enhanced Social Recommendations in SAMI: Exploring the Role of Personality Detection in Matchmaking](https://arxiv.org/abs/2509.09583)
*Brittany Harbison,Samuel Taubman,Travis Taylor,Ashok. K. Goel*

Main category: cs.CL

TL;DR: 本文提出一种利用GPT零样本能力检测人格的模型，并将其集成到SAMI系统中，以实现更有效的社会推荐。


<details>
  <summary>Details</summary>
Motivation: SAMI在创建学生有效心理模型方面受到不完整的心理理论的限制，无法直观地理解人格，这可能会影响其推荐的相关性。

Method: 提出了一种利用GPT的零样本能力从论坛介绍帖子中推断五大性格特征的人格检测模型，并将其集成到SAMI基于实体的匹配系统中，以实现基于人格的社会推荐。

Result: 该模型在这一任务中表现出色，并且初步整合表明人格特质可以补充现有的匹配因素。

Conclusion: 初步整合表明人格特质可以补充现有的匹配因素，但需要进一步评估其对学生参与度和匹配质量的全面影响。

Abstract: Social connection is a vital part of learning, yet online course environments
present barriers to the organic formation of social groups. SAMI offers one
solution by facilitating student connections, but its effectiveness is
constrained by an incomplete Theory of Mind, limiting its ability to create an
effective mental model of a student. One facet of this is its inability to
intuit personality, which may influence the relevance of its recommendations.
To explore this, we propose a personality detection model utilizing GPTs
zero-shot capability to infer Big-Five personality traits from forum
introduction posts, often encouraged in online courses. We benchmark its
performance against established models, demonstrating its efficacy in this
task. Furthermore, we integrate this model into SAMIs entity-based matchmaking
system, enabling personality-informed social recommendations. Initial
integration suggests personality traits can complement existing matching
factors, though additional evaluation is required to determine their full
impact on student engagement and match quality.

</details>


### [32] [Fluent but Unfeeling: The Emotional Blind Spots of Language Models](https://arxiv.org/abs/2509.09593)
*Bangzhao Shu,Isha Joshi,Melissa Karnaze,Anh C. Pham,Ishita Kakkar,Sindhu Kothe,Arpine Hovasapian,Mai ElSherief*

Main category: cs.CL

TL;DR: 本研究引入了一个细粒度情感标签的数据集，评估了大型语言模型在情感识别方面的表现，发现它们在细粒度情感对齐方面仍存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常集中在将情感分类到预定义的有限类别中，忽略了更细微的表达。因此，需要评估大型语言模型是否在细粒度水平上与人类情感一致。

Method: 引入了EXPRESS数据集，并使用现有的情感理论对预测的情感术语进行分解，以进行细粒度比较。

Result: 系统测试显示，准确预测与人类自我披露情感一致的情感仍然具有挑战性。定性分析进一步表明，某些大型语言模型生成的情感术语与现有情感理论和定义一致，但有时无法像人类自我披露那样有效地捕捉上下文线索。

Conclusion: 研究结果表明，大型语言模型在细粒度情感对齐方面存在局限性，并为未来增强其上下文理解提供了见解。

Abstract: The versatility of Large Language Models (LLMs) in natural language
understanding has made them increasingly popular in mental health research.
While many studies explore LLMs' capabilities in emotion recognition, a
critical gap remains in evaluating whether LLMs align with human emotions at a
fine-grained level. Existing research typically focuses on classifying emotions
into predefined, limited categories, overlooking more nuanced expressions. To
address this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit
communities featuring 251 fine-grained, self-disclosed emotion labels. Our
comprehensive evaluation framework examines predicted emotion terms and
decomposes them into eight basic emotions using established emotion theories,
enabling a fine-grained comparison. Systematic testing of prevalent LLMs under
various prompt settings reveals that accurately predicting emotions that align
with human self-disclosed emotions remains challenging. Qualitative analysis
further shows that while certain LLMs generate emotion terms consistent with
established emotion theories and definitions, they sometimes fail to capture
contextual cues as effectively as human self-disclosures. These findings
highlight the limitations of LLMs in fine-grained emotion alignment and offer
insights for future research aimed at enhancing their contextual understanding.

</details>


### [33] [LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death Determination](https://arxiv.org/abs/2509.09602)
*Yiqun T. Chen,Tyler H. McCormick,Li Liu,Abhirup Datta*

Main category: cs.CL

TL;DR: 本研究探讨了利用大型语言模型提高口头尸检准确性的可能性，并发现GPT-5在不同年龄组中表现出色，显示出其在低资源环境中的潜在应用价值。


<details>
  <summary>Details</summary>
Motivation: 在缺乏医疗认证的资源有限的环境中，口头尸检（VA）是估计死亡原因的关键工具。本研究旨在探索使用大型语言模型来提高口头尸检的准确性。

Method: 该研究提出了LA-VA，这是一个结合大型语言模型（LLMs）与传统算法方法和基于嵌入的分类的验证概念管道，用于改进死亡原因预测。

Result: GPT-5在个体性能上表现最佳，平均测试站点准确率分别为成人48.6%、儿童50.5%和新生儿53.5%，比传统的统计机器学习基线高出5-10%。

Conclusion: 研究结果表明，简单的现成LLM辅助方法可以显著提高口头尸检的准确性，这对低资源环境中的全球健康监测具有重要意义。

Abstract: Verbal autopsy (VA) is a critical tool for estimating causes of death in
resource-limited settings where medical certification is unavailable. This
study presents LA-VA, a proof-of-concept pipeline that combines Large Language
Models (LLMs) with traditional algorithmic approaches and embedding-based
classification for improved cause-of-death prediction. Using the Population
Health Metrics Research Consortium (PHMRC) dataset across three age categories
(Adult: 7,580; Child: 1,960; Neonate: 2,438), we evaluate multiple approaches:
GPT-5 predictions, LCVA baseline, text embeddings, and meta-learner ensembles.
Our results demonstrate that GPT-5 achieves the highest individual performance
with average test site accuracies of 48.6% (Adult), 50.5% (Child), and 53.5%
(Neonate), outperforming traditional statistical machine learning baselines by
5-10%. Our findings suggest that simple off-the-shelf LLM-assisted approaches
could substantially improve verbal autopsy accuracy, with important
implications for global health surveillance in low-resource settings.

</details>


### [34] [Bridging the Capability Gap: Joint Alignment Tuning for Harmonizing LLM-based Multi-Agent Systems](https://arxiv.org/abs/2509.09629)
*Minghang Zhu,Zhengliang Shi,Zhiwei Xu,Shiguang Wu,Lingjie Wang,Pengjie Ren,Zhaochun Ren,Zhumin Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为MOAT的多智能体联合对齐调优框架，通过迭代对齐提高智能体协作能力。MOAT交替进行两个关键阶段：(1) 规划智能体对齐，优化规划智能体以生成更好地引导接地智能体的子目标序列；(2) 接地智能体改进，使用智能体自身生成的多样化子目标-动作对来微调接地智能体，以增强其泛化能力。理论分析证明MOAT确保了非递减且逐步收敛的训练过程。在六个基准测试中的实验表明，MOAT优于最先进的基线，分别在保留任务和保留任务上平均提高了3.1%和4.4%。


<details>
  <summary>Details</summary>
Motivation: Most existing methods typically fine-tune these agents independently, leading to capability gaps among them with poor coordination.

Method: MOAT, a Multi-Agent Joint Alignment Tuning framework that improves agents collaboration through iterative alignment.

Result: Experiments across six benchmarks demonstrate that MOAT outperforms state-of-the-art baselines, achieving average improvements of 3.1% on held-in tasks and 4.4% on held-out tasks.

Conclusion: MOAT outperforms state-of-the-art baselines, achieving average improvements of 3.1% on held-in tasks and 4.4% on held-out tasks.

Abstract: The advancement of large language models (LLMs) has enabled the construction
of multi-agent systems to solve complex tasks by dividing responsibilities
among specialized agents, such as a planning agent for subgoal generation and a
grounding agent for executing tool-use actions. Most existing methods typically
fine-tune these agents independently, leading to capability gaps among them
with poor coordination. To address this, we propose MOAT, a Multi-Agent Joint
Alignment Tuning framework that improves agents collaboration through iterative
alignment. MOAT alternates between two key stages: (1) Planning Agent
Alignment, which optimizes the planning agent to generate subgoal sequences
that better guide the grounding agent; and (2) Grounding Agent Improving, which
fine-tunes the grounding agent using diverse subgoal-action pairs generated by
the agent itself to enhance its generalization capablity. Theoretical analysis
proves that MOAT ensures a non-decreasing and progressively convergent training
process. Experiments across six benchmarks demonstrate that MOAT outperforms
state-of-the-art baselines, achieving average improvements of 3.1% on held-in
tasks and 4.4% on held-out tasks.

</details>


### [35] [All for One: LLMs Solve Mental Math at the Last Token With Information Transferred From Other Tokens](https://arxiv.org/abs/2509.09650)
*Siddarth Mamidanna,Daking Rai,Ziyu Yao,Yilun Zhou*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型在心算任务中的内部机制，发现了一个高效的子图AF1，该子图在各种任务中表现良好，并且具有跨模型迁移的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在许多计算任务中表现出色，但其内部工作机制仍然不清晰。本文旨在探讨这些模型在心算任务中的计算过程，特别是它们如何利用自注意力和多层感知器进行计算。

Method: 本文通过两种技术，Context-Aware Mean Ablation (CAMA) 和 Attention-Based Peeking (ABP)，研究了大型语言模型在心算任务中的内部运作机制。具体步骤包括：抑制初始层中的输入特定token计算，限制信息传递路径，以及强制所有计算发生在最后一个token。

Result: 实验表明，AF1子图在各种心算任务中表现优异，并且对于模型的高性能是必要且足够的。此外，该子图可以跨模型迁移，并适用于多种输入样式。

Conclusion: 本文发现了一个名为AF1的子图，该子图在各种心算任务中表现出高准确性，并且对于模型的高性能是必要且足够的。此外，该子图可以在不同模型之间迁移，并适用于多种输入样式。

Abstract: Large language models (LLMs) demonstrate proficiency across numerous
computational tasks, yet their inner workings remain unclear. In theory, the
combination of causal self-attention and multilayer perceptron layers allows
every token to access and compute information based on all preceding tokens. In
practice, to what extent are such operations present? In this paper, on mental
math tasks (i.e., direct math calculation via next-token prediction without
explicit reasoning), we investigate this question in three steps: inhibiting
input-specific token computations in the initial layers, restricting the routes
of information transfer across token positions in the next few layers, and
forcing all computation to happen at the last token in the remaining layers.
With two proposed techniques, Context-Aware Mean Ablation (CAMA) and
Attention-Based Peeking (ABP), we identify an All-for-One subgraph (AF1) with
high accuracy on a wide variety of mental math tasks, where meaningful
computation occurs very late (in terms of layer depth) and only at the last
token, which receives information of other tokens in few specific middle
layers. Experiments on a variety of models and arithmetic expressions show that
this subgraph is sufficient and necessary for high model performance, transfers
across different models, and works on a variety of input styles. Ablations on
different CAMA and ABP alternatives reveal their unique advantages over other
methods, which may be of independent interest.

</details>


### [36] [Steering MoE LLMs via Expert (De)Activation](https://arxiv.org/abs/2509.09660)
*Mohsen Fayyaz,Ali Modarressi,Hanieh Deilamsalehy,Franck Dernoncourt,Ryan Rossi,Trung Bui,Hinrich Schütze,Nanyun Peng*

Main category: cs.CL

TL;DR: SteerMoE是一种用于引导MoE模型的框架，能够通过检测和控制与行为相关的专家来提高模型的安全性和忠实性。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型在处理不同行为时可能缺乏灵活性和可控性，因此需要一种方法来检测和控制与行为相关的专家，以提高模型的安全性和忠实性。

Method: SteerMoE通过检测和控制与行为相关的专家来实现对MoE模型的引导。检测方法识别在对比输入中具有不同激活模式的专家，并在推理过程中选择性地（去）激活这些专家。

Result: 在11个基准测试和6个LLM中，SteerMoE提高了安全性高达+20%，忠实性高达+27%。在对抗攻击模式下，它单独降低了安全性-41%，并与现有破解方法结合时降低了-100%，绕过了所有安全防护措施。

Conclusion: SteerMoE框架可以有效地控制MoE模型的行为，如忠实性和安全性，同时揭示了专家内部隐藏的对齐假象的新维度。

Abstract: Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token
through a subset of specialized Feed-Forward Networks (FFN), known as experts.
We present SteerMoE, a framework for steering MoE models by detecting and
controlling behavior-linked experts. Our detection method identifies experts
with distinct activation patterns across paired inputs exhibiting contrasting
behaviors. By selectively (de)activating such experts during inference, we
control behaviors like faithfulness and safety without retraining or modifying
weights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to
+20% and faithfulness by +27%. In adversarial attack mode, it drops safety by
-41% alone, and -100% when combined with existing jailbreak methods, bypassing
all safety guardrails and exposing a new dimension of alignment faking hidden
within experts.

</details>


### [37] [CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning in Large Language Models](https://arxiv.org/abs/2509.09675)
*Runpeng Dai,Linfeng Song,Haolin Liu,Zhenwen Liang,Dian Yu,Haitao Mi,Zhaopeng Tu,Rui Liu,Tong Zheng,Hongtu Zhu,Dong Yu*

Main category: cs.CL

TL;DR: 本文提出了一种基于好奇心驱动探索的RLVR方法，提升了LLM的推理能力，并揭示了RLVR中的校准崩溃机制。


<details>
  <summary>Details</summary>
Motivation: 当前的RLVR方法探索效果不佳，导致过早收敛和熵崩溃，需要一种更有效的探索机制。

Method: 我们引入了好奇心驱动探索（CDE），利用模型自身的内在好奇心来引导探索，并通过困惑度和价值估计方差作为探索奖励信号。

Result: 我们的方法在AIME基准测试中实现了约3个百分点的提升，并揭示了RLVR中的校准崩溃机制。

Conclusion: 我们的方法在AIME基准测试中比标准RLVR提高了大约3个百分点，并揭示了RLVR中的校准崩溃机制，有助于理解LLM的常见失败模式。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful paradigm
for enhancing the reasoning ability of Large Language Models (LLMs). Yet
current RLVR methods often explore poorly, leading to premature convergence and
entropy collapse. To address this challenge, we introduce Curiosity-Driven
Exploration (CDE), a framework that leverages the model's own intrinsic sense
of curiosity to guide exploration. We formalize curiosity with signals from
both the actor and the critic: for the actor, we use perplexity over its
generated response, and for the critic, we use the variance of value estimates
from a multi-head architecture. Both signals serve as an exploration bonus
within the RLVR framework to guide the model. Our theoretical analysis shows
that the actor-wise bonus inherently penalizes overconfident errors and
promotes diversity among correct responses; moreover, we connect the
critic-wise bonus to the well-established count-based exploration bonus in RL.
Empirically, our method achieves an approximate +3 point improvement over
standard RLVR using GRPO/PPO on AIME benchmarks. Further analysis identifies a
calibration collapse mechanism within RLVR, shedding light on common LLM
failure modes.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [38] [Open-sci-ref-0.01: open and reproducible reference baselines for language model and dataset comparison](https://arxiv.org/abs/2509.09009)
*Marianna Nezhurina,Taishi Nakamura,Timur Carstensen,Niccolò Ajroldi,Ville Komulainen,David Salinas,Jenia Jitsev*

Main category: cs.LG

TL;DR: 本文介绍了一种名为open-sci-ref的密集Transformer模型家族，用于作为研究基准，帮助研究人员评估其他训练方法的质量。


<details>
  <summary>Details</summary>
Motivation: 为了提供一个标准化的基准，使研究人员能够评估其他训练方法的合理性和质量，并促进未来的研究。

Method: 训练了一系列密集的Transformer模型，作为研究基准，覆盖多个模型规模（0.13B到1.7B参数）和标记规模（最多1T）。

Result: 在各种标准化基准上评估模型，结果表明在NemoTron-CC HQ上训练的表现优于其他参考数据集。

Conclusion: 通过建立基准线，研究人员可以评估不同训练方法在不同规模和数据集上的合理性和质量。

Abstract: We introduce open-sci-ref, a family of dense transformer models trained as
research baselines across multiple model (0.13B to 1.7B parameters) and token
scales (up to 1T) on 8 recent open reference datasets. Evaluating the models on
various standardized benchmarks, our training runs set establishes reference
points that enable researchers to assess the sanity and quality of alternative
training approaches across scales and datasets. Intermediate checkpoints allow
comparison and studying of the training dynamics. The established reference
baselines allow training procedures to be compared through their scaling
trends, aligning them on a common compute axis. Comparison of open reference
datasets reveals that training on NemoTron-CC HQ consistently outperforms other
reference datasets, followed by DCLM-baseline and FineWeb-Edu. In addition to
intermediate training checkpoints, the release includes logs, code, and
downstream evaluations to simplify reproduction, standardize comparison, and
facilitate future research.

</details>


### [39] [Identifying Key Features for Establishing Sustainable Agro-Tourism Centre: A Data Driven Approach](https://arxiv.org/abs/2509.09214)
*Alka Gadakh,Vidya Kumbhar,Sonal Khosla,Kumar Karunendra*

Main category: cs.LG

TL;DR: 本研究探讨了Agro-tourism的增长策略，通过两个阶段的方法确定了重要的增长指标，并应用了多种机器学习模型进行特征选择和分类分析，结果显示逻辑回归模型在不同数据分割比例下表现最佳


<details>
  <summary>Details</summary>
Motivation: Agro-tourism作为一种战略经济模式，旨在通过多样化本地社区（如农民）的收入来源来促进农村发展，同时保护本土文化传统和传统农业实践。由于Agro-tourism是一个快速增长的子领域，需要详细研究其增长策略

Method: 本研究分为两个阶段：第一阶段通过全面的文献综述确定了Agro-tourism增长的重要指标，第二阶段使用最先进的技术识别了Agro-tourism增长的重要指标。应用了机器学习模型进行特征选择，包括LASSO、逻辑回归、决策树、随机森林和XGBoost模型

Result: 研究结果表明，LASSO方法结合逻辑回归模型在70-30%的训练测试数据中表现出最高的分类准确率（98%），而在80-20%的训练测试数据中，逻辑回归模型保持最高准确率（99%）

Conclusion: 研究结果表明，LASSO方法结合逻辑回归模型在70-30%的训练测试数据中表现出最高的分类准确率（98%），而在80-20%的训练测试数据中，逻辑回归模型保持最高准确率（99%）

Abstract: Agro-tourism serves as a strategic economic model designed to facilitate
rural development by diversifying income streams for local communities like
farmers while promoting the conservation of indigenous cultural heritage and
traditional agricultural practices. As a very booming subdomain of tourism,
there is a need to study the strategies for the growth of Agro-tourism in
detail. The current study has identified the important indicators for the
growth and enhancement of agro-tourism. The study is conducted in two phases:
identification of the important indicators through a comprehensive literature
review and in the second phase state-of-the-art techniques were used to
identify the important indicators for the growth of agro-tourism. The
indicators are also called features synonymously, the machine learning models
for feature selection were applied and it was observed that the Least Absolute
Shrinkage and Selection Operator (LASSO) method combined with, the machine
Learning Classifiers such as Logistic Regression (LR), Decision Trees (DT),
Random Forest (RF) Tree, and Extreme Gradient Boosting (XGBOOST) models were
used to suggest the growth of the agro-tourism. The results show that with the
LASSO method, LR model gives the highest classification accuracy of 98% in
70-30% train-test data followed by RF with 95% accuracy. Similarly, in the
80-20% train-test data LR maintains the highest accuracy at 99%, while DT and
XGBoost follow with 97% accuracy.

</details>


### [40] [Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents](https://arxiv.org/abs/2509.09265)
*Jiawei Wang,Jiacai Liu,Yuqian Fu,Yingru Li,Xintao Wang,Yuan Lin,Yu Yue,Lin Zhang,Yang Wang,Ke Wang*

Main category: cs.LG

TL;DR: 本文提出了一种名为EMPG的框架，通过基于步骤不确定性及最终任务结果重新校准学习信号，解决了长时域任务中由于稀疏奖励导致的信用分配问题。实验表明，EMPG在多个任务中表现出色，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: In long-horizon tasks, recent agents based on Large Language Models (LLMs) face a significant challenge that sparse, outcome-based rewards make it difficult to assign credit to intermediate steps.

Method: Entropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the learning signal based on step-wise uncertainty and the final task outcome.

Result: Through comprehensive experiments on three challenging agent tasks, WebShop, ALFWorld, and Deep Search, we demonstrate that EMPG achieves substantial performance gains.

Conclusion: EMPG achieves substantial performance gains and significantly outperforms strong policy gradient baselines.

Abstract: In long-horizon tasks, recent agents based on Large Language Models (LLMs)
face a significant challenge that sparse, outcome-based rewards make it
difficult to assign credit to intermediate steps. Previous methods mainly focus
on creating dense reward signals to guide learning, either through traditional
reinforcement learning techniques like inverse reinforcement learning or by
using Process Reward Models for step-by-step feedback. In this paper, we
identify a fundamental problem in the learning dynamics of LLMs: the magnitude
of policy gradients is inherently coupled with the entropy, which leads to
inefficient small updates for confident correct actions and potentially
destabilizes large updates for uncertain ones. To resolve this, we propose
Entropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the
learning signal based on step-wise uncertainty and the final task outcome. EMPG
amplifies updates for confident correct actions, penalizes confident errors,
and attenuates updates from uncertain steps to stabilize exploration. We
further introduce a bonus term for future clarity that encourages agents to
find more predictable solution paths. Through comprehensive experiments on
three challenging agent tasks, WebShop, ALFWorld, and Deep Search, we
demonstrate that EMPG achieves substantial performance gains and significantly
outperforms strong policy gradient baselines. Project page is at
https://empgseed-seed.github.io/

</details>


### [41] [LLMs Don't Know Their Own Decision Boundaries: The Unreliability of Self-Generated Counterfactual Explanations](https://arxiv.org/abs/2509.09396)
*Harry Mayne,Ryan Othniel Kearns,Yushi Yang,Andrew M. Bean,Eoin Delaney,Chris Russell,Adam Mahdi*

Main category: cs.LG

TL;DR: This paper evaluates the effectiveness of self-generated counterfactual explanations (SCEs) in language models. It finds that while SCEs are often valid, they are rarely minimal and offer limited insight into model behavior. The results suggest that SCEs may be an ineffective or even misleading explainability tool.


<details>
  <summary>Details</summary>
Motivation: To collaborate effectively with humans, language models must be able to explain their decisions in natural language. The study aims to assess the effectiveness of SCEs as an explainability tool.

Method: We study self-generated counterfactual explanations (SCEs) where a model explains its prediction by modifying the input such that it would have predicted a different outcome. We evaluate whether LLMs can produce SCEs that are valid and minimal.

Result: LLMs typically produce SCEs that are valid but not minimal, offering little insight into their decision-making behavior. When asked to generate minimal counterfactuals, LLMs make excessively small edits that fail to change predictions. The validity-minimality trade-off is consistent across several LLMs, datasets, and evaluation settings.

Conclusion: SCEs are, at best, an ineffective explainability tool and, at worst, can provide misleading insights into model behaviour. Proposals to deploy LLMs in high-stakes settings must consider the impact of unreliable self-explanations on downstream decision-making.

Abstract: To collaborate effectively with humans, language models must be able to
explain their decisions in natural language. We study a specific type of
self-explanation: self-generated counterfactual explanations (SCEs), where a
model explains its prediction by modifying the input such that it would have
predicted a different outcome. We evaluate whether LLMs can produce SCEs that
are valid, achieving the intended outcome, and minimal, modifying the input no
more than necessary. When asked to generate counterfactuals, we find that LLMs
typically produce SCEs that are valid, but far from minimal, offering little
insight into their decision-making behaviour. Worryingly, when asked to
generate minimal counterfactuals, LLMs typically make excessively small edits
that fail to change predictions. The observed validity-minimality trade-off is
consistent across several LLMs, datasets, and evaluation settings. Our findings
suggest that SCEs are, at best, an ineffective explainability tool and, at
worst, can provide misleading insights into model behaviour. Proposals to
deploy LLMs in high-stakes settings must consider the impact of unreliable
self-explanations on downstream decision-making. Our code is available at
https://github.com/HarryMayne/SCEs.

</details>


### [42] [ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable Orthogonal Butterfly Transforms](https://arxiv.org/abs/2509.09679)
*Bingxin Xu,Zhen Dong,Oussama Elachqar,Yuzhang Shang*

Main category: cs.LG

TL;DR: ButterflyQuant improves 2-bit quantization by using learnable butterfly transforms and uniformity regularization, achieving better performance than existing methods.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the limitations of fixed rotation-based methods for extreme 2-bit quantization, which cannot adapt to specific weight distributions and suffer from catastrophic performance loss due to outliers in activations.

Method: ButterflyQuant replaces Hadamard rotations with learnable butterfly transforms parameterized by continuous Givens rotation angles, enabling smooth optimization while maintaining orthogonality. It also introduces uniformity regularization on post-transformation activations.

Result: ButterflyQuant achieves a perplexity of 15.4 on LLaMA-2-7B with 2-bit quantization, outperforming QuaRot's 22.1. It requires only 128 calibration samples and converges quickly on a single GPU.

Conclusion: ButterflyQuant achieves better performance than existing methods with 2-bit quantization, demonstrating the effectiveness of layer-adaptive rotations and learnable butterfly transforms.

Abstract: Large language models require massive memory footprints, severely limiting
deployment on consumer hardware. Quantization reduces memory through lower
numerical precision, but extreme 2-bit quantization suffers from catastrophic
performance loss due to outliers in activations. Rotation-based methods such as
QuIP and QuaRot apply orthogonal transforms to eliminate outliers before
quantization, using computational invariance: $\mathbf{y} = \mathbf{Wx} =
(\mathbf{WQ}^T)(\mathbf{Qx})$ for orthogonal $\mathbf{Q}$. However, these
methods use fixed transforms--Hadamard matrices achieving optimal worst-case
coherence $\mu = 1/\sqrt{n}$--that cannot adapt to specific weight
distributions. We identify that different transformer layers exhibit distinct
outlier patterns, motivating layer-adaptive rotations rather than
one-size-fits-all approaches. We propose ButterflyQuant, which replaces
Hadamard rotations with learnable butterfly transforms parameterized by
continuous Givens rotation angles. Unlike Hadamard's discrete $\{+1, -1\}$
entries that are non-differentiable and prohibit gradient-based learning,
butterfly transforms' continuous parameterization enables smooth optimization
while guaranteeing orthogonality by construction. This orthogonal constraint
ensures theoretical guarantees in outlier suppression while achieving $O(n \log
n)$ computational complexity with only $\frac{n \log n}{2}$ learnable
parameters. We further introduce a uniformity regularization on
post-transformation activations to promote smoother distributions amenable to
quantization. Learning requires only 128 calibration samples and converges in
minutes on a single GPU--a negligible one-time cost. On LLaMA-2-7B with 2-bit
quantization, ButterflyQuant achieves 15.4 perplexity versus 22.1 for QuaRot.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [43] [Generative Engine Optimization: How to Dominate AI Search](https://arxiv.org/abs/2509.08919)
*Mahe Chen,Xiaoxuan Wang,Kaiwen Chen,Nick Koudas*

Main category: cs.IR

TL;DR: 本文研究了生成式AI搜索与传统搜索引擎之间的差异，并提出了生成式引擎优化（GEO）的战略议程。


<details>
  <summary>Details</summary>
Motivation: 随着像ChatGPT、Perplexity和Gemini这样的生成式AI驱动的搜索引擎的迅速采用，信息检索正在从传统的排名列表转变为合成的、有引用支持的答案。这种转变挑战了现有的搜索引擎优化（SEO）实践，并需要一个新的范式，即生成式引擎优化（GEO）。

Method: 本文通过一系列大规模、受控实验，在多个垂直领域、语言和查询改写中进行了AI搜索和传统网络搜索（Google）的全面比较分析。

Result: 关键发现表明，AI搜索表现出对获得的媒体（第三方权威来源）的系统性且压倒性的偏见，而不是品牌拥有和社交媒体内容，这与Google更平衡的混合形成鲜明对比。我们进一步证明，AI搜索服务在领域多样性、新鲜度、跨语言稳定性以及对措辞的敏感性方面彼此存在显著差异。

Conclusion: 本文提供了在新的生成式搜索景观中实现可见性的基础实证分析和战略框架。

Abstract: The rapid adoption of generative AI-powered search engines like ChatGPT,
Perplexity, and Gemini is fundamentally reshaping information retrieval, moving
from traditional ranked lists to synthesized, citation-backed answers. This
shift challenges established Search Engine Optimization (SEO) practices and
necessitates a new paradigm, which we term Generative Engine Optimization
(GEO).
  This paper presents a comprehensive comparative analysis of AI Search and
traditional web search (Google). Through a series of large-scale, controlled
experiments across multiple verticals, languages, and query paraphrases, we
quantify critical differences in how these systems source information. Our key
findings reveal that AI Search exhibit a systematic and overwhelming bias
towards Earned media (third-party, authoritative sources) over Brand-owned and
Social content, a stark contrast to Google's more balanced mix. We further
demonstrate that AI Search services differ significantly from each other in
their domain diversity, freshness, cross-language stability, and sensitivity to
phrasing.
  Based on these empirical results, we formulate a strategic GEO agenda. We
provide actionable guidance for practitioners, emphasizing the critical need
to: (1) engineer content for machine scannability and justification, (2)
dominate earned media to build AI-perceived authority, (3) adopt
engine-specific and language-aware strategies, and (4) overcome the inherent
"big brand bias" for niche players. Our work provides the foundational
empirical analysis and a strategic framework for achieving visibility in the
new generative search landscape.

</details>


### [44] [Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations](https://arxiv.org/abs/2509.09651)
*Zakaria El Kassimi,Fares Fourati,Mohamed-Slim Alouini*

Main category: cs.IR

TL;DR: 本文研究了无线电法规领域的问答问题，提出了一种电信特定的检索增强生成（RAG）管道，并创建了第一个多选评估集。实验结果表明，该方法在生成准确性上显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 我们研究了无线电法规领域的问答，这是一个法律敏感且高风险的领域。

Method: 我们提出了一个电信特定的检索增强生成（RAG）管道，并引入了我们认为的第一个多选评估集，该集从权威来源使用自动化过滤和人工验证构建。

Result: 我们的检索器在定义的领域特定检索指标下达到了约97%的准确率。除了检索之外，我们的方法在所有测试模型的生成准确性上都有所提高。特别是，虽然天真地插入没有结构化检索的文档仅对GPT-4o产生微不足道的增益（不到1%），但应用我们的管道却带来了近12%的相对改进。

Conclusion: 这些发现表明，精心定位的接地提供了一个简单而强大的基线，并为法规问答提供了有效的领域特定解决方案。

Abstract: We study question answering in the domain of radio regulations, a legally
sensitive and high-stakes area. We propose a telecom-specific
Retrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge,
the first multiple-choice evaluation set for this domain, constructed from
authoritative sources using automated filtering and human validation. To assess
retrieval quality, we define a domain-specific retrieval metric, under which
our retriever achieves approximately 97% accuracy. Beyond retrieval, our
approach consistently improves generation accuracy across all tested models. In
particular, while naively inserting documents without structured retrieval
yields only marginal gains for GPT-4o (less than 1%), applying our pipeline
results in nearly a 12% relative improvement. These findings demonstrate that
carefully targeted grounding provides a simple yet strong baseline and an
effective domain-specific solution for regulatory question answering. All code
and evaluation scripts, along with our derived question-answer dataset, are
available at https://github.com/Zakaria010/Radio-RAG.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [45] [A vibe coding learning design to enhance EFL students' talking to, through, and about AI](https://arxiv.org/abs/2509.08854)
*David James Woo,Kai Guo,Yangyang Yu*

Main category: cs.CY

TL;DR: 本文报告了在英语作为外语教育中试点使用vibe coding（使用自然语言通过AI创建软件应用程序）的创新实践。研究开发了一个包含三个维度的人机元语言框架，并通过案例研究方法分析了学生的不同表现，得出有效vibe coding教学需要明确的元语言支架的结论。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨使用自然语言通过AI创建软件应用程序（vibe coding）在英语作为外语（EFL）教育中的应用。

Method: 本文采用案例研究方法，收集了工作表、视频记录、自言自语协议、屏幕录制和AI生成图像的数据。

Result: 研究结果揭示了学生在提示工程方法上的差异，这表明不同的AI心理模型和在归因作者权方面的紧张关系。一个学生成功地vibe编码了一个符合她设计功能的应用程序，而另一个学生遇到了技术困难，其设计意图与实际功能之间存在重大差距。

Conclusion: 本文认为AI作为一种有益的语言工具，有效的vibe编码教学需要明确的元语言支架，教授结构化的提示工程，促进批判性的作者权讨论，并发展用于阐述AI心理模型的词汇。

Abstract: This innovative practice article reports on the piloting of vibe coding
(using natural language to create software applications with AI) for English as
a Foreign Language (EFL) education. We developed a human-AI meta-languaging
framework with three dimensions: talking to AI (prompt engineering), talking
through AI (negotiating authorship), and talking about AI (mental models of
AI). Using backward design principles, we created a four-hour workshop where
two students designed applications addressing authentic EFL writing challenges.
We adopted a case study methodology, collecting data from worksheets and video
recordings, think-aloud protocols, screen recordings, and AI-generated images.
Contrasting cases showed one student successfully vibe coding a functional
application cohering to her intended design, while another encountered
technical difficulties with major gaps between intended design and actual
functionality. Analysis reveals differences in students' prompt engineering
approaches, suggesting different AI mental models and tensions in attributing
authorship. We argue that AI functions as a beneficial languaging machine, and
that differences in how students talk to, through, and about AI explain vibe
coding outcome variations. Findings indicate that effective vibe coding
instruction requires explicit meta-languaging scaffolding, teaching structured
prompt engineering, facilitating critical authorship discussions, and
developing vocabulary for articulating AI mental models.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [46] [OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning](https://arxiv.org/abs/2509.09332)
*Yuecheng Liu,Dafeng Chi,Shiguang Wu,Zhanguang Zhang,Yuzheng Zhuang,Bowen Yang,He Zhu,Lingfeng Zhang,Pengwei Xie,David Gamaliel Arcos Bravo,Yingxue Zhang,Jianye Hao,Xingyue Quan*

Main category: cs.RO

TL;DR: OmniEVA is an embodied versatile planner that addresses the limitations of current MLLM-based embodied systems by introducing a Task-Adaptive 3D Grounding mechanism and an Embodiment-Aware Reasoning framework. It achieves state-of-the-art performance in embodied reasoning and demonstrates strong capabilities across various downstream scenarios.


<details>
  <summary>Details</summary>
Motivation: Current MLLM-based embodied systems face two critical limitations: Geometric Adaptability Gap and Embodiment Constraint Gap. Models trained solely on 2D inputs or with hard-coded 3D geometry injection suffer from either insufficient spatial information or restricted 2D generalization, leading to poor adaptability across tasks with diverse spatial demands. Prior work often neglects the physical constraints and capacities of real robots, resulting in task plans that are theoretically valid but practically infeasible.

Method: Introduce OmniEVA -- an embodied versatile planner that enables advanced embodied reasoning and task planning through two pivotal innovations: (1) a Task-Adaptive 3D Grounding mechanism, which introduces a gated router to perform explicit selective regulation of 3D fusion based on contextual requirements, enabling context-aware 3D grounding for diverse embodied tasks. (2) an Embodiment-Aware Reasoning framework that jointly incorporates task goals and embodiment constraints into the reasoning loop, resulting in planning decisions that are both goal-directed and executable.

Result: Extensive experimental results demonstrate that OmniEVA achieves state-of-the-art general embodied reasoning performance and exhibits a strong ability across a wide range of downstream scenarios. Evaluations of a suite of proposed embodied benchmarks, including both primitive and composite tasks, confirm its robust and versatile planning capabilities.

Conclusion: OmniEVA not only achieves state-of-the-art general embodied reasoning performance, but also exhibits a strong ability across a wide range of downstream scenarios. Evaluations of a suite of proposed embodied benchmarks confirm its robust and versatile planning capabilities.

Abstract: Recent advances in multimodal large language models (MLLMs) have opened new
opportunities for embodied intelligence, enabling multimodal understanding,
reasoning, and interaction, as well as continuous spatial decision-making.
Nevertheless, current MLLM-based embodied systems face two critical
limitations. First, Geometric Adaptability Gap: models trained solely on 2D
inputs or with hard-coded 3D geometry injection suffer from either insufficient
spatial information or restricted 2D generalization, leading to poor
adaptability across tasks with diverse spatial demands. Second, Embodiment
Constraint Gap: prior work often neglects the physical constraints and
capacities of real robots, resulting in task plans that are theoretically valid
but practically infeasible.To address these gaps, we introduce OmniEVA -- an
embodied versatile planner that enables advanced embodied reasoning and task
planning through two pivotal innovations: (1) a Task-Adaptive 3D Grounding
mechanism, which introduces a gated router to perform explicit selective
regulation of 3D fusion based on contextual requirements, enabling
context-aware 3D grounding for diverse embodied tasks. (2) an Embodiment-Aware
Reasoning framework that jointly incorporates task goals and embodiment
constraints into the reasoning loop, resulting in planning decisions that are
both goal-directed and executable. Extensive experimental results demonstrate
that OmniEVA not only achieves state-of-the-art general embodied reasoning
performance, but also exhibits a strong ability across a wide range of
downstream scenarios. Evaluations of a suite of proposed embodied benchmarks,
including both primitive and composite tasks, confirm its robust and versatile
planning capabilities. Project page: https://omnieva.github.io

</details>


### [47] [SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning](https://arxiv.org/abs/2509.09674)
*Haozhan Li,Yuxin Zuo,Jiale Yu,Yuhao Zhang,Zhaohui Yang,Kaiyan Zhang,Xuekai Zhu,Yuchen Zhang,Tianxing Chen,Ganqu Cui,Dehui Wang,Dingxiang Luo,Yuchen Fan,Youbang Sun,Jia Zeng,Jiangmiao Pang,Shanghang Zhang,Yu Wang,Yao Mu,Bowen Zhou,Ning Ding*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Vision-Language-Action (VLA) models have recently emerged as a powerful
paradigm for robotic manipulation. Despite substantial progress enabled by
large-scale pretraining and supervised fine-tuning (SFT), these models face two
fundamental challenges: (i) the scarcity and high cost of large-scale
human-operated robotic trajectories required for SFT scaling, and (ii) limited
generalization to tasks involving distribution shift. Recent breakthroughs in
Large Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can
dramatically enhance step-by-step reasoning capabilities, raising a natural
question: Can RL similarly improve the long-horizon step-by-step action
planning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL
framework tailored for VLA models. Building upon veRL, we introduce
VLA-specific trajectory sampling, scalable parallelization, multi-environment
rendering, and optimized loss computation. When applied to OpenVLA-OFT,
SimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $\pi_0$
on RoboTwin 1.0\&2.0 with the exploration-enhancing strategies we introduce.
SimpleVLA-RL not only reduces dependence on large-scale data and enables robust
generalization, but also remarkably surpasses SFT in real-world tasks.
Moreover, we identify a novel phenomenon ``pushcut'' during RL training,
wherein the policy discovers previously unseen patterns beyond those seen in
the previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [48] [Bona fide Cross Testing Reveals Weak Spot in Audio Deepfake Detection Systems](https://arxiv.org/abs/2509.09204)
*Chin Yuen Kwok,Jia Qi Yip,Zhen Qiu,Chi Hung Chi,Kwok Yan Lam*

Main category: cs.SD

TL;DR: 本文提出了一种新的评估框架，以解决当前音频深度伪造检测模型评估中数据集多样性和可靠性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的音频深度伪造检测模型评估数据集通常结合多个合成器，但这种方法不成比例地加权样本较多的合成器，低估了其他合成器的影响，限制了EER的整体可靠性。此外，大多数ADD数据集在真实语音方面缺乏多样性，通常只包含一种环境和语音风格，限制了它们模拟现实条件的能力。

Method: 我们提出了一个名为真实交叉测试的新型评估框架，该框架结合了多样化的真实数据集，并汇总EER以进行更平衡的评估。

Result: 我们对九种真实语音类型中的150多个合成器进行了基准测试，并发布了一个新的数据集以促进进一步的研究。

Conclusion: 我们的方法相比传统评估方法提高了鲁棒性和可解释性。我们对超过150个合成器进行了基准测试，并发布了一个新的数据集以促进进一步的研究。

Abstract: Audio deepfake detection (ADD) models are commonly evaluated using datasets
that combine multiple synthesizers, with performance reported as a single Equal
Error Rate (EER). However, this approach disproportionately weights
synthesizers with more samples, underrepresenting others and reducing the
overall reliability of EER. Additionally, most ADD datasets lack diversity in
bona fide speech, often featuring a single environment and speech style (e.g.,
clean read speech), limiting their ability to simulate real-world conditions.
To address these challenges, we propose bona fide cross-testing, a novel
evaluation framework that incorporates diverse bona fide datasets and
aggregates EERs for more balanced assessments. Our approach improves robustness
and interpretability compared to traditional evaluation methods. We benchmark
over 150 synthesizers across nine bona fide speech types and release a new
dataset to facilitate further research at
https://github.com/cyaaronk/audio_deepfake_eval.

</details>


### [49] [DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for Low-Latency Zero-Shot Text-To-Speech](https://arxiv.org/abs/2509.09631)
*Ngoc-Son Nguyen,Hieu-Nghia Huynh-Nguyen,Thanh V. T. Tran,Truong-Son Hy,Van Nguyen*

Main category: cs.SD

TL;DR: DiFlow-TTS是第一个探索纯离散流匹配用于语音合成的模型，它在紧凑且统一的架构中显式建模了分解的语音属性。该模型通过条件化文本内容以及从参考语音中提取的韵律和声学属性，利用上下文学习，在零样本设置中实现有效的属性克隆。此外，该模型采用分解的流预测机制，具有不同的头部用于韵律和声学细节，使其能够学习特定方面的分布。实验结果表明，DiFlow-TTS在多个关键指标上取得了有希望的性能，包括自然度、韵律、说话人风格的保留和能量控制。它还保持了紧凑的模型大小，并实现了低延迟推理，生成语音的速度比最新的现有基线快25.8倍。


<details>
  <summary>Details</summary>
Motivation: 现有的流匹配方法通常将这些离散标记嵌入到连续空间中并应用连续流匹配，这可能无法充分利用离散表示的优势。因此，需要一种新的方法来解决零样本文本到语音合成中的挑战，如推理速度慢和重复伪影。

Method: DiFlow-TTS是第一个探索纯离散流匹配用于语音合成的模型，它在紧凑且统一的架构中显式建模了分解的语音属性。该模型通过条件化文本内容以及从参考语音中提取的韵律和声学属性，利用上下文学习，在零样本设置中实现有效的属性克隆。此外，该模型采用分解的流预测机制，具有不同的头部用于韵律和声学细节，使其能够学习特定方面的分布。

Result: 实验结果表明，DiFlow-TTS在多个关键指标上取得了有希望的性能，包括自然度、韵律、说话人风格的保留和能量控制。它还保持了紧凑的模型大小，并实现了低延迟推理，生成语音的速度比最新的现有基线快25.8倍。

Conclusion: DiFlow-TTS在多个关键指标上表现出色，包括自然度、韵律、说话人风格的保留和能量控制。同时，它保持了紧凑的模型大小，并实现了低延迟推理，生成语音的速度比最新的现有基线快25.8倍。

Abstract: Zero-shot Text-to-Speech (TTS) aims to synthesize high-quality speech that
mimics the voice of an unseen speaker using only a short reference sample,
requiring not only speaker adaptation but also accurate modeling of prosodic
attributes. Recent approaches based on language models, diffusion, and flow
matching have shown promising results in zero-shot TTS, but still suffer from
slow inference and repetition artifacts. Discrete codec representations have
been widely adopted for speech synthesis, and recent works have begun to
explore diffusion models in purely discrete settings, suggesting the potential
of discrete generative modeling for speech synthesis. However, existing
flow-matching methods typically embed these discrete tokens into a continuous
space and apply continuous flow matching, which may not fully leverage the
advantages of discrete representations. To address these challenges, we
introduce DiFlow-TTS, which, to the best of our knowledge, is the first model
to explore purely Discrete Flow Matching for speech synthesis. DiFlow-TTS
explicitly models factorized speech attributes within a compact and unified
architecture. It leverages in-context learning by conditioning on textual
content, along with prosodic and acoustic attributes extracted from a reference
speech, enabling effective attribute cloning in a zero-shot setting. In
addition, the model employs a factorized flow prediction mechanism with
distinct heads for prosody and acoustic details, allowing it to learn
aspect-specific distributions. Experimental results demonstrate that DiFlow-TTS
achieves promising performance in several key metrics, including naturalness,
prosody, preservation of speaker style, and energy control. It also maintains a
compact model size and achieves low-latency inference, generating speech up to
25.8 times faster than the latest existing baselines.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [50] [Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs](https://arxiv.org/abs/2509.08847)
*Amna Hassan*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的框架，通过自然语言处理和多模态大型语言模型将游戏设计文档转换为功能性的Unity游戏原型，有效解决了AI辅助游戏开发中的关键差距。


<details>
  <summary>Details</summary>
Motivation: 本文旨在通过自然语言处理（NLP）和多模态大型语言模型（LLMs）将游戏设计文档（GDDs）转换为功能性的Unity游戏原型，从而解决AI辅助游戏开发中的关键差距。

Method: 我们引入了一个端到端的系统，解析GDD，提取结构化的游戏规范，并合成符合Unity的C#代码，该代码实现了设计文档中定义的核心机制、系统和架构。我们的方法结合了一个针对Unity代码生成进行微调的LLaMA-3模型和一个自定义的Unity集成包，以简化实现过程。

Result: 评估结果表明，与基线模型相比，我们的微调模型在编译成功率、GDD遵循度、最佳实践采用和代码模块化指标上表现出色，平均得分为4.8/5.0。生成的模板在多个游戏类型中表现出对GDD规范的高度遵循度。

Conclusion: 我们的系统有效解决了AI辅助游戏开发中的关键差距，将LLMs定位为在从游戏设计到实现的过渡中具有价值的工具。

Abstract: This paper presents a novel framework for automated game template generation
by transforming Game Design Documents (GDDs) into functional Unity game
prototypes using Natural Language Processing (NLP) and multi-modal Large
Language Models (LLMs). We introduce an end-to-end system that parses GDDs,
extracts structured game specifications, and synthesizes Unity-compatible C#
code that implements the core mechanics, systems, and architecture defined in
the design documentation. Our approach combines a fine-tuned LLaMA-3 model
specialized for Unity code generation with a custom Unity integration package
that streamlines the implementation process. Evaluation results demonstrate
significant improvements over baseline models, with our fine-tuned model
achieving superior performance (4.8/5.0 average score) compared to
state-of-the-art LLMs across compilation success, GDD adherence, best practices
adoption, and code modularity metrics. The generated templates demonstrate high
adherence to GDD specifications across multiple game genres. Our system
effectively addresses critical gaps in AI-assisted game development,
positioning LLMs as valuable tools in streamlining the transition from game
design to implementation.

</details>


### [51] [Tree-OPO: Off-policy Monte Carlo Tree-Guided Advantage Optimization for Multistep Reasoning](https://arxiv.org/abs/2509.09284)
*Bingning Huang,Tu Nguyen,Matthieu Zimmer*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent advances in reasoning with large language models (LLMs) have shown the
effectiveness of Monte Carlo Tree Search (MCTS) for generating high-quality
intermediate trajectories, particularly in math and symbolic domains. Inspired
by this, we explore how MCTS-derived trajectories, traditionally used for
training value or reward models, can be repurposed to improve policy
optimization in preference-based reinforcement learning (RL). Specifically, we
focus on Group Relative Policy Optimization (GRPO), a recent algorithm that
enables preference-consistent policy learning without value networks. We
propose a staged GRPO training paradigm where completions are derived from
partially revealed MCTS rollouts, introducing a novel tree-structured setting
for advantage estimation. This leads to a rich class of prefix-conditioned
reward signals, which we analyze theoretically and empirically. Our initial
results indicate that while structured advantage estimation can stabilize
updates and better reflect compositional reasoning quality, challenges such as
advantage saturation and reward signal collapse remain. We propose heuristic
and statistical solutions to mitigate these issues and discuss open challenges
for learning under staged or tree-like reward structures.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [52] [Recurrence Meets Transformers for Universal Multimodal Retrieval](https://arxiv.org/abs/2509.08897)
*Davide Caffagni,Sara Sarto,Marcella Cornia,Lorenzo Baraldi,Rita Cucchiara*

Main category: cs.CV

TL;DR: 本文提出了一种名为ReT-2的统一检索模型，能够支持多模态查询和多模态文档集合的搜索。ReT-2在多个基准测试中表现出色，并且比之前的方法更快、更节省内存。


<details>
  <summary>Details</summary>
Motivation: 随着多模态检索的快速发展及其在LLMs和多模态LLMs中的应用，出现了越来越复杂的检索任务。现有方法主要依赖于特定任务的微调视觉语言模型，并且仅限于单模态查询或文档。

Method: ReT-2是一个统一的检索模型，支持多模态查询（包括图像和文本），并在多模态文档集合中进行搜索。它利用多层表示和具有LSTM启发式门控机制的循环Transformer架构，以动态整合跨层和模态的信息，捕捉细粒度的视觉和文本细节。

Result: ReT-2在M2KR和M-BEIR基准测试中表现出色，一致达到了最先进的性能。此外，与之前的方法相比，ReT-2提供了更快的推理和更少的内存使用。当集成到检索增强生成管道中时，ReT-2还提高了Encyclopedic-VQA和InfoSeek数据集的下游性能。

Conclusion: ReT-2在多种设置中 consistently achieves state-of-the-art performance，同时提供更快的推理和更少的内存使用。当集成到检索增强生成管道中时，ReT-2还提高了Encyclopedic-VQA和InfoSeek数据集的下游性能。

Abstract: With the rapid advancement of multimodal retrieval and its application in
LLMs and multimodal LLMs, increasingly complex retrieval tasks have emerged.
Existing methods predominantly rely on task-specific fine-tuning of
vision-language models and are limited to single-modality queries or documents.
In this paper, we propose ReT-2, a unified retrieval model that supports
multimodal queries, composed of both images and text, and searches across
multimodal document collections where text and images coexist. ReT-2 leverages
multi-layer representations and a recurrent Transformer architecture with
LSTM-inspired gating mechanisms to dynamically integrate information across
layers and modalities, capturing fine-grained visual and textual details. We
evaluate ReT-2 on the challenging M2KR and M-BEIR benchmarks across different
retrieval configurations. Results demonstrate that ReT-2 consistently achieves
state-of-the-art performance across diverse settings, while offering faster
inference and reduced memory usage compared to prior approaches. When
integrated into retrieval-augmented generation pipelines, ReT-2 also improves
downstream performance on Encyclopedic-VQA and InfoSeek datasets. Our source
code and trained models are publicly available at:
https://github.com/aimagelab/ReT-2

</details>


### [53] [COCO-Urdu: A Large-Scale Urdu Image-Caption Dataset with Multimodal Quality Estimation](https://arxiv.org/abs/2509.09014)
*Umair Hassan*

Main category: cs.CV

TL;DR: 本文介绍了COCO-Urdu，一个大规模的乌尔都语图像描述数据集，通过高质量的翻译和验证方法，旨在减少多模态研究中的语言偏见。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语在多模态和视觉-语言研究中严重不足，缺乏大规模高质量数据集限制了乌尔都语系统的开发，并加剧了以高资源语言为主训练的多语言视觉-语言模型中的偏见。

Method: 使用SeamlessM4T v2进行翻译，并利用混合多模态质量评估框架（包括COMET-Kiwi、CLIP-based相似性以及BERTScore与回译）对句子进行验证，低分句子通过开源大语言模型进行迭代优化。

Result: COCO-Urdu是目前最大的公开可用的乌尔都语图像描述数据集，在BLEU、SacreBLEU和chrF指标上表现出色。

Conclusion: 通过发布数据集和质量评估管道，我们旨在减少多模态研究中的语言偏见，并为包容性的视觉语言系统建立基础。

Abstract: Urdu, spoken by over 250 million people, remains critically under-served in
multimodal and vision-language research. The absence of large-scale,
high-quality datasets has limited the development of Urdu-capable systems and
reinforced biases in multilingual vision-language models trained primarily on
high-resource languages. To address this gap, we present COCO-Urdu, a
large-scale image-caption dataset derived from MS COCO, containing 59,000
images and 319,000 Urdu captions selected through stratified sampling to
preserve the original distribution. Captions were translated using SeamlessM4T
v2 and validated with a hybrid multimodal quality estimation framework that
integrates COMET-Kiwi for translation quality, CLIP-based similarity for visual
grounding, and BERTScore with back-translation for semantic consistency;
low-scoring captions were iteratively refined using open-source large language
models. We further benchmark COCO-Urdu on BLEU, SacreBLEU, and chrF, reporting
consistently strong results. To the best of our knowledge, COCO-Urdu is the
largest publicly available Urdu captioning dataset. By releasing both the
dataset and the quality estimation pipeline, we aim to reduce language bias in
multimodal research and establish a foundation for inclusive vision-language
systems.

</details>


### [54] [Can Multimodal LLMs See Materials Clearly? A Multimodal Benchmark on Materials Characterization](https://arxiv.org/abs/2509.09307)
*Zhengzhao Lai,Youbin Zheng,Zhenyang Cai,Haonan Lyu,Jinpu Yang,Hongqing Liang,Yan Hu,Benyou Wang*

Main category: cs.CV

TL;DR: 本文提出了MatCha基准，用于评估多模态大语言模型在材料表征图像理解中的表现，结果表明现有模型在处理需要高级专业知识和复杂视觉感知的问题时存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 为了填补多模态大语言模型在理解真实世界材料表征图像数据方面的不足，需要一个专门的基准来评估其能力。

Method: 提出MatCha基准，用于评估多模态大语言模型在材料表征图像理解中的表现。

Result: 评估结果显示，最先进的多模态大语言模型在MatCha上的表现与人类专家存在显著差距，特别是在需要高级专业知识和复杂视觉感知的问题上。

Conclusion: 现有的多模态大语言模型在真实材料表征场景中的适应性仍然有限，需要进一步研究以提升其性能。

Abstract: Materials characterization is fundamental to acquiring materials information,
revealing the processing-microstructure-property relationships that guide
material design and optimization. While multimodal large language models
(MLLMs) have recently shown promise in generative and predictive tasks within
materials science, their capacity to understand real-world characterization
imaging data remains underexplored. To bridge this gap, we present MatCha, the
first benchmark for materials characterization image understanding, comprising
1,500 questions that demand expert-level domain expertise. MatCha encompasses
four key stages of materials research comprising 21 distinct tasks, each
designed to reflect authentic challenges faced by materials scientists. Our
evaluation of state-of-the-art MLLMs on MatCha reveals a significant
performance gap compared to human experts. These models exhibit degradation
when addressing questions requiring higher-level expertise and sophisticated
visual perception. Simple few-shot and chain-of-thought prompting struggle to
alleviate these limitations. These findings highlight that existing MLLMs still
exhibit limited adaptability to real-world materials characterization
scenarios. We hope MatCha will facilitate future research in areas such as new
material discovery and autonomous scientific agents. MatCha is available at
https://github.com/FreedomIntelligence/MatCha.

</details>


### [55] [FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark](https://arxiv.org/abs/2509.09680)
*Rongyao Fang,Aldrich Yu,Chengqi Duan,Linjiang Huang,Shuai Bai,Yuxuan Cai,Kun Wang,Si Liu,Xihui Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: 本文介绍了FLUX-Reason-6M数据集和PRISM-Bench基准，以解决开源文本到图像模型缺乏大规模、面向推理的数据集和评估基准的问题。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大规模、面向推理的数据集和全面的评估基准，开源文本到图像模型的发展受到了阻碍。

Method: 我们引入了FLUX-Reason-6M数据集和PRISM-Bench基准，用于评估文本到图像生成模型的性能。

Result: 我们在PRISM-Bench上对19个领先的模型进行了广泛的评估，揭示了关键的性能差距，并指出了需要改进的具体领域。

Conclusion: 我们的数据集、基准和评估代码已发布，以推动面向推理的T2I生成的下一次浪潮。

Abstract: The advancement of open-source text-to-image (T2I) models has been hindered
by the absence of large-scale, reasoning-focused datasets and comprehensive
evaluation benchmarks, resulting in a performance gap compared to leading
closed-source systems. To address this challenge, We introduce FLUX-Reason-6M
and PRISM-Bench (Precise and Robust Image Synthesis Measurement Benchmark).
FLUX-Reason-6M is a massive dataset consisting of 6 million high-quality
FLUX-generated images and 20 million bilingual (English and Chinese)
descriptions specifically designed to teach complex reasoning. The image are
organized according to six key characteristics: Imagination, Entity, Text
rendering, Style, Affection, and Composition, and design explicit Generation
Chain-of-Thought (GCoT) to provide detailed breakdowns of image generation
steps. The whole data curation takes 15,000 A100 GPU days, providing the
community with a resource previously unattainable outside of large industrial
labs. PRISM-Bench offers a novel evaluation standard with seven distinct
tracks, including a formidable Long Text challenge using GCoT. Through
carefully designed prompts, it utilizes advanced vision-language models for
nuanced human-aligned assessment of prompt-image alignment and image
aesthetics. Our extensive evaluation of 19 leading models on PRISM-Bench
reveals critical performance gaps and highlights specific areas requiring
improvement. Our dataset, benchmark, and evaluation code are released to
catalyze the next wave of reasoning-oriented T2I generation. Project page:
https://flux-reason-6m.github.io/ .

</details>
