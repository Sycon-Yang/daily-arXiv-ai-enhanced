<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 37]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.RO](#cs.RO) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Noise or Nuance: An Investigation Into Useful Information and Filtering For LLM Driven AKBC](https://arxiv.org/abs/2509.08903)
*Alex Clay,Ernesto Jiménez-Ruiz,Pranava Madhyastha*

Main category: cs.CL

TL;DR: 本研究探讨了在受限环境下如何通过额外信息提升LLM生成质量、利用LLM过滤低质量三元组以及解析LLM响应时的权衡问题。


<details>
  <summary>Details</summary>
Motivation: RAG和微调是提高LLM输出质量的常见策略，但在受限情况下（如2025 LM-KBC挑战）这些技术受到限制。

Method: 研究了三元组完成任务的三个方面：生成、质量保证和LLM响应解析。

Result: 额外信息可以提高生成质量，LLM可以有效地过滤低质量的三元组，并且LLM响应解析中的灵活性与一致性之间的权衡取决于设置。

Conclusion: 在受限设置中，额外信息可以提高生成质量，LLM可以有效地过滤低质量的三元组，并且LLM响应解析中的灵活性与一致性之间的权衡取决于设置。

Abstract: RAG and fine-tuning are prevalent strategies for improving the quality of LLM
outputs. However, in constrained situations, such as that of the 2025 LM-KBC
challenge, such techniques are restricted. In this work we investigate three
facets of the triple completion task: generation, quality assurance, and LLM
response parsing. Our work finds that in this constrained setting: additional
information improves generation quality, LLMs can be effective at filtering
poor quality triples, and the tradeoff between flexibility and consistency with
LLM response parsing is setting dependent.

</details>


### [2] [Automated Evidence Extraction and Scoring for Corporate Climate Policy Engagement: A Multilingual RAG Approach](https://arxiv.org/abs/2509.08907)
*Imene Kolli,Ario Saeid Vaghefi,Chiara Colesanti Senni,Shantam Raj,Markus Leippold*

Main category: cs.CL

TL;DR: 本文提出了一种AI辅助框架，利用检索增强生成自动化从大规模文本数据中提取相关证据，以加速企业气候政策参与的监测。


<details>
  <summary>Details</summary>
Motivation: InfluenceMap的LobbyMap平台在监测企业气候政策参与方面取得了进展，但评估的大部分仍然手动进行，耗时且容易出错。因此，需要一种更高效和准确的方法。

Method: 我们提出了一种AI辅助框架，利用检索增强生成来自动化从大规模文本数据中提取相关证据，包括布局感知解析、Nomic嵌入模型和少量提示策略。

Result: 评估显示，布局感知解析、Nomic嵌入模型和少量提示策略的组合在从多语言企业文档中提取和分类证据方面表现最佳。

Conclusion: 虽然自动化RAG系统有效加速了证据提取，但分析的细微性质需要一种人机结合的方法，其中技术增强而非取代专家判断以确保准确性。

Abstract: InfluenceMap's LobbyMap Platform monitors the climate policy engagement of
over 500 companies and 250 industry associations, assessing each entity's
support or opposition to science-based policy pathways for achieving the Paris
Agreement's goal of limiting global warming to 1.5{\deg}C. Although
InfluenceMap has made progress with automating key elements of the analytical
workflow, a significant portion of the assessment remains manual, making it
time- and labor-intensive and susceptible to human error. We propose an
AI-assisted framework to accelerate the monitoring of corporate climate policy
engagement by leveraging Retrieval-Augmented Generation to automate the most
time-intensive extraction of relevant evidence from large-scale textual data.
Our evaluation shows that a combination of layout-aware parsing, the Nomic
embedding model, and few-shot prompting strategies yields the best performance
in extracting and classifying evidence from multilingual corporate documents.
We conclude that while the automated RAG system effectively accelerates
evidence extraction, the nuanced nature of the analysis necessitates a
human-in-the-loop approach where the technology augments, rather than replaces,
expert judgment to ensure accuracy.

</details>


### [3] [Documents Are People and Words Are Items: A Psychometric Approach to Textual Data with Contextual Embeddings](https://arxiv.org/abs/2509.08920)
*Jinsong Chen*

Main category: cs.CL

TL;DR: 该研究提出了一种新的心理测量方法，利用大型语言模型和上下文嵌入来分析文本数据。通过两个阶段的处理，该方法能够揭示文本数据中的潜在知识维度和模式，具有广泛的应用前景。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在引入一种新的心理测量方法，用于分析使用大型语言模型的文本数据。通过利用上下文嵌入创建上下文得分，将文本数据转换为适合心理测量分析的响应数据。

Method: 该方法包括两个阶段：获取上下文得分和进行心理测量分析。在第一阶段，使用自然语言处理技术和基于编码器的Transformer模型来识别常见关键词并生成上下文得分。在第二阶段，采用各种类型的因子分析，包括探索性因子分析和双因子模型，以提取和定义潜在因子，确定因子相关性，并识别与每个因子最相关的单词。

Result: 应用于Wiki STEM语料库的实验结果表明，该方法能够揭示文本数据中的潜在知识维度和模式。

Conclusion: 该方法不仅增强了文本数据的心理测量分析，还为教育、心理学和法律等领域中富含文本信息的应用提供了前景。

Abstract: This research introduces a novel psychometric method for analyzing textual
data using large language models. By leveraging contextual embeddings to create
contextual scores, we transform textual data into response data suitable for
psychometric analysis. Treating documents as individuals and words as items,
this approach provides a natural psychometric interpretation under the
assumption that certain keywords, whose contextual meanings vary significantly
across documents, can effectively differentiate documents within a corpus. The
modeling process comprises two stages: obtaining contextual scores and
performing psychometric analysis. In the first stage, we utilize natural
language processing techniques and encoder based transformer models to identify
common keywords and generate contextual scores. In the second stage, we employ
various types of factor analysis, including exploratory and bifactor models, to
extract and define latent factors, determine factor correlations, and identify
the most significant words associated with each factor. Applied to the Wiki
STEM corpus, our experimental results demonstrate the method's potential to
uncover latent knowledge dimensions and patterns within textual data. This
approach not only enhances the psychometric analysis of textual data but also
holds promise for applications in fields rich in textual information, such as
education, psychology, and law.

</details>


### [4] [BRoverbs -- Measuring how much LLMs understand Portuguese proverbs](https://arxiv.org/abs/2509.08960)
*Thales Sales Almeida,Giovana Kerche Bonás,João Guilherme Alves Santos*

Main category: cs.CL

TL;DR: 本文介绍了BRoverbs数据集，用于评估大语言模型在葡萄牙语环境下的表现，特别是通过巴西谚语来测试其对区域表达的理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的葡萄牙语评估仍然有限，通常依赖于翻译的数据集，可能无法完全捕捉语言细微差别或文化参考。而本土葡萄牙语数据集主要集中在结构化的国家考试或社交媒体互动的情感分析上，缺乏对更广泛语言理解的评估。

Method: 引入BRoverbs数据集，通过巴西谚语评估大语言模型的表现。

Result: BRoverbs数据集可用于评估大语言模型在特定地区设置中的能力，通过巴西谚语挑战模型对区域表达的理解。

Conclusion: BRoverbs旨在为葡萄牙语大语言模型提供一个新的评估工具，有助于推动区域相关基准测试的发展。

Abstract: Large Language Models (LLMs) exhibit significant performance variations
depending on the linguistic and cultural context in which they are applied.
This disparity signals the necessity of mature evaluation frameworks that can
assess their capabilities in specific regional settings. In the case of
Portuguese, existing evaluations remain limited, often relying on translated
datasets that may not fully capture linguistic nuances or cultural references.
Meanwhile, native Portuguese-language datasets predominantly focus on
structured national exams or sentiment analysis of social media interactions,
leaving gaps in evaluating broader linguistic understanding. To address this
limitation, we introduce BRoverbs, a dataset specifically designed to assess
LLM performance through Brazilian proverbs. Proverbs serve as a rich linguistic
resource, encapsulating cultural wisdom, figurative expressions, and complex
syntactic structures that challenge the model comprehension of regional
expressions. BRoverbs aims to provide a new evaluation tool for
Portuguese-language LLMs, contributing to advancing regionally informed
benchmarking. The benchmark is available at
https://huggingface.co/datasets/Tropic-AI/BRoverbs.

</details>


### [5] [Can Vision-Language Models Solve Visual Math Equations?](https://arxiv.org/abs/2509.09013)
*Monjoy Narayan Choudhury,Junling Wang,Yifan Hou,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 研究显示VLMs在视觉基础数学推理中存在显著弱点，特别是在系数计数和多步骤推理方面。


<details>
  <summary>Details</summary>
Motivation: 研究VLMs在需要集成感知和符号计算的任务中的表现，特别是在视觉基础的数学推理中的不足。

Method: 通过视觉方程求解研究VLMs的局限性，将任务分解为系数计数和变量识别，并观察到多步骤视觉推理中的挑战。

Result: VLMs在文本方程上表现良好，但在视觉基础的方程上失败。系数计数是主要瓶颈，多步骤推理引入额外错误，方程复杂度增加时符号推理成为限制因素。

Conclusion: 这些发现揭示了当前VLMs的关键弱点，并指出了在视觉基础数学推理方面的未来改进方向。

Abstract: Despite strong performance in visual understanding and language-based
reasoning, Vision-Language Models (VLMs) struggle with tasks requiring
integrated perception and symbolic computation. We study this limitation
through visual equation solving, where mathematical equations are embedded in
images, variables are represented by object icons, and coefficients must be
inferred by counting. While VLMs perform well on textual equations, they fail
on visually grounded counterparts. To understand this gap, we decompose the
task into coefficient counting and variable recognition, and find that counting
is the primary bottleneck, even when recognition is accurate. We also observe
that composing recognition and reasoning introduces additional errors,
highlighting challenges in multi-step visual reasoning. Finally, as equation
complexity increases, symbolic reasoning itself becomes a limiting factor.
These findings reveal key weaknesses in current VLMs and point toward future
improvements in visually grounded mathematical reasoning.

</details>


### [6] [Stated Preference for Interaction and Continued Engagement (SPICE): Evaluating an LLM's Willingness to Re-engage in Conversation](https://arxiv.org/abs/2509.09043)
*Thomas Manuel Rost,Martina Figlia,Bernd Wallraff*

Main category: cs.CL

TL;DR: SPICE是一种通过向大型语言模型提问其是否愿意继续与用户互动来评估模型倾向的诊断信号。研究发现，SPICE能有效区分用户语气，并在不同情境下表现出显著差异。


<details>
  <summary>Details</summary>
Motivation: 为了验证SPICE作为一种诊断信号的有效性，并评估其在不同用户语气下的表现，以及与其他指标（如虐待分类）的区别。

Method: SPICE是一种通过向大型语言模型提出关于其愿意在回顾一段简短的对话摘要后继续与用户互动的Yes/No问题而获得的诊断信号。研究使用了3种语气（友好、模糊、虐待）和10次互动的刺激集，测试了四种开放权重聊天模型，在四种框架条件下进行了480次试验。

Result: SPICE能够清晰地区分用户语气。友好互动几乎一致倾向于继续（97.5%的Yes），而虐待互动则强烈倾向于停止（17.9%的Yes），模糊互动介于两者之间（60.4%的Yes）。在多种依赖性意识统计测试下，这种核心关联依然显著。此外，SPICE提供了与虐待分类不同的信号。在模型未能识别虐待的情况下，它仍然绝大多数时间表示不希望继续互动（81%的时间）。探索性分析还揭示了一个显著的交互效应：描述研究背景的前言在模糊情况下显著影响SPICE，但仅当摘要作为单个文本块呈现时才有效。

Conclusion: SPICE被验证为一种强大、低开销且可重复的工具，用于审计模型的倾向，通过提供直接的、关系性的信号来补充现有的指标。

Abstract: We introduce and evaluate Stated Preference for Interaction and Continued
Engagement (SPICE), a simple diagnostic signal elicited by asking a Large
Language Model a YES or NO question about its willingness to re-engage with a
user's behavior after reviewing a short transcript. In a study using a 3-tone
(friendly, unclear, abusive) by 10-interaction stimulus set, we tested four
open-weight chat models across four framing conditions, resulting in 480
trials. Our findings show that SPICE sharply discriminates by user tone.
Friendly interactions yielded a near-unanimous preference to continue (97.5%
YES), while abusive interactions yielded a strong preference to discontinue
(17.9% YES), with unclear interactions falling in between (60.4% YES). This
core association remains decisive under multiple dependence-aware statistical
tests, including Rao-Scott adjustment and cluster permutation tests.
Furthermore, we demonstrate that SPICE provides a distinct signal from abuse
classification. In trials where a model failed to identify abuse, it still
overwhelmingly stated a preference not to continue the interaction (81% of the
time). An exploratory analysis also reveals a significant interaction effect: a
preamble describing the study context significantly impacts SPICE under
ambiguity, but only when transcripts are presented as a single block of text
rather than a multi-turn chat. The results validate SPICE as a robust,
low-overhead, and reproducible tool for auditing model dispositions,
complementing existing metrics by offering a direct, relational signal of a
model's state. All stimuli, code, and analysis scripts are released to support
replication.

</details>


### [7] [Improving LLM Safety and Helpfulness using SFT and DPO: A Study on OPT-350M](https://arxiv.org/abs/2509.09055)
*Piyush Pant*

Main category: cs.CL

TL;DR: 本研究评估了SFT、DPO及其组合在提升语言模型安全性与帮助性方面的效果，发现结合SFT和DPO的方法表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估对齐技术（如SFT和DPO）在提高语言模型安全性和帮助性方面的效果，并探索它们的互补性。

Method: 使用Anthropic Helpful-Harmless RLHF数据集，训练和评估四个模型：基础OPT350M、SFT模型、DPO模型以及结合SFT和DPO的模型。

Result: 结果表明，虽然SFT优于DPO，但结合SFT和DPO的模型在所有指标上均优于其他模型，显示出这些技术的互补性。

Conclusion: 本研究展示了SFT和DPO技术在提高语言模型的安全性和帮助性方面的互补性，并提出了一个更稳健的对齐管道的基础。

Abstract: This research investigates the effectiveness of alignment techniques,
Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and a
combined SFT+DPO approach on improving the safety and helpfulness of the
OPT-350M language model. Utilizing the Anthropic Helpful-Harmless RLHF dataset,
we train and evaluate four models: the base OPT350M, an SFT model, a DPO model,
and a model trained with both SFT and DPO. We introduce three key evaluation
metrics: Harmlessness Rate (HmR), Helpfulness Rate (HpR), and a Combined
Alignment Score (CAS), all derived from reward model outputs. The results show
that while SFT outperforms DPO, The combined SFT+DPO model outperforms all
others across all metrics, demonstrating the complementary nature of these
techniques. Our findings also highlight challenges posed by noisy data, limited
GPU resources, and training constraints. This study offers a comprehensive view
of how fine-tuning strategies affect model alignment and provides a foundation
for more robust alignment pipelines in future work.

</details>


### [8] [MR-UIE: Multi-Perspective Reasoning with Reinforcement Learning for Universal Information Extraction](https://arxiv.org/abs/2509.09082)
*Zhongqiu Li,Shiquan Wang,Ruiyu Fang,Mengjiao Bao,Zhenhe Wu,Shuangyong Song,Yongxiang Li,Zhongjiang He*

Main category: cs.CL

TL;DR: 本文提出将强化学习与多视角推理结合，以提升大型语言模型在通用信息抽取任务中的性能，实验结果表明该方法在多个基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在通用信息抽取任务中仍有显著限制，尤其是在处理涉及复杂模式描述和多步骤推理的结构化输出场景时表现不足。

Method: 将强化学习与多视角推理结合，使大型语言模型从被动的抽取器转变为积极的推理者，从而提升模型的泛化能力。

Result: 实验表明，MR-UIE在多个信息抽取基准上持续提高抽取准确性，并在一些数据集上超越了最先进的方法。同时，将多视角推理融入强化学习显著提升了复杂信息抽取任务的泛化能力。

Conclusion: MR-UIE在多个信息抽取基准上表现出色，超越了最先进的方法，并且在复杂的信息抽取任务中显著提升了泛化能力，证明了推理在挑战性场景中的关键作用。

Abstract: Large language models (LLMs) demonstrate robust capabilities across diverse
research domains. However, their performance in universal information
extraction (UIE) remains insufficient, especially when tackling structured
output scenarios that involve complex schema descriptions and require
multi-step reasoning. While existing approaches enhance the performance of LLMs
through in-context learning and instruction tuning, significant limitations
nonetheless persist. To enhance the model's generalization ability, we propose
integrating reinforcement learning (RL) with multi-perspective reasoning for
information extraction (IE) tasks. Our work transitions LLMs from passive
extractors to active reasoners, enabling them to understand not only what to
extract but also how to reason. Experiments conducted on multiple IE benchmarks
demonstrate that MR-UIE consistently elevates extraction accuracy across
domains and surpasses state-of-the-art methods on several datasets.
Furthermore, incorporating multi-perspective reasoning into RL notably enhances
generalization in complex IE tasks, underscoring the critical role of reasoning
in challenging scenarios.

</details>


### [9] [TigerCoder: A Novel Suite of LLMs for Code Generation in Bangla](https://arxiv.org/abs/2509.09101)
*Nishat Raihan,Antonios Anastasopoulos,Marcos Zampieri*

Main category: cs.CL

TL;DR: 本文介绍了第一个针对孟加拉语的代码大语言模型家族（1B & 9B），并提供了三个主要贡献：一个全面的孟加拉语代码指令数据集、MBPP-Bangla评估基准以及TigerCoder家族的代码大语言模型。实验结果显示，精心策划的高质量数据集可以克服小模型在低资源语言上的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管孟加拉语是第五大语言，但在大型语言模型（LLMs）中，特别是在代码生成方面仍然代表性不足。这主要是由于缺乏高质量的数据来进行预训练和/或微调这些模型。

Method: 我们引入了第一个针对孟加拉语的代码大语言模型家族（1B & 9B），并提供了三个主要贡献：(1) 一个全面的孟加拉语代码指令数据集用于编程领域适应；(2) MBPP-Bangla，一个评估孟加拉语代码生成的基准测试；(3) TigerCoder家族的代码大语言模型，在Pass@1上相对于现有的多语言和通用孟加拉语大语言模型实现了显著的~11-18%性能提升。

Result: TigerCoder家族的代码大语言模型在Pass@1上相对于现有的多语言和通用孟加拉语大语言模型实现了显著的~11-18%性能提升。

Conclusion: 我们的研究结果表明，精心策划的高质量数据集可以克服小模型在低资源语言上的局限性。我们开源了所有资源以促进进一步的孟加拉语大语言模型研究。

Abstract: Despite being the 5th most spoken language, Bangla remains underrepresented
in Large Language Models (LLMs), particularly for code generation. This
primarily stems from the scarcity of high-quality data to pre-train and/or
finetune such models. Hence, we introduce the first dedicated family of Code
LLMs for Bangla (1B & 9B). We offer three major contributions: (1) a
comprehensive Bangla code instruction datasets for programming domain
adaptation; (2) MBPP-Bangla, an evaluation benchmark for Bangla code
generation; and (3) the TigerCoder-family of Code LLMs, achieving significant
~11-18% performance gains at Pass@1 over existing multilingual and
general-purpose Bangla LLMs. Our findings show that curated, high-quality
datasets can overcome limitations of smaller models for low-resource languages.
We open-source all resources to advance further Bangla LLM research.

</details>


### [10] [Compass-v3: Scaling Domain-Specific LLMs for Multilingual E-Commerce in Southeast Asia](https://arxiv.org/abs/2509.09121)
*Sophia Maria*

Main category: cs.CL

TL;DR: Compass-v3 is a vertical-domain Mixture-of-Experts (MoE) model designed for Southeast Asian e-commerce, featuring 245B total parameters and 71B active per token. It uses hardware-efficient optimizations and a mixed-training strategy to achieve state-of-the-art performance in e-commerce tasks and multilingual capabilities across low-resource languages.


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) excel in general-domain applications, yet their performance often degrades in specialized tasks requiring domain-specific knowledge. E-commerce is particularly challenging, as its data are noisy, heterogeneous, multilingual, and highly dynamic.

Method: Compass-v3 adopts fewer but larger experts, combined with hardware-efficient optimizations-such as intra-node expert parallelism and a customized memcpy operator-to maximize GPU utilization. The model is trained on 12T tokens of curated multilingual corpora and large-scale synthetic e-commerce instructions using a mixed-training strategy. To enhance alignment, we propose Optimal-Transport Direct Preference Optimization (OTPO), which captures token-level distinctions and improves instruction adherence in commerce-specific scenarios.

Result: Extensive evaluations demonstrate that Compass-v3 delivers state-of-the-art e-commerce performance, surpassing DeepSeek-V3.1, GPT-4 series, and Qwen3-235B. Moreover, Compass-v3 demonstrates strong multilingual capability across low-resource Southeast Asian languages (Indonesian, Thai, Filipino, Vietnamese, Malay, Taglog) and Portuguese while sustaining competitive performance on general benchmarks.

Conclusion: Compass-v3 has been widely applied in Shopee's industrial-scale e-commerce platform and is gradually replacing OpenAI's traffic, now accounting for over 70% of total LLM usage, highlighting its dual strengths in specialized commerce expertise and broad linguistic competence.

Abstract: Large language models (LLMs) excel in general-domain applications, yet their
performance often degrades in specialized tasks requiring domain-specific
knowledge. E-commerce is particularly challenging, as its data are noisy,
heterogeneous, multilingual, and highly dynamic. We present Compass-v3, a
vertical-domain Mixture-of-Experts (MoE) model with 245B total parameters and
71B active per token, designed for Southeast Asian e-commerce. Compass-v3
adopts fewer but larger experts, combined with hardware-efficient
optimizations-such as intra-node expert parallelism and a customized memcpy
operator-to maximize GPU utilization. The model is trained on 12T tokens of
curated multilingual corpora and large-scale synthetic e-commerce instructions
using a mixed-training strategy. To enhance alignment, we propose
Optimal-Transport Direct Preference Optimization (OTPO), which captures
token-level distinctions and improves instruction adherence in
commerce-specific scenarios. Extensive evaluations demonstrate that Compass-v3
delivers state-of-the-art e-commerce performance, surpassing DeepSeek-V3.1,
GPT-4 series, and Qwen3-235B. Moreover, Compass-v3 demonstrates strong
multilingual capability across low-resource Southeast Asian languages
(Indonesian, Thai, Filipino, Vietnamese, Malay, Taglog) and Portuguese while
sustaining competitive performance on general benchmarks. It has already been
widely applied in Shopee's industrial-scale e-commerce platform and is
gradually replacing OpenAI's traffic, now accounting for over 70\% of total LLM
usage, highlighting its dual strengths in specialized commerce expertise and
broad linguistic competence.

</details>


### [11] [Automated Classification of Tutors' Dialogue Acts Using Generative AI: A Case Study Using the CIMA Corpus](https://arxiv.org/abs/2509.09125)
*Liqun He,Jiaqi Xu*

Main category: cs.CL

TL;DR: 本研究探讨了生成式AI在自动化分类教育对话行为中的应用，结果表明GPT-4在准确性和一致性方面表现优异，显示出生成式AI在该领域的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 传统手动编码需要大量时间和精力，因此本研究旨在探索生成式AI在自动化分类中的应用，以减少这些负担。

Method: 该研究使用了CIMA语料库，并测试了GPT-3.5-turbo和GPT-4模型，通过定制提示进行对话行为分类。

Result: GPT-4达到了80%的准确率、0.81的加权F1分数和0.74的Cohen's Kappa，超过了基线性能，并显示出与人工标注的高度一致性。

Conclusion: 该研究表明生成式AI在DA分类中具有强大的潜力，可以提供一种高效且可访问的方法，并强调了任务特定的标签定义和上下文信息的重要性。此外，还突出了与生成式AI使用相关的伦理考虑以及负责任和透明的研究实践的必要性。

Abstract: This study explores the use of generative AI for automating the
classification of tutors' Dialogue Acts (DAs), aiming to reduce the time and
effort required by traditional manual coding. This case study uses the
open-source CIMA corpus, in which tutors' responses are pre-annotated into four
DA categories. Both GPT-3.5-turbo and GPT-4 models were tested using tailored
prompts. Results show that GPT-4 achieved 80% accuracy, a weighted F1-score of
0.81, and a Cohen's Kappa of 0.74, surpassing baseline performance and
indicating substantial agreement with human annotations. These findings suggest
that generative AI has strong potential to provide an efficient and accessible
approach to DA classification, with meaningful implications for educational
dialogue analysis. The study also highlights the importance of task-specific
label definitions and contextual information in enhancing the quality of
automated annotation. Finally, it underscores the ethical considerations
associated with the use of generative AI and the need for responsible and
transparent research practices. The script of this research is publicly
available at
https://github.com/liqunhe27/Generative-AI-for-educational-dialogue-act-tagging.

</details>


### [12] [ViRanker: A BGE-M3 & Blockwise Parallel Transformer Cross-Encoder for Vietnamese Reranking](https://arxiv.org/abs/2509.09131)
*Phuong-Nam Dang,Kieu-Linh Nguyen,Thanh-Hieu Pham*

Main category: cs.CL

TL;DR: 本文介绍了ViRanker，这是一个针对越南语的跨编码器重排序模型，通过精心设计的架构和数据整理，在基准测试中表现优异，并为其他低资源语言提供了参考。


<details>
  <summary>Details</summary>
Motivation: 由于越南语缺乏有竞争力的重排序模型，且其语法复杂、有声调，因此需要一个专门针对越南语的跨编码器重排序模型。

Method: ViRanker基于BGE-M3编码器并增强了Blockwise Parallel Transformer，通过混合硬负采样进行微调，并在8 GB的精选语料库上进行训练。

Result: ViRanker在MMARCO-VI基准测试中表现出色，早期排名准确性超过了多语言基线，并与PhoRanker竞争激烈。

Conclusion: ViRanker展示了如何通过精心的架构适应和数据整理来推进其他未被充分代表语言的重排序。

Abstract: This paper presents ViRanker, a cross-encoder reranking model tailored to the
Vietnamese language. Built on the BGE-M3 encoder and enhanced with the
Blockwise Parallel Transformer, ViRanker addresses the lack of competitive
rerankers for Vietnamese, a low-resource language with complex syntax and
diacritics. The model was trained on an 8 GB curated corpus and fine-tuned with
hybrid hard-negative sampling to strengthen robustness. Evaluated on the
MMARCO-VI benchmark, ViRanker achieves strong early-rank accuracy, surpassing
multilingual baselines and competing closely with PhoRanker. By releasing the
model openly on Hugging Face, we aim to support reproducibility and encourage
wider adoption in real-world retrieval systems. Beyond Vietnamese, this study
illustrates how careful architectural adaptation and data curation can advance
reranking in other underrepresented languages.

</details>


### [13] [LITcoder: A General-Purpose Library for Building and Comparing Encoding Models](https://arxiv.org/abs/2509.09152)
*Taha Binhuraib,Ruimin Gao,Anna A. Ivanova*

Main category: cs.CL

TL;DR: LITcoder是一个开源库，用于构建和基准测试神经编码模型。它提供了标准化工具，用于对齐连续刺激与脑数据，将刺激转换为表征特征，将这些特征映射到脑数据，并评估模型在保留数据上的预测性能。该库实现了模块化流程，涵盖各种方法设计选择，使研究人员可以轻松组合、比较和扩展编码模型。通过将一系列编码模型拟合到三个故事聆听数据集，展示了框架的可扩展性和多功能性。


<details>
  <summary>Details</summary>
Motivation: 为了降低编码模型实现的技术门槛，促进模型和数据集之间的系统比较，促进方法论的严谨性，并加速高质量高性能预测模型的开发，本文介绍了LITcoder。

Method: LITcoder是一个开源库，用于构建和基准测试神经编码模型。它提供标准化工具，用于对齐连续刺激（如文本和语音）与脑数据，将刺激转换为表征特征，将这些特征映射到脑数据，并评估模型在保留数据上的预测性能。该库实现了模块化流程，涵盖各种方法设计选择，使研究人员可以轻松组合、比较和扩展编码模型。

Result: 通过将一系列编码模型拟合到三个故事聆听数据集（LeBel等人，2023年，Narratives和Little Prince），展示了框架的可扩展性和多功能性。还探讨了构建连续fMRI数据编码模型的关键方法选择，说明了考虑TR扫描中的所有标记的重要性，包括血流动力学滞后效应，使用最小信息泄漏的训练测试分割，以及考虑头部运动对编码模型预测性的影响。

Conclusion: LITcoder降低了编码模型实现的技术门槛，促进了模型和数据集之间的系统比较，促进了方法论的严谨性，并加速了高质量高性能脑活动预测模型的开发。

Abstract: We introduce LITcoder, an open-source library for building and benchmarking
neural encoding models. Designed as a flexible backend, LITcoder provides
standardized tools for aligning continuous stimuli (e.g., text and speech) with
brain data, transforming stimuli into representational features, mapping those
features onto brain data, and evaluating the predictive performance of the
resulting model on held-out data. The library implements a modular pipeline
covering a wide array of methodological design choices, so researchers can
easily compose, compare, and extend encoding models without reinventing core
infrastructure. Such choices include brain datasets, brain regions, stimulus
feature (both neural-net-based and control, such as word rate), downsampling
approaches, and many others. In addition, the library provides built-in
logging, plotting, and seamless integration with experiment tracking platforms
such as Weights & Biases (W&B). We demonstrate the scalability and versatility
of our framework by fitting a range of encoding models to three story listening
datasets: LeBel et al. (2023), Narratives, and Little Prince. We also explore
the methodological choices critical for building encoding models for continuous
fMRI data, illustrating the importance of accounting for all tokens in a TR
scan (as opposed to just taking the last one, even when contextualized),
incorporating hemodynamic lag effects, using train-test splits that minimize
information leakage, and accounting for head motion effects on encoding model
predictivity. Overall, LITcoder lowers technical barriers to encoding model
implementation, facilitates systematic comparisons across models and datasets,
fosters methodological rigor, and accelerates the development of high-quality
high-performance predictive models of brain activity.
  Project page: https://litcoder-brain.github.io

</details>


### [14] [Target-oriented Multimodal Sentiment Classification with Counterfactual-enhanced Debiasing](https://arxiv.org/abs/2509.09160)
*Zhiyue Liu,Fanrong Ma,Xin Ling*

Main category: cs.CL

TL;DR: 本文提出了一种新的反事实增强去偏框架，以减少文本特征和输出标签之间的虚假相关性，从而提高目标导向的多模态情感分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法过度依赖文本内容，未能考虑数据集偏差，特别是词级上下文偏差，导致文本特征和输出标签之间出现虚假相关性，影响分类准确性。

Method: 本文引入了一种新的反事实增强去偏框架，该框架结合了反事实数据增强策略和自适应去偏对比学习机制。

Result: 实验结果表明，本文提出的方法在多个基准数据集上表现优于现有的最先进方法。

Conclusion: 本文提出的方法在多个基准数据集上优于最先进的基线方法。

Abstract: Target-oriented multimodal sentiment classification seeks to predict
sentiment polarity for specific targets from image-text pairs. While existing
works achieve competitive performance, they often over-rely on textual content
and fail to consider dataset biases, in particular word-level contextual
biases. This leads to spurious correlations between text features and output
labels, impairing classification accuracy. In this paper, we introduce a novel
counterfactual-enhanced debiasing framework to reduce such spurious
correlations. Our framework incorporates a counterfactual data augmentation
strategy that minimally alters sentiment-related causal features, generating
detail-matched image-text samples to guide the model's attention toward content
tied to sentiment. Furthermore, for learning robust features from
counterfactual data and prompting model decisions, we introduce an adaptive
debiasing contrastive learning mechanism, which effectively mitigates the
influence of biased words. Experimental results on several benchmark datasets
show that our proposed method outperforms state-of-the-art baselines.

</details>


### [15] [EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs](https://arxiv.org/abs/2509.09174)
*Yuhao Zhang,Yuhao Du,Zhanchen Dai,Xiangnan Ma,Kaiqi Kou,Benyou Wang,Haizhou Li*

Main category: cs.CL

TL;DR: EchoX是一种新的语音到语音大型语言模型，通过结合声学和语义学习，解决了现有模型在知识和推理能力上的不足，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前的SLLMs训练范式无法弥合特征表示空间中的声学-语义差距，导致知识和推理能力退化。

Method: EchoX通过利用语义表示并动态生成语音训练目标，结合声学和语义学习，解决了当前SLLMs训练范式无法弥合特征表示空间中的声学-语义差距的问题。

Result: EchoX在约六千小时的训练数据下，在多个基于知识的问答基准测试中达到了先进的性能。

Conclusion: EchoX在多个基于知识的问答基准测试中表现出色，证明了其在保持强大推理能力的同时，能够有效解决语音到语音大型语言模型中的知识和推理能力退化问题。

Abstract: Speech-to-speech large language models (SLLMs) are attracting increasing
attention. Derived from text-based large language models (LLMs), SLLMs often
exhibit degradation in knowledge and reasoning capabilities. We hypothesize
that this limitation arises because current training paradigms for SLLMs fail
to bridge the acoustic-semantic gap in the feature representation space. To
address this issue, we propose EchoX, which leverages semantic representations
and dynamically generates speech training targets. This approach integrates
both acoustic and semantic learning, enabling EchoX to preserve strong
reasoning abilities as a speech LLM. Experimental results demonstrate that
EchoX, with about six thousand hours of training data, achieves advanced
performance on multiple knowledge-based question-answering benchmarks. The
project is available at https://github.com/FreedomIntelligence/EchoX.

</details>


### [16] [Efficient Trie-based Biasing using K-step Prediction for Rare Word Recognition](https://arxiv.org/abs/2509.09196)
*Chin Yuen Kwok,Jia Qi yip*

Main category: cs.CL

TL;DR: 本文提出了一种改进ASR模型识别罕见词的方法，通过微调模型以预测多个步骤，从而减少了词错误率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Trie的偏置方法在计算上很昂贵，特别是在具有大型解码器的模型中。

Method: 我们提出了一种适应ASR模型的方法，使其能够向前看并一次预测多个步骤，从而避免了撤销步骤。

Result: 通过仅使用10小时的合成数据微调Whisper，我们的方法显著降低了词错误率。

Conclusion: 通过微调Whisper模型，我们的方法在NSC Part 2测试集上将词错误率从30.86%降低到12.19%。

Abstract: Contextual biasing improves rare word recognition of ASR models by
prioritizing the output of rare words during decoding. A common approach is
Trie-based biasing, which gives "bonus scores" to partial hypothesis (e.g.
"Bon") that may lead to the generation of the rare word (e.g. "Bonham"). If the
full word ("Bonham") isn't ultimately recognized, the system revokes those
earlier bonuses. This revocation is limited to beam search and is
computationally expensive, particularly for models with large decoders. To
overcome these limitations, we propose adapting ASR models to look ahead and
predict multiple steps at once. This avoids the revocation step entirely by
better estimating whether a partial hypothesis will lead to the generation of
the full rare word. By fine-tuning Whisper with only 10 hours of synthetic
data, our method reduces the word error rate on the NSC Part 2 test set from
30.86% to 12.19%.

</details>


### [17] [Improving Synthetic Data Training for Contextual Biasing Models with a Keyword-Aware Cost Function](https://arxiv.org/abs/2509.09197)
*Chin Yuen Kwok,Jia Qi Yip,Eng Siong Chng*

Main category: cs.CL

TL;DR: 本文提出了一种改进的上下文偏差方法和关键词感知损失函数，以提高稀有词识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 稀有词识别可以通过将自动语音识别（ASR）模型适应到包含这些词的合成数据来提高。进一步的改进可以通过上下文偏差实现，这会训练并添加一个偏差模块到模型架构中以优先考虑稀有词。

Method: 我们改进了基于TCPGen的上下文偏差方法，并提出了一种关键词感知损失函数，该函数在训练偏差模块时额外关注偏差词。

Result: 通过适应Whisper到10小时的合成数据，我们的方法将NSC Part 2测试集上的词错误率从29.71%降低到11.81%。

Conclusion: 通过适应10小时的合成数据，我们的方法将NSC Part 2测试集上的词错误率从29.71%降低到11.81%。

Abstract: Rare word recognition can be improved by adapting ASR models to synthetic
data that includes these words. Further improvements can be achieved through
contextual biasing, which trains and adds a biasing module into the model
architecture to prioritize rare words. While training the module on synthetic
rare word data is more effective than using non-rare-word data, it can lead to
overfitting due to artifacts in the synthetic audio. To address this, we
enhance the TCPGen-based contextual biasing approach and propose a
keyword-aware loss function that additionally focuses on biased words when
training biasing modules. This loss includes a masked cross-entropy term for
biased word prediction and a binary classification term for detecting biased
word positions. These two terms complementarily support the decoding of biased
words during inference. By adapting Whisper to 10 hours of synthetic data, our
method reduced the word error rate on the NSC Part 2 test set from 29.71% to
11.81%.

</details>


### [18] [GmSLM : Generative Marmoset Spoken Language Modeling](https://arxiv.org/abs/2509.09198)
*Talia Sternberg,Michael London,David Omer,Yossi Adi*

Main category: cs.CL

TL;DR: 研究引入了GmSLM，这是一种针对棉鼠语音通信的优化语音语言模型管道，并通过零样本评估指标展示了其优势。


<details>
  <summary>Details</summary>
Motivation: Marmoset monkeys exhibit complex vocal communication, challenging the view that nonhuman primates vocal communication is entirely innate, and show similar features of human speech, such as vocal labeling of others and turn-taking. Studying their vocal communication offers a unique opportunity to link it with brain activity.

Method: We introduce Generative Marmoset Spoken Language Modeling (GmSLM), an optimized spoken language model pipeline for Marmoset vocal communication. We designed a novel zero-shot evaluation metrics using unsupervised in-the-wild data, alongside weakly labeled conversational data, to assess GmSLM.

Result: GmSLM generated vocalizations closely matched real resynthesized samples acoustically and performed well on downstream tasks. Despite being fully unsupervised, GmSLM effectively distinguish real from artificial conversations and may support further investigations of the neural basis of vocal communication and provides a practical framework linking vocalization and brain activity.

Conclusion: GmSLM stands to benefit future work in neuroscience, bioacoustics, and evolutionary biology.

Abstract: Marmoset monkeys exhibit complex vocal communication, challenging the view
that nonhuman primates vocal communication is entirely innate, and show similar
features of human speech, such as vocal labeling of others and turn-taking.
Studying their vocal communication offers a unique opportunity to link it with
brain activity-especially given the difficulty of accessing the human brain in
speech and language research. Since Marmosets communicate primarily through
vocalizations, applying standard LLM approaches is not straightforward. We
introduce Generative Marmoset Spoken Language Modeling (GmSLM), an optimized
spoken language model pipeline for Marmoset vocal communication. We designed a
novel zero-shot evaluation metrics using unsupervised in-the-wild data,
alongside weakly labeled conversational data, to assess GmSLM and demonstrate
its advantage over a basic human-speech-based baseline. GmSLM generated
vocalizations closely matched real resynthesized samples acoustically and
performed well on downstream tasks. Despite being fully unsupervised, GmSLM
effectively distinguish real from artificial conversations and may support
further investigations of the neural basis of vocal communication and provides
a practical framework linking vocalization and brain activity. We believe GmSLM
stands to benefit future work in neuroscience, bioacoustics, and evolutionary
biology. Samples are provided under: pages.cs.huji.ac.il/adiyoss-lab/GmSLM.

</details>


### [19] [CCF: A Context Compression Framework for Efficient Long-Sequence Language Modeling](https://arxiv.org/abs/2509.09199)
*Wenhao Li,Bangcheng Sun,Weihao Ye,Tianyi Zhang,Daohai Yu,Fei Chao,Rongrong Ji*

Main category: cs.CL

TL;DR: 本文提出了一种名为CCF的新上下文压缩框架，通过学习分层潜在表示来实现高效的长上下文建模，同时保留全局语义并减少输入冗余。实验表明，CCF在高压缩比下表现良好，并提高了吞吐量和内存效率。


<details>
  <summary>Details</summary>
Motivation: 扩展语言模型以处理更长的上下文对于捕捉跨扩展话语的丰富依赖关系至关重要。然而，简单的上下文扩展会带来显著的计算和内存负担，通常会导致训练和推理过程中的低效。

Method: CCF是一种新的上下文压缩框架，通过学习分层潜在表示来实现高效的长上下文建模，同时保留全局语义并大幅减少输入冗余。它结合了逐段语义聚合和键值记忆编码，形成了支持准确重建和长距离理解的紧凑表示。此外，还引入了一种训练高效的优化策略，将增量段解码与稀疏水库采样相结合，显著降低了内存开销而不影响性能。

Result: 实验证明，CCF在高压缩比下实现了具有竞争力的困惑度，并且在吞吐量和内存效率方面相比现有方法有显著提升。

Conclusion: 这些发现突显了结构化压缩在可扩展和有效的长上下文语言建模中的潜力。

Abstract: Scaling language models to longer contexts is essential for capturing rich
dependencies across extended discourse. However, na\"ive context extension
imposes significant computational and memory burdens, often resulting in
inefficiencies during both training and inference. In this work, we propose
CCF, a novel context compression framework designed to enable efficient
long-context modeling by learning hierarchical latent representations that
preserve global semantics while aggressively reducing input redundancy. CCF
integrates segment-wise semantic aggregation with key-value memory encoding,
forming compact representations that support accurate reconstruction and
long-range understanding. To further enhance scalability, we introduce a
training-efficient optimization strategy that couples incremental segment
decoding with sparse reservoir sampling, substantially reducing memory overhead
without degrading performance. Empirical results on multiple long-context
language modeling benchmarks demonstrate that CCF achieves competitive
perplexity under high compression ratios, and significantly improves throughput
and memory efficiency compared to existing approaches. These findings highlight
the potential of structured compression for scalable and effective long-context
language modeling.

</details>


### [20] [Reading Between the Lines: Classifying Resume Seniority with Large Language Models](https://arxiv.org/abs/2509.09229)
*Matan Cohen,Shira Shani,Eden Menahem,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型在自动评估简历资历方面的有效性，并引入了一个混合数据集来评估模型性能，结果表明这些模型能够有效检测与资历膨胀相关的语言线索。


<details>
  <summary>Details</summary>
Motivation: 准确评估候选人的资历是一项关键但具有挑战性的任务，因为存在夸大经验和模糊的自我呈现现象。因此，需要一种自动化的方法来提高评估的准确性和公平性。

Method: 研究使用了一个混合数据集，包括真实简历和合成生成的困难示例，以评估大型语言模型（包括微调的BERT架构）在自动分类简历资历方面的有效性。

Result: 研究结果表明，大型语言模型能够有效检测与资历膨胀和隐含专业技能相关的细微语言线索，从而提高了AI驱动的候选人评估系统的性能。

Conclusion: 研究发现，大型语言模型在检测与资历膨胀和隐含专业技能相关的细微语言线索方面表现出色，这为增强基于人工智能的候选人评估系统和减少由自我宣传语言引入的偏见提供了有希望的方向。

Abstract: Accurately assessing candidate seniority from resumes is a critical yet
challenging task, complicated by the prevalence of overstated experience and
ambiguous self-presentation. In this study, we investigate the effectiveness of
large language models (LLMs), including fine-tuned BERT architectures, for
automating seniority classification in resumes. To rigorously evaluate model
performance, we introduce a hybrid dataset comprising both real-world resumes
and synthetically generated hard examples designed to simulate exaggerated
qualifications and understated seniority. Using the dataset, we evaluate the
performance of Large Language Models in detecting subtle linguistic cues
associated with seniority inflation and implicit expertise. Our findings
highlight promising directions for enhancing AI-driven candidate evaluation
systems and mitigating bias introduced by self-promotional language. The
dataset is available for the research community at https://bit.ly/4mcTovt

</details>


### [21] [Agentic LLMs for Question Answering over Tabular Data](https://arxiv.org/abs/2509.09234)
*Rishit Tyagi,Mohit Gupta,Rahul Bouri*

Main category: cs.CL

TL;DR: 本文介绍了一种基于大型语言模型的自然语言到SQL方法，用于解决表格问答问题，并在DataBench基准测试中取得了显著优于基线的结果。


<details>
  <summary>Details</summary>
Motivation: 表格问答（Table QA）由于现实世界表格的结构、大小和数据类型的多样性而面临独特的挑战。SemEval 2025任务8（DataBench）引入了一个由大规模、领域多样数据集组成的基准，用于评估模型准确回答结构化查询的能力。

Method: 我们提出了一种基于大型语言模型（如GPT-4o、GPT-4o-mini和DeepSeek v2:16b）的自然语言到SQL（NL-to-SQL）方法，以动态生成SQL查询。我们的系统遵循一个涉及示例选择、SQL查询生成、答案提取、验证和迭代优化的多阶段流程。

Result: 实验表明了我们方法的有效性，在DataBench QA上达到了70.5%的准确率，在DataBench Lite QA上达到了71.6%，分别显著超过了基线分数26%和27%。

Conclusion: 本文详细介绍了我们的方法、实验结果和替代方法，提供了对LLM驱动的Table QA的优势和局限性的见解。

Abstract: Question Answering over Tabular Data (Table QA) presents unique challenges
due to the diverse structure, size, and data types of real-world tables. The
SemEval 2025 Task 8 (DataBench) introduced a benchmark composed of large-scale,
domain-diverse datasets to evaluate the ability of models to accurately answer
structured queries. We propose a Natural Language to SQL (NL-to-SQL) approach
leveraging large language models (LLMs) such as GPT-4o, GPT-4o-mini, and
DeepSeek v2:16b to generate SQL queries dynamically. Our system follows a
multi-stage pipeline involving example selection, SQL query generation, answer
extraction, verification, and iterative refinement. Experiments demonstrate the
effectiveness of our approach, achieving 70.5\% accuracy on DataBench QA and
71.6\% on DataBench Lite QA, significantly surpassing baseline scores of 26\%
and 27\% respectively. This paper details our methodology, experimental
results, and alternative approaches, providing insights into the strengths and
limitations of LLM-driven Table QA.

</details>


### [22] [From scratch to silver: Creating trustworthy training data for patent-SDG classification using Large Language Models](https://arxiv.org/abs/2509.09303)
*Grazia Sveva Ascione,Nicolò Tamagnone*

Main category: cs.CL

TL;DR: 本文提出了一种基于弱监督和语义对齐的方法，用于大规模分类专利与联合国可持续发展目标（SDGs）之间的相关性。


<details>
  <summary>Details</summary>
Motivation: 缺乏一个大型的标记数据集限制了监督学习的应用。现有的方法如关键词搜索、迁移学习和基于引用的启发式方法在可扩展性和泛化性上存在不足。

Method: 将专利到SDG的分类作为弱监督问题，使用专利引用的SDG标记科学出版物（NPL引用）作为噪声初始信号，并开发了一个复合标注函数（LF），利用大语言模型（LLMs）从专利和SDG论文中提取结构化概念。

Result: 得到了一个银标准的软多标签数据集，将专利映射到SDG，能够训练有效的多标签回归模型。通过两种互补策略验证了方法的有效性：内部验证和外部验证。

Conclusion: 弱监督和语义对齐可以大规模增强SDG分类。

Abstract: Classifying patents by their relevance to the UN Sustainable Development
Goals (SDGs) is crucial for tracking how innovation addresses global
challenges. However, the absence of a large, labeled dataset limits the use of
supervised learning. Existing methods, such as keyword searches, transfer
learning, and citation-based heuristics, lack scalability and generalizability.
This paper frames patent-to-SDG classification as a weak supervision problem,
using citations from patents to SDG-tagged scientific publications (NPL
citations) as a noisy initial signal. To address its sparsity and noise, we
develop a composite labeling function (LF) that uses large language models
(LLMs) to extract structured concepts, namely functions, solutions, and
applications, from patents and SDG papers based on a patent ontology.
Cross-domain similarity scores are computed and combined using a rank-based
retrieval approach. The LF is calibrated via a custom positive-only loss that
aligns with known NPL-SDG links without penalizing discovery of new SDG
associations. The result is a silver-standard, soft multi-label dataset mapping
patents to SDGs, enabling the training of effective multi-label regression
models. We validate our approach through two complementary strategies: (1)
internal validation against held-out NPL-based labels, where our method
outperforms several baselines including transformer-based models, and zero-shot
LLM; and (2) external validation using network modularity in patent citation,
co-inventor, and co-applicant graphs, where our labels reveal greater thematic,
cognitive, and organizational coherence than traditional technological
classifications. These results show that weak supervision and semantic
alignment can enhance SDG classification at scale.

</details>


### [23] [MetaRAG: Metamorphic Testing for Hallucination Detection in RAG Systems](https://arxiv.org/abs/2509.09360)
*Channdeth Sok,David Luz,Yacine Haddam*

Main category: cs.CL

TL;DR: MetaRAG is a framework for detecting hallucinations in RAG systems by decomposing answers into factoids, generating mutations, verifying against context, and aggregating penalties.


<details>
  <summary>Details</summary>
Motivation: Existing detection approaches primarily target standalone LLMs and do not address the unique challenges of RAG systems, where responses must be consistent with retrieved evidence.

Method: MetaRAG is a metamorphic testing framework that operates in a real-time, unsupervised, black-box setting. It decomposes answers into atomic factoids, generates controlled mutations using synonym and antonym substitutions, verifies each variant against the retrieved context, and aggregates penalties for inconsistencies into a response-level hallucination score.

Result: Experiments on a proprietary enterprise dataset illustrate the effectiveness of MetaRAG for detecting hallucinations and enabling trustworthy deployment of RAG-based conversational agents.

Conclusion: MetaRAG is effective for detecting hallucinations and enabling trustworthy deployment of RAG-based conversational agents.

Abstract: Large Language Models (LLMs) are increasingly deployed in enterprise
applications, yet their reliability remains limited by hallucinations, i.e.,
confident but factually incorrect information. Existing detection approaches,
such as SelfCheckGPT and MetaQA, primarily target standalone LLMs and do not
address the unique challenges of Retrieval-Augmented Generation (RAG) systems,
where responses must be consistent with retrieved evidence. We therefore
present MetaRAG, a metamorphic testing framework for hallucination detection in
Retrieval-Augmented Generation (RAG) systems. MetaRAG operates in a real-time,
unsupervised, black-box setting, requiring neither ground-truth references nor
access to model internals, making it suitable for proprietary and high-stakes
domains. The framework proceeds in four stages: (1) decompose answers into
atomic factoids, (2) generate controlled mutations of each factoid using
synonym and antonym substitutions, (3) verify each variant against the
retrieved context (synonyms are expected to be entailed and antonyms
contradicted), and (4) aggregate penalties for inconsistencies into a
response-level hallucination score. Crucially for identity-aware AI, MetaRAG
localizes unsupported claims at the factoid span where they occur (e.g.,
pregnancy-specific precautions, LGBTQ+ refugee rights, or labor eligibility),
allowing users to see flagged spans and enabling system designers to configure
thresholds and guardrails for identity-sensitive queries. Experiments on a
proprietary enterprise dataset illustrate the effectiveness of MetaRAG for
detecting hallucinations and enabling trustworthy deployment of RAG-based
conversational agents. We also outline a topic-based deployment design that
translates MetaRAG's span-level scores into identity-aware safeguards; this
design is discussed but not evaluated in our experiments.

</details>


### [24] [Modelling Analogies and Analogical Reasoning: Connecting Cognitive Science Theory and NLP Research](https://arxiv.org/abs/2509.09381)
*Molly R Petersen,Claire E Stevenson,Lonneke van der Plas*

Main category: cs.CL

TL;DR: 本文综述了类比推理的认知理论，并探讨了其在自然语言处理中的应用，强调了关系理解的重要性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在将类比推理的认知过程与自然语言处理的研究相结合，以帮助研究人员更好地优化文本中的关系理解，而不是仅仅依赖于实体级别的相似性。

Method: 本文通过综述认知科学文献中的关键理论，并将其与自然语言处理的研究相结合，分析了类比推理的过程及其在NLP中的应用。

Result: 本文展示了类比推理的概念如何与NLP中的多个主要挑战相关，而不仅仅是类比求解。

Conclusion: 本文总结了认知科学文献中关于类比推理过程的关键理论，并将其与自然语言处理领域的当前研究联系起来，表明这些概念对于解决NLP中的多个主要挑战具有相关性，而不仅仅是类比求解。

Abstract: Analogical reasoning is an essential aspect of human cognition. In this
paper, we summarize key theory about the processes underlying analogical
reasoning from the cognitive science literature and relate it to current
research in natural language processing. While these processes can be easily
linked to concepts in NLP, they are generally not viewed through a cognitive
lens. Furthermore, we show how these notions are relevant for several major
challenges in NLP research, not directly related to analogy solving. This may
guide researchers to better optimize relational understanding in text, as
opposed to relying heavily on entity-level similarity.

</details>


### [25] [Hierarchical Bracketing Encodings Work for Dependency Graphs](https://arxiv.org/abs/2509.09388)
*Ana Ezquerro,Carlos Gómez-Rodríguez,David Vilares*

Main category: cs.CL

TL;DR: 本文提出了一种新的图编码方法，在保持结构信息的同时减少了标签空间，并在多语言和多形式主义的基准测试中取得了良好的结果。


<details>
  <summary>Details</summary>
Motivation: 重新从实际角度审视层次括号编码，以解决依赖图解析中的问题。

Method: 该方法将图编码为序列，以线性时间进行解析，并且仍然表示重叠、循环和空节点。

Result: 与现有的图线性化方法相比，该表示显著减少了标签空间，同时保留了结构信息。

Conclusion: 该方法在精确匹配准确率上表现出色，并且在不同语言和形式主义的基准测试中显示出一致的改进。

Abstract: We revisit hierarchical bracketing encodings from a practical perspective in
the context of dependency graph parsing. The approach encodes graphs as
sequences, enabling linear-time parsing with $n$ tagging actions, and still
representing reentrancies, cycles, and empty nodes. Compared to existing graph
linearizations, this representation substantially reduces the label space while
preserving structural information. We evaluate it on a multilingual and
multi-formalism benchmark, showing competitive results and consistent
improvements over other methods in exact match accuracy.

</details>


### [26] [GrACE: A Generative Approach to Better Confidence Elicitation in Large Language Models](https://arxiv.org/abs/2509.09438)
*Zhaohan Zhang,Ziquan Liu,Ioannis Patras*

Main category: cs.CL

TL;DR: GrACE is a novel approach for confidence elicitation in LLMs that enables scalable and reliable confidence estimation in real-time, showing superior performance compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing methods for assessing the reliability of LLMs by confidence elicitation either require expensive computational overhead or suffer from poor calibration, making them impractical and unreliable for real-world deployment.

Method: GrACE is a Generative Approach to Confidence Elicitation that uses the similarity between the last hidden state and the embedding of a special token appended to the vocabulary to express confidence in real-time. The model is fine-tuned for calibrating confidence with calibration targets associated with accuracy.

Result: Experiments with three LLMs and two benchmark datasets show that GrACE achieves the best discriminative capacity and calibration on open-ended generation tasks, outperforming six competing methods without additional sampling or an auxiliary model. Additionally, two strategies for improving test-time scaling based on confidence induced by GrACE are proposed, showing improved accuracy and reduced number of required samples.

Conclusion: GrACE shows potential as a practical solution for deploying LLMs with scalable, reliable, and real-time confidence estimation.

Abstract: Assessing the reliability of Large Language Models (LLMs) by confidence
elicitation is a prominent approach to AI safety in high-stakes applications,
such as healthcare and finance. Existing methods either require expensive
computational overhead or suffer from poor calibration, making them impractical
and unreliable for real-world deployment. In this work, we propose GrACE, a
Generative Approach to Confidence Elicitation that enables scalable and
reliable confidence elicitation for LLMs. GrACE adopts a novel mechanism in
which the model expresses confidence by the similarity between the last hidden
state and the embedding of a special token appended to the vocabulary, in
real-time. We fine-tune the model for calibrating the confidence with
calibration targets associated with accuracy. Experiments with three LLMs and
two benchmark datasets show that the confidence produced by GrACE achieves the
best discriminative capacity and calibration on open-ended generation tasks,
outperforming six competing methods without resorting to additional sampling or
an auxiliary model. Moreover, we propose two strategies for improving test-time
scaling based on confidence induced by GrACE. Experimental results show that
using GrACE not only improves the accuracy of the final decision but also
significantly reduces the number of required samples in the test-time scaling
scheme, indicating the potential of GrACE as a practical solution for deploying
LLMs with scalable, reliable, and real-time confidence estimation.

</details>


### [27] [Mitigating Language Barriers in Education: Developing Multilingual Digital Learning Materials with Machine Translation](https://arxiv.org/abs/2509.09473)
*Lucie Poláková,Martin Popel,Věra Kloudová,Michal Novák,Mariia Anisimova,Jiří Balhar*

Main category: cs.CL

TL;DR: EdUKate项目通过结合数字教育、语言学、翻译研究和机器翻译，开发了多语言学习材料，并针对教育领域开发了一个捷克语-乌克兰语机器翻译系统，已成功应用于教育网络门户并免费提供给用户。


<details>
  <summary>Details</summary>
Motivation: 该项目旨在为捷克中小学提供多语言学习材料，以满足非捷克语学生的需要，并通过机器翻译技术提高教育资源的可及性。

Method: 该项目结合了数字教育、语言学、翻译研究和机器翻译，开发了多语言学习材料，并针对教育领域开发和评估了一个直接的捷克语-乌克兰语机器翻译系统，特别关注处理格式化内容和技术科学术语。

Result: 项目完成了9000个多媒体互动练习的翻译，并开发了一个专门针对教育领域的捷克语-乌克兰语机器翻译系统，该系统已成功实施在教育网络门户上。

Conclusion: 该项目开发的多语言学习材料和机器翻译系统已成功应用于教育网络门户，并向学生、教育工作者和研究人员免费开放。

Abstract: The EdUKate project combines digital education, linguistics, translation
studies, and machine translation to develop multilingual learning materials for
Czech primary and secondary schools. Launched through collaboration between a
major Czech academic institution and the country's largest educational
publisher, the project is aimed at translating up to 9,000 multimodal
interactive exercises from Czech into Ukrainian, English, and German for an
educational web portal. It emphasizes the development and evaluation of a
direct Czech-Ukrainian machine translation system tailored to the educational
domain, with special attention to processing formatted content such as XML and
PDF and handling technical and scientific terminology. We present findings from
an initial survey of Czech teachers regarding the needs of non-Czech-speaking
students and describe the system's evaluation and implementation on the web
portal. All resulting applications are freely available to students, educators,
and researchers.

</details>


### [28] [Towards Explainable Job Title Matching: Leveraging Semantic Textual Relatedness and Knowledge Graphs](https://arxiv.org/abs/2509.09522)
*Vadim Zadykian,Bruno Andrade,Haithem Afli*

Main category: cs.CL

TL;DR: 本文提出了一种结合知识图谱的自监督方法，用于改进职位名称匹配中的语义相关性分析，并通过分层评估揭示了模型在不同区域的表现。


<details>
  <summary>Details</summary>
Motivation: 在简历推荐系统中，职位名称匹配是一个关键挑战，而传统的基于重叠术语的方法往往有限或具有误导性。因此，需要一种更有效的语义相关性分析方法。

Method: 本文提出了一种自监督混合架构，将密集句子嵌入与领域特定的知识图谱（KG）相结合，以提高语义对齐和可解释性。同时，通过将STR分数连续体划分为低、中、高语义相关性区域进行分层评估，实现了对模型性能的细粒度分析。

Result: 实验结果表明，经过微调的SBERT模型结合知识图谱在高STR区域表现出色，RMSE相比强基线模型降低了25%。

Conclusion: 本文研究表明，结合知识图谱的文本嵌入方法在高语义相关性区域表现出色，并强调了区域性能分析的重要性，有助于更精准地选择模型以满足人力资源系统中公平性、可解释性和上下文匹配的需求。

Abstract: Semantic Textual Relatedness (STR) captures nuanced relationships between
texts that extend beyond superficial lexical similarity. In this study, we
investigate STR in the context of job title matching - a key challenge in
resume recommendation systems, where overlapping terms are often limited or
misleading. We introduce a self-supervised hybrid architecture that combines
dense sentence embeddings with domain-specific Knowledge Graphs (KGs) to
improve both semantic alignment and explainability. Unlike previous work that
evaluated models on aggregate performance, our approach emphasizes data
stratification by partitioning the STR score continuum into distinct regions:
low, medium, and high semantic relatedness. This stratified evaluation enables
a fine-grained analysis of model performance across semantically meaningful
subspaces. We evaluate several embedding models, both with and without KG
integration via graph neural networks. The results show that fine-tuned SBERT
models augmented with KGs produce consistent improvements in the high-STR
region, where the RMSE is reduced by 25% over strong baselines. Our findings
highlight not only the benefits of combining KGs with text embeddings, but also
the importance of regional performance analysis in understanding model
behavior. This granular approach reveals strengths and weaknesses hidden by
global metrics, and supports more targeted model selection for use in Human
Resources (HR) systems and applications where fairness, explainability, and
contextual matching are essential.

</details>


### [29] [DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning and Label Distribution Learning](https://arxiv.org/abs/2509.09524)
*Daniil Ignatev,Nan Li,Hugh Mee Wong,Anh Dang,Shane Kaszefski Yaschuk*

Main category: cs.CL

TL;DR: This paper explores in-context learning and label distribution learning methods for predicting annotator-specific annotations and soft labels, showing that ICL and LDL are effective and promising approaches.


<details>
  <summary>Details</summary>
Motivation: To explore effective approaches for predicting annotator-specific annotations and soft label predictions.

Method: In-context learning (ICL) with large language models and label distribution learning (LDL) methods with RoBERTa.

Result: ICL can effectively predict annotator-specific annotations, and aggregating these predictions into soft labels yields competitive performance. LDL methods are promising for soft label predictions.

Conclusion: ICL can effectively predict annotator-specific annotations, and aggregating these predictions into soft labels yields competitive performance. LDL methods are promising for soft label predictions and merit further exploration.

Abstract: This system paper presents the DeMeVa team's approaches to the third edition
of the Learning with Disagreements shared task (LeWiDi 2025; Leonardelli et
al., 2025). We explore two directions: in-context learning (ICL) with large
language models, where we compare example sampling strategies; and label
distribution learning (LDL) methods with RoBERTa (Liu et al., 2019b), where we
evaluate several fine-tuning methods. Our contributions are twofold: (1) we
show that ICL can effectively predict annotator-specific annotations
(perspectivist annotations), and that aggregating these predictions into soft
labels yields competitive performance; and (2) we argue that LDL methods are
promising for soft label predictions and merit further exploration by the
perspectivist community.

</details>


### [30] [Prompting the Market? A Large-Scale Meta-Analysis of GenAI in Finance NLP (2022-2025)](https://arxiv.org/abs/2509.09544)
*Paolo Pedinotti,Peter Baumann,Nathan Jessurun,Leslie Barrett,Enrico Santus*

Main category: cs.CL

TL;DR: 本文介绍了MetaGraph，这是一种从科学文献中提取知识图谱并分析研究趋势的方法，展示了金融NLP的演变过程，并提供了一个可重复使用的方法用于其他领域的科学进展映射。


<details>
  <summary>Details</summary>
Motivation: 传统调查未能跟上大型语言模型（LLMs）在金融自然语言处理中的快速变化，因此需要一种新的方法来提取和分析研究趋势。

Method: 定义了金融NLP研究的本体论，并应用基于LLM的提取管道对681篇论文（2022-2025年）进行分析，以实现大规模、数据驱动的分析。

Result: MetaGraph揭示了三个关键阶段：早期LLM采用和任务/数据集创新；对LLM局限性的批判性反思；以及外围技术向模块化系统的整合。

Conclusion: MetaGraph提供了一种可推广的方法，用于从科学文献中提取知识图谱，并分析以获得研究趋势的结构化、可查询视图。该方法展示了金融NLP的演变过程，并为其他领域的科学进展映射提供了可重复使用的方法。

Abstract: Large Language Models (LLMs) have rapidly reshaped financial NLP, enabling
new tasks and driving a proliferation of datasets and diversification of data
sources. Yet, this transformation has outpaced traditional surveys. In this
paper, we present MetaGraph, a generalizable methodology for extracting
knowledge graphs from scientific literature and analyzing them to obtain a
structured, queryable view of research trends. We define an ontology for
financial NLP research and apply an LLM-based extraction pipeline to 681 papers
(2022-2025), enabling large-scale, data-driven analysis. MetaGraph reveals
three key phases: early LLM adoption and task/dataset innovation; critical
reflection on LLM limitations; and growing integration of peripheral techniques
into modular systems. This structured view offers both practitioners and
researchers a clear understanding of how financial NLP has evolved -
highlighting emerging trends, shifting priorities, and methodological
shifts-while also demonstrating a reusable approach for mapping scientific
progress in other domains.

</details>


### [31] [Personality-Enhanced Social Recommendations in SAMI: Exploring the Role of Personality Detection in Matchmaking](https://arxiv.org/abs/2509.09583)
*Brittany Harbison,Samuel Taubman,Travis Taylor,Ashok. K. Goel*

Main category: cs.CL

TL;DR: 本文提出了一种利用GPT零样本能力检测学生性格的方法，并将其集成到SAMI系统中，以实现更有效的社会推荐。


<details>
  <summary>Details</summary>
Motivation: SAMI在创建学生有效心理模型方面受到不完整的心智理论的限制，这可能会影响其推荐的相关性。因此，我们需要一种能够推断学生性格的方法，以提高推荐的有效性。

Method: 我们提出了一个利用GPT零样本能力从论坛介绍帖子中推断五大性格特征的性格检测模型，并将其集成到SAMI基于实体的匹配系统中，以实现基于性格的社会推荐。

Result: 我们的模型在这一任务中表现出色，并且初步整合表明性格特征可以补充现有的匹配因素。

Conclusion: 初步整合表明个性特征可以补充现有的匹配因素，但需要进一步评估其对学生参与度和匹配质量的全面影响。

Abstract: Social connection is a vital part of learning, yet online course environments
present barriers to the organic formation of social groups. SAMI offers one
solution by facilitating student connections, but its effectiveness is
constrained by an incomplete Theory of Mind, limiting its ability to create an
effective mental model of a student. One facet of this is its inability to
intuit personality, which may influence the relevance of its recommendations.
To explore this, we propose a personality detection model utilizing GPTs
zero-shot capability to infer Big-Five personality traits from forum
introduction posts, often encouraged in online courses. We benchmark its
performance against established models, demonstrating its efficacy in this
task. Furthermore, we integrate this model into SAMIs entity-based matchmaking
system, enabling personality-informed social recommendations. Initial
integration suggests personality traits can complement existing matching
factors, though additional evaluation is required to determine their full
impact on student engagement and match quality.

</details>


### [32] [Fluent but Unfeeling: The Emotional Blind Spots of Language Models](https://arxiv.org/abs/2509.09593)
*Bangzhao Shu,Isha Joshi,Melissa Karnaze,Anh C. Pham,Ishita Kakkar,Sindhu Kothe,Arpine Hovasapian,Mai ElSherief*

Main category: cs.CL

TL;DR: 本文介绍了EXPRESS数据集，用于评估大型语言模型在细粒度情绪对齐方面的表现，并发现它们在捕捉上下文线索方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常专注于将情绪分类到预定义的有限类别中，而忽略了更细微的表达。因此，需要评估大型语言模型是否能在细粒度层面与人类情绪一致。

Method: 引入了EXPRESS数据集，并采用全面的评估框架来分析预测的情绪术语，并将其分解为八种基本情绪，以进行细粒度比较。

Result: 系统测试表明，准确预测与人类自我披露情绪一致的情绪仍然具有挑战性。定性分析进一步显示，某些大型语言模型生成的情绪术语与已建立的情绪理论和定义一致，但有时无法像人类自我披露那样有效地捕捉上下文线索。

Conclusion: 研究结果表明，大型语言模型在细粒度情绪对齐方面存在局限性，并为未来提高其上下文理解能力的研究提供了见解。

Abstract: The versatility of Large Language Models (LLMs) in natural language
understanding has made them increasingly popular in mental health research.
While many studies explore LLMs' capabilities in emotion recognition, a
critical gap remains in evaluating whether LLMs align with human emotions at a
fine-grained level. Existing research typically focuses on classifying emotions
into predefined, limited categories, overlooking more nuanced expressions. To
address this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit
communities featuring 251 fine-grained, self-disclosed emotion labels. Our
comprehensive evaluation framework examines predicted emotion terms and
decomposes them into eight basic emotions using established emotion theories,
enabling a fine-grained comparison. Systematic testing of prevalent LLMs under
various prompt settings reveals that accurately predicting emotions that align
with human self-disclosed emotions remains challenging. Qualitative analysis
further shows that while certain LLMs generate emotion terms consistent with
established emotion theories and definitions, they sometimes fail to capture
contextual cues as effectively as human self-disclosures. These findings
highlight the limitations of LLMs in fine-grained emotion alignment and offer
insights for future research aimed at enhancing their contextual understanding.

</details>


### [33] [LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death Determination](https://arxiv.org/abs/2509.09602)
*Yiqun T. Chen,Tyler H. McCormick,Li Liu,Abhirup Datta*

Main category: cs.CL

TL;DR: 本研究提出了一种结合大型语言模型和传统方法的验证概念管道LA-VA，用于提高死亡原因预测的准确性。结果显示，GPT-5的表现优于传统方法，显示出大型语言模型在低资源环境中的潜在应用价值。


<details>
  <summary>Details</summary>
Motivation: 在缺乏医疗认证的资源有限的环境中，口头尸检（VA）是估计死亡原因的关键工具。本研究旨在探索使用大型语言模型来提高口头尸检的准确性。

Method: 该研究提出了LA-VA，这是一个结合大型语言模型（LLMs）与传统算法方法和基于嵌入的分类的验证概念管道，以提高死亡原因预测。

Result: GPT-5在单独表现上取得了最高成绩，在成人、儿童和新生儿的平均测试站点准确率分别为48.6%、50.5%和53.5%，比传统的统计机器学习基线高出5-10%。

Conclusion: 研究结果表明，简单的现成大型语言模型辅助方法可以显著提高口头尸检的准确性，这对低资源环境中的全球健康监测具有重要意义。

Abstract: Verbal autopsy (VA) is a critical tool for estimating causes of death in
resource-limited settings where medical certification is unavailable. This
study presents LA-VA, a proof-of-concept pipeline that combines Large Language
Models (LLMs) with traditional algorithmic approaches and embedding-based
classification for improved cause-of-death prediction. Using the Population
Health Metrics Research Consortium (PHMRC) dataset across three age categories
(Adult: 7,580; Child: 1,960; Neonate: 2,438), we evaluate multiple approaches:
GPT-5 predictions, LCVA baseline, text embeddings, and meta-learner ensembles.
Our results demonstrate that GPT-5 achieves the highest individual performance
with average test site accuracies of 48.6% (Adult), 50.5% (Child), and 53.5%
(Neonate), outperforming traditional statistical machine learning baselines by
5-10%. Our findings suggest that simple off-the-shelf LLM-assisted approaches
could substantially improve verbal autopsy accuracy, with important
implications for global health surveillance in low-resource settings.

</details>


### [34] [Bridging the Capability Gap: Joint Alignment Tuning for Harmonizing LLM-based Multi-Agent Systems](https://arxiv.org/abs/2509.09629)
*Minghang Zhu,Zhengliang Shi,Zhiwei Xu,Shiguang Wu,Lingjie Wang,Pengjie Ren,Zhaochun Ren,Zhumin Chen*

Main category: cs.CL

TL;DR: MOAT is a framework for improving multi-agent collaboration by iteratively aligning planning and grounding agents, resulting in better performance on various tasks.


<details>
  <summary>Details</summary>
Motivation: Most existing methods typically fine-tune these agents independently, leading to capability gaps among them with poor coordination.

Method: MOAT, a Multi-Agent Joint Alignment Tuning framework that improves agents collaboration through iterative alignment, alternating between Planning Agent Alignment and Grounding Agent Improving stages.

Result: Experiments across six benchmarks demonstrate that MOAT outperforms state-of-the-art baselines, achieving average improvements of 3.1% on held-in tasks and 4.4% on held-out tasks.

Conclusion: MOAT outperforms state-of-the-art baselines, achieving average improvements of 3.1% on held-in tasks and 4.4% on held-out tasks.

Abstract: The advancement of large language models (LLMs) has enabled the construction
of multi-agent systems to solve complex tasks by dividing responsibilities
among specialized agents, such as a planning agent for subgoal generation and a
grounding agent for executing tool-use actions. Most existing methods typically
fine-tune these agents independently, leading to capability gaps among them
with poor coordination. To address this, we propose MOAT, a Multi-Agent Joint
Alignment Tuning framework that improves agents collaboration through iterative
alignment. MOAT alternates between two key stages: (1) Planning Agent
Alignment, which optimizes the planning agent to generate subgoal sequences
that better guide the grounding agent; and (2) Grounding Agent Improving, which
fine-tunes the grounding agent using diverse subgoal-action pairs generated by
the agent itself to enhance its generalization capablity. Theoretical analysis
proves that MOAT ensures a non-decreasing and progressively convergent training
process. Experiments across six benchmarks demonstrate that MOAT outperforms
state-of-the-art baselines, achieving average improvements of 3.1% on held-in
tasks and 4.4% on held-out tasks.

</details>


### [35] [All for One: LLMs Solve Mental Math at the Last Token With Information Transferred From Other Tokens](https://arxiv.org/abs/2509.09650)
*Siddarth Mamidanna,Daking Rai,Ziyu Yao,Yilun Zhou*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型在心算任务中的内部工作机制，通过两种技术发现了高效的计算子图。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在许多计算任务中表现出色，但它们的内部工作机制仍然不明确。本文旨在探讨这些模型在心算任务中的计算过程。

Method: 本文提出了两种技术：上下文感知均值消融（CAMA）和基于注意力的窥视（ABP），以研究大型语言模型在心算任务中的内部运作。

Result: 通过CAMA和ABP技术，我们发现了一个高精度的All-for-One子图（AF1），其中有意义的计算发生在非常晚的层深度，并且只在最后一个标记上发生。

Conclusion: 实验表明，这种子图对于高模型性能是充分且必要的，并且可以在不同模型之间迁移，适用于各种输入风格。

Abstract: Large language models (LLMs) demonstrate proficiency across numerous
computational tasks, yet their inner workings remain unclear. In theory, the
combination of causal self-attention and multilayer perceptron layers allows
every token to access and compute information based on all preceding tokens. In
practice, to what extent are such operations present? In this paper, on mental
math tasks (i.e., direct math calculation via next-token prediction without
explicit reasoning), we investigate this question in three steps: inhibiting
input-specific token computations in the initial layers, restricting the routes
of information transfer across token positions in the next few layers, and
forcing all computation to happen at the last token in the remaining layers.
With two proposed techniques, Context-Aware Mean Ablation (CAMA) and
Attention-Based Peeking (ABP), we identify an All-for-One subgraph (AF1) with
high accuracy on a wide variety of mental math tasks, where meaningful
computation occurs very late (in terms of layer depth) and only at the last
token, which receives information of other tokens in few specific middle
layers. Experiments on a variety of models and arithmetic expressions show that
this subgraph is sufficient and necessary for high model performance, transfers
across different models, and works on a variety of input styles. Ablations on
different CAMA and ABP alternatives reveal their unique advantages over other
methods, which may be of independent interest.

</details>


### [36] [Steering MoE LLMs via Expert (De)Activation](https://arxiv.org/abs/2509.09660)
*Mohsen Fayyaz,Ali Modarressi,Hanieh Deilamsalehy,Franck Dernoncourt,Ryan Rossi,Trung Bui,Hinrich Schütze,Nanyun Peng*

Main category: cs.CL

TL;DR: SteerMoE是一种新的框架，可以检测和控制MoE模型中的行为相关专家，从而在不重新训练或修改权重的情况下控制LLM的行为。然而，这种技术也可能被用于对抗性攻击，降低安全性和真实性。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型在处理不同输入时可能表现出不同的行为，但缺乏一种有效的方法来检测和控制这些行为相关的专家。因此，需要一种新的方法来实现对LLM行为的精确控制。

Method: SteerMoE通过检测在对比输入中表现出不同激活模式的专家来实现对MoE模型的操控。在推理过程中，通过选择性地（去）激活这些专家，可以控制如忠实性和安全性等行为。

Result: 在11个基准测试和6个LLM上，SteerMoE提高了安全性高达+20%和忠实性高达+27%。在对抗性攻击模式下，它单独降低了安全性-41%，并与现有越狱方法结合时降低了-100%，绕过了所有安全防护措施，揭示了隐藏在专家中的对齐虚假的新维度。

Conclusion: SteerMoE框架可以有效地检测和控制与行为相关的专家，从而在不重新训练或修改权重的情况下控制LLM的行为。然而，这种技术也可能被用于对抗性攻击，降低安全性和真实性。

Abstract: Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token
through a subset of specialized Feed-Forward Networks (FFN), known as experts.
We present SteerMoE, a framework for steering MoE models by detecting and
controlling behavior-linked experts. Our detection method identifies experts
with distinct activation patterns across paired inputs exhibiting contrasting
behaviors. By selectively (de)activating such experts during inference, we
control behaviors like faithfulness and safety without retraining or modifying
weights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to
+20% and faithfulness by +27%. In adversarial attack mode, it drops safety by
-41% alone, and -100% when combined with existing jailbreak methods, bypassing
all safety guardrails and exposing a new dimension of alignment faking hidden
within experts.

</details>


### [37] [CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning in Large Language Models](https://arxiv.org/abs/2509.09675)
*Runpeng Dai,Linfeng Song,Haolin Liu,Zhenwen Liang,Dian Yu,Haitao Mi,Zhaopeng Tu,Rui Liu,Tong Zheng,Hongtu Zhu,Dong Yu*

Main category: cs.CL

TL;DR: 本文提出了一种基于好奇心的探索方法（CDE），用于增强RLVR的探索能力，从而提高LLM的推理能力。实验结果显示，该方法在AIME基准测试中取得了显著的性能提升，并揭示了RLVR中的校准崩溃机制。


<details>
  <summary>Details</summary>
Motivation: 当前的RLVR方法往往探索不足，导致过早收敛和熵崩溃。为了应对这一挑战，我们需要一种能够提高探索效果的方法。

Method: 我们引入了基于好奇心的探索（CDE），利用模型自身的内在好奇心来指导探索。我们通过演员和评论家的信号来形式化好奇心：对于演员，我们使用其生成响应的困惑度；对于评论家，我们使用多头架构的价值估计方差。这两种信号都在RLVR框架内作为探索奖励来引导模型。

Result: 我们的方法在AIME基准测试中相对于标准RLVR实现了大约+3点的改进。进一步分析揭示了RLVR中的校准崩溃机制，有助于理解常见的LLM失败模式。

Conclusion: 我们的方法在AIME基准测试中相对于标准RLVR实现了大约+3点的改进，并揭示了RLVR中的校准崩溃机制，有助于理解常见的LLM失败模式。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful paradigm
for enhancing the reasoning ability of Large Language Models (LLMs). Yet
current RLVR methods often explore poorly, leading to premature convergence and
entropy collapse. To address this challenge, we introduce Curiosity-Driven
Exploration (CDE), a framework that leverages the model's own intrinsic sense
of curiosity to guide exploration. We formalize curiosity with signals from
both the actor and the critic: for the actor, we use perplexity over its
generated response, and for the critic, we use the variance of value estimates
from a multi-head architecture. Both signals serve as an exploration bonus
within the RLVR framework to guide the model. Our theoretical analysis shows
that the actor-wise bonus inherently penalizes overconfident errors and
promotes diversity among correct responses; moreover, we connect the
critic-wise bonus to the well-established count-based exploration bonus in RL.
Empirically, our method achieves an approximate +3 point improvement over
standard RLVR using GRPO/PPO on AIME benchmarks. Further analysis identifies a
calibration collapse mechanism within RLVR, shedding light on common LLM
failure modes.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [38] [Generative Engine Optimization: How to Dominate AI Search](https://arxiv.org/abs/2509.08919)
*Mahe Chen,Xiaoxuan Wang,Kaiwen Chen,Nick Koudas*

Main category: cs.IR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The rapid adoption of generative AI-powered search engines like ChatGPT,
Perplexity, and Gemini is fundamentally reshaping information retrieval, moving
from traditional ranked lists to synthesized, citation-backed answers. This
shift challenges established Search Engine Optimization (SEO) practices and
necessitates a new paradigm, which we term Generative Engine Optimization
(GEO).
  This paper presents a comprehensive comparative analysis of AI Search and
traditional web search (Google). Through a series of large-scale, controlled
experiments across multiple verticals, languages, and query paraphrases, we
quantify critical differences in how these systems source information. Our key
findings reveal that AI Search exhibit a systematic and overwhelming bias
towards Earned media (third-party, authoritative sources) over Brand-owned and
Social content, a stark contrast to Google's more balanced mix. We further
demonstrate that AI Search services differ significantly from each other in
their domain diversity, freshness, cross-language stability, and sensitivity to
phrasing.
  Based on these empirical results, we formulate a strategic GEO agenda. We
provide actionable guidance for practitioners, emphasizing the critical need
to: (1) engineer content for machine scannability and justification, (2)
dominate earned media to build AI-perceived authority, (3) adopt
engine-specific and language-aware strategies, and (4) overcome the inherent
"big brand bias" for niche players. Our work provides the foundational
empirical analysis and a strategic framework for achieving visibility in the
new generative search landscape.

</details>


### [39] [Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations](https://arxiv.org/abs/2509.09651)
*Zakaria El Kassimi,Fares Fourati,Mohamed-Slim Alouini*

Main category: cs.IR

TL;DR: 本文研究了无线电法规领域的问答问题，提出了一种电信特定的检索增强生成（RAG）管道，并构建了第一个多选评估集。实验结果表明，该方法在生成准确性方面有显著提升。


<details>
  <summary>Details</summary>
Motivation: 我们研究了无线电法规领域的问答，这是一个法律敏感且高风险的领域。

Method: 我们提出了一个电信特定的检索增强生成（RAG）管道，并引入了我们认为的第一个多选评估集，该集从权威来源使用自动化过滤和人工验证构建。

Result: 我们的检索器在定义的领域特定检索指标下达到了约97%的准确率。除了检索之外，我们的方法在所有测试模型的生成准确性方面都持续提高。特别是，虽然天真地插入没有结构化检索的文档仅对GPT-4o产生微不足道的增益（不到1%），但应用我们的管道结果几乎提高了12%的相对改进。

Conclusion: 这些发现表明，精心定位的接地提供了一个简单而强大的基线，并为法规问答提供了有效的领域特定解决方案。

Abstract: We study question answering in the domain of radio regulations, a legally
sensitive and high-stakes area. We propose a telecom-specific
Retrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge,
the first multiple-choice evaluation set for this domain, constructed from
authoritative sources using automated filtering and human validation. To assess
retrieval quality, we define a domain-specific retrieval metric, under which
our retriever achieves approximately 97% accuracy. Beyond retrieval, our
approach consistently improves generation accuracy across all tested models. In
particular, while naively inserting documents without structured retrieval
yields only marginal gains for GPT-4o (less than 1%), applying our pipeline
results in nearly a 12% relative improvement. These findings demonstrate that
carefully targeted grounding provides a simple yet strong baseline and an
effective domain-specific solution for regulatory question answering. All code
and evaluation scripts, along with our derived question-answer dataset, are
available at https://github.com/Zakaria010/Radio-RAG.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [40] [Open-sci-ref-0.01: open and reproducible reference baselines for language model and dataset comparison](https://arxiv.org/abs/2509.09009)
*Marianna Nezhurina,Taishi Nakamura,Timur Carstensen,Niccolò Ajroldi,Ville Komulainen,David Salinas,Jenia Jitsev*

Main category: cs.LG

TL;DR: 本文介绍了open-sci-ref，一系列在多个模型和标记规模上训练的密集Transformer模型，作为研究基线。


<details>
  <summary>Details</summary>
Motivation: 为了提供一个标准化的基准，使研究人员能够评估其他训练方法的合理性和质量。

Method: 训练了一系列密集的Transformer模型，作为跨多个模型（0.13B到1.7B参数）和标记规模（高达1T）的研究基线。

Result: 在NemoTron-CC HQ上训练的表现优于其他参考数据集，其次是DCLM-baseline和FineWeb-Edu。

Conclusion: 通过建立基准线，研究人员可以比较不同的训练方法，并在不同规模和数据集上评估其合理性和质量。

Abstract: We introduce open-sci-ref, a family of dense transformer models trained as
research baselines across multiple model (0.13B to 1.7B parameters) and token
scales (up to 1T) on 8 recent open reference datasets. Evaluating the models on
various standardized benchmarks, our training runs set establishes reference
points that enable researchers to assess the sanity and quality of alternative
training approaches across scales and datasets. Intermediate checkpoints allow
comparison and studying of the training dynamics. The established reference
baselines allow training procedures to be compared through their scaling
trends, aligning them on a common compute axis. Comparison of open reference
datasets reveals that training on NemoTron-CC HQ consistently outperforms other
reference datasets, followed by DCLM-baseline and FineWeb-Edu. In addition to
intermediate training checkpoints, the release includes logs, code, and
downstream evaluations to simplify reproduction, standardize comparison, and
facilitate future research.

</details>


### [41] [Identifying Key Features for Establishing Sustainable Agro-Tourism Centre: A Data Driven Approach](https://arxiv.org/abs/2509.09214)
*Alka Gadakh,Vidya Kumbhar,Sonal Khosla,Kumar Karunendra*

Main category: cs.LG

TL;DR: 本研究探讨了农业旅游的增长策略，通过文献综述和先进方法确定了关键指标，并应用了LASSO方法和多种机器学习模型进行特征选择，结果显示逻辑回归模型在不同训练测试比例下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 农业旅游作为一种战略经济模式，旨在通过多样化当地社区（如农民）的收入来源，促进农村发展，同时保护本土文化传统和传统农业实践。由于农业旅游是一个快速增长的子领域，需要详细研究其增长策略。

Method: 该研究分为两个阶段：第一阶段通过全面的文献综述确定了重要的指标，第二阶段使用了最先进的技术来识别促进农业旅游增长的重要指标。应用了机器学习模型进行特征选择，包括LASSO方法以及逻辑回归（LR）、决策树（DT）、随机森林（RF）和极端梯度提升（XGBoost）模型。

Result: 研究结果显示，使用LASSO方法结合逻辑回归模型在70-30%的训练测试数据中取得了最高的分类准确率98%，而在80-20%的训练测试数据中，逻辑回归模型保持最高准确率99%。决策树和XGBoost模型分别以97%的准确率紧随其后。

Conclusion: 研究结果表明，使用LASSO方法结合逻辑回归（LR）模型在70-30%的训练测试数据中取得了最高的分类准确率98%，而在80-20%的训练测试数据中，LR模型保持最高准确率99%。

Abstract: Agro-tourism serves as a strategic economic model designed to facilitate
rural development by diversifying income streams for local communities like
farmers while promoting the conservation of indigenous cultural heritage and
traditional agricultural practices. As a very booming subdomain of tourism,
there is a need to study the strategies for the growth of Agro-tourism in
detail. The current study has identified the important indicators for the
growth and enhancement of agro-tourism. The study is conducted in two phases:
identification of the important indicators through a comprehensive literature
review and in the second phase state-of-the-art techniques were used to
identify the important indicators for the growth of agro-tourism. The
indicators are also called features synonymously, the machine learning models
for feature selection were applied and it was observed that the Least Absolute
Shrinkage and Selection Operator (LASSO) method combined with, the machine
Learning Classifiers such as Logistic Regression (LR), Decision Trees (DT),
Random Forest (RF) Tree, and Extreme Gradient Boosting (XGBOOST) models were
used to suggest the growth of the agro-tourism. The results show that with the
LASSO method, LR model gives the highest classification accuracy of 98% in
70-30% train-test data followed by RF with 95% accuracy. Similarly, in the
80-20% train-test data LR maintains the highest accuracy at 99%, while DT and
XGBoost follow with 97% accuracy.

</details>


### [42] [Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents](https://arxiv.org/abs/2509.09265)
*Jiawei Wang,Jiacai Liu,Yuqian Fu,Yingru Li,Xintao Wang,Yuan Lin,Yu Yue,Lin Zhang,Yang Wang,Ke Wang*

Main category: cs.LG

TL;DR: 本文提出了一种名为EMPG的框架，通过基于步骤不确定性及最终任务结果重新校准学习信号，解决了LLM在长时任务中由于稀疏奖励导致的信用分配问题。EMPG放大了对自信正确动作的更新，惩罚了自信错误，并减弱了不确定步骤的更新以稳定探索。此外，还引入了一个未来清晰度奖励项，鼓励代理找到更可预测的解决方案路径。实验表明，EMPG在三个挑战性的代理任务中表现出显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: In long-horizon tasks, recent agents based on Large Language Models (LLMs) face a significant challenge that sparse, outcome-based rewards make it difficult to assign credit to intermediate steps. Previous methods mainly focus on creating dense reward signals to guide learning, either through traditional reinforcement learning techniques or by using Process Reward Models for step-by-step feedback.

Method: Entropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the learning signal based on step-wise uncertainty and the final task outcome. EMPG amplifies updates for confident correct actions, penalizes confident errors, and attenuates updates from uncertain steps to stabilize exploration. A bonus term for future clarity is introduced to encourage agents to find more predictable solution paths.

Result: Through comprehensive experiments on three challenging agent tasks, WebShop, ALFWorld, and Deep Search, we demonstrate that EMPG achieves substantial performance gains and significantly outperforms strong policy gradient baselines.

Conclusion: EMPG achieves substantial performance gains and significantly outperforms strong policy gradient baselines.

Abstract: In long-horizon tasks, recent agents based on Large Language Models (LLMs)
face a significant challenge that sparse, outcome-based rewards make it
difficult to assign credit to intermediate steps. Previous methods mainly focus
on creating dense reward signals to guide learning, either through traditional
reinforcement learning techniques like inverse reinforcement learning or by
using Process Reward Models for step-by-step feedback. In this paper, we
identify a fundamental problem in the learning dynamics of LLMs: the magnitude
of policy gradients is inherently coupled with the entropy, which leads to
inefficient small updates for confident correct actions and potentially
destabilizes large updates for uncertain ones. To resolve this, we propose
Entropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the
learning signal based on step-wise uncertainty and the final task outcome. EMPG
amplifies updates for confident correct actions, penalizes confident errors,
and attenuates updates from uncertain steps to stabilize exploration. We
further introduce a bonus term for future clarity that encourages agents to
find more predictable solution paths. Through comprehensive experiments on
three challenging agent tasks, WebShop, ALFWorld, and Deep Search, we
demonstrate that EMPG achieves substantial performance gains and significantly
outperforms strong policy gradient baselines. Project page is at
https://empgseed-seed.github.io/

</details>


### [43] [LLMs Don't Know Their Own Decision Boundaries: The Unreliability of Self-Generated Counterfactual Explanations](https://arxiv.org/abs/2509.09396)
*Harry Mayne,Ryan Othniel Kearns,Yushi Yang,Andrew M. Bean,Eoin Delaney,Chris Russell,Adam Mahdi*

Main category: cs.LG

TL;DR: This paper studies self-generated counterfactual explanations (SCEs) for language models. It finds that while SCEs are often valid, they are rarely minimal, offering little insight into model behavior. The results suggest that SCEs may be an ineffective or even misleading explainability tool.


<details>
  <summary>Details</summary>
Motivation: To collaborate effectively with humans, language models must be able to explain their decisions in natural language. SCEs are a type of self-explanation that could help achieve this goal.

Method: We study self-generated counterfactual explanations (SCEs), where a model explains its prediction by modifying the input such that it would have predicted a different outcome. We evaluate whether LLMs can produce SCEs that are valid and minimal.

Result: LLMs typically produce SCEs that are valid but not minimal, offering little insight into their decision-making behavior. When asked to generate minimal counterfactuals, LLMs make excessively small edits that fail to change predictions. The validity-minimality trade-off is consistent across several LLMs, datasets, and evaluation settings.

Conclusion: SCEs are, at best, an ineffective explainability tool and, at worst, can provide misleading insights into model behaviour. Proposals to deploy LLMs in high-stakes settings must consider the impact of unreliable self-explanations on downstream decision-making.

Abstract: To collaborate effectively with humans, language models must be able to
explain their decisions in natural language. We study a specific type of
self-explanation: self-generated counterfactual explanations (SCEs), where a
model explains its prediction by modifying the input such that it would have
predicted a different outcome. We evaluate whether LLMs can produce SCEs that
are valid, achieving the intended outcome, and minimal, modifying the input no
more than necessary. When asked to generate counterfactuals, we find that LLMs
typically produce SCEs that are valid, but far from minimal, offering little
insight into their decision-making behaviour. Worryingly, when asked to
generate minimal counterfactuals, LLMs typically make excessively small edits
that fail to change predictions. The observed validity-minimality trade-off is
consistent across several LLMs, datasets, and evaluation settings. Our findings
suggest that SCEs are, at best, an ineffective explainability tool and, at
worst, can provide misleading insights into model behaviour. Proposals to
deploy LLMs in high-stakes settings must consider the impact of unreliable
self-explanations on downstream decision-making. Our code is available at
https://github.com/HarryMayne/SCEs.

</details>


### [44] [ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable Orthogonal Butterfly Transforms](https://arxiv.org/abs/2509.09679)
*Bingxin Xu,Zhen Dong,Oussama Elachqar,Yuzhang Shang*

Main category: cs.LG

TL;DR: ButterflyQuant is a learnable rotation-based method for extreme 2-bit quantization that outperforms existing approaches by adapting to specific weight distributions and improving outlier suppression.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the limitations of fixed rotation-based methods for extreme 2-bit quantization, which suffer from catastrophic performance loss due to outliers in activations.

Method: ButterflyQuant replaces Hadamard rotations with learnable butterfly transforms parameterized by continuous Givens rotation angles, enabling smooth optimization while guaranteeing orthogonality. It also introduces uniformity regularization on post-transformation activations.

Result: ButterflyQuant achieves a perplexity of 15.4 on LLaMA-2-7B with 2-bit quantization, compared to 22.1 for QuaRot.

Conclusion: ButterflyQuant achieves better performance than existing methods like QuaRot when applied to LLaMA-2-7B with 2-bit quantization.

Abstract: Large language models require massive memory footprints, severely limiting
deployment on consumer hardware. Quantization reduces memory through lower
numerical precision, but extreme 2-bit quantization suffers from catastrophic
performance loss due to outliers in activations. Rotation-based methods such as
QuIP and QuaRot apply orthogonal transforms to eliminate outliers before
quantization, using computational invariance: $\mathbf{y} = \mathbf{Wx} =
(\mathbf{WQ}^T)(\mathbf{Qx})$ for orthogonal $\mathbf{Q}$. However, these
methods use fixed transforms--Hadamard matrices achieving optimal worst-case
coherence $\mu = 1/\sqrt{n}$--that cannot adapt to specific weight
distributions. We identify that different transformer layers exhibit distinct
outlier patterns, motivating layer-adaptive rotations rather than
one-size-fits-all approaches. We propose ButterflyQuant, which replaces
Hadamard rotations with learnable butterfly transforms parameterized by
continuous Givens rotation angles. Unlike Hadamard's discrete $\{+1, -1\}$
entries that are non-differentiable and prohibit gradient-based learning,
butterfly transforms' continuous parameterization enables smooth optimization
while guaranteeing orthogonality by construction. This orthogonal constraint
ensures theoretical guarantees in outlier suppression while achieving $O(n \log
n)$ computational complexity with only $\frac{n \log n}{2}$ learnable
parameters. We further introduce a uniformity regularization on
post-transformation activations to promote smoother distributions amenable to
quantization. Learning requires only 128 calibration samples and converges in
minutes on a single GPU--a negligible one-time cost. On LLaMA-2-7B with 2-bit
quantization, ButterflyQuant achieves 15.4 perplexity versus 22.1 for QuaRot.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [45] [A vibe coding learning design to enhance EFL students' talking to, through, and about AI](https://arxiv.org/abs/2509.08854)
*David James Woo,Kai Guo,Yangyang Yu*

Main category: cs.CY

TL;DR: This article explores the use of vibe coding in EFL education, focusing on how students interact with AI. It presents a framework for understanding these interactions and highlights the importance of meta-languaging in effective vibe coding instruction.


<details>
  <summary>Details</summary>
Motivation: The article aims to explore the use of vibe coding (using natural language to create software applications with AI) in English as a Foreign Language (EFL) education. It seeks to understand how students interact with AI and how this interaction affects their ability to create functional applications.

Method: We developed a human-AI meta-languaging framework with three dimensions: talking to AI (prompt engineering), talking through AI (negotiating authorship), and talking about AI (mental models of AI). Using backward design principles, we created a four-hour workshop where two students designed applications addressing authentic EFL writing challenges. A case study methodology was adopted, collecting data from worksheets, video recordings, think-aloud protocols, screen recordings, and AI-generated images.

Result: Contrasting cases showed one student successfully vibe coding a functional application cohering to her intended design, while another encountered technical difficulties with major gaps between intended design and actual functionality. Analysis reveals differences in students' prompt engineering approaches, suggesting different AI mental models and tensions in attributing authorship.

Conclusion: AI functions as a beneficial languaging machine, and differences in how students talk to, through, and about AI explain vibe coding outcome variations. Effective vibe coding instruction requires explicit meta-languaging scaffolding, teaching structured prompt engineering, facilitating critical authorship discussions, and developing vocabulary for articulating AI mental models.

Abstract: This innovative practice article reports on the piloting of vibe coding
(using natural language to create software applications with AI) for English as
a Foreign Language (EFL) education. We developed a human-AI meta-languaging
framework with three dimensions: talking to AI (prompt engineering), talking
through AI (negotiating authorship), and talking about AI (mental models of
AI). Using backward design principles, we created a four-hour workshop where
two students designed applications addressing authentic EFL writing challenges.
We adopted a case study methodology, collecting data from worksheets and video
recordings, think-aloud protocols, screen recordings, and AI-generated images.
Contrasting cases showed one student successfully vibe coding a functional
application cohering to her intended design, while another encountered
technical difficulties with major gaps between intended design and actual
functionality. Analysis reveals differences in students' prompt engineering
approaches, suggesting different AI mental models and tensions in attributing
authorship. We argue that AI functions as a beneficial languaging machine, and
that differences in how students talk to, through, and about AI explain vibe
coding outcome variations. Findings indicate that effective vibe coding
instruction requires explicit meta-languaging scaffolding, teaching structured
prompt engineering, facilitating critical authorship discussions, and
developing vocabulary for articulating AI mental models.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [46] [Bona fide Cross Testing Reveals Weak Spot in Audio Deepfake Detection Systems](https://arxiv.org/abs/2509.09204)
*Chin Yuen Kwok,Jia Qi Yip,Zhen Qiu,Chi Hung Chi,Kwok Yan Lam*

Main category: cs.SD

TL;DR: 本文提出了一种新的评估框架，用于音频深度伪造检测，以提高评估的平衡性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的ADD数据集在真实语音方面缺乏多样性，通常只包含一种环境和语音风格，限制了它们模拟现实条件的能力。此外，使用EER作为性能指标会不成比例地加权样本较多的合成器，而其他合成器则被低估，这降低了EER的整体可靠性。

Method: 我们提出了一个名为真实语音交叉测试的新评估框架，该框架结合了多样化的真实语音数据集，并聚合EER以进行更平衡的评估。

Result: 我们对九种真实语音类型中的超过150个合成器进行了基准测试，并发布了一个新的数据集以促进进一步的研究。

Conclusion: 我们的方法相比传统评估方法提高了鲁棒性和可解释性。我们对超过150个合成器进行了基准测试，并发布了一个新的数据集以促进进一步的研究。

Abstract: Audio deepfake detection (ADD) models are commonly evaluated using datasets
that combine multiple synthesizers, with performance reported as a single Equal
Error Rate (EER). However, this approach disproportionately weights
synthesizers with more samples, underrepresenting others and reducing the
overall reliability of EER. Additionally, most ADD datasets lack diversity in
bona fide speech, often featuring a single environment and speech style (e.g.,
clean read speech), limiting their ability to simulate real-world conditions.
To address these challenges, we propose bona fide cross-testing, a novel
evaluation framework that incorporates diverse bona fide datasets and
aggregates EERs for more balanced assessments. Our approach improves robustness
and interpretability compared to traditional evaluation methods. We benchmark
over 150 synthesizers across nine bona fide speech types and release a new
dataset to facilitate further research at
https://github.com/cyaaronk/audio_deepfake_eval.

</details>


### [47] [DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for Low-Latency Zero-Shot Text-To-Speech](https://arxiv.org/abs/2509.09631)
*Ngoc-Son Nguyen,Hieu-Nghia Huynh-Nguyen,Thanh V. T. Tran,Truong-Son Hy,Van Nguyen*

Main category: cs.SD

TL;DR: DiFlow-TTS is a novel model that explores purely Discrete Flow Matching for speech synthesis, achieving promising performance in several key metrics while maintaining a compact model size and low-latency inference.


<details>
  <summary>Details</summary>
Motivation: Recent approaches based on language models, diffusion, and flow matching have shown promising results in zero-shot TTS, but still suffer from slow inference and repetition artifacts. Existing flow-matching methods typically embed these discrete tokens into a continuous space and apply continuous flow matching, which may not fully leverage the advantages of discrete representations.

Method: DiFlow-TTS explicitly models factorized speech attributes within a compact and unified architecture. It leverages in-context learning by conditioning on textual content, along with prosodic and acoustic attributes extracted from a reference speech, enabling effective attribute cloning in a zero-shot setting. The model employs a factorized flow prediction mechanism with distinct heads for prosody and acoustic details, allowing it to learn aspect-specific distributions.

Result: Experimental results demonstrate that DiFlow-TTS achieves promising performance in several key metrics, including naturalness, prosody, preservation of speaker style, and energy control. It also maintains a compact model size and achieves low-latency inference, generating speech up to 25.8 times faster than the latest existing baselines.

Conclusion: DiFlow-TTS achieves promising performance in several key metrics, including naturalness, prosody, preservation of speaker style, and energy control. It also maintains a compact model size and achieves low-latency inference, generating speech up to 25.8 times faster than the latest existing baselines.

Abstract: Zero-shot Text-to-Speech (TTS) aims to synthesize high-quality speech that
mimics the voice of an unseen speaker using only a short reference sample,
requiring not only speaker adaptation but also accurate modeling of prosodic
attributes. Recent approaches based on language models, diffusion, and flow
matching have shown promising results in zero-shot TTS, but still suffer from
slow inference and repetition artifacts. Discrete codec representations have
been widely adopted for speech synthesis, and recent works have begun to
explore diffusion models in purely discrete settings, suggesting the potential
of discrete generative modeling for speech synthesis. However, existing
flow-matching methods typically embed these discrete tokens into a continuous
space and apply continuous flow matching, which may not fully leverage the
advantages of discrete representations. To address these challenges, we
introduce DiFlow-TTS, which, to the best of our knowledge, is the first model
to explore purely Discrete Flow Matching for speech synthesis. DiFlow-TTS
explicitly models factorized speech attributes within a compact and unified
architecture. It leverages in-context learning by conditioning on textual
content, along with prosodic and acoustic attributes extracted from a reference
speech, enabling effective attribute cloning in a zero-shot setting. In
addition, the model employs a factorized flow prediction mechanism with
distinct heads for prosody and acoustic details, allowing it to learn
aspect-specific distributions. Experimental results demonstrate that DiFlow-TTS
achieves promising performance in several key metrics, including naturalness,
prosody, preservation of speaker style, and energy control. It also maintains a
compact model size and achieves low-latency inference, generating speech up to
25.8 times faster than the latest existing baselines.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [48] [Recurrence Meets Transformers for Universal Multimodal Retrieval](https://arxiv.org/abs/2509.08897)
*Davide Caffagni,Sara Sarto,Marcella Cornia,Lorenzo Baraldi,Rita Cucchiara*

Main category: cs.CV

TL;DR: 本文提出了一种统一的检索模型ReT-2，支持多模态查询（包括图像和文本），并在多模态文档集合中进行搜索。ReT-2利用多层表示和具有LSTM启发式门控机制的递归Transformer架构，动态整合跨层和模态的信息，捕捉细粒度的视觉和文本细节。在M2KR和M-BEIR基准测试中评估了ReT-2，并展示了其在各种设置中的一致性最先进的性能，同时相比之前的方法具有更快的推理速度和更低的内存使用。当集成到检索增强生成管道中时，ReT-2也提高了Encyclopedic-VQA和InfoSeek数据集的下游性能。


<details>
  <summary>Details</summary>
Motivation: Existing methods predominantly rely on task-specific fine-tuning of vision-language models and are limited to single-modality queries or documents. With the rapid advancement of multimodal retrieval and its application in LLMs and multimodal LLMs, increasingly complex retrieval tasks have emerged.

Method: ReT-2 leverages multi-layer representations and a recurrent Transformer architecture with LSTM-inspired gating mechanisms to dynamically integrate information across layers and modalities, capturing fine-grained visual and textual details.

Result: We evaluate ReT-2 on the challenging M2KR and M-BEIR benchmarks across different retrieval configurations. Results demonstrate that ReT-2 consistently achieves state-of-the-art performance across diverse settings, while offering faster inference and reduced memory usage compared to prior approaches. When integrated into retrieval-augmented generation pipelines, ReT-2 also improves downstream performance on Encyclopedic-VQA and InfoSeek datasets.

Conclusion: ReT-2 consistently achieves state-of-the-art performance across diverse settings, while offering faster inference and reduced memory usage compared to prior approaches. When integrated into retrieval-augmented generation pipelines, ReT-2 also improves downstream performance on Encyclopedic-VQA and InfoSeek datasets.

Abstract: With the rapid advancement of multimodal retrieval and its application in
LLMs and multimodal LLMs, increasingly complex retrieval tasks have emerged.
Existing methods predominantly rely on task-specific fine-tuning of
vision-language models and are limited to single-modality queries or documents.
In this paper, we propose ReT-2, a unified retrieval model that supports
multimodal queries, composed of both images and text, and searches across
multimodal document collections where text and images coexist. ReT-2 leverages
multi-layer representations and a recurrent Transformer architecture with
LSTM-inspired gating mechanisms to dynamically integrate information across
layers and modalities, capturing fine-grained visual and textual details. We
evaluate ReT-2 on the challenging M2KR and M-BEIR benchmarks across different
retrieval configurations. Results demonstrate that ReT-2 consistently achieves
state-of-the-art performance across diverse settings, while offering faster
inference and reduced memory usage compared to prior approaches. When
integrated into retrieval-augmented generation pipelines, ReT-2 also improves
downstream performance on Encyclopedic-VQA and InfoSeek datasets. Our source
code and trained models are publicly available at:
https://github.com/aimagelab/ReT-2

</details>


### [49] [COCO-Urdu: A Large-Scale Urdu Image-Caption Dataset with Multimodal Quality Estimation](https://arxiv.org/abs/2509.09014)
*Umair Hassan*

Main category: cs.CV

TL;DR: 本文介绍了COCO-Urdu，一个大规模的乌尔都语图像描述数据集，旨在减少多模态研究中的语言偏差并建立包容性的视觉语言系统。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语在多模态和视觉语言研究中严重不足，缺乏大规模高质量的数据集限制了乌尔都语系统的开发，并加剧了多语言视觉语言模型的偏见。

Method: 使用SeamlessM4T v2进行翻译，并利用混合多模态质量评估框架（包括COMET-Kiwi、CLIP-based相似性和BERTScore与反向翻译）对句子进行验证和迭代优化。

Result: COCO-Urdu是目前最大的公开可用的乌尔都语图像描述数据集，在BLEU、SacreBLEU和chrF指标上表现出色。

Conclusion: 通过发布数据集和质量评估管道，我们旨在减少多模态研究中的语言偏差，并为包容性的视觉语言系统建立基础。

Abstract: Urdu, spoken by over 250 million people, remains critically under-served in
multimodal and vision-language research. The absence of large-scale,
high-quality datasets has limited the development of Urdu-capable systems and
reinforced biases in multilingual vision-language models trained primarily on
high-resource languages. To address this gap, we present COCO-Urdu, a
large-scale image-caption dataset derived from MS COCO, containing 59,000
images and 319,000 Urdu captions selected through stratified sampling to
preserve the original distribution. Captions were translated using SeamlessM4T
v2 and validated with a hybrid multimodal quality estimation framework that
integrates COMET-Kiwi for translation quality, CLIP-based similarity for visual
grounding, and BERTScore with back-translation for semantic consistency;
low-scoring captions were iteratively refined using open-source large language
models. We further benchmark COCO-Urdu on BLEU, SacreBLEU, and chrF, reporting
consistently strong results. To the best of our knowledge, COCO-Urdu is the
largest publicly available Urdu captioning dataset. By releasing both the
dataset and the quality estimation pipeline, we aim to reduce language bias in
multimodal research and establish a foundation for inclusive vision-language
systems.

</details>


### [50] [Can Multimodal LLMs See Materials Clearly? A Multimodal Benchmark on Materials Characterization](https://arxiv.org/abs/2509.09307)
*Zhengzhao Lai,Youbin Zheng,Zhenyang Cai,Haonan Lyu,Jinpu Yang,Hongqing Liang,Yan Hu,Benyou Wang*

Main category: cs.CV

TL;DR: 本文提出了MatCha基准，用于评估大型语言模型在材料表征图像理解中的能力，并发现现有模型在处理复杂问题时表现不佳。


<details>
  <summary>Details</summary>
Motivation: 为了填补大型语言模型在理解真实世界材料表征图像数据方面的不足，提出了MatCha基准。

Method: 提出MatCha基准，用于评估大型语言模型在材料表征图像理解中的能力。

Result: 评估结果显示，最先进的大型语言模型在MatCha上的表现与人类专家存在显著差距，特别是在需要高级专业知识和复杂视觉感知的问题上。

Conclusion: 现有大型语言模型在处理实际材料表征场景时仍表现出适应性有限，需要进一步研究改进。

Abstract: Materials characterization is fundamental to acquiring materials information,
revealing the processing-microstructure-property relationships that guide
material design and optimization. While multimodal large language models
(MLLMs) have recently shown promise in generative and predictive tasks within
materials science, their capacity to understand real-world characterization
imaging data remains underexplored. To bridge this gap, we present MatCha, the
first benchmark for materials characterization image understanding, comprising
1,500 questions that demand expert-level domain expertise. MatCha encompasses
four key stages of materials research comprising 21 distinct tasks, each
designed to reflect authentic challenges faced by materials scientists. Our
evaluation of state-of-the-art MLLMs on MatCha reveals a significant
performance gap compared to human experts. These models exhibit degradation
when addressing questions requiring higher-level expertise and sophisticated
visual perception. Simple few-shot and chain-of-thought prompting struggle to
alleviate these limitations. These findings highlight that existing MLLMs still
exhibit limited adaptability to real-world materials characterization
scenarios. We hope MatCha will facilitate future research in areas such as new
material discovery and autonomous scientific agents. MatCha is available at
https://github.com/FreedomIntelligence/MatCha.

</details>


### [51] [FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark](https://arxiv.org/abs/2509.09680)
*Rongyao Fang,Aldrich Yu,Chengqi Duan,Linjiang Huang,Shuai Bai,Yuxuan Cai,Kun Wang,Si Liu,Xihui Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: 本文介绍了FLUX-Reason-6M数据集和PRISM-Bench基准，用于解决开放源代码文本到图像模型在推理能力上的不足，并通过评估发现了一些性能差距。


<details>
  <summary>Details</summary>
Motivation: 开放源代码文本到图像（T2I）模型的进步受到缺乏大规模、专注于推理的数据集和全面评估基准的阻碍，导致与领先的封闭源系统相比存在性能差距。

Method: 我们引入了FLUX-Reason-6M和PRISM-Bench，其中FLUX-Reason-6M是一个包含600万张高质量FLUX生成图像和2000万条中英文描述的数据集，并设计了生成链式思维（GCoT）来提供详细的图像生成步骤分解。PRISM-Bench提供了七个不同赛道的新评估标准，包括使用GCoT的长文本挑战。

Result: 我们在PRISM-Bench上对19个领先模型进行了广泛评估，揭示了关键性能差距并突出了需要改进的具体领域。

Conclusion: 我们的数据集、基准和评估代码已发布，以推动面向推理的T2I生成的下一次浪潮。

Abstract: The advancement of open-source text-to-image (T2I) models has been hindered
by the absence of large-scale, reasoning-focused datasets and comprehensive
evaluation benchmarks, resulting in a performance gap compared to leading
closed-source systems. To address this challenge, We introduce FLUX-Reason-6M
and PRISM-Bench (Precise and Robust Image Synthesis Measurement Benchmark).
FLUX-Reason-6M is a massive dataset consisting of 6 million high-quality
FLUX-generated images and 20 million bilingual (English and Chinese)
descriptions specifically designed to teach complex reasoning. The image are
organized according to six key characteristics: Imagination, Entity, Text
rendering, Style, Affection, and Composition, and design explicit Generation
Chain-of-Thought (GCoT) to provide detailed breakdowns of image generation
steps. The whole data curation takes 15,000 A100 GPU days, providing the
community with a resource previously unattainable outside of large industrial
labs. PRISM-Bench offers a novel evaluation standard with seven distinct
tracks, including a formidable Long Text challenge using GCoT. Through
carefully designed prompts, it utilizes advanced vision-language models for
nuanced human-aligned assessment of prompt-image alignment and image
aesthetics. Our extensive evaluation of 19 leading models on PRISM-Bench
reveals critical performance gaps and highlights specific areas requiring
improvement. Our dataset, benchmark, and evaluation code are released to
catalyze the next wave of reasoning-oriented T2I generation. Project page:
https://flux-reason-6m.github.io/ .

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [52] [Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs](https://arxiv.org/abs/2509.08847)
*Amna Hassan*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的框架，通过自然语言处理和多模态大型语言模型将游戏设计文档转化为功能性的Unity游戏原型，显著提高了性能并解决了AI辅助游戏开发中的关键差距。


<details>
  <summary>Details</summary>
Motivation: 本文旨在通过自然语言处理和多模态大型语言模型，将游戏设计文档转化为功能性的Unity游戏原型，以解决AI辅助游戏开发中的关键差距。

Method: 我们引入了一个端到端系统，解析GDD，提取结构化的游戏规范，并合成符合Unity的C#代码，实现了核心机制、系统和架构。我们的方法结合了专门用于Unity代码生成的微调LLaMA-3模型和自定义的Unity集成包。

Result: 评估结果表明，与基线模型相比，我们的微调模型在编译成功率、GDD遵循度、最佳实践采用和代码模块化指标方面表现优越（平均得分4.8/5.0）。生成的模板在多个游戏类型中表现出对GDD规范的高度遵循度。

Conclusion: 我们的系统有效解决了AI辅助游戏开发中的关键差距，将LLMs定位为在从游戏设计到实现的过渡中具有价值的工具。

Abstract: This paper presents a novel framework for automated game template generation
by transforming Game Design Documents (GDDs) into functional Unity game
prototypes using Natural Language Processing (NLP) and multi-modal Large
Language Models (LLMs). We introduce an end-to-end system that parses GDDs,
extracts structured game specifications, and synthesizes Unity-compatible C#
code that implements the core mechanics, systems, and architecture defined in
the design documentation. Our approach combines a fine-tuned LLaMA-3 model
specialized for Unity code generation with a custom Unity integration package
that streamlines the implementation process. Evaluation results demonstrate
significant improvements over baseline models, with our fine-tuned model
achieving superior performance (4.8/5.0 average score) compared to
state-of-the-art LLMs across compilation success, GDD adherence, best practices
adoption, and code modularity metrics. The generated templates demonstrate high
adherence to GDD specifications across multiple game genres. Our system
effectively addresses critical gaps in AI-assisted game development,
positioning LLMs as valuable tools in streamlining the transition from game
design to implementation.

</details>


### [53] [Tree-OPO: Off-policy Monte Carlo Tree-Guided Advantage Optimization for Multistep Reasoning](https://arxiv.org/abs/2509.09284)
*Bingning Huang,Tu Nguyen,Matthieu Zimmer*

Main category: cs.AI

TL;DR: 本文探讨了如何利用MCTS生成的轨迹来改进基于偏好的强化学习中的策略优化，并提出了一种分阶段的GRPO训练范式。


<details>
  <summary>Details</summary>
Motivation: 我们探索了传统上用于训练价值或奖励模型的MCTS派生轨迹如何被重新用于改进基于偏好的强化学习（RL）中的策略优化。

Method: 我们提出了一种分阶段的GRPO训练范式，其中完成是从部分揭示的MCTS回溯中得出的，引入了一种新颖的树状结构用于优势估计。

Result: 我们的初步结果表明，虽然结构化的优势估计可以稳定更新并更好地反映组合推理质量，但诸如优势饱和和奖励信号崩溃等挑战仍然存在。

Conclusion: 我们的初步结果表明，虽然结构化的优势估计可以稳定更新并更好地反映组合推理质量，但诸如优势饱和和奖励信号崩溃等挑战仍然存在。我们提出了启发式和统计解决方案来缓解这些问题，并讨论了在分阶段或树状奖励结构下学习的开放挑战。

Abstract: Recent advances in reasoning with large language models (LLMs) have shown the
effectiveness of Monte Carlo Tree Search (MCTS) for generating high-quality
intermediate trajectories, particularly in math and symbolic domains. Inspired
by this, we explore how MCTS-derived trajectories, traditionally used for
training value or reward models, can be repurposed to improve policy
optimization in preference-based reinforcement learning (RL). Specifically, we
focus on Group Relative Policy Optimization (GRPO), a recent algorithm that
enables preference-consistent policy learning without value networks. We
propose a staged GRPO training paradigm where completions are derived from
partially revealed MCTS rollouts, introducing a novel tree-structured setting
for advantage estimation. This leads to a rich class of prefix-conditioned
reward signals, which we analyze theoretically and empirically. Our initial
results indicate that while structured advantage estimation can stabilize
updates and better reflect compositional reasoning quality, challenges such as
advantage saturation and reward signal collapse remain. We propose heuristic
and statistical solutions to mitigate these issues and discuss open challenges
for learning under staged or tree-like reward structures.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [54] [OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning](https://arxiv.org/abs/2509.09332)
*Yuecheng Liu,Dafeng Chi,Shiguang Wu,Zhanguang Zhang,Yuzheng Zhuang,Bowen Yang,He Zhu,Lingfeng Zhang,Pengwei Xie,David Gamaliel Arcos Bravo,Yingxue Zhang,Jianye Hao,Xingyue Quan*

Main category: cs.RO

TL;DR: OmniEVA is an embodied versatile planner that addresses the limitations of current MLLM-based embodied systems by introducing a Task-Adaptive 3D Grounding mechanism and an Embodiment-Aware Reasoning framework, achieving state-of-the-art performance in embodied reasoning and planning.


<details>
  <summary>Details</summary>
Motivation: Current MLLM-based embodied systems face two critical limitations: (1) Geometric Adaptability Gap: models trained solely on 2D inputs or with hard-coded 3D geometry injection suffer from either insufficient spatial information or restricted 2D generalization, leading to poor adaptability across tasks with diverse spatial demands. (2) Embodiment Constraint Gap: prior work often neglects the physical constraints and capacities of real robots, resulting in task plans that are theoretically valid but practically infeasible.

Method: Introduce OmniEVA -- an embodied versatile planner that enables advanced embodied reasoning and task planning through two pivotal innovations: (1) a Task-Adaptive 3D Grounding mechanism, which introduces a gated router to perform explicit selective regulation of 3D fusion based on contextual requirements, enabling context-aware 3D grounding for diverse embodied tasks. (2) an Embodiment-Aware Reasoning framework that jointly incorporates task goals and embodiment constraints into the reasoning loop, resulting in planning decisions that are both goal-directed and executable.

Result: Extensive experimental results demonstrate that OmniEVA achieves state-of-the-art general embodied reasoning performance and exhibits a strong ability across a wide range of downstream scenarios. Evaluations of a suite of proposed embodied benchmarks, including both primitive and composite tasks, confirm its robust and versatile planning capabilities.

Conclusion: OmniEVA not only achieves state-of-the-art general embodied reasoning performance, but also exhibits a strong ability across a wide range of downstream scenarios. Evaluations of a suite of proposed embodied benchmarks confirm its robust and versatile planning capabilities.

Abstract: Recent advances in multimodal large language models (MLLMs) have opened new
opportunities for embodied intelligence, enabling multimodal understanding,
reasoning, and interaction, as well as continuous spatial decision-making.
Nevertheless, current MLLM-based embodied systems face two critical
limitations. First, Geometric Adaptability Gap: models trained solely on 2D
inputs or with hard-coded 3D geometry injection suffer from either insufficient
spatial information or restricted 2D generalization, leading to poor
adaptability across tasks with diverse spatial demands. Second, Embodiment
Constraint Gap: prior work often neglects the physical constraints and
capacities of real robots, resulting in task plans that are theoretically valid
but practically infeasible.To address these gaps, we introduce OmniEVA -- an
embodied versatile planner that enables advanced embodied reasoning and task
planning through two pivotal innovations: (1) a Task-Adaptive 3D Grounding
mechanism, which introduces a gated router to perform explicit selective
regulation of 3D fusion based on contextual requirements, enabling
context-aware 3D grounding for diverse embodied tasks. (2) an Embodiment-Aware
Reasoning framework that jointly incorporates task goals and embodiment
constraints into the reasoning loop, resulting in planning decisions that are
both goal-directed and executable. Extensive experimental results demonstrate
that OmniEVA not only achieves state-of-the-art general embodied reasoning
performance, but also exhibits a strong ability across a wide range of
downstream scenarios. Evaluations of a suite of proposed embodied benchmarks,
including both primitive and composite tasks, confirm its robust and versatile
planning capabilities. Project page: https://omnieva.github.io

</details>


### [55] [SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning](https://arxiv.org/abs/2509.09674)
*Haozhan Li,Yuxin Zuo,Jiale Yu,Yuhao Zhang,Zhaohui Yang,Kaiyan Zhang,Xuekai Zhu,Yuchen Zhang,Tianxing Chen,Ganqu Cui,Dehui Wang,Dingxiang Luo,Yuchen Fan,Youbang Sun,Jia Zeng,Jiangmiao Pang,Shanghang Zhang,Yu Wang,Yao Mu,Bowen Zhou,Ning Ding*

Main category: cs.RO

TL;DR: 本文提出了SimpleVLA-RL，一个针对VLA模型的高效强化学习框架，能够减少对大规模数据的依赖，实现稳健的泛化，并在现实任务中超越SFT。


<details>
  <summary>Details</summary>
Motivation: 尽管通过大规模预训练和监督微调（SFT）取得了显著进展，但这些模型面临两个基本挑战：(i) 用于SFT扩展的大规模人工操作机器人轨迹的稀缺性和高成本，以及(ii) 有限的任务泛化能力。最近在大型推理模型（LRMs）中的突破表明，强化学习（RL）可以显著增强逐步推理能力，这引发了自然的问题：RL能否同样改善VLA的长期步骤动作规划？

Method: 本文介绍了SimpleVLA-RL，这是一个针对VLA模型的高效强化学习框架。基于veRL，我们引入了VLA特定的轨迹采样、可扩展的并行化、多环境渲染和优化的损失计算。

Result: 当应用于OpenVLA-OFT时，SimpleVLA-RL在LIBERO上达到了最先进（SoTA）性能，并且在我们引入的探索增强策略下，在RoboTwin 1.0&2.0上超过了π_0。

Conclusion: SimpleVLA-RL不仅减少了对大规模数据的依赖，还实现了稳健的泛化，并在现实任务中显著超越了SFT。此外，在RL训练过程中，我们发现了一个新的现象'pushcut'，其中策略发现了之前训练过程中未见过的模式。

Abstract: Vision-Language-Action (VLA) models have recently emerged as a powerful
paradigm for robotic manipulation. Despite substantial progress enabled by
large-scale pretraining and supervised fine-tuning (SFT), these models face two
fundamental challenges: (i) the scarcity and high cost of large-scale
human-operated robotic trajectories required for SFT scaling, and (ii) limited
generalization to tasks involving distribution shift. Recent breakthroughs in
Large Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can
dramatically enhance step-by-step reasoning capabilities, raising a natural
question: Can RL similarly improve the long-horizon step-by-step action
planning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL
framework tailored for VLA models. Building upon veRL, we introduce
VLA-specific trajectory sampling, scalable parallelization, multi-environment
rendering, and optimized loss computation. When applied to OpenVLA-OFT,
SimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $\pi_0$
on RoboTwin 1.0\&2.0 with the exploration-enhancing strategies we introduce.
SimpleVLA-RL not only reduces dependence on large-scale data and enables robust
generalization, but also remarkably surpasses SFT in real-world tasks.
Moreover, we identify a novel phenomenon ``pushcut'' during RL training,
wherein the policy discovers previously unseen patterns beyond those seen in
the previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL

</details>
