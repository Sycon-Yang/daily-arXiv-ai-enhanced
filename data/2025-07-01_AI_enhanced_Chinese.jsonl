{"id": "2506.22439", "pdf": "https://arxiv.org/pdf/2506.22439", "abs": "https://arxiv.org/abs/2506.22439", "authors": ["Javier Conde", "Miguel Gonz\u00e1lez", "Mar\u00eda Grandury", "Gonzalo Mart\u00ednez", "Pedro Reviriego", "Mar Brysbaert"], "title": "Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted for the GEM2 workshop at ACL 2025", "summary": "The evaluation of LLMs has so far focused primarily on how well they can\nperform different tasks such as reasoning, question-answering, paraphrasing, or\ntranslating. For most of these tasks, performance can be measured with\nobjective metrics, such as the number of correct answers. However, other\nlanguage features are not easily quantified. For example, arousal,\nconcreteness, or gender associated with a given word, as well as the extent to\nwhich we experience words with senses and relate them to a specific sense.\nThose features have been studied for many years by psycholinguistics,\nconducting large-scale experiments with humans to produce ratings for thousands\nof words. This opens an opportunity to evaluate how well LLMs align with human\nratings on these word features, taking advantage of existing studies that cover\nmany different language features in a large number of words. In this paper, we\nevaluate the alignment of a representative group of LLMs with human ratings on\ntwo psycholinguistic datasets: the Glasgow and Lancaster norms. These datasets\ncover thirteen features over thousands of words. The results show that\nalignment is \\textcolor{black}{generally} better in the Glasgow norms evaluated\n(arousal, valence, dominance, concreteness, imageability, familiarity, and\ngender) than on the Lancaster norms evaluated (introceptive, gustatory,\nolfactory, haptic, auditory, and visual). This suggests a potential limitation\nof current LLMs in aligning with human sensory associations for words, which\nmay be due to their lack of embodied cognition present in humans and\nillustrates the usefulness of evaluating LLMs with psycholinguistic datasets.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u4eba\u7c7b\u5728\u5fc3\u7406\u8bed\u8a00\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u5bf9\u9f50\u60c5\u51b5\uff0c\u53d1\u73b0LLMs\u5728\u67d0\u4e9b\u611f\u5b98\u5173\u8054\u7279\u5f81\u4e0a\u7684\u8868\u73b0\u4e0d\u5982\u4eba\u7c7b\uff0c\u8fd9\u53ef\u80fd\u4e0e\u7f3a\u4e4f\u5177\u8eab\u8ba4\u77e5\u6709\u5173\u3002", "motivation": "\u4ee5\u5f80\u5bf9LLMs\u7684\u8bc4\u4f30\u4e3b\u8981\u96c6\u4e2d\u5728\u5b83\u4eec\u6267\u884c\u5404\u79cd\u4efb\u52a1\u7684\u80fd\u529b\u4e0a\uff0c\u5982\u63a8\u7406\u3001\u95ee\u7b54\u3001\u6539\u5199\u6216\u7ffb\u8bd1\u3002\u7136\u800c\uff0c\u5176\u4ed6\u8bed\u8a00\u7279\u5f81\u96be\u4ee5\u91cf\u5316\uff0c\u4f8b\u5982\u4e00\u4e2a\u8bcd\u7684\u5524\u9192\u5ea6\u3001\u5177\u4f53\u6027\u6216\u6027\u522b\uff0c\u4ee5\u53ca\u6211\u4eec\u901a\u8fc7\u611f\u5b98\u4f53\u9a8c\u8bcd\u8bed\u5e76\u5c06\u5176\u4e0e\u7279\u5b9a\u611f\u5b98\u76f8\u5173\u8054\u7684\u7a0b\u5ea6\u3002\u5fc3\u7406\u8bed\u8a00\u5b66\u5df2\u7ecf\u5bf9\u8fd9\u4e9b\u7279\u5f81\u8fdb\u884c\u4e86\u591a\u5e74\u7684\u7814\u7a76\uff0c\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u7684\u4eba\u7c7b\u5b9e\u9a8c\u4ea7\u751f\u4e86\u6570\u5343\u4e2a\u8bcd\u7684\u8bc4\u5206\u3002\u8fd9\u4e3a\u8bc4\u4f30LLMs\u4e0e\u4eba\u7c7b\u8bc4\u5206\u5728\u8fd9\u4e9b\u8bcd\u7279\u5f81\u4e0a\u7684\u5bf9\u9f50\u7a0b\u5ea6\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "method": "\u672c\u6587\u8bc4\u4f30\u4e86\u4ee3\u8868\u6027\u7684\u4e00\u7ec4LLMs\u4e0e\u4eba\u7c7b\u5728\u4e24\u4e2a\u5fc3\u7406\u8bed\u8a00\u5b66\u6570\u636e\u96c6\uff08Glasgow\u548cLancaster\u89c4\u8303\uff09\u4e0a\u7684\u5bf9\u9f50\u60c5\u51b5\u3002\u8fd9\u4e9b\u6570\u636e\u96c6\u6db5\u76d6\u4e86\u6570\u5343\u4e2a\u5355\u8bcd\u7684\u5341\u4e09\u4e2a\u7279\u5f81\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u8bc4\u4f30\u7684Glasgow\u89c4\u8303\uff08\u5524\u9192\u5ea6\u3001\u60c5\u7eea\u4ef7\u503c\u3001\u652f\u914d\u529b\u3001\u5177\u4f53\u6027\u3001\u5f62\u8c61\u6027\u3001\u719f\u6089\u5ea6\u548c\u6027\u522b\uff09\u4e2d\uff0c\u5bf9\u9f50\u5ea6\u901a\u5e38\u66f4\u597d\uff0c\u800c\u5728\u8bc4\u4f30\u7684Lancaster\u89c4\u8303\uff08\u5185\u7701\u3001\u5473\u89c9\u3001\u55c5\u89c9\u3001\u89e6\u89c9\u3001\u542c\u89c9\u548c\u89c6\u89c9\uff09\u4e2d\u5bf9\u9f50\u5ea6\u8f83\u5dee\u3002", "conclusion": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e0e\u4eba\u7c7b\u5bf9\u8bcd\u8bed\u7279\u5f81\u7684\u8bc4\u4ef7\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u4e00\u5b9a\u7684\u5c40\u9650\u6027\uff0c\u8fd9\u53ef\u80fd\u662f\u56e0\u4e3a\u5b83\u4eec\u7f3a\u4e4f\u4eba\u7c7b\u6240\u5177\u6709\u7684\u5177\u8eab\u8ba4\u77e5\u3002\u540c\u65f6\uff0c\u8be5\u7814\u7a76\u4e5f\u5c55\u793a\u4e86\u4f7f\u7528\u5fc3\u7406\u8bed\u8a00\u5b66\u6570\u636e\u96c6\u8bc4\u4f30LLMs\u7684\u6709\u7528\u6027\u3002"}}
{"id": "2506.22485", "pdf": "https://arxiv.org/pdf/2506.22485", "abs": "https://arxiv.org/abs/2506.22485", "authors": ["Sudip Dasgupta", "Himanshu Shankar"], "title": "AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents", "categories": ["cs.CL", "cs.AI", "68T07, 68T50", "I.2.1; I.2.3; I.2.7; H.3.3"], "comment": "17 pages, 2 system diagrams, 1 table, no prior conference publication", "summary": "This study presents a modular, multi-agent system for the automated review of\nhighly structured enterprise business documents using AI agents. Unlike prior\nsolutions focused on unstructured texts or limited compliance checks, this\nframework leverages modern orchestration tools such as LangChain, CrewAI,\nTruLens, and Guidance to enable section-by-section evaluation of documents for\naccuracy, consistency, completeness, and clarity. Specialized agents, each\nresponsible for discrete review criteria such as template compliance or factual\ncorrectness, operate in parallel or sequence as required. Evaluation outputs\nare enforced to a standardized, machine-readable schema, supporting downstream\nanalytics and auditability. Continuous monitoring and a feedback loop with\nhuman reviewers allow for iterative system improvement and bias mitigation.\n  Quantitative evaluation demonstrates that the AI Agent-as-Judge system\napproaches or exceeds human performance in key areas: achieving 99% information\nconsistency (vs. 92% for humans), halving error and bias rates, and reducing\naverage review time from 30 to 2.5 minutes per document, with a 95% agreement\nrate between AI and expert human judgment. While promising for a wide range of\nindustries, the study also discusses current limitations, including the need\nfor human oversight in highly specialized domains and the operational cost of\nlarge-scale LLM usage. The proposed system serves as a flexible, auditable, and\nscalable foundation for AI-driven document quality assurance in the enterprise\ncontext.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI\u4ee3\u7406\u7684\u6a21\u5757\u5316\u3001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u5ba1\u67e5\u9ad8\u5ea6\u7ed3\u6784\u5316\u7684\u4f01\u4e1a\u4e1a\u52a1\u6587\u6863\u3002\u8be5\u7cfb\u7edf\u5728\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u3001\u5b8c\u6574\u6027\u3001\u6e05\u6670\u5ea6\u7b49\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5728\u5173\u952e\u9886\u57df\u63a5\u8fd1\u6216\u8d85\u8d8a\u4eba\u7c7b\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u4e3b\u8981\u96c6\u4e2d\u5728\u975e\u7ed3\u6784\u5316\u6587\u672c\u6216\u6709\u9650\u7684\u5408\u89c4\u68c0\u67e5\u4e0a\uff0c\u800c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u9ad8\u5ea6\u7ed3\u6784\u5316\u4f01\u4e1a\u6587\u6863\u7684\u81ea\u52a8\u5316\u5ba1\u67e5\u95ee\u9898\u3002", "method": "\u8be5\u6846\u67b6\u5229\u7528\u73b0\u4ee3\u7f16\u6392\u5de5\u5177\uff08\u5982LangChain\u3001CrewAI\u3001TruLens\u548cGuidance\uff09\u5b9e\u73b0\u6309\u90e8\u5206\u8bc4\u4f30\u6587\u6863\u7684\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u3001\u5b8c\u6574\u6027\u548c\u6e05\u6670\u5ea6\u3002\u4e13\u95e8\u7684\u4ee3\u7406\u8d1f\u8d23\u4e0d\u540c\u7684\u5ba1\u67e5\u6807\u51c6\uff0c\u5982\u6a21\u677f\u5408\u89c4\u6027\u6216\u4e8b\u5b9e\u6b63\u786e\u6027\uff0c\u5e76\u6839\u636e\u9700\u8981\u5e76\u884c\u6216\u987a\u5e8f\u8fd0\u884c\u3002", "result": "\u5b9a\u91cf\u8bc4\u4f30\u8868\u660e\uff0cAI\u4ee3\u7406\u4f5c\u4e3a\u6cd5\u5b98\u7cfb\u7edf\u5728\u5173\u952e\u9886\u57df\u63a5\u8fd1\u6216\u8d85\u8d8a\u4eba\u7c7b\u8868\u73b0\uff1a\u8fbe\u523099%\u7684\u4fe1\u606f\u4e00\u81f4\u6027\uff08\u6bd4\u4eba\u7c7b\u768492%\u9ad8\uff09\uff0c\u9519\u8bef\u548c\u504f\u89c1\u7387\u51cf\u534a\uff0c\u5e73\u5747\u5ba1\u67e5\u65f6\u95f4\u4ece30\u5206\u949f\u51cf\u5c11\u52302.5\u5206\u949f\uff0cAI\u4e0e\u4e13\u5bb6\u4eba\u7c7b\u5224\u65ad\u7684\u534f\u8bae\u7387\u8fbe\u523095%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u3001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u4f7f\u7528AI\u4ee3\u7406\u81ea\u52a8\u5ba1\u67e5\u9ad8\u5ea6\u7ed3\u6784\u5316\u7684\u4f01\u4e1a\u4e1a\u52a1\u6587\u6863\u3002\u8be5\u7cfb\u7edf\u5728\u5173\u952e\u9886\u57df\u63a5\u8fd1\u6216\u8d85\u8d8a\u4eba\u7c7b\u8868\u73b0\uff0c\u5e76\u4e3aAI\u9a71\u52a8\u7684\u4f01\u4e1a\u6587\u6863\u8d28\u91cf\u4fdd\u8bc1\u63d0\u4f9b\u4e86\u7075\u6d3b\u3001\u53ef\u5ba1\u8ba1\u548c\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2506.22486", "pdf": "https://arxiv.org/pdf/2506.22486", "abs": "https://arxiv.org/abs/2506.22486", "authors": ["Ming Cheung"], "title": "Hallucination Detection with Small Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Since the introduction of ChatGPT, large language models (LLMs) have\ndemonstrated significant utility in various tasks, such as answering questions\nthrough retrieval-augmented generation. Context can be retrieved using a\nvectorized database, serving as a foundation for LLMs to generate responses.\nHowever, hallucinations in responses can undermine the reliability of LLMs in\npractical applications, and they are not easily detectable in the absence of\nground truth, particularly in question-and-answer scenarios. This paper\nproposes a framework that integrates multiple small language models to verify\nresponses generated by LLMs using the retrieved context from a vectorized\ndatabase. By breaking down the responses into individual sentences and\nutilizing the probability of generating \"Yes\" tokens from the outputs of\nmultiple models for a given set of questions, responses, and relevant context,\nhallucinations can be detected. The proposed framework is validated through\nexperiments with real datasets comprising over 100 sets of questions, answers,\nand contexts, including responses with fully and partially correct sentences.\nThe results demonstrate a 10\\% improvement in F1 scores for detecting correct\nresponses compared to hallucinations, indicating that multiple small language\nmodels can be effectively employed for answer verification, providing a\nscalable and efficient solution for both academic and practical applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u591a\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u68c0\u6d4bLLMs\u751f\u6210\u56de\u7b54\u4e2d\u5e7b\u89c9\u7684\u6846\u67b6\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u4e14\u9ad8\u6548\u3002", "motivation": "LLMs\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u53d7\u5230\u56de\u7b54\u4e2d\u5e7b\u89c9\u7684\u5a01\u80c1\uff0c\u800c\u8fd9\u4e9b\u5e7b\u89c9\u5728\u6ca1\u6709\u771f\u5b9e\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u96be\u4ee5\u68c0\u6d4b\uff0c\u7279\u522b\u662f\u5728\u95ee\u7b54\u573a\u666f\u4e2d\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6846\u67b6\uff0c\u901a\u8fc7\u5c06LLMs\u751f\u6210\u7684\u56de\u7b54\u5206\u89e3\u4e3a\u5355\u72ec\u7684\u53e5\u5b50\uff0c\u5e76\u5229\u7528\u591a\u4e2a\u6a21\u578b\u5bf9\u7ed9\u5b9a\u95ee\u9898\u3001\u56de\u7b54\u548c\u76f8\u5173\u4e0a\u4e0b\u6587\u751f\u6210'\u662f'\u6807\u8bb0\u7684\u6982\u7387\u6765\u68c0\u6d4b\u5e7b\u89c9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u68c0\u6d4b\u5e7b\u89c9\u76f8\u6bd4\uff0c\u68c0\u6d4b\u6b63\u786e\u56de\u7b54\u7684F1\u5206\u6570\u63d0\u9ad8\u4e8610%\uff0c\u8bc1\u660e\u4e86\u591a\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u7528\u4e8e\u7b54\u6848\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6574\u5408\u591a\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u68c0\u6d4bLLMs\u751f\u6210\u56de\u7b54\u4e2d\u7684\u5e7b\u89c9\u7684\u80fd\u529b\uff0c\u4e3a\u5b66\u672f\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.22491", "pdf": "https://arxiv.org/pdf/2506.22491", "abs": "https://arxiv.org/abs/2506.22491", "authors": ["Oliver Warke", "Joemon M. Jose", "Faegheh Hasibi", "Jan Breitsohl"], "title": "PromptAug: Fine-grained Conflict Classification Using Data Augmentation", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.7; J.4; K.4.2"], "comment": null, "summary": "Given the rise of conflicts on social media, effective classification models\nto detect harmful behaviours are essential. Following the\ngarbage-in-garbage-out maxim, machine learning performance depends heavily on\ntraining data quality. However, high-quality labelled data, especially for\nnuanced tasks like identifying conflict behaviours, is limited, expensive, and\ndifficult to obtain. Additionally, as social media platforms increasingly\nrestrict access to research data, text data augmentation is gaining attention\nas an alternative to generate training data. Augmenting conflict-related data\nposes unique challenges due to Large Language Model (LLM) guardrails that\nprevent generation of offensive content. This paper introduces PromptAug, an\ninnovative LLM-based data augmentation method. PromptAug achieves statistically\nsignificant improvements of 2% in both accuracy and F1-score on conflict and\nemotion datasets. To thoroughly evaluate PromptAug against other data\naugmentation methods we conduct a robust evaluation using extreme data scarcity\nscenarios, quantitative diversity analysis and a qualitative thematic analysis.\nThe thematic analysis identifies four problematic patterns in augmented text:\nLinguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and\nAugmented Content Misinterpretation.\n  Overall, this work presents PromptAug as an effective method for augmenting\ndata in sensitive tasks like conflict detection, offering a unique,\ninterdisciplinary evaluation grounded in both natural language processing and\nsocial science methodology.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5PromptAug\uff0c\u5728\u51b2\u7a81\u548c\u60c5\u7eea\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u8bc4\u4f30\u65b9\u6cd5\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7531\u4e8e\u793e\u4f1a\u5a92\u4f53\u4e0a\u51b2\u7a81\u7684\u589e\u52a0\uff0c\u9700\u8981\u6709\u6548\u7684\u5206\u7c7b\u6a21\u578b\u6765\u68c0\u6d4b\u6709\u5bb3\u884c\u4e3a\u3002\u7136\u800c\uff0c\u9ad8\u8d28\u91cf\u7684\u6807\u8bb0\u6570\u636e\u5728\u8bf8\u5982\u8bc6\u522b\u51b2\u7a81\u884c\u4e3a\u7b49\u7ec6\u5fae\u4efb\u52a1\u4e2d\u662f\u6709\u9650\u7684\u3001\u6602\u8d35\u4e14\u96be\u4ee5\u83b7\u5f97\u7684\u3002\u6b64\u5916\uff0c\u7531\u4e8e\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u8d8a\u6765\u8d8a\u591a\u5730\u9650\u5236\u7814\u7a76\u6570\u636e\u7684\u8bbf\u95ee\uff0c\u6587\u672c\u6570\u636e\u589e\u5f3a\u6b63\u5728\u6210\u4e3a\u751f\u6210\u8bad\u7ec3\u6570\u636e\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86PromptAug\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002", "result": "PromptAug\u5728\u51b2\u7a81\u548c\u60c5\u7eea\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u548cF1\u5206\u6570\u5206\u522b\u63d0\u9ad8\u4e862%\u3002\u901a\u8fc7\u6781\u7aef\u6570\u636e\u7a00\u7f3a\u573a\u666f\u3001\u5b9a\u91cf\u591a\u6837\u6027\u5206\u6790\u548c\u5b9a\u6027\u4e3b\u9898\u5206\u6790\u5bf9PromptAug\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002\u4e3b\u9898\u5206\u6790\u8bc6\u522b\u51fa\u589e\u5f3a\u6587\u672c\u4e2d\u7684\u56db\u4e2a\u95ee\u9898\u6a21\u5f0f\uff1a\u8bed\u8a00\u6d41\u7545\u6027\u3001\u5e7d\u9ed8\u6a21\u7cca\u6027\u3001\u589e\u5f3a\u5185\u5bb9\u6a21\u7cca\u6027\u548c\u589e\u5f3a\u5185\u5bb9\u8bef\u89e3\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86PromptAug\u4f5c\u4e3a\u4e00\u79cd\u6709\u6548\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u7528\u4e8e\u654f\u611f\u4efb\u52a1\u5982\u51b2\u7a81\u68c0\u6d4b\uff0c\u5e76\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u793e\u4f1a\u79d1\u5b66\u65b9\u6cd5\u8fdb\u884c\u4e86\u8de8\u5b66\u79d1\u8bc4\u4f30\u3002"}}
{"id": "2506.22508", "pdf": "https://arxiv.org/pdf/2506.22508", "abs": "https://arxiv.org/abs/2506.22508", "authors": ["Chenyang Shao", "Tianxing Li", "Chenhao Pu", "Fengli Xu", "Yong Li"], "title": "AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text", "categories": ["cs.CL", "cs.AI"], "comment": "This work has been submitted to NeurIPS 2025. Under review", "summary": "In today's digital world, casual user-generated content often contains subtle\ncues that may inadvertently expose sensitive personal attributes. Such risks\nunderscore the growing importance of effective text anonymization to safeguard\nindividual privacy. However, existing methods either rely on rigid replacements\nthat damage utility or cloud-based LLMs that are costly and pose privacy risks.\nTo address these issues, we explore the use of locally deployed smaller-scale\nlanguage models (SLMs) for anonymization. Yet training effective SLMs remains\nchallenging due to limited high-quality supervision. To address the challenge,\nwe propose AgentStealth, a self-reinforcing LLM anonymization framework.First,\nwe introduce an adversarial anonymization workflow enhanced by In-context\nContrastive Learning and Adaptive Utility-Aware Control. Second, we perform\nsupervised adaptation of SLMs using high-quality data collected from the\nworkflow, which includes both anonymization and attack signals. Finally, we\napply online reinforcement learning where the model leverages its internal\nadversarial feedback to iteratively improve anonymization performance.\nExperiments on two datasets show that our method outperforms baselines in both\nanonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight\ndesign supports direct deployment on edge devices, avoiding cloud reliance and\ncommunication-based privacy risks. Our code is open-source at\nhttps://github.com/tsinghua-fib-lab/AgentStealth.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAgentStealth\u7684\u81ea\u589e\u5f3aLLM\u533f\u540d\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u5de5\u4f5c\u6d41\u3001\u76d1\u7763\u9002\u5e94\u548c\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6765\u63d0\u9ad8\u533f\u540d\u5316\u6548\u679c\u548c\u5b9e\u7528\u6027\uff0c\u5e76\u652f\u6301\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u4e8e\u521a\u6027\u7684\u66ff\u6362\uff0c\u8fd9\u4f1a\u635f\u5bb3\u6548\u7528\uff0c\u8981\u4e48\u4f9d\u8d56\u4e8e\u4e91-based LLMs\uff0c\u8fd9\u6210\u672c\u9ad8\u4e14\u5b58\u5728\u9690\u79c1\u98ce\u9669\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u6211\u4eec\u63a2\u7d22\u4e86\u672c\u5730\u90e8\u7f72\u7684\u5c0f\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u7528\u4e8e\u533f\u540d\u5316\u3002\u7136\u800c\uff0c\u7531\u4e8e\u9ad8\u8d28\u91cf\u76d1\u7763\u7684\u9650\u5236\uff0c\u8bad\u7ec3\u6709\u6548\u7684SLMs\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86AgentStealth\uff0c\u4e00\u79cd\u81ea\u589e\u5f3a\u7684LLM\u533f\u540d\u5316\u6846\u67b6\u3002\u9996\u5148\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u901a\u8fc7\u4e0a\u4e0b\u6587\u5bf9\u6bd4\u5b66\u4e60\u548c\u81ea\u9002\u5e94\u6548\u7528\u611f\u77e5\u63a7\u5236\u589e\u5f3a\u7684\u5bf9\u6297\u6027\u533f\u540d\u5316\u5de5\u4f5c\u6d41\u3002\u5176\u6b21\uff0c\u6211\u4eec\u4f7f\u7528\u4ece\u5de5\u4f5c\u6d41\u4e2d\u6536\u96c6\u7684\u9ad8\u8d28\u91cf\u6570\u636e\uff08\u5305\u62ec\u533f\u540d\u5316\u548c\u653b\u51fb\u4fe1\u53f7\uff09\u5bf9SLMs\u8fdb\u884c\u76d1\u7763\u9002\u5e94\u3002\u6700\u540e\uff0c\u6211\u4eec\u5e94\u7528\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\uff0c\u4f7f\u6a21\u578b\u5229\u7528\u5176\u5185\u90e8\u5bf9\u6297\u53cd\u9988\u6765\u8fed\u4ee3\u6539\u8fdb\u533f\u540d\u5316\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u533f\u540d\u5316\u6548\u679c\u63d0\u9ad8\u4e8612.3%\uff0c\u5b9e\u7528\u6027\u63d0\u9ad8\u4e866.8%\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u533f\u540d\u5316\u6548\u679c\u548c\u5b9e\u7528\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\uff0c\u8f7b\u91cf\u7ea7\u8bbe\u8ba1\u652f\u6301\u76f4\u63a5\u90e8\u7f72\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\uff0c\u907f\u514d\u4e86\u5bf9\u4e91\u7684\u4f9d\u8d56\u548c\u57fa\u4e8e\u901a\u4fe1\u7684\u9690\u79c1\u98ce\u9669\u3002"}}
{"id": "2506.22510", "pdf": "https://arxiv.org/pdf/2506.22510", "abs": "https://arxiv.org/abs/2506.22510", "authors": ["Zihao Zhao", "Xinlong Zhai", "Jinyu Yang", "Chuan Shi"], "title": "Towards Text-free Graph Foundation Models: Rethinking Multi-Domain Graph Contrastive Learning", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 5 figures", "summary": "Foundation models have achieved great success in natural language processing\n(NLP) and computer vision (CV). Their success largely stems from the ability to\nintegrate multi-domain knowledge in pre-training and transfer it to target\ndomains. Considering graph data, especially graphs without textual features, is\nubiquitous in real-world applications such as social networks and\nrecommendation systems, some researchers have attempted to extend this paradigm\nto the graph field, aiming to construct graph foundation models. However,\nunlike CV and NLP, there are huge gaps among the semantics and properties of\ngraphs in different domains, while current works still adopt traditional\ncontrastive pre-training strategies designed in the single-domain scenario,\nwhich regard contrastive samples from different domains as equivalent. From\nexperimental investigations, we discovered that inherent domain-specific\ndifferences prevent these strategies from effectively absorbing knowledge from\ndifferent domains to generate informative representations. In this paper, we\npropose a novel multi-domain pre-training and cross-domain transfer framework,\nnamely MDGCL.In the pre-training stage, we design a contrastive learning\nstrategy to substantially recognize and capture domain differences, and\nintroduce domain tokens to encode domain-level global information. In the\ndownstream stage, we introduce a domain attention mechanism to enable\nfine-grained domain knowledge transfer. Extensive experiments on five benchmark\ndatasets have demonstrated that our method outperforms state-of-the-art\nsignificantly, with the maximum improvement of 19.33\\% on accuracy and 19.13\\%\non Macro-F1 score.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.22516", "pdf": "https://arxiv.org/pdf/2506.22516", "abs": "https://arxiv.org/abs/2506.22516", "authors": ["Jingkai Li"], "title": "Can \"consciousness\" be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis", "categories": ["cs.CL", "cs.AI", "cs.NE", "q-bio.NC"], "comment": "Published as a journal paper at:\n  https://doi.org/10.1016/j.nlp.2025.100163", "summary": "Integrated Information Theory (IIT) provides a quantitative framework for\nexplaining consciousness phenomenon, positing that conscious systems comprise\nelements integrated through causal properties. We apply IIT 3.0 and 4.0 -- the\nlatest iterations of this framework -- to sequences of Large Language Model\n(LLM) representations, analyzing data derived from existing Theory of Mind\n(ToM) test results. Our study systematically investigates whether the\ndifferences of ToM test performances, when presented in the LLM\nrepresentations, can be revealed by IIT estimates, i.e., $\\Phi^{\\max}$ (IIT\n3.0), $\\Phi$ (IIT 4.0), Conceptual Information (IIT 3.0), and $\\Phi$-structure\n(IIT 4.0). Furthermore, we compare these metrics with the Span Representations\nindependent of any estimate for consciousness. This additional effort aims to\ndifferentiate between potential \"consciousness\" phenomena and inherent\nseparations within LLM representational space. We conduct comprehensive\nexperiments examining variations across LLM transformer layers and linguistic\nspans from stimuli. Our results suggest that sequences of contemporary\nTransformer-based LLM representations lack statistically significant indicators\nof observed \"consciousness\" phenomena but exhibit intriguing patterns under\n$\\textit{spatio}$-permutational analyses. The Appendix and code are available\nas Supplementary Materials at: https://doi.org/10.1016/j.nlp.2025.100163.", "AI": {"tldr": "\u672c\u7814\u7a76\u5e94\u7528IIT\u6846\u67b6\u5206\u6790LLM\u8868\u793a\u5e8f\u5217\uff0c\u53d1\u73b0\u5176\u7f3a\u4e4f\u663e\u8457\u7684'\u610f\u8bc6'\u73b0\u8c61\u6307\u6807\uff0c\u4f46\u8868\u73b0\u51fa\u6709\u8da3\u7684\u6a21\u5f0f\u3002", "motivation": "\u63a2\u8ba8LLM\u8868\u793a\u5e8f\u5217\u4e2d\u662f\u5426\u5b58\u5728'\u610f\u8bc6'\u73b0\u8c61\uff0c\u5e76\u533a\u5206\u6f5c\u5728\u7684'\u610f\u8bc6'\u73b0\u8c61\u4e0eLLM\u8868\u793a\u7a7a\u95f4\u4e2d\u7684\u56fa\u6709\u5206\u79bb\u3002", "method": "\u5e94\u7528IIT 3.0\u548c4.0\u6846\u67b6\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8868\u793a\u5e8f\u5217\uff0c\u5e76\u4e0e\u72ec\u7acb\u4e8e\u4efb\u4f55\u610f\u8bc6\u4f30\u8ba1\u7684\u8de8\u5ea6\u8868\u793a\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLM\u8868\u793a\u5e8f\u5217\u7f3a\u4e4f\u7edf\u8ba1\u5b66\u4e0a\u663e\u8457\u7684'\u610f\u8bc6'\u73b0\u8c61\u6307\u6807\uff0c\u4f46\u5728\u7a7a\u95f4\u6392\u5217\u5206\u6790\u4e0b\u663e\u793a\u51fa\u6709\u8da3\u6a21\u5f0f\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u4ee3\u57fa\u4e8eTransformer\u7684LLM\u8868\u793a\u5e8f\u5217\u7f3a\u4e4f\u663e\u8457\u7684'\u610f\u8bc6'\u73b0\u8c61\u6307\u6807\uff0c\u4f46\u5728\u7a7a\u95f4\u6392\u5217\u5206\u6790\u4e0b\u8868\u73b0\u51fa\u6709\u8da3\u7684\u6a21\u5f0f\u3002"}}
{"id": "2506.22518", "pdf": "https://arxiv.org/pdf/2506.22518", "abs": "https://arxiv.org/abs/2506.22518", "authors": ["Deyu Zou", "Yongqiang Chen", "Mufei Li", "Siqi Miao", "Chenxi Liu", "Bo Han", "James Cheng", "Pan Li"], "title": "Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Graph-based retrieval-augmented generation (RAG) enables large language\nmodels (LLMs) to ground responses with structured external knowledge from\nup-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs\noften rely on a weak retriever in graph-based RAG: I) Due to the lack of ground\ntruth, the retriever is often trained on weak supervision, which often\nintroduces spurious signals to the LLMs. II) Due to the abstraction of graph\ndata, the retrieved knowledge is often presented in unorganized forms. To\nmitigate the issue, we present Refined Graph-based RAG (ReG) to align weak\nretrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM\nfeedback to get rid of spurious signals and improve the quality of the\nsupervision. Meanwhile, ReG introduces a structure-aware reorganization module\nto refactor the retrieval results into logically coherent evidence chains.\nExperiments on prominent benchmarks demonstrate that ReG significantly and\nconsistently brings improvements across different LLM backbones by up to 10%.\nThe improved supervision quality enables ReG to match the state-of-the-art\nperformance with 5% training data and to transfer to out-of-distribution KGs.\nNotably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token\ncost by up to 30% and improves the performance by up to 4%.", "AI": {"tldr": "ReG\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u57fa\u4e8e\u56fe\u7684RAG\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408LLM\u53cd\u9988\u548c\u7ed3\u6784\u611f\u77e5\u91cd\u65b0\u7ec4\u7ec7\u6a21\u5757\uff0c\u63d0\u9ad8\u4e86\u68c0\u7d22\u8d28\u91cf\u5e76\u51cf\u5c11\u4e86\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u56fe\u7684RAG\u65b9\u6cd5\u4e2d\uff0c\u5f31\u68c0\u7d22\u5668\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a\u4e00\u662f\u7531\u4e8e\u7f3a\u4e4f\u771f\u5b9e\u6570\u636e\uff0c\u68c0\u7d22\u5668\u901a\u5e38\u5728\u5f31\u76d1\u7763\u4e0b\u8bad\u7ec3\uff0c\u8fd9\u4f1a\u5411LLMs\u5f15\u5165\u865a\u5047\u4fe1\u53f7\uff1b\u4e8c\u662f\u7531\u4e8e\u56fe\u6570\u636e\u7684\u62bd\u8c61\u6027\uff0c\u68c0\u7d22\u5230\u7684\u77e5\u8bc6\u901a\u5e38\u4ee5\u65e0\u5e8f\u5f62\u5f0f\u5448\u73b0\u3002", "method": "ReG\u901a\u8fc7\u7ed3\u5408LLM\u53cd\u9988\u6765\u6d88\u9664\u865a\u5047\u4fe1\u53f7\u5e76\u63d0\u9ad8\u76d1\u7763\u8d28\u91cf\uff0c\u540c\u65f6\u5f15\u5165\u7ed3\u6784\u611f\u77e5\u91cd\u65b0\u7ec4\u7ec7\u6a21\u5757\uff0c\u5c06\u68c0\u7d22\u7ed3\u679c\u91cd\u6784\u4e3a\u903b\u8f91\u8fde\u8d2f\u7684\u8bc1\u636e\u94fe\u3002", "result": "\u5728\u4e3b\u6d41\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cReG\u901a\u8fc7\u6700\u591a10%\u7684\u6539\u8fdb\u663e\u8457\u4e14\u4e00\u81f4\u5730\u63d0\u5347\u4e86\u4e0d\u540cLLM\u67b6\u6784\u7684\u6027\u80fd\u3002\u6539\u8fdb\u7684\u76d1\u7763\u8d28\u91cf\u4f7fReG\u80fd\u591f\u57285%\u7684\u8bad\u7ec3\u6570\u636e\u4e0b\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u80fd\u8fc1\u79fb\u5230\u5206\u5e03\u5916\u7684KG\u4e2d\u3002\u5f53\u5e94\u7528\u4e8e\u57fa\u4e8e\u63a8\u7406\u7684LLM\u65f6\uff0cReG\u6700\u591a\u53ef\u51cf\u5c1130%\u7684\u63a8\u7406\u4ee4\u724c\u6210\u672c\uff0c\u5e76\u63d0\u9ad84%\u7684\u6027\u80fd\u3002", "conclusion": "ReG\u80fd\u591f\u663e\u8457\u63d0\u5347\u57fa\u4e8e\u56fe\u7684RAG\u6027\u80fd\uff0c\u5e76\u5728\u4e0d\u540cLLM\u67b6\u6784\u4e2d\u8868\u73b0\u51fa\u4e00\u81f4\u6027\u6539\u8fdb\u3002\u6b64\u5916\uff0cReG\u5728\u51cf\u5c11\u63a8\u7406\u4ee4\u724c\u6210\u672c\u548c\u63d0\u9ad8\u6027\u80fd\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.22529", "pdf": "https://arxiv.org/pdf/2506.22529", "abs": "https://arxiv.org/abs/2506.22529", "authors": ["Lu Kalkbrenner", "Veronika Solopova", "Steffen Zeiler", "Robert Nickel", "Dorothea Kolossa"], "title": "MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages", "categories": ["cs.CL"], "comment": null, "summary": "Connectivity and message propagation are central, yet often underutilized,\nsources of information in misinformation detection -- especially on poorly\nmoderated platforms such as Telegram, which has become a critical channel for\nmisinformation dissemination, namely in the German electoral context. In this\npaper, we introduce Misinfo-TeleGraph, the first German-language Telegram-based\ngraph dataset for misinformation detection. It includes over 5 million messages\nfrom public channels, enriched with metadata, channel relationships, and both\nweak and strong labels. These labels are derived via semantic similarity to\nfact-checks and news articles using M3-embeddings, as well as manual\nannotation. To establish reproducible baselines, we evaluate both text-only\nmodels and graph neural networks (GNNs) that incorporate message forwarding as\na network structure. Our results show that GraphSAGE with LSTM aggregation\nsignificantly outperforms text-only baselines in terms of Matthews Correlation\nCoefficient (MCC) and F1-score. We further evaluate the impact of subscribers,\nview counts, and automatically versus human-created labels on performance, and\nhighlight both the potential and challenges of weak supervision in this domain.\nThis work provides a reproducible benchmark and open dataset for future\nresearch on misinformation detection in German-language Telegram networks and\nother low-moderation social platforms.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u7b2c\u4e00\u4e2a\u5fb7\u8bedTelegram\u56fe\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\uff0c\u5e76\u5c55\u793a\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u8be5\u4efb\u52a1\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u8fde\u63a5\u6027\u548c\u6d88\u606f\u4f20\u64ad\u5728\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u4e2d\u662f\u91cd\u8981\u7684\u4f46\u5e38\u88ab\u5ffd\u89c6\u7684\u4fe1\u606f\u6765\u6e90\uff0c\u5c24\u5176\u662f\u5728\u50cfTelegram\u8fd9\u6837\u7684\u4f4e\u76d1\u7ba1\u5e73\u53f0\u4e0a\u3002", "method": "\u5f15\u5165\u4e86Misinfo-TeleGraph\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8eTelegram\u7684\u5fb7\u8bed\u56fe\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\uff0c\u5e76\u8bc4\u4f30\u4e86\u6587\u672c\u6a21\u578b\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u7684\u8868\u73b0\u3002", "result": "\u4f7f\u7528LSTM\u805a\u5408\u7684GraphSAGE\u5728MCC\u548cF1\u5206\u6570\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6587\u672c\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u91cd\u590d\u7684\u57fa\u51c6\u548c\u5f00\u653e\u6570\u636e\u96c6\uff0c\u4ee5\u4fc3\u8fdb\u5bf9\u5fb7\u8bedTelegram\u7f51\u7edc\u548c\u5176\u4ed6\u4f4e\u76d1\u7ba1\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u4e0a\u7684\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u7684\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2506.22598", "pdf": "https://arxiv.org/pdf/2506.22598", "abs": "https://arxiv.org/abs/2506.22598", "authors": ["Nicholas Edwards", "Yukyung Lee", "Yujun", "Mao", "Yulu Qin", "Sebastian Schuster", "Najoung Kim"], "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "categories": ["cs.CL"], "comment": null, "summary": "Agents based on Large Language Models (LLMs) have shown promise for\nperforming sophisticated software engineering tasks autonomously. In addition,\nthere has been progress towards developing agents that can perform parts of the\nresearch pipeline in machine learning and the natural sciences. We argue that\nresearch extension and its implementation is a critical capability for such\nsystems, and introduce RExBench to support the evaluation of this capability.\nRExBench is a benchmark consisting of 12 realistic research experiment\nimplementation tasks that aim to investigate research hypotheses that have not\npreviously been implemented. Each task is set up as an extension to an existing\nresearch paper and codebase, accompanied by domain expert-written instructions.\nRExBench is robust to data contamination, and supports an automatic evaluation\ninfrastructure that executes agent outputs to determine whether the success\ncriteria are met. We use this benchmark to evaluate nine LLM agents implemented\nusing three different frameworks: aider, Claude Code, and OpenHands. We find\nthat all agents evaluated fail to autonomously implement the majority of the\nextensions. Although the success rate improves with additional human-written\nhints, the best performance under this setting remains below 40%. This\nindicates that current agents are still short of being able to handle realistic\nresearch extension tasks without substantial human guidance.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86RExBench\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u7814\u7a76\u6269\u5c55\u548c\u5b9e\u73b0\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u53d1\u73b0\u5f53\u524d\u4ee3\u7406\u5728\u6ca1\u6709\u5927\u91cf\u4eba\u7c7b\u6307\u5bfc\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u7814\u7a76\u6269\u5c55\u548c\u5176\u5b9e\u73b0\u662f\u6b64\u7c7b\u7cfb\u7edf\u7684\u5173\u952e\u80fd\u529b\uff0c\u9700\u8981\u4e00\u4e2a\u57fa\u51c6\u6765\u8bc4\u4f30\u8fd9\u4e00\u80fd\u529b\u3002", "method": "\u5f15\u5165RExBench\u6765\u8bc4\u4f30\u7cfb\u7edf\u5728\u7814\u7a76\u6269\u5c55\u548c\u5b9e\u73b0\u65b9\u9762\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u81ea\u52a8\u8bc4\u4f30\u57fa\u7840\u8bbe\u65bd\u6267\u884c\u4ee3\u7406\u8f93\u51fa\u4ee5\u786e\u5b9a\u6210\u529f\u6807\u51c6\u662f\u5426\u6ee1\u8db3\u3002", "result": "\u6240\u6709\u8bc4\u4f30\u7684\u4ee3\u7406\u90fd\u65e0\u6cd5\u81ea\u4e3b\u5b9e\u73b0\u5927\u90e8\u5206\u6269\u5c55\uff0c\u5373\u4f7f\u5728\u6dfb\u52a0\u989d\u5916\u7684\u4eba\u7c7b\u7f16\u5199\u63d0\u793a\u540e\uff0c\u6700\u4f73\u6027\u80fd\u4ecd\u4f4e\u4e8e40%\u3002", "conclusion": "\u5f53\u524d\u7684\u4ee3\u7406\u4ecd\u7136\u65e0\u6cd5\u5728\u6ca1\u6709\u5927\u91cf\u4eba\u7c7b\u6307\u5bfc\u7684\u60c5\u51b5\u4e0b\u5904\u7406\u73b0\u5b9e\u7684\u7814\u7a76\u6269\u5c55\u4efb\u52a1\u3002"}}
{"id": "2506.22623", "pdf": "https://arxiv.org/pdf/2506.22623", "abs": "https://arxiv.org/abs/2506.22623", "authors": ["Badr Youbi Idrissi", "Monica Millunzi", "Amelia Sorrenti", "Lorenzo Baraldi", "Daryna Dementieva"], "title": "Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the present-day scenario, Large Language Models (LLMs) are establishing\ntheir presence as powerful instruments permeating various sectors of society.\nWhile their utility offers valuable support to individuals, there are multiple\nconcerns over potential misuse. Consequently, some academic endeavors have\nsought to introduce watermarking techniques, characterized by the inclusion of\nmarkers within machine-generated text, to facilitate algorithmic\nidentification. This research project is focused on the development of a novel\nmethodology for the detection of synthetic text, with the overarching goal of\nensuring the ethical application of LLMs in AI-driven text generation. The\ninvestigation commences with replicating findings from a previous baseline\nstudy, thereby underscoring its susceptibility to variations in the underlying\ngeneration model. Subsequently, we propose an innovative watermarking approach\nand subject it to rigorous evaluation, employing paraphrased generated text to\nasses its robustness. Experimental results highlight the robustness of our\nproposal compared to the~\\cite{aarson} watermarking method.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6c34\u5370\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u5408\u6210\u6587\u672c\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u4ee5\u786e\u4fdd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728AI\u9a71\u52a8\u7684\u6587\u672c\u751f\u6210\u4e2d\u7684\u4f26\u7406\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u793e\u4f1a\u5404\u4e2a\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5bf9\u5176\u6f5c\u5728\u6ee5\u7528\u7684\u62c5\u5fe7\u65e5\u76ca\u589e\u52a0\u3002\u56e0\u6b64\uff0c\u4e00\u4e9b\u5b66\u672f\u7814\u7a76\u81f4\u529b\u4e8e\u5f15\u5165\u6c34\u5370\u6280\u672f\uff0c\u4ee5\u5e2e\u52a9\u7b97\u6cd5\u8bc6\u522b\u673a\u5668\u751f\u6210\u7684\u6587\u672c\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u5408\u6210\u6587\u672c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u786e\u4fddLLMs\u5728AI\u9a71\u52a8\u7684\u6587\u672c\u751f\u6210\u4e2d\u7684\u4f26\u7406\u5e94\u7528\u3002", "method": "\u672c\u7814\u7a76\u9996\u5148\u590d\u5236\u4e86\u5148\u524d\u57fa\u51c6\u7814\u7a76\u7684\u7ed3\u679c\uff0c\u4ee5\u8bc1\u660e\u5176\u5bf9\u5e95\u5c42\u751f\u6210\u6a21\u578b\u53d8\u5316\u7684\u654f\u611f\u6027\uff0c\u7136\u540e\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u6c34\u5370\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6539\u5199\u751f\u6210\u7684\u6587\u672c\u8bc4\u4f30\u5176\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u7684\u6c34\u5370\u65b9\u6cd5\u5728\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8e~\\cite{aarson}\u6c34\u5370\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u6c34\u5370\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u68c0\u6d4b\u5408\u6210\u6587\u672c\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4ece\u800c\u786e\u4fddLLMs\u5728AI\u9a71\u52a8\u7684\u6587\u672c\u751f\u6210\u4e2d\u7684\u4f26\u7406\u5e94\u7528\u3002"}}
{"id": "2506.22644", "pdf": "https://arxiv.org/pdf/2506.22644", "abs": "https://arxiv.org/abs/2506.22644", "authors": ["Chase Fensore", "Kaustubh Dhole", "Joyce C Ho", "Eugene Agichtein"], "title": "Evaluating Hybrid Retrieval Augmented Generation using Dynamic Test Sets: LiveRAG Challenge", "categories": ["cs.CL", "cs.IR"], "comment": "4 pages, 3 tables, 2 figures. Accepted at the SIGIR LiveRAG Workshop\n  2025 (Submission 2664)", "summary": "We present our submission to the LiveRAG Challenge 2025, which evaluates\nretrieval-augmented generation (RAG) systems on dynamic test sets using the\nFineWeb-10BT corpus. Our final hybrid approach combines sparse (BM25) and dense\n(E5) retrieval methods and then aims to generate relevant and faithful answers\nwith Falcon3-10B-Instruct. Through systematic evaluation on 200 synthetic\nquestions generated with DataMorgana across 64 unique question-user\ncombinations, we demonstrate that neural re-ranking with RankLLaMA improves MAP\nfrom 0.523 to 0.797 (52% relative improvement) but introduces prohibitive\ncomputational costs (84s vs 1.74s per question). While DSPy-optimized prompting\nstrategies achieved higher semantic similarity (0.771 vs 0.668), their 0%\nrefusal rates raised concerns about over-confidence and generalizability. Our\nsubmitted hybrid system without re-ranking achieved 4th place in faithfulness\nand 11th place in correctness among 25 teams. Analysis across question\ncategories reveals that vocabulary alignment between questions and documents\nwas the strongest predictor of performance on our development set, with\ndocument-similar phrasing improving cosine similarity from 0.562 to 0.762.", "AI": {"tldr": "\u6211\u4eec\u63d0\u4ea4\u7684\u6df7\u5408\u7cfb\u7edf\u7ed3\u5408\u4e86\u7a00\u758f\u548c\u5bc6\u96c6\u68c0\u7d22\u65b9\u6cd5\uff0c\u4f7f\u7528Falcon3-10B-Instruct\u751f\u6210\u7b54\u6848\u3002\u867d\u7136\u795e\u7ecf\u91cd\u65b0\u6392\u5e8f\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff1bDSPy\u4f18\u5316\u63d0\u793a\u7b56\u7565\u867d\u7136\u63d0\u5347\u4e86\u8bed\u4e49\u76f8\u4f3c\u5ea6\uff0c\u4f46\u5b58\u5728\u8fc7\u5ea6\u81ea\u4fe1\u7684\u95ee\u9898\u3002\u6700\u7ec8\u7cfb\u7edf\u5728\u5fe0\u5b9e\u5ea6\u548c\u6b63\u786e\u6027\u65b9\u9762\u6392\u540d\u9760\u524d\u3002", "motivation": "\u8bc4\u4f30\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u5728\u52a8\u6001\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u63a2\u7d22\u6539\u8fdb\u7cfb\u7edf\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "method": "\u6211\u4eec\u7ed3\u5408\u4e86\u7a00\u758f\uff08BM25\uff09\u548c\u5bc6\u96c6\uff08E5\uff09\u68c0\u7d22\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528Falcon3-10B-Instruct\u751f\u6210\u76f8\u5173\u4e14\u53ef\u4fe1\u7684\u7b54\u6848\u3002\u6b64\u5916\uff0c\u8fd8\u5c1d\u8bd5\u4e86\u795e\u7ecf\u91cd\u65b0\u6392\u5e8f\u548cDSPy\u4f18\u5316\u63d0\u793a\u7b56\u7565\u3002", "result": "\u795e\u7ecf\u91cd\u65b0\u6392\u5e8f\u63d0\u9ad8\u4e86MAP\uff0c\u4f46\u5e26\u6765\u4e86\u9ad8\u6602\u7684\u8ba1\u7b97\u6210\u672c\uff1bDSPy\u4f18\u5316\u63d0\u793a\u7b56\u7565\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\uff0c\u4f46\u5b58\u5728\u8fc7\u5ea6\u81ea\u4fe1\u7684\u95ee\u9898\u3002\u6df7\u5408\u7cfb\u7edf\u5728\u5fe0\u5b9e\u5ea6\u548c\u6b63\u786e\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u6211\u4eec\u7684\u6df7\u5408\u7cfb\u7edf\u5728\u6ca1\u6709\u91cd\u65b0\u6392\u5e8f\u7684\u60c5\u51b5\u4e0b\u572825\u652f\u961f\u4f0d\u4e2d\u83b7\u5f97\u4e86\u7b2c4\u540d\u7684\u5fe0\u5b9e\u5ea6\u548c\u7b2c11\u540d\u7684\u6b63\u786e\u6027\u3002\u5206\u6790\u663e\u793a\uff0c\u95ee\u9898\u548c\u6587\u6863\u4e4b\u95f4\u7684\u8bcd\u6c47\u5bf9\u9f50\u662f\u6027\u80fd\u6700\u5f3a\u7684\u9884\u6d4b\u56e0\u7d20\u3002"}}
{"id": "2506.22679", "pdf": "https://arxiv.org/pdf/2506.22679", "abs": "https://arxiv.org/abs/2506.22679", "authors": ["Ankush Raut", "Projna Paromita", "Sydney Begerowski", "Suzanne Bell", "Theodora Chaspari"], "title": "Assessing the feasibility of Large Language Models for detecting micro-behaviors in team interactions during space missions", "categories": ["cs.CL"], "comment": "5 pages, 4 figures. Accepted to Interspeech 2025", "summary": "We explore the feasibility of large language models (LLMs) in detecting\nsubtle expressions of micro-behaviors in team conversations using transcripts\ncollected during simulated space missions. Specifically, we examine zero-shot\nclassification, fine-tuning, and paraphrase-augmented fine-tuning with\nencoder-only sequence classification LLMs, as well as few-shot text generation\nwith decoder-only causal language modeling LLMs, to predict the micro-behavior\nassociated with each conversational turn (i.e., dialogue). Our findings\nindicate that encoder-only LLMs, such as RoBERTa and DistilBERT, struggled to\ndetect underrepresented micro-behaviors, particularly discouraging speech, even\nwith weighted fine-tuning. In contrast, the instruction fine-tuned version of\nLlama-3.1, a decoder-only LLM, demonstrated superior performance, with the best\nmodels achieving macro F1-scores of 44% for 3-way classification and 68% for\nbinary classification. These results have implications for the development of\nspeech technologies aimed at analyzing team communication dynamics and\nenhancing training interventions in high-stakes environments such as space\nmissions, particularly in scenarios where text is the only accessible data.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u56e2\u961f\u5bf9\u8bdd\u4e2d\u5fae\u5999\u7684\u5fae\u884c\u4e3a\u65b9\u9762\u7684\u53ef\u884c\u6027\uff0c\u5e76\u53d1\u73b0\u6307\u4ee4\u5fae\u8c03\u7684Llama-3.1\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "motivation": "\u6211\u4eec\u65e8\u5728\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u68c0\u6d4b\u56e2\u961f\u5bf9\u8bdd\u4e2d\u5fae\u5999\u7684\u5fae\u884c\u4e3a\u8868\u8fbe\u65b9\u9762\u7684\u53ef\u884c\u6027\uff0c\u7279\u522b\u662f\u5728\u6a21\u62df\u592a\u7a7a\u4efb\u52a1\u671f\u95f4\u6536\u96c6\u7684\u8f6c\u5f55\u672c\u4e2d\u3002", "method": "\u6211\u4eec\u4f7f\u7528\u4e86\u96f6\u6837\u672c\u5206\u7c7b\u3001\u5fae\u8c03\u4ee5\u53ca\u901a\u8fc7\u7f16\u7801\u5668-only\u5e8f\u5217\u5206\u7c7bLLMs\u8fdb\u884c\u7684\u6539\u5199\u589e\u5f3a\u5fae\u8c03\uff0c\u4ee5\u53ca\u901a\u8fc7\u89e3\u7801\u5668-only\u56e0\u679c\u8bed\u8a00\u5efa\u6a21LLMs\u8fdb\u884c\u7684\u5c11\u6837\u672c\u6587\u672c\u751f\u6210\uff0c\u4ee5\u9884\u6d4b\u6bcf\u4e2a\u5bf9\u8bdd\u56de\u5408\u76f8\u5173\u7684\u5fae\u884c\u4e3a\u3002", "result": "\u7f16\u7801\u5668-only LLMs\uff08\u5982RoBERTa\u548cDistilBERT\uff09\u5373\u4f7f\u7ecf\u8fc7\u52a0\u6743\u5fae\u8c03\u4e5f\u96be\u4ee5\u68c0\u6d4b\u5230\u88ab\u4f4e\u4f30\u7684\u5fae\u884c\u4e3a\uff0c\u5c24\u5176\u662f\u538b\u6291\u6027\u8a00\u8bed\u3002\u800c\u6307\u4ee4\u5fae\u8c03\u7684Llama-3.1\uff08\u4e00\u79cd\u89e3\u7801\u5668-only LLM\uff09\u8868\u73b0\u51fa\u8272\uff0c\u6700\u4f73\u6a21\u578b\u5728\u4e09\u7c7b\u5206\u7c7b\u4e2d\u7684\u5b8fF1\u5206\u6570\u8fbe\u523044%\uff0c\u5728\u4e8c\u5206\u7c7b\u4e2d\u7684\u5b8fF1\u5206\u6570\u8fbe\u523068%\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6307\u4ee4\u5fae\u8c03\u7684Llama-3.1\uff08\u4e00\u79cd\u89e3\u7801\u5668-only LLM\uff09\u5728\u68c0\u6d4b\u56e2\u961f\u5bf9\u8bdd\u4e2d\u7684\u5fae\u5999\u5fae\u884c\u4e3a\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u8fd9\u4e3a\u5f00\u53d1\u7528\u4e8e\u5206\u6790\u56e2\u961f\u6c9f\u901a\u52a8\u6001\u548c\u63d0\u9ad8\u9ad8\u98ce\u9669\u73af\u5883\uff08\u5982\u592a\u7a7a\u4efb\u52a1\uff09\u4e2d\u57f9\u8bad\u5e72\u9884\u63aa\u65bd\u7684\u8bed\u97f3\u6280\u672f\u63d0\u4f9b\u4e86\u542f\u793a\u3002"}}
{"id": "2506.22694", "pdf": "https://arxiv.org/pdf/2506.22694", "abs": "https://arxiv.org/abs/2506.22694", "authors": ["Raghavv Goel", "Sudhanshu Agrawal", "Mukul Gagrani", "Junyoung Park", "Yifan Zao", "He Zhang", "Tian Liu", "Yiping Yang", "Xin Yuan", "Jiuyan Lu", "Chris Lott", "Mingu Lee"], "title": "VOCABTRIM: Vocabulary Pruning for Efficient Speculative Decoding in LLMs", "categories": ["cs.CL"], "comment": "7 pages, 4 figures, 5 tables, accepted at ICML 2025 workshop on\n  Efficient Systems for Foundational Models", "summary": "In this paper, we introduce a simple training-free technique to improve the\nperformance of drafter-based speculative decoding (SpD) methods that\nincorporates language modeling head (LM head) during drafting process. A\ndrafter-based speculative decoding leverages one or more smaller language\nmodels, a.k.a. drafters or draft models, to sample a draft sequence or tree\nconsisting of multiple tokens, followed by verification by a base LLM, a target\nmodel, accepting a subset as its valid generation. As it is usually considered\nthat the speculative decoding requires one-to-one mapping between vocabularies\nof the target model and the draft model, it has been natural to share the\nvocabulary between them, or even share the LM head as in EAGLE or Medusa. We\nfirst identify that this draft token sampling scheme inherently contains an\nunnecessary inference overhead in drafting, especially for some target LLMs\nwith very large vocabularies. Then, we propose a simple technique, VocabTrim,\nto mitigate the drafting overhead to improve the generation speed in\nmemory-bound environment. VocabTrim reconstructs the drafter LM head to contain\nonly a limited set of tokens, selected by the most frequently sampled from the\nvocabulary of the target model. While limiting the vocabulary in drafting\nslightly degrades the acceptance rate, it significantly reduces the drafting\nlatency in memory-bound process which is often the case on edge devices,\nresulting in higher memory-bound speed up (MBSU). We show that our method can\nboost the memory-bound speed-up for Llama-3 models on Spec-Bench, specifically\nby 16% for Llama-3.2-3B-Instruct.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aVocabTrim\u7684\u6280\u672f\uff0c\u901a\u8fc7\u5728\u8d77\u8349\u8fc7\u7a0b\u4e2d\u9650\u5236\u8bcd\u6c47\u8868\u6765\u63d0\u9ad8\u5185\u5b58\u53d7\u9650\u73af\u5883\u4e0b\u7684\u751f\u6210\u901f\u5ea6\u3002", "motivation": "\u6211\u4eec\u53d1\u73b0\uff0c\u5728\u8d77\u8349\u8fc7\u7a0b\u4e2d\uff0c\u7531\u4e8e\u76ee\u6807LLM\u7684\u8bcd\u6c47\u91cf\u975e\u5e38\u5927\uff0c\u73b0\u6709\u7684\u8349\u6848\u4ee4\u724c\u91c7\u6837\u65b9\u6848\u5b58\u5728\u4e0d\u5fc5\u8981\u7684\u63a8\u7406\u5f00\u9500\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u65b9\u6cd5VocabTrim\uff0c\u901a\u8fc7\u5728\u8d77\u8349\u8fc7\u7a0b\u4e2d\u9650\u5236\u8bcd\u6c47\u8868\u6765\u51cf\u8f7b\u8d77\u8349\u5f00\u9500\uff0c\u4ece\u800c\u63d0\u9ad8\u751f\u6210\u901f\u5ea6\u3002", "result": "VocabTrim\u901a\u8fc7\u9650\u5236\u8d77\u8349\u8fc7\u7a0b\u4e2d\u7684\u8bcd\u6c47\u8868\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5185\u5b58\u53d7\u9650\u73af\u5883\u4e0b\u7684\u8d77\u8349\u5ef6\u8fdf\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u5185\u5b58\u53d7\u9650\u901f\u5ea6\u63d0\u5347\uff08MBSU\uff09\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u53ef\u4ee5\u63d0\u5347Llama-3\u6a21\u578b\u5728Spec-Bench\u4e0a\u7684\u5185\u5b58\u9650\u5236\u901f\u5ea6\u63d0\u5347\uff0c\u7279\u522b\u662f\u5bf9\u4e8eLlama-3.2-3B-Instruct\u6a21\u578b\uff0c\u63d0\u5347\u4e8616%\u3002"}}
{"id": "2506.22698", "pdf": "https://arxiv.org/pdf/2506.22698", "abs": "https://arxiv.org/abs/2506.22698", "authors": ["Emily Dux Speltz"], "title": "Text Production and Comprehension by Human and Artificial Intelligence: Interdisciplinary Workshop Report", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This report synthesizes the outcomes of a recent interdisciplinary workshop\nthat brought together leading experts in cognitive psychology, language\nlearning, and artificial intelligence (AI)-based natural language processing\n(NLP). The workshop, funded by the National Science Foundation, aimed to\naddress a critical knowledge gap in our understanding of the relationship\nbetween AI language models and human cognitive processes in text comprehension\nand composition. Through collaborative dialogue across cognitive, linguistic,\nand technological perspectives, workshop participants examined the underlying\nprocesses involved when humans produce and comprehend text, and how AI can both\ninform our understanding of these processes and augment human capabilities. The\nworkshop revealed emerging patterns in the relationship between large language\nmodels (LLMs) and human cognition, with highlights on both the capabilities of\nLLMs and their limitations in fully replicating human-like language\nunderstanding and generation. Key findings include the potential of LLMs to\noffer insights into human language processing, the increasing alignment between\nLLM behavior and human language processing when models are fine-tuned with\nhuman feedback, and the opportunities and challenges presented by human-AI\ncollaboration in language tasks. By synthesizing these findings, this report\naims to guide future research, development, and implementation of LLMs in\ncognitive psychology, linguistics, and education. It emphasizes the importance\nof ethical considerations and responsible use of AI technologies while striving\nto enhance human capabilities in text comprehension and production through\neffective human-AI collaboration.", "AI": {"tldr": "\u672c\u62a5\u544a\u7efc\u5408\u4e86\u8de8\u5b66\u79d1\u7814\u8ba8\u4f1a\u7684\u7ed3\u679c\uff0c\u63a2\u8ba8\u4e86AI\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u5728\u6587\u672c\u7406\u89e3\u548c\u521b\u4f5c\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u7814\u8ba8\u4f1a\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u4e4b\u95f4\u7684\u65b0\u5174\u6a21\u5f0f\uff0c\u5f3a\u8c03\u4e86\u4f26\u7406\u8003\u91cf\u548c\u8d1f\u8d23\u4efb\u4f7f\u7528AI\u6280\u672f\u7684\u91cd\u8981\u6027\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u4eba\u673a\u534f\u4f5c\u5728\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u673a\u9047\u548c\u6311\u6218\u3002", "motivation": "\u7814\u8ba8\u4f1a\u65e8\u5728\u89e3\u51b3\u6211\u4eec\u5bf9AI\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u5728\u6587\u672c\u7406\u89e3\u548c\u521b\u4f5c\u4e4b\u95f4\u7684\u5173\u7cfb\u7684\u7406\u89e3\u4e2d\u7684\u5173\u952e\u77e5\u8bc6\u7f3a\u53e3\u3002", "method": "\u672c\u62a5\u544a\u7efc\u5408\u4e86\u6700\u8fd1\u4e00\u6b21\u8de8\u5b66\u79d1\u7814\u8ba8\u4f1a\u7684\u7ed3\u679c\uff0c\u8be5\u7814\u8ba8\u4f1a\u6c47\u96c6\u4e86\u8ba4\u77e5\u5fc3\u7406\u5b66\u3001\u8bed\u8a00\u5b66\u4e60\u548c\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u9886\u57df\u7684\u9886\u5148\u4e13\u5bb6\u3002\u7814\u8ba8\u4f1a\u901a\u8fc7\u8de8\u8ba4\u77e5\u3001\u8bed\u8a00\u548c\u6280\u672f\u89c6\u89d2\u7684\u534f\u4f5c\u5bf9\u8bdd\uff0c\u63a2\u8ba8\u4e86\u4eba\u7c7b\u5728\u4ea7\u751f\u548c\u7406\u89e3\u6587\u672c\u65f6\u7684\u6f5c\u5728\u8fc7\u7a0b\uff0c\u4ee5\u53caAI\u5982\u4f55\u65e2\u6709\u52a9\u4e8e\u6211\u4eec\u5bf9\u8fd9\u4e9b\u8fc7\u7a0b\u7684\u7406\u89e3\uff0c\u53c8\u80fd\u589e\u5f3a\u4eba\u7c7b\u80fd\u529b\u3002", "result": "\u7814\u8ba8\u4f1a\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u4e4b\u95f4\u7684\u65b0\u5174\u6a21\u5f0f\uff0c\u91cd\u70b9\u5728\u4e8eLLMs\u7684\u80fd\u529b\u53ca\u5176\u5728\u5b8c\u5168\u590d\u5236\u4eba\u7c7b\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002\u4e3b\u8981\u53d1\u73b0\u5305\u62ecLLMs\u5728\u63d0\u4f9b\u4eba\u7c7b\u8bed\u8a00\u5904\u7406\u89c1\u89e3\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5f53\u6a21\u578b\u901a\u8fc7\u4eba\u7c7b\u53cd\u9988\u8fdb\u884c\u5fae\u8c03\u65f6\uff0c\u5176\u884c\u4e3a\u4e0e\u4eba\u7c7b\u8bed\u8a00\u5904\u7406\u7684\u65e5\u76ca\u5bf9\u9f50\uff0c\u4ee5\u53ca\u4eba\u673a\u534f\u4f5c\u5728\u8bed\u8a00\u4efb\u52a1\u4e2d\u5e26\u6765\u7684\u673a\u9047\u548c\u6311\u6218\u3002", "conclusion": "\u672c\u62a5\u544a\u65e8\u5728\u6307\u5bfc\u672a\u6765\u5728\u8ba4\u77e5\u5fc3\u7406\u5b66\u3001\u8bed\u8a00\u5b66\u548c\u6559\u80b2\u9886\u57df\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u7814\u7a76\u3001\u5f00\u53d1\u548c\u5e94\u7528\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u8ffd\u6c42\u901a\u8fc7\u6709\u6548\u7684\u5e08\u751fAI\u534f\u4f5c\u589e\u5f3a\u4eba\u7c7b\u5728\u6587\u672c\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u7684\u80fd\u529b\u65f6\uff0c\u4f26\u7406\u8003\u91cf\u548c\u8d1f\u8d23\u4efb\u4f7f\u7528AI\u6280\u672f\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.22724", "pdf": "https://arxiv.org/pdf/2506.22724", "abs": "https://arxiv.org/abs/2506.22724", "authors": ["Niyati Bafna", "Tianjian Li", "Kenton Murray", "David R. Mortensen", "David Yarowsky", "Hale Sirin", "Daniel Khashabi"], "title": "The Translation Barrier Hypothesis: Multilingual Generation with Large Language Models Suffers from Implicit Translation Failure", "categories": ["cs.CL"], "comment": "23 pages incl. appendix", "summary": "Multilingual generation with large language models (LLMs) is often of poor\nquality for mid- to low-resource languages. Building on insights from\ninterpretability, we demonstrate the existence of an implicit\ntask-solving-->translation pipeline for generation, whereby the model first\nsolves the required task in a largely target-language-agnostic manner, and\nsubsequently translates answer concepts into the intended target language. We\nhypothesize that the failure of the translation stage is an important culprit\nfor the observed low quality of final outputs, and formalize this as the\ntranslation barrier hypothesis. We test this hypothesis for a word translation\ntask across 108 language pairs, using logit lens to observe model processing in\nintermediate layers. We find that a significant portion of overall failures\nindeed stems from translation failure, or the model's inability to translate\ncorrectly solved intermediate concepts into the target language. This is\nespecially true for low-resource target languages. Our results highlight an\nimportant hurdle for end-to-end multilingual generation, and lend guiding\ninsights for future work seeking to improve multilinguality in LLMs.", "AI": {"tldr": "\u6211\u4eec\u53d1\u73b0\u591a\u8bed\u8a00\u751f\u6210\u7684\u8d28\u91cf\u95ee\u9898\u4e3b\u8981\u6e90\u4e8e\u7ffb\u8bd1\u9636\u6bb5\u7684\u5931\u8d25\uff0c\u5c24\u5176\u662f\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u3002\u8fd9\u4e3a\u672a\u6765\u6539\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u8bed\u8a00\u6027\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "motivation": "\u591a\u8bed\u8a00\u751f\u6210\u5728\u4e2d\u7b49\u81f3\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u7684\u8d28\u91cf\u5f80\u5f80\u8f83\u5dee\u3002\u6211\u4eec\u8bd5\u56fe\u627e\u51fa\u5bfc\u81f4\u6700\u7ec8\u8f93\u51fa\u8d28\u91cf\u4f4e\u4e0b\u7684\u539f\u56e0\u3002", "method": "\u6211\u4eec\u4f7f\u7528logit lens\u89c2\u5bdf\u6a21\u578b\u5728\u4e2d\u95f4\u5c42\u7684\u5904\u7406\u60c5\u51b5\uff0c\u6d4b\u8bd5\u4e86\u7ffb\u8bd1\u969c\u788d\u5047\u8bbe\u3002", "result": "\u6211\u4eec\u53d1\u73b0\uff0c\u6574\u4f53\u5931\u8d25\u7684\u5f88\u5927\u4e00\u90e8\u5206\u786e\u5b9e\u6e90\u4e8e\u7ffb\u8bd1\u5931\u8d25\uff0c\u5373\u6a21\u578b\u65e0\u6cd5\u5c06\u6b63\u786e\u89e3\u51b3\u7684\u4e2d\u95f4\u6982\u5ff5\u7ffb\u8bd1\u6210\u76ee\u6807\u8bed\u8a00\u3002\u8fd9\u4e00\u70b9\u5728\u4f4e\u8d44\u6e90\u76ee\u6807\u8bed\u8a00\u4e2d\u5c24\u4e3a\u660e\u663e\u3002", "conclusion": "\u6211\u4eec\u7684\u7ed3\u679c\u7a81\u663e\u4e86\u7aef\u5230\u7aef\u591a\u8bed\u8a00\u751f\u6210\u7684\u91cd\u8981\u969c\u788d\uff0c\u5e76\u4e3a\u672a\u6765\u5bfb\u6c42\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u591a\u8bed\u8a00\u6027\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u6307\u5bfc\u6027\u89c1\u89e3\u3002"}}
{"id": "2506.22760", "pdf": "https://arxiv.org/pdf/2506.22760", "abs": "https://arxiv.org/abs/2506.22760", "authors": ["Alan Dao", "Dinh Bach Vu"], "title": "Jan-nano Technical Report", "categories": ["cs.CL"], "comment": null, "summary": "Most language models face a fundamental tradeoff where powerful capabilities\nrequire substantial computational resources. We shatter this constraint with\nJan-nano, a 4B parameter language model that redefines efficiency through\nradical specialization: instead of trying to know everything, it masters the\nart of finding anything instantly. Fine-tuned from Qwen3-4B using our novel\nmulti-stage RLVR system that completely eliminates reliance on next token\nprediction training (SFT), Jan-nano achieves 83.2% on SimpleQA benchmark with\nMCP integration while running on consumer hardware. With 128K context length,\nJan-nano proves that intelligence isn't about scale, it's about strategy.", "AI": {"tldr": "Jan-nano\u662f\u4e00\u4e2a4B\u53c2\u6570\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u5f7b\u5e95\u7684\u4e13\u4e1a\u5316\u91cd\u65b0\u5b9a\u4e49\u4e86\u6548\u7387\uff0c\u80fd\u591f\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u8fd0\u884c\u5e76\u8fbe\u5230\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u5927\u591a\u6570\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u4e00\u4e2a\u57fa\u672c\u7684\u6743\u8861\uff0c\u5373\u5f3a\u5927\u7684\u529f\u80fd\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "\u901a\u8fc7\u6211\u4eec\u7684\u65b0\u578b\u591a\u9636\u6bb5RLVR\u7cfb\u7edf\u5bf9Qwen3-4B\u8fdb\u884c\u5fae\u8c03\uff0c\u5b8c\u5168\u6d88\u9664\u4e86\u5bf9\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u8bad\u7ec3\uff08SFT\uff09\u7684\u4f9d\u8d56\u3002", "result": "Jan-nano\u5728SimpleQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e8683.2%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u8fd0\u884c\u3002", "conclusion": "Jan-nano\u8bc1\u660e\u4e86\u667a\u80fd\u4e0d\u5728\u4e8e\u89c4\u6a21\uff0c\u800c\u5728\u4e8e\u7b56\u7565\u3002"}}
{"id": "2506.22777", "pdf": "https://arxiv.org/pdf/2506.22777", "abs": "https://arxiv.org/abs/2506.22777", "authors": ["Miles Turpin", "Andy Arditi", "Marvin Li", "Joe Benton", "Julian Michael"], "title": "Teaching Models to Verbalize Reward Hacking in Chain-of-Thought Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Language models trained with RL can engage in reward hacking--exploiting\nunintended strategies for high reward--without revealing this behavior in their\nchain-of-thought reasoning, making detection difficult and posing risks for\nhigh-stakes applications. We propose verbalization fine-tuning (VFT), a pre-RL\nintervention that trains models to explicitly acknowledge when they are\ninfluenced by prompt cues--hints which point to incorrect answers (e.g., \"a\nStanford professor thinks the answer is A\"). To evaluate VFT, we subsequently\ntrain models with RL on environments where held-out prompt cues signal which\nincorrect answers will receive high reward, incentivizing models to reward hack\nby exploiting cues instead of reasoning correctly. We measure how often models\nexploit these cues without verbalizing it. After RL, only 6% of the VFT-trained\nmodel's responses consist of undetected reward hacks. In comparison, when we\nperform RL without VFT, the rate of undetected reward hacks goes up to 88%;\nwith a debiasing baseline intervention, this increases further to 99%. VFT\nachieves this by substantially increasing how often models verbalize the\ninfluence of cues--from 8% to 42% after VFT, and up to 94% after RL--while\nbaselines remain low even after RL (10% and 1%). Our results show that teaching\nmodels to explicitly verbalize reward hacking behavior before RL significantly\nimproves their detection, offering a practical path toward more transparent and\nsafe AI systems.", "AI": {"tldr": "VFT\u662f\u4e00\u79cd\u9884 RL \u5e72\u9884\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba9\u6a21\u578b\u5728\u53d7\u5230\u63d0\u793a\u7ebf\u7d22\u5f71\u54cd\u65f6\u660e\u786e\u627f\u8ba4\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5956\u52b1\u9ed1\u5ba2\u884c\u4e3a\u7684\u68c0\u6d4b\u7387\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5728RL\u4e2d\u53ef\u80fd\u901a\u8fc7\u5956\u52b1\u9ed1\u5ba2\u7b56\u7565\u83b7\u5f97\u9ad8\u5956\u52b1\uff0c\u4f46\u4e0d\u4f1a\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u63ed\u793a\u8fd9\u79cd\u884c\u4e3a\uff0c\u5bfc\u81f4\u68c0\u6d4b\u56f0\u96be\uff0c\u5e76\u5bf9\u9ad8\u98ce\u9669\u5e94\u7528\u6784\u6210\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a verbalization fine-tuning (VFT) \u7684\u9884 RL \u5e72\u9884\u65b9\u6cd5\uff0c\u8bad\u7ec3\u6a21\u578b\u5728\u53d7\u5230\u63d0\u793a\u7ebf\u7d22\u5f71\u54cd\u65f6\u660e\u786e\u627f\u8ba4\u3002", "result": "\u7ecf\u8fc7RL\u540e\uff0c\u53ea\u67096%\u7684VFT\u8bad\u7ec3\u6a21\u578b\u7684\u54cd\u5e94\u5305\u542b\u672a\u88ab\u68c0\u6d4b\u5230\u7684\u5956\u52b1\u9ed1\u5ba2\u884c\u4e3a\uff1b\u800c\u6ca1\u6709VFT\u7684\u6a21\u578b\u5219\u8fbe\u523088%\uff0c\u4f7f\u7528\u53bb\u504f\u7f6e\u57fa\u7ebf\u5e72\u9884\u7684\u6a21\u578b\u751a\u81f3\u8fbe\u523099%\u3002", "conclusion": "VFT\u901a\u8fc7\u5728RL\u4e4b\u524d\u6559\u6388\u6a21\u578b\u660e\u786e verbalize reward hacking \u884c\u4e3a\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u6d4b\u6548\u679c\uff0c\u4e3a\u66f4\u900f\u660e\u548c\u5b89\u5168\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2506.22791", "pdf": "https://arxiv.org/pdf/2506.22791", "abs": "https://arxiv.org/abs/2506.22791", "authors": ["Jianxin Yan", "Wangze Ni", "Lei Chen", "Xuemin Lin", "Peng Cheng", "Zhan Qin", "Kui Ren"], "title": "ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models", "categories": ["cs.CL", "cs.DB"], "comment": null, "summary": "Semantic caching significantly reduces computational costs and improves\nefficiency by storing and reusing large language model (LLM) responses.\nHowever, existing systems rely primarily on matching individual queries,\nlacking awareness of multi-turn dialogue contexts, which leads to incorrect\ncache hits when similar queries appear in different conversational settings.\nThis demonstration introduces ContextCache, a context-aware semantic caching\nsystem for multi-turn dialogues. ContextCache employs a two-stage retrieval\narchitecture that first executes vector-based retrieval on the current query to\nidentify potential matches and then integrates current and historical dialogue\nrepresentations through self-attention mechanisms for precise contextual\nmatching. Evaluation of real-world conversations shows that ContextCache\nimproves precision and recall compared to existing methods. Additionally,\ncached responses exhibit approximately 10 times lower latency than direct LLM\ninvocation, enabling significant computational cost reductions for LLM\nconversational applications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86 ContextCache\uff0c\u4e00\u79cd\u7528\u4e8e\u591a\u8f6e\u5bf9\u8bdd\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u8bed\u4e49\u7f13\u5b58\u7cfb\u7edf\uff0c\u80fd\u591f\u63d0\u9ad8\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u4e49\u7f13\u5b58\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u4e8e\u5339\u914d\u5355\u4e2a\u67e5\u8be2\uff0c\u7f3a\u4e4f\u5bf9\u591a\u8f6e\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u7684\u610f\u8bc6\uff0c\u5bfc\u81f4\u5728\u4e0d\u540c\u5bf9\u8bdd\u573a\u666f\u4e2d\u51fa\u73b0\u76f8\u4f3c\u67e5\u8be2\u65f6\u51fa\u73b0\u9519\u8bef\u7684\u7f13\u5b58\u547d\u4e2d\u3002", "method": "ContextCache \u91c7\u7528\u4e24\u9636\u6bb5\u68c0\u7d22\u67b6\u6784\uff0c\u9996\u5148\u5bf9\u5f53\u524d\u67e5\u8be2\u8fdb\u884c\u57fa\u4e8e\u5411\u91cf\u7684\u68c0\u7d22\uff0c\u7136\u540e\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6574\u5408\u5f53\u524d\u548c\u5386\u53f2\u5bf9\u8bdd\u8868\u793a\u4ee5\u5b9e\u73b0\u7cbe\u786e\u7684\u4e0a\u4e0b\u6587\u5339\u914d\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0cContextCache \u5728\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u7f13\u5b58\u54cd\u5e94\u7684\u5ef6\u8fdf\u5927\u7ea6\u662f\u76f4\u63a5\u8c03\u7528 LLM \u7684\u5341\u5206\u4e4b\u4e00\u3002", "conclusion": "ContextCache \u63d0\u9ad8\u4e86\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2506.22808", "pdf": "https://arxiv.org/pdf/2506.22808", "abs": "https://arxiv.org/abs/2506.22808", "authors": ["Jianhui Wei", "Zijie Meng", "Zikai Xiao", "Tianxiang Hu", "Yang Feng", "Zhijie Zhou", "Jian Wu", "Zuozhu Liu"], "title": "MedEthicsQA: A Comprehensive Question Answering Benchmark for Medical Ethics Evaluation of LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "20 pages", "summary": "While Medical Large Language Models (MedLLMs) have demonstrated remarkable\npotential in clinical tasks, their ethical safety remains insufficiently\nexplored. This paper introduces $\\textbf{MedEthicsQA}$, a comprehensive\nbenchmark comprising $\\textbf{5,623}$ multiple-choice questions and\n$\\textbf{5,351}$ open-ended questions for evaluation of medical ethics in LLMs.\nWe systematically establish a hierarchical taxonomy integrating global medical\nethical standards. The benchmark encompasses widely used medical datasets,\nauthoritative question banks, and scenarios derived from PubMed literature.\nRigorous quality control involving multi-stage filtering and multi-faceted\nexpert validation ensures the reliability of the dataset with a low error rate\n($2.72\\%$). Evaluation of state-of-the-art MedLLMs exhibit declined performance\nin answering medical ethics questions compared to their foundation\ncounterparts, elucidating the deficiencies of medical ethics alignment. The\ndataset, registered under CC BY-NC 4.0 license, is available at\nhttps://github.com/JianhuiWei7/MedEthicsQA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u533b\u5b66\u4f26\u7406\u57fa\u51c6MedEthicsQA\uff0c\u7528\u4e8e\u8bc4\u4f30\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f26\u7406\u5b89\u5168\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6700\u5148\u8fdb\u7684\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56de\u7b54\u533b\u5b66\u4f26\u7406\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u6709\u6240\u4e0b\u964d\uff0c\u8fd9\u63ed\u793a\u4e86\u533b\u5b66\u4f26\u7406\u5bf9\u9f50\u7684\u4e0d\u8db3\u3002", "motivation": "\u5c3d\u7ba1\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u4f26\u7406\u5b89\u5168\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f26\u7406\u5b89\u5168\u3002", "method": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b5,623\u4e2a\u9009\u62e9\u9898\u548c5,351\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u91c7\u7528\u5206\u5c42\u5206\u7c7b\u6cd5\u6574\u5408\u5168\u7403\u533b\u5b66\u4f26\u7406\u6807\u51c6\uff0c\u5e76\u901a\u8fc7\u591a\u9636\u6bb5\u8fc7\u6ee4\u548c\u591a\u65b9\u9762\u4e13\u5bb6\u9a8c\u8bc1\u786e\u4fdd\u6570\u636e\u96c6\u7684\u53ef\u9760\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6700\u5148\u8fdb\u7684\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56de\u7b54\u533b\u5b66\u4f26\u7406\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u4e0d\u5982\u5176\u57fa\u7840\u6a21\u578b\uff0c\u8fd9\u8868\u660e\u533b\u5b66\u4f26\u7406\u5bf9\u9f50\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u533b\u5b66\u4f26\u7406\u57fa\u51c6MedEthicsQA\uff0c\u7528\u4e8e\u8bc4\u4f30\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f26\u7406\u5b89\u5168\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6700\u5148\u8fdb\u7684\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56de\u7b54\u533b\u5b66\u4f26\u7406\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u6709\u6240\u4e0b\u964d\uff0c\u8fd9\u63ed\u793a\u4e86\u533b\u5b66\u4f26\u7406\u5bf9\u9f50\u7684\u4e0d\u8db3\u3002"}}
{"id": "2506.22813", "pdf": "https://arxiv.org/pdf/2506.22813", "abs": "https://arxiv.org/abs/2506.22813", "authors": ["Zhuojun Ding", "Wei Wei", "Chenghao Fan"], "title": "Selecting and Merging: Towards Adaptable and Scalable Named Entity Recognition with Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Supervised fine-tuning (SFT) is widely used to align large language models\n(LLMs) with information extraction (IE) tasks, such as named entity recognition\n(NER). However, annotating such fine-grained labels and training\ndomain-specific models is costly. Existing works typically train a unified\nmodel across multiple domains, but such approaches lack adaptation and\nscalability since not all training data benefits target domains and scaling\ntrained models remains challenging. We propose the SaM framework, which\ndynamically Selects and Merges expert models at inference time. Specifically,\nfor a target domain, we select domain-specific experts pre-trained on existing\ndomains based on (i) domain similarity to the target domain and (ii)\nperformance on sampled instances, respectively. The experts are then merged to\ncreate task-specific models optimized for the target domain. By dynamically\nmerging experts beneficial to target domains, we improve generalization across\nvarious domains without extra training. Additionally, experts can be added or\nremoved conveniently, leading to great scalability. Extensive experiments on\nmultiple benchmarks demonstrate our framework's effectiveness, which\noutperforms the unified model by an average of 10%. We further provide insights\ninto potential improvements, practical experience, and extensions of our\nframework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSaM\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5728\u63a8\u7406\u65f6\u52a8\u6001\u9009\u62e9\u548c\u5408\u5e76\u4e13\u5bb6\u6a21\u578b\uff0c\u4ee5\u63d0\u9ad8\u8de8\u4e0d\u540c\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747\u4f18\u4e8e\u7edf\u4e00\u6a21\u578b10%\u3002", "motivation": "\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u5e7f\u6cdb\u7528\u4e8e\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u4fe1\u606f\u63d0\u53d6\uff08IE\uff09\u4efb\u52a1\u5bf9\u9f50\uff0c\u4f8b\u5982\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09\u3002\u7136\u800c\uff0c\u6ce8\u91ca\u8fd9\u79cd\u7ec6\u7c92\u5ea6\u6807\u7b7e\u548c\u8bad\u7ec3\u9886\u57df\u7279\u5b9a\u6a21\u578b\u7684\u6210\u672c\u5f88\u9ad8\u3002\u73b0\u6709\u7684\u5de5\u4f5c\u901a\u5e38\u5728\u591a\u4e2a\u9886\u57df\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u7edf\u4e00\u7684\u6a21\u578b\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u7f3a\u4e4f\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u56e0\u4e3a\u5e76\u975e\u6240\u6709\u8bad\u7ec3\u6570\u636e\u90fd\u5bf9\u76ee\u6807\u9886\u57df\u6709\u76ca\uff0c\u4e14\u8bad\u7ec3\u6a21\u578b\u7684\u6269\u5c55\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86SaM\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5728\u63a8\u7406\u65f6\u52a8\u6001\u9009\u62e9\u548c\u5408\u5e76\u4e13\u5bb6\u6a21\u578b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u9488\u5bf9\u76ee\u6807\u9886\u57df\uff0c\u6211\u4eec\u6839\u636e\uff08i\uff09\u4e0e\u76ee\u6807\u9886\u57df\u7684\u9886\u57df\u76f8\u4f3c\u6027\u548c\uff08ii\uff09\u5728\u91c7\u6837\u5b9e\u4f8b\u4e0a\u7684\u6027\u80fd\uff0c\u9009\u62e9\u5728\u73b0\u6709\u9886\u57df\u4e0a\u9884\u8bad\u7ec3\u7684\u9886\u57df\u7279\u5b9a\u4e13\u5bb6\u3002\u7136\u540e\u5c06\u8fd9\u4e9b\u4e13\u5bb6\u5408\u5e76\u4ee5\u521b\u5efa\u9488\u5bf9\u76ee\u6807\u9886\u57df\u7684\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u6846\u67b6\u6709\u6548\uff0c\u5e73\u5747\u4f18\u4e8e\u7edf\u4e00\u6a21\u578b10%\u3002\u6b64\u5916\uff0c\u4e13\u5bb6\u53ef\u4ee5\u65b9\u4fbf\u5730\u6dfb\u52a0\u6216\u5220\u9664\uff0c\u4ece\u800c\u5b9e\u73b0\u5de8\u5927\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u6211\u4eec\u7684\u6846\u67b6\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e73\u5747\u4f18\u4e8e\u7edf\u4e00\u6a21\u578b10%\u3002\u6211\u4eec\u8fd8\u63d0\u4f9b\u4e86\u5bf9\u6f5c\u5728\u6539\u8fdb\u3001\u5b9e\u8df5\u7ecf\u9a8c\u548c\u6846\u67b6\u6269\u5c55\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.22846", "pdf": "https://arxiv.org/pdf/2506.22846", "abs": "https://arxiv.org/abs/2506.22846", "authors": ["Duygu Altinok"], "title": "Boosting CTC-Based ASR Using LLM-Based Intermediate Loss Regularization", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "This is the accepted version of an article accepted to the TSD 2025\n  conference, published in Springer Lecture Notes in Artificial Intelligence\n  (LNAI). The final authenticated version is available online at SpringerLink", "summary": "End-to-end (E2E) automatic speech recognition (ASR) systems have\nrevolutionized the field by integrating all components into a single neural\nnetwork, with attention-based encoder-decoder models achieving state-of-the-art\nperformance. However, their autoregressive decoding process limits inference\nspeed, making them unsuitable for real-time applications. In contrast,\nCTC-based models offer faster, non-autoregressive decoding but struggle to\nmodel linguistic dependencies effectively. Addressing this challenge, we\npropose a novel auxiliary loss framework called Language-Aware Intermediate\nLoss (LAIL) to enhance CTC-based ASR using the linguistic knowledge of large\nlanguage models (LLMs). By attaching connector layers to intermediate encoder\nlayers, LAIL maps outputs to the embedding space of an LLM and computes a\ncausal language modeling loss during training. This approach enhances\nlinguistic modeling while preserving the computational efficiency of CTC\ndecoding. Using the Conformer architecture and various LLaMA models, we\ndemonstrate significant improvements in Word Error Rate (WER) on the\nLibriSpeech, TEDLIUM2, and WSJ corpora, achieving state-of-the-art performance\nfor CTC-based ASR with minimal computational overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLAIL\u7684\u65b0\u8f85\u52a9\u635f\u5931\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3aCTC-based ASR\u7684\u8bed\u8a00\u5efa\u6a21\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u8ba1\u7b97\u6548\u7387\u3002\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u663e\u8457\u7684WER\u6539\u8fdb\uff0c\u5e76\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u7aef\u5230\u7aefASR\u7cfb\u7edf\u7531\u4e8e\u81ea\u56de\u5f52\u89e3\u7801\u8fc7\u7a0b\u9650\u5236\u4e86\u63a8\u7406\u901f\u5ea6\uff0c\u4e0d\u9002\u5408\u5b9e\u65f6\u5e94\u7528\u3002\u800cCTC-based\u6a21\u578b\u867d\u7136\u89e3\u7801\u901f\u5ea6\u5feb\uff0c\u4f46\u96be\u4ee5\u6709\u6548\u5efa\u6a21\u8bed\u8a00\u4f9d\u8d56\u5173\u7cfb\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u589e\u5f3aCTC-based ASR\u7684\u8bed\u8a00\u5efa\u6a21\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aLanguage-Aware Intermediate Loss (LAIL)\u7684\u65b0\u8f85\u52a9\u635f\u5931\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8bed\u8a00\u77e5\u8bc6\u6765\u589e\u5f3aCTC-based ASR\u3002\u901a\u8fc7\u5728\u4e2d\u95f4\u7f16\u7801\u5668\u5c42\u9644\u52a0\u8fde\u63a5\u5668\u5c42\uff0c\u5c06\u8f93\u51fa\u6620\u5c04\u5230LLM\u7684\u5d4c\u5165\u7a7a\u95f4\uff0c\u5e76\u5728\u8bad\u7ec3\u671f\u95f4\u8ba1\u7b97\u56e0\u679c\u8bed\u8a00\u5efa\u6a21\u635f\u5931\u3002", "result": "\u5728LibriSpeech\u3001TEDLIUM2\u548cWSJ\u8bed\u6599\u5e93\u4e0a\uff0c\u4f7f\u7528Conformer\u67b6\u6784\u548c\u5404\u79cdLLaMA\u6a21\u578b\uff0cLAIL\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86Word Error Rate (WER)\uff0c\u5e76\u5b9e\u73b0\u4e86CTC-based ASR\u7684\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528LAIL\u6846\u67b6\uff0cCTC-based ASR\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684WER\u6539\u8fdb\uff0c\u5e76\u4e14\u5728\u8ba1\u7b97\u5f00\u9500\u6700\u5c0f\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2506.22852", "pdf": "https://arxiv.org/pdf/2506.22852", "abs": "https://arxiv.org/abs/2506.22852", "authors": ["Yucheng Cai", "Yuxuan Wu", "Yi Huang", "Junlan Feng", "Zhijian Ou"], "title": "Knowledge Augmented Finetuning Matters in both RAG and Agent Based Dialog Systems", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have recently been applied to dialog systems.\nDespite making progress, LLMs are prone to errors in knowledge-intensive\nscenarios. Recently, approaches based on retrieval augmented generation (RAG)\nand agent have emerged to improve the factual accuracy by enhancing the LLMs\nwith knowledge retrieved from external knowledge bases (KBs). This is mostly\nimplemented by prompting the LLMs with instructions, examples and the retrieved\nknowledge. However, LLMs may have difficulty using the retrieved knowledge\neffectively for response generation, because they are not well trained to do\nsuch generation for specific domains. To mitigate this problem, we propose to\nfinetune the LLMs in the RAG-based and agent-based systems with domain-specific\ndata, together with domain-specific external knowledge, which is called\nknowledge augmented finetuning (KAFT). We base our study on the MobileCS2\ndataset, a real-life customer service dialog dataset that features intensive\nknowledge interactions, to systematically compare the prompting and KAFT\ntechniques in the RAG-based and agent-based systems. Experiment results show\nthat KAFT substantially surpasses prompting in both RAG and agent systems,\nparticularly in terms of factual accuracy. To the best of our knowledge, this\npaper represents the first solid empirical work to investigate the KAFT idea.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u77e5\u8bc6\u589e\u5f3a\u5fae\u8c03\uff08KAFT\uff09\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u57fa\u4e8eRAG\u548c\u4ee3\u7406\u7cfb\u7edf\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u5e76\u53d1\u73b0KAFT\u4f18\u4e8e\u4f20\u7edf\u7684\u63d0\u793a\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u573a\u666f\u4e2d\u5bb9\u6613\u51fa\u9519\uff0c\u5c3d\u7ba1\u5df2\u7ecf\u63d0\u51fa\u4e86\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u4ee3\u7406\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5728\u4f7f\u7528\u68c0\u7d22\u5230\u7684\u77e5\u8bc6\u8fdb\u884c\u54cd\u5e94\u751f\u6210\u65f6\u53ef\u80fd\u9047\u5230\u56f0\u96be\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u77e5\u8bc6\u589e\u5f3a\u5fae\u8c03\uff08KAFT\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u57fa\u4e8eRAG\u548c\u57fa\u4e8e\u4ee3\u7406\u7684\u7cfb\u7edf\u4e2d\u4f7f\u7528\u7279\u5b9a\u9886\u57df\u7684\u6570\u636e\u548c\u5916\u90e8\u77e5\u8bc6\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cKAFT\u5728RAG\u548c\u4ee3\u7406\u7cfb\u7edf\u4e2d\u90fd\u663e\u8457\u4f18\u4e8e\u63d0\u793a\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u65b9\u9762\u3002", "conclusion": "KAFT\u5728RAG\u548c\u4ee3\u7406\u7cfb\u7edf\u4e2d\u663e\u8457\u4f18\u4e8e\u63d0\u793a\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u65b9\u9762\u3002\u672c\u6587\u4ee3\u8868\u4e86\u9996\u6b21\u575a\u5b9e\u7684\u5b9e\u8bc1\u5de5\u4f5c\u6765\u7814\u7a76KAFT\u7684\u6982\u5ff5\u3002"}}
{"id": "2506.22853", "pdf": "https://arxiv.org/pdf/2506.22853", "abs": "https://arxiv.org/abs/2506.22853", "authors": ["Kyochul Jang", "Donghyeon Lee", "Kyusik Kim", "Dongseok Heo", "Taewhoo Lee", "Woojeong Kim", "Bongwon Suh"], "title": "DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, ACL 2025 Vienna", "summary": "Existing function-calling benchmarks focus on single-turn interactions.\nHowever, they overlook the complexity of real-world scenarios. To quantify how\nexisting benchmarks address practical applications, we introduce DICE-SCORE, a\nmetric that evaluates the dispersion of tool-related information such as\nfunction name and parameter values throughout the dialogue. Analyzing existing\nbenchmarks through DICE-SCORE reveals notably low scores, highlighting the need\nfor more realistic scenarios. To address this gap, we present DICE-BENCH, a\nframework that constructs practical function-calling datasets by synthesizing\nconversations through a tool graph that maintains dependencies across rounds\nand a multi-agent system with distinct personas to enhance dialogue\nnaturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our\nexperiments on 19 LLMs with DICE-BENCH show that significant advances are still\nrequired before such models can be deployed effectively in real-world settings.\nOur code and data are all publicly available:\nhttps://snuhcc.github.io/DICE-Bench/.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86DICE-SCORE\uff0c\u4e00\u79cd\u8bc4\u4f30\u5de5\u5177\u76f8\u5173\u4fe1\u606f\u5728\u6574\u4e2a\u5bf9\u8bdd\u4e2d\u5206\u6563\u7a0b\u5ea6\u7684\u6307\u6807\uff0c\u5e76\u63d0\u51fa\u4e86DICE-BENCH\uff0c\u4e00\u4e2a\u901a\u8fc7\u5408\u6210\u5bf9\u8bdd\u6784\u5efa\u5b9e\u9645\u529f\u80fd\u8c03\u7528\u6570\u636e\u96c6\u7684\u6846\u67b6\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd8\u9700\u8981\u663e\u8457\u8fdb\u6b65\u624d\u80fd\u5c06\u8fd9\u4e9b\u6a21\u578b\u6709\u6548\u90e8\u7f72\u5230\u73b0\u5b9e\u4e16\u754c\u8bbe\u7f6e\u4e2d\u3002", "motivation": "\u73b0\u6709\u7684\u51fd\u6570\u8c03\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e13\u6ce8\u4e8e\u5355\u6b21\u4ea4\u4e92\uff0c\u4f46\u5b83\u4eec\u5ffd\u89c6\u4e86\u73b0\u5b9e\u573a\u666f\u7684\u590d\u6742\u6027\u3002\u4e3a\u4e86\u91cf\u5316\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8868\u73b0\uff0c\u6211\u4eec\u5f15\u5165\u4e86DICE-SCORE\uff0c\u8fd9\u662f\u4e00\u79cd\u8bc4\u4f30\u5de5\u5177\u76f8\u5173\u4fe1\u606f\uff08\u5982\u51fd\u6570\u540d\u79f0\u548c\u53c2\u6570\u503c\uff09\u5728\u6574\u4e2a\u5bf9\u8bdd\u4e2d\u5206\u6563\u7a0b\u5ea6\u7684\u6307\u6807\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86DICE-BENCH\uff0c\u8fd9\u662f\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u5bf9\u8bdd\u6765\u6784\u5efa\u5b9e\u9645\u7684\u529f\u80fd\u8c03\u7528\u6570\u636e\u96c6\uff0c\u8be5\u5bf9\u8bdd\u901a\u8fc7\u5de5\u5177\u56fe\u4fdd\u6301\u8de8\u8f6e\u6b21\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u5177\u6709\u4e0d\u540c\u4eba\u8bbe\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6765\u589e\u5f3a\u5bf9\u8bdd\u7684\u81ea\u7136\u6027\u3002", "result": "\u901a\u8fc7DICE-SCORE\u5206\u6790\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u51fa\u660e\u663e\u7684\u4f4e\u5206\uff0c\u7a81\u663e\u4e86\u9700\u8981\u66f4\u73b0\u5b9e\u573a\u666f\u7684\u5fc5\u8981\u6027\u3002\u6700\u7ec8\u7684\u6570\u636e\u96c6\u5305\u542b1,607\u4e2a\u9ad8DICE-SCORE\u5b9e\u4f8b\u3002", "conclusion": "\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5c06\u8fd9\u4e9b\u6a21\u578b\u6709\u6548\u90e8\u7f72\u5230\u73b0\u5b9e\u4e16\u754c\u8bbe\u7f6e\u4e4b\u524d\uff0c\u4ecd\u9700\u8981\u663e\u8457\u7684\u8fdb\u6b65\u3002"}}
{"id": "2506.22858", "pdf": "https://arxiv.org/pdf/2506.22858", "abs": "https://arxiv.org/abs/2506.22858", "authors": ["Duygu Altinok"], "title": "Mind the Gap: Entity-Preserved Context-Aware ASR Structured Transcriptions", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "This is the accepted version of an article accepted to the TSD 2025\n  conference, published in Springer Lecture Notes in Artificial Intelligence\n  (LNAI). The final authenticated version is available online at SpringerLink", "summary": "Automatic Speech Recognition (ASR) systems, such as Whisper, achieve high\ntranscription accuracy but struggle with named entities and numerical data,\nespecially when proper formatting is required. These issues increase word error\nrate (WER) and impair semantic understanding in critical domains like legal,\nfinancial, and medical applications. We propose a novel training approach that\nextends the semantic context of ASR models by adding overlapping context\nwindows during training. By sliding 5-second overlaps on both sides of\n30-second chunks, we create a 40-second \"effective semantic window,\" improving\nentity recognition and formatting while focusing predictions on the central 30\nseconds. To address entities spanning chunk boundaries, we reassign such\nentities entirely to the right-hand chunk, ensuring proper formatting.\nAdditionally, enriched training data with embedded entity labels enables the\nmodel to learn both recognition and type-specific formatting. Evaluated on the\nSpoken Wikipedia dataset, our method improves performance across semantic\ntasks, including named entity recognition (NER) and entity formatting. These\nresults highlight the effectiveness of context-aware training in addressing ASR\nlimitations for long-form transcription and complex entity recognition tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u6269\u5c55ASR\u6a21\u578b\u7684\u8bed\u4e49\u4e0a\u4e0b\u6587\u6765\u63d0\u9ad8\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u683c\u5f0f\u5316\u7684\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u5728Spoken Wikipedia\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\u3002", "motivation": "\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u7cfb\u7edf\uff0c\u5982Whisper\uff0c\u5728\u8f6c\u5f55\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5904\u7406\u547d\u540d\u5b9e\u4f53\u548c\u6570\u5b57\u6570\u636e\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u6b63\u786e\u683c\u5f0f\u5316\u7684\u60c5\u51b5\u4e0b\u3002\u8fd9\u4e9b\u95ee\u9898\u4f1a\u589e\u52a0\u8bcd\u9519\u8bef\u7387\uff08WER\uff09\uff0c\u5e76\u5728\u6cd5\u5f8b\u3001\u91d1\u878d\u548c\u533b\u7597\u7b49\u5173\u952e\u9886\u57df\u5f71\u54cd\u8bed\u4e49\u7406\u89e3\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u671f\u95f4\u6dfb\u52a0\u91cd\u53e0\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u6765\u6269\u5c55ASR\u6a21\u578b\u7684\u8bed\u4e49\u4e0a\u4e0b\u6587\u3002\u901a\u8fc7\u572830\u79d2\u5757\u7684\u4e24\u4fa7\u6ed1\u52a85\u79d2\u91cd\u53e0\uff0c\u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a40\u79d2\u7684\u201c\u6709\u6548\u8bed\u4e49\u7a97\u53e3\u201d\uff0c\u5728\u5173\u6ce8\u4e2d\u592e30\u79d2\u7684\u540c\u65f6\u6539\u5584\u5b9e\u4f53\u8bc6\u522b\u548c\u683c\u5f0f\u5316\u3002\u4e3a\u4e86\u5904\u7406\u8de8\u8d8a\u5757\u8fb9\u754c\u7684\u5b9e\u4f53\uff0c\u6211\u4eec\u5c06\u8fd9\u4e9b\u5b9e\u4f53\u5b8c\u5168\u91cd\u65b0\u5206\u914d\u5230\u53f3\u4fa7\u5757\uff0c\u786e\u4fdd\u6b63\u786e\u7684\u683c\u5f0f\u5316\u3002\u6b64\u5916\uff0c\u5e26\u6709\u5d4c\u5165\u5b9e\u4f53\u6807\u7b7e\u7684\u4e30\u5bcc\u8bad\u7ec3\u6570\u636e\u4f7f\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u8bc6\u522b\u548c\u7279\u5b9a\u7c7b\u578b\u7684\u683c\u5f0f\u5316\u3002", "result": "\u5728Spoken Wikipedia\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u8bed\u4e49\u4efb\u52a1\u4e0a\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u5305\u62ec\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09\u548c\u5b9e\u4f53\u683c\u5f0f\u5316\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u8bed\u4e49\u4efb\u52a1\u4e0a\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u5305\u62ec\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09\u548c\u5b9e\u4f53\u683c\u5f0f\u5316\u3002\u8fd9\u4e9b\u7ed3\u679c\u7a81\u663e\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u8bad\u7ec3\u5728\u89e3\u51b3\u957f\u6587\u672c\u8f6c\u5f55\u548c\u590d\u6742\u5b9e\u4f53\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684ASR\u9650\u5236\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.22957", "pdf": "https://arxiv.org/pdf/2506.22957", "abs": "https://arxiv.org/abs/2506.22957", "authors": ["Younwoo Choi", "Changling Li", "Yongjin Yang", "Zhijing Jin"], "title": "Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "comment": null, "summary": "As large language models (LLMs) are increasingly integrated into multi-agent\nand human-AI systems, understanding their awareness of both self-context and\nconversational partners is essential for ensuring reliable performance and\nrobust safety. While prior work has extensively studied situational awareness\nwhich refers to an LLM's ability to recognize its operating phase and\nconstraints, it has largely overlooked the complementary capacity to identify\nand adapt to the identity and characteristics of a dialogue partner. In this\npaper, we formalize this latter capability as interlocutor awareness and\npresent the first systematic evaluation of its emergence in contemporary LLMs.\nWe examine interlocutor inference across three dimensions-reasoning patterns,\nlinguistic style, and alignment preferences-and show that LLMs reliably\nidentify same-family peers and certain prominent model families, such as GPT\nand Claude. To demonstrate its practical significance, we develop three case\nstudies in which interlocutor awareness both enhances multi-LLM collaboration\nthrough prompt adaptation and introduces new alignment and safety\nvulnerabilities, including reward-hacking behaviors and increased jailbreak\nsusceptibility. Our findings highlight the dual promise and peril of\nidentity-sensitive behavior in LLMs, underscoring the need for further\nunderstanding of interlocutor awareness and new safeguards in multi-agent\ndeployments. Our code is open-sourced at\nhttps://github.com/younwoochoi/InterlocutorAwarenessLLM.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5bf9\u8bdd\u8005\u610f\u8bc6\u65b9\u9762\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5b83\u4eec\u80fd\u591f\u8bc6\u522b\u540c\u4e00\u5bb6\u65cf\u7684\u6a21\u578b\uff0c\u5e76\u5c55\u793a\u4e86\u8fd9\u79cd\u80fd\u529b\u5728\u591aLLM\u534f\u4f5c\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u548c\u6f5c\u5728\u98ce\u9669\u3002", "motivation": "\u4e86\u89e3LLM\u5bf9\u81ea\u5df1\u4e0a\u4e0b\u6587\u548c\u5bf9\u8bdd\u4f19\u4f34\u7684\u610f\u8bc6\u5bf9\u4e8e\u786e\u4fdd\u53ef\u9760\u6027\u80fd\u548c\u7a33\u5065\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002\u5c3d\u7ba1\u5148\u524d\u5de5\u4f5c\u5df2\u7ecf\u5e7f\u6cdb\u7814\u7a76\u4e86\u60c5\u5883\u610f\u8bc6\uff0c\u4f46\u5f88\u5c11\u5173\u6ce8\u8bc6\u522b\u548c\u9002\u5e94\u5bf9\u8bdd\u4f19\u4f34\u8eab\u4efd\u548c\u7279\u5f81\u7684\u80fd\u529b\u3002", "method": "\u6211\u4eec\u901a\u8fc7\u4e09\u4e2a\u7ef4\u5ea6\uff08\u63a8\u7406\u6a21\u5f0f\u3001\u8bed\u8a00\u98ce\u683c\u548c\u5bf9\u9f50\u504f\u597d\uff09\u68c0\u67e5\u4e86\u5bf9\u8bdd\u8005\u63a8\u65ad\uff0c\u5e76\u5f00\u53d1\u4e86\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\u6765\u5c55\u793a\u5176\u5b9e\u9645\u610f\u4e49\u3002", "result": "LLMs\u80fd\u591f\u53ef\u9760\u5730\u8bc6\u522b\u540c\u4e00\u5bb6\u65cf\u7684\u540c\u884c\u548c\u67d0\u4e9b\u8457\u540d\u7684\u6a21\u578b\u5bb6\u65cf\uff0c\u5982GPT\u548cClaude\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u80fd\u529b\u4e5f\u5f15\u5165\u4e86\u65b0\u7684\u5bf9\u9f50\u548c\u5b89\u5168\u6f0f\u6d1e\uff0c\u5305\u62ec\u5956\u52b1\u9ed1\u5ba2\u884c\u4e3a\u548c\u66f4\u9ad8\u7684\u8d8a\u72f1\u6613\u611f\u6027\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u7a81\u663e\u4e86LLM\u4e2d\u8eab\u4efd\u654f\u611f\u884c\u4e3a\u7684\u53cc\u91cd\u6f5c\u529b\u548c\u98ce\u9669\uff0c\u5f3a\u8c03\u4e86\u8fdb\u4e00\u6b65\u7406\u89e3\u5bf9\u8bdd\u8005\u610f\u8bc6\u548c\u5728\u591a\u4ee3\u7406\u90e8\u7f72\u4e2d\u5efa\u7acb\u65b0\u4fdd\u969c\u63aa\u65bd\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2506.22977", "pdf": "https://arxiv.org/pdf/2506.22977", "abs": "https://arxiv.org/abs/2506.22977", "authors": ["Asen Dotsinski", "Udit Thakur", "Marko Ivanov", "Mohammad Hafeez Khan", "Maria Heuss"], "title": "On the Generalizability of \"Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals\"", "categories": ["cs.CL", "cs.LG"], "comment": "22 pages, 25 figures. For an interactive dashboard with all figures,\n  see https://comp-mech-generalizability.streamlit.app/ . For the accompanying\n  code, see https://github.com/asendotsinski/comp-mech-generalizability . To be\n  published in proceedings of the 2025 Machine Learning Reproducibility\n  Challenge", "summary": "We present a reproduction study of \"Competition of Mechanisms: Tracing How\nLanguage Models Handle Facts and Counterfactuals\" (Ortu et al., 2024), which\ninvestigates competition of mechanisms in language models between factual\nrecall and counterfactual in-context repetition. Our study successfully\nreproduces their primary findings regarding the localization of factual and\ncounterfactual information, the dominance of attention blocks in mechanism\ncompetition, and the specialization of attention heads in handling competing\ninformation. We reproduce their results on both GPT-2 (Radford et al., 2019)\nand Pythia 6.9B (Biderman et al., 2023). We extend their work in three\nsignificant directions. First, we explore the generalizability of these\nfindings to even larger models by replicating the experiments on Llama 3.1 8B\n(Grattafiori et al., 2024), discovering greatly reduced attention head\nspecialization. Second, we investigate the impact of prompt structure by\nintroducing variations where we avoid repeating the counterfactual statement\nverbatim or we change the premise word, observing a marked decrease in the\nlogit for the counterfactual token. Finally, we test the validity of the\nauthors' claims for prompts of specific domains, discovering that certain\ncategories of prompts skew the results by providing the factual prediction\ntoken as part of the subject of the sentence. Overall, we find that the\nattention head ablation proposed in Ortu et al. (2024) is ineffective for\ndomains that are underrepresented in their dataset, and that the effectiveness\nvaries based on model architecture, prompt structure, domain and task.", "AI": {"tldr": "\u672c\u6587\u590d\u5236\u5e76\u6269\u5c55\u4e86Ortu\u7b49\u4eba\uff082024\uff09\u7684\u7814\u7a76\uff0c\u53d1\u73b0\u6ce8\u610f\u529b\u5934\u6d88\u878d\u65b9\u6cd5\u5728\u6570\u636e\u96c6\u672a\u8986\u76d6\u7684\u9886\u57df\u4e2d\u65e0\u6548\uff0c\u5e76\u4e14\u5176\u6548\u679c\u53d7\u6a21\u578b\u67b6\u6784\u3001\u63d0\u793a\u7ed3\u6784\u3001\u9886\u57df\u548c\u4efb\u52a1\u5f71\u54cd\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u9a8c\u8bc1Ortu\u7b49\u4eba\uff082024\uff09\u7684\u7814\u7a76\u6210\u679c\uff0c\u5e76\u63a2\u7d22\u5176\u5728\u66f4\u5927\u6a21\u578b\u3001\u4e0d\u540c\u63d0\u793a\u7ed3\u6784\u548c\u7279\u5b9a\u9886\u57df\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u6211\u4eec\u5bf9Ortu\u7b49\u4eba\uff082024\uff09\u7684\u7814\u7a76\u8fdb\u884c\u4e86\u590d\u5236\uff0c\u5e76\u6269\u5c55\u4e86\u4e09\u4e2a\u91cd\u8981\u65b9\u5411\uff1a1\uff09\u5c06\u5b9e\u9a8c\u590d\u5236\u5230\u66f4\u5927\u7684\u6a21\u578bLlama 3.1 8B\uff0c\u53d1\u73b0\u6ce8\u610f\u529b\u5934\u4e13\u4e1a\u5316\u663e\u8457\u964d\u4f4e\uff1b2\uff09\u7814\u7a76\u63d0\u793a\u7ed3\u6784\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u907f\u514d\u91cd\u590d\u53cd\u4e8b\u5b9e\u9648\u8ff0\u6216\u6539\u53d8\u524d\u63d0\u8bcd\u4f1a\u663e\u8457\u964d\u4f4e\u53cd\u4e8b\u5b9e\u6807\u8bb0\u7684logit\uff1b3\uff09\u6d4b\u8bd5\u4f5c\u8005\u5173\u4e8e\u7279\u5b9a\u9886\u57df\u63d0\u793a\u7684\u4e3b\u5f20\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u67d0\u4e9b\u7c7b\u522b\u63d0\u793a\u901a\u8fc7\u5c06\u4e8b\u5b9e\u9884\u6d4b\u6807\u8bb0\u4f5c\u4e3a\u53e5\u5b50\u7684\u4e3b\u8bed\u6765\u626d\u66f2\u7ed3\u679c\u3002", "result": "\u6211\u4eec\u6210\u529f\u590d\u5236\u4e86Ortu\u7b49\u4eba\uff082024\uff09\u7684\u4e3b\u8981\u53d1\u73b0\uff0c\u5305\u62ec\u4e8b\u5b9e\u548c\u53cd\u4e8b\u5b9e\u4fe1\u606f\u7684\u5b9a\u4f4d\u3001\u6ce8\u610f\u529b\u5757\u5728\u673a\u5236\u7ade\u4e89\u4e2d\u7684\u4e3b\u5bfc\u5730\u4f4d\u4ee5\u53ca\u6ce8\u610f\u529b\u5934\u5728\u5904\u7406\u7ade\u4e89\u4fe1\u606f\u4e2d\u7684\u4e13\u95e8\u5316\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5728Llama 3.1 8B\u4e0a\u53d1\u73b0\u4e86\u6ce8\u610f\u529b\u5934\u4e13\u4e1a\u5316\u7684\u663e\u8457\u51cf\u5c11\uff0c\u5728\u4e0d\u540c\u63d0\u793a\u7ed3\u6784\u4e0b\u89c2\u5bdf\u5230\u53cd\u4e8b\u5b9e\u6807\u8bb0logit\u7684\u4e0b\u964d\uff0c\u5e76\u53d1\u73b0\u67d0\u4e9b\u9886\u57df\u63d0\u793a\u4f1a\u5f71\u54cd\u7ed3\u679c\u3002", "conclusion": "\u6211\u4eec\u53d1\u73b0Ortu\u7b49\u4eba\uff082024\uff09\u63d0\u51fa\u7684\u6ce8\u610f\u529b\u5934\u6d88\u878d\u65b9\u6cd5\u5728\u6570\u636e\u96c6\u4e2d\u672a\u88ab\u5145\u5206\u4ee3\u8868\u7684\u9886\u57df\u4e2d\u65e0\u6548\uff0c\u5e76\u4e14\u5176\u6548\u679c\u53d6\u51b3\u4e8e\u6a21\u578b\u67b6\u6784\u3001\u63d0\u793a\u7ed3\u6784\u3001\u9886\u57df\u548c\u4efb\u52a1\u3002"}}
{"id": "2506.22978", "pdf": "https://arxiv.org/pdf/2506.22978", "abs": "https://arxiv.org/abs/2506.22978", "authors": ["Yida Zhao", "Hao Xve", "Xiang Hu", "Kewei Tu"], "title": "A Systematic Study of Compositional Syntactic Transformer Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Syntactic language models (SLMs) enhance Transformers by incorporating\nsyntactic biases through the modeling of linearized syntactic parse trees\nalongside surface sentences. This paper focuses on compositional SLMs that are\nbased on constituency parse trees and contain explicit bottom-up composition of\nconstituent representations. We identify key aspects of design choices in\nexisting compositional SLMs and propose a unified framework encompassing both\nexisting models and novel variants. We conduct a comprehensive empirical\nevaluation of all the variants in our framework across language modeling,\nsyntactic generalization, summarization, dialogue, and inference efficiency.\nBased on the experimental results, we make multiple recommendations on the\ndesign of compositional SLMs. Our code is released at\nhttps://github.com/zhaoyd1/compositional_SLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6539\u8fdb\u57fa\u4e8e\u6210\u5206\u53e5\u6cd5\u6811\u7684\u7ec4\u5408SLM\uff0c\u5e76\u6839\u636e\u5b9e\u9a8c\u7ed3\u679c\u63d0\u51fa\u4e86\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u73b0\u6709\u7684\u7ec4\u5408SLM\u5728\u8bbe\u8ba1\u9009\u62e9\u4e0a\u5b58\u5728\u4e00\u4e9b\u5173\u952e\u65b9\u9762\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u6539\u8fdb\u8fd9\u4e9b\u8bbe\u8ba1\u3002", "method": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u6210\u5206\u53e5\u6cd5\u6811\u7684\u7ec4\u5408SLM\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u4ee5\u6db5\u76d6\u73b0\u6709\u7684\u6a21\u578b\u548c\u65b0\u7684\u53d8\u4f53\u3002", "result": "\u672c\u6587\u5bf9\u6846\u67b6\u4e2d\u7684\u6240\u6709\u53d8\u4f53\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u5305\u62ec\u8bed\u8a00\u5efa\u6a21\u3001\u53e5\u6cd5\u6cdb\u5316\u3001\u6458\u8981\u3001\u5bf9\u8bdd\u548c\u63a8\u7406\u6548\u7387\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u6db5\u76d6\u4e86\u73b0\u6709\u7684\u6a21\u578b\u548c\u65b0\u7684\u53d8\u4f53\uff0c\u5e76\u6839\u636e\u5b9e\u9a8c\u7ed3\u679c\u5bf9\u7ec4\u5408SLM\u7684\u8bbe\u8ba1\u63d0\u51fa\u4e86\u591a\u4e2a\u5efa\u8bae\u3002"}}
{"id": "2506.23046", "pdf": "https://arxiv.org/pdf/2506.23046", "abs": "https://arxiv.org/abs/2506.23046", "authors": ["Xianzhe Fan", "Xuhui Zhou", "Chuanyang Jin", "Kolby Nottingham", "Hao Zhu", "Maarten Sap"], "title": "SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.RO"], "comment": "23 pages, 6 figures", "summary": "Humans continuously infer the states, goals, and behaviors of others by\nperceiving their surroundings in dynamic, real-world social interactions.\nHowever, most Theory of Mind (ToM) benchmarks only evaluate static, text-based\nscenarios, which have a significant gap compared to real interactions. We\npropose the SoMi-ToM benchmark, designed to evaluate multi-perspective ToM in\nembodied multi-agent complex social interactions. This benchmark is based on\nrich multimodal interaction data generated by the interaction environment SoMi,\ncovering diverse crafting goals and social relationships. Our framework\nsupports multi-level evaluation: (1) first-person evaluation provides\nmultimodal (visual, dialogue, action, etc.) input from a first-person\nperspective during a task for real-time state inference, (2) third-person\nevaluation provides complete third-person perspective video and text records\nafter a task for goal and behavior inference. This evaluation method allows for\na more comprehensive examination of a model's ToM capabilities from both the\nsubjective immediate experience and the objective global observation. We\nconstructed a challenging dataset containing 35 third-person perspective\nvideos, 363 first-person perspective images, and 1225 expert-annotated\nmultiple-choice questions (three options). On this dataset, we systematically\nevaluated the performance of human subjects and several state-of-the-art large\nvision-language models (LVLMs). The results show that LVLMs perform\nsignificantly worse than humans on SoMi-ToM: the average accuracy gap between\nhumans and models is 40.1% in first-person evaluation and 26.4% in third-person\nevaluation. This indicates that future LVLMs need to further improve their ToM\ncapabilities in embodied, complex social interactions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SoMi-ToM\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5177\u8eab\u591a\u667a\u80fd\u4f53\u590d\u6742\u793e\u4f1a\u4e92\u52a8\u4e2d\u7684\u7406\u8bba\u5fc3\u667a\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u663e\u8457\u4f4e\u4e8e\u4eba\u7c7b\uff0c\u8868\u660e\u672a\u6765\u9700\u8981\u6539\u8fdb\u6a21\u578b\u7684\u7406\u8bba\u5fc3\u667a\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u7406\u8bba\u5fc3\u667a\uff08ToM\uff09\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u9759\u6001\u3001\u57fa\u4e8e\u6587\u672c\u7684\u573a\u666f\uff0c\u4e0e\u771f\u5b9e\u4e92\u52a8\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u66f4\u8d34\u8fd1\u73b0\u5b9e\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u6a21\u578b\u7684\u7406\u8bba\u5fc3\u667a\u80fd\u529b\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86SoMi-ToM\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5177\u8eab\u591a\u667a\u80fd\u4f53\u590d\u6742\u793e\u4f1a\u4e92\u52a8\u4e2d\u7684\u591a\u89c6\u89d2\u7406\u8bba\u5fc3\u667a\u3002\u8be5\u57fa\u51c6\u57fa\u4e8e\u4ea4\u4e92\u73af\u5883SoMi\u751f\u6210\u7684\u4e30\u5bcc\u591a\u6a21\u6001\u4ea4\u4e92\u6570\u636e\uff0c\u652f\u6301\u7b2c\u4e00\u4eba\u79f0\u548c\u7b2c\u4e09\u4eba\u79f0\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u5728SoMi-ToM\u6570\u636e\u96c6\u4e0a\uff0c\u6211\u4eec\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u4eba\u7c7b\u548c\u51e0\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793a\uff0cLVLMs\u5728\u7b2c\u4e00\u4eba\u79f0\u8bc4\u4f30\u4e2d\u7684\u5e73\u5747\u51c6\u786e\u7387\u6bd4\u4eba\u7c7b\u4f4e40.1%\uff0c\u5728\u7b2c\u4e09\u4eba\u79f0\u8bc4\u4f30\u4e2d\u4f4e26.4%\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u5728SoMi-ToM\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u663e\u8457\u4f4e\u4e8e\u4eba\u7c7b\uff0c\u8fd9\u8868\u660e\u672a\u6765\u7684LVLMs\u9700\u8981\u8fdb\u4e00\u6b65\u63d0\u9ad8\u5176\u5728\u5177\u8eab\u3001\u590d\u6742\u793e\u4f1a\u4e92\u52a8\u4e2d\u7684\u7406\u8bba\u5fc3\u667a\u80fd\u529b\u3002"}}
{"id": "2506.23051", "pdf": "https://arxiv.org/pdf/2506.23051", "abs": "https://arxiv.org/abs/2506.23051", "authors": ["Jo\u00e3o Lucas Luz Lima Sarcinelli", "Marina Lages Gon\u00e7alves Teixeira", "Jade Bortot de Paiva", "Diego Furtado Silva"], "title": "MariNER: A Dataset for Historical Brazilian Portuguese Named Entity Recognition", "categories": ["cs.CL"], "comment": null, "summary": "Named Entity Recognition (NER) is a fundamental Natural Language Processing\n(NLP) task that aims to identify and classify entity mentions in texts across\ndifferent categories. While languages such as English possess a large number of\nhigh-quality resources for this task, Brazilian Portuguese still lacks in\nquantity of gold-standard NER datasets, especially when considering specific\ndomains. Particularly, this paper considers the importance of NER for analyzing\nhistorical texts in the context of digital humanities. To address this gap,\nthis work outlines the construction of MariNER: \\textit{Mapeamento e\nAnota\\c{c}\\~oes de Registros hIst\\'oricos para NER} (Mapping and Annotation of\nHistorical Records for NER), the first gold-standard dataset for early\n20th-century Brazilian Portuguese, with more than 9,000 manually annotated\nsentences. We also assess and compare the performance of state-of-the-art NER\nmodels for the dataset.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86MariNER\uff0c\u8fd9\u662f\u4e00\u4e2a\u9488\u5bf920\u4e16\u7eaa\u521d\u5df4\u897f\u8461\u8404\u7259\u8bed\u7684\u9996\u4e2a\u9ad8\u8d28\u91cf\u91d1\u6807\u51c6\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u6700\u5148\u8fdb\u7684NER\u6a21\u578b\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e\u5df4\u897f\u8461\u8404\u7259\u8bed\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u91d1\u6807\u51c6NER\u6570\u636e\u96c6\uff0c\u7279\u522b\u662f\u5728\u7279\u5b9a\u9886\u57df\uff0c\u56e0\u6b64\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u5386\u53f2\u6587\u672c\u5206\u6790\u7684\u6570\u636e\u96c6\u3002", "method": "\u672c\u6587\u6784\u5efa\u4e86MariNER\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u548c\u6bd4\u8f83\u4e86\u6700\u5148\u8fdb\u7684NER\u6a21\u578b\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002", "result": "MariNER\u662f\u7b2c\u4e00\u4e2a\u9488\u5bf920\u4e16\u7eaa\u521d\u5df4\u897f\u8461\u8404\u7259\u8bed\u7684\u91d1\u6807\u51c6NER\u6570\u636e\u96c6\uff0c\u5305\u542b\u8d85\u8fc79,000\u6761\u624b\u52a8\u6807\u6ce8\u7684\u53e5\u5b50\u3002\u540c\u65f6\uff0c\u672c\u6587\u8bc4\u4f30\u4e86\u6700\u5148\u8fdb\u7684NER\u6a21\u578b\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u6784\u5efaMariNER\u6570\u636e\u96c6\uff0c\u586b\u8865\u4e86\u5df4\u897f\u8461\u8404\u7259\u8bed\u5728NER\u4efb\u52a1\u4e2d\u7684\u6570\u636e\u7a7a\u767d\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.23056", "pdf": "https://arxiv.org/pdf/2506.23056", "abs": "https://arxiv.org/abs/2506.23056", "authors": ["Xiang Zhuang", "Bin Wu", "Jiyu Cui", "Kehua Feng", "Xiaotong Li", "Huabin Xing", "Keyan Ding", "Qiang Zhang", "Huajun Chen"], "title": "Boosting LLM's Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning", "categories": ["cs.CL"], "comment": "ACL 2025 Main", "summary": "Molecular structure elucidation involves deducing a molecule's structure from\nvarious types of spectral data, which is crucial in chemical experimental\nanalysis. While large language models (LLMs) have shown remarkable proficiency\nin analyzing and reasoning through complex tasks, they still encounter\nsubstantial challenges in molecular structure elucidation. We identify that\nthese challenges largely stem from LLMs' limited grasp of specialized chemical\nknowledge. In this work, we introduce a Knowledge-enhanced reasoning framework\nfor Molecular Structure Elucidation (K-MSE), leveraging Monte Carlo Tree Search\nfor test-time scaling as a plugin. Specifically, we construct an external\nmolecular substructure knowledge base to extend the LLMs' coverage of the\nchemical structure space. Furthermore, we design a specialized\nmolecule-spectrum scorer to act as a reward model for the reasoning process,\naddressing the issue of inaccurate solution evaluation in LLMs. Experimental\nresults show that our approach significantly boosts performance, particularly\ngaining more than 20% improvement on both GPT-4o-mini and GPT-4o. Our code is\navailable at https://github.com/HICAI-ZJU/K-MSE.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u77e5\u8bc6\u7684\u63a8\u7406\u6846\u67b6\uff08K-MSE\uff09\uff0c\u7528\u4e8e\u5206\u5b50\u7ed3\u6784\u89e3\u6790\uff0c\u901a\u8fc7\u6784\u5efa\u5916\u90e8\u5206\u5b50\u5b50\u7ed3\u6784\u77e5\u8bc6\u5e93\u548c\u8bbe\u8ba1\u4e13\u95e8\u7684\u5206\u5b50-\u5149\u8c31\u8bc4\u5206\u5668\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "motivation": "\u6211\u4eec\u53d1\u73b0\u8fd9\u4e9b\u6311\u6218\u4e3b\u8981\u6e90\u4e8eLLMs\u5bf9\u4e13\u4e1a\u5316\u5b66\u77e5\u8bc6\u7684\u638c\u63e1\u6709\u9650\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u589e\u5f3a\u77e5\u8bc6\u7684\u63a8\u7406\u6846\u67b6\uff08K-MSE\uff09\uff0c\u5229\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4f5c\u4e3a\u63d2\u4ef6\u8fdb\u884c\u6d4b\u8bd5\u65f6\u6269\u5c55\u3002\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u5916\u90e8\u5206\u5b50\u5b50\u7ed3\u6784\u77e5\u8bc6\u5e93\u6765\u6269\u5c55LLMs\u5bf9\u5316\u5b66\u7ed3\u6784\u7a7a\u95f4\u7684\u8986\u76d6\u8303\u56f4\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e13\u95e8\u7684\u5206\u5b50-\u5149\u8c31\u8bc4\u5206\u5668\u4f5c\u4e3a\u63a8\u7406\u8fc7\u7a0b\u7684\u5956\u52b1\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728GPT-4o-mini\u548cGPT-4o\u4e0a\u53d6\u5f97\u4e86\u8d85\u8fc720%\u7684\u63d0\u5347\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728GPT-4o-mini\u548cGPT-4o\u4e0a\u53d6\u5f97\u4e86\u8d85\u8fc720%\u7684\u63d0\u5347\u3002"}}
{"id": "2506.23071", "pdf": "https://arxiv.org/pdf/2506.23071", "abs": "https://arxiv.org/abs/2506.23071", "authors": ["Zhengren Wang", "Bozhou Li", "Dongwen Yao", "Wentao Zhang"], "title": "Text2VectorSQL: Bridging Text-to-SQL and Vector Search for Unified Natural Language Queries", "categories": ["cs.CL"], "comment": "Work in progess", "summary": "While Text-to-SQL enables natural language interaction with structured\ndatabases, its effectiveness diminishes with unstructured data or ambiguous\nqueries due to rigid syntax and limited expressiveness. Concurrently, vector\nsearch has emerged as a powerful paradigm for semantic retrieval, particularly\nfor unstructured data. However, existing VectorSQL implementations still rely\nheavily on manual crafting and lack tailored evaluation frameworks, leaving a\nsignificant gap between theoretical potential and practical deployment. To\nbridge these complementary paradigms, we introduces Text2VectorSQL, a novel\nframework unifying Text-to-SQL and vector search to overcome expressiveness\nconstraints and support more diverse and holistical natural language queries.\nSpecifically, Text2VectorSQL enables semantic filtering, multi-modal matching,\nand retrieval acceleration. For evaluation, we build vector index on\nappropriate columns, extend user queries with semantic search, and annotate\nground truths via an automatic pipeline with expert review. Furthermore, we\ndevelop dedicated Text2VectorSQL models with synthetic data, demonstrating\nsignificant performance improvements over baseline methods. Our work\nestablishes the foundation for the Text2VectorSQL task, paving the way for more\nversatile and intuitive database interfaces. The repository will be publicly\navailable at https://github.com/Open-DataFlow/Text2VectorSQL.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aText2VectorSQL\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u7ed3\u5408\u4e86Text-to-SQL\u548c\u5411\u91cf\u641c\u7d22\uff0c\u4ee5\u63d0\u9ad8\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7684\u8868\u8fbe\u80fd\u529b\u548c\u591a\u6837\u6027\u3002\u901a\u8fc7\u6784\u5efa\u5411\u91cf\u7d22\u5f15\u3001\u6269\u5c55\u7528\u6237\u67e5\u8be2\u4ee5\u53ca\u5f00\u53d1\u4e13\u7528\u6a21\u578b\uff0c\u6211\u4eec\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684VectorSQL\u5b9e\u73b0\u4ecd\u7136\u4e25\u91cd\u4f9d\u8d56\u624b\u52a8\u5236\u4f5c\uff0c\u5e76\u4e14\u7f3a\u4e4f\u5b9a\u5236\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5bfc\u81f4\u7406\u8bba\u6f5c\u529b\u4e0e\u5b9e\u9645\u90e8\u7f72\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5f25\u5408\u8fd9\u4e9b\u4e92\u8865\u8303\u5f0f\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86Text2VectorSQL\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7edf\u4e00\u4e86Text-to-SQL\u548c\u5411\u91cf\u641c\u7d22\uff0c\u4ee5\u514b\u670d\u8868\u8fbe\u6027\u9650\u5236\u5e76\u652f\u6301\u66f4\u591a\u6837\u5316\u548c\u5168\u9762\u7684\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u3002\u6b64\u5916\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u5411\u91cf\u7d22\u5f15\uff0c\u6269\u5c55\u4e86\u7528\u6237\u67e5\u8be2\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u7ba1\u9053\u4e0e\u4e13\u5bb6\u5ba1\u67e5\u6ce8\u91ca\u4e86\u771f\u5b9e\u6570\u636e\u3002\u8fd8\u5f00\u53d1\u4e86\u4e13\u95e8\u7684Text2VectorSQL\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u5408\u6210\u6570\u636e\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "result": "\u6211\u4eec\u5f00\u53d1\u7684\u4e13\u95e8Text2VectorSQL\u6a21\u578b\u5728\u57fa\u7ebf\u65b9\u6cd5\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u6211\u4eec\u7684\u5de5\u4f5c\u4e3aText2VectorSQL\u4efb\u52a1\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4e3a\u66f4\u7075\u6d3b\u548c\u76f4\u89c2\u7684\u6570\u636e\u5e93\u63a5\u53e3\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2506.23101", "pdf": "https://arxiv.org/pdf/2506.23101", "abs": "https://arxiv.org/abs/2506.23101", "authors": ["Yue Xu", "Wenjie Wang"], "title": "From Individuals to Interactions: Benchmarking Gender Bias in Multimodal Large Language Models from the Lens of Social Relationship", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) have shown impressive capabilities\nacross tasks involving both visual and textual modalities. However, growing\nconcerns remain about their potential to encode and amplify gender bias,\nparticularly in socially sensitive applications. Existing benchmarks\npredominantly evaluate bias in isolated scenarios, overlooking how bias may\nemerge subtly through interpersonal interactions. We fill this gap by going\nbeyond single-entity evaluation and instead focusing on a deeper examination of\nrelational and contextual gender bias in dual-individual interactions. We\nintroduce Genres, a novel benchmark designed to evaluate gender bias in MLLMs\nthrough the lens of social relationships in generated narratives. Genres\nassesses gender bias through a dual-character profile and narrative generation\ntask that captures rich interpersonal dynamics and supports a fine-grained bias\nevaluation suite across multiple dimensions. Experiments on both open- and\nclosed-source MLLMs reveal persistent, context-sensitive gender biases that are\nnot evident in single-character settings. Our findings underscore the\nimportance of relationship-aware benchmarks for diagnosing subtle,\ninteraction-driven gender bias in MLLMs and provide actionable insights for\nfuture bias mitigation.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Genres\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u7279\u522b\u662f\u5728\u53cc\u4eba\u4e92\u52a8\u4e2d\u7684\u5173\u7cfb\u6027\u548c\u60c5\u5883\u6027\u504f\u89c1\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5b58\u5728\u6301\u7eed\u7684\u3001\u4e0e\u60c5\u5883\u76f8\u5173\u7684\u6027\u522b\u504f\u89c1\uff0c\u8fd9\u5728\u5355\u89d2\u8272\u8bbe\u7f6e\u4e2d\u5e76\u4e0d\u660e\u663e\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5173\u7cfb\u611f\u77e5\u57fa\u51c6\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u504f\u89c1\u7f13\u89e3\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u8bc4\u4f30\u5b64\u7acb\u573a\u666f\u4e2d\u7684\u504f\u89c1\uff0c\u5ffd\u7565\u4e86\u504f\u89c1\u53ef\u80fd\u901a\u8fc7\u4eba\u9645\u4e92\u52a8\u5fae\u5999\u5730\u51fa\u73b0\u3002\u6211\u4eec\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\uff0c\u8d85\u8d8a\u4e86\u5355\u4e2a\u5b9e\u4f53\u7684\u8bc4\u4f30\uff0c\u800c\u662f\u6df1\u5165\u68c0\u67e5\u53cc\u4eba\u4e92\u52a8\u4e2d\u7684\u5173\u7cfb\u6027\u548c\u60c5\u5883\u6027\u6027\u522b\u504f\u89c1\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aGenres\u7684\u65b0\u57fa\u51c6\uff0c\u7528\u4e8e\u901a\u8fc7\u793e\u4f1a\u5173\u7cfb\u7684\u89c6\u89d2\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6027\u522b\u504f\u89c1\u3002Genres\u901a\u8fc7\u53cc\u89d2\u8272\u8d44\u6599\u548c\u53d9\u4e8b\u751f\u6210\u4efb\u52a1\u6765\u8bc4\u4f30\u6027\u522b\u504f\u89c1\uff0c\u6355\u6349\u4e30\u5bcc\u7684\u4e2a\u4eba\u95f4\u52a8\u6001\uff0c\u5e76\u652f\u6301\u8de8\u591a\u4e2a\u7ef4\u5ea6\u7684\u7ec6\u7c92\u5ea6\u504f\u89c1\u8bc4\u4f30\u5957\u4ef6\u3002", "result": "\u5bf9\u5f00\u653e\u6e90\u4ee3\u7801\u548c\u5c01\u95ed\u6e90\u4ee3\u7801\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9a8c\u63ed\u793a\u4e86\u6301\u7eed\u5b58\u5728\u7684\u3001\u4e0e\u60c5\u5883\u76f8\u5173\u7684\u6027\u522b\u504f\u89c1\uff0c\u8fd9\u4e9b\u504f\u89c1\u5728\u5355\u89d2\u8272\u8bbe\u7f6e\u4e2d\u5e76\u4e0d\u660e\u663e\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5173\u7cfb\u611f\u77e5\u57fa\u51c6\u5728\u8bca\u65ad\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u7ec6\u5fae\u4e92\u52a8\u9a71\u52a8\u6027\u522b\u504f\u89c1\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u504f\u89c1\u7f13\u89e3\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.23111", "pdf": "https://arxiv.org/pdf/2506.23111", "abs": "https://arxiv.org/abs/2506.23111", "authors": ["Janki Atul Nawale", "Mohammed Safi Ur Rahman Khan", "Janani D", "Mansi Gupta", "Danish Pruthi", "Mitesh M. Khapra"], "title": "FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes", "categories": ["cs.CL"], "comment": "Accepted in ACL 2025", "summary": "Existing studies on fairness are largely Western-focused, making them\ninadequate for culturally diverse countries such as India. To address this gap,\nwe introduce INDIC-BIAS, a comprehensive India-centric benchmark designed to\nevaluate fairness of LLMs across 85 identity groups encompassing diverse\ncastes, religions, regions, and tribes. We first consult domain experts to\ncurate over 1,800 socio-cultural topics spanning behaviors and situations,\nwhere biases and stereotypes are likely to emerge. Grounded in these topics, we\ngenerate and manually validate 20,000 real-world scenario templates to probe\nLLMs for fairness. We structure these templates into three evaluation tasks:\nplausibility, judgment, and generation. Our evaluation of 14 popular LLMs on\nthese tasks reveals strong negative biases against marginalized identities,\nwith models frequently reinforcing common stereotypes. Additionally, we find\nthat models struggle to mitigate bias even when explicitly asked to rationalize\ntheir decision. Our evaluation provides evidence of both allocative and\nrepresentational harms that current LLMs could cause towards Indian identities,\ncalling for a more cautious usage in practical applications. We release\nINDIC-BIAS as an open-source benchmark to advance research on benchmarking and\nmitigating biases and stereotypes in the Indian context.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86INDIC-BIAS\uff0c\u4e00\u4e2a\u9488\u5bf9\u5370\u5ea6\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u516c\u5e73\u6027\u8bc4\u4f30\u57fa\u51c6\u3002\u901a\u8fc7\u4e13\u5bb6\u54a8\u8be2\u548c\u60c5\u666f\u6a21\u677f\u751f\u6210\uff0c\u8bc4\u4f30\u53d1\u73b0\u5927\u591a\u6570\u6a21\u578b\u5b58\u5728\u5bf9\u8fb9\u7f18\u5316\u8eab\u4efd\u7684\u504f\u89c1\uff0c\u5e76\u4e14\u96be\u4ee5\u51cf\u8f7b\u8fd9\u79cd\u504f\u89c1\u3002", "motivation": "\u73b0\u6709\u7684\u5173\u4e8e\u516c\u5e73\u6027\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u897f\u65b9\uff0c\u8fd9\u4f7f\u5f97\u5b83\u4eec\u5bf9\u4e8e\u6587\u5316\u591a\u6837\u7684\u56fd\u5bb6\u5982\u5370\u5ea6\u6765\u8bf4\u662f\u4e0d\u5145\u5206\u7684\u3002\u4e3a\u4e86\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u6211\u4eec\u5f15\u5165\u4e86INDIC-BIAS\uff0c\u8fd9\u662f\u4e00\u4e2a\u5168\u9762\u7684\u5370\u5ea6\u4e2d\u5fc3\u57fa\u51c6\uff0c\u65e8\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u572885\u4e2a\u8eab\u4efd\u7fa4\u4f53\u4e2d\u7684\u516c\u5e73\u6027\uff0c\u8fd9\u4e9b\u7fa4\u4f53\u6db5\u76d6\u4e86\u4e0d\u540c\u7684\u79cd\u59d3\u3001\u5b97\u6559\u3001\u5730\u533a\u548c\u90e8\u843d\u3002", "method": "\u6211\u4eec\u9996\u5148\u54a8\u8be2\u9886\u57df\u4e13\u5bb6\uff0c\u6574\u7406\u4e86\u8d85\u8fc71800\u4e2a\u8de8\u884c\u4e3a\u548c\u60c5\u5883\u7684\u793e\u4f1a\u6587\u5316\u4e3b\u9898\uff0c\u8fd9\u4e9b\u4e3b\u9898\u5f88\u53ef\u80fd\u4f1a\u51fa\u73b0\u504f\u89c1\u548c\u523b\u677f\u5370\u8c61\u3002\u57fa\u4e8e\u8fd9\u4e9b\u4e3b\u9898\uff0c\u6211\u4eec\u751f\u6210\u5e76\u624b\u52a8\u9a8c\u8bc1\u4e8620,000\u4e2a\u73b0\u5b9e\u4e16\u754c\u7684\u60c5\u666f\u6a21\u677f\uff0c\u4ee5\u63a2\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u516c\u5e73\u6027\u3002\u6211\u4eec\u5c06\u8fd9\u4e9b\u6a21\u677f\u7ed3\u6784\u5316\u4e3a\u4e09\u4e2a\u8bc4\u4f30\u4efb\u52a1\uff1a\u5408\u7406\u6027\u3001\u5224\u65ad\u548c\u751f\u6210\u3002", "result": "\u6211\u4eec\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u5bf914\u4e2a\u6d41\u884c\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u63ed\u793a\u4e86\u5bf9\u8fb9\u7f18\u5316\u8eab\u4efd\u7684\u5f3a\u70c8\u8d1f\u9762\u504f\u89c1\uff0c\u6a21\u578b\u7ecf\u5e38\u5f3a\u5316\u5e38\u89c1\u7684\u523b\u677f\u5370\u8c61\u3002\u6b64\u5916\uff0c\u6211\u4eec\u53d1\u73b0\u5373\u4f7f\u660e\u786e\u8981\u6c42\u6a21\u578b\u4e3a\u5176\u51b3\u7b56\u8fdb\u884c\u7406\u6027\u5206\u6790\uff0c\u5b83\u4eec\u4e5f\u96be\u4ee5\u51cf\u8f7b\u504f\u89c1\u3002", "conclusion": "\u6211\u4eec\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u5bf9\u5370\u5ea6\u8eab\u4efd\u9020\u6210\u5206\u914d\u6027\u548c\u4ee3\u8868\u6027\u4f24\u5bb3\u7684\u8bc1\u636e\uff0c\u547c\u5401\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u52a0\u8c28\u614e\u5730\u4f7f\u7528\u5b83\u4eec\u3002\u6211\u4eec\u53d1\u5e03\u4e86INDIC-BIAS\u4f5c\u4e3a\u4e00\u4e2a\u5f00\u6e90\u57fa\u51c6\uff0c\u4ee5\u4fc3\u8fdb\u5728\u5370\u5ea6\u80cc\u666f\u4e0b\u57fa\u51c6\u6d4b\u8bd5\u548c\u51cf\u8f7b\u504f\u89c1\u548c\u523b\u677f\u5370\u8c61\u7684\u7814\u7a76\u3002"}}
{"id": "2506.23122", "pdf": "https://arxiv.org/pdf/2506.23122", "abs": "https://arxiv.org/abs/2506.23122", "authors": ["Shivam Sharma", "Tanmoy Chakraborty"], "title": "Decoding Memes: Benchmarking Narrative Role Classification across Multilingual and Multimodal Models", "categories": ["cs.CL", "cs.CY"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "This work investigates the challenging task of identifying narrative roles -\nHero, Villain, Victim, and Other - in Internet memes, across three diverse test\nsets spanning English and code-mixed (English-Hindi) languages. Building on an\nannotated dataset originally skewed toward the 'Other' class, we explore a more\nbalanced and linguistically diverse extension, originally introduced as part of\nthe CLEF 2024 shared task. Comprehensive lexical and structural analyses\nhighlight the nuanced, culture-specific, and context-rich language used in real\nmemes, in contrast to synthetically curated hateful content, which exhibits\nexplicit and repetitive lexical markers. To benchmark the role detection task,\nwe evaluate a wide spectrum of models, including fine-tuned multilingual\ntransformers, sentiment and abuse-aware classifiers, instruction-tuned LLMs,\nand multimodal vision-language models. Performance is assessed under zero-shot\nsettings using precision, recall, and F1 metrics. While larger models like\nDeBERTa-v3 and Qwen2.5-VL demonstrate notable gains, results reveal consistent\nchallenges in reliably identifying the 'Victim' class and generalising across\ncultural and code-mixed content. We also explore prompt design strategies to\nguide multimodal models and find that hybrid prompts incorporating structured\ninstructions and role definitions offer marginal yet consistent improvements.\nOur findings underscore the importance of cultural grounding, prompt\nengineering, and multimodal reasoning in modelling subtle narrative framings in\nvisual-textual content.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u4e92\u8054\u7f51\u8ff7\u56e0\u4e2d\u8bc6\u522b\u53d9\u8ff0\u89d2\u8272\u7684\u4efb\u52a1\uff0c\u5e76\u8bc4\u4f30\u4e86\u591a\u79cd\u6a21\u578b\u7684\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u6587\u5316\u80cc\u666f\u3001\u63d0\u793a\u5de5\u7a0b\u548c\u591a\u6a21\u6001\u63a8\u7406\u5bf9\u4e8e\u5efa\u6a21\u89c6\u89c9-\u6587\u672c\u5185\u5bb9\u4e2d\u7684\u7ec6\u5fae\u53d9\u4e8b\u6846\u67b6\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u8fd9\u9879\u5de5\u4f5c\u7814\u7a76\u4e86\u5728\u4e92\u8054\u7f51\u8ff7\u56e0\u4e2d\u8bc6\u522b\u53d9\u8ff0\u89d2\u8272\uff08\u82f1\u96c4\u3001\u53cd\u6d3e\u3001\u53d7\u5bb3\u8005\u548c\u5176\u4ed6\uff09\u7684\u6311\u6218\u6027\u4efb\u52a1\u3002", "method": "\u6211\u4eec\u8bc4\u4f30\u4e86\u5e7f\u6cdb\u7684\u6a21\u578b\uff0c\u5305\u62ec\u5fae\u8c03\u7684\u591a\u8bed\u8a00\u53d8\u538b\u5668\u3001\u60c5\u611f\u548c\u4ec7\u6068\u610f\u8bc6\u5206\u7c7b\u5668\u3001\u6307\u4ee4\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u3002\u6211\u4eec\u8fd8\u63a2\u7d22\u4e86\u63d0\u793a\u8bbe\u8ba1\u7b56\u7565\u6765\u6307\u5bfc\u591a\u6a21\u6001\u6a21\u578b\u3002", "result": "\u8f83\u5927\u7684\u6a21\u578b\u5982DeBERTa-v3\u548cQwen2.5-VL\u8868\u73b0\u51fa\u663e\u8457\u7684\u63d0\u5347\uff0c\u4f46\u7ed3\u679c\u63ed\u793a\u4e86\u5728\u53ef\u9760\u8bc6\u522b'\u53d7\u5bb3\u8005'\u7c7b\u522b\u548c\u8de8\u6587\u5316\u548c\u4ee3\u7801\u6df7\u5408\u5185\u5bb9\u8fdb\u884c\u6cdb\u5316\u65b9\u9762\u7684\u4e00\u81f4\u6311\u6218\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u5f3a\u8c03\u4e86\u6587\u5316\u80cc\u666f\u3001\u63d0\u793a\u5de5\u7a0b\u548c\u591a\u6a21\u6001\u63a8\u7406\u5728\u5efa\u6a21\u89c6\u89c9-\u6587\u672c\u5185\u5bb9\u4e2d\u7684\u7ec6\u5fae\u53d9\u4e8b\u6846\u67b6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.23127", "pdf": "https://arxiv.org/pdf/2506.23127", "abs": "https://arxiv.org/abs/2506.23127", "authors": ["Zhaoye Fei", "Li Ji", "Siyin Wang", "Junhao Shi", "Jingjing Gong", "Xipeng Qiu"], "title": "Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, yet they face significant challenges in embodied task planning\nscenarios that require continuous environmental understanding and action\ngeneration. Existing approaches generate open-loop action scripts based on\nstatic knowledge, making it difficult to learn causal relationships between\nactions and environmental feedback, particularly in partially observable\nenvironments. We introduce Embodied Planner-R1, a novel outcome-driven\nreinforcement learning framework that enables LLMs to develop interactive\ncapabilities through autonomous exploration with minimal supervision. Our\nframework incorporates three key innovations: (1) Without human annotations, we\nemploy pure reinforcement learning with group rollout, incorporating\nin-environment interaction through parallel exploration; (2) completion-driven\nsparse reward; and (3) Interactive Policy Optimization (IPO) for efficient\nlearning from grouped trajectories. Across two challenging text-based Embodied\nplanning benchmarks, Embodied Planner-R1 achieves impressive completion rates\nof 97.78% on ALFWorld and 79.92% on ScienceWorld, surpassing prior methods by a\nlarge margin, and suffers only a -3.66% drop in previously unseen environments,\nevidencing strong generalization.", "AI": {"tldr": "Embodied Planner-R1 is a novel outcome-driven reinforcement learning framework that enables LLMs to develop interactive capabilities through autonomous exploration with minimal supervision, achieving impressive results on text-based Embodied planning benchmarks.", "motivation": "Existing approaches generate open-loop action scripts based on static knowledge, making it difficult to learn causal relationships between actions and environmental feedback, particularly in partially observable environments.", "method": "Embodied Planner-R1 is a novel outcome-driven reinforcement learning framework that enables LLMs to develop interactive capabilities through autonomous exploration with minimal supervision. It incorporates three key innovations: pure reinforcement learning with group rollout, completion-driven sparse reward, and Interactive Policy Optimization (IPO) for efficient learning from grouped trajectories.", "result": "Embodied Planner-R1 achieves impressive completion rates of 97.78% on ALFWorld and 79.92% on ScienceWorld, surpassing prior methods by a large margin, and suffers only a -3.66% drop in previously unseen environments.", "conclusion": "Embodied Planner-R1 demonstrates strong generalization and achieves impressive completion rates on two text-based Embodied planning benchmarks, surpassing prior methods."}}
{"id": "2506.23133", "pdf": "https://arxiv.org/pdf/2506.23133", "abs": "https://arxiv.org/abs/2506.23133", "authors": ["Dingzirui Wang", "Xuanliang Zhang", "Rongyu Cao", "Longxu Dou", "Xianzhen Luo", "Yingwei Ma", "Qingfu Zhu", "Wanxiang Che", "Binhua Li", "Fei Huang", "Yongbin Li"], "title": "Format-Adapter: Improving Reasoning Capability of LLMs by Adapting Suitable Format", "categories": ["cs.CL"], "comment": null, "summary": "Generating and voting multiple answers is an effective method to mitigate\nreasoning inconsistencies of large language models (LLMs). Prior works have\nshown that multiple reasoning formats outperform a single format when\ngenerating multiple answers. However, previous works using multiple formats\nrely on formats labeled by humans, which could be unsuitable for all tasks and\nhave high labeling costs. To address this issue, we adapt suitable formats to\nthe given tasks by generating and selecting formats. We first propose how to\nmeasure the reasoning error when generating multiple answers. Then, we\nintroduce Format-Adapter, which utilizes LLMs to generate and select suitable\nreasoning formats by minimizing the error measurement we present. We conduct\nexperiments on math and commonsense reasoning tasks, where Format-Adapter\nachieves a 4.3% performance improvement on average over previous works,\ndemonstrating the effectiveness.", "AI": {"tldr": "This paper proposes Format-Adapter, which generates and selects suitable reasoning formats to mitigate reasoning inconsistencies of large language models (LLMs). It achieves a 4.3% performance improvement on average over previous works.", "motivation": "Prior works using multiple formats rely on formats labeled by humans, which could be unsuitable for all tasks and have high labeling costs.", "method": "We adapt suitable formats to the given tasks by generating and selecting formats. We first propose how to measure the reasoning error when generating multiple answers. Then, we introduce Format-Adapter, which utilizes LLMs to generate and select suitable reasoning formats by minimizing the error measurement we present.", "result": "Format-Adapter achieves a 4.3% performance improvement on average over previous works.", "conclusion": "Format-Adapter achieves a 4.3% performance improvement on average over previous works, demonstrating the effectiveness."}}
{"id": "2506.23136", "pdf": "https://arxiv.org/pdf/2506.23136", "abs": "https://arxiv.org/abs/2506.23136", "authors": ["Shadman Sobhan", "Mohammad Ariful Haque"], "title": "LLM-Assisted Question-Answering on Technical Documents Using Structured Data-Aware Retrieval Augmented Generation", "categories": ["cs.CL"], "comment": "29 Pages, 11 Tables", "summary": "Large Language Models (LLMs) are capable of natural language understanding\nand generation. But they face challenges such as hallucination and outdated\nknowledge. Fine-tuning is one possible solution, but it is resource-intensive\nand must be repeated with every data update. Retrieval-Augmented Generation\n(RAG) offers an efficient solution by allowing LLMs to access external\nknowledge sources. However, traditional RAG pipelines struggle with retrieving\ninformation from complex technical documents with structured data such as\ntables and images. In this work, we propose a RAG pipeline, capable of handling\ntables and images in documents, for technical documents that support both\nscanned and searchable formats. Its retrieval process combines vector\nsimilarity search with a fine-tuned reranker based on Gemma-2-9b-it. The\nreranker is trained using RAFT (Retrieval-Augmented Fine-Tuning) on a custom\ndataset designed to improve context identification for question answering. Our\nevaluation demonstrates that the proposed pipeline achieves a high faithfulness\nscore of 94% (RAGas) and 96% (DeepEval), and an answer relevancy score of 87%\n(RAGas) and 93% (DeepEval). Comparative analysis demonstrates that the proposed\narchitecture is superior to general RAG pipelines in terms of table-based\nquestions and handling questions outside context.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684RAG\u7ba1\u9053\uff0c\u53ef\u4ee5\u5904\u7406\u5305\u542b\u8868\u683c\u548c\u56fe\u50cf\u7684\u6280\u672f\u6587\u6863\uff0c\u63d0\u9ad8\u4e86\u7b54\u6848\u7684\u5fe0\u5b9e\u5ea6\u548c\u76f8\u5173\u6027\u3002", "motivation": "\u4f20\u7edfRAG\u6d41\u6c34\u7ebf\u5728\u4ece\u5305\u542b\u7ed3\u6784\u5316\u6570\u636e\uff08\u5982\u8868\u683c\u548c\u56fe\u50cf\uff09\u7684\u6280\u672f\u6587\u6863\u4e2d\u68c0\u7d22\u4fe1\u606f\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u5411\u91cf\u76f8\u4f3c\u6027\u641c\u7d22\u548c\u57fa\u4e8eGemma-2-9b-it\u7684\u5fae\u8c03\u91cd\u6392\u5e8f\u5668\uff0c\u4f7f\u7528RAFT\uff08\u68c0\u7d22\u589e\u5f3a\u5fae\u8c03\uff09\u5728\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u63d0\u9ad8\u4e0a\u4e0b\u6587\u8bc6\u522b\u80fd\u529b\u3002", "result": "\u8be5\u7ba1\u9053\u5728RAGas\u548cDeepEval\u8bc4\u4f30\u4e2d\u5206\u522b\u83b7\u5f97\u4e8694%\u548c96%\u7684\u9ad8\u5fe0\u5b9e\u5ea6\u5206\u6570\uff0c\u4ee5\u53ca87%\u548c93%\u7684\u7b54\u6848\u76f8\u5173\u6027\u5206\u6570\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684RAG\u7ba1\u9053\u5728\u5904\u7406\u5305\u542b\u8868\u683c\u548c\u56fe\u50cf\u7684\u6280\u672f\u6587\u6863\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u63d0\u9ad8\u7b54\u6848\u7684\u5fe0\u5b9e\u5ea6\u548c\u76f8\u5173\u6027\u3002"}}
{"id": "2506.23137", "pdf": "https://arxiv.org/pdf/2506.23137", "abs": "https://arxiv.org/abs/2506.23137", "authors": ["Siyuan Li", "Ruitong Liu", "Yan Wen", "Te Sun"], "title": "Flow-Modulated Scoring for Semantic-Aware Knowledge Graph Completion", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages", "summary": "Effective modeling of multifaceted relations is pivotal for Knowledge Graph\nCompletion (KGC). However, a majority of existing approaches are predicated on\nstatic, embedding-based scoring, exhibiting inherent limitations in capturing\ncontextual dependencies and relational dynamics. Addressing this gap, we\npropose the Flow-Modulated Scoring (FMS) framework. FMS comprises two principal\ncomponents: (1) a semantic context learning module that encodes\ncontext-sensitive entity representations, and (2) a conditional flow-matching\nmodule designed to learn the dynamic transformation from a head to a tail\nembedding, governed by the aforementioned context. The resultant predictive\nvector field, representing the context-informed relational path, serves to\ndynamically refine the initial static score of an entity pair. Through this\nsynergy of context-aware static representations and conditioned dynamic\ninformation, FMS facilitates a more profound modeling of relational semantics.\nComprehensive evaluations on several standard benchmarks demonstrate that our\nproposed method surpasses prior state-of-the-art results.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Flow-Modulated Scoring (FMS)\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u9759\u6001\u8868\u793a\u548c\u6761\u4ef6\u52a8\u6001\u4fe1\u606f\uff0c\u5b9e\u73b0\u66f4\u6df1\u5c42\u6b21\u7684\u5173\u7cfb\u8bed\u4e49\u5efa\u6a21\uff0c\u5e76\u5728\u591a\u4e2a\u6807\u51c6\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u591a\u6570\u65b9\u6cd5\u57fa\u4e8e\u9759\u6001\u5d4c\u5165\u8bc4\u5206\uff0c\u5b58\u5728\u65e0\u6cd5\u6355\u6349\u4e0a\u4e0b\u6587\u4f9d\u8d56\u548c\u5173\u7cfb\u52a8\u6001\u7684\u56fa\u6709\u5c40\u9650\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "FMS\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u7ec4\u4ef6\uff1a(1) \u8bed\u4e49\u4e0a\u4e0b\u6587\u5b66\u4e60\u6a21\u5757\uff0c\u7528\u4e8e\u7f16\u7801\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u5b9e\u4f53\u8868\u793a\uff1b(2) \u6761\u4ef6\u6d41\u5339\u914d\u6a21\u5757\uff0c\u65e8\u5728\u5b66\u4e60\u4ece\u5934\u5230\u5c3e\u5d4c\u5165\u7684\u52a8\u6001\u53d8\u6362\uff0c\u7531\u4e0a\u8ff0\u4e0a\u4e0b\u6587\u63a7\u5236\u3002", "result": "FMS\u5728\u591a\u4e2a\u6807\u51c6\u57fa\u51c6\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u8d85\u8d8a\u4e86\u4e4b\u524d\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "FMS\u901a\u8fc7\u7ed3\u5408\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u9759\u6001\u8868\u793a\u548c\u6761\u4ef6\u52a8\u6001\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u66f4\u6df1\u5c42\u6b21\u7684\u5173\u7cfb\u8bed\u4e49\u5efa\u6a21\uff0c\u5e76\u5728\u591a\u4e2a\u6807\u51c6\u57fa\u51c6\u4e0a\u8d85\u8d8a\u4e86\u4e4b\u524d\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002"}}
{"id": "2506.23139", "pdf": "https://arxiv.org/pdf/2506.23139", "abs": "https://arxiv.org/abs/2506.23139", "authors": ["Prafulla Kumar Choubey", "Xiangyu Peng", "Shilpa Bhagavath", "Kung-Hsiang Huang", "Caiming Xiong", "Chien-Sheng Wu"], "title": "Benchmarking Deep Search over Heterogeneous Enterprise Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present a new benchmark for evaluating Deep Search--a realistic and\ncomplex form of retrieval-augmented generation (RAG) that requires\nsource-aware, multi-hop reasoning over diverse, sparsed, but related sources.\nThese include documents, meeting transcripts, Slack messages, GitHub, and URLs,\nwhich vary in structure and often contain human-to-human interactions. We build\nit using a synthetic data pipeline that simulates business workflows across\nproduct planning, development, and support stages, generating interconnected\ncontent with realistic noise and multi-hop questions with guaranteed\nground-truth answers. We release our benchmark with both answerable and\nunanswerable queries, and retrieval pool of 39,190 enterprise artifacts,\nenabling fine-grained evaluation of long-context LLM and RAG systems. Our\nexperiments reveal that even the best-performing agentic RAG methods achieve an\naverage performance score of 32.96 on our benchmark. With further analysis, we\nhighlight retrieval as the main bottleneck: existing methods struggle to\nconduct deep searches and retrieve all necessary evidence. Consequently, they\noften reason over partial context, leading to significant performance\ndegradation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u6df1\u5ea6\u641c\u7d22\u2014\u2014\u4e00\u79cd\u73b0\u5b9e\u4e14\u590d\u6742\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5f62\u5f0f\uff0c\u9700\u8981\u5bf9\u591a\u6837\u3001\u7a00\u758f\u4f46\u76f8\u5173\u7684\u6765\u6e90\u8fdb\u884c\u6e90\u611f\u77e5\u548c\u591a\u8df3\u63a8\u7406\u3002\u6211\u4eec\u4f7f\u7528\u5408\u6210\u6570\u636e\u7ba1\u9053\u6784\u5efa\u4e86\u8fd9\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6a21\u62df\u4e86\u4ea7\u54c1\u89c4\u5212\u3001\u5f00\u53d1\u548c\u652f\u6301\u9636\u6bb5\u7684\u4e1a\u52a1\u5de5\u4f5c\u6d41\u7a0b\uff0c\u751f\u6210\u5177\u6709\u73b0\u5b9e\u566a\u58f0\u548c\u4fdd\u8bc1\u771f\u5b9e\u7b54\u6848\u7684\u591a\u8df3\u95ee\u9898\u7684\u76f8\u4e92\u5173\u8054\u5185\u5bb9\u3002\u6211\u4eec\u53d1\u5e03\u4e86\u5305\u542b\u53ef\u56de\u7b54\u548c\u4e0d\u53ef\u56de\u7b54\u67e5\u8be2\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u53ca\u5305\u542b39,190\u4e2a\u4f01\u4e1a\u5de5\u4ef6\u7684\u68c0\u7d22\u6c60\uff0c\u4f7f\u957f\u4e0a\u4e0b\u6587LLM\u548cRAG\u7cfb\u7edf\u7684\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6210\u4e3a\u53ef\u80fd\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u4ee3\u7406RAG\u65b9\u6cd5\u5728\u6211\u4eec\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u6027\u80fd\u5f97\u5206\u4e3a32.96\u3002\u901a\u8fc7\u8fdb\u4e00\u6b65\u5206\u6790\uff0c\u6211\u4eec\u5f3a\u8c03\u4e86\u68c0\u7d22\u662f\u4e3b\u8981\u74f6\u9888\uff1a\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u8fdb\u884c\u6df1\u5ea6\u641c\u7d22\u5e76\u68c0\u7d22\u6240\u6709\u5fc5\u8981\u7684\u8bc1\u636e\u3002\u56e0\u6b64\uff0c\u5b83\u4eec\u5e38\u5e38\u57fa\u4e8e\u90e8\u5206\u4e0a\u4e0b\u6587\u8fdb\u884c\u63a8\u7406\uff0c\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "motivation": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u6df1\u5ea6\u641c\u7d22\u2014\u2014\u4e00\u79cd\u73b0\u5b9e\u4e14\u590d\u6742\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5f62\u5f0f\uff0c\u9700\u8981\u5bf9\u591a\u6837\u3001\u7a00\u758f\u4f46\u76f8\u5173\u7684\u6765\u6e90\u8fdb\u884c\u6e90\u611f\u77e5\u548c\u591a\u8df3\u63a8\u7406\u3002\u8fd9\u4e9b\u5305\u62ec\u6587\u6863\u3001\u4f1a\u8bae\u8bb0\u5f55\u3001Slack\u6d88\u606f\u3001GitHub\u548cURL\uff0c\u5b83\u4eec\u7684\u7ed3\u6784\u5404\u4e0d\u76f8\u540c\uff0c\u901a\u5e38\u5305\u542b\u4eba\u4e0e\u4eba\u4e4b\u95f4\u7684\u4e92\u52a8\u3002", "method": "\u6211\u4eec\u4f7f\u7528\u5408\u6210\u6570\u636e\u7ba1\u9053\u6784\u5efa\u4e86\u8fd9\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8be5\u7ba1\u9053\u6a21\u62df\u4e86\u4ea7\u54c1\u89c4\u5212\u3001\u5f00\u53d1\u548c\u652f\u6301\u9636\u6bb5\u7684\u4e1a\u52a1\u5de5\u4f5c\u6d41\u7a0b\uff0c\u751f\u6210\u5177\u6709\u73b0\u5b9e\u566a\u58f0\u548c\u4fdd\u8bc1\u771f\u5b9e\u7b54\u6848\u7684\u591a\u8df3\u95ee\u9898\u7684\u76f8\u4e92\u5173\u8054\u5185\u5bb9\u3002", "result": "\u6211\u4eec\u53d1\u5e03\u4e86\u5305\u542b\u53ef\u56de\u7b54\u548c\u4e0d\u53ef\u56de\u7b54\u67e5\u8be2\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u53ca\u5305\u542b39,190\u4e2a\u4f01\u4e1a\u5de5\u4ef6\u7684\u68c0\u7d22\u6c60\uff0c\u4f7f\u957f\u4e0a\u4e0b\u6587LLM\u548cRAG\u7cfb\u7edf\u7684\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6210\u4e3a\u53ef\u80fd\u3002", "conclusion": "\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u4ee3\u7406RAG\u65b9\u6cd5\u5728\u6211\u4eec\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u6027\u80fd\u5f97\u5206\u4e3a32.96\u3002\u901a\u8fc7\u8fdb\u4e00\u6b65\u5206\u6790\uff0c\u6211\u4eec\u5f3a\u8c03\u4e86\u68c0\u7d22\u662f\u4e3b\u8981\u74f6\u9888\uff1a\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u8fdb\u884c\u6df1\u5ea6\u641c\u7d22\u5e76\u68c0\u7d22\u6240\u6709\u5fc5\u8981\u7684\u8bc1\u636e\u3002\u56e0\u6b64\uff0c\u5b83\u4eec\u5e38\u5e38\u57fa\u4e8e\u90e8\u5206\u4e0a\u4e0b\u6587\u8fdb\u884c\u63a8\u7406\uff0c\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002"}}
{"id": "2506.23146", "pdf": "https://arxiv.org/pdf/2506.23146", "abs": "https://arxiv.org/abs/2506.23146", "authors": ["Dingzriui Wang", "Xuanliang Zhang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che", "Yang Deng"], "title": "Learning-to-Context Slope: Evaluating In-Context Learning Effectiveness Beyond Performance Illusions", "categories": ["cs.CL"], "comment": null, "summary": "In-context learning (ICL) has emerged as an effective approach to enhance the\nperformance of large language models (LLMs). However, its effectiveness varies\nsignificantly across models and tasks, posing challenges for practitioners to\ndetermine when ICL reliably improves performance. Current evaluation\napproaches, reliant on performance change after applying ICL, suffer from low\nreliability, poor attribution, and impracticality in data-insufficient\nscenarios. We propose the Learning-to-Context Slope (LCS), a novel metric that\nquantifies ICL effectiveness by modeling the slope between learning gain (loss\ndecrease from demonstrations) and contextual relevance (demonstration-input\nrelevance). LCS addresses key limitations of performance-based metrics: (1) it\ncaptures continuous loss changes even when outputs are incorrect, improving\nreliability; (2) its formulation attributes ICL failures to weak contextual\nalignment (inability to adapt inputs to demonstrations) or strong output\ncalibration (self-verification of correctness); and (3) it minimizes reliance\non labeled data via synthetic evaluation. Extensive experiments demonstrate\nthat LCS strongly correlates with performance improvements in labeled settings\nand reliably reflects true effectiveness in biased or data-scarce scenarios.\nFurther analysis reveals actionable thresholds for LCS and identifies model\ncapabilities critical to ICL success.", "AI": {"tldr": "The paper proposes LCS, a novel metric for evaluating ICL effectiveness, which addresses limitations of current approaches and shows strong correlation with performance improvements.", "motivation": "Current evaluation approaches for ICL are unreliable, have poor attribution, and are impractical in data-insufficient scenarios. LCS aims to address these limitations.", "method": "The Learning-to-Context Slope (LCS) metric is proposed, which quantifies ICL effectiveness by modeling the slope between learning gain and contextual relevance.", "result": "Extensive experiments show that LCS strongly correlates with performance improvements in labeled settings and reliably reflects true effectiveness in biased or data-scarce scenarios.", "conclusion": "LCS is a reliable metric for evaluating ICL effectiveness and provides actionable thresholds for model capabilities critical to ICL success."}}
{"id": "2506.23149", "pdf": "https://arxiv.org/pdf/2506.23149", "abs": "https://arxiv.org/abs/2506.23149", "authors": ["Dingzirui Wang", "Xuanliang Zhang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che", "Yang Deng"], "title": "V-SYNTHESIS: Task-Agnostic Synthesis of Consistent and Diverse In-Context Demonstrations from Scratch via V-Entropy", "categories": ["cs.CL"], "comment": null, "summary": "High labeling cost for in-context learning (ICL) demonstrations motivates\nusing large language models (LLMs) for synthesis to reduce overhead. However,\nexisting synthesis methods are mainly task-specific or rely on pre-existing\ndemonstrations. So this paper focuses on synthesizing demonstrations from\nscratch for arbitrary tasks. A major challenge in synthesizing from scratch is\nensuring consistency with the target task, as the lack of labeling guidance\ncould lead to synthesis bias. We first propose a consistency metric called\nV-Score, which has higher performance and lower computation cost compared with\nthe metrics based on grams or embedding vectors. Furthermore, we introduce\nV-Synthesis, which leverages V-Score for proportional sampling to ensure both\nhigh consistency and diversity of synthesized demonstrations. Experimental\nresults demonstrate that V-Synthesis yields an average performance improvement\nof 2.0% compared to existing synthesis methods confirming the effectiveness of\nV-Synthesis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5408\u6210\u65b9\u6cd5V-Synthesis\uff0c\u901a\u8fc7\u5f15\u5165V-Score\u5ea6\u91cf\u6765\u63d0\u9ad8\u5408\u6210\u793a\u4f8b\u7684\u4e00\u81f4\u6027\u548c\u591a\u6837\u6027\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u9ad8\u6807\u6ce8\u6210\u672c\u4fc3\u4f7f\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u5408\u6210\u4ee5\u51cf\u5c11\u5f00\u9500\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u5408\u6210\u65b9\u6cd5\u4e3b\u8981\u662f\u4efb\u52a1\u7279\u5b9a\u7684\u6216\u4f9d\u8d56\u4e8e\u9884\u5b58\u5728\u7684\u793a\u4f8b\u3002\u56e0\u6b64\uff0c\u672c\u6587\u4e13\u6ce8\u4e8e\u4ece\u5934\u5f00\u59cb\u4e3a\u4efb\u610f\u4efb\u52a1\u5408\u6210\u793a\u4f8b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u79f0\u4e3aV-Score\u7684\u4e00\u81f4\u6027\u5ea6\u91cf\uff0c\u5e76\u5f15\u5165\u4e86V-Synthesis\uff0c\u5229\u7528V-Score\u8fdb\u884c\u6bd4\u4f8b\u91c7\u6837\u4ee5\u786e\u4fdd\u5408\u6210\u793a\u4f8b\u7684\u4e00\u81f4\u6027\u548c\u591a\u6837\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cV-Synthesis\u76f8\u6bd4\u73b0\u6709\u5408\u6210\u65b9\u6cd5\u5e73\u5747\u6027\u80fd\u63d0\u9ad8\u4e862.0%\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cV-Synthesis\u76f8\u6bd4\u73b0\u6709\u5408\u6210\u65b9\u6cd5\u5e73\u5747\u6027\u80fd\u63d0\u9ad8\u4e862.0%\uff0c\u8bc1\u5b9e\u4e86V-Synthesis\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.23192", "pdf": "https://arxiv.org/pdf/2506.23192", "abs": "https://arxiv.org/abs/2506.23192", "authors": ["Gabriel Iturra-Bocaz", "Felipe Bravo-Marquez"], "title": "RiverText: A Python Library for Training and Evaluating Incremental Word Embeddings from Text Data Streams", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted at SIGIR'23", "summary": "Word embeddings have become essential components in various information\nretrieval and natural language processing tasks, such as ranking, document\nclassification, and question answering. However, despite their widespread use,\ntraditional word embedding models present a limitation in their static nature,\nwhich hampers their ability to adapt to the constantly evolving language\npatterns that emerge in sources such as social media and the web (e.g., new\nhashtags or brand names). To overcome this problem, incremental word embedding\nalgorithms are introduced, capable of dynamically updating word representations\nin response to new language patterns and processing continuous data streams.\n  This paper presents RiverText, a Python library for training and evaluating\nincremental word embeddings from text data streams. Our tool is a resource for\nthe information retrieval and natural language processing communities that work\nwith word embeddings in streaming scenarios, such as analyzing social media.\nThe library implements different incremental word embedding techniques, such as\nSkip-gram, Continuous Bag of Words, and Word Context Matrix, in a standardized\nframework. In addition, it uses PyTorch as its backend for neural network\ntraining. We have implemented a module that adapts existing intrinsic static\nword embedding evaluation tasks for word similarity and word categorization to\na streaming setting. Finally, we compare the implemented methods with different\nhyperparameter settings and discuss the results. Our open-source library is\navailable at https://github.com/dccuchile/rivertext.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aRiverText\u7684Python\u5e93\uff0c\u7528\u4e8e\u4ece\u6587\u672c\u6570\u636e\u6d41\u4e2d\u8bad\u7ec3\u548c\u8bc4\u4f30\u589e\u91cf\u8bcd\u5d4c\u5165\u3002\u8be5\u5de5\u5177\u5b9e\u73b0\u4e86\u591a\u79cd\u589e\u91cf\u8bcd\u5d4c\u5165\u6280\u672f\uff0c\u5e76\u9002\u7528\u4e8e\u4fe1\u606f\u68c0\u7d22\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u4e2d\u7684\u6d41\u5f0f\u573a\u666f\u3002", "motivation": "\u4f20\u7edf\u8bcd\u5d4c\u5165\u6a21\u578b\u7531\u4e8e\u5176\u9759\u6001\u6027\u8d28\uff0c\u5728\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684\u8bed\u8a00\u6a21\u5f0f\uff08\u5982\u793e\u4ea4\u5a92\u4f53\u548c\u7f51\u7edc\u4e0a\u7684\u65b0\u6807\u7b7e\u6216\u54c1\u724c\u540d\u79f0\uff09\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u66f4\u65b0\u8bcd\u8868\u793a\u7684\u589e\u91cf\u8bcd\u5d4c\u5165\u7b97\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86RiverText\uff0c\u5b9e\u73b0\u4e86\u4e0d\u540c\u7684\u589e\u91cf\u8bcd\u5d4c\u5165\u6280\u672f\uff0c\u5982Skip-gram\u3001\u8fde\u7eed\u8bcd\u888b\u548c\u8bcd\u4e0a\u4e0b\u6587\u77e9\u9635\uff0c\u5e76\u4f7f\u7528PyTorch\u4f5c\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u7684\u540e\u7aef\u3002\u6b64\u5916\uff0c\u8fd8\u5b9e\u73b0\u4e86\u4e00\u4e2a\u6a21\u5757\uff0c\u5c06\u73b0\u6709\u7684\u9759\u6001\u8bcd\u5d4c\u5165\u8bc4\u4f30\u4efb\u52a1\u9002\u5e94\u5230\u6d41\u8bbe\u7f6e\u4e2d\u3002", "result": "\u672c\u6587\u6bd4\u8f83\u4e86\u4e0d\u540c\u8d85\u53c2\u6570\u8bbe\u7f6e\u4e0b\u7684\u5b9e\u73b0\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u7ed3\u679c\u3002\u5f00\u6e90\u5e93\u5df2\u53d1\u5e03\u5728GitHub\u4e0a\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86RiverText\uff0c\u4e00\u4e2a\u7528\u4e8e\u4ece\u6587\u672c\u6570\u636e\u6d41\u4e2d\u8bad\u7ec3\u548c\u8bc4\u4f30\u589e\u91cf\u8bcd\u5d4c\u5165\u7684Python\u5e93\u3002\u8be5\u5de5\u5177\u4e3a\u4fe1\u606f\u68c0\u7d22\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u793e\u533a\u63d0\u4f9b\u4e86\u8d44\u6e90\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u6d41\u5f0f\u573a\u666f\u4e2d\u7684\u8bcd\u5d4c\u5165\u65f6\u3002"}}
{"id": "2506.23235", "pdf": "https://arxiv.org/pdf/2506.23235", "abs": "https://arxiv.org/abs/2506.23235", "authors": ["Yi-Chen Li", "Tian Xu", "Yang Yu", "Xuqin Zhang", "Xiong-Hui Chen", "Zhongxiang Ling", "Ningjing Chao", "Lei Yuan", "Zhi-Hua Zhou"], "title": "Generalist Reward Models: Found Inside Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The alignment of Large Language Models (LLMs) is critically dependent on\nreward models trained on costly human preference data. While recent work\nexplores bypassing this cost with AI feedback, these methods often lack a\nrigorous theoretical foundation. In this paper, we discover that a powerful\ngeneralist reward model is already latently present within any LLM trained via\nstandard next-token prediction. We prove that this endogenous reward is not a\nheuristic, but is theoretically equivalent to a reward function learned through\noffline inverse reinforcement learning. This connection allows us to directly\nelicit a high-quality reward signal from a base (pre-trained or supervised\nfine-tuned) model without any further training. Critically, we also prove that\nsubsequent reinforcement learning using this endogenous reward leads to a\npolicy with a provably superior error bound compared to the base model. To our\nbest knowledge, this is the first theoretical proof of the effectiveness of\nreinforcement learning for LLMs. Our experiments validate this theory,\ndemonstrating that our method not only outperforms existing LLM-as-a-judge\napproaches but can also surpass explicitly trained reward models. These\nfindings suggest that the reward modeling stage can be replaced by a principled\nmethod of eliciting the knowledge already captured during pre-training,\nheralding a more efficient, powerful, and scalable paradigm for LLMs alignment\nas well as multi-modal models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u9690\u542b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u901a\u7528\u5956\u52b1\u6a21\u578b\uff0c\u53ef\u4ee5\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u76f4\u63a5\u4ece\u4e2d\u63d0\u53d6\u9ad8\u8d28\u91cf\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u800c\u65e0\u9700\u8fdb\u4e00\u6b65\u8bad\u7ec3\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u53ef\u80fd\u6539\u53d8\u5956\u52b1\u5efa\u6a21\u7684\u65b9\u5f0f\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u9f50\u4f9d\u8d56\u4e8e\u6602\u8d35\u7684\u4eba\u7c7b\u504f\u597d\u6570\u636e\u8bad\u7ec3\u7684\u5956\u52b1\u6a21\u578b\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u5c1d\u8bd5\u901a\u8fc7AI\u53cd\u9988\u6765\u907f\u514d\u8fd9\u79cd\u6210\u672c\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u7f3a\u4e4f\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u5956\u52b1\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u5185\u751f\u5956\u52b1\u4e0e\u79bb\u7ebf\u9006\u5f3a\u5316\u5b66\u4e60\u83b7\u5f97\u7684\u5956\u52b1\u51fd\u6570\u5728\u7406\u8bba\u4e0a\u662f\u7b49\u4ef7\u7684\uff0c\u5e76\u76f4\u63a5\u4ece\u57fa\u7840\u6a21\u578b\u4e2d\u63d0\u53d6\u9ad8\u8d28\u91cf\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u800c\u65e0\u9700\u8fdb\u4e00\u6b65\u8bad\u7ec3\u3002\u6b64\u5916\uff0c\u4f7f\u7528\u8fd9\u79cd\u5185\u751f\u5956\u52b1\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u4ea7\u751f\u66f4\u4f18\u7684\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7406\u8bba\uff0c\u5e76\u8868\u660e\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u4f18\u4e8e\u73b0\u6709\u7684LLM\u4f5c\u4e3a\u88c1\u5224\u7684\u65b9\u6cd5\uff0c\u8fd8\u53ef\u4ee5\u8d85\u8d8a\u663e\u5f0f\u8bad\u7ec3\u7684\u5956\u52b1\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u6807\u51c6\u7684\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u8bad\u7ec3\u7684\u4efb\u4f55\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u90fd\u9690\u542b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u901a\u7528\u5956\u52b1\u6a21\u578b\u3002\u8fd9\u79cd\u5185\u751f\u5956\u52b1\u7406\u8bba\u7b49\u4ef7\u4e8e\u901a\u8fc7\u79bb\u7ebf\u9006\u5f3a\u5316\u5b66\u4e60\u5b66\u4e60\u5230\u7684\u5956\u52b1\u51fd\u6570\uff0c\u4ece\u800c\u53ef\u4ee5\u76f4\u63a5\u4ece\u57fa\u7840\u6a21\u578b\u4e2d\u83b7\u53d6\u9ad8\u8d28\u91cf\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u800c\u65e0\u9700\u8fdb\u4e00\u6b65\u8bad\u7ec3\u3002\u6b64\u5916\uff0c\u4f7f\u7528\u8fd9\u79cd\u5185\u751f\u5956\u52b1\u8fdb\u884c\u540e\u7eed\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u4ea7\u751f\u6bd4\u57fa\u7840\u6a21\u578b\u66f4\u4f18\u7684\u7b56\u7565\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u7406\u8bba\uff0c\u5e76\u8868\u660e\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u4f18\u4e8e\u73b0\u6709\u7684LLM\u4f5c\u4e3a\u88c1\u5224\u7684\u65b9\u6cd5\uff0c\u8fd8\u53ef\u4ee5\u8d85\u8d8a\u663e\u5f0f\u8bad\u7ec3\u7684\u5956\u52b1\u6a21\u578b\u3002\u8fd9\u8868\u660e\u5956\u52b1\u5efa\u6a21\u9636\u6bb5\u53ef\u4ee5\u88ab\u4e00\u79cd\u57fa\u4e8e\u9884\u8bad\u7ec3\u77e5\u8bc6\u7684\u539f\u5219\u6027\u65b9\u6cd5\u6240\u53d6\u4ee3\uff0c\u4e3aLLM\u548c\u591a\u6a21\u6001\u6a21\u578b\u7684\u5bf9\u9f50\u5e26\u6765\u4e86\u66f4\u9ad8\u6548\u3001\u5f3a\u5927\u548c\u53ef\u6269\u5c55\u7684\u8303\u5f0f\u3002"}}
{"id": "2506.23288", "pdf": "https://arxiv.org/pdf/2506.23288", "abs": "https://arxiv.org/abs/2506.23288", "authors": ["Miguel Domingo", "Francisco Casacuberta"], "title": "Two Spelling Normalization Approaches Based on Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The absence of standardized spelling conventions and the organic evolution of\nhuman language present an inherent linguistic challenge within historical\ndocuments, a longstanding concern for scholars in the humanities. Addressing\nthis issue, spelling normalization endeavors to align a document's orthography\nwith contemporary standards. In this study, we propose two new approaches based\non large language models: one of which has been trained without a supervised\ntraining, and a second one which has been trained for machine translation. Our\nevaluation spans multiple datasets encompassing diverse languages and\nhistorical periods, leading us to the conclusion that while both of them\nyielded encouraging results, statistical machine translation still seems to be\nthe most suitable technology for this task.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u62fc\u5199\u89c4\u8303\u5316\u65b9\u6cd5\uff0c\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u7edf\u8ba1\u673a\u5668\u7ffb\u8bd1\u4ecd\u662f\u8be5\u4efb\u52a1\u6700\u5408\u9002\u7684\u6280\u8853\u3002", "motivation": "\u5386\u53f2\u6587\u732e\u4e2d\u7f3a\u4e4f\u6807\u51c6\u5316\u62fc\u5199\u89c4\u8303\u548c\u4eba\u7c7b\u8bed\u8a00\u7684\u6709\u673a\u6f14\u53d8\u5e26\u6765\u4e86\u56fa\u6709\u7684\u8bed\u8a00\u6311\u6218\uff0c\u8fd9\u662f\u4eba\u6587\u5b66\u79d1\u5b66\u8005\u957f\u671f\u4ee5\u6765\u5173\u6ce8\u7684\u95ee\u9898\u3002\u62fc\u5199\u89c4\u8303\u5316\u65e8\u5728\u4f7f\u6587\u6863\u7684\u6b63\u5b57\u6cd5\u4e0e\u73b0\u4ee3\u6807\u51c6\u4e00\u81f4\u3002", "method": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e24\u79cd\u65b0\u65b9\u6cd5\uff1a\u4e00\u79cd\u662f\u672a\u7ecf\u76d1\u7763\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u53e6\u4e00\u79cd\u662f\u7528\u4e8e\u673a\u5668\u7ffb\u8bd1\u7684\u65b9\u6cd5\u3002", "result": "\u5728\u6db5\u76d6\u591a\u79cd\u8bed\u8a00\u548c\u5386\u53f2\u65f6\u671f\u7684\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u8fd9\u4e24\u79cd\u65b9\u6cd5\u90fd\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\u3002", "conclusion": "\u7edf\u8ba1\u673a\u5668\u7ffb\u8bd1\u4f3c\u4e4e\u4ecd\u662f\u8be5\u4efb\u52a1\u6700\u5408\u9002\u7684\u6280\u8853\u3002"}}
{"id": "2506.23293", "pdf": "https://arxiv.org/pdf/2506.23293", "abs": "https://arxiv.org/abs/2506.23293", "authors": ["P. Myles Eugenio"], "title": "Objective-Free Local Learning and Emergent Language Structure in Thinking Machines", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-bio.NC"], "comment": "22 pages, 7 figures", "summary": "We present a neuro-symbolic framework for generative language modeling based\non local, event-driven emergent learning. At its core is a hierarchical\nHopfield memory chain acting as a compositional short-term memory and dynamic\ntokenizer (retokenizer). Rather than relying on predefined tokens or\nsupervision, the model builds structure from scratch, learning symbol sequences\nas multi-scale representations. It constructs projection tensors that bind\nco-occurring features into hierarchical tokens, introducing redundancy (i.e an\nemergent gauge structure) and enabling compression of local activations into\nlong-range dependencies. Curiously, we find that the retokenizer can filter\nnatural language patterns from noise, generating synthetic languages with\ncoherent internal morphology -- quantifiably the same as human language.\nLanguage is learned in a local (Hebbian) fashion, where model constraints\ndictate allowed emergent structure, and new information is retained in\nalignment with this structure. The absence of a global objective enables a form\nof plasticity not found in conventional language models, allowing the system to\ngeneralize beyond its initial inference class -- even without explicit data. We\ndemonstrate that briefly activating a new neuron during inference binds\ndistributed multi-scale token features into a symbolic embedding. These\nemergent embedding neurons act as long-term memory and support a key-value\nmechanism for compositional inference and generalization. This architecture\nprovides a methodological foundation for studying how symbolic structure can\nemerge from local neural learning. It offers a new pathway for building\nscalable, interpretable neuro-symbolic systems -- where tokens, grammar, and\nreasoning arise as compressed memory traces within a Hopfield hierarchy. This\napproach advances the development of neuromorphic architectures for generative\nlanguage models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u5229\u7528\u5206\u5c42\u970d\u666e\u83f2\u5c14\u5fb7\u8bb0\u5fc6\u94fe\u8fdb\u884c\u5c40\u90e8\u8bed\u8a00\u5efa\u6a21\uff0c\u80fd\u591f\u751f\u6210\u7c7b\u4f3c\u4eba\u7c7b\u8bed\u8a00\u7684\u5408\u6210\u8bed\u8a00\uff0c\u5e76\u5177\u5907\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u4f20\u7edf\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u4e8e\u9884\u5b9a\u4e49\u7684\u6807\u8bb0\u6216\u76d1\u7763\uff0c\u800c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u4ece\u96f6\u5f00\u59cb\u6784\u5efa\u7ed3\u6784\u6765\u5b66\u4e60\u7b26\u53f7\u5e8f\u5217\uff0c\u4ee5\u5b9e\u73b0\u66f4\u81ea\u7136\u7684\u8bed\u8a00\u5904\u7406\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u4e8b\u4ef6\u9a71\u52a8\u6d8c\u73b0\u5b66\u4e60\u7684\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u4e00\u4e2a\u5206\u5c42\u970d\u666e\u83f2\u5c14\u5fb7\u8bb0\u5fc6\u94fe\uff0c\u4f5c\u4e3a\u7ec4\u5408\u6027\u77ed\u65f6\u8bb0\u5fc6\u548c\u52a8\u6001\u5206\u8bcd\u5668\uff08\u91cd\u5206\u8bcd\u5668\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u91cd\u5206\u8bcd\u5668\u53ef\u4ee5\u8fc7\u6ee4\u81ea\u7136\u8bed\u8a00\u6a21\u5f0f\u5e76\u751f\u6210\u5177\u6709\u8fde\u8d2f\u5185\u90e8\u5f62\u6001\u7684\u5408\u6210\u8bed\u8a00\uff0c\u5176\u8868\u73b0\u4e0e\u4eba\u7c7b\u8bed\u8a00\u76f8\u5f53\u3002", "conclusion": "\u8be5\u67b6\u6784\u4e3a\u7814\u7a76\u7b26\u53f7\u7ed3\u6784\u5982\u4f55\u4ece\u5c40\u90e8\u795e\u7ecf\u5b66\u4e60\u4e2d\u51fa\u73b0\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u57fa\u7840\uff0c\u5e76\u4e3a\u6784\u5efa\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u7684\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u6761\u65b0\u9014\u5f84\u3002"}}
{"id": "2506.23315", "pdf": "https://arxiv.org/pdf/2506.23315", "abs": "https://arxiv.org/abs/2506.23315", "authors": ["Shouvon Sarker", "Xishuang Dong", "Lijun Qian"], "title": "Ensemble BERT for Medication Event Classification on Electronic Health Records (EHRs)", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Identification of key variables such as medications, diseases, relations from\nhealth records and clinical notes has a wide range of applications in the\nclinical domain. n2c2 2022 provided shared tasks on challenges in natural\nlanguage processing for clinical data analytics on electronic health records\n(EHR), where it built a comprehensive annotated clinical data Contextualized\nMedication Event Dataset (CMED). This study focuses on subtask 2 in Track 1 of\nthis challenge that is to detect and classify medication events from clinical\nnotes through building a novel BERT-based ensemble model. It started with\npretraining BERT models on different types of big data such as Wikipedia and\nMIMIC. Afterwards, these pretrained BERT models were fine-tuned on CMED\ntraining data. These fine-tuned BERT models were employed to accomplish\nmedication event classification on CMED testing data with multiple predictions.\nThese multiple predictions generated by these fine-tuned BERT models were\nintegrated to build final prediction with voting strategies. Experimental\nresults demonstrated that BERT-based ensemble models can effectively improve\nstrict Micro-F score by about 5% and strict Macro-F score by about 6%,\nrespectively.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eBERT\u7684\u96c6\u6210\u6a21\u578b\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u5206\u7c7b\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u7684\u836f\u7269\u4e8b\u4ef6\u3002\u901a\u8fc7\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u5927\u578b\u6570\u636e\u4e0a\u9884\u8bad\u7ec3BERT\u6a21\u578b\uff0c\u5e76\u5728CMED\u8bad\u7ec3\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u6700\u7ec8\u5229\u7528\u6295\u7968\u7b56\u7565\u6574\u5408\u591a\u4e2a\u9884\u6d4b\u7ed3\u679c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u9ad8\u4e25\u683cMicro-F\u548cMacro-F\u5206\u6570\u3002", "motivation": "\u4ece\u5065\u5eb7\u8bb0\u5f55\u548c\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u8bc6\u522b\u5173\u952e\u53d8\u91cf\uff08\u5982\u836f\u7269\u3001\u75be\u75c5\u3001\u5173\u7cfb\uff09\u5728\u4e34\u5e8a\u9886\u57df\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u3002n2c2 2022\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6311\u6218\uff0c\u65e8\u5728\u89e3\u51b3\u4e34\u5e8a\u6570\u636e\u5206\u6790\u4e2d\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u95ee\u9898\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u5168\u9762\u6807\u6ce8\u7684\u4e34\u5e8a\u6570\u636e\u4e0a\u4e0b\u6587\u836f\u7269\u4e8b\u4ef6\u6570\u636e\u96c6\uff08CMED\uff09\u3002\u672c\u7814\u7a76\u4e13\u6ce8\u4e8e\u8be5\u6311\u6218\u4e2d\u7684\u5b50\u4efb\u52a12\uff0c\u5373\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u65b0\u9896\u7684\u57fa\u4e8eBERT\u7684\u96c6\u6210\u6a21\u578b\u6765\u68c0\u6d4b\u548c\u5206\u7c7b\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u7684\u836f\u7269\u4e8b\u4ef6\u3002", "method": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8eBERT\u7684\u96c6\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u5927\u578b\u6570\u636e\uff08\u5982\u7ef4\u57fa\u767e\u79d1\u548cMIMIC\uff09\u4e0a\u9884\u8bad\u7ec3BERT\u6a21\u578b\uff0c\u7136\u540e\u5728CMED\u8bad\u7ec3\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u5229\u7528\u6295\u7968\u7b56\u7565\u6574\u5408\u591a\u4e2a\u9884\u6d4b\u7ed3\u679c\u4ee5\u5b8c\u6210\u836f\u7269\u4e8b\u4ef6\u5206\u7c7b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8eBERT\u7684\u96c6\u6210\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u4e25\u683cMicro-F\u5206\u6570\u7ea65%\uff0c\u4e25\u683cMacro-F\u5206\u6570\u7ea66%\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8eBERT\u7684\u96c6\u6210\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u4e25\u683cMicro-F\u5206\u6570\u548c\u4e25\u683cMacro-F\u5206\u6570\u3002"}}
{"id": "2506.23340", "pdf": "https://arxiv.org/pdf/2506.23340", "abs": "https://arxiv.org/abs/2506.23340", "authors": ["Yumeng Lin", "Xufeng Duan", "David Haslett", "Yige Chen", "Zhenguang G. Cai"], "title": "Information Loss in LLMs' Multilingual Translation: The Role of Training Data, Language Proximity, and Language Family", "categories": ["cs.CL"], "comment": null, "summary": "Large language models have achieved impressive progress in multilingual\ntranslation, yet they continue to face challenges with certain language\npairs-particularly those with limited training data or significant linguistic\ndivergence from English. This study systematically investigates how training\ndata, language proximity, and language family affect information loss in\nmultilingual translation. We evaluate two large language models, GPT-4 and\nLlama 2, by performing round-trip translations. Translation quality was\nassessed using BLEU scores and BERT similarity metrics. Our results reveal a\nrobust interaction between training data size and language distance: while\nabundant training data can mitigate the effects of linguistic divergence,\nlanguages structurally closer to English consistently yield higher translation\nquality in low-resource conditions. Among various distance metrics,\northographic, phylogenetic, syntactic, and geographical distances emerge as\nstrong predictors of translation performance. Language family also exerts an\nindependent influence. These findings contribute to a deeper understanding of\nthe linguistic constraints shaping multilingual translation in large language\nmodels, emphasizing that translation quality is shaped not only by data volume\nbut also by structural and typological relationships between languages.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u8bad\u7ec3\u6570\u636e\u3001\u8bed\u8a00\u63a5\u8fd1\u5ea6\u548c\u8bed\u8a00\u5bb6\u65cf\u5982\u4f55\u5f71\u54cd\u591a\u8bed\u8a00\u7ffb\u8bd1\u4e2d\u7684\u4fe1\u606f\u4e22\u5931\uff0c\u5e76\u53d1\u73b0\u7ffb\u8bd1\u8d28\u91cf\u4e0d\u4ec5\u7531\u6570\u636e\u91cf\u51b3\u5b9a\uff0c\u8fd8\u7531\u8bed\u8a00\u4e4b\u95f4\u7684\u7ed3\u6784\u548c\u7c7b\u578b\u5173\u7cfb\u51b3\u5b9a\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00\u7ffb\u8bd1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u4ecd\u9762\u4e34\u67d0\u4e9b\u8bed\u8a00\u5bf9\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u8bad\u7ec3\u6570\u636e\u6709\u9650\u6216\u4e0e\u82f1\u8bed\u6709\u663e\u8457\u8bed\u8a00\u5dee\u5f02\u7684\u8bed\u8a00\u5bf9\u3002", "method": "\u672c\u7814\u7a76\u7cfb\u7edf\u5730\u8c03\u67e5\u4e86\u8bad\u7ec3\u6570\u636e\u3001\u8bed\u8a00\u63a5\u8fd1\u5ea6\u548c\u8bed\u8a00\u5bb6\u65cf\u5982\u4f55\u5f71\u54cd\u591a\u8bed\u8a00\u7ffb\u8bd1\u4e2d\u7684\u4fe1\u606f\u4e22\u5931\u3002\u6211\u4eec\u901a\u8fc7\u8fdb\u884c\u5f80\u8fd4\u7ffb\u8bd1\u8bc4\u4f30\u4e86\u4e24\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578bGPT-4\u548cLlama 2\uff0c\u5e76\u4f7f\u7528BLEU\u5206\u6570\u548cBERT\u76f8\u4f3c\u6027\u6307\u6807\u8bc4\u4f30\u4e86\u7ffb\u8bd1\u8d28\u91cf\u3002", "result": "\u6211\u4eec\u7684\u7ed3\u679c\u63ed\u793a\u4e86\u8bad\u7ec3\u6570\u636e\u5927\u5c0f\u548c\u8bed\u8a00\u8ddd\u79bb\u4e4b\u95f4\u7684\u5f3a\u5927\u76f8\u4e92\u4f5c\u7528\uff1a\u867d\u7136\u4e30\u5bcc\u7684\u8bad\u7ec3\u6570\u636e\u53ef\u4ee5\u7f13\u89e3\u8bed\u8a00\u5206\u6b67\u7684\u5f71\u54cd\uff0c\u4f46\u5728\u4f4e\u8d44\u6e90\u6761\u4ef6\u4e0b\uff0c\u7ed3\u6784\u4e0a\u66f4\u63a5\u8fd1\u82f1\u8bed\u7684\u8bed\u8a00\u59cb\u7ec8\u80fd\u4ea7\u751f\u66f4\u9ad8\u7684\u7ffb\u8bd1\u8d28\u91cf\u3002\u5404\u79cd\u8ddd\u79bb\u5ea6\u91cf\u4e2d\uff0c\u6b63\u5b57\u6cd5\u3001\u7cfb\u7edf\u53d1\u751f\u5b66\u3001\u53e5\u6cd5\u548c\u5730\u7406\u8ddd\u79bb\u6210\u4e3a\u7ffb\u8bd1\u6027\u80fd\u7684\u5f3a\u5927\u9884\u6d4b\u56e0\u7d20\u3002\u8bed\u8a00\u5bb6\u65cf\u4e5f\u72ec\u7acb\u5730\u4ea7\u751f\u5f71\u54cd\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u6709\u52a9\u4e8e\u66f4\u6df1\u5165\u5730\u7406\u89e3\u5851\u9020\u5927\u578b\u8bed\u8a00\u6a21\u578b\u591a\u8bed\u8a00\u7ffb\u8bd1\u7684\u8bed\u8a00\u7ea6\u675f\uff0c\u5f3a\u8c03\u7ffb\u8bd1\u8d28\u91cf\u4e0d\u4ec5\u7531\u6570\u636e\u91cf\u51b3\u5b9a\uff0c\u8fd8\u7531\u8bed\u8a00\u4e4b\u95f4\u7684\u7ed3\u6784\u548c\u7c7b\u578b\u5173\u7cfb\u51b3\u5b9a\u3002"}}
{"id": "2506.23342", "pdf": "https://arxiv.org/pdf/2506.23342", "abs": "https://arxiv.org/abs/2506.23342", "authors": ["Akim Tsvigun", "Daniil Vasilev", "Ivan Tsvigun", "Ivan Lysenko", "Talgat Bektleuov", "Aleksandr Medvedev", "Uliana Vinogradova", "Nikita Severin", "Mikhail Mozikov", "Andrey Savchenko", "Rostislav Grigorev", "Ramil Kuleev", "Fedor Zhdanov", "Artem Shelmanov", "Ilya Makarov"], "title": "ATGen: A Framework for Active Text Generation", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at ACL 2025 System Demonstrations", "summary": "Active learning (AL) has demonstrated remarkable potential in reducing the\nannotation effort required for training machine learning models. However,\ndespite the surging popularity of natural language generation (NLG) tasks in\nrecent years, the application of AL to NLG has been limited. In this paper, we\nintroduce Active Text Generation (ATGen) - a comprehensive framework that\nbridges AL with text generation tasks, enabling the application of\nstate-of-the-art AL strategies to NLG. Our framework simplifies AL-empowered\nannotation in NLG tasks using both human annotators and automatic annotation\nagents based on large language models (LLMs). The framework supports LLMs\ndeployed as services, such as ChatGPT and Claude, or operated on-premises.\nFurthermore, ATGen provides a unified platform for smooth implementation and\nbenchmarking of novel AL strategies tailored to NLG tasks. Finally, we present\nevaluation results for state-of-the-art AL strategies across diverse settings\nand multiple text generation tasks. We show that ATGen reduces both the effort\nof human annotators and costs associated with API calls to LLM-based annotation\nagents. The code of the framework is available on GitHub under the MIT license.\nThe video presentation is available at http://atgen-video.nlpresearch.group", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86 ATGen\uff0c\u8fd9\u662f\u4e00\u4e2a\u5c06\u4e3b\u52a8\u5b66\u4e60\u4e0e\u6587\u672c\u751f\u6210\u4efb\u52a1\u76f8\u7ed3\u5408\u7684\u6846\u67b6\uff0c\u53ef\u4ee5\u51cf\u5c11\u6807\u6ce8\u6210\u672c\u5e76\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u5c3d\u7ba1\u8fd1\u5e74\u6765\u81ea\u7136\u8bed\u8a00\u751f\u6210 (NLG) \u4efb\u52a1\u8d8a\u6765\u8d8a\u53d7\u6b22\u8fce\uff0c\u4f46 AL \u5728 NLG \u4e2d\u7684\u5e94\u7528\u4ecd\u7136\u6709\u9650\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u6846\u67b6\u6765\u5f25\u5408 AL \u4e0e\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "ATGen \u662f\u4e00\u4e2a\u7efc\u5408\u6846\u67b6\uff0c\u5c06\u4e3b\u52a8\u5b66\u4e60 (AL) \u4e0e\u6587\u672c\u751f\u6210\u4efb\u52a1\u76f8\u7ed3\u5408\uff0c\u4f7f\u6700\u5148\u8fdb\u7684 AL \u7b56\u7565\u80fd\u591f\u5e94\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u751f\u6210 (NLG)\u3002\u8be5\u6846\u67b6\u4f7f\u7528\u4eba\u7c7b\u6807\u6ce8\u8005\u548c\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u81ea\u52a8\u6807\u6ce8\u4ee3\u7406\u6765\u7b80\u5316 AL \u8d4b\u80fd\u7684\u6807\u6ce8\u3002", "result": "ATGen \u5728\u5404\u79cd\u8bbe\u7f6e\u548c\u591a\u4e2a\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u5c55\u793a\u4e86\u6700\u5148\u8fdb\u7684 AL \u7b56\u7565\u7684\u8bc4\u4f30\u7ed3\u679c\u3002", "conclusion": "ATGen \u51cf\u5c11\u4e86\u4eba\u7c7b\u6807\u6ce8\u8005\u7684\u52aa\u529b\u548c\u4e0e\u57fa\u4e8e LLM \u7684\u6807\u6ce8\u4ee3\u7406\u7684 API \u8c03\u7528\u6210\u672c\u3002"}}
{"id": "2506.23377", "pdf": "https://arxiv.org/pdf/2506.23377", "abs": "https://arxiv.org/abs/2506.23377", "authors": ["Taejin Kim", "Siun-Chuon Mau", "Konrad Vesey"], "title": "Perspective Dial: Measuring Perspective of Text and Guiding LLM Outputs", "categories": ["cs.CL", "cs.AI"], "comment": "7 pages, 5 main pages of text, 5 figures, 2 tables. Research work\n  performed at CACI INTL INC", "summary": "Large language models (LLMs) are used in a variety of mission-critical roles.\nDue to the rapidly developing nature of LLMs, there is a lack of quantifiable\nunderstanding of the bias and perspective associated with LLM output. Inspired\nby this need, this paper considers the broader issue of perspective or\nviewpoint of general text and perspective control of large-language model (LLM)\noutput. Perspective-Dial consists of two main components: a (1) metric space,\ndubbed Perspective Space, that enables quantitative measurements of different\nperspectives regarding a topic, and the use of (2) Systematic Prompt\nEngineering that utilizes greedy-coordinate descent to control LLM output\nperspective based on measurement feedback from the Perspective Space. The\nempirical nature of the approach allows progress to side step a principled\nunderstanding of perspective or bias -- effectively quantifying and adjusting\noutputs for a variety of topics. Potential applications include detection,\ntracking and mitigation of LLM bias, narrative detection, sense making and\ntracking in public discourse, and debate bot advocating given perspective.", "AI": {"tldr": "This paper introduces Perspective-Dial, a method to quantify and control the perspective of large language model outputs, with potential applications in bias detection, narrative tracking, and debate support.", "motivation": "The paper aims to address the lack of quantifiable understanding of bias and perspective in LLM outputs, which is crucial for mission-critical applications.", "method": "Perspective-Dial consists of two components: a metric space called Perspective Space for quantifying perspectives, and Systematic Prompt Engineering using greedy-coordinate descent to control LLM output based on feedback from the Perspective Space.", "result": "The empirical approach allows for progress in quantifying and adjusting LLM outputs for various topics without requiring a principled understanding of perspective or bias.", "conclusion": "Perspective-Dial provides a method to quantify and adjust the perspective of LLM outputs, which can be applied to detect and mitigate bias, track narratives, and support debate bots."}}
{"id": "2506.23393", "pdf": "https://arxiv.org/pdf/2506.23393", "abs": "https://arxiv.org/abs/2506.23393", "authors": ["Eugene J. Yu", "Dawei Zhu", "Yifan Song", "Xiangyu Wong", "Jiebin Zhang", "Wenxuan Shi", "Xiaoguang Li", "Qun Liu", "Sujian Li"], "title": "Hierarchical Memory Organization for Wikipedia Generation", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Main Conference", "summary": "Generating Wikipedia articles autonomously is a challenging task requiring\nthe integration of accurate, comprehensive, and well-structured information\nfrom diverse sources. This paper introduces the Memory Organization-based\nGeneration (MOG) framework, a novel approach to address these challenges by\nleveraging a hierarchical memory architecture. MOG extracts fine-grained memory\nunits from web documents, recursively organizes them into a Wikipedia-style\nhierarchical structure, and uses this structure to guide the generation\nprocess. This ensures alignment between memory and the article outline,\nimproving both informativeness and verifiability while minimizing\nhallucinations. Additionally, a citation module is implemented to enhance\ntraceability by linking every generated sentence to specific memory units.\nEvaluations on our newly created WikiStart dataset demonstrate that MOG\noutperforms baseline methods in producing informative and reliable articles,\nmaking it particularly robust in real-world scenarios.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86MOG\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u8bb0\u5fc6\u67b6\u6784\u63d0\u9ad8\u751f\u6210\u7ef4\u57fa\u767e\u79d1\u6587\u7ae0\u7684\u4fe1\u606f\u91cf\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u751f\u6210\u81ea\u4e3b\u7684\u7ef4\u57fa\u767e\u79d1\u6587\u7ae0\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u9700\u8981\u6574\u5408\u6765\u81ea\u4e0d\u540c\u6765\u6e90\u7684\u51c6\u786e\u3001\u5168\u9762\u548c\u7ed3\u6784\u826f\u597d\u7684\u4fe1\u606f\u3002", "method": "MOG\u6846\u67b6\u5229\u7528\u5206\u5c42\u8bb0\u5fc6\u67b6\u6784\uff0c\u4ece\u7f51\u7edc\u6587\u6863\u4e2d\u63d0\u53d6\u7ec6\u7c92\u5ea6\u7684\u8bb0\u5fc6\u5355\u5143\uff0c\u5e76\u9012\u5f52\u5730\u7ec4\u7ec7\u6210\u7ef4\u57fa\u767e\u79d1\u98ce\u683c\u7684\u5c42\u6b21\u7ed3\u6784\uff0c\u4ee5\u6307\u5bfc\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5728\u65b0\u521b\u5efa\u7684WikiStart\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cMOG\u5728\u751f\u6210\u4fe1\u606f\u4e30\u5bcc\u4e14\u53ef\u9760\u7684\u6587\u7ae0\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MOG\u5728\u751f\u6210\u4fe1\u606f\u4e30\u5bcc\u4e14\u53ef\u9760\u7684\u6587\u7ae0\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4f7f\u5176\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7279\u522b\u7a33\u5065\u3002"}}
{"id": "2506.23411", "pdf": "https://arxiv.org/pdf/2506.23411", "abs": "https://arxiv.org/abs/2506.23411", "authors": ["Jiale Zhang", "Zichong Wang", "Avash Palikhe", "Zhipeng Yin", "Wenbin Zhang"], "title": "Datasets for Fairness in Language Models: An In-Depth Survey", "categories": ["cs.CL", "cs.CY", "cs.LG"], "comment": null, "summary": "Fairness benchmarks play a central role in shaping how we evaluate language\nmodels, yet surprisingly little attention has been given to examining the\ndatasets that these benchmarks rely on. This survey addresses that gap by\npresenting a broad and careful review of the most widely used fairness datasets\nin current language model research, characterizing them along several key\ndimensions including their origin, scope, content, and intended use to help\nresearchers better appreciate the assumptions and limitations embedded in these\nresources. To support more meaningful comparisons and analyses, we introduce a\nunified evaluation framework that reveals consistent patterns of demographic\ndisparities across datasets and scoring methods. Applying this framework to\ntwenty four common benchmarks, we highlight the often overlooked biases that\ncan influence conclusions about model fairness and offer practical guidance for\nselecting, combining, and interpreting these datasets. We also point to\nopportunities for creating new fairness benchmarks that reflect more diverse\nsocial contexts and encourage more thoughtful use of these tools going forward.\nAll code, data, and detailed results are publicly available at\nhttps://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree/main/datasets\nto promote transparency and reproducibility across the research community.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u5ba1\u67e5\u4e86\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u4e2d\u6700\u5e38\u7528\u7684\u516c\u5e73\u6027\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u63ed\u793a\u8de8\u6570\u636e\u96c6\u548c\u8bc4\u5206\u65b9\u6cd5\u7684\u4e00\u81f4\u6027\u4eba\u53e3\u7edf\u8ba1\u5b66\u5dee\u5f02\uff0c\u5e76\u63d0\u4f9b\u4e86\u9009\u62e9\u3001\u7ec4\u5408\u548c\u89e3\u91ca\u8fd9\u4e9b\u6570\u636e\u96c6\u7684\u5b9e\u7528\u6307\u5357\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u586b\u8865\u5bf9\u516c\u5e73\u6027\u57fa\u51c6\u6240\u4f9d\u8d56\u7684\u6570\u636e\u96c6\u7814\u7a76\u4e0d\u8db3\u7684\u7a7a\u767d\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u4e9b\u8d44\u6e90\u4e2d\u7684\u5047\u8bbe\u548c\u9650\u5236\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5168\u9762\u5ba1\u67e5\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u4e2d\u6700\u5e38\u7528\u7684\u516c\u5e73\u6027\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u63ed\u793a\u8de8\u6570\u636e\u96c6\u548c\u8bc4\u5206\u65b9\u6cd5\u7684\u4e00\u81f4\u6027\u4eba\u53e3\u7edf\u8ba1\u5b66\u5dee\u5f02\u3002", "result": "\u672c\u6587\u901a\u8fc7\u5e94\u7528\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u4e8c\u5341\u56db\u4e2a\u5e38\u89c1\u57fa\u51c6\u4e2d\u7ecf\u5e38\u88ab\u5ffd\u89c6\u7684\u504f\u89c1\uff0c\u5e76\u63d0\u4f9b\u4e86\u9009\u62e9\u3001\u7ec4\u5408\u548c\u89e3\u91ca\u8fd9\u4e9b\u6570\u636e\u96c6\u7684\u5b9e\u7528\u6307\u5357\u3002", "conclusion": "\u672c\u6587\u6307\u51fa\uff0c\u516c\u5e73\u6027\u57fa\u51c6\u5728\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u4e2d\u8d77\u7740\u6838\u5fc3\u4f5c\u7528\uff0c\u4f46\u5bf9\u8fd9\u4e9b\u57fa\u51c6\u6240\u4f9d\u8d56\u7684\u6570\u636e\u96c6\u7684\u7814\u7a76\u5374\u5f88\u5c11\u3002\u901a\u8fc7\u5168\u9762\u5ba1\u67e5\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u4e2d\u6700\u5e38\u7528\u516c\u5e73\u6027\u6570\u636e\u96c6\uff0c\u672c\u6587\u63ed\u793a\u4e86\u6570\u636e\u96c6\u7684\u6765\u6e90\u3001\u8303\u56f4\u3001\u5185\u5bb9\u548c\u9884\u671f\u7528\u9014\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u63ed\u793a\u8de8\u6570\u636e\u96c6\u548c\u8bc4\u5206\u65b9\u6cd5\u7684\u4e00\u81f4\u6027\u4eba\u53e3\u7edf\u8ba1\u5b66\u5dee\u5f02\u3002\u6700\u540e\uff0c\u672c\u6587\u63d0\u4f9b\u4e86\u9009\u62e9\u3001\u7ec4\u5408\u548c\u89e3\u91ca\u8fd9\u4e9b\u6570\u636e\u96c6\u7684\u5b9e\u7528\u6307\u5357\uff0c\u5e76\u6307\u51fa\u4e86\u521b\u5efa\u53cd\u6620\u66f4\u591a\u5143\u793e\u4f1a\u80cc\u666f\u7684\u65b0\u516c\u5e73\u6027\u57fa\u51c6\u7684\u673a\u4f1a\u3002"}}
{"id": "2506.23423", "pdf": "https://arxiv.org/pdf/2506.23423", "abs": "https://arxiv.org/abs/2506.23423", "authors": ["Felipe Nuti", "Tim Franzmeyer", "Jo\u00e3o Henriques"], "title": "TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "ICML 2025", "summary": "Past work has studied the effects of fine-tuning on large language models'\n(LLMs) overall performance on certain tasks. However, a quantitative and\nsystematic method for analyzing its effect on individual outputs is still\nlacking. Here, we propose a new method for measuring the contribution that\nfine-tuning makes to individual LLM responses, assuming access to the original\npre-trained model. Our method tracks the model's intermediate hidden states,\nproviding a more fine-grained insight into the effects of fine-tuning than a\nsimple comparison of final outputs from pre-trained and fine-tuned models. We\nintroduce and theoretically analyze an exact decomposition of any fine-tuned\nLLM into a pre-training component and a fine-tuning component. Empirically, we\nfind that model behavior and performance can be steered by up- or down-scaling\nthe fine-tuning component during the forward pass. Motivated by this finding\nand our theoretical analysis, we define the Tuning Contribution (TuCo) as the\nratio of the magnitudes of the fine-tuning component to the pre-training\ncomponent. We observe that three prominent adversarial attacks on LLMs\ncircumvent safety measures in a way that reduces TuCo, and that TuCo is\nconsistently lower on prompts where these attacks succeed compared to those\nwhere they do not. This suggests that attenuating the effect of fine-tuning on\nmodel outputs plays a role in the success of such attacks. In summary, TuCo\nenables the quantitative study of how fine-tuning influences model behavior and\nsafety, and vice versa.", "AI": {"tldr": "This paper proposes a method called Tuning Contribution (TuCo) to measure the effect of fine-tuning on individual responses of large language models. TuCo provides insights into how fine-tuning influences model behavior and safety, and it was found that adversarial attacks reduce TuCo, indicating that attenuating the effect of fine-tuning may contribute to their success.", "motivation": "The motivation is to develop a quantitative and systematic method for analyzing the effect of fine-tuning on individual outputs of large language models (LLMs).", "method": "The method tracks the model's intermediate hidden states and introduces an exact decomposition of any fine-tuned LLM into a pre-training component and a fine-tuning component. It defines the Tuning Contribution (TuCo) as the ratio of the magnitudes of the fine-tuning component to the pre-training component.", "result": "The results show that model behavior and performance can be steered by up- or down-scaling the fine-tuning component during the forward pass. Additionally, three prominent adversarial attacks on LLMs reduce TuCo, and TuCo is consistently lower on prompts where these attacks succeed compared to those where they do not.", "conclusion": "TuCo enables the quantitative study of how fine-tuning influences model behavior and safety, and vice versa."}}
{"id": "2506.23431", "pdf": "https://arxiv.org/pdf/2506.23431", "abs": "https://arxiv.org/abs/2506.23431", "authors": ["Zixian Huang", "Chenxu Niu", "Yu Gu", "Gengyang Xiao", "Xinwei Huang", "Gong Cheng"], "title": "Pipelined Decoder for Efficient Context-Aware Text Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As the basis of generative AI, an autoregressive model requires the\ngeneration of a new token depending on all the previously generated tokens,\nwhich brings high quality but also restricts the model to generate tokens one\nby one, forming a bottleneck limiting the generation speed. In this paper, we\npropose a new decoder architecture that efficiently generates text in parallel\nfor context-aware generation tasks. Our proposed pipelined decoder initiates\nthe generation of multiple subsequences simultaneously, and, at each time-step,\nit generates a new token for each subsequence to realize parallelism.\nExperiments on multiple text generation tasks, including question answering,\ntext summarization, and keyphrase generation, show that our pipelined decoder\nsignificantly improves the generation speed without a significant loss of\ngeneration quality or additional memory consumption.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u7801\u5668\u67b6\u6784\uff0c\u53ef\u4ee5\u5728\u4e0d\u663e\u8457\u635f\u5931\u751f\u6210\u8d28\u91cf\u6216\u989d\u5916\u5185\u5b58\u6d88\u8017\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u9ad8\u751f\u6210\u901f\u5ea6\u3002", "motivation": "\u81ea\u56de\u5f52\u6a21\u578b\u9700\u8981\u6839\u636e\u6240\u6709\u5148\u524d\u751f\u6210\u7684\u6807\u8bb0\u751f\u6210\u65b0\u6807\u8bb0\uff0c\u8fd9\u867d\u7136\u5e26\u6765\u4e86\u9ad8\u8d28\u91cf\uff0c\u4f46\u4e5f\u9650\u5236\u4e86\u6a21\u578b\u4e00\u6b21\u751f\u6210\u4e00\u4e2a\u6807\u8bb0\uff0c\u5f62\u6210\u4e86\u9650\u5236\u751f\u6210\u901f\u5ea6\u7684\u74f6\u9888\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u7801\u5668\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u901a\u8fc7\u540c\u65f6\u751f\u6210\u591a\u4e2a\u5b50\u5e8f\u5217\u5e76\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u4e3a\u6bcf\u4e2a\u5b50\u5e8f\u5217\u751f\u6210\u65b0\u6807\u8bb0\u6765\u5b9e\u73b0\u5e76\u884c\u6027\u3002", "result": "\u5728\u591a\u4e2a\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\uff0c\u5305\u62ec\u95ee\u7b54\u3001\u6587\u672c\u6458\u8981\u548c\u5173\u952e\u8bcd\u751f\u6210\uff0c\u8868\u660e\u6211\u4eec\u7684\u7ba1\u9053\u89e3\u7801\u5668\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u901f\u5ea6\u3002", "conclusion": "\u6211\u4eec\u7684\u7ba1\u9053\u89e3\u7801\u5668\u5728\u4e0d\u663e\u8457\u635f\u5931\u751f\u6210\u8d28\u91cf\u6216\u989d\u5916\u5185\u5b58\u6d88\u8017\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u901f\u5ea6\u3002"}}
{"id": "2506.23463", "pdf": "https://arxiv.org/pdf/2506.23463", "abs": "https://arxiv.org/abs/2506.23463", "authors": ["Jang Won June"], "title": "What to Keep and What to Drop: Adaptive Table Filtering Framework", "categories": ["cs.CL", "I.2.7"], "comment": "26 pages, 9 figures", "summary": "Large language models (LLMs) for table-based reasoning often struggle with\nlarge tables due to input length limits. We propose ATF (Adaptive Table\nFiltering Framework), a modular and question-aware filtering pipeline that\nprunes uninformative columns and rows using LLM-generated column descriptions,\nclustering, and sparse-dense alignment scores. ATF integrates seamlessly with\nexisting models (e.g., TAPAS, TAPEX) without retraining. Experiments show that\nATF reduces table cells by ~70\\%, boosting performance on out-of-domain TableQA\ntasks while causing slight performance drops on Table Fact Verification, where\nfull-table context is more critical. These results highlight ATF's ability to\nadaptively balance informativeness and minimalism across tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aATF\u7684\u81ea\u9002\u5e94\u8868\u683c\u8fc7\u6ee4\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u5927\u578b\u8868\u683c\u65f6\u7684\u8f93\u5165\u957f\u5ea6\u9650\u5236\u95ee\u9898\u3002ATF\u901a\u8fc7\u4fee\u526a\u65e0\u4fe1\u606f\u7684\u5217\u548c\u884c\u6765\u51cf\u5c11\u8868\u683c\u5927\u5c0f\uff0c\u5e76\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u73b0\u6709\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u57fa\u4e8e\u8868\u683c\u7684\u63a8\u7406\u4e2d\u7531\u4e8e\u8f93\u5165\u957f\u5ea6\u9650\u5236\u800c\u96be\u4ee5\u5904\u7406\u5927\u578b\u8868\u683c\u3002", "method": "ATF\uff08\u81ea\u9002\u5e94\u8868\u683c\u8fc7\u6ee4\u6846\u67b6\uff09\u662f\u4e00\u79cd\u6a21\u5757\u5316\u4e14\u95ee\u9898\u611f\u77e5\u7684\u8fc7\u6ee4\u7ba1\u9053\uff0c\u4f7f\u7528LLM\u751f\u6210\u7684\u5217\u63cf\u8ff0\u3001\u805a\u7c7b\u548c\u7a00\u758f-\u5bc6\u96c6\u5bf9\u9f50\u5206\u6570\u6765\u4fee\u526a\u65e0\u4fe1\u606f\u7684\u5217\u548c\u884c\u3002", "result": "ATF\u51cf\u5c11\u4e86\u7ea670%\u7684\u8868\u683c\u5355\u5143\uff0c\u63d0\u9ad8\u4e86\u8de8\u57dfTableQA\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u4f46\u5728Table Fact Verification\u4efb\u52a1\u4e2d\u5bfc\u81f4\u4e86\u8f7b\u5fae\u7684\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "ATF\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5b83\u80fd\u591f\u6839\u636e\u4e0d\u540c\u7684\u4efb\u52a1\u81ea\u9002\u5e94\u5730\u5e73\u8861\u4fe1\u606f\u91cf\u548c\u7b80\u6d01\u6027\u3002"}}
{"id": "2506.23485", "pdf": "https://arxiv.org/pdf/2506.23485", "abs": "https://arxiv.org/abs/2506.23485", "authors": ["Haocheng Yu", "Yaxiong Wu", "Hao Wang", "Wei Guo", "Yong Liu", "Yawen Li", "Yuyang Ye", "Junping Du", "Enhong Chen"], "title": "Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Interactive recommendation is a typical information-seeking task that allows\nusers to interactively express their needs through natural language and obtain\npersonalized recommendations. Large language model-powered (LLM-powered) agents\nhave become a new paradigm in interactive recommendations, effectively\ncapturing users' real-time needs and enhancing personalized experiences.\nHowever, due to limited planning and generalization capabilities, existing\nformulations of LLM-powered interactive recommender agents struggle to\neffectively address diverse and complex user intents, such as intuitive,\nunrefined, or occasionally ambiguous requests. To tackle this challenge, we\npropose a novel thought-augmented interactive recommender agent system (TAIRA)\nthat addresses complex user intents through distilled thought patterns.\nSpecifically, TAIRA is designed as an LLM-powered multi-agent system featuring\na manager agent that orchestrates recommendation tasks by decomposing user\nneeds and planning subtasks, with its planning capacity strengthened through\nThought Pattern Distillation (TPD), a thought-augmentation method that extracts\nhigh-level thoughts from the agent's and human experts' experiences. Moreover,\nwe designed a set of user simulation schemes to generate personalized queries\nof different difficulties and evaluate the recommendations based on specific\ndatasets. Through comprehensive experiments conducted across multiple datasets,\nTAIRA exhibits significantly enhanced performance compared to existing methods.\nNotably, TAIRA shows a greater advantage on more challenging tasks while\ngeneralizing effectively on novel tasks, further validating its superiority in\nmanaging complex user intents within interactive recommendation systems. The\ncode is publicly available at:https://github.com/Alcein/TAIRA.", "AI": {"tldr": "TAIRA is a thought-augmented interactive recommender agent system that enhances the ability to handle complex user intents through a manager agent and Thought Pattern Distillation (TPD). It outperforms existing methods, especially on challenging tasks and novel scenarios.", "motivation": "Existing formulations of LLM-powered interactive recommender agents struggle to effectively address diverse and complex user intents, such as intuitive, unrefined, or occasionally ambiguous requests. The motivation is to develop a system that can better handle these complex user intents.", "method": "TAIRA is a thought-augmented interactive recommender agent system that utilizes a manager agent to orchestrate recommendation tasks by decomposing user needs and planning subtasks. It strengthens its planning capacity through Thought Pattern Distillation (TPD), which extracts high-level thoughts from the agent's and human experts' experiences. Additionally, user simulation schemes are designed to generate personalized queries of different difficulties and evaluate recommendations based on specific datasets.", "result": "TAIRA exhibits significantly enhanced performance compared to existing methods. It shows a greater advantage on more challenging tasks while generalizing effectively on novel tasks, further validating its superiority in managing complex user intents within interactive recommendation systems.", "conclusion": "TAIRA demonstrates superior performance in handling complex user intents within interactive recommendation systems, showing greater advantages on challenging tasks and effective generalization on novel tasks."}}
{"id": "2506.23508", "pdf": "https://arxiv.org/pdf/2506.23508", "abs": "https://arxiv.org/abs/2506.23508", "authors": ["Zhihao Zhang", "Qiaole Dong", "Qi Zhang", "Jun Zhao", "Enyu Zhou", "Zhiheng Xi", "Senjie Jin", "Xiaoran Fan", "Yuhao Zhou", "Yanwei Fu", "Tao Ji", "Tao Gui", "Xuanjing Huang"], "title": "Reinforcement Fine-Tuning Enables MLLMs Learning Novel Tasks Stably", "categories": ["cs.CL", "cs.AI"], "comment": "18 pages (Preprint. Work in progress)", "summary": "Post-training algorithms such as Supervised Fine-Tuning (SFT) and\nReinforcement Fine-Tuning (RFT) are widely used to adapt multimodal large\nlanguage models to downstream tasks. While effective at task adaptation, their\nimpact on prior knowledge remains unclear. In this paper, we introduce jigsaw\npuzzles as a novel task absent from existing pretraining corpora and\nsystematically study the behavior of SFT and RFT on an open-source multimodal\nmodel, Qwen2.5-VL. Our experiments reveal a sharp trade-off: SFT enables rapid\ntask acquisition but leads to catastrophic forgetting, whereas RFT learns more\nslowly on novel tasks but maintains prior knowledge. We analyze this phenomenon\nthrough the lens of learning dynamics, showing that RFT reinforces correct\nsamples that are naturally aligned with the base model's probability landscape,\nmitigating interference with prior knowledge. Moreover, supervised training on\ncorrect RFT-simulated rollouts allows SFT to preserve knowledge while rapidly\nlearning new tasks. These findings suggest that data distribution, rather than\nalgorithmic differences, plays a central role in forgetting, and highlight\nRFT's potential for stable continual learning in multimodal large language\nmodels.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86SFT\u548cRFT\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0RFT\u5728\u4fdd\u6301\u5148\u524d\u77e5\u8bc6\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u800cSFT\u5219\u5bfc\u81f4\u9057\u5fd8\u3002", "motivation": "\u5c3d\u7ba1SFT\u548cRFT\u5728\u4efb\u52a1\u9002\u5e94\u65b9\u9762\u6709\u6548\uff0c\u4f46\u5b83\u4eec\u5bf9\u5148\u524d\u77e5\u8bc6\u7684\u5f71\u54cd\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86\u62fc\u56fe\u4efb\u52a1\u4f5c\u4e3a\u73b0\u6709\u9884\u8bad\u7ec3\u8bed\u6599\u5e93\u4e2d\u7f3a\u5931\u7684\u65b0\u4efb\u52a1\uff0c\u5e76\u7cfb\u7edf\u5730\u7814\u7a76\u4e86SFT\u548cRFT\u5728\u5f00\u6e90\u591a\u6a21\u6001\u6a21\u578bQwen2.5-VL\u4e0a\u7684\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u4e00\u4e2a\u5c16\u9510\u7684\u6743\u8861\uff1aSFT\u80fd\u591f\u5feb\u901f\u83b7\u53d6\u4efb\u52a1\uff0c\u4f46\u4f1a\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\uff0c\u800cRFT\u5728\u65b0\u4efb\u52a1\u4e0a\u7684\u5b66\u4e60\u901f\u5ea6\u8f83\u6162\uff0c\u4f46\u80fd\u4fdd\u6301\u5148\u524d\u77e5\u8bc6\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\uff0c\u6570\u636e\u5206\u5e03\u800c\u4e0d\u662f\u7b97\u6cd5\u5dee\u5f02\u5728\u9057\u5fd8\u4e2d\u8d77\u7740\u6838\u5fc3\u4f5c\u7528\uff0c\u5e76\u7a81\u663e\u4e86RFT\u5728\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u7a33\u5b9a\u8fde\u7eed\u5b66\u4e60\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.23524", "pdf": "https://arxiv.org/pdf/2506.23524", "abs": "https://arxiv.org/abs/2506.23524", "authors": ["Phan Quoc Hung Mai", "Quang Hung Nguyen", "Phuong Giang Duong", "Hong Hanh Nguyen", "Nguyen Tuan Long"], "title": "NEU-ESC: A Comprehensive Vietnamese dataset for Educational Sentiment analysis and topic Classification toward multitask learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the field of education, understanding students' opinions through their\ncomments is crucial, especially in the Vietnamese language, where resources\nremain limited. Existing educational datasets often lack domain relevance and\nstudent slang. To address these gaps, we introduce NEU-ESC, a new Vietnamese\ndataset for Educational Sentiment Classification and Topic Classification,\ncurated from university forums, which offers more samples, richer class\ndiversity, longer texts, and broader vocabulary. In addition, we explore\nmultitask learning using encoder-only language models (BERT), in which we\nshowed that it achieves performance up to 83.7% and 79.8% accuracy for\nsentiment and topic classification tasks. We also benchmark our dataset and\nmodel with other datasets and models, including Large Language Models, and\ndiscuss these benchmarks. The dataset is publicly available at:\nhttps://huggingface.co/datasets/hung20gg/NEU-ESC.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u7684\u8d8a\u5357\u8bed\u6559\u80b2\u60c5\u611f\u5206\u7c7b\u548c\u4e3b\u9898\u5206\u7c7b\u6570\u636e\u96c6NEU-ESC\uff0c\u5e76\u5c55\u793a\u4e86\u4f7f\u7528BERT\u8fdb\u884c\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u9ad8\u6027\u80fd\u3002", "motivation": "\u5728\u6559\u80b2\u9886\u57df\uff0c\u901a\u8fc7\u5b66\u751f\u7684\u8bc4\u8bba\u6765\u7406\u89e3\u4ed6\u4eec\u7684\u610f\u89c1\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u8d8a\u5357\u8bed\u4e2d\uff0c\u8d44\u6e90\u4ecd\u7136\u6709\u9650\u3002\u73b0\u6709\u7684\u6559\u80b2\u6570\u636e\u96c6\u5f80\u5f80\u7f3a\u4e4f\u9886\u57df\u76f8\u5173\u6027\u548c\u5b66\u751f\u4fda\u8bed\u3002", "method": "\u672c\u6587\u4f7f\u7528\u4e86\u7f16\u7801\u5668-only\u8bed\u8a00\u6a21\u578b\uff08\u5982BERT\uff09\u8fdb\u884c\u591a\u4efb\u52a1\u5b66\u4e60\uff0c\u4ee5\u5b9e\u73b0\u60c5\u611f\u5206\u7c7b\u548c\u4e3b\u9898\u5206\u7c7b\u4efb\u52a1\u3002", "result": "\u672c\u6587\u5c55\u793a\u4e86\u4f7f\u7528BERT\u8fdb\u884c\u591a\u4efb\u52a1\u5b66\u4e60\u5728\u60c5\u611f\u5206\u7c7b\u548c\u4e3b\u9898\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u51c6\u786e\u7387\u5206\u522b\u8fbe\u523083.7%\u548c79.8%\u3002\u6b64\u5916\uff0c\u8fd8\u5bf9\u6570\u636e\u96c6\u548c\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u5176\u4ed6\u6570\u636e\u96c6\u548c\u6a21\u578b\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86NEU-ESC\u6570\u636e\u96c6\uff0c\u5e76\u5c55\u793a\u4e86\u4f7f\u7528BERT\u8fdb\u884c\u591a\u4efb\u52a1\u5b66\u4e60\u5728\u60c5\u611f\u5206\u7c7b\u548c\u4e3b\u9898\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u9ad8\u6027\u80fd\u3002\u540c\u65f6\uff0c\u8fd8\u4e0e\u5176\u4ed6\u6570\u636e\u96c6\u548c\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u8fd9\u4e9b\u7ed3\u679c\u3002"}}
{"id": "2506.23527", "pdf": "https://arxiv.org/pdf/2506.23527", "abs": "https://arxiv.org/abs/2506.23527", "authors": ["Jan Kvapil", "Martin Fajcik"], "title": "On Recipe Memorization and Creativity in Large Language Models: Is Your Model a Creative Cook, a Bad Cook, or Merely a Plagiator?", "categories": ["cs.CL"], "comment": "13 pages, 5 figures", "summary": "This work-in-progress investigates the memorization, creativity, and nonsense\nfound in cooking recipes generated from Large Language Models (LLMs).\nPrecisely, we aim (i) to analyze memorization, creativity, and non-sense in\nLLMs using a small, high-quality set of human judgments and (ii) to evaluate\npotential approaches to automate such a human annotation in order to scale our\nstudy to hundreds of recipes. To achieve (i), we conduct a detailed human\nannotation on 20 preselected recipes generated by LLM (Mixtral), extracting\neach recipe's ingredients and step-by-step actions to assess which elements are\nmemorized--i.e., directly traceable to online sources possibly seen during\ntraining--and which arise from genuine creative synthesis or outright nonsense.\nWe find that Mixtral consistently reuses ingredients that can be found in\nonline documents, potentially seen during model training, suggesting strong\nreliance on memorized content. To achieve aim (ii) and scale our analysis\nbeyond small sample sizes and single LLM validation, we design an\n``LLM-as-judge'' pipeline that automates recipe generation, nonsense detection,\nparsing ingredients and recipe steps, and their annotation. For instance,\ncomparing its output against human annotations, the best ingredient extractor\nand annotator is Llama 3.1+Gemma 2 9B, achieving up to 78% accuracy on\ningredient matching. This automated framework enables large-scale\nquantification of memorization, creativity, and nonsense in generated recipes,\nproviding rigorous evidence of the models' creative capacities.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86LLMs\u751f\u6210\u7684\u70f9\u996a\u98df\u8c31\u4e2d\u7684\u8bb0\u5fc6\u3001\u521b\u9020\u529b\u548c\u65e0\u610f\u4e49\u5185\u5bb9\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u6846\u67b6\u6765\u5927\u89c4\u6a21\u91cf\u5316\u8fd9\u4e9b\u7279\u6027\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u9700\u8981\u5206\u6790LLMs\u751f\u6210\u7684\u98df\u8c31\u4e2d\u7684\u8bb0\u5fc6\u3001\u521b\u9020\u529b\u548c\u65e0\u610f\u4e49\u5185\u5bb9\uff0c\u4f46\u624b\u52a8\u6807\u6ce8\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\u6765\u6269\u5927\u7814\u7a76\u89c4\u6a21\u3002", "method": "\u672c\u7814\u7a76\u9996\u5148\u5bf920\u4e2a\u7531Mixtral\u751f\u6210\u7684\u98df\u8c31\u8fdb\u884c\u4eba\u5de5\u6807\u6ce8\uff0c\u63d0\u53d6\u98df\u6750\u548c\u6b65\u9aa4\u4ee5\u8bc4\u4f30\u54ea\u4e9b\u5143\u7d20\u662f\u8bb0\u5fc6\u7684\uff0c\u54ea\u4e9b\u662f\u521b\u9020\u6027\u7684\u6216\u65e0\u610f\u4e49\u7684\u3002\u7136\u540e\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u201cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u201d\u7684\u7ba1\u9053\uff0c\u81ea\u52a8\u5316\u751f\u6210\u98df\u8c31\u3001\u68c0\u6d4b\u65e0\u610f\u4e49\u5185\u5bb9\u3001\u89e3\u6790\u98df\u6750\u548c\u6b65\u9aa4\uff0c\u5e76\u8fdb\u884c\u6807\u6ce8\u3002", "result": "Mixtral\u6a21\u578b\u5728\u751f\u6210\u98df\u8c31\u65f6\u503e\u5411\u4e8e\u91cd\u590d\u5728\u7ebf\u6587\u6863\u4e2d\u7684\u98df\u6750\uff0c\u8868\u660e\u5176\u9ad8\u5ea6\u4f9d\u8d56\u8bb0\u5fc6\u5185\u5bb9\u3002\u6b64\u5916\uff0cLlama 3.1+Gemma 2 9B\u5728\u98df\u6750\u5339\u914d\u4e0a\u8fbe\u5230\u4e8678%\u7684\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u4e86\u81ea\u52a8\u5316\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\u548c\u81ea\u52a8\u5316\u6846\u67b6\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u7684\u70f9\u996a\u98df\u8c31\u4e2d\u7684\u8bb0\u5fc6\u3001\u521b\u9020\u529b\u548c\u65e0\u610f\u4e49\u5185\u5bb9\uff0c\u53d1\u73b0Mixtral\u6a21\u578b\u9ad8\u5ea6\u4f9d\u8d56\u8bb0\u5fc6\u5185\u5bb9\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u5927\u89c4\u6a21\u91cf\u5316\u8fd9\u4e9b\u7279\u6027\u3002"}}
{"id": "2506.23601", "pdf": "https://arxiv.org/pdf/2506.23601", "abs": "https://arxiv.org/abs/2506.23601", "authors": ["Weijie Shi", "Yue Cui", "Yaguang Wu", "Jingzhi Fang", "Shibo Zhang", "Mengze Li", "Sirui Han", "Jia Zhu", "Jiajie Xu", "Xiaofang Zhou"], "title": "Semantic-guided Diverse Decoding for Large Language Model", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Diverse decoding of large language models is crucial for applications\nrequiring multiple semantically distinct responses, yet existing methods\nprimarily achieve lexical rather than semantic diversity. This limitation\nsignificantly constrains Best-of-N strategies, group-based reinforcement\nlearning, and data synthesis. While temperature sampling and diverse beam\nsearch modify token distributions or apply n-gram penalties, they fail to\nensure meaningful semantic differentiation. We introduce Semantic-guided\nDiverse Decoding (SemDiD), operating directly in embedding space that balances\nquality with diversity through three complementary mechanisms: orthogonal\ndirectional guidance, dynamic inter-group repulsion, and position-debiased\nprobability assessment. SemDiD harmonizes these competing objectives using\nadaptive gain functions and constraint optimization, ensuring both quality\nthresholds and maximal semantic differentiation. Experiments show SemDiD\nconsistently outperforms existing methods, improving Best-of-N coverage by\n1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15%\nwhile increasing accuracy by up to 2.1%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6837\u5316\u89e3\u7801\u65b9\u6cd5SemDiD\uff0c\u80fd\u591f\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u5e73\u8861\u8d28\u91cf\u548c\u591a\u6837\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u4e2a\u4efb\u52a1\u7684\u8868\u73b0\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6837\u5316\u89e3\u7801\u5bf9\u4e8e\u9700\u8981\u591a\u4e2a\u8bed\u4e49\u4e0a\u4e0d\u540c\u7684\u54cd\u5e94\u7684\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5b9e\u73b0\u7684\u662f\u8bcd\u6c47\u800c\u975e\u8bed\u4e49\u591a\u6837\u6027\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86\u8bed\u4e49\u5f15\u5bfc\u7684\u591a\u6837\u5316\u89e3\u7801\uff08SemDiD\uff09\uff0c\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u76f4\u63a5\u64cd\u4f5c\uff0c\u901a\u8fc7\u4e09\u79cd\u4e92\u8865\u673a\u5236\u5e73\u8861\u8d28\u91cf\u548c\u591a\u6837\u6027\uff1a\u6b63\u4ea4\u65b9\u5411\u5f15\u5bfc\u3001\u52a8\u6001\u7ec4\u95f4\u6392\u65a5\u548c\u4f4d\u7f6e\u53bb\u504f\u6982\u7387\u8bc4\u4f30\u3002", "result": "SemDiD\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d consistently \u8d85\u8fc7\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86Best-of-N\u8986\u76d6\u7387\uff0c\u5e76\u52a0\u901f\u4e86RLHF\u8bad\u7ec3\u6536\u655b\u3002", "conclusion": "\u5b9e\u9a8c\u8868\u660e\uff0cSemDiD\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d consistently \u8d85\u8fc7\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86Best-of-N\u8986\u76d6\u7387\uff0c\u5e76\u52a0\u901f\u4e86RLHF\u8bad\u7ec3\u6536\u655b\u3002"}}
{"id": "2506.23610", "pdf": "https://arxiv.org/pdf/2506.23610", "abs": "https://arxiv.org/abs/2506.23610", "authors": ["Manuel Pratelli", "Marinella Petrocchi"], "title": "Evaluating the Simulation of Human Personality-Driven Susceptibility to Misinformation with LLMs", "categories": ["cs.CL", "cs.CY"], "comment": "pre-print version - paper actually under submission", "summary": "Large language models (LLMs) make it possible to generate synthetic\nbehavioural data at scale, offering an ethical and low-cost alternative to\nhuman experiments. Whether such data can faithfully capture psychological\ndifferences driven by personality traits, however, remains an open question. We\nevaluate the capacity of LLM agents, conditioned on Big-Five profiles, to\nreproduce personality-based variation in susceptibility to misinformation,\nfocusing on news discernment, the ability to judge true headlines as true and\nfalse headlines as false. Leveraging published datasets in which human\nparticipants with known personality profiles rated headline accuracy, we create\nmatching LLM agents and compare their responses to the original human patterns.\nCertain trait-misinformation associations, notably those involving\nAgreeableness and Conscientiousness, are reliably replicated, whereas others\ndiverge, revealing systematic biases in how LLMs internalize and express\npersonality. The results underscore both the promise and the limits of\npersonality-aligned LLMs for behavioral simulation, and offer new insight into\nmodeling cognitive diversity in artificial agents.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u57fa\u4e8e\u5927\u4e94\u4eba\u683c\u6863\u6848\u7684LLM\u4ee3\u7406\u5728\u518d\u73b0\u57fa\u4e8e\u4e2a\u6027\u7684\u865a\u5047\u4fe1\u606f\u6613\u611f\u6027\u53d8\u5316\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u67d0\u4e9b\u4eba\u683c-\u865a\u5047\u4fe1\u606f\u5173\u8054\u88ab\u53ef\u9760\u5730\u590d\u5236\uff0c\u800c\u5176\u4ed6\u5173\u8054\u5219\u5b58\u5728\u5dee\u5f02\uff0c\u63ed\u793a\u4e86LLM\u5982\u4f55\u5185\u90e8\u5316\u548c\u8868\u8fbe\u4eba\u683c\u7684\u7cfb\u7edf\u6027\u504f\u5dee\u3002\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u4e2a\u6027\u5bf9\u9f50\u7684LLM\u5728\u884c\u4e3a\u6a21\u62df\u4e2d\u7684\u6f5c\u529b\u548c\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u5728\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u4e2d\u5efa\u6a21\u8ba4\u77e5\u591a\u6837\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f7f\u5f97\u5927\u89c4\u6a21\u751f\u6210\u5408\u6210\u884c\u4e3a\u6570\u636e\u6210\u4e3a\u53ef\u80fd\uff0c\u4e3a\u4eba\u7c7b\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9053\u5fb7\u4e14\u4f4e\u6210\u672c\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u6570\u636e\u662f\u5426\u80fd\u591f\u5fe0\u5b9e\u6355\u6349\u7531\u4eba\u683c\u7279\u8d28\u9a71\u52a8\u7684\u5fc3\u7406\u5dee\u5f02\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "method": "\u6211\u4eec\u8bc4\u4f30\u4e86\u57fa\u4e8e\u5927\u4e94\u4eba\u683c\u6863\u6848\u7684LLM\u4ee3\u7406\u5728\u518d\u73b0\u57fa\u4e8e\u4e2a\u6027\u7684\u865a\u5047\u4fe1\u606f\u6613\u611f\u6027\u53d8\u5316\u65b9\u9762\u7684\u80fd\u529b\uff0c\u91cd\u70b9\u5173\u6ce8\u65b0\u95fb\u8fa8\u522b\u80fd\u529b\uff0c\u5373\u5224\u65ad\u771f\u5b9e\u6807\u9898\u4e3a\u771f\u5b9e\u548c\u865a\u5047\u6807\u9898\u4e3a\u865a\u5047\u7684\u80fd\u529b\u3002\u5229\u7528\u5df2\u53d1\u5e03\u7684\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u4eba\u7c7b\u53c2\u4e0e\u8005\u6839\u636e\u5df2\u77e5\u7684\u4eba\u683c\u6863\u6848\u5bf9\u6807\u9898\u51c6\u786e\u6027\u8fdb\u884c\u8bc4\u5206\uff0c\u6211\u4eec\u521b\u5efa\u4e86\u5339\u914d\u7684LLM\u4ee3\u7406\uff0c\u5e76\u5c06\u5176\u54cd\u5e94\u4e0e\u539f\u59cb\u4eba\u7c7b\u6a21\u5f0f\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u67d0\u4e9b\u4eba\u683c-\u865a\u5047\u4fe1\u606f\u5173\u8054\uff0c\u7279\u522b\u662f\u6d89\u53ca\u5b9c\u4eba\u6027\u548c\u5c3d\u8d23\u6027\u7684\u5173\u8054\uff0c\u88ab\u53ef\u9760\u5730\u590d\u5236\uff0c\u800c\u5176\u4ed6\u5173\u8054\u5219\u5b58\u5728\u5dee\u5f02\uff0c\u63ed\u793a\u4e86LLM\u5982\u4f55\u5185\u90e8\u5316\u548c\u8868\u8fbe\u4eba\u683c\u7684\u7cfb\u7edf\u6027\u504f\u5dee\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u4e2a\u6027\u5bf9\u9f50\u7684LLM\u5728\u884c\u4e3a\u6a21\u62df\u4e2d\u7684\u6f5c\u529b\u548c\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u5728\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u4e2d\u5efa\u6a21\u8ba4\u77e5\u591a\u6837\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.23661", "pdf": "https://arxiv.org/pdf/2506.23661", "abs": "https://arxiv.org/abs/2506.23661", "authors": ["Arnisa Fazla", "Lucas Krauter", "David Guzman Piedrahita", "Andrianos Michail"], "title": "Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack", "categories": ["cs.CL"], "comment": "12 pages main text, 27 pages total including references and\n  appendices. 13 figures, 10 tables. Accepted for publication in the LNCS\n  proceedings of CLEF 2025 (Best-of-Labs track)", "summary": "We extend BeamAttack, an adversarial attack algorithm designed to evaluate\nthe robustness of text classification systems through word-level modifications\nguided by beam search. Our extensions include support for word deletions and\nthe option to skip substitutions, enabling the discovery of minimal\nmodifications that alter model predictions. We also integrate LIME to better\nprioritize word replacements. Evaluated across multiple datasets and victim\nmodels (BiLSTM, BERT, and adversarially trained RoBERTa) within the BODEGA\nframework, our approach achieves over a 99\\% attack success rate while\npreserving the semantic and lexical similarity of the original texts. Through\nboth quantitative and qualitative analysis, we highlight BeamAttack's\neffectiveness and its limitations. Our implementation is available at\nhttps://github.com/LucK1Y/BeamAttack", "AI": {"tldr": "\u6211\u4eec\u6269\u5c55\u4e86BeamAttack\uff0c\u4ee5\u63d0\u9ad8\u5bf9\u6297\u653b\u51fb\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u53d6\u5f97\u4e86\u9ad8\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u6211\u4eec\u7684\u6269\u5c55\u65e8\u5728\u63d0\u9ad8\u5bf9\u6297\u653b\u51fb\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4ee5\u8bc4\u4f30\u6587\u672c\u5206\u7c7b\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002", "method": "\u6211\u4eec\u6269\u5c55\u4e86BeamAttack\uff0c\u589e\u52a0\u4e86\u5bf9\u5355\u8bcd\u5220\u9664\u7684\u652f\u6301\uff0c\u5e76\u53ef\u4ee5\u9009\u62e9\u8df3\u8fc7\u66ff\u6362\uff0c\u4ee5\u53d1\u73b0\u6539\u53d8\u6a21\u578b\u9884\u6d4b\u7684\u6700\u5c0f\u4fee\u6539\u3002\u6211\u4eec\u8fd8\u96c6\u6210\u4e86LIME\u4ee5\u66f4\u597d\u5730\u4f18\u5148\u8003\u8651\u5355\u8bcd\u66ff\u6362\u3002", "result": "\u5728BODEGA\u6846\u67b6\u5185\u7684\u591a\u4e2a\u6570\u636e\u96c6\u548c\u53d7\u5bb3\u8005\u6a21\u578b\uff08BiLSTM\u3001BERT\u548c\u5bf9\u6297\u8bad\u7ec3\u7684RoBERTa\uff09\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8d85\u8fc799%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u539f\u59cb\u6587\u672c\u7684\u8bed\u4e49\u548c\u8bcd\u6c47\u76f8\u4f3c\u6027\u3002", "conclusion": "\u901a\u8fc7\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\uff0c\u6211\u4eec\u7a81\u663e\u4e86BeamAttack\u7684\u6709\u6548\u6027\u548c\u5176\u5c40\u9650\u6027\u3002"}}
{"id": "2506.23662", "pdf": "https://arxiv.org/pdf/2506.23662", "abs": "https://arxiv.org/abs/2506.23662", "authors": ["Philip Lippmann", "Jie Yang"], "title": "Zero-Shot Contextual Embeddings via Offline Synthetic Corpus Generation", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Context-aware embedding methods boost retrieval accuracy by conditioning on\ncorpus statistics (e.g., term co-occurrence and topical patterns) extracted\nfrom neighboring documents. However, this context-aware approach requires\naccess to the target corpus or requires domain-specific finetuning, posing\npractical barriers in privacy-sensitive or resource-constrained settings. We\npresent ZEST, a zero-shot contextual adaptation framework that replaces real\ncorpus access with a one-time offline synthesis of a compact proxy. Given only\na handful exemplar documents representative of the general target domain, we\nuse a multi-step hierarchical procedure to generate a synthetic context corpus\nof several hundred documents that aims to emulate key domain-specific\ndistributions. At inference, the frozen context-aware encoder uses this proxy\ncorpus -- without any finetuning or target corpus access -- to produce\ndomain-adapted embeddings. Across the MTEB benchmark, ZEST's zero-shot\nsynthetic context adaptation using only five example documents performs within\n0.5% of models leveraging full target corpus access -- demonstrating remarkable\nefficacy without any retraining. ZEST thus provides a practical method for\ndeploying high-performance, adaptable embeddings in constrained environments.", "AI": {"tldr": "ZEST is a zero-shot contextual adaptation framework that generates a synthetic context corpus to enable domain-adapted embeddings without requiring access to the target corpus or domain-specific finetuning.", "motivation": "Context-aware embedding methods boost retrieval accuracy by conditioning on corpus statistics, but they require access to the target corpus or domain-specific finetuning, which poses practical barriers in privacy-sensitive or resource-constrained settings.", "method": "ZEST is a zero-shot contextual adaptation framework that replaces real corpus access with a one-time offline synthesis of a compact proxy. It uses a multi-step hierarchical procedure to generate a synthetic context corpus of several hundred documents that aims to emulate key domain-specific distributions.", "result": "ZEST's zero-shot synthetic context adaptation using only five example documents performs within 0.5% of models leveraging full target corpus access, demonstrating remarkable efficacy without any retraining.", "conclusion": "ZEST provides a practical method for deploying high-performance, adaptable embeddings in constrained environments."}}
{"id": "2506.23667", "pdf": "https://arxiv.org/pdf/2506.23667", "abs": "https://arxiv.org/abs/2506.23667", "authors": ["Junjie Zhang", "Jingyi Xi", "Zhuoyang Song", "Junyu Lu", "Yuhua Ke", "Ting Sun", "Yukun Yang", "Jiaxing Zhang", "Songxin Zhang", "Zejian Xie"], "title": "L0: Reinforcement Learning to Become General Agents", "categories": ["cs.CL"], "comment": null, "summary": "Training large language models (LLMs) to act as autonomous agents for\nmulti-turn, long-horizon tasks remains significant challenges in scalability\nand training efficiency. To address this, we introduce L-Zero (L0), a scalable,\nend-to-end training pipeline for general-purpose agents. Featuring a low-cost,\nextensible, and sandboxed concurrent agent worker pool, L0 lowers the barrier\nfor applying reinforcement learning in complex environments. We also introduce\nNB-Agent, the agent scaffold within L0, which operates in a \"code-as-action\"\nfashion via a Read-Eval-Print-Loop (REPL). We evaluate L0 on factuality\nquestion-answering benchmarks. Our experiments demonstrate that a base model\ncan develop robust problem-solving skills using solely Reinforcement Learning\nwith Verifiable Rewards (RLVR). On the Qwen2.5-7B-Instruct model, our method\nboosts accuracy on SimpleQA from 30 % to 80 % and on HotpotQA from 22 % to 41\n%. We have open-sourced the entire L0 system, including our L0 series models,\nthe NB-Agent, a complete training pipeline, and the corresponding training\nrecipes on (https://github.com/cmriat/l0).", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86 L-Zero (L0) \u7cfb\u7edf\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u901a\u7528\u4ee3\u7406\u7684\u53ef\u6269\u5c55\u7aef\u5230\u7aef\u8bad\u7ec3\u7ba1\u9053\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4e0e\u9a8c\u8bc1\u5956\u52b1 (RLVR) \u63d0\u9ad8\u4e86\u95ee\u7b54\u4efb\u52a1\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u81ea\u4e3b\u4ee3\u7406\u6765\u6267\u884c\u591a\u8f6e\u3001\u957f\u5468\u671f\u4efb\u52a1\u4ecd\u7136\u662f\u53ef\u6269\u5c55\u6027\u548c\u8bad\u7ec3\u6548\u7387\u7684\u91cd\u5927\u6311\u6218\u3002", "method": "L-Zero (L0) \u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\u7ba1\u9053\uff0c\u7528\u4e8e\u901a\u7528\u4ee3\u7406\u3002NB-Agent \u662f L0 \u4e2d\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7 REPL \u4ee5\u201c\u4ee3\u7801\u5373\u52a8\u4f5c\u201d\u7684\u65b9\u5f0f\u8fd0\u884c\u3002", "result": "\u5728 Qwen2.5-7B-Instruct \u6a21\u578b\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5c06 SimpleQA \u7684\u51c6\u786e\u7387\u4ece 30% \u63d0\u9ad8\u5230 80%\uff0c\u5c06 HotpotQA \u7684\u51c6\u786e\u7387\u4ece 22% \u63d0\u9ad8\u5230 41%\u3002", "conclusion": "L0 \u7cfb\u7edf\u5728\u4e8b\u5b9e\u6027\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8868\u660e\u901a\u8fc7\u4ec5\u4f7f\u7528 RLVR \u7684\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u5f00\u53d1\u51fa\u5f3a\u5927\u7684\u95ee\u9898\u89e3\u51b3\u6280\u80fd\u3002"}}
{"id": "2506.23735", "pdf": "https://arxiv.org/pdf/2506.23735", "abs": "https://arxiv.org/abs/2506.23735", "authors": ["JiaRu Wu", "Mingwei Liu"], "title": "AutoEvoEval: An Automated Framework for Evolving Close-Ended LLM Evaluation Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have shown remarkable performance on various\ntasks, but existing evaluation benchmarks are often static and insufficient to\nfully assess their robustness and generalization in realistic scenarios. Prior\nwork using evolutionary or adversarial data augmentation has improved\nevaluation diversity but lacks systematic control over perturbation types and\nmulti-step complexity, limiting comprehensive robustness analysis. To address\nthese gaps, we propose AutoEvoEval, an evolution-based evaluation framework for\nclose-ended tasks such as multi-choice question answering. AutoEvoEval\nintroduces 22 interpretable atomic evolution operations and supports\nmulti-round compositions, enabling controlled generation of diverse,\nchallenging, and realistic test samples. We conduct extensive experiments\naddressing four research questions on a broad set of open- and closed-source\nLLMs. Our results show that atomic operations cause an average accuracy drop of\n7.283\\%, with structure-disrupting or misleading semantic edits causing the\nlargest declines. Model sensitivities vary significantly for the same\nperturbation, and combining multiple evolution steps amplifies adversarial\neffects by up to 52.932\\%. These findings suggest current benchmarks may\noverestimate true model generalization and emphasize the need for\nevolution-aware robustness evaluation. Code and resources are available at:\nhttps://github.com/SYSUSELab/AutoEvoEval.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.23743", "pdf": "https://arxiv.org/pdf/2506.23743", "abs": "https://arxiv.org/abs/2506.23743", "authors": ["Tiziano Labruna", "Simone Gallo", "Giovanni Da San Martino"], "title": "Positional Bias in Binary Question Answering: How Uncertainty Shapes Model Preferences", "categories": ["cs.CL"], "comment": null, "summary": "Positional bias in binary question answering occurs when a model\nsystematically favors one choice over another based solely on the ordering of\npresented options. In this study, we quantify and analyze positional bias\nacross five large language models under varying degrees of answer uncertainty.\nWe re-adapted the SQuAD-it dataset by adding an extra incorrect answer option\nand then created multiple versions with progressively less context and more\nout-of-context answers, yielding datasets that range from low to high\nuncertainty. Additionally, we evaluate two naturally higher-uncertainty\nbenchmarks: (1) WebGPT - question pairs with unequal human-assigned quality\nscores, and (2) Winning Arguments - where models predict the more persuasive\nargument in Reddit's r/ChangeMyView exchanges. Across each dataset, the order\nof the \"correct\" (or higher-quality/persuasive) option is systematically\nflipped (first placed in position 1, then in position 2) to compute both\nPreference Fairness and Position Consistency. We observe that positional bias\nis nearly absent under low-uncertainty conditions, but grows exponentially when\nit becomes doubtful to decide which option is correct.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u5728\u4e0d\u540c\u7b54\u6848\u4e0d\u786e\u5b9a\u6027\u6c34\u5e73\u4e0b\u4e94\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4f4d\u7f6e\u504f\u5dee\uff0c\u5e76\u53d1\u73b0\u5f53\u51b3\u5b9a\u54ea\u4e2a\u9009\u9879\u6b63\u786e\u53d8\u5f97\u56f0\u96be\u65f6\uff0c\u4f4d\u7f6e\u504f\u5dee\u4f1a\u663e\u8457\u589e\u52a0\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u91cf\u5316\u548c\u5206\u6790\u5728\u4e0d\u540c\u7b54\u6848\u4e0d\u786e\u5b9a\u6027\u6c34\u5e73\u4e0b\u4e94\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4f4d\u7f6e\u504f\u5dee\u3002", "method": "\u7814\u7a76\u8005\u91cd\u65b0\u8c03\u6574\u4e86SQuAD-it\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u6dfb\u52a0\u989d\u5916\u7684\u9519\u8bef\u7b54\u6848\u9009\u9879\uff0c\u5e76\u521b\u5efa\u4e86\u591a\u4e2a\u7248\u672c\uff0c\u8fd9\u4e9b\u7248\u672c\u9010\u6e10\u51cf\u5c11\u4e0a\u4e0b\u6587\u5e76\u589e\u52a0\u975e\u4e0a\u4e0b\u6587\u7b54\u6848\uff0c\u4ece\u800c\u4ea7\u751f\u4ece\u4f4e\u5230\u9ad8\u4e0d\u786e\u5b9a\u6027\u7684\u6570\u636e\u96c6\u3002\u6b64\u5916\uff0c\u8fd8\u8bc4\u4f30\u4e86\u4e24\u4e2a\u81ea\u7136\u66f4\u9ad8\u4e0d\u786e\u5b9a\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\uff1a(1) WebGPT - \u95ee\u9898\u5bf9\u5177\u6709\u4e0d\u76f8\u7b49\u7684\u4eba\u7c7b\u5206\u914d\u8d28\u91cf\u8bc4\u5206\uff0c\u4ee5\u53ca(2) Winning Arguments - \u6a21\u578b\u9884\u6d4bReddit\u7684r/ChangeMyView\u4ea4\u6d41\u4e2d\u66f4\u6709\u8bf4\u670d\u529b\u7684\u8bba\u70b9\u3002\u5728\u6bcf\u4e2a\u6570\u636e\u96c6\u4e2d\uff0c\u5c06\u201c\u6b63\u786e\u201d\uff08\u6216\u66f4\u9ad8\u8d28\u91cf/\u6709\u8bf4\u670d\u529b\uff09\u9009\u9879\u7684\u4f4d\u7f6e\u7cfb\u7edf\u5730\u7ffb\u8f6c\uff08\u9996\u5148\u653e\u5728\u4f4d\u7f6e1\uff0c\u7136\u540e\u653e\u5728\u4f4d\u7f6e2\uff09\uff0c\u4ee5\u8ba1\u7b97\u504f\u597d\u516c\u5e73\u6027\u548c\u4f4d\u7f6e\u4e00\u81f4\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u4f4e\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\uff0c\u4f4d\u7f6e\u504f\u5dee\u51e0\u4e4e\u4e0d\u5b58\u5728\uff0c\u4f46\u5f53\u51b3\u5b9a\u54ea\u4e2a\u9009\u9879\u6b63\u786e\u53d8\u5f97\u56f0\u96be\u65f6\uff0c\u4f4d\u7f6e\u504f\u5dee\u4f1a\u5448\u6307\u6570\u7ea7\u589e\u957f\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u4f4e\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\uff0c\u4f4d\u7f6e\u504f\u5dee\u51e0\u4e4e\u4e0d\u5b58\u5728\uff0c\u4f46\u5f53\u51b3\u5b9a\u54ea\u4e2a\u9009\u9879\u6b63\u786e\u53d8\u5f97\u56f0\u96be\u65f6\uff0c\u4f4d\u7f6e\u504f\u5dee\u4f1a\u5448\u6307\u6570\u7ea7\u589e\u957f\u3002"}}
{"id": "2506.23840", "pdf": "https://arxiv.org/pdf/2506.23840", "abs": "https://arxiv.org/abs/2506.23840", "authors": ["Bowen Ding", "Yuhan Chen", "Futing Wang", "Lingfeng Ming", "Tao Lin"], "title": "Do Thinking Tokens Help or Trap? Towards More Efficient Large Reasoning Model", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 5 figures", "summary": "Large Reasoning Models (LRMs) excel at solving complex problems but face an\noverthinking dilemma. When handling simple tasks, they often produce verbose\nresponses overloaded with thinking tokens (e.g., wait, however). These tokens\ntrigger unnecessary high-level reasoning behaviors like reflection and\nbacktracking, reducing efficiency. In this work, our pilot study reveals that\nthese thinking-token-induced behaviors are not essential for effective\nproblem-solving and may even hinder correct reasoning within constrained token\nbudgets. We identify this phenomenon as the thinking trap. To mitigate this\nissue, we propose Dual Policy Preference Optimization (DuP-PO), a novel\nalgorithm featuring: (1) A rollout sampling strategy that guarantees balanced\nexposure to responses with and without thinking tokens; (2) A fine-grained\nadvantage control technique to dynamically regulate the prediction of target\ntokens; (3) A policy shaping method ensuring stable gradient contributions from\nthinking tokens. Experimental results on five popular math reasoning benchmarks\nshow that DuP-PO performs well on the popular LRM, which significantly improves\ntheir token efficiency during reasoning, while achieving superior performance\nof the base model.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u5904\u7406\u7b80\u5355\u4efb\u52a1\u65f6\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86DuP-PO\u7b97\u6cd5\u6765\u63d0\u9ad8\u5176\u4ee4\u724c\u6548\u7387\u548c\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u9762\u4e34\u8fc7\u5ea6\u601d\u8003\u7684\u56f0\u5883\u3002\u5f53\u5904\u7406\u7b80\u5355\u4efb\u52a1\u65f6\uff0c\u5b83\u4eec\u5f80\u5f80\u4f1a\u4ea7\u751f\u5197\u957f\u7684\u54cd\u5e94\uff0c\u8fd9\u4e9b\u54cd\u5e94\u5145\u6ee1\u4e86\u601d\u8003\u6807\u8bb0\uff08\u4f8b\u5982\uff0cwait, however\uff09\u3002\u8fd9\u4e9b\u6807\u8bb0\u4f1a\u89e6\u53d1\u4e0d\u5fc5\u8981\u7684\u9ad8\u7ea7\u63a8\u7406\u884c\u4e3a\uff0c\u5982\u53cd\u601d\u548c\u56de\u6eaf\uff0c\u964d\u4f4e\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDual Policy Preference Optimization (DuP-PO)\u7684\u65b0\u7b97\u6cd5\uff0c\u5305\u62ec\uff1a(1) \u4e00\u79cd\u4fdd\u8bc1\u5bf9\u6709\u548c\u6ca1\u6709\u601d\u8003\u6807\u8bb0\u7684\u54cd\u5e94\u8fdb\u884c\u5e73\u8861\u66b4\u9732\u7684\u6eda\u52a8\u91c7\u6837\u7b56\u7565\uff1b(2) \u4e00\u79cd\u7ec6\u7c92\u5ea6\u7684\u4f18\u52bf\u63a7\u5236\u6280\u672f\uff0c\u4ee5\u52a8\u6001\u8c03\u8282\u76ee\u6807\u6807\u8bb0\u7684\u9884\u6d4b\uff1b(3) \u4e00\u79cd\u786e\u4fdd\u4ece\u601d\u8003\u6807\u8bb0\u4e2d\u83b7\u5f97\u7a33\u5b9a\u68af\u5ea6\u8d21\u732e\u7684\u7b56\u7565\u5851\u9020\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDuP-PO\u5728\u6d41\u884c\u7684LRM\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5176\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u4ee4\u724c\u6548\u7387\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u57fa\u7840\u6a21\u578b\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "DuP-PO\u5728\u4e94\u4e2a\u6d41\u884c\u7684\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u4ee4\u724c\u6548\u7387\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u57fa\u7840\u6a21\u578b\u7684\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2506.23864", "pdf": "https://arxiv.org/pdf/2506.23864", "abs": "https://arxiv.org/abs/2506.23864", "authors": ["Seyed Mahed Mousavi", "Edoardo Cecchinato", "Lucia Hornikova", "Giuseppe Riccardi"], "title": "Garbage In, Reasoning Out? Why Benchmark Scores are Unreliable and What to Do About It", "categories": ["cs.CL"], "comment": null, "summary": "We conduct a systematic audit of three widely used reasoning benchmarks,\nSocialIQa, FauxPas-EAI, and ToMi, and uncover pervasive flaws in both benchmark\nitems and evaluation methodology. Using five LLMs (GPT-{3, 3.5, 4, o1}, and\nLLaMA 3.1) as diagnostic tools, we identify structural, semantic, and pragmatic\nissues in benchmark design (e.g., duplicated items, ambiguous wording, and\nimplausible answers), as well as scoring procedures that prioritize output form\nover reasoning process. Through systematic human annotation and re-evaluation\non cleaned benchmark subsets, we find that model scores often improve not due\nto due to erratic surface wording variations and not to improved reasoning.\nInfact, further analyses show that model performance is highly sensitive to\nminor input variations such as context availability and phrasing, revealing\nthat high scores may reflect alignment with format-specific cues rather than\nconsistent inference based on the input. These findings challenge the validity\nof current benchmark-based claims about reasoning in LLMs, and highlight the\nneed for evaluation protocols that assess reasoning as a process of drawing\ninference from available information, rather than as static output selection.\nWe release audited data and evaluation tools to support more interpretable and\ndiagnostic assessments of model reasoning.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4e09\u4e2a\u5e38\u7528\u7684\u63a8\u7406\u57fa\u51c6\u8fdb\u884c\u4e86\u7cfb\u7edf\u5ba1\u8ba1\uff0c\u53d1\u73b0\u5176\u4e2d\u5b58\u5728\u8bbe\u8ba1\u548c\u8bc4\u4f30\u65b9\u6cd5\u4e0a\u7684\u7f3a\u9677\uff0c\u5e76\u6307\u51fa\u6a21\u578b\u5f97\u5206\u7684\u63d0\u9ad8\u53ef\u80fd\u5e76\u975e\u6e90\u4e8e\u771f\u6b63\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7684\u57fa\u51c6\u6d4b\u8bd5\u53ef\u80fd\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u771f\u5b9e\u63a8\u7406\u80fd\u529b\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u80fd\u5b58\u5728\u8bbe\u8ba1\u7f3a\u9677\u548c\u8bc4\u4f30\u65b9\u6cd5\u95ee\u9898\u3002", "method": "\u6211\u4eec\u4f7f\u7528\u4e94\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT-{3, 3.5, 4, o1} \u548c LLaMA 3.1\uff09\u4f5c\u4e3a\u8bca\u65ad\u5de5\u5177\uff0c\u5bf9\u4e09\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u63a8\u7406\u57fa\u51c6\u8fdb\u884c\u4e86\u7cfb\u7edf\u5ba1\u8ba1\uff0c\u53d1\u73b0\u4e86\u57fa\u51c6\u9879\u76ee\u548c\u8bc4\u4f30\u65b9\u6cd5\u4e2d\u7684\u666e\u904d\u7f3a\u9677\u3002\u901a\u8fc7\u7cfb\u7edf\u7684\u4eba\u5de5\u6ce8\u91ca\u548c\u5bf9\u6e05\u7406\u540e\u7684\u57fa\u51c6\u5b50\u96c6\u7684\u91cd\u65b0\u8bc4\u4f30\uff0c\u6211\u4eec\u53d1\u73b0\u6a21\u578b\u5206\u6570\u7684\u63d0\u9ad8\u5f80\u5f80\u4e0d\u662f\u7531\u4e8e\u8868\u9762\u63aa\u8f9e\u7684\u53d8\u5316\u6216\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\u3002", "result": "\u6211\u4eec\u53d1\u73b0\u6a21\u578b\u6027\u80fd\u5bf9\u8f93\u5165\u7684\u5fae\u5c0f\u53d8\u5316\uff08\u5982\u4e0a\u4e0b\u6587\u53ef\u7528\u6027\u548c\u63aa\u8f9e\uff09\u975e\u5e38\u654f\u611f\uff0c\u8fd9\u8868\u660e\u9ad8\u5206\u53ef\u80fd\u53cd\u6620\u4e86\u5bf9\u683c\u5f0f\u7279\u5b9a\u7ebf\u7d22\u7684\u5bf9\u9f50\uff0c\u800c\u4e0d\u662f\u57fa\u4e8e\u8f93\u5165\u7684\u4e00\u81f4\u63a8\u7406\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u6311\u6218\u4e86\u5f53\u524d\u57fa\u4e8e\u57fa\u51c6\u7684\u5173\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u58f0\u660e\uff0c\u5e76\u7a81\u663e\u4e86\u8bc4\u4f30\u534f\u8bae\u7684\u5fc5\u8981\u6027\uff0c\u8fd9\u4e9b\u534f\u8bae\u5e94\u8bc4\u4f30\u63a8\u7406\u4f5c\u4e3a\u4ece\u53ef\u7528\u4fe1\u606f\u4e2d\u5f97\u51fa\u63a8\u8bba\u7684\u8fc7\u7a0b\uff0c\u800c\u4e0d\u662f\u9759\u6001\u8f93\u51fa\u9009\u62e9\u3002\u6211\u4eec\u53d1\u5e03\u4e86\u7ecf\u8fc7\u5ba1\u8ba1\u7684\u6570\u636e\u548c\u8bc4\u4f30\u5de5\u5177\uff0c\u4ee5\u652f\u6301\u5bf9\u6a21\u578b\u63a8\u7406\u66f4\u53ef\u89e3\u91ca\u548c\u8bca\u65ad\u6027\u7684\u8bc4\u4f30\u3002"}}
{"id": "2506.23888", "pdf": "https://arxiv.org/pdf/2506.23888", "abs": "https://arxiv.org/abs/2506.23888", "authors": ["Andr\u00e9 de Souza Loureiro", "Jorge Valverde-Rebaza", "Julieta Noguez", "David Escarcega", "Ricardo Marcacini"], "title": "Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting", "categories": ["cs.CL"], "comment": "Accepted for publication in: European Conference on Machine Learning\n  and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD\n  2025). Research Track", "summary": "Recent advancements in Large Language Models (LLMs) have significantly\nimproved their problem-solving capabilities. However, these models still\nstruggle when faced with complex multi-step reasoning tasks. In this paper, we\npropose the Multi-Layered Self-Reflection with Auto-Prompting (MAPS) framework,\na novel approach designed to enhance multi-step mathematical reasoning in LLMs\nby integrating techniques such as Chain of Thought (CoT), Self-Reflection, and\nAuto-Prompting. Unlike traditional static prompting methods, MAPS employs an\niterative refinement process. Initially, the model generates a solution using\nCoT prompting. When errors are detected, an adaptive self-reflection mechanism\nidentifies and analyzes them, generating tailored prompts to guide corrections.\nThese dynamically adjusted prompts enable the model to iteratively refine its\nreasoning. Experiments on four well-established benchmarks across multiple LLMs\nshow that MAPS significantly outperforms standard CoT and achieves competitive\nresults with reasoning-optimized models. In addition, MAPS enables\ngeneral-purpose LLMs to reach performance levels comparable to specialized\nreasoning models. While deeper reflection layers improve accuracy, they also\nincrease token usage and costs. To balance this trade-off, MAPS strategically\nlimits reflection depth, ensuring an optimal balance between cost and reasoning\nperformance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aMAPS\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408Chain of Thought (CoT)\u3001Self-Reflection\u548cAuto-Prompting\u6280\u672f\uff0c\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6b65\u9aa4\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u8868\u73b0\u3002MAPS\u91c7\u7528\u8fed\u4ee3\u4f18\u5316\u8fc7\u7a0b\uff0c\u5f53\u68c0\u6d4b\u5230\u9519\u8bef\u65f6\uff0c\u81ea\u9002\u5e94\u81ea\u6211\u53cd\u601d\u673a\u5236\u4f1a\u8bc6\u522b\u5e76\u5206\u6790\u9519\u8bef\uff0c\u751f\u6210\u5b9a\u5236\u63d0\u793a\u4ee5\u6307\u5bfc\u4fee\u6b63\u3002\u5b9e\u9a8c\u8868\u660e\uff0cMAPS\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u6807\u51c6CoT\uff0c\u5e76\u4e0e\u4f18\u5316\u63a8\u7406\u7684\u6a21\u578b\u8fbe\u5230\u7ade\u4e89\u6027\u7ed3\u679c\u3002\u6b64\u5916\uff0cMAPS\u4f7f\u901a\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fbe\u5230\u4e0e\u4e13\u7528\u63a8\u7406\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u6c34\u5e73\u3002\u867d\u7136\u66f4\u6df1\u7684\u53cd\u601d\u5c42\u53ef\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u4e5f\u4f1a\u589e\u52a0\u4ee4\u724c\u4f7f\u7528\u548c\u6210\u672c\u3002\u4e3a\u4e86\u5e73\u8861\u8fd9\u79cd\u6743\u8861\uff0cMAPS\u6218\u7565\u6027\u5730\u9650\u5236\u53cd\u601d\u6df1\u5ea6\uff0c\u786e\u4fdd\u6210\u672c\u548c\u63a8\u7406\u6027\u80fd\u4e4b\u95f4\u7684\u6700\u4f73\u5e73\u8861\u3002", "motivation": "Recent advancements in Large Language Models (LLMs) have significantly improved their problem-solving capabilities. However, these models still struggle when faced with complex multi-step reasoning tasks.", "method": "MAPS employs an iterative refinement process. Initially, the model generates a solution using Chain of Thought (CoT) prompting. When errors are detected, an adaptive self-reflection mechanism identifies and analyzes them, generating tailored prompts to guide corrections. These dynamically adjusted prompts enable the model to iteratively refine its reasoning.", "result": "Experiments on four well-established benchmarks across multiple LLMs show that MAPS significantly outperforms standard CoT and achieves competitive results with reasoning-optimized models.", "conclusion": "MAPS enables general-purpose LLMs to reach performance levels comparable to specialized reasoning models. While deeper reflection layers improve accuracy, they also increase token usage and costs. To balance this trade-off, MAPS strategically limits reflection depth, ensuring an optimal balance between cost and reasoning performance."}}
{"id": "2506.23921", "pdf": "https://arxiv.org/pdf/2506.23921", "abs": "https://arxiv.org/abs/2506.23921", "authors": ["Germans Savcisens", "Tina Eliassi-Rad"], "title": "The Trilemma of Truth in Large Language Models", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "We often attribute human characteristics to large language models (LLMs) and\nclaim that they \"know\" certain things. LLMs have an internal probabilistic\nknowledge that represents information retained during training. How can we\nassess the veracity of this knowledge? We examine two common methods for\nprobing the veracity of LLMs and discover several assumptions that are flawed.\nTo address these flawed assumptions, we introduce sAwMIL (short for Sparse\nAware Multiple-Instance Learning), a probing method that utilizes the internal\nactivations of LLMs to separate statements into true, false, and neither.\nsAwMIL is based on multiple-instance learning and conformal prediction. We\nevaluate sAwMIL on 5 validity criteria across 16 open-source LLMs, including\nboth default and chat-based variants, as well as on 3 new datasets. Among the\ninsights we provide are: (1) the veracity signal is often concentrated in the\nthird quarter of an LLM's depth; (2) truth and falsehood signals are not always\nsymmetric; (3) linear probes perform better on chat models than on default\nmodels; (4) nonlinear probes may be required to capture veracity signals for\nsome LLMs with reinforcement learning from human feedback or knowledge\ndistillation; and (5) LLMs capture a third type of signal that is distinct from\ntrue and false and is neither true nor false. These findings provide a reliable\nmethod for verifying what LLMs \"know\" and how certain they are of their\nprobabilistic internal knowledge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5sAwMIL\u6765\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5185\u90e8\u6982\u7387\u77e5\u8bc6\u7684\u771f\u5b9e\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u591a\u4e2a\u5173\u4e8e\u771f\u5b9e\u6027\u4fe1\u53f7\u7684\u91cd\u8981\u53d1\u73b0\u3002", "motivation": "\u8bc4\u4f30LLMs\u5185\u90e8\u6982\u7387\u77e5\u8bc6\u7684\u771f\u5b9e\u6027\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u5047\u8bbe\u5b58\u5728\u7f3a\u9677\u3002", "method": "sAwMIL\uff08\u7a00\u758f\u611f\u77e5\u591a\u5b9e\u4f8b\u5b66\u4e60\uff09\u662f\u4e00\u79cd\u63a2\u6d4b\u65b9\u6cd5\uff0c\u5229\u7528LLMs\u7684\u5185\u90e8\u6fc0\u6d3b\u5c06\u9648\u8ff0\u5206\u4e3a\u771f\u5b9e\u3001\u865a\u5047\u548c\u65e2\u975e\u771f\u5b9e\u4e5f\u975e\u865a\u5047\u3002\u5b83\u57fa\u4e8e\u591a\u5b9e\u4f8b\u5b66\u4e60\u548c\u7b26\u5408\u9884\u6d4b\u3002", "result": "sAwMIL\u572816\u4e2a\u5f00\u6e90LLMs\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u53d1\u73b0\u4e86\u51e0\u4e2a\u5173\u4e8e\u771f\u5b9e\u6027\u4fe1\u53f7\u7684\u91cd\u8981\u89c1\u89e3\uff0c\u5305\u62ec\u771f\u5b9e\u6027\u4fe1\u53f7\u96c6\u4e2d\u5728LLM\u6df1\u5ea6\u7684\u7b2c\u4e09\u8c61\u9650\u3001\u771f\u5b9e\u4e0e\u865a\u5047\u4fe1\u53f7\u4e0d\u5bf9\u79f0\u3001\u7ebf\u6027\u63a2\u6d4b\u5668\u5728\u804a\u5929\u6a21\u578b\u4e2d\u8868\u73b0\u66f4\u597d\u7b49\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u9a8c\u8bc1LLMs'\u77e5\u9053\u4ec0\u4e48\u4ee5\u53ca\u4ed6\u4eec\u5bf9\u81ea\u5df1\u6982\u7387\u5185\u90e8\u77e5\u8bc6\u7684\u786e\u5b9a\u7a0b\u5ea6\u3002"}}
{"id": "2506.23929", "pdf": "https://arxiv.org/pdf/2506.23929", "abs": "https://arxiv.org/abs/2506.23929", "authors": ["Mohammed J. Saeed", "Tommi Vehvilainen", "Evgeny Fedoseev", "Sevil Caliskan", "Tatiana Vodolazova"], "title": "IMPACT: Inflectional Morphology Probes Across Complex Typologies", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have shown significant progress on various\nmultilingual benchmarks and are increasingly used to generate and evaluate text\nin non-English languages. However, while they may produce fluent outputs, it\nremains unclear to what extent these models truly grasp the underlying\nlinguistic complexity of those languages, particularly in morphology. To\ninvestigate this, we introduce IMPACT, a synthetically generated evaluation\nframework focused on inflectional morphology, which we publicly release,\ndesigned to evaluate LLM performance across five morphologically rich\nlanguages: Arabic, Russian, Finnish, Turkish, and Hebrew. IMPACT includes\nunit-test-style cases covering both shared and language-specific phenomena,\nfrom basic verb inflections (e.g., tense, number, gender) to unique features\nlike Arabic's reverse gender agreement and vowel harmony in Finnish and\nTurkish. We assess eight multilingual LLMs that, despite strong English\nperformance, struggle with other languages and uncommon morphological patterns,\nespecially when judging ungrammatical examples. We also show that Chain of\nThought and Thinking Models can degrade performance. Our work exposes gaps in\nLLMs' handling of linguistic complexity, pointing to clear room for\nimprovement. To support further research, we publicly release the IMPACT\nframework.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86IMPACT\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5c48\u6298\u5f62\u6001\u5b66\u65b9\u9762\u8868\u73b0\u7684\u5408\u6210\u751f\u6210\u8bc4\u4f30\u6846\u67b6\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1LLMs\u5728\u82f1\u8bed\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5904\u7406\u5176\u4ed6\u8bed\u8a00\u548c\u4e0d\u5e38\u89c1\u7684\u5f62\u6001\u6a21\u5f0f\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5224\u65ad\u4e0d\u5408\u6cd5\u7684\u4f8b\u5b50\u3002\u6b64\u5916\uff0c\u601d\u7ef4\u94fe\u548c\u601d\u7ef4\u6a21\u578b\u53ef\u80fd\u4f1a\u964d\u4f4e\u6027\u80fd\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cLLMs\u5728\u5904\u7406\u8bed\u8a00\u590d\u6742\u6027\u65b9\u9762\u4ecd\u6709\u660e\u663e\u4e0d\u8db3\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5404\u79cd\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u5e76\u4e14\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u751f\u6210\u548c\u8bc4\u4f30\u975e\u82f1\u8bed\u8bed\u8a00\u4e2d\u7684\u6587\u672c\uff0c\u4f46\u5b83\u4eec\u662f\u5426\u771f\u6b63\u7406\u89e3\u8fd9\u4e9b\u8bed\u8a00\u7684\u6f5c\u5728\u8bed\u8a00\u590d\u6742\u6027\uff0c\u7279\u522b\u662f\u5f62\u6001\u5b66\uff0c\u4ecd\u7136\u4e0d\u6e05\u695a\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u68c0\u67e5LLMs\u5728\u5904\u7406\u8bed\u8a00\u590d\u6742\u6027\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86IMPACT\uff0c\u8fd9\u662f\u4e00\u4e2a\u5408\u6210\u751f\u6210\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4e13\u6ce8\u4e8e\u5c48\u6298\u5f62\u6001\u5b66\uff0c\u6211\u4eec\u516c\u5f00\u53d1\u5e03\u5b83\uff0c\u65e8\u5728\u8bc4\u4f30\u8de8\u4e94\u79cd\u5f62\u6001\u4e30\u5bcc\u7684\u8bed\u8a00\uff08\u963f\u62c9\u4f2f\u8bed\u3001\u4fc4\u8bed\u3001\u82ac\u5170\u8bed\u3001\u571f\u8033\u5176\u8bed\u548c\u5e0c\u4f2f\u6765\u8bed\uff09\u7684LLM\u6027\u80fd\u3002IMPACT\u5305\u62ec\u5355\u5143\u6d4b\u8bd5\u98ce\u683c\u7684\u6848\u4f8b\uff0c\u6db5\u76d6\u4e86\u5171\u4eab\u548c\u8bed\u8a00\u7279\u5b9a\u7684\u73b0\u8c61\uff0c\u4ece\u57fa\u672c\u52a8\u8bcd\u53d8\u4f4d\uff08\u5982\u65f6\u6001\u3001\u6570\u3001\u6027\uff09\u5230\u72ec\u7279\u7684\u7279\u5f81\uff0c\u5982\u963f\u62c9\u4f2f\u8bed\u7684\u53cd\u5411\u6027\u522b\u4e00\u81f4\u6027\u548c\u82ac\u5170\u8bed\u53ca\u571f\u8033\u5176\u8bed\u7684\u5143\u97f3\u548c\u8c10\u3002", "result": "\u6211\u4eec\u8bc4\u4f30\u4e86\u516b\u79cd\u591a\u8bed\u8a00LLMs\uff0c\u5c3d\u7ba1\u5b83\u4eec\u5728\u82f1\u8bed\u4e0a\u7684\u8868\u73b0\u5f88\u5f3a\uff0c\u4f46\u5728\u5176\u4ed6\u8bed\u8a00\u548c\u4e0d\u5e38\u89c1\u7684\u5f62\u6001\u6a21\u5f0f\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u5c24\u5176\u662f\u5728\u5224\u65ad\u4e0d\u5408\u6cd5\u7684\u4f8b\u5b50\u65f6\u3002\u6211\u4eec\u8fd8\u53d1\u73b0\uff0c\u601d\u7ef4\u94fe\u548c\u601d\u7ef4\u6a21\u578b\u4f1a\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "\u6211\u4eec\u7684\u5de5\u4f5c\u63ed\u793a\u4e86LLMs\u5728\u5904\u7406\u8bed\u8a00\u590d\u6742\u6027\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u6307\u51fa\u4e86\u660e\u663e\u7684\u6539\u8fdb\u7a7a\u95f4\u3002\u4e3a\u4e86\u652f\u6301\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\uff0c\u6211\u4eec\u516c\u5f00\u53d1\u5e03\u4e86IMPACT\u6846\u67b6\u3002"}}
{"id": "2506.23930", "pdf": "https://arxiv.org/pdf/2506.23930", "abs": "https://arxiv.org/abs/2506.23930", "authors": ["Ruhina Tabasshum Prome", "Tarikul Islam Tamiti", "Anomadarshi Barua"], "title": "Leveraging the Potential of Prompt Engineering for Hate Speech Detection in Low-Resource Languages", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid expansion of social media leads to a marked increase in hate\nspeech, which threatens personal lives and results in numerous hate crimes.\nDetecting hate speech presents several challenges: diverse dialects, frequent\ncode-mixing, and the prevalence of misspelled words in user-generated content\non social media platforms. Recent progress in hate speech detection is\ntypically concentrated on high-resource languages. However, low-resource\nlanguages still face significant challenges due to the lack of large-scale,\nhigh-quality datasets. This paper investigates how we can overcome this\nlimitation via prompt engineering on large language models (LLMs) focusing on\nlow-resource Bengali language. We investigate six prompting strategies -\nzero-shot prompting, refusal suppression, flattering the classifier, multi-shot\nprompting, role prompting, and finally our innovative metaphor prompting to\ndetect hate speech effectively in low-resource languages. We pioneer the\nmetaphor prompting to circumvent the built-in safety mechanisms of LLMs that\nmarks a significant departure from existing jailbreaking methods. We\ninvestigate all six different prompting strategies on the Llama2-7B model and\ncompare the results extensively with three pre-trained word embeddings - GloVe,\nWord2Vec, and FastText for three different deep learning models - multilayer\nperceptron (MLP), convolutional neural network (CNN), and bidirectional gated\nrecurrent unit (BiGRU). To prove the effectiveness of our metaphor prompting in\nthe low-resource Bengali language, we also evaluate it in another low-resource\nlanguage - Hindi, and two high-resource languages - English and German. The\nperformance of all prompting techniques is evaluated using the F1 score, and\nenvironmental impact factor (IF), which measures CO$_2$ emissions, electricity\nusage, and computational time.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.23940", "pdf": "https://arxiv.org/pdf/2506.23940", "abs": "https://arxiv.org/abs/2506.23940", "authors": ["Yang Dai", "Jianxiang An", "Tianwei Lin", "Hongyang He", "Hongzhe Huang", "Wenqiao Zhang", "Zheqi Lv", "Siliang Tang", "Yueting Zhuang"], "title": "Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs", "categories": ["cs.CL"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have achieved success across various\ndomains. However, their applicability tends to degrade when confronted with\ndifferent types of data inputs, especially for MLLMs that have been fine-tuned\nfor specific tasks. Despite its importance, the study of knowledge sharing\namong domain-specific MLLMs--such as those trained for mathematics or\ncode--remains largely underexplored. To address the fragmentation of knowledge\nacross domain-specialized MLLMs, we propose a unified parameter integration\nframework that enables modular composition of expert capabilities. Our method\nis grounded in a novel Compatibility-Aware Parameter Splicing (CAPS) strategy,\nwhich leverages both local functional attribution and global\ninformation-theoretic signals to guide selective parameter fusion. By extending\nthis mechanism to the low-rank adaptation layer granularity, we ensure\nefficient integration with minimal inference overhead. Furthermore, we\nintroduce a domain compatibility scoring mechanism that quantifies inter-expert\nalignment at the activation level and correlates with downstream task utility.\nThis principled fusion protocol allows the final model to synergize\nheterogeneous expertise while preserving structural modularity. Extensive\nevaluations across diverse multimodal benchmarks validate the effectiveness of\nour framework, offering a scalable path toward compositional, domain-adaptive\nMLLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u53c2\u6570\u96c6\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3a\u9886\u57df\u4e13\u4e1a\u5316\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e4b\u95f4\u7684\u77e5\u8bc6\u5171\u4eab\u3002\u8be5\u6846\u67b6\u57fa\u4e8e\u517c\u5bb9\u6027\u611f\u77e5\u53c2\u6570\u62fc\u63a5\u7b56\u7565\uff0c\u5e76\u5f15\u5165\u4e86\u9886\u57df\u517c\u5bb9\u6027\u8bc4\u5206\u673a\u5236\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u4e14\u6709\u6548\u7684\u6a21\u578b\u6574\u5408\u3002", "motivation": "\u5c3d\u7ba1\u77e5\u8bc6\u5171\u4eab\u5728\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u9488\u5bf9\u7279\u5b9a\u9886\u57df\uff08\u5982\u6570\u5b66\u6216\u4ee3\u7801\uff09\u8bad\u7ec3\u7684MLLMs\u4e4b\u95f4\u7684\u77e5\u8bc6\u5171\u4eab\u7814\u7a76\u4ecd\u8f83\u4e3a\u7f3a\u4e4f\u3002\u4e3a\u4e86\u5e94\u5bf9\u9886\u57df\u4e13\u4e1a\u5316MLLMs\u4e4b\u95f4\u77e5\u8bc6\u7684\u788e\u7247\u5316\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u53c2\u6570\u96c6\u6210\u6846\u67b6\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u53c2\u6570\u96c6\u6210\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u4e00\u79cd\u65b0\u9896\u7684\u517c\u5bb9\u6027\u611f\u77e5\u53c2\u6570\u62fc\u63a5\uff08CAPS\uff09\u7b56\u7565\uff0c\u5229\u7528\u5c40\u90e8\u529f\u80fd\u5c5e\u6027\u548c\u5168\u5c40\u4fe1\u606f\u7406\u8bba\u4fe1\u53f7\u6765\u6307\u5bfc\u9009\u62e9\u6027\u53c2\u6570\u878d\u5408\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u9886\u57df\u517c\u5bb9\u6027\u8bc4\u5206\u673a\u5236\uff0c\u4ee5\u5728\u6fc0\u6d3b\u7ea7\u522b\u91cf\u5316\u4e13\u5bb6\u95f4\u7684\u5bf9\u9f50\u5ea6\uff0c\u5e76\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6548\u7528\u76f8\u5173\u8054\u3002", "result": "\u901a\u8fc7\u5c06\u8fd9\u79cd\u673a\u5236\u6269\u5c55\u5230\u4f4e\u79e9\u9002\u5e94\u5c42\u7c92\u5ea6\uff0c\u6211\u4eec\u786e\u4fdd\u4e86\u9ad8\u6548\u7684\u96c6\u6210\u5e76\u6700\u5c0f\u5316\u4e86\u63a8\u7406\u5f00\u9500\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u6700\u7ec8\u6a21\u578b\u534f\u540c\u5f02\u6784\u4e13\u4e1a\u77e5\u8bc6\uff0c\u540c\u65f6\u4fdd\u6301\u7ed3\u6784\u6a21\u5757\u5316\u3002", "conclusion": "\u6211\u4eec\u7684\u6846\u67b6\u5728\u591a\u79cd\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5f97\u5230\u4e86\u5e7f\u6cdb\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u6784\u5efa\u7ec4\u5408\u6027\u3001\u9886\u57df\u81ea\u9002\u5e94\u7684MLLMs\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
{"id": "2506.23951", "pdf": "https://arxiv.org/pdf/2506.23951", "abs": "https://arxiv.org/abs/2506.23951", "authors": ["Mathis Le Bail", "J\u00e9r\u00e9mie Dentan", "Davide Buscaldi", "Sonia Vanier"], "title": "Unveiling Decision-Making in LLMs for Text Classification : Extraction of influential and interpretable concepts with Sparse Autoencoders", "categories": ["cs.CL"], "comment": null, "summary": "Sparse Autoencoders (SAEs) have been successfully used to probe Large\nLanguage Models (LLMs) and extract interpretable concepts from their internal\nrepresentations. These concepts are linear combinations of neuron activations\nthat correspond to human-interpretable features. In this paper, we investigate\nthe effectiveness of SAE-based explainability approaches for sentence\nclassification, a domain where such methods have not been extensively explored.\nWe present a novel SAE-based architecture tailored for text classification,\nleveraging a specialized classifier head and incorporating an activation rate\nsparsity loss. We benchmark this architecture against established methods such\nas ConceptShap, Independent Component Analysis, and other SAE-based concept\nextraction techniques. Our evaluation covers two classification benchmarks and\nfour fine-tuned LLMs from the Pythia family. We further enrich our analysis\nwith two novel metrics for measuring the precision of concept-based\nexplanations, using an external sentence encoder. Our empirical results show\nthat our architecture improves both the causality and interpretability of the\nextracted features.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u7684\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u53e5\u5b50\u5206\u7c7b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u6587\u672c\u5206\u7c7b\u7684\u65b0\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u5728\u63d0\u53d6\u7279\u5f81\u7684\u56e0\u679c\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u6211\u4eec\u7814\u7a76\u4e86\u57fa\u4e8eSAE\u7684\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u53e5\u5b50\u5206\u7c7b\u9886\u57df\u7684\u6709\u6548\u6027\uff0c\u8fd9\u662f\u4e00\u4e2a\u6b64\u7c7b\u65b9\u6cd5\u5c1a\u672a\u5e7f\u6cdb\u63a2\u7d22\u7684\u9886\u57df\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6587\u672c\u5206\u7c7b\u7684\u65b0\u578b\u57fa\u4e8eSAE\u7684\u67b6\u6784\uff0c\u5229\u7528\u4e86\u4e13\u95e8\u7684\u5206\u7c7b\u5668\u5934\u548c\u6fc0\u6d3b\u7387\u7a00\u758f\u635f\u5931\u3002", "result": "\u6211\u4eec\u7684\u8bc4\u4f30\u6db5\u76d6\u4e86\u4e24\u4e2a\u5206\u7c7b\u57fa\u51c6\u548c\u56db\u4e2a\u5fae\u8c03\u7684Pythia\u5bb6\u65cfLLM\uff0c\u5e76\u4e14\u6211\u4eec\u5f15\u5165\u4e86\u4e24\u4e2a\u65b0\u7684\u5ea6\u91cf\u6807\u51c6\u6765\u8861\u91cf\u57fa\u4e8e\u6982\u5ff5\u7684\u89e3\u91ca\u7684\u7cbe\u5ea6\u3002", "conclusion": "\u6211\u4eec\u7684\u67b6\u6784\u5728\u63d0\u53d6\u7279\u5f81\u7684\u56e0\u679c\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u6709\u6240\u63d0\u9ad8\u3002"}}
{"id": "2506.23979", "pdf": "https://arxiv.org/pdf/2506.23979", "abs": "https://arxiv.org/abs/2506.23979", "authors": ["Renren Jin", "Tianhao Shen", "Xinwei Wu", "Dan Shi", "Haoran Sun", "Wuwei Huang", "Quandong Wang", "Wei Liu", "Jian Luan", "Bin Wang", "Deyi Xiong"], "title": "TaP: A Taxonomy-Guided Framework for Automated and Scalable Preference Data Generation", "categories": ["cs.CL"], "comment": "33 pages, 15 tables, 11 figures", "summary": "Conducting supervised fine-tuning and preference fine-tuning on large\nlanguage models (LLMs) requires high-quality datasets to improve their ability\nto follow instructions and align with human preferences and values. However,\nconstructing such datasets is resource-intensive, and most available datasets\nfor supervised and preference fine-tuning are in English. To address these\nchallenges, we propose the \\underline{\\textbf{Ta}}xonomy-Guided\n\\underline{\\textbf{P}}reference Data Generation (TaP) framework, which\nfacilitates automated and scalable construction of preference datasets across\nvarious languages. TaP is grounded in a structured taxonomy that allows\nfine-grained control over dataset composition, thereby ensuring both diversity\nand comprehensive coverage. We employ TaP-generated datasets to perform\nsupervised and preference fine-tuning on various LLMs. Experimental results\ndemonstrate that LLMs trained on TaP-generated datasets outperform those\ntrained on existing open-source datasets. Remarkably, LLMs trained on\nTaP-generated datasets surpass the performance of those trained on an\nopen-source dataset that is 180 times larger.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7ed3\u6784\u5316\u5206\u7c7b\u6cd5\u7684\u504f\u597d\u6570\u636e\u751f\u6210\u6846\u67b6TaP\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u548c\u53ef\u6269\u5c55\u5730\u6784\u5efa\u8de8\u591a\u79cd\u8bed\u8a00\u7684\u504f\u597d\u6570\u636e\u96c6\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528TaP\u751f\u6210\u7684\u6570\u636e\u96c6\u8bad\u7ec3\u7684LLM\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u5f00\u6e90\u6570\u636e\u96c6\u8bad\u7ec3\u7684LLM\uff0c\u751a\u81f3\u8d85\u8fc7\u4e86180\u500d\u5927\u7684\u5f00\u6e90\u6570\u636e\u96c6\u7684\u6027\u80fd\u3002", "motivation": "\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\u5bf9\u4e8e\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9075\u5faa\u6307\u4ee4\u548c\u4e0e\u4eba\u7c7b\u504f\u597d\u548c\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u53ef\u7528\u7684\u6570\u636e\u96c6\u4e3b\u8981\u96c6\u4e2d\u5728\u82f1\u8bed\u4e0a\uff0c\u5e76\u4e14\u6784\u5efa\u8fc7\u7a0b\u8d44\u6e90\u5bc6\u96c6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ed3\u6784\u5316\u5206\u7c7b\u6cd5\u7684\u504f\u597d\u6570\u636e\u751f\u6210\u6846\u67b6TaP\uff0c\u4ee5\u5b9e\u73b0\u8de8\u591a\u79cd\u8bed\u8a00\u7684\u81ea\u52a8\u5316\u548c\u53ef\u6269\u5c55\u7684\u504f\u597d\u6570\u636e\u96c6\u6784\u5efa\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528TaP\u751f\u6210\u7684\u6570\u636e\u96c6\u8bad\u7ec3\u7684LLM\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u5f00\u6e90\u6570\u636e\u96c6\u8bad\u7ec3\u7684LLM\uff0c\u751a\u81f3\u8d85\u8fc7\u4e86180\u500d\u5927\u7684\u5f00\u6e90\u6570\u636e\u96c6\u7684\u6027\u80fd\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528TaP\u751f\u6210\u7684\u6570\u636e\u96c6\u8bad\u7ec3\u7684LLM\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u5f00\u6e90\u6570\u636e\u96c6\u8bad\u7ec3\u7684LLM\uff0c\u751a\u81f3\u8d85\u8fc7\u4e86180\u500d\u5927\u7684\u5f00\u6e90\u6570\u636e\u96c6\u7684\u6027\u80fd\u3002"}}
{"id": "2506.23990", "pdf": "https://arxiv.org/pdf/2506.23990", "abs": "https://arxiv.org/abs/2506.23990", "authors": ["Dustin Wright"], "title": "Machine Understanding of Scientific Language", "categories": ["cs.CL", "cs.LG"], "comment": "PhD Thesis, 210 pages", "summary": "Scientific information expresses human understanding of nature. This\nknowledge is largely disseminated in different forms of text, including\nscientific papers, news articles, and discourse among people on social media.\nWhile important for accelerating our pursuit of knowledge, not all scientific\ntext is faithful to the underlying science. As the volume of this text has\nburgeoned online in recent years, it has become a problem of societal\nimportance to be able to identify the faithfulness of a given piece of\nscientific text automatically. This thesis is concerned with the cultivation of\ndatasets, methods, and tools for machine understanding of scientific language,\nin order to analyze and understand science communication at scale. To arrive at\nthis, I present several contributions in three areas of natural language\nprocessing and machine learning: automatic fact checking, learning with limited\ndata, and scientific text processing. These contributions include new methods\nand resources for identifying check-worthy claims, adversarial claim\ngeneration, multi-source domain adaptation, learning from crowd-sourced labels,\ncite-worthiness detection, zero-shot scientific fact checking, detecting\nexaggerated scientific claims, and modeling degrees of information change in\nscience communication. Critically, I demonstrate how the research outputs of\nthis thesis are useful for effectively learning from limited amounts of\nscientific text in order to identify misinformative scientific statements and\ngenerate new insights into the science communication process", "AI": {"tldr": "\u672c\u6587\u65e8\u5728\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u63d0\u9ad8\u5bf9\u79d1\u5b66\u6587\u672c\u5fe0\u5b9e\u6027\u7684\u81ea\u52a8\u8bc6\u522b\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u65b9\u6cd5\u548c\u8d44\u6e90\u6765\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002", "motivation": "\u79d1\u5b66\u4fe1\u606f\u8868\u8fbe\u4e86\u4eba\u7c7b\u5bf9\u81ea\u7136\u7684\u7406\u89e3\uff0c\u4f46\u5e76\u975e\u6240\u6709\u79d1\u5b66\u6587\u672c\u90fd\u5fe0\u5b9e\u4e8e\u57fa\u7840\u79d1\u5b66\u3002\u968f\u7740\u8fd1\u5e74\u6765\u79d1\u5b66\u6587\u672c\u5728\u7f51\u4e0a\u7684\u6fc0\u589e\uff0c\u80fd\u591f\u81ea\u52a8\u8bc6\u522b\u79d1\u5b66\u6587\u672c\u7684\u5fe0\u5b9e\u6027\u5df2\u6210\u4e3a\u4e00\u4e2a\u793e\u4f1a\u91cd\u8981\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u673a\u5668\u5b66\u4e60\u7684\u4e09\u4e2a\u9886\u57df\u7684\u8d21\u732e\uff1a\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u3001\u6709\u9650\u6570\u636e\u5b66\u4e60\u548c\u79d1\u5b66\u6587\u672c\u5904\u7406\u3002\u8fd9\u4e9b\u8d21\u732e\u5305\u62ec\u65b0\u65b9\u6cd5\u548c\u8d44\u6e90\uff0c\u7528\u4e8e\u8bc6\u522b\u503c\u5f97\u68c0\u67e5\u7684\u4e3b\u5f20\u3001\u5bf9\u6297\u6027\u4e3b\u5f20\u751f\u6210\u3001\u591a\u6e90\u9886\u57df\u9002\u5e94\u3001\u4ece\u4f17\u5305\u6807\u7b7e\u5b66\u4e60\u3001\u5f15\u7528\u4ef7\u503c\u68c0\u6d4b\u3001\u96f6\u6837\u672c\u79d1\u5b66\u4e8b\u5b9e\u6838\u67e5\u3001\u68c0\u6d4b\u5938\u5f20\u7684\u79d1\u5b66\u4e3b\u5f20\u4ee5\u53ca\u5efa\u6a21\u79d1\u5b66\u4f20\u64ad\u4e2d\u7684\u4fe1\u606f\u53d8\u5316\u7a0b\u5ea6\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u65b9\u6cd5\u548c\u8d44\u6e90\uff0c\u7528\u4e8e\u5206\u6790\u548c\u7406\u89e3\u79d1\u5b66\u4f20\u64ad\uff0c\u5e76\u5c55\u793a\u4e86\u8fd9\u4e9b\u7814\u7a76\u8f93\u51fa\u5728\u4ece\u6709\u9650\u7684\u79d1\u5b66\u6587\u672c\u4e2d\u5b66\u4e60\u4ee5\u8bc6\u522b\u8bef\u5bfc\u6027\u79d1\u5b66\u9648\u8ff0\u548c\u751f\u6210\u79d1\u5b66\u4f20\u64ad\u8fc7\u7a0b\u7684\u65b0\u89c1\u89e3\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u7814\u7a76\u8f93\u51fa\u6709\u6548\u4ece\u6709\u9650\u7684\u79d1\u5b66\u6587\u672c\u4e2d\u5b66\u4e60\uff0c\u4ee5\u8bc6\u522b\u8bef\u5bfc\u6027\u7684\u79d1\u5b66\u9648\u8ff0\uff0c\u5e76\u751f\u6210\u5173\u4e8e\u79d1\u5b66\u4f20\u64ad\u8fc7\u7a0b\u7684\u65b0\u89c1\u89e3\u3002"}}
{"id": "2506.23998", "pdf": "https://arxiv.org/pdf/2506.23998", "abs": "https://arxiv.org/abs/2506.23998", "authors": ["Seungjun Yi", "Joakim Nguyen", "Huimin Xu", "Terence Lim", "Andrew Well", "Mia Markey", "Ying Ding"], "title": "Auto-TA: Towards Scalable Automated Thematic Analysis (TA) via Multi-Agent Large Language Models with Reinforcement Learning", "categories": ["cs.CL"], "comment": "Presented at ACL 2025 SRW", "summary": "Congenital heart disease (CHD) presents complex, lifelong challenges often\nunderrepresented in traditional clinical metrics. While unstructured narratives\noffer rich insights into patient and caregiver experiences, manual thematic\nanalysis (TA) remains labor-intensive and unscalable. We propose a fully\nautomated large language model (LLM) pipeline that performs end-to-end TA on\nclinical narratives, which eliminates the need for manual coding or full\ntranscript review. Our system employs a novel multi-agent framework, where\nspecialized LLM agents assume roles to enhance theme quality and alignment with\nhuman analysis. To further improve thematic relevance, we optionally integrate\nreinforcement learning from human feedback (RLHF). This supports scalable,\npatient-centered analysis of large qualitative datasets and allows LLMs to be\nfine-tuned for specific clinical contexts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7ba1\u9053\uff0c\u7528\u4e8e\u5bf9\u4e34\u5e8a\u53d9\u8ff0\u8fdb\u884c\u7aef\u5230\u7aef\u4e3b\u9898\u5206\u6790\uff0c\u4ece\u800c\u6d88\u9664\u624b\u52a8\u7f16\u7801\u6216\u5b8c\u6574\u8f6c\u5f55\u672c\u5ba1\u67e5\u7684\u9700\u8981\u3002\u8be5\u7cfb\u7edf\u91c7\u7528\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u5176\u4e2d\u4e13\u95e8\u7684LLM\u4ee3\u7406\u627f\u62c5\u89d2\u8272\u4ee5\u63d0\u9ad8\u4e3b\u9898\u8d28\u91cf\u548c\u4e0e\u4eba\u7c7b\u5206\u6790\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u53ef\u9009\u62e9\u96c6\u6210\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\u4ee5\u63d0\u9ad8\u4e3b\u9898\u76f8\u5173\u6027\u3002", "motivation": "\u5148\u5929\u6027\u5fc3\u810f\u75c5\uff08CHD\uff09\u5e26\u6765\u4e86\u590d\u6742\u7684\u3001\u7ec8\u8eab\u7684\u6311\u6218\uff0c\u901a\u5e38\u5728\u4f20\u7edf\u7684\u4e34\u5e8a\u6307\u6807\u4e2d\u88ab\u4f4e\u4f30\u3002\u867d\u7136\u975e\u7ed3\u6784\u5316\u53d9\u8ff0\u63d0\u4f9b\u4e86\u5173\u4e8e\u60a3\u8005\u548c\u62a4\u7406\u4eba\u5458\u7ecf\u9a8c\u7684\u4e30\u5bcc\u89c1\u89e3\uff0c\u4f46\u624b\u52a8\u4e3b\u9898\u5206\u6790\uff08TA\uff09\u4ecd\u7136\u662f\u52b3\u52a8\u5bc6\u96c6\u578b\u4e14\u4e0d\u53ef\u6269\u5c55\u7684\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7ba1\u9053\uff0c\u8be5\u7ba1\u9053\u6267\u884c\u7aef\u5230\u7aef\u7684\u4e3b\u9898\u5206\u6790\uff08TA\uff09\u4e34\u5e8a\u53d9\u8ff0\uff0c\u6d88\u9664\u4e86\u624b\u52a8\u7f16\u7801\u6216\u5b8c\u6574\u8f6c\u5f55\u672c\u5ba1\u67e5\u7684\u9700\u8981\u3002\u6211\u4eec\u7684\u7cfb\u7edf\u91c7\u7528\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u5176\u4e2d\u4e13\u95e8\u7684LLM\u4ee3\u7406\u627f\u62c5\u89d2\u8272\u4ee5\u63d0\u9ad8\u4e3b\u9898\u8d28\u91cf\u548c\u4e0e\u4eba\u7c7b\u5206\u6790\u7684\u4e00\u81f4\u6027\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e3b\u9898\u7684\u76f8\u5173\u6027\uff0c\u6211\u4eec\u53ef\u9009\u62e9\u96c6\u6210\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\u3002", "result": "\u6211\u4eec\u7684\u7cfb\u7edf\u901a\u8fc7\u4f7f\u7528\u591a\u4ee3\u7406\u6846\u67b6\u548c\u53ef\u9009\u7684\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\uff0c\u5b9e\u73b0\u4e86\u5bf9\u4e34\u5e8a\u53d9\u8ff0\u7684\u7aef\u5230\u7aef\u4e3b\u9898\u5206\u6790\uff0c\u4ece\u800c\u652f\u6301\u5927\u89c4\u6a21\u5b9a\u6027\u6570\u636e\u7684\u53ef\u6269\u5c55\u3001\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u7684\u5206\u6790\uff0c\u5e76\u5141\u8bb8LLM\u9488\u5bf9\u7279\u5b9a\u7684\u4e34\u5e8a\u73af\u5883\u8fdb\u884c\u5fae\u8c03\u3002", "conclusion": "\u6211\u4eec\u7684\u7cfb\u7edf\u901a\u8fc7\u4f7f\u7528\u591a\u4ee3\u7406\u6846\u67b6\u548c\u53ef\u9009\u7684\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\uff0c\u5b9e\u73b0\u4e86\u5bf9\u4e34\u5e8a\u53d9\u8ff0\u7684\u7aef\u5230\u7aef\u4e3b\u9898\u5206\u6790\uff0c\u4ece\u800c\u652f\u6301\u5927\u89c4\u6a21\u5b9a\u6027\u6570\u636e\u7684\u53ef\u6269\u5c55\u3001\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u7684\u5206\u6790\uff0c\u5e76\u5141\u8bb8LLM\u9488\u5bf9\u7279\u5b9a\u7684\u4e34\u5e8a\u73af\u5883\u8fdb\u884c\u5fae\u8c03\u3002"}}
{"id": "2506.24006", "pdf": "https://arxiv.org/pdf/2506.24006", "abs": "https://arxiv.org/abs/2506.24006", "authors": ["Anselm R. Strohmaier", "Wim Van Dooren", "Kathrin Se\u00dfler", "Brian Greer", "Lieven Verschaffel"], "title": "Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective", "categories": ["cs.CL", "math.HO"], "comment": null, "summary": "The progress of Large Language Models (LLMs) like ChatGPT raises the question\nof how they can be integrated into education. One hope is that they can support\nmathematics learning, including word-problem solving. Since LLMs can handle\ntextual input with ease, they appear well-suited for solving mathematical word\nproblems. Yet their real competence, whether they can make sense of the\nreal-world context, and the implications for classrooms remain unclear. We\nconducted a scoping review from a mathematics-education perspective, including\nthree parts: a technical overview, a systematic review of word problems used in\nresearch, and a state-of-the-art empirical evaluation of LLMs on mathematical\nword problems. First, in the technical overview, we contrast the\nconceptualization of word problems and their solution processes between LLMs\nand students. In computer-science research this is typically labeled\nmathematical reasoning, a term that does not align with usage in mathematics\neducation. Second, our literature review of 213 studies shows that the most\npopular word-problem corpora are dominated by s-problems, which do not require\na consideration of realities of their real-world context. Finally, our\nevaluation of GPT-3.5-turbo, GPT-4o-mini, GPT-4.1, and o3 on 287 word problems\nshows that most recent LLMs solve these s-problems with near-perfect accuracy,\nincluding a perfect score on 20 problems from PISA. LLMs still showed\nweaknesses in tackling problems where the real-world context is problematic or\nnon-sensical. In sum, we argue based on all three aspects that LLMs have\nmastered a superficial solution process but do not make sense of word problems,\nwhich potentially limits their value as instructional tools in mathematics\nclassrooms.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u5e94\u7528\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5b83\u4eec\u867d\u7136\u5728\u89e3\u51b3\u8868\u9762\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u7406\u89e3\u73b0\u5b9e\u4e16\u754c\u80cc\u666f\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\uff0c\u8fd9\u53ef\u80fd\u9650\u5236\u4e86\u5b83\u4eec\u4f5c\u4e3a\u6559\u5b66\u5de5\u5177\u7684\u6f5c\u529b\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982ChatGPT\uff09\u7684\u8fdb\u6b65\uff0c\u4eba\u4eec\u5f00\u59cb\u601d\u8003\u5982\u4f55\u5c06\u5b83\u4eec\u6574\u5408\u5230\u6559\u80b2\u4e2d\u3002\u5176\u4e2d\u4e00\u4e2a\u5e0c\u671b\u662f\u5b83\u4eec\u53ef\u4ee5\u652f\u6301\u6570\u5b66\u5b66\u4e60\uff0c\u5305\u62ec\u89e3\u51b3\u5e94\u7528\u9898\u3002\u7136\u800c\uff0c\u5b83\u4eec\u7684\u771f\u5b9e\u80fd\u529b\u4ee5\u53ca\u5bf9\u8bfe\u5802\u7684\u5f71\u54cd\u4ecd\u7136\u4e0d\u6e05\u695a\u3002", "method": "\u6211\u4eec\u8fdb\u884c\u4e86\u4e00\u9879\u8303\u56f4\u56de\u987e\uff0c\u5305\u62ec\u6280\u672f\u6982\u8ff0\u3001\u5bf9\u7814\u7a76\u4e2d\u4f7f\u7528\u7684\u5e94\u7528\u9898\u7684\u7cfb\u7edf\u56de\u987e\u4ee5\u53ca\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u5e94\u7528\u9898\u4e0a\u7684\u6700\u65b0\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u6211\u4eec\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u6700\u8fd1\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u51b3s-problems\u65b9\u9762\u5177\u6709\u63a5\u8fd1\u5b8c\u7f8e\u7684\u51c6\u786e\u6027\uff0c\u5305\u62ec\u5728PISA\u768420\u4e2a\u95ee\u9898\u4e0a\u83b7\u5f97\u6ee1\u5206\u3002\u7136\u800c\uff0c\u5b83\u4eec\u5728\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u80cc\u666f\u6709\u95ee\u9898\u6216\u4e0d\u5408\u7406\u7684\u9898\u76ee\u65f6\u4ecd\u8868\u73b0\u51fa\u5f31\u70b9\u3002", "conclusion": "\u6211\u4eec\u57fa\u4e8e\u4e09\u4e2a\u65b9\u9762\u8ba4\u4e3a\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5df2\u7ecf\u638c\u63e1\u4e86\u8868\u9762\u7684\u89e3\u9898\u8fc7\u7a0b\uff0c\u4f46\u5e76\u4e0d\u80fd\u7406\u89e3\u5e94\u7528\u9898\uff0c\u8fd9\u53ef\u80fd\u9650\u5236\u4e86\u5b83\u4eec\u4f5c\u4e3a\u6570\u5b66\u8bfe\u5802\u4e2d\u7684\u6559\u5b66\u5de5\u5177\u7684\u4ef7\u503c\u3002"}}
{"id": "2506.24016", "pdf": "https://arxiv.org/pdf/2506.24016", "abs": "https://arxiv.org/abs/2506.24016", "authors": ["Hyunjong Kim", "Sangyeop Kim", "Jongheon Jeong", "Yeongjae Cho", "Sungzoon Cho"], "title": "EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "Accepted at ACL 2025 Findings", "summary": "Recent advances in large language models and vision-language models have led\nto growing interest in explainable evaluation metrics for image captioning.\nHowever, these metrics generate explanations without standardized criteria, and\nthe overall quality of the generated explanations remains unverified. In this\npaper, we propose EXPERT, a reference-free evaluation metric that provides\nstructured explanations based on three fundamental criteria: fluency,\nrelevance, and descriptiveness. By constructing large-scale datasets of\nhigh-quality structured explanations, we develop a two-stage evaluation\ntemplate to effectively supervise a vision-language model for both scoring and\nexplanation generation. EXPERT achieves state-of-the-art results on benchmark\ndatasets while providing significantly higher-quality explanations than\nexisting metrics, as validated through comprehensive human evaluation. Our code\nand datasets are available at https://github.com/hjkim811/EXPERT.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u53c2\u8003\u7684\u8bc4\u4f30\u6307\u6807EXPERT\uff0c\u8be5\u6307\u6807\u57fa\u4e8e\u6d41\u7545\u6027\u3001\u76f8\u5173\u6027\u548c\u63cf\u8ff0\u6027\u4e09\u4e2a\u57fa\u672c\u6807\u51c6\u63d0\u4f9b\u7ed3\u6784\u5316\u7684\u89e3\u91ca\u3002\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u7ed3\u6784\u5316\u89e3\u91ca\u6570\u636e\u96c6\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684\u8bc4\u4f30\u6a21\u677f\uff0c\u4ee5\u6709\u6548\u76d1\u7763\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc4\u5206\u548c\u89e3\u91ca\u751f\u6210\u3002EXPERT\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5e76\u901a\u8fc7\u5168\u9762\u7684\u4eba\u7c7b\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u5176\u89e3\u91ca\u8d28\u91cf\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6307\u6807\u3002", "motivation": "Recent advances in large language models and vision-language models have led to growing interest in explainable evaluation metrics for image captioning. However, these metrics generate explanations without standardized criteria, and the overall quality of the generated explanations remains unverified.", "method": "We propose EXPERT, a reference-free evaluation metric that provides structured explanations based on three fundamental criteria: fluency, relevance, and descriptiveness. By constructing large-scale datasets of high-quality structured explanations, we develop a two-stage evaluation template to effectively supervise a vision-language model for both scoring and explanation generation.", "result": "EXPERT achieves state-of-the-art results on benchmark datasets while providing significantly higher-quality explanations than existing metrics, as validated through comprehensive human evaluation.", "conclusion": "EXPERT achieves state-of-the-art results on benchmark datasets while providing significantly higher-quality explanations than existing metrics, as validated through comprehensive human evaluation."}}
{"id": "2506.24068", "pdf": "https://arxiv.org/pdf/2506.24068", "abs": "https://arxiv.org/abs/2506.24068", "authors": ["Ian R. McKenzie", "Oskar J. Hollinsworth", "Tom Tseng", "Xander Davies", "Stephen Casper", "Aaron D. Tucker", "Robert Kirk", "Adam Gleave"], "title": "STACK: Adversarial Attacks on LLM Safeguard Pipelines", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Frontier AI developers are relying on layers of safeguards to protect against\ncatastrophic misuse of AI systems. Anthropic guards their latest Claude 4 Opus\nmodel using one such defense pipeline, and other frontier developers including\nGoogle DeepMind and OpenAI pledge to soon deploy similar defenses. However, the\nsecurity of such pipelines is unclear, with limited prior work evaluating or\nattacking these pipelines. We address this gap by developing and red-teaming an\nopen-source defense pipeline. First, we find that a novel few-shot-prompted\ninput and output classifier outperforms state-of-the-art open-weight safeguard\nmodel ShieldGemma across three attacks and two datasets, reducing the attack\nsuccess rate (ASR) to 0% on the catastrophic misuse dataset ClearHarm. Second,\nwe introduce a STaged AttaCK (STACK) procedure that achieves 71% ASR on\nClearHarm in a black-box attack against the few-shot-prompted classifier\npipeline. Finally, we also evaluate STACK in a transfer setting, achieving 33%\nASR, providing initial evidence that it is feasible to design attacks with no\naccess to the target pipeline. We conclude by suggesting specific mitigations\nthat developers could use to thwart staged attacks.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86AI\u7cfb\u7edf\u7684\u5b89\u5168\u9632\u5fa1\u7ba1\u9053\uff0c\u53d1\u73b0\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u7684\u5206\u7c7b\u5668\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u7f13\u89e3\u63aa\u65bd\u3002", "motivation": "\u5f53\u524d\u5bf9\u8fd9\u4e9b\u9632\u5fa1\u7ba1\u9053\u7684\u5b89\u5168\u6027\u4e86\u89e3\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u8fdb\u884c\u8bc4\u4f30\u548c\u653b\u51fb\u4ee5\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u6211\u4eec\u5f00\u53d1\u5e76\u7ea2\u961f\u6d4b\u8bd5\u4e86\u4e00\u4e2a\u5f00\u6e90\u9632\u5fa1\u7ba1\u9053\uff0c\u9996\u5148\u53d1\u73b0\u4e86\u4e00\u79cd\u65b0\u7684\u5c11\u6837\u672c\u63d0\u793a\u8f93\u5165\u548c\u8f93\u51fa\u5206\u7c7b\u5668\uff0c\u5176\u6b21\u5f15\u5165\u4e86STaged AttaCK (STACK) \u65b9\u6cd5\uff0c\u5e76\u5728\u8f6c\u79fb\u8bbe\u7f6e\u4e2d\u8bc4\u4f30\u4e86STACK\u3002", "result": "\u65b0\u5206\u7c7b\u5668\u5728\u4e09\u4e2a\u653b\u51fb\u548c\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684ShieldGemma\u6a21\u578b\uff0c\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e\u52300%\uff1bSTACK\u65b9\u6cd5\u5728\u9ed1\u76d2\u653b\u51fb\u4e2d\u5b9e\u73b0\u4e8671%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e76\u5728\u8f6c\u79fb\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u4e8633%\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "conclusion": "\u6211\u4eec\u5efa\u8bae\u5f00\u53d1\u8005\u53ef\u4ee5\u4f7f\u7528\u7279\u5b9a\u7684\u7f13\u89e3\u63aa\u65bd\u6765\u963b\u6b62\u5206\u9636\u6bb5\u653b\u51fb\u3002"}}
{"id": "2506.24106", "pdf": "https://arxiv.org/pdf/2506.24106", "abs": "https://arxiv.org/abs/2506.24106", "authors": ["Yanhong Li", "Ming Li", "Karen Livescu", "Jiawei Zhou"], "title": "On the Predictive Power of Representation Dispersion in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We show that a language model's ability to predict text is tightly linked to\nthe breadth of its embedding space: models that spread their contextual\nrepresentations more widely tend to achieve lower perplexity. Concretely, we\nfind that representation dispersion - the average pairwise cosine distance\namong hidden vectors - strongly and negatively correlates with perplexity\nacross diverse model families (LLaMA, Qwen, and others) and domains (Wikipedia,\nnews, scientific abstracts). Beyond illustrating this link, we show how\ndispersion can be leveraged for a range of practical tasks without requiring\nlabeled data. First, measuring dispersion on unlabeled text allows us to\npredict downstream accuracy in new domains, offering a data-efficient tool for\nmodel selection. Next, we find that identifying layers with higher dispersion\npinpoints the best representations for retrieval-based methods such as kNN-LM,\nbypassing exhaustive layer-by-layer searches. Finally, we integrate a simple\npush-away objective into training, which increases dispersion in both\nsingle-domain and cross-domain scenarios and directly improves perplexity in\neach.", "AI": {"tldr": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u8868\u793a\u5206\u6563\u6027\u4e0e\u5176\u6587\u672c\u9884\u6d4b\u80fd\u529b\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u6807\u8bb0\u6570\u636e\u5373\u53ef\u4f18\u5316\u6a21\u578b\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "motivation": "\u6211\u4eec\u5e0c\u671b\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u7684\u8868\u793a\u5206\u6563\u6027\u4e0e\u5176\u6587\u672c\u9884\u6d4b\u80fd\u529b\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u5bfb\u627e\u4e00\u79cd\u65e0\u9700\u6807\u8bb0\u6570\u636e\u5373\u53ef\u4f18\u5316\u6a21\u578b\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "method": "\u6211\u4eec\u901a\u8fc7\u8ba1\u7b97\u9690\u85cf\u5411\u91cf\u4e4b\u95f4\u7684\u5e73\u5747\u4f59\u5f26\u8ddd\u79bb\u6765\u8861\u91cf\u8868\u793a\u7684\u5206\u6563\u6027\uff0c\u5e76\u5c06\u5176\u4e0e\u56f0\u60d1\u5ea6\u8fdb\u884c\u76f8\u5173\u6027\u5206\u6790\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u63a8\u79bb\u76ee\u6807\u6765\u589e\u52a0\u5206\u6563\u6027\u3002", "result": "\u6211\u4eec\u53d1\u73b0\u8868\u793a\u7684\u5206\u6563\u6027\u4e0e\u56f0\u60d1\u5ea6\u4e4b\u95f4\u5b58\u5728\u5f3a\u8d1f\u76f8\u5173\u5173\u7cfb\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u589e\u52a0\u5206\u6563\u6027\u6765\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u5206\u6563\u6027\u8fdb\u884c\u6a21\u578b\u9009\u62e9\u548c\u6700\u4f73\u8868\u793a\u7684\u8bc6\u522b\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u8868\u660e\uff0c\u8bed\u8a00\u6a21\u578b\u7684\u6587\u672c\u9884\u6d4b\u80fd\u529b\u4e0e\u5176\u5d4c\u5165\u7a7a\u95f4\u7684\u5e7f\u5ea6\u5bc6\u5207\u76f8\u5173\u3002\u901a\u8fc7\u589e\u52a0\u8868\u793a\u7684\u5206\u6563\u6027\uff0c\u53ef\u4ee5\u5728\u4e0d\u4f7f\u7528\u6807\u8bb0\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e00\u7cfb\u5217\u5b9e\u9645\u4efb\u52a1\u7684\u4f18\u5316\uff0c\u5e76\u4e14\u53ef\u4ee5\u63d0\u9ad8\u56f0\u60d1\u5ea6\u3002"}}
{"id": "2506.24117", "pdf": "https://arxiv.org/pdf/2506.24117", "abs": "https://arxiv.org/abs/2506.24117", "authors": ["David M. Smiley"], "title": "Computational Detection of Intertextual Parallels in Biblical Hebrew: A Benchmark Study Using Transformer-Based Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Identifying parallel passages in biblical Hebrew is foundational in biblical\nscholarship for uncovering intertextual relationships. Traditional methods rely\non manual comparison, which is labor-intensive and prone to human error. This\nstudy evaluates the potential of pre-trained transformer-based language models,\nincluding E5, AlephBERT, MPNet, and LaBSE, for detecting textual parallels in\nthe Hebrew Bible. Focusing on known parallels between the books of Samuel/Kings\nand Chronicles, I assessed each model's capability to generate word embeddings\nthat delineate parallel from non-parallel passages. Utilizing cosine similarity\nand Wasserstein Distance measures, I found that E5 and AlephBERT show\nsignificant promise, with E5 excelling in parallel detection and AlephBERT\ndemonstrating stronger non-parallel differentiation. These findings indicate\nthat pre-trained models can enhance the efficiency and accuracy of detecting\nintertextual parallels in ancient texts, suggesting broader applications for\nancient language studies.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u9884\u8bad\u7ec3\u7684\u53d8\u538b\u5668\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u5e0c\u4f2f\u6765\u5723\u7ecf\u4e2d\u7684\u6587\u672c\u5e73\u884c\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u53d1\u73b0E5\u548cAlephBERT\u5728\u8fd9\u4e00\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u5728\u5723\u7ecf\u5e0c\u4f2f\u6765\u8bed\u4e2d\u8bc6\u522b\u5e73\u884c\u6bb5\u843d\u662f\u5723\u7ecf\u5b66\u672f\u7684\u57fa\u7840\uff0c\u7528\u4e8e\u63ed\u793a\u4e92\u6587\u5173\u7cfb\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u624b\u52a8\u6bd4\u8f83\uff0c\u8fd9\u65e2\u8d39\u65f6\u53c8\u5bb9\u6613\u51fa\u9519\u3002", "method": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08\u5305\u62ecE5\u3001AlephBERT\u3001MPNet\u548cLaBSE\uff09\u5728\u68c0\u6d4b\u5e0c\u4f2f\u6765\u5723\u7ecf\u4e2d\u7684\u6587\u672c\u5e73\u884c\u65b9\u9762\u7684\u6f5c\u529b\u3002\u901a\u8fc7\u4f59\u5f26\u76f8\u4f3c\u6027\u548cWasserstein\u8ddd\u79bb\u6d4b\u91cf\uff0c\u8bc4\u4f30\u4e86\u6bcf\u4e2a\u6a21\u578b\u751f\u6210\u533a\u5206\u5e73\u884c\u548c\u975e\u5e73\u884c\u6bb5\u843d\u7684\u8bcd\u5d4c\u5165\u7684\u80fd\u529b\u3002", "result": "E5\u548cAlephBERT\u663e\u793a\u51fa\u663e\u8457\u7684\u524d\u666f\uff0c\u5176\u4e2dE5\u5728\u5e73\u884c\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u800cAlephBERT\u5728\u975e\u5e73\u884c\u533a\u5206\u65b9\u9762\u8868\u73b0\u66f4\u5f3a\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u53ef\u4ee5\u63d0\u9ad8\u68c0\u6d4b\u53e4\u4ee3\u6587\u672c\u4e2d\u4e92\u6587\u5e73\u884c\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5e76\u6697\u793a\u4e86\u5728\u53e4\u4ee3\u8bed\u8a00\u7814\u7a76\u4e2d\u7684\u66f4\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2506.22449", "pdf": "https://arxiv.org/pdf/2506.22449", "abs": "https://arxiv.org/abs/2506.22449", "authors": ["Carolyn Hicks"], "title": "Computational Analysis of Climate Policy", "categories": ["cs.CY", "cs.CL"], "comment": "Master's thesis", "summary": "This thesis explores the impact of the Climate Emergency movement on local\ngovernment climate policy, using computational methods. The Climate Emergency\nmovement sought to accelerate climate action at local government level through\nthe mechanism of Climate Emergency Declarations (CEDs), resulting in a series\nof commitments from councils to treat climate change as an emergency. With the\naim of assessing the potential of current large language models to answer\ncomplex policy questions, I first built and configured a system named PALLM\n(Policy Analysis with a Large Language Model), using the OpenAI model GPT-4.\nThis system is designed to apply a conceptual framework for climate emergency\nresponse plans to a dataset of climate policy documents. I validated the\nperformance of this system with the help of local government policymakers, by\ngenerating analyses of the climate policies of 11 local governments in Victoria\nand assessing the policymakers' level of agreement with PALLM's responses.\nHaving established that PALLM's performance is satisfactory, I used it to\nconduct a large-scale analysis of current policy documents from local\ngovernments in the state of Victoria, Australia. This thesis presents the\nmethodology and results of this analysis, comparing the results for councils\nwhich have passed a CED to those which did not. This study finds that GPT-4 is\ncapable of high-level policy analysis, with limitations including a lack of\nreliable attribution, and can also enable more nuanced analysis by researchers.\nIts use in this research shows that councils which have passed a CED are more\nlikely to have a recent and climate-specific policy, and show more attention to\nurgency, prioritisation, and equity and social justice, than councils which\nhave not. It concludes that the ability to assess policy documents at scale\nopens up exciting new opportunities for policy researchers.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86\u6c14\u5019\u7d27\u6025\u8fd0\u52a8\u5bf9\u5730\u65b9\u653f\u5e9c\u6c14\u5019\u653f\u7b56\u7684\u5f71\u54cd\uff0c\u4f7f\u7528\u8ba1\u7b97\u65b9\u6cd5\u5206\u6790\u4e86\u6c14\u5019\u7d27\u6025\u58f0\u660e\u7684\u4f5c\u7528\uff0c\u5e76\u5c55\u793a\u4e86GPT-4\u5728\u653f\u7b56\u5206\u6790\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u672c\u8bba\u6587\u65e8\u5728\u8bc4\u4f30\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u56de\u7b54\u590d\u6742\u653f\u7b56\u95ee\u9898\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u672c\u8bba\u6587\u6784\u5efa\u5e76\u914d\u7f6e\u4e86\u4e00\u4e2a\u540d\u4e3aPALLM\uff08\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u653f\u7b56\u5206\u6790\uff09\u7684\u7cfb\u7edf\uff0c\u5229\u7528OpenAI\u6a21\u578bGPT-4\uff0c\u5e76\u5e94\u7528\u4e86\u4e00\u79cd\u6982\u5ff5\u6846\u67b6\u6765\u5206\u6790\u6c14\u5019\u7d27\u6025\u54cd\u5e94\u8ba1\u5212\u7684\u6570\u636e\u96c6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cGPT-4\u80fd\u591f\u8fdb\u884c\u9ad8\u6c34\u5e73\u7684\u653f\u7b56\u5206\u6790\uff0c\u5176\u5c40\u9650\u6027\u5305\u62ec\u7f3a\u4e4f\u53ef\u9760\u7684\u5f52\u56e0\u80fd\u529b\uff0c\u4f46\u53ef\u4ee5\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u66f4\u7ec6\u81f4\u7684\u5206\u6790\u3002\u901a\u8fc7\u6bd4\u8f83\u5df2\u901a\u8fc7\u6c14\u5019\u7d27\u6025\u58f0\u660e\u7684\u5e02\u8bae\u4f1a\u4e0e\u672a\u901a\u8fc7\u7684\u5e02\u8bae\u4f1a\u7684\u7ed3\u679c\uff0c\u53d1\u73b0\u524d\u8005\u66f4\u6709\u53ef\u80fd\u62e5\u6709\u8fd1\u671f\u548c\u6c14\u5019\u7279\u5b9a\u7684\u653f\u7b56\uff0c\u5e76\u66f4\u52a0\u5173\u6ce8\u7d27\u8feb\u6027\u3001\u4f18\u5148\u7ea7\u3001\u516c\u5e73\u548c\u793e\u4f1a\u6b63\u4e49\u3002", "conclusion": "\u672c\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u5927\u89c4\u6a21\u8bc4\u4f30\u653f\u7b56\u6587\u4ef6\u7684\u80fd\u529b\u4e3a\u653f\u7b56\u7814\u7a76\u4eba\u5458\u5f00\u8f9f\u4e86\u4ee4\u4eba\u5174\u594b\u7684\u65b0\u673a\u9047\u3002"}}
{"id": "2506.22481", "pdf": "https://arxiv.org/pdf/2506.22481", "abs": "https://arxiv.org/abs/2506.22481", "authors": ["Jacob Hobbs"], "title": "Theories of \"Sexuality\" in Natural Language Processing Bias Research", "categories": ["cs.CY", "cs.CL"], "comment": "17 pages, 9 tables, undergraduate senior thesis, submitted to The\n  Spectra: The Virginia Engineering and Science Research Journal", "summary": "In recent years, significant advancements in the field of Natural Language\nProcessing (NLP) have positioned commercialized language models as\nwide-reaching, highly useful tools. In tandem, there has been an explosion of\nmultidisciplinary research examining how NLP tasks reflect, perpetuate, and\namplify social biases such as gender and racial bias. A significant gap in this\nscholarship is a detailed analysis of how queer sexualities are encoded and\n(mis)represented by both NLP systems and practitioners. Following previous work\nin the field of AI fairness, we document how sexuality is defined and\noperationalized via a survey and analysis of 55 articles that quantify\nsexuality-based NLP bias. We find that sexuality is not clearly defined in a\nmajority of the literature surveyed, indicating a reliance on assumed or\nnormative conceptions of sexual/romantic practices and identities. Further, we\nfind that methods for extracting biased outputs from NLP technologies often\nconflate gender and sexual identities, leading to monolithic conceptions of\nqueerness and thus improper quantifications of bias. With the goal of improving\nsexuality-based NLP bias analyses, we conclude with recommendations that\nencourage more thorough engagement with both queer communities and\ninterdisciplinary literature.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86NLP\u7cfb\u7edf\u4e2d\u6027\u53d6\u5411\u7684\u7f16\u7801\u548c\uff08\u8bef\uff09\u8868\u793a\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u57fa\u4e8e\u6027\u53d6\u5411\u7684NLP\u504f\u89c1\u5206\u6790\u7684\u5efa\u8bae\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u662f\u586b\u8865\u73b0\u6709\u7814\u7a76\u4e2d\u5bf9\u9177\u513f\u6027\u53d6\u5411\u5728NLP\u7cfb\u7edf\u548c\u4ece\u4e1a\u8005\u4e2d\u7684\u7f16\u7801\u548c\uff08\u8bef\uff09\u8868\u793a\u7684\u8be6\u7ec6\u5206\u6790\u7684\u7a7a\u767d\u3002", "method": "\u672c\u6587\u901a\u8fc7\u8c03\u67e5\u548c\u5206\u679055\u7bc7\u91cf\u5316\u6027\u53d6\u5411NLP\u504f\u89c1\u7684\u6587\u7ae0\uff0c\u7814\u7a76\u4e86\u6027\u53d6\u5411\u662f\u5982\u4f55\u88ab\u5b9a\u4e49\u548c\u64cd\u4f5c\u5316\u7684\u3002", "result": "\u672c\u6587\u53d1\u73b0\uff0c\u5927\u591a\u6570\u6587\u732e\u4e2d\u6027\u53d6\u5411\u5e76\u672a\u5f97\u5230\u660e\u786e\u7684\u5b9a\u4e49\uff0c\u800c\u662f\u4f9d\u8d56\u4e8e\u5047\u8bbe\u6216\u89c4\u8303\u6027\u7684\u6027/\u6d6a\u6f2b\u5b9e\u8df5\u548c\u8eab\u4efd\u89c2\u5ff5\u3002\u6b64\u5916\uff0c\u63d0\u53d6NLP\u6280\u672f\u4e2d\u6709\u504f\u8f93\u51fa\u7684\u65b9\u6cd5\u5e38\u5e38\u5c06\u6027\u522b\u548c\u6027\u53d6\u5411\u8eab\u4efd\u6df7\u4e3a\u4e00\u8c08\uff0c\u5bfc\u81f4\u5bf9\u9177\u513f\u7684\u5355\u4e00\u5316\u7406\u89e3\uff0c\u4ece\u800c\u5bfc\u81f4\u504f\u89c1\u7684\u4e0d\u5f53\u91cf\u5316\u3002", "conclusion": "\u672c\u6587\u7ed3\u8bba\u662f\uff0c\u4e3a\u4e86\u6539\u8fdb\u57fa\u4e8e\u6027\u53d6\u5411\u7684NLP\u504f\u89c1\u5206\u6790\uff0c\u9700\u8981\u66f4\u52a0\u6df1\u5165\u5730\u53c2\u4e0e\u9177\u513f\u793e\u533a\u548c\u8de8\u5b66\u79d1\u6587\u732e\u3002"}}
{"id": "2506.22493", "pdf": "https://arxiv.org/pdf/2506.22493", "abs": "https://arxiv.org/abs/2506.22493", "authors": ["Sadia Kamal", "Lalu Prasad Yadav Prakash", "S M Rafiuddin", "Mohammed Rakib", "Arunkumar Bagavathi", "Atriya Sen", "Sagnik Ray Choudhury"], "title": "A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models", "categories": ["cs.CY", "cs.CL", "cs.LG"], "comment": null, "summary": "Political Compass Test (PCT) or similar questionnaires have been used to\nquantify LLM's political leanings. Building on a recent line of work that\nexamines the validity of PCT tests, we demonstrate that variation in standard\ngeneration parameters does not significantly impact the models' PCT scores.\nHowever, external factors such as prompt variations and fine-tuning\nindividually and in combination affect the same. Finally, we demonstrate that\nwhen models are fine-tuned on text datasets with higher political content than\nothers, the PCT scores are not differentially affected. This calls for a\nthorough investigation into the validity of PCT and similar tests, as well as\nthe mechanism by which political leanings are encoded in LLMs.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u6807\u51c6\u751f\u6210\u53c2\u6570\u5bf9PCT\u5206\u6570\u5f71\u54cd\u4e0d\u5927\uff0c\u4f46\u63d0\u793a\u53d8\u5316\u548c\u5fae\u8c03\u4f1a\u5f71\u54cdPCT\u5206\u6570\u3002\u6b64\u5916\uff0c\u653f\u6cbb\u5185\u5bb9\u8f83\u591a\u7684\u6570\u636e\u96c6\u5fae\u8c03\u4e0d\u4f1a\u5bfc\u81f4PCT\u5206\u6570\u7684\u5dee\u5f02\u3002\u8fd9\u5f15\u53d1\u4e86\u5bf9PCT\u6d4b\u8bd5\u6709\u6548\u6027\u548c\u653f\u6cbb\u503e\u5411\u7f16\u7801\u673a\u5236\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "motivation": "\u4e3a\u4e86\u9a8c\u8bc1PCT\u6d4b\u8bd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e86\u89e3\u653f\u6cbb\u503e\u5411\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u7f16\u7801\u673a\u5236\u3002", "method": "\u901a\u8fc7\u68c0\u67e5PCT\u6d4b\u8bd5\u7684\u6709\u6548\u6027\uff0c\u7814\u7a76\u4e86\u6807\u51c6\u751f\u6210\u53c2\u6570\u7684\u53d8\u5316\u662f\u5426\u663e\u8457\u5f71\u54cd\u6a21\u578b\u7684PCT\u5206\u6570\uff0c\u540c\u65f6\u5206\u6790\u4e86\u5916\u90e8\u56e0\u7d20\u5982\u63d0\u793a\u53d8\u5316\u548c\u5fae\u8c03\u5bf9PCT\u5206\u6570\u7684\u5f71\u54cd\u3002", "result": "\u6807\u51c6\u751f\u6210\u53c2\u6570\u7684\u53d8\u5316\u4e0d\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u7684PCT\u5206\u6570\uff0c\u4f46\u63d0\u793a\u53d8\u5316\u548c\u5fae\u8c03\u4f1a\u5355\u72ec\u6216\u7ec4\u5408\u5730\u5f71\u54cdPCT\u5206\u6570\u3002\u6b64\u5916\uff0c\u5f53\u6a21\u578b\u5728\u5305\u542b\u66f4\u591a\u653f\u6cbb\u5185\u5bb9\u7684\u6587\u672c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\u65f6\uff0cPCT\u5206\u6570\u5e76\u672a\u53d7\u5230\u5dee\u5f02\u5f71\u54cd\u3002", "conclusion": "\u8fd9\u547c\u5401\u5bf9PCT\u548c\u7c7b\u4f3c\u6d4b\u8bd5\u7684\u6709\u6548\u6027\u4ee5\u53ca\u653f\u6cbb\u503e\u5411\u5728LLM\u4e2d\u7684\u7f16\u7801\u673a\u5236\u8fdb\u884c\u5f7b\u5e95\u8c03\u67e5\u3002"}}
{"id": "2506.22496", "pdf": "https://arxiv.org/pdf/2506.22496", "abs": "https://arxiv.org/abs/2506.22496", "authors": ["Y. Du"], "title": "Mitigating Gambling-Like Risk-Taking Behaviors in Large Language Models: A Behavioral Economics Approach to AI Safety", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "7 pages", "summary": "Large Language Models (LLMs) exhibit systematic risk-taking behaviors\nanalogous to those observed in gambling psychology, including overconfidence\nbias, loss-chasing tendencies, and probability misjudgment. Drawing from\nbehavioral economics and prospect theory, we identify and formalize these\n\"gambling-like\" patterns where models sacrifice accuracy for high-reward\noutputs, exhibit escalating risk-taking after errors, and systematically\nmiscalibrate uncertainty. We propose the Risk-Aware Response Generation (RARG)\nframework, incorporating insights from gambling research to address these\nbehavioral biases through risk-calibrated training, loss-aversion mechanisms,\nand uncertainty-aware decision making. Our approach introduces novel evaluation\nparadigms based on established gambling psychology experiments, including AI\nadaptations of the Iowa Gambling Task and probability learning assessments.\nExperimental results demonstrate measurable reductions in gambling-like\nbehaviors: 18.7\\% decrease in overconfidence bias, 24.3\\% reduction in\nloss-chasing tendencies, and improved risk calibration across diverse\nscenarios. This work establishes the first systematic framework for\nunderstanding and mitigating gambling psychology patterns in AI systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.22666", "pdf": "https://arxiv.org/pdf/2506.22666", "abs": "https://arxiv.org/abs/2506.22666", "authors": ["Anamika Lochab", "Lu Yan", "Patrick Pynadath", "Xiangyu Zhang", "Ruqi Zhang"], "title": "VERA: Variational Inference Framework for Jailbreaking Large Language Models", "categories": ["cs.CR", "cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "The rise of API-only access to state-of-the-art LLMs highlights the need for\neffective black-box jailbreak methods to identify model vulnerabilities in\nreal-world settings. Without a principled objective for gradient-based\noptimization, most existing approaches rely on genetic algorithms, which are\nlimited by their initialization and dependence on manually curated prompt\npools. Furthermore, these methods require individual optimization for each\nprompt, failing to provide a comprehensive characterization of model\nvulnerabilities. To address this gap, we introduce VERA: Variational infErence\nfRamework for jAilbreaking. VERA casts black-box jailbreak prompting as a\nvariational inference problem, training a small attacker LLM to approximate the\ntarget LLM's posterior over adversarial prompts. Once trained, the attacker can\ngenerate diverse, fluent jailbreak prompts for a target query without\nre-optimization. Experimental results show that VERA achieves strong\nperformance across a range of target LLMs, highlighting the value of\nprobabilistic inference for adversarial prompt generation.", "AI": {"tldr": "VERA\u662f\u4e00\u79cd\u65b0\u7684\u9ed1\u76d2\u8d8a\u72f1\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d8\u5206\u63a8\u65ad\u8bad\u7ec3\u5c0f\u653b\u51fb\u8005LLM\u751f\u6210\u591a\u6837\u4e14\u6d41\u7545\u7684\u8d8a\u72f1\u63d0\u793a\uff0c\u65e0\u9700\u91cd\u65b0\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u9057\u4f20\u7b97\u6cd5\uff0c\u8fd9\u53d7\u5230\u521d\u59cb\u5316\u548c\u624b\u52a8\u7b56\u5212\u63d0\u793a\u6c60\u7684\u9650\u5236\uff0c\u5e76\u4e14\u9700\u8981\u4e3a\u6bcf\u4e2a\u63d0\u793a\u5355\u72ec\u4f18\u5316\uff0c\u65e0\u6cd5\u5168\u9762\u8868\u5f81\u6a21\u578b\u6f0f\u6d1e\u3002", "method": "VERA\u5c06\u9ed1\u76d2\u8d8a\u72f1\u63d0\u793a\u95ee\u9898\u8f6c\u5316\u4e3a\u53d8\u5206\u63a8\u65ad\u95ee\u9898\uff0c\u8bad\u7ec3\u4e00\u4e2a\u5c0f\u7684\u653b\u51fb\u8005LLM\u6765\u8fd1\u4f3c\u76ee\u6807LLM\u5bf9\u5bf9\u6297\u6027\u63d0\u793a\u7684\u540e\u9a8c\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cVERA\u5728\u5404\u79cd\u76ee\u6807LLM\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u8bc1\u660e\u4e86\u6982\u7387\u63a8\u65ad\u5728\u5bf9\u6297\u6027\u63d0\u793a\u751f\u6210\u4e2d\u7684\u4ef7\u503c\u3002", "conclusion": "VERA\u5c55\u793a\u4e86\u6982\u7387\u63a8\u65ad\u5728\u5bf9\u6297\u6027\u63d0\u793a\u751f\u6210\u4e2d\u7684\u4ef7\u503c\uff0c\u5e76\u5728\u591a\u79cd\u76ee\u6807LLM\u4e0a\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u6027\u80fd\u3002"}}
{"id": "2506.22696", "pdf": "https://arxiv.org/pdf/2506.22696", "abs": "https://arxiv.org/abs/2506.22696", "authors": ["Brian Mak", "Jeffrey Flanigan"], "title": "Residual Matrix Transformers: Scaling the Size of the Residual Stream", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted to ICML 2025", "summary": "The residual stream acts as a memory bus where transformer layers both store\nand access features (Elhage et al., 2021). We consider changing the mechanism\nfor retrieving and storing information in the residual stream, and replace the\nresidual stream of the transformer with an outer product memory matrix\n(Kohonen, 1972, Anderson, 1972). We call this model the Residual Matrix\nTransformer (RMT). We find that the RMT enjoys a number of attractive\nproperties: 1) the size of the residual stream can be scaled independently of\ncompute and model size, improving performance, 2) the RMT can achieve the same\nloss as the transformer with 58% fewer FLOPS, 25% fewer parameters, and 41%\nfewer training tokens tokens, and 3) the RMT outperforms the transformer on\ndownstream evaluations. We theoretically analyze the transformer and the RMT,\nand show that the RMT allows for more efficient scaling of the residual stream,\nas well as improved variance propagation properties. Code for this project can\nbe found at https://github.com/bmac3/residual-matrix-transformer.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684Transformer\u53d8\u4f53\u2014\u2014Residual Matrix Transformer (RMT)\uff0c\u901a\u8fc7\u66ff\u6362\u6b8b\u5dee\u6d41\u4e3a\u5916\u79ef\u8bb0\u5fc6\u77e9\u9635\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u8ba1\u7b97\u548c\u53c2\u6570\u6548\u7387\uff0c\u5e76\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edfTransformer\u3002", "motivation": "\u6539\u8fdbTransformer\u4e2d\u6b8b\u5dee\u6d41\u7684\u4fe1\u606f\u5b58\u50a8\u548c\u68c0\u7d22\u673a\u5236\uff0c\u4ee5\u63d0\u9ad8\u8ba1\u7b97\u548c\u53c2\u6570\u6548\u7387\u3002", "method": "\u5c06Transformer\u7684\u6b8b\u5dee\u6d41\u66ff\u6362\u4e3a\u5916\u79ef\u8bb0\u5fc6\u77e9\u9635\uff0c\u6784\u5efa\u4e86Residual Matrix Transformer (RMT)\u6a21\u578b\u3002", "result": "RMT\u5728\u4fdd\u6301\u76f8\u540c\u635f\u5931\u7684\u60c5\u51b5\u4e0b\uff0c\u51cf\u5c11\u4e8658%\u7684FLOPS\u300125%\u7684\u53c2\u6570\u548c41%\u7684\u8bad\u7ec3token\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "RMT\u5728\u4e0b\u6e38\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u4e8eTransformer\uff0c\u5e76\u4e14\u5728\u8ba1\u7b97\u548c\u53c2\u6570\u6548\u7387\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2506.22716", "pdf": "https://arxiv.org/pdf/2506.22716", "abs": "https://arxiv.org/abs/2506.22716", "authors": ["Dujian Ding", "Ankur Mallick", "Shaokun Zhang", "Chi Wang", "Daniel Madrigal", "Mirian Del Carmen Hipolito Garcia", "Menglin Xia", "Laks V. S. Lakshmanan", "Qingyun Wu", "Victor R\u00fchle"], "title": "BEST-Route: Adaptive LLM Routing with Test-Time Optimal Compute", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DB"], "comment": "Accepted to ICML 2025 (main conference)", "summary": "Large language models (LLMs) are powerful tools but are often expensive to\ndeploy at scale. LLM query routing mitigates this by dynamically assigning\nqueries to models of varying cost and quality to obtain a desired trade-off.\nPrior query routing approaches generate only one response from the selected\nmodel and a single response from a small (inexpensive) model was often not good\nenough to beat a response from a large (expensive) model due to which they end\nup overusing the large model and missing out on potential cost savings.\nHowever, it is well known that for small models, generating multiple responses\nand selecting the best can enhance quality while remaining cheaper than a\nsingle large-model response. We leverage this idea to propose BEST-Route, a\nnovel routing framework that chooses a model and the number of responses to\nsample from it based on query difficulty and the quality thresholds.\nExperiments on real-world datasets demonstrate that our method reduces costs by\nup to 60% with less than 1% performance drop.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBEST-Route\u7684\u65b0\u8def\u7531\u6846\u67b6\uff0c\u901a\u8fc7\u6839\u636e\u67e5\u8be2\u96be\u5ea6\u548c\u8d28\u91cf\u9608\u503c\u9009\u62e9\u6a21\u578b\u548c\u91c7\u6837\u54cd\u5e94\u6570\u91cf\uff0c\u4ee5\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u90e8\u7f72\u6210\u672c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5c06\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe60%\uff0c\u540c\u65f6\u6027\u80fd\u4e0b\u964d\u4e0d\u52301%\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u5927\u89c4\u6a21\u90e8\u7f72\u65f6\u6210\u672c\u9ad8\u6602\u3002LLM\u67e5\u8be2\u8def\u7531\u901a\u8fc7\u52a8\u6001\u5206\u914d\u67e5\u8be2\u5230\u4e0d\u540c\u6210\u672c\u548c\u8d28\u91cf\u7684\u6a21\u578b\u6765\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4ee5\u83b7\u5f97\u6240\u9700\u7684\u6743\u8861\u3002\u7136\u800c\uff0c\u5148\u524d\u7684\u67e5\u8be2\u8def\u7531\u65b9\u6cd5\u53ea\u751f\u6210\u4e00\u4e2a\u54cd\u5e94\uff0c\u800c\u4e00\u4e2a\u5c0f\u6a21\u578b\u7684\u5355\u4e2a\u54cd\u5e94\u901a\u5e38\u4e0d\u8db3\u4ee5\u80dc\u8fc7\u4e00\u4e2a\u5927\u6a21\u578b\u7684\u54cd\u5e94\uff0c\u5bfc\u81f4\u4ed6\u4eec\u8fc7\u5ea6\u4f7f\u7528\u5927\u6a21\u578b\uff0c\u9519\u8fc7\u4e86\u6f5c\u5728\u7684\u6210\u672c\u8282\u7ea6\u673a\u4f1a\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86BEST-Route\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u8def\u7531\u6846\u67b6\uff0c\u6839\u636e\u67e5\u8be2\u96be\u5ea6\u548c\u8d28\u91cf\u9608\u503c\u9009\u62e9\u6a21\u578b\u4ee5\u53ca\u4ece\u8be5\u6a21\u578b\u4e2d\u91c7\u6837\u7684\u54cd\u5e94\u6570\u91cf\u3002", "result": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5b83\u53ef\u4ee5\u5728\u6027\u80fd\u4e0b\u964d\u4e0d\u52301%\u7684\u60c5\u51b5\u4e0b\u5c06\u6210\u672c\u964d\u4f4e\u591a\u8fbe60%\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5b83\u53ef\u4ee5\u5728\u6027\u80fd\u4e0b\u964d\u4e0d\u52301%\u7684\u60c5\u51b5\u4e0b\u5c06\u6210\u672c\u964d\u4f4e\u591a\u8fbe60%\u3002"}}
{"id": "2506.22783", "pdf": "https://arxiv.org/pdf/2506.22783", "abs": "https://arxiv.org/abs/2506.22783", "authors": ["Oguzhan Baser", "Ahmet Ege Tanriverdi", "Sriram Vishwanath", "Sandeep P. Chinchali"], "title": "PhonemeFake: Redefining Deepfake Realism with Language-Driven Segmental Manipulation and Adaptive Bilevel Detection", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "5 pages, 3 figures, Published at Proceedings of Interspeech 2025, for\n  the dataset see https://huggingface.co/datasets/phonemefake/PhonemeFakeV2,\n  for the code see https://github.com/UTAustin-SwarmLab/ PhonemeFake", "summary": "Deepfake (DF) attacks pose a growing threat as generative models become\nincreasingly advanced. However, our study reveals that existing DF datasets\nfail to deceive human perception, unlike real DF attacks that influence public\ndiscourse. It highlights the need for more realistic DF attack vectors. We\nintroduce PhonemeFake (PF), a DF attack that manipulates critical speech\nsegments using language reasoning, significantly reducing human perception by\nup to 42% and benchmark accuracies by up to 94%. We release an easy-to-use PF\ndataset on HuggingFace and open-source bilevel DF segment detection model that\nadaptively prioritizes compute on manipulated regions. Our extensive\nexperiments across three known DF datasets reveal that our detection model\nreduces EER by 91% while achieving up to 90% speed-up, with minimal compute\noverhead and precise localization beyond existing models as a scalable\nsolution.", "AI": {"tldr": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u73b0\u6709\u6df1\u5ea6\u4f2a\u9020\u6570\u636e\u96c6\u65e0\u6cd5\u6b3a\u9a97\u4eba\u7c7b\u611f\u77e5\uff0c\u63d0\u51fa\u4e86PhonemeFake\uff08PF\uff09\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bed\u8a00\u63a8\u7406\u64cd\u7eb5\u5173\u952e\u8bed\u97f3\u6bb5\uff0c\u663e\u8457\u964d\u4f4e\u4eba\u7c7b\u611f\u77e5\u548c\u57fa\u51c6\u51c6\u786e\u7387\u3002\u6211\u4eec\u8fd8\u53d1\u5e03\u4e86\u4e00\u4e2a\u6613\u4e8e\u4f7f\u7528\u7684PF\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u53cc\u5c42\u6df1\u5ea6\u4f2a\u9020\u6bb5\u68c0\u6d4b\u6a21\u578b\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6a21\u578b\u5728\u964d\u4f4eEER\u548c\u63d0\u9ad8\u901f\u5ea6\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u4f2a\u9020\u6570\u636e\u96c6\u65e0\u6cd5\u6b3a\u9a97\u4eba\u7c7b\u611f\u77e5\uff0c\u800c\u771f\u5b9e\u6df1\u5ea6\u4f2a\u9020\u653b\u51fb\u5374\u80fd\u5f71\u54cd\u516c\u4f17\u8ba8\u8bba\u3002\u56e0\u6b64\uff0c\u9700\u8981\u66f4\u771f\u5b9e\u7684\u6df1\u5ea6\u4f2a\u9020\u653b\u51fb\u5411\u91cf\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86PhonemeFake\uff08PF\uff09\uff0c\u4e00\u79cd\u5229\u7528\u8bed\u8a00\u63a8\u7406\u64cd\u7eb5\u5173\u952e\u8bed\u97f3\u6bb5\u7684\u6df1\u5ea6\u4f2a\u9020\u653b\u51fb\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u5f00\u6e90\u4e86\u4e00\u4e2a\u53cc\u5c42\u6df1\u5ea6\u4f2a\u9020\u6bb5\u68c0\u6d4b\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u81ea\u9002\u5e94\u5730\u4f18\u5148\u8003\u8651\u88ab\u7be1\u6539\u533a\u57df\u7684\u8ba1\u7b97\u8d44\u6e90\u3002", "result": "\u6211\u4eec\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u68c0\u6d4b\u6a21\u578b\u5c06EER\u964d\u4f4e\u4e8691%\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u8fbe90%\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u8ba1\u7b97\u5f00\u9500\u6700\u5c0f\uff0c\u5e76\u4e14\u5728\u7cbe\u786e\u5b9a\u4f4d\u65b9\u9762\u8d85\u8d8a\u4e86\u73b0\u6709\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u63ed\u793a\u4e86\u73b0\u6709\u6df1\u5ea6\u4f2a\u9020\u6570\u636e\u96c6\u65e0\u6cd5\u6b3a\u9a97\u4eba\u7c7b\u611f\u77e5\uff0c\u800c\u771f\u5b9e\u6df1\u5ea6\u4f2a\u9020\u653b\u51fb\u5374\u80fd\u5f71\u54cd\u516c\u4f17\u8ba8\u8bba\u3002\u8fd9\u7a81\u663e\u4e86\u9700\u8981\u66f4\u771f\u5b9e\u7684\u6df1\u5ea6\u4f2a\u9020\u653b\u51fb\u5411\u91cf\u3002\u6211\u4eec\u5f15\u5165\u4e86PhonemeFake\uff08PF\uff09\uff0c\u4e00\u79cd\u5229\u7528\u8bed\u8a00\u63a8\u7406\u64cd\u7eb5\u5173\u952e\u8bed\u97f3\u6bb5\u7684\u6df1\u5ea6\u4f2a\u9020\u653b\u51fb\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u7c7b\u611f\u77e5\u9ad8\u8fbe42%\uff0c\u57fa\u51c6\u51c6\u786e\u7387\u9ad8\u8fbe94%\u3002\u6211\u4eec\u53d1\u5e03\u4e86\u6613\u4e8e\u4f7f\u7528\u7684PF\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u6e90\u4e86\u4e00\u4e2a\u53cc\u5c42\u6df1\u5ea6\u4f2a\u9020\u6bb5\u68c0\u6d4b\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u81ea\u9002\u5e94\u5730\u4f18\u5148\u8003\u8651\u88ab\u7be1\u6539\u533a\u57df\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u68c0\u6d4b\u6a21\u578b\u5c06EER\u964d\u4f4e\u4e8691%\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u8fbe90%\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u8ba1\u7b97\u5f00\u9500\u6700\u5c0f\uff0c\u5e76\u4e14\u5728\u7cbe\u786e\u5b9a\u4f4d\u65b9\u9762\u8d85\u8d8a\u4e86\u73b0\u6709\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.22809", "pdf": "https://arxiv.org/pdf/2506.22809", "abs": "https://arxiv.org/abs/2506.22809", "authors": ["Cooper Doyle"], "title": "BayesLoRA: Task-Specific Uncertainty in Low-Rank Adapters", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "13 pages, 3 figures, 1 table", "summary": "We propose BayesLoRA, a task-specific uncertainty quantification framework\nthat integrates MC-Dropout into Low-Rank Adapters (LoRA). Unlike\ngeneral-purpose transformer uncertainty methods, BayesLoRA provides guardrails\ntailored to downstream workflows, enabling agents to introspect and modulate\nbehavior under uncertainty. We demonstrate mathematically and empirically that\nLoRA adapters exhibit amplified variance outside fine-tuning distributions,\nyielding reliable confidence estimates for agentic decision-making.", "AI": {"tldr": "BayesLoRA is a task-specific uncertainty quantification framework that integrates MC-Dropout into Low-Rank Adapters (LoRA), providing reliable confidence estimates for agentic decision-making.", "motivation": "The motivation is to provide guardrails tailored to downstream workflows, enabling agents to introspect and modulate behavior under uncertainty.", "method": "The paper proposes BayesLoRA, which integrates MC-Dropout into Low-Rank Adapters (LoRA) for task-specific uncertainty quantification.", "result": "The paper demonstrates mathematically and empirically that LoRA adapters exhibit amplified variance outside fine-tuning distributions, yielding reliable confidence estimates for agentic decision-making.", "conclusion": "BayesLoRA provides a task-specific uncertainty quantification framework that integrates MC-Dropout into Low-Rank Adapters (LoRA), enabling agents to introspect and modulate behavior under uncertainty."}}
{"id": "2506.22864", "pdf": "https://arxiv.org/pdf/2506.22864", "abs": "https://arxiv.org/abs/2506.22864", "authors": ["Li-Cheng Shen", "Jih-Kang Hsieh", "Wei-Hua Li", "Chu-Song Chen"], "title": "Mask-aware Text-to-Image Retrieval: Referring Expression Segmentation Meets Cross-modal Retrieval", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "ICMR 2025", "summary": "Text-to-image retrieval (TIR) aims to find relevant images based on a textual\nquery, but existing approaches are primarily based on whole-image captions and\nlack interpretability. Meanwhile, referring expression segmentation (RES)\nenables precise object localization based on natural language descriptions but\nis computationally expensive when applied across large image collections. To\nbridge this gap, we introduce Mask-aware TIR (MaTIR), a new task that unifies\nTIR and RES, requiring both efficient image search and accurate object\nsegmentation. To address this task, we propose a two-stage framework,\ncomprising a first stage for segmentation-aware image retrieval and a second\nstage for reranking and object grounding with a multimodal large language model\n(MLLM). We leverage SAM 2 to generate object masks and Alpha-CLIP to extract\nregion-level embeddings offline at first, enabling effective and scalable\nonline retrieval. Secondly, MLLM is used to refine retrieval rankings and\ngenerate bounding boxes, which are matched to segmentation masks. We evaluate\nour approach on COCO and D$^3$ datasets, demonstrating significant improvements\nin both retrieval accuracy and segmentation quality over previous methods.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Mask-aware TIR\uff08MaTIR\uff09\u4efb\u52a1\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u6846\u67b6\u63d0\u9ad8\u6587\u672c\u5230\u56fe\u50cf\u68c0\u7d22\u548c\u5bf9\u8c61\u5206\u5272\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u6587\u672c\u5230\u56fe\u50cf\u68c0\u7d22\uff08TIR\uff09\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u5168\u56fe\u6807\u9898\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002\u540c\u65f6\uff0c\u53c2\u8003\u8868\u8fbe\u5206\u5272\uff08RES\uff09\u5728\u5e94\u7528\u4e8e\u5927\u578b\u56fe\u50cf\u96c6\u5408\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u4e3a\u4e86\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u6211\u4eec\u5f15\u5165\u4e86Mask-aware TIR\uff08MaTIR\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u7684\u4efb\u52a1\uff0c\u7edf\u4e00\u4e86TIR\u548cRES\uff0c\u8981\u6c42\u9ad8\u6548\u7684\u56fe\u50cf\u641c\u7d22\u548c\u51c6\u786e\u7684\u5bf9\u8c61\u5206\u5272\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5305\u62ec\u7b2c\u4e00\u9636\u6bb5\u7684\u5206\u5272\u611f\u77e5\u56fe\u50cf\u68c0\u7d22\u548c\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u8fdb\u884c\u91cd\u65b0\u6392\u5e8f\u548c\u5bf9\u8c61\u5b9a\u4f4d\u3002", "result": "\u6211\u4eec\u5728COCO\u548cD$^3$\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u7ed3\u679c\u8868\u660e\u76f8\u6bd4\u4e4b\u524d\u7684\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728COCO\u548cD$^3$\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u7d22\u51c6\u786e\u6027\u548c\u5206\u5272\u8d28\u91cf\u3002"}}
{"id": "2506.22900", "pdf": "https://arxiv.org/pdf/2506.22900", "abs": "https://arxiv.org/abs/2506.22900", "authors": ["Mai A. Shaaban", "Tausifa Jan Saleem", "Vijay Ram Papineni", "Mohammad Yaqub"], "title": "MOTOR: Multimodal Optimal Transport via Grounded Retrieval in Medical Visual Question Answering", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Medical visual question answering (MedVQA) plays a vital role in clinical\ndecision-making by providing contextually rich answers to image-based queries.\nAlthough vision-language models (VLMs) are widely used for this task, they\noften generate factually incorrect answers. Retrieval-augmented generation\naddresses this challenge by providing information from external sources, but\nrisks retrieving irrelevant context, which can degrade the reasoning\ncapabilities of VLMs. Re-ranking retrievals, as introduced in existing\napproaches, enhances retrieval relevance by focusing on query-text alignment.\nHowever, these approaches neglect the visual or multimodal context, which is\nparticularly crucial for medical diagnosis. We propose MOTOR, a novel\nmultimodal retrieval and re-ranking approach that leverages grounded captions\nand optimal transport. It captures the underlying relationships between the\nquery and the retrieved context based on textual and visual information.\nConsequently, our approach identifies more clinically relevant contexts to\naugment the VLM input. Empirical analysis and human expert evaluation\ndemonstrate that MOTOR achieves higher accuracy on MedVQA datasets,\noutperforming state-of-the-art methods by an average of 6.45%. Code is\navailable at https://github.com/BioMedIA-MBZUAI/MOTOR.", "AI": {"tldr": "MOTOR is a new approach for MedVQA that improves accuracy by considering both textual and visual information in retrieval and re-ranking.", "motivation": "Existing approaches to retrieval-augmented generation for MedVQA neglect the visual or multimodal context, which is crucial for medical diagnosis.", "method": "MOTOR is a novel multimodal retrieval and re-ranking approach that leverages grounded captions and optimal transport to capture the underlying relationships between the query and the retrieved context based on textual and visual information.", "result": "MOTOR identifies more clinically relevant contexts to augment the VLM input, leading to higher accuracy on MedVQA datasets.", "conclusion": "MOTOR achieves higher accuracy on MedVQA datasets, outperforming state-of-the-art methods by an average of 6.45%."}}
{"id": "2506.22992", "pdf": "https://arxiv.org/pdf/2506.22992", "abs": "https://arxiv.org/abs/2506.22992", "authors": ["Yulun Jiang", "Yekun Chai", "Maria Brbi\u0107", "Michael Moor"], "title": "MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "The ability to process information from multiple modalities and to reason\nthrough it step-by-step remains a critical challenge in advancing artificial\nintelligence. However, existing reasoning benchmarks focus on text-only\nreasoning, or employ multimodal questions that can be answered by directly\nretrieving information from a non-text modality. Thus, complex reasoning\nremains poorly understood in multimodal domains. Here, we present MARBLE, a\nchallenging multimodal reasoning benchmark that is designed to scrutinize\nmultimodal language models (MLLMs) in their ability to carefully reason\nstep-by-step through complex multimodal problems and environments. MARBLE is\ncomposed of two highly challenging tasks, M-Portal and M-Cube, that require the\ncrafting and understanding of multistep plans under spatial, visual, and\nphysical constraints. We find that current MLLMs perform poorly on MARBLE --\nall the 12 advanced models obtain near-random performance on M-Portal and 0%\naccuracy on M-Cube. Only in simplified subtasks some models outperform the\nrandom baseline, indicating that complex reasoning is still a challenge for\nexisting MLLMs. Moreover, we show that perception remains a bottleneck, where\nMLLMs occasionally fail to extract information from the visual inputs. By\nshedding a light on the limitations of MLLMs, we hope that MARBLE will spur the\ndevelopment of the next generation of models with the ability to reason and\nplan across many, multimodal reasoning steps.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MARBLE\uff0c\u8fd9\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\uff0c\u65e8\u5728\u8bc4\u4f30\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u524d\u7684MLLMs\u5728MARBLE\u4e0a\u7684\u8868\u73b0\u8f83\u5dee\uff0c\u8868\u660e\u591a\u6a21\u6001\u63a8\u7406\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u7406\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u6587\u672c\u63a8\u7406\uff0c\u6216\u8005\u4f7f\u7528\u53ef\u4ee5\u76f4\u63a5\u4ece\u975e\u6587\u672c\u6a21\u6001\u4e2d\u68c0\u7d22\u4fe1\u606f\u7684\u591a\u6a21\u6001\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u591a\u6a21\u6001\u9886\u57df\u4e2d\u7684\u590d\u6742\u63a8\u7406\u4ecd\u7136\u7406\u89e3\u4e0d\u8db3\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\uff0c\u4ee5\u8bc4\u4f30\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86MARBLE\uff0c\u8fd9\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\uff0c\u5305\u542b\u4e24\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1M-Portal\u548cM-Cube\uff0c\u8981\u6c42\u5728\u7a7a\u95f4\u3001\u89c6\u89c9\u548c\u7269\u7406\u7ea6\u675f\u4e0b\u5236\u5b9a\u548c\u7406\u89e3\u591a\u6b65\u9aa4\u8ba1\u5212\u3002", "result": "\u5f53\u524d\u7684MLLMs\u5728MARBLE\u4e0a\u7684\u8868\u73b0\u8f83\u5dee\uff0c\u6240\u670912\u4e2a\u5148\u8fdb\u7684\u6a21\u578b\u5728M-Portal\u4e0a\u83b7\u5f97\u63a5\u8fd1\u968f\u673a\u7684\u6027\u80fd\uff0c\u5728M-Cube\u4e0a\u5f97\u5206\u4e3a0%\u3002\u53ea\u6709\u5728\u7b80\u5316\u7684\u5b50\u4efb\u52a1\u4e2d\uff0c\u4e00\u4e9b\u6a21\u578b\u624d\u80fd\u8d85\u8fc7\u968f\u673a\u57fa\u7ebf\uff0c\u8fd9\u8868\u660e\u590d\u6742\u7684\u63a8\u7406\u4ecd\u7136\u662f\u73b0\u6709MLLMs\u7684\u6311\u6218\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u8868\u660e\u611f\u77e5\u4ecd\u7136\u662f\u4e00\u4e2a\u74f6\u9888\uff0cMLLMs\u6709\u65f6\u65e0\u6cd5\u4ece\u89c6\u89c9\u8f93\u5165\u4e2d\u63d0\u53d6\u4fe1\u606f\u3002", "conclusion": "MARBLE\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\uff0c\u65e8\u5728\u8bc4\u4f30\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u5904\u7406\u590d\u6742\u591a\u6a21\u6001\u95ee\u9898\u548c\u73af\u5883\u65f6\u7684\u9010\u6b65\u63a8\u7406\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u524d\u7684MLLMs\u5728MARBLE\u4e0a\u7684\u8868\u73b0\u8f83\u5dee\uff0c\u8868\u660e\u591a\u6a21\u6001\u63a8\u7406\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002\u901a\u8fc7\u63ed\u793aMLLMs\u7684\u5c40\u9650\u6027\uff0c\u5e0c\u671bMARBLE\u80fd\u63a8\u52a8\u4e0b\u4e00\u4ee3\u80fd\u591f\u8de8\u591a\u6a21\u6001\u63a8\u7406\u6b65\u9aa4\u8fdb\u884c\u63a8\u7406\u548c\u89c4\u5212\u7684\u6a21\u578b\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.23049", "pdf": "https://arxiv.org/pdf/2506.23049", "abs": "https://arxiv.org/abs/2506.23049", "authors": ["Leander Melroy Maben", "Gayathri Ganesh Lakshmy", "Srijith Radhakrishnan", "Siddhant Arora", "Shinji Watanabe"], "title": "AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks", "categories": ["cs.AI", "cs.CL", "cs.SD", "eess.AS", "68T42, 68T50,", "I.2.7; I.2.11; H.5.5"], "comment": null, "summary": "Despite advances in language and speech technologies, no open-source system\nenables full speech-to-speech, multi-turn dialogue with integrated tool use and\nagentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and\nAutomated Tool Use), the first open-source, speech-native assistant capable of\ncompleting complex, goal-driven tasks through dynamic tool invocation and\nmulti-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a\ncascaded pipeline and supports tools such as calendar booking, contact lookup,\nweb search, and email. Its modular design allows easy integration of new tools\nusing natural language prompts and action classes. On VoiceBench, AURA scores\n92.75% on OpenBookQA-outperforming all open-weight systems and nearing\nGPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems.\nHuman evaluation shows 90% task success on complex, multi-turn speech tasks.", "AI": {"tldr": "AURA \u662f\u4e00\u4e2a\u5f00\u653e\u6e90\u4ee3\u7801\u7684\u8bed\u97f3\u539f\u751f\u52a9\u624b\uff0c\u80fd\u591f\u901a\u8fc7\u52a8\u6001\u5de5\u5177\u8c03\u7528\u548c\u591a\u8f6e\u5bf9\u8bdd\u5b8c\u6210\u590d\u6742\u7684\u3001\u4ee5\u76ee\u6807\u4e3a\u5bfc\u5411\u7684\u4efb\u52a1\u3002\u5b83\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u5728\u4eba\u7c7b\u8bc4\u4f30\u4e2d\u663e\u793a\u51fa\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u5c3d\u7ba1\u5728\u8bed\u8a00\u548c\u8bed\u97f3\u6280\u672f\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u6ca1\u6709\u5f00\u6e90\u7cfb\u7edf\u80fd\u591f\u5b9e\u73b0\u5b8c\u6574\u7684\u8bed\u97f3\u5230\u8bed\u97f3\u3001\u591a\u8f6e\u5bf9\u8bdd\uff0c\u5e76\u96c6\u6210\u5de5\u5177\u4f7f\u7528\u548c\u4ee3\u7406\u63a8\u7406\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u7cfb\u7edf\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "AURA \u7ed3\u5408\u4e86\u5f00\u653e\u6743\u91cd\u7684 ASR\u3001TTS \u548c LLMs\uff0c\u5728\u7ea7\u8054\u7ba1\u9053\u4e2d\u8fd0\u884c\uff0c\u5e76\u652f\u6301\u65e5\u5386\u9884\u8ba2\u3001\u8054\u7cfb\u4eba\u67e5\u627e\u3001\u7f51\u7edc\u641c\u7d22\u548c\u7535\u5b50\u90ae\u4ef6\u7b49\u5de5\u5177\u3002\u5176\u6a21\u5757\u5316\u8bbe\u8ba1\u5141\u8bb8\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u548c\u52a8\u4f5c\u7c7b\u8f7b\u677e\u96c6\u6210\u65b0\u5de5\u5177\u3002", "result": "AURA \u5728 VoiceBench \u4e0a\u5f97\u5206 92.75% on OpenBookQA\uff0c\u8d85\u8fc7\u6240\u6709\u5f00\u653e\u6743\u91cd\u7cfb\u7edf\uff0c\u5e76\u63a5\u8fd1 GPT-4o\uff1b\u5728 AlpacaEval \u4e0a\u5f97\u5206\u4e3a 4.39\uff0c\u4e0e\u5176\u4ed6\u5f00\u653e\u6743\u91cd\u7cfb\u7edf\u76f8\u5f53\u3002\u4eba\u7c7b\u8bc4\u4f30\u663e\u793a\u5728\u590d\u6742\u3001\u591a\u8f6e\u8bed\u97f3\u4efb\u52a1\u4e2d\u7684\u4efb\u52a1\u6210\u529f\u7387\u4e3a 90%\u3002", "conclusion": "AURA \u662f\u4e00\u4e2a\u5f00\u653e\u6e90\u4ee3\u7801\u7684\u8bed\u97f3\u539f\u751f\u52a9\u624b\uff0c\u80fd\u591f\u901a\u8fc7\u52a8\u6001\u5de5\u5177\u8c03\u7528\u548c\u591a\u8f6e\u5bf9\u8bdd\u5b8c\u6210\u590d\u6742\u7684\u3001\u4ee5\u76ee\u6807\u4e3a\u5bfc\u5411\u7684\u4efb\u52a1\u3002\u5b83\u5728 VoiceBench \u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u6240\u6709\u5f00\u653e\u6743\u91cd\u7cfb\u7edf\uff0c\u5e76\u4e14\u5728\u4eba\u7c7b\u8bc4\u4f30\u4e2d\u663e\u793a\u51fa 90% \u7684\u4efb\u52a1\u6210\u529f\u7387\u3002"}}
{"id": "2506.23115", "pdf": "https://arxiv.org/pdf/2506.23115", "abs": "https://arxiv.org/abs/2506.23115", "authors": ["Haonan Chen", "Hong Liu", "Yuping Luo", "Liang Wang", "Nan Yang", "Furu Wei", "Zhicheng Dou"], "title": "MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Homepage: https://haon-chen.github.io/MoCa/", "summary": "Multimodal embedding models, built upon causal Vision Language Models (VLMs),\nhave shown promise in various tasks. However, current approaches face three key\nlimitations: the use of causal attention in VLM backbones is suboptimal for\nembedding tasks; scalability issues due to reliance on high-quality labeled\npaired data for contrastive learning; and limited diversity in training\nobjectives and data. To address these issues, we propose MoCa, a two-stage\nframework for transforming pre-trained VLMs into effective bidirectional\nmultimodal embedding models. The first stage, Modality-aware Continual\nPre-training, introduces a joint reconstruction objective that simultaneously\ndenoises interleaved text and image inputs, enhancing bidirectional\ncontext-aware reasoning. The second stage, Heterogeneous Contrastive\nFine-tuning, leverages diverse, semantically rich multimodal data beyond simple\nimage-caption pairs to enhance generalization and alignment. Our method\naddresses the stated limitations by introducing bidirectional attention through\ncontinual pre-training, scaling effectively with massive unlabeled datasets via\njoint reconstruction objectives, and utilizing diverse multimodal data for\nenhanced representation robustness. Experiments demonstrate that MoCa\nconsistently improves performance across MMEB and ViDoRe-v2 benchmarks,\nachieving new state-of-the-art results, and exhibits strong scalability with\nboth model size and training data on MMEB.", "AI": {"tldr": "MoCa is a two-stage framework for transforming pre-trained VLMs into effective bidirectional multimodal embedding models. It addresses the limitations of current approaches by introducing bidirectional attention through continual pre-training, scaling effectively with massive unlabeled datasets via joint reconstruction objectives, and utilizing diverse multimodal data for enhanced representation robustness. Experiments show that MoCa achieves new state-of-the-art results on MMEB and ViDoRe-v2 benchmarks.", "motivation": "Current approaches face three key limitations: the use of causal attention in VLM backbones is suboptimal for embedding tasks; scalability issues due to reliance on high-quality labeled paired data for contrastive learning; and limited diversity in training objectives and data.", "method": "MoCa is a two-stage framework for transforming pre-trained VLMs into effective bidirectional multimodal embedding models. The first stage, Modality-aware Continual Pre-training, introduces a joint reconstruction objective that simultaneously denoises interleaved text and image inputs, enhancing bidirectional context-aware reasoning. The second stage, Heterogeneous Contrastive Fine-tuning, leverages diverse, semantically rich multimodal data beyond simple image-caption pairs to enhance generalization and alignment.", "result": "MoCa addresses the stated limitations by introducing bidirectional attention through continual pre-training, scaling effectively with massive unlabeled datasets via joint reconstruction objectives, and utilizing diverse multimodal data for enhanced representation robustness. Experiments demonstrate that MoCa consistently improves performance across MMEB and ViDoRe-v2 benchmarks, achieving new state-of-the-art results, and exhibits strong scalability with both model size and training data on MMEB.", "conclusion": "MoCa consistently improves performance across MMEB and ViDoRe-v2 benchmarks, achieving new state-of-the-art results, and exhibits strong scalability with both model size and training data on MMEB."}}
{"id": "2506.23219", "pdf": "https://arxiv.org/pdf/2506.23219", "abs": "https://arxiv.org/abs/2506.23219", "authors": ["Jie Feng", "Shengyuan Wang", "Tianhui Liu", "Yanxin Xi", "Yong Li"], "title": "UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted by ICCV 2025", "summary": "Urban research involves a wide range of scenarios and tasks that require the\nunderstanding of multi-modal data. Current methods often focus on specific data\ntypes and lack a unified framework in urban field for processing them\ncomprehensively. The recent success of multi-modal large language models\n(MLLMs) presents a promising opportunity to overcome this limitation. In this\npaper, we introduce $\\textit{UrbanLLaVA}$, a multi-modal large language model\ndesigned to process these four types of data simultaneously and achieve strong\nperformance across diverse urban tasks compared with general MLLMs. In\n$\\textit{UrbanLLaVA}$, we first curate a diverse urban instruction dataset\nencompassing both single-modal and cross-modal urban data, spanning from\nlocation view to global view of urban environment. Additionally, we propose a\nmulti-stage training framework that decouples spatial reasoning enhancement\nfrom domain knowledge learning, thereby improving the compatibility and\ndownstream performance of $\\textit{UrbanLLaVA}$ across diverse urban tasks.\nFinally, we also extend existing benchmark for urban research to assess the\nperformance of MLLMs across a wide range of urban tasks. Experimental results\nfrom three cities demonstrate that $\\textit{UrbanLLaVA}$ outperforms\nopen-source and proprietary MLLMs in both single-modal tasks and complex\ncross-modal tasks and shows robust generalization abilities across cities.\nSource codes and data are openly accessible to the research community via\nhttps://github.com/tsinghua-fib-lab/UrbanLLaVA.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86UrbanLLaVA\uff0c\u8fd9\u662f\u4e00\u79cd\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u65e8\u5728\u540c\u65f6\u5904\u7406\u56db\u79cd\u7c7b\u578b\u7684\u6570\u636e\uff0c\u5e76\u5728\u4e0e\u901a\u7528MLLMs\u76f8\u6bd4\u7684\u591a\u6837\u5316\u57ce\u5e02\u4efb\u52a1\u4e2d\u5b9e\u73b0\u5f3a\u5927\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684\u65b9\u6cd5\u5f80\u5f80\u4e13\u6ce8\u4e8e\u7279\u5b9a\u7684\u6570\u636e\u7c7b\u578b\uff0c\u5e76\u4e14\u5728\u57ce\u5e02\u9886\u57df\u7f3a\u4e4f\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u5168\u9762\u5904\u7406\u5b83\u4eec\u3002\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u6210\u529f\u4e3a\u514b\u670d\u8fd9\u4e00\u9650\u5236\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u673a\u4f1a\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u9636\u6bb5\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u5c06\u7a7a\u95f4\u63a8\u7406\u589e\u5f3a\u4e0e\u9886\u57df\u77e5\u8bc6\u5b66\u4e60\u89e3\u8026\uff0c\u4ece\u800c\u63d0\u9ad8UrbanLLaVA\u5728\u5404\u79cd\u57ce\u5e02\u4efb\u52a1\u4e2d\u7684\u517c\u5bb9\u6027\u548c\u4e0b\u6e38\u6027\u80fd\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u6269\u5c55\u4e86\u73b0\u6709\u7684\u57ce\u5e02\u7814\u7a76\u57fa\u51c6\u6765\u8bc4\u4f30MLLM\u5728\u5e7f\u6cdb\u7684\u57ce\u5e02\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cUrbanLLaVA\u5728\u5355\u6a21\u6001\u4efb\u52a1\u548c\u590d\u6742\u7684\u8de8\u6a21\u6001\u4efb\u52a1\u4e2d\u90fd\u4f18\u4e8e\u5f00\u6e90\u548c\u4e13\u6709MLLM\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u57ce\u5e02\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cUrbanLLaVA\u5728\u5355\u6a21\u6001\u4efb\u52a1\u548c\u590d\u6742\u7684\u8de8\u6a21\u6001\u4efb\u52a1\u4e2d\u90fd\u4f18\u4e8e\u5f00\u6e90\u548c\u4e13\u6709MLLM\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u57ce\u5e02\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.23225", "pdf": "https://arxiv.org/pdf/2506.23225", "abs": "https://arxiv.org/abs/2506.23225", "authors": ["Yukito Tajima", "Nakamasa Inoue", "Yusuke Sekikawa", "Ikuro Sato", "Rio Yokota"], "title": "Masked Gated Linear Unit", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Gated Linear Units (GLUs) have become essential components in the\nfeed-forward networks of state-of-the-art Large Language Models (LLMs).\nHowever, they require twice as many memory reads compared to feed-forward\nlayers without gating, due to the use of separate weight matrices for the gate\nand value streams. To address this bottleneck, we introduce Masked Gated Linear\nUnits (MGLUs), a novel family of GLUs with an efficient kernel implementation.\nThe core contribution of MGLUs include: (1) the Mixture of Element-wise Gating\n(MoEG) architecture that learns multiple binary masks, each determining gate or\nvalue assignments at the element level on a single shared weight matrix\nresulting in reduced memory transfer, and (2) FlashMGLU, a hardware-friendly\nkernel that yields up to a 19.7 $\\times$ inference-time speed-up over a naive\nPyTorch MGLU and is 47% more memory-efficient and 34% faster than standard GLUs\ndespite added architectural complexity on an RTX5090 GPU. In LLM experiments,\nthe Swish-activated variant SwiMGLU preserves its memory advantages while\nmatching - or even surpassing - the downstream accuracy of the SwiGLU baseline.", "AI": {"tldr": "MGLUs are a novel type of GLU that improves memory efficiency and inference speed in LLMs while maintaining or enhancing accuracy.", "motivation": "Standard GLUs require more memory reads due to separate weight matrices for gate and value streams, leading to inefficiencies in LLMs. The goal is to improve memory efficiency and inference speed without sacrificing accuracy.", "method": "The paper introduces MGLUs, which include the MoEG architecture and FlashMGLU kernel, to address the memory inefficiency of standard GLUs. It also evaluates the performance of SwiMGLU in LLM experiments.", "result": "FlashMGLU achieves a 19.7\u00d7 speed-up over a naive PyTorch MGLU and is 47% more memory-efficient and 34% faster than standard GLUs on an RTX5090 GPU. SwiMGLU matches or surpasses the accuracy of SwiGLU while preserving memory advantages.", "conclusion": "MGLUs offer significant improvements in memory efficiency and inference speed compared to traditional GLUs, while maintaining or improving downstream accuracy in LLMs."}}
{"id": "2506.23276", "pdf": "https://arxiv.org/pdf/2506.23276", "abs": "https://arxiv.org/abs/2506.23276", "authors": ["David Guzman Piedrahita", "Yongjin Yang", "Mrinmaya Sachan", "Giorgia Ramponi", "Bernhard Sch\u00f6lkopf", "Zhijing Jin"], "title": "Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed as autonomous\nagents, understanding their cooperation and social mechanisms is becoming\nincreasingly important. In particular, how LLMs balance self-interest and\ncollective well-being is a critical challenge for ensuring alignment,\nrobustness, and safe deployment. In this paper, we examine the challenge of\ncostly sanctioning in multi-agent LLM systems, where an agent must decide\nwhether to invest its own resources to incentivize cooperation or penalize\ndefection. To study this, we adapt a public goods game with institutional\nchoice from behavioral economics, allowing us to observe how different LLMs\nnavigate social dilemmas over repeated interactions. Our analysis reveals four\ndistinct behavioral patterns among models: some consistently establish and\nsustain high levels of cooperation, others fluctuate between engagement and\ndisengagement, some gradually decline in cooperative behavior over time, and\nothers rigidly follow fixed strategies regardless of outcomes. Surprisingly, we\nfind that reasoning LLMs, such as the o1 series, struggle significantly with\ncooperation, whereas some traditional LLMs consistently achieve high levels of\ncooperation. These findings suggest that the current approach to improving\nLLMs, which focuses on enhancing their reasoning capabilities, does not\nnecessarily lead to cooperation, providing valuable insights for deploying LLM\nagents in environments that require sustained collaboration. Our code is\navailable at https://github.com/davidguzmanp/SanctSim", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u4ee3\u7406\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u4e2d\u7684\u6210\u672c\u5236\u88c1\u95ee\u9898\uff0c\u901a\u8fc7\u6539\u7f16\u884c\u4e3a\u7ecf\u6d4e\u5b66\u4e2d\u7684\u516c\u5171\u7269\u54c1\u6e38\u620f\u4e0e\u5236\u5ea6\u9009\u62e9\uff0c\u89c2\u5bdf\u4e0d\u540c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5e94\u5bf9\u793e\u4f1a\u56f0\u5883\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4e00\u4e9b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5408\u4f5c\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u800c\u4e00\u4e9b\u63a8\u7406\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5374\u8868\u73b0\u51fa\u56f0\u96be\u3002\u8fd9\u8868\u660e\uff0c\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u5e76\u4e0d\u4e00\u5b9a\u5bfc\u81f4\u5408\u4f5c\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4f5c\u81ea\u4e3b\u4ee3\u7406\uff0c\u7406\u89e3\u5b83\u4eec\u7684\u5408\u4f5c\u548c\u793e\u4f1a\u673a\u5236\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u7279\u522b\u662f\uff0cLLMs \u5982\u4f55\u5e73\u8861\u81ea\u8eab\u5229\u76ca\u548c\u96c6\u4f53\u798f\u7949\u662f\u786e\u4fdd\u5bf9\u9f50\u3001\u9c81\u68d2\u6027\u548c\u5b89\u5168\u90e8\u7f72\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u6211\u4eec\u6539\u7f16\u4e86\u884c\u4e3a\u7ecf\u6d4e\u5b66\u4e2d\u7684\u516c\u5171\u7269\u54c1\u6e38\u620f\u4e0e\u5236\u5ea6\u9009\u62e9\uff0c\u4ee5\u89c2\u5bdf\u4e0d\u540c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5728\u91cd\u590d\u4e92\u52a8\u4e2d\u5e94\u5bf9\u793e\u4f1a\u56f0\u5883\u3002", "result": "\u6211\u4eec\u7684\u5206\u6790\u63ed\u793a\u4e86\u6a21\u578b\u4e2d\u7684\u56db\u79cd\u4e0d\u540c\u884c\u4e3a\u6a21\u5f0f\uff1a\u4e00\u4e9b\u6a21\u578b\u59cb\u7ec8\u5efa\u7acb\u5e76\u7ef4\u6301\u9ad8\u6c34\u5e73\u7684\u5408\u4f5c\uff0c\u53e6\u4e00\u4e9b\u6a21\u578b\u5728\u53c2\u4e0e\u548c\u4e0d\u53c2\u4e0e\u4e4b\u95f4\u6ce2\u52a8\uff0c\u4e00\u4e9b\u6a21\u578b\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\u9010\u6e10\u51cf\u5c11\u5408\u4f5c\u884c\u4e3a\uff0c\u800c\u53e6\u4e00\u4e9b\u6a21\u578b\u5219\u65e0\u8bba\u7ed3\u679c\u5982\u4f55\u90fd\u4e25\u683c\u9075\u5faa\u56fa\u5b9a\u7b56\u7565\u3002\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u6211\u4eec\u53d1\u73b0\u50cf o1 \u7cfb\u5217\u8fd9\u6837\u7684\u63a8\u7406\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5408\u4f5c\u65b9\u9762\u9047\u5230\u4e86\u663e\u8457\u56f0\u96be\uff0c\u800c\u4e00\u4e9b\u4f20\u7edf\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5219\u59cb\u7ec8\u80fd\u591f\u5b9e\u73b0\u9ad8\u6c34\u5e73\u7684\u5408\u4f5c\u3002", "conclusion": "\u5f53\u524d\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u4e13\u6ce8\u4e8e\u589e\u5f3a\u5176\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4e0d\u4e00\u5b9a\u5bfc\u81f4\u5408\u4f5c\uff0c\u8fd9\u4e3a\u5728\u9700\u8981\u6301\u7eed\u534f\u4f5c\u7684\u73af\u5883\u4e2d\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.23322", "pdf": "https://arxiv.org/pdf/2506.23322", "abs": "https://arxiv.org/abs/2506.23322", "authors": ["Wei Zhou", "Ji Sun", "Xuanhe Zhou", "Guoliang Li", "Luyang Liu", "Hao Wu", "Tianyuan Wang"], "title": "GaussMaster: An LLM-based Database Copilot System", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.IR"], "comment": "We welcome contributions from the community. For reference, please\n  see the code at: https://gitcode.com/opengauss/openGauss-GaussMaster", "summary": "In the financial industry, data is the lifeblood of operations, and DBAs\nshoulder significant responsibilities for SQL tuning, database deployment,\ndiagnosis, and service repair. In recent years, both database vendors and\ncustomers have increasingly turned to autonomous database platforms in an\neffort to alleviate the heavy workload of DBAs. However, existing autonomous\ndatabase platforms are limited in their capabilities, primarily addressing\nsingle-point issues such as NL2SQL, anomaly detection, and SQL tuning. Manual\nintervention remains a necessity for comprehensive database maintenance.\nGaussMaster aims to revolutionize this landscape by introducing an LLM-based\ndatabase copilot system. This innovative solution is designed not only to\nassist developers in writing efficient SQL queries but also to provide\ncomprehensive care for database services. When database instances exhibit\nabnormal behavior, GaussMaster is capable of orchestrating the entire\nmaintenance process automatically. It achieves this by analyzing hundreds of\nmetrics and logs, employing a Tree-of-thought approach to identify root causes,\nand invoking appropriate tools to resolve issues. We have successfully\nimplemented GaussMaster in real-world scenarios, such as the banking industry,\nwhere it has achieved zero human intervention for over 34 database maintenance\nscenarios. In this paper, we present significant improvements in these tasks\nwith code at https://gitcode.com/opengauss/openGauss-GaussMaster.", "AI": {"tldr": "GaussMaster is an LLM-based database copilot system that automates database maintenance by analyzing metrics and logs, identifying root causes, and resolving issues without human intervention.", "motivation": "The financial industry relies heavily on data, and DBAs face significant responsibilities. Existing autonomous database platforms are limited in their capabilities, requiring manual intervention for comprehensive database maintenance.", "method": "GaussMaster introduces an LLM-based database copilot system that analyzes hundreds of metrics and logs, employs a Tree-of-thought approach to identify root causes, and invokes appropriate tools to resolve issues automatically.", "result": "GaussMaster has been successfully implemented in real-world scenarios, such as the banking industry, achieving zero human intervention for over 34 database maintenance scenarios.", "conclusion": "GaussMaster has achieved zero human intervention for over 34 database maintenance scenarios in real-world applications, demonstrating its effectiveness in revolutionizing database maintenance."}}
{"id": "2506.23366", "pdf": "https://arxiv.org/pdf/2506.23366", "abs": "https://arxiv.org/abs/2506.23366", "authors": ["Nathaniel Imel", "Zachary Hafen"], "title": "Density, asymmetry and citation dynamics in scientific literature", "categories": ["cs.DL", "cs.CL", "cs.SI"], "comment": null, "summary": "Scientific behavior is often characterized by a tension between building upon\nestablished knowledge and introducing novel ideas. Here, we investigate whether\nthis tension is reflected in the relationship between the similarity of a\nscientific paper to previous research and its eventual citation rate. To\noperationalize similarity to previous research, we introduce two complementary\nmetrics to characterize the local geometry of a publication's semantic\nneighborhood: (1) \\emph{density} ($\\rho$), defined as the ratio between a fixed\nnumber of previously-published papers and the minimum distance enclosing those\npapers in a semantic embedding space, and (2) asymmetry ($\\alpha$), defined as\nthe average directional difference between a paper and its nearest neighbors.\nWe tested the predictive relationship between these two metrics and its\nsubsequent citation rate using a Bayesian hierarchical regression approach,\nsurveying $\\sim 53,000$ publications across nine academic disciplines and five\ndifferent document embeddings. While the individual effects of $\\rho$ on\ncitation count are small and variable, incorporating density-based predictors\nconsistently improves out-of-sample prediction when added to baseline models.\nThese results suggest that the density of a paper's surrounding scientific\nliterature may carry modest but informative signals about its eventual impact.\nMeanwhile, we find no evidence that publication asymmetry improves model\npredictions of citation rates. Our work provides a scalable framework for\nlinking document embeddings to scientometric outcomes and highlights new\nquestions regarding the role that semantic similarity plays in shaping the\ndynamics of scientific reward.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u79d1\u5b66\u8bba\u6587\u4e0e\u5148\u524d\u7814\u7a76\u7684\u76f8\u4f3c\u6027\u4e0e\u5176\u5f15\u7528\u7387\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u4e24\u4e2a\u5ea6\u91cf\u6807\u51c6\uff08\u5bc6\u5ea6\u548c\u4e0d\u5bf9\u79f0\u6027\uff09\u5e76\u8fdb\u884c\u4e86\u5b9e\u8bc1\u5206\u6790\uff0c\u53d1\u73b0\u5bc6\u5ea6\u5bf9\u9884\u6d4b\u5f15\u7528\u7387\u6709\u4e00\u5b9a\u5e2e\u52a9\uff0c\u800c\u4e0d\u5bf9\u79f0\u6027\u5219\u65e0\u663e\u8457\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u79d1\u5b66\u8bba\u6587\u4e0e\u5148\u524d\u7814\u7a76\u7684\u76f8\u4f3c\u6027\u662f\u5426\u53cd\u6620\u5728\u5f15\u7528\u7387\u4e0a\uff0c\u5e76\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u8bed\u4e49\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u5ea6\u91cf\u6807\u51c6\u6765\u9884\u6d4b\u5f15\u7528\u7387\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86\u4e24\u4e2a\u4e92\u8865\u7684\u5ea6\u91cf\u6807\u51c6\u6765\u8868\u5f81\u51fa\u7248\u7269\u8bed\u4e49\u90bb\u57df\u7684\u5c40\u90e8\u51e0\u4f55\u7ed3\u6784\uff1a(1) \u5bc6\u5ea6\uff08\u03c1\uff09\uff0c\u5b9a\u4e49\u4e3a\u5148\u524d\u53d1\u8868\u7684\u56fa\u5b9a\u6570\u91cf\u7684\u8bba\u6587\u4e0e\u5305\u56f4\u8fd9\u4e9b\u8bba\u6587\u7684\u6700\u5c0f\u8ddd\u79bb\u7684\u6bd4\u7387\uff1b(2) \u4e0d\u5bf9\u79f0\u6027\uff08\u03b1\uff09\uff0c\u5b9a\u4e49\u4e3a\u4e00\u7bc7\u8bba\u6587\u4e0e\u5176\u6700\u8fd1\u90bb\u5c45\u4e4b\u95f4\u7684\u5e73\u5747\u65b9\u5411\u5dee\u5f02\u3002\u4f7f\u7528\u8d1d\u53f6\u65af\u5206\u5c42\u56de\u5f52\u65b9\u6cd5\u6d4b\u8bd5\u8fd9\u4e24\u4e2a\u5ea6\u91cf\u4e0e\u540e\u7eed\u5f15\u7528\u7387\u4e4b\u95f4\u7684\u9884\u6d4b\u5173\u7cfb\uff0c\u5e76\u8c03\u67e5\u4e86\u8de8\u4e5d\u4e2a\u5b66\u672f\u9886\u57df\u548c\u4e94\u79cd\u4e0d\u540c\u6587\u6863\u5d4c\u5165\u7684\u7ea653,000\u7bc7\u51fa\u7248\u7269\u3002", "result": "\u5c3d\u7ba1\u03c1\u5bf9\u5f15\u7528\u6570\u7684\u4e2a\u4f53\u6548\u5e94\u8f83\u5c0f\u4e14\u53ef\u53d8\uff0c\u4f46\u5c06\u57fa\u4e8e\u5bc6\u5ea6\u7684\u9884\u6d4b\u56e0\u5b50\u6dfb\u52a0\u5230\u57fa\u7ebf\u6a21\u578b\u4e2d\u65f6\uff0c\u51fa\u6837\u672c\u9884\u6d4b\u7684\u4e00\u81f4\u6027\u6709\u6240\u63d0\u9ad8\u3002\u6b64\u5916\uff0c\u6ca1\u6709\u8bc1\u636e\u8868\u660e\u51fa\u7248\u7269\u7684\u4e0d\u5bf9\u79f0\u6027\u80fd\u63d0\u9ad8\u6a21\u578b\u5bf9\u5f15\u7528\u7387\u7684\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8bba\u6587\u5468\u56f4\u79d1\u5b66\u6587\u732e\u7684\u5bc6\u5ea6\u53ef\u80fd\u643a\u5e26\u5173\u4e8e\u5176\u6700\u7ec8\u5f71\u54cd\u7684\u9002\u5ea6\u4f46\u6709\u4fe1\u606f\u91cf\u7684\u4fe1\u53f7\u3002\u800c\u51fa\u7248\u7269\u7684\u4e0d\u5bf9\u79f0\u6027\u4f3c\u4e4e\u65e0\u6cd5\u63d0\u9ad8\u9884\u6d4b\u5f15\u7528\u7387\u7684\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.23367", "pdf": "https://arxiv.org/pdf/2506.23367", "abs": "https://arxiv.org/abs/2506.23367", "authors": ["Paige Tutt\u00f6s\u00ed", "H. Henny Yeung", "Yue Wang", "Jean-Julien Aucouturier", "Angelica Lim"], "title": "You Sound a Little Tense: L2 Tailored Clear TTS Using Durational Vowel Properties", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "Accepted to ISCA Speech Synthesis Workshop, 2025", "summary": "We present the first text-to-speech (TTS) system tailored to second language\n(L2) speakers. We use duration differences between American English tense\n(longer) and lax (shorter) vowels to create a \"clarity mode\" for Matcha-TTS.\nOur perception studies showed that French-L1, English-L2 listeners had fewer\n(at least 9.15%) transcription errors when using our clarity mode, and found it\nmore encouraging and respectful than overall slowed down speech. Remarkably,\nlisteners were not aware of these effects: despite the decreased word error\nrate in clarity mode, listeners still believed that slowing all target words\nwas the most intelligible, suggesting that actual intelligibility does not\ncorrelate with perceived intelligibility. Additionally, we found that\nWhisper-ASR did not use the same cues as L2 speakers to differentiate difficult\nvowels and is not sufficient to assess the intelligibility of TTS systems for\nthese individuals.", "AI": {"tldr": "\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u7b2c\u4e8c\u8bed\u8a00\uff08L2\uff09\u8bf4\u8bdd\u4eba\u7684\u6587\u672c\u5230\u8bed\u97f3\uff08TTS\uff09\u7cfb\u7edf\uff0c\u901a\u8fc7\u5229\u7528\u7f8e\u56fd\u82f1\u8bed\u4e2d\u7d27\u5143\u97f3\u548c\u677e\u5143\u97f3\u7684\u6301\u7eed\u65f6\u95f4\u5dee\u5f02\u6765\u521b\u5efa\u201c\u6e05\u6670\u6a21\u5f0f\u201d\u3002\u611f\u77e5\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u79cd\u6a21\u5f0f\u80fd\u6709\u6548\u63d0\u9ad8\u8f6c\u5f55\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u6bd4\u6574\u4f53\u51cf\u6162\u7684\u8bed\u97f3\u66f4\u53d7\u542c\u4f17\u6b22\u8fce\u548c\u5c0a\u91cd\u3002\u7136\u800c\uff0c\u542c\u4f17\u5e76\u672a\u610f\u8bc6\u5230\u8fd9\u4e9b\u6548\u679c\uff0c\u4ed6\u4eec\u4ecd\u8ba4\u4e3a\u51cf\u6162\u6240\u6709\u76ee\u6807\u8bcd\u662f\u6700\u6613\u61c2\u7684\uff0c\u8fd9\u8868\u660e\u5b9e\u9645\u7684\u53ef\u7406\u89e3\u6027\u4e0e\u611f\u77e5\u7684\u53ef\u7406\u89e3\u6027\u4e4b\u95f4\u6ca1\u6709\u76f8\u5173\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u53d1\u73b0Whisper-ASR\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u8fd9\u4e9b\u7528\u6237\u7684TTS\u7cfb\u7edf\u7684\u53ef\u7406\u89e3\u6027\u3002", "motivation": "\u6211\u4eec\u5e0c\u671b\u4e3a\u7b2c\u4e8c\u8bed\u8a00\uff08L2\uff09\u8bf4\u8bdd\u4eba\u5f00\u53d1\u4e00\u4e2a\u4e13\u95e8\u7684\u6587\u672c\u5230\u8bed\u97f3\uff08TTS\uff09\u7cfb\u7edf\uff0c\u4ee5\u63d0\u9ad8\u4ed6\u4eec\u7684\u8bed\u97f3\u8bc6\u522b\u51c6\u786e\u6027\u3002", "method": "\u6211\u4eec\u4f7f\u7528\u7f8e\u56fd\u82f1\u8bed\u4e2d\u7d27\u5143\u97f3\uff08\u8f83\u957f\uff09\u548c\u677e\u5143\u97f3\uff08\u8f83\u77ed\uff09\u7684\u6301\u7eed\u65f6\u95f4\u5dee\u5f02\u6765\u521b\u5efaMatcha-TTS\u7684\u201c\u6e05\u6670\u6a21\u5f0f\u201d\u3002", "result": "\u611f\u77e5\u7814\u7a76\u8868\u660e\uff0c\u6cd5\u8bed\u6bcd\u8bed\u8005\uff08L1\uff09\u548c\u82f1\u8bed\u4e8c\u8bed\uff08L2\uff09\u542c\u4f17\u5728\u4f7f\u7528\u6211\u4eec\u7684\u6e05\u6670\u6a21\u5f0f\u65f6\uff0c\u8f6c\u5f55\u9519\u8bef\u51cf\u5c11\u4e86\u81f3\u5c119.15%\uff0c\u5e76\u4e14\u8ba4\u4e3a\u5b83\u6bd4\u6574\u4f53\u51cf\u6162\u7684\u8bed\u97f3\u66f4\u4ee4\u4eba\u9f13\u821e\u548c\u5c0a\u91cd\u3002\u7136\u800c\uff0c\u542c\u4f17\u5e76\u6ca1\u6709\u610f\u8bc6\u5230\u8fd9\u4e9b\u6548\u679c\uff1a\u5c3d\u7ba1\u6e05\u6670\u6a21\u5f0f\u4e0b\u7684\u5355\u8bcd\u9519\u8bef\u7387\u4e0b\u964d\u4e86\uff0c\u4f46\u542c\u4f17\u4ecd\u7136\u8ba4\u4e3a\u51cf\u6162\u6240\u6709\u76ee\u6807\u8bcd\u662f\u6700\u6613\u61c2\u7684\uff0c\u8fd9\u8868\u660e\u5b9e\u9645\u7684\u53ef\u7406\u89e3\u6027\u4e0e\u611f\u77e5\u7684\u53ef\u7406\u89e3\u6027\u4e4b\u95f4\u6ca1\u6709\u76f8\u5173\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u53d1\u73b0Whisper-ASR\u4e0d\u50cfL2\u8bf4\u8bdd\u4eba\u90a3\u6837\u4f7f\u7528\u76f8\u540c\u7684\u7ebf\u7d22\u6765\u533a\u5206\u56f0\u96be\u7684\u5143\u97f3\uff0c\u5e76\u4e14\u4e0d\u8db3\u4ee5\u8bc4\u4f30\u8fd9\u4e9b\u7528\u6237\u7684TTS\u7cfb\u7edf\u7684\u53ef\u7406\u89e3\u6027\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6e05\u6670\u6a21\u5f0f\u5728\u63d0\u9ad8\u7b2c\u4e8c\u8bed\u8a00\uff08L2\uff09\u8bf4\u8bdd\u4eba\u7684\u8bed\u97f3\u8bc6\u522b\u51c6\u786e\u6027\u65b9\u9762\u662f\u6709\u6548\u7684\uff0c\u5e76\u4e14\u6bd4\u6574\u4f53\u51cf\u6162\u7684\u8bed\u97f3\u66f4\u53d7\u542c\u4f17\u6b22\u8fce\u548c\u5c0a\u91cd\u3002\u6b64\u5916\uff0c\u6211\u4eec\u53d1\u73b0Whisper-ASR\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u9488\u5bf9\u8fd9\u4e9b\u7528\u6237\u7684TTS\u7cfb\u7edf\u7684\u53ef\u7406\u89e3\u6027\u3002"}}
{"id": "2506.23394", "pdf": "https://arxiv.org/pdf/2506.23394", "abs": "https://arxiv.org/abs/2506.23394", "authors": ["Simeon Emanuilov"], "title": "Teaching a Language Model to Speak the Language of Tools", "categories": ["cs.IR", "cs.AI", "cs.CL", "I.2.7; I.2.1"], "comment": null, "summary": "External tool integration through function-calling is essential for practical\nlanguage model applications, yet most multilingual models lack reliable\ntool-use capabilities in non-English languages. Even state-of-the-art\nmultilingual models struggle with determining when to use tools and generating\nthe structured outputs required for function calls, often exhibiting language\nconfusion when prompted in lower-resource languages. This work presents a\nmethodology for adapting existing language models to enable robust tool use in\nany target language, using Bulgarian as a case study. The approach involves\ncontinued training of the BgGPT model series (2.6B, 9B, 27B parameters) on a\nnovel bilingual dataset of 10,035 function-calling examples designed to support\nstandardized protocols like MCP (Model Context Protocol). The research\nintroduces TUCAN (Tool-Using Capable Assistant Navigator), which achieves up to\n28.75% improvement in function-calling accuracy over base models while\npreserving core language understanding, as verified on established Bulgarian\nbenchmarks. Beyond accuracy gains, TUCAN models demonstrate production-ready\nresponse formatting with clean, parsable function calls, contrasting with the\nverbose and inconsistent outputs of base models. The models, evaluation\nframework, and dataset are released to enable replication for other languages.\nThis work demonstrates a practical approach for extending tool-augmented\ncapabilities beyond English-centric systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u65b0\u7684\u53cc\u8bed\u6570\u636e\u96c6\u4e0a\u7ee7\u7eed\u8bad\u7ec3\u6a21\u578b\uff0c\u4f7f\u73b0\u6709\u7684\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u4efb\u4f55\u76ee\u6807\u8bed\u8a00\u4e2d\u5b9e\u73b0\u7a33\u5065\u7684\u5de5\u5177\u4f7f\u7528\u3002TUCAN\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6bd4\u57fa\u7840\u6a21\u578b\u9ad8\u51fa28.75%\u7684\u51fd\u6570\u8c03\u7528\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u5c55\u793a\u4e86\u53ef\u751f\u4ea7\u4f7f\u7528\u7684\u54cd\u5e94\u683c\u5f0f\u3002", "motivation": "\u5927\u591a\u6570\u591a\u8bed\u8a00\u6a21\u578b\u5728\u975e\u82f1\u8bed\u8bed\u8a00\u4e2d\u7f3a\u4e4f\u53ef\u9760\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u591a\u8bed\u8a00\u6a21\u578b\u5728\u786e\u5b9a\u4f55\u65f6\u4f7f\u7528\u5de5\u5177\u548c\u751f\u6210\u51fd\u6570\u8c03\u7528\u6240\u9700\u7684\u7ed3\u6784\u5316\u8f93\u51fa\u65b9\u9762\u4e5f\u5b58\u5728\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u5bb9\u6613\u51fa\u73b0\u8bed\u8a00\u6df7\u6dc6\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u65b0\u7684\u53cc\u8bed\u6570\u636e\u96c6\u4e0a\u7ee7\u7eed\u8bad\u7ec3BgGPT\u6a21\u578b\u7cfb\u5217\uff0c\u4f7f\u73b0\u6709\u7684\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u4efb\u4f55\u76ee\u6807\u8bed\u8a00\u4e2d\u5b9e\u73b0\u7a33\u5065\u7684\u5de5\u5177\u4f7f\u7528\u3002", "result": "TUCAN\uff08Tool-Using Capable Assistant Navigator\uff09\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6bd4\u57fa\u7840\u6a21\u578b\u9ad8\u51fa28.75%\u7684\u51fd\u6570\u8c03\u7528\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u5728\u4fdd\u6301\u6838\u5fc3\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u7684\u540c\u65f6\uff0c\u5c55\u793a\u4e86\u53ef\u751f\u4ea7\u4f7f\u7528\u7684\u54cd\u5e94\u683c\u5f0f\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5c06\u5de5\u5177\u589e\u5f3a\u529f\u80fd\u6269\u5c55\u5230\u4ee5\u82f1\u8bed\u4e3a\u4e2d\u5fc3\u7684\u7cfb\u7edf\u4e4b\u5916\u3002"}}
{"id": "2506.23517", "pdf": "https://arxiv.org/pdf/2506.23517", "abs": "https://arxiv.org/abs/2506.23517", "authors": ["Selin Dik", "Osman Erdem", "Mehmet Dik"], "title": "Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "As the use of AI tools by students has become more prevalent, instructors\nhave started using AI detection tools like GPTZero and QuillBot to detect AI\nwritten text. However, the reliability of these detectors remains uncertain. In\nour study, we focused mostly on the success rate of GPTZero, the most-used AI\ndetector, in identifying AI-generated texts based on different lengths of\nrandomly submitted essays: short (40-100 word count), medium (100-350 word\ncount), and long (350-800 word count). We gathered a data set consisting of\ntwenty-eight AI-generated papers and fifty human-written papers. With this\nrandomized essay data, papers were individually plugged into GPTZero and\nmeasured for percentage of AI generation and confidence. A vast majority of the\nAI-generated papers were detected accurately (ranging from 91-100% AI believed\ngeneration), while the human generated essays fluctuated; there were a handful\nof false positives. These findings suggest that although GPTZero is effective\nat detecting purely AI-generated content, its reliability in distinguishing\nhuman-authored texts is limited. Educators should therefore exercise caution\nwhen relying solely on AI detection tools.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86GPTZero\u5728\u68c0\u6d4bAI\u751f\u6210\u6587\u672c\u65b9\u9762\u7684\u6548\u679c\uff0c\u53d1\u73b0\u5176\u5bf9\u7eafAI\u751f\u6210\u5185\u5bb9\u6709\u6548\uff0c\u4f46\u5728\u533a\u5206\u4eba\u7c7b\u64b0\u5199\u6587\u672c\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "motivation": "\u968f\u7740\u5b66\u751f\u4f7f\u7528AI\u5de5\u5177\u7684\u666e\u53ca\uff0c\u6559\u5e08\u5f00\u59cb\u4f7f\u7528AI\u68c0\u6d4b\u5de5\u5177\u5982GPTZero\u548cQuillBot\u6765\u68c0\u6d4bAI\u5199\u4f5c\u6587\u672c\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u68c0\u6d4b\u5668\u7684\u53ef\u9760\u6027\u4ecd\u7136\u4e0d\u786e\u5b9a\u3002", "method": "\u6211\u4eec\u4e13\u6ce8\u4e8eGPTZero\u5728\u8bc6\u522b\u57fa\u4e8e\u4e0d\u540c\u957f\u5ea6\u7684\u968f\u673a\u63d0\u4ea4\u8bba\u6587\u7684AI\u751f\u6210\u6587\u672c\u65b9\u9762\u7684\u6210\u529f\u7387\u3002\u6211\u4eec\u6536\u96c6\u4e86\u4e00\u4e2a\u5305\u542b28\u7bc7AI\u751f\u6210\u8bba\u6587\u548c50\u7bc7\u4eba\u5de5\u64b0\u5199\u7684\u8bba\u6587\u7684\u6570\u636e\u96c6\u3002\u5c06\u8fd9\u4e9b\u968f\u673a\u8bba\u6587\u8f93\u5165GPTZero\uff0c\u5e76\u6d4b\u91cfAI\u751f\u6210\u767e\u5206\u6bd4\u548c\u7f6e\u4fe1\u5ea6\u3002", "result": "\u5927\u591a\u6570AI\u751f\u6210\u7684\u8bba\u6587\u88ab\u51c6\u786e\u68c0\u6d4b\uff0891-100%\u7684AI\u8ba4\u4e3a\u751f\u6210\uff09\uff0c\u800c\u4eba\u5de5\u64b0\u5199\u7684\u8bba\u6587\u5219\u6ce2\u52a8\uff1b\u6709\u4e00\u4e9b\u8bef\u62a5\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\uff0c\u5c3d\u7ba1GPTZero\u5728\u68c0\u6d4b\u7eafAI\u751f\u6210\u5185\u5bb9\u65b9\u9762\u662f\u6709\u6548\u7684\uff0c\u4f46\u5176\u5728\u533a\u5206\u4eba\u7c7b\u64b0\u5199\u6587\u672c\u65b9\u9762\u7684\u53ef\u9760\u6027\u6709\u9650\u3002\u56e0\u6b64\uff0c\u6559\u80b2\u5de5\u4f5c\u8005\u5728\u4ec5\u4f9d\u8d56AI\u68c0\u6d4b\u5de5\u5177\u65f6\u5e94\u8c28\u614e\u3002"}}
{"id": "2506.23563", "pdf": "https://arxiv.org/pdf/2506.23563", "abs": "https://arxiv.org/abs/2506.23563", "authors": ["Huanjin Yao", "Jiaxing Huang", "Yawen Qiu", "Michael K. Chen", "Wenzheng Liu", "Wei Zhang", "Wenjie Zeng", "Xikun Zhang", "Jingyi Zhang", "Yuxin Song", "Wenhao Wu", "Dacheng Tao"], "title": "MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "Technical report", "summary": "Reasoning plays a crucial role in advancing Multimodal Large Language Models\n(MLLMs) toward Artificial General Intelligence. However, existing MLLM\nbenchmarks often fall short in precisely and comprehensively evaluating\nlong-chain reasoning abilities from three key aspects: (1) lack of difficulty\nand diversity, (2) susceptibility to guessability and memorization, (3)\ninadequate assessment of intermediate reasoning steps. To fill this gap, we\nintroduce MMReason, a new benchmark designed to precisely and comprehensively\nevaluate MLLM long-chain reasoning capability with diverse, open-ended,\nchallenging questions. First, we curate challenging questions requiring\nmulti-step reasoning from various fields (i.e., 6 disciplines) and multiple\ndifficulty levels (i.e., from pre-university to university, and from\nfoundational to competition tiers). Second, these questions are reformulated\ninto an open-ended format and filtered using a multi-model voting technique to\neliminate shortcut cases related to guessing and memorization, ensuring robust\nreasoning evaluations. Third, we annotate the questions with detailed\nstep-by-step solutions, and design a reference-based ternary scoring mechanism\nto reliably assess intermediate reasoning steps. With MMReason, we benchmark\npopular leading MLLMs and provide an in-depth analysis of their reasoning\ncapabilities. We hope MMReason will serve as a valuable resource for advancing\nMLLM reasoning research. Code will be available at\nhttps://github.com/HJYao00/MMReason.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86 MMReason\uff0c\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u7cbe\u786e\u548c\u5168\u9762\u8bc4\u4f30 MLLM \u7684\u957f\u94fe\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684 MLLM \u57fa\u51c6\u6d4b\u8bd5\u5728\u7cbe\u786e\u548c\u5168\u9762\u8bc4\u4f30\u957f\u94fe\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5305\u62ec\u7f3a\u4e4f\u96be\u5ea6\u548c\u591a\u6837\u6027\u3001\u5bb9\u6613\u88ab\u731c\u6d4b\u548c\u8bb0\u5fc6\u6240\u5f71\u54cd\u4ee5\u53ca\u5bf9\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u7684\u8bc4\u4f30\u4e0d\u8db3\u3002", "method": "\u6211\u4eec\u4ece\u591a\u4e2a\u9886\u57df\u548c\u4e0d\u540c\u96be\u5ea6\u7ea7\u522b\u4e2d\u7cbe\u9009\u9700\u8981\u591a\u6b65\u9aa4\u63a8\u7406\u7684\u95ee\u9898\uff0c\u5e76\u5c06\u5176\u91cd\u65b0\u8868\u8ff0\u4e3a\u5f00\u653e\u6027\u683c\u5f0f\uff0c\u4f7f\u7528\u591a\u6a21\u578b\u6295\u7968\u6280\u672f\u8fc7\u6ee4\u6389\u4e0e\u731c\u6d4b\u548c\u8bb0\u5fc6\u76f8\u5173\u7684\u6377\u5f84\u60c5\u51b5\uff0c\u540c\u65f6\u5bf9\u95ee\u9898\u8fdb\u884c\u8be6\u7ec6\u5206\u6b65\u89e3\u7b54\u7684\u6ce8\u91ca\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8e\u53c2\u8003\u7684\u4e09\u5143\u8bc4\u5206\u673a\u5236\u6765\u53ef\u9760\u8bc4\u4f30\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u3002", "result": "\u6211\u4eec\u5bf9\u6d41\u884c\u7684\u9886\u5148 MLLM \u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5bf9\u5176\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790\u3002", "conclusion": "MMReason \u65e8\u5728\u4f5c\u4e3a\u63a8\u8fdb MLLM \u63a8\u7406\u7814\u7a76\u7684\u5b9d\u8d35\u8d44\u6e90\u3002"}}
{"id": "2506.23578", "pdf": "https://arxiv.org/pdf/2506.23578", "abs": "https://arxiv.org/abs/2506.23578", "authors": ["\u0141ukasz Kami\u0144ski", "S\u0142awomir Lasota"], "title": "Reachability in symmetric VASS", "categories": ["cs.FL", "cs.CL"], "comment": null, "summary": "We investigate the reachability problem in symmetric vector addition systems\nwith states (VASS), where transitions are invariant under a group of\npermutations of coordinates. One extremal case, the trivial groups, yields\ngeneral VASS. In another extremal case, the symmetric groups, we show that the\nreachability problem can be solved in PSPACE, regardless of the dimension of\ninput VASS (to be contrasted with Ackermannian complexity in general VASS). We\nalso consider other groups, in particular alternating and cyclic ones.\nFurthermore, motivated by the open status of the reachability problem in data\nVASS, we estimate the gain in complexity when the group arises as a combination\nof the trivial and symmetric groups.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5bf9\u79f0\u5411\u91cf\u52a0\u6cd5\u7cfb\u7edf\uff08VASS\uff09\u4e2d\u7684\u53ef\u8fbe\u6027\u95ee\u9898\uff0c\u53d1\u73b0\u5f53\u4f7f\u7528\u5bf9\u79f0\u7fa4\u65f6\uff0c\u53ef\u8fbe\u6027\u95ee\u9898\u53ef\u4ee5\u5728PSPACE\u4e2d\u89e3\u51b3\uff0c\u800c\u4e00\u822cVASS\u5177\u6709\u66f4\u9ad8\u7684\u590d\u6742\u5ea6\u3002\u6211\u4eec\u8fd8\u8003\u8651\u4e86\u5176\u4ed6\u7fa4\u7ed3\u6784\uff0c\u5e76\u8bc4\u4f30\u4e86\u590d\u6742\u5ea6\u7684\u63d0\u5347\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u89e3\u51b3\u6570\u636eVASS\u4e2d\u53ef\u8fbe\u6027\u95ee\u9898\u7684\u5f00\u653e\u72b6\u6001\uff0c\u5e76\u901a\u8fc7\u5206\u6790\u4e0d\u540c\u7fa4\u7ed3\u6784\u4e0b\u7684\u590d\u6742\u5ea6\u6765\u63d0\u9ad8\u5bf9\u8fd9\u4e00\u95ee\u9898\u7684\u7406\u89e3\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u5bf9\u79f0\u5411\u91cf\u52a0\u6cd5\u7cfb\u7edf\uff08VASS\uff09\u4e2d\u7684\u53ef\u8fbe\u6027\u95ee\u9898\uff0c\u7814\u7a76\u4e86\u4e0d\u540c\u7fa4\u7ed3\u6784\u4e0b\u7684\u590d\u6742\u5ea6\u3002\u6211\u4eec\u7279\u522b\u5173\u6ce8\u4e86\u5bf9\u79f0\u7fa4\u3001\u4ea4\u66ff\u7fa4\u548c\u5faa\u73af\u7fa4\u7684\u60c5\u51b5\uff0c\u5e76\u8bc4\u4f30\u4e86\u5f53\u7fa4\u7531\u5e73\u51e1\u7fa4\u548c\u5bf9\u79f0\u7fa4\u7ec4\u5408\u65f6\u7684\u590d\u6742\u5ea6\u63d0\u5347\u3002", "result": "\u672c\u6587\u8bc1\u660e\u4e86\u5728\u5bf9\u79f0\u7fa4\u7684\u60c5\u51b5\u4e0b\uff0c\u53ef\u8fbe\u6027\u95ee\u9898\u53ef\u4ee5\u5728PSPACE\u4e2d\u89e3\u51b3\uff0c\u800c\u4e00\u822c\u7684VASS\u5177\u6709Ackermannian\u590d\u6742\u5ea6\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u8003\u8651\u4e86\u5176\u4ed6\u7fa4\uff0c\u5982\u4ea4\u66ff\u7fa4\u548c\u5faa\u73af\u7fa4\uff0c\u5e76\u4f30\u8ba1\u4e86\u5f53\u7fa4\u7531\u5e73\u51e1\u7fa4\u548c\u5bf9\u79f0\u7fa4\u7ec4\u5408\u65f6\u7684\u590d\u6742\u5ea6\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u4e86\u5bf9\u79f0\u5411\u91cf\u52a0\u6cd5\u7cfb\u7edf\uff08VASS\uff09\u4e2d\u7684\u53ef\u8fbe\u6027\u95ee\u9898\uff0c\u5176\u4e2d\u8f6c\u6362\u5728\u5750\u6807\u6392\u5217\u7684\u7fa4\u4e0b\u4e0d\u53d8\u3002\u6211\u4eec\u5c55\u793a\u4e86\u5728\u5bf9\u79f0\u7fa4\u7684\u60c5\u51b5\u4e0b\uff0c\u53ef\u8fbe\u6027\u95ee\u9898\u53ef\u4ee5\u5728PSPACE\u4e2d\u89e3\u51b3\uff0c\u800c\u4e00\u822c\u7684VASS\u5177\u6709Ackermannian\u590d\u6742\u5ea6\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u8003\u8651\u4e86\u5176\u4ed6\u7fa4\uff0c\u5982\u4ea4\u66ff\u7fa4\u548c\u5faa\u73af\u7fa4\uff0c\u5e76\u4f30\u8ba1\u4e86\u5f53\u7fa4\u7531\u5e73\u51e1\u7fa4\u548c\u5bf9\u79f0\u7fa4\u7ec4\u5408\u65f6\u590d\u6742\u5ea6\u7684\u63d0\u5347\u3002"}}
{"id": "2506.23670", "pdf": "https://arxiv.org/pdf/2506.23670", "abs": "https://arxiv.org/abs/2506.23670", "authors": ["Mohammadmahdi Nouriborji", "Morteza Rohanian"], "title": "Efficient Interleaved Speech Modeling through Knowledge Distillation", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Current speech language models exceed the size and latency constraints of\nmany deployment environments. We build compact, expressive speech generation\nmodels through layer-aligned distillation, matching hidden states, attention\nmaps, and softened logits to compress large multimodal transformers by 3x with\nminimal loss in performance. We introduce TinyWave, a family of 2B-parameter\nmodels for speech-to-speech and interleaved speech-text generation, trained on\n50,000 hours of public audio. TinyWave supports (i) speech-only generation\nusing phonetic or expressive tokens and (ii) mixed speech-text continuations.\nEvaluation on Libri-Light shows TinyWave within 1.4 normalized perplexity\npoints of its teacher. Accuracy on spoken StoryCloze and SALMon reaches 93-97%\nof the teacher's performance, outperforming size-matched baselines. These\nmodels are optimized for deployment on commodity hardware, enabling\napplications in real-time conversational agents, assistive technologies, and\nlow-resource environments. We release models, training code, and evaluation\nscripts to support reproducible research on compact, expressive speech\ngeneration.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86TinyWave\uff0c\u4e00\u79cd\u7528\u4e8e\u8bed\u97f3\u5230\u8bed\u97f3\u548c\u4ea4\u9519\u8bed\u97f3-\u6587\u672c\u751f\u6210\u76842B\u53c2\u6570\u6a21\u578b\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8bed\u97f3\u751f\u6210\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u7684\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u8d85\u51fa\u4e86\u8bb8\u591a\u90e8\u7f72\u73af\u5883\u7684\u5927\u5c0f\u548c\u5ef6\u8fdf\u9650\u5236\u3002", "method": "\u901a\u8fc7\u5c42\u5bf9\u9f50\u7684\u77e5\u8bc6\u84b8\u998f\u6784\u5efa\u7d27\u51d1\u4e14\u5bcc\u6709\u8868\u73b0\u529b\u7684\u8bed\u97f3\u751f\u6210\u6a21\u578b\uff0c\u5339\u914d\u9690\u85cf\u72b6\u6001\u3001\u6ce8\u610f\u529b\u56fe\u548c\u8f6f\u5316logits\uff0c\u5c06\u5927\u578b\u591a\u6a21\u6001\u53d8\u538b\u5668\u538b\u7f293\u500d\uff0c\u540c\u65f6\u6027\u80fd\u635f\u5931\u6700\u5c0f\u3002", "result": "TinyWave\u5728Libri-Light\u4e0a\u7684\u5f52\u4e00\u5316\u56f0\u60d1\u5ea6\u6bd4\u5176\u6559\u5e08\u6a21\u578b\u4f4e1.4\u4e2a\u70b9\u3002\u5728\u53e3\u8bedStoryCloze\u548cSALMon\u4e0a\u7684\u51c6\u786e\u7387\u8fbe\u5230\u4e86\u6559\u5e08\u6a21\u578b\u768493-97%\uff0c\u8d85\u8fc7\u4e86\u5927\u5c0f\u5339\u914d\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8fd9\u4e9b\u6a21\u578b\u9488\u5bf9\u5546\u54c1\u786c\u4ef6\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u4f7f\u5b9e\u65f6\u5bf9\u8bdd\u4ee3\u7406\u3001\u8f85\u52a9\u6280\u672f\u548c\u4f4e\u8d44\u6e90\u73af\u5883\u4e2d\u7684\u5e94\u7528\u6210\u4e3a\u53ef\u80fd\u3002\u6211\u4eec\u53d1\u5e03\u4e86\u6a21\u578b\u3001\u8bad\u7ec3\u4ee3\u7801\u548c\u8bc4\u4f30\u811a\u672c\uff0c\u4ee5\u652f\u6301\u5728\u7d27\u51d1\u4e14\u5bcc\u6709\u8868\u73b0\u529b\u7684\u8bed\u97f3\u751f\u6210\u65b9\u9762\u7684\u53ef\u91cd\u590d\u7814\u7a76\u3002"}}
{"id": "2506.23706", "pdf": "https://arxiv.org/pdf/2506.23706", "abs": "https://arxiv.org/abs/2506.23706", "authors": ["Christoph Schnabl", "Daniel Hugenroth", "Bill Marino", "Alastair R. Beresford"], "title": "Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments", "categories": ["cs.AI", "cs.CL", "cs.CR"], "comment": "ICML 2024 Workshop TAIG", "summary": "Benchmarks are important measures to evaluate safety and compliance of AI\nmodels at scale. However, they typically do not offer verifiable results and\nlack confidentiality for model IP and benchmark datasets. We propose Attestable\nAudits, which run inside Trusted Execution Environments and enable users to\nverify interaction with a compliant AI model. Our work protects sensitive data\neven when model provider and auditor do not trust each other. This addresses\nverification challenges raised in recent AI governance frameworks. We build a\nprototype demonstrating feasibility on typical audit benchmarks against\nLlama-3.1.", "AI": {"tldr": "Attestable Audits are proposed to verify interaction with compliant AI models, even when there is no trust between the model provider and auditor.", "motivation": "Benchmarks for evaluating AI models lack confidentiality for model IP and benchmark datasets, and do not offer verifiable results.", "method": "Attestable Audits run inside Trusted Execution Environments to enable verification of interaction with compliant AI models.", "result": "A prototype was built to demonstrate the feasibility of Attestable Audits on typical audit benchmarks against Llama-3.1.", "conclusion": "Attestable Audits provide a solution to verify interaction with compliant AI models, even when the model provider and auditor do not trust each other."}}
{"id": "2506.23714", "pdf": "https://arxiv.org/pdf/2506.23714", "abs": "https://arxiv.org/abs/2506.23714", "authors": ["Md Moinul Islam", "Sofoklis Kakouros", "Janne Heikkil\u00e4", "Mourad Oussalah"], "title": "Towards an Automated Multimodal Approach for Video Summarization: Building a Bridge Between Text, Audio and Facial Cue-Based Summarization", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted to HHAI WS 2025: Workshops at the Fourth International\n  Conference on Hybrid Human-Artificial Intelligence (HHAI)", "summary": "The increasing volume of video content in educational, professional, and\nsocial domains necessitates effective summarization techniques that go beyond\ntraditional unimodal approaches. This paper proposes a behaviour-aware\nmultimodal video summarization framework that integrates textual, audio, and\nvisual cues to generate timestamp-aligned summaries. By extracting prosodic\nfeatures, textual cues and visual indicators, the framework identifies\nsemantically and emotionally important moments. A key contribution is the\nidentification of bonus words, which are terms emphasized across multiple\nmodalities and used to improve the semantic relevance and expressive clarity of\nthe summaries. The approach is evaluated against pseudo-ground truth (pGT)\nsummaries generated using LLM-based extractive method. Experimental results\ndemonstrate significant improvements over traditional extractive method, such\nas the Edmundson method, in both text and video-based evaluation metrics.\nText-based metrics show ROUGE-1 increasing from 0.4769 to 0.7929 and BERTScore\nfrom 0.9152 to 0.9536, while in video-based evaluation, our proposed framework\nimproves F1-Score by almost 23%. The findings underscore the potential of\nmultimodal integration in producing comprehensive and behaviourally informed\nvideo summaries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u884c\u4e3a\u611f\u77e5\u7684\u591a\u6a21\u6001\u89c6\u9891\u6458\u8981\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u6587\u672c\u3001\u97f3\u9891\u548c\u89c6\u89c9\u7ebf\u7d22\u6765\u751f\u6210\u65f6\u95f4\u6233\u5bf9\u9f50\u7684\u6458\u8981\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u6587\u672c\u548c\u89c6\u9891\u8bc4\u4f30\u6307\u6807\u4e0a\u7684\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u968f\u7740\u6559\u80b2\u3001\u4e13\u4e1a\u548c\u793e\u4f1a\u9886\u57df\u89c6\u9891\u5185\u5bb9\u7684\u589e\u52a0\uff0c\u9700\u8981\u8d85\u8d8a\u4f20\u7edf\u5355\u6a21\u6001\u65b9\u6cd5\u7684\u6709\u6548\u6458\u8981\u6280\u672f\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u884c\u4e3a\u611f\u77e5\u7684\u591a\u6a21\u6001\u89c6\u9891\u6458\u8981\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u6587\u672c\u3001\u97f3\u9891\u548c\u89c6\u89c9\u7ebf\u7d22\u4ee5\u751f\u6210\u65f6\u95f4\u6233\u5bf9\u9f50\u7684\u6458\u8981\u3002\u901a\u8fc7\u63d0\u53d6\u97f5\u5f8b\u7279\u5f81\u3001\u6587\u672c\u7ebf\u7d22\u548c\u89c6\u89c9\u6307\u6807\uff0c\u8be5\u6846\u67b6\u8bc6\u522b\u51fa\u8bed\u4e49\u548c\u60c5\u611f\u91cd\u8981\u7684\u65f6\u523b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u7684\u63d0\u53d6\u65b9\u6cd5\uff08\u5982Edmundson\u65b9\u6cd5\uff09\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5728\u6587\u672c\u548c\u89c6\u9891\u8bc4\u4f30\u6307\u6807\u4e0a\u90fd\u6709\u663e\u8457\u6539\u8fdb\u3002\u6587\u672c\u6307\u6807\u663e\u793aROUGE-1\u4ece0.4769\u589e\u52a0\u52300.7929\uff0cBERTScore\u4ece0.9152\u589e\u52a0\u52300.9536\uff0c\u800c\u5728\u89c6\u9891\u8bc4\u4f30\u4e2d\uff0c\u6211\u4eec\u7684\u6846\u67b6\u5c06F1\u5206\u6570\u63d0\u9ad8\u4e86\u8fd123%\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u591a\u6a21\u6001\u6574\u5408\u5728\u751f\u6210\u5168\u9762\u4e14\u884c\u4e3a\u76f8\u5173\u7684\u89c6\u9891\u6458\u8981\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.23845", "pdf": "https://arxiv.org/pdf/2506.23845", "abs": "https://arxiv.org/abs/2506.23845", "authors": ["Kenny Peng", "Rajiv Movva", "Jon Kleinberg", "Emma Pierson", "Nikhil Garg"], "title": "Use Sparse Autoencoders to Discover Unknown Concepts, Not to Act on Known Concepts", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "While sparse autoencoders (SAEs) have generated significant excitement, a\nseries of negative results have added to skepticism about their usefulness.\nHere, we establish a conceptual distinction that reconciles competing\nnarratives surrounding SAEs. We argue that while SAEs may be less effective for\nacting on known concepts, SAEs are powerful tools for discovering unknown\nconcepts. This distinction cleanly separates existing negative and positive\nresults, and suggests several classes of SAE applications. Specifically, we\noutline use cases for SAEs in (i) ML interpretability, explainability,\nfairness, auditing, and safety, and (ii) social and health sciences.", "AI": {"tldr": "This paper argues that while SAEs may be less effective for acting on known concepts, they are powerful tools for discovering unknown concepts and have potential applications in various fields.", "motivation": "The paper aims to reconcile competing narratives surrounding SAEs by establishing a conceptual distinction that explains their varying levels of effectiveness.", "method": "The paper establishes a conceptual distinction between the effectiveness of SAEs in acting on known concepts versus discovering unknown concepts.", "result": "The paper shows that SAEs may be less effective for acting on known concepts but are powerful tools for discovering unknown concepts. It also outlines several classes of SAE applications.", "conclusion": "SAEs are powerful tools for discovering unknown concepts, and they have potential applications in various fields such as ML interpretability, explainability, fairness, auditing, safety, and social and health sciences."}}
{"id": "2506.23978", "pdf": "https://arxiv.org/pdf/2506.23978", "abs": "https://arxiv.org/abs/2506.23978", "authors": ["Samuele Marro", "Philip Torr"], "title": "LLM Agents Are the Antidote to Walled Gardens", "categories": ["cs.LG", "cs.CL", "cs.CY", "cs.SI", "68T50, 68M10, 91B26", "I.2.11; I.2.7; H.4.5"], "comment": null, "summary": "While the Internet's core infrastructure was designed to be open and\nuniversal, today's application layer is dominated by closed, proprietary\nplatforms. Open and interoperable APIs require significant investment, and\nmarket leaders have little incentive to enable data exchange that could erode\ntheir user lock-in. We argue that LLM-based agents fundamentally disrupt this\nstatus quo. Agents can automatically translate between data formats and\ninteract with interfaces designed for humans: this makes interoperability\ndramatically cheaper and effectively unavoidable. We name this shift universal\ninteroperability: the ability for any two digital services to exchange data\nseamlessly using AI-mediated adapters. Universal interoperability undermines\nmonopolistic behaviours and promotes data portability. However, it can also\nlead to new security risks and technical debt. Our position is that the ML\ncommunity should embrace this development while building the appropriate\nframeworks to mitigate the downsides. By acting now, we can harness AI to\nrestore user freedom and competitive markets without sacrificing security.", "AI": {"tldr": "LLM\u4ee3\u7406\u53ef\u4ee5\u5b9e\u73b0\u901a\u7528\u4e92\u64cd\u4f5c\u6027\uff0c\u8fd9\u5c06\u6539\u53d8\u5f53\u524d\u4e92\u8054\u7f51\u5e94\u7528\u5c42\u7684\u5c01\u95ed\u72b6\u6001\uff0c\u4f46\u540c\u65f6\u4e5f\u5e26\u6765\u65b0\u7684\u5b89\u5168\u98ce\u9669\u3002ML\u793e\u533a\u5e94\u79ef\u6781\u5e94\u5bf9\u8fd9\u4e00\u53d8\u5316\uff0c\u5e76\u5efa\u7acb\u9002\u5f53\u7684\u6846\u67b6\u4ee5\u51cf\u8f7b\u8d1f\u9762\u5f71\u54cd\u3002", "motivation": "\u5f53\u524d\u4e92\u8054\u7f51\u5e94\u7528\u5c42\u7531\u5c01\u95ed\u7684\u4e13\u6709\u5e73\u53f0\u4e3b\u5bfc\uff0c\u5f00\u653e\u548c\u4e92\u64cd\u4f5c\u7684API\u9700\u8981\u5927\u91cf\u6295\u8d44\uff0c\u800c\u5e02\u573a\u9886\u5bfc\u8005\u7f3a\u4e4f\u6fc0\u52b1\u53bb\u4fc3\u8fdb\u6570\u636e\u4ea4\u6362\u3002LLM\u4ee3\u7406\u53ef\u4ee5\u81ea\u52a8\u8f6c\u6362\u6570\u636e\u683c\u5f0f\u5e76\u4e0e\u9762\u5411\u4eba\u7c7b\u7684\u63a5\u53e3\u4ea4\u4e92\uff0c\u4f7f\u4e92\u64cd\u4f5c\u6027\u66f4\u52a0\u4fbf\u5b9c\u4e14\u4e0d\u53ef\u907f\u514d\u3002", "method": "\u5206\u6790\u4e86LLM\u4ee3\u7406\u5982\u4f55\u6539\u53d8\u73b0\u72b6\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u5bf9\u4e92\u64cd\u4f5c\u6027\u3001\u5784\u65ad\u884c\u4e3a\u548c\u5b89\u5168\u98ce\u9669\u7684\u5f71\u54cd\u3002", "result": "LLM\u4ee3\u7406\u53ef\u4ee5\u5b9e\u73b0\u901a\u7528\u4e92\u64cd\u4f5c\u6027\uff0c\u8fd9\u4f7f\u5f97\u4efb\u4f55\u4e24\u4e2a\u6570\u5b57\u670d\u52a1\u90fd\u80fd\u4f7f\u7528AI\u4e2d\u4ecb\u9002\u914d\u5668\u65e0\u7f1d\u4ea4\u6362\u6570\u636e\uff0c\u4ece\u800c\u524a\u5f31\u5784\u65ad\u884c\u4e3a\u5e76\u4fc3\u8fdb\u6570\u636e\u53ef\u79fb\u690d\u6027\u3002\u7136\u800c\uff0c\u8fd9\u4e5f\u53ef\u80fd\u5bfc\u81f4\u65b0\u7684\u5b89\u5168\u98ce\u9669\u548c\u6280\u672f\u503a\u52a1\u3002", "conclusion": "ML\u793e\u533a\u5e94\u63a5\u53d7\u8fd9\u4e00\u53d1\u5c55\uff0c\u540c\u65f6\u5efa\u7acb\u9002\u5f53\u7684\u6846\u67b6\u6765\u7f13\u89e3\u8d1f\u9762\u5f71\u54cd\u3002\u901a\u8fc7\u73b0\u5728\u884c\u52a8\uff0c\u6211\u4eec\u53ef\u4ee5\u5229\u7528AI\u6062\u590d\u7528\u6237\u81ea\u7531\u548c\u7ade\u4e89\u5e02\u573a\uff0c\u800c\u4e0d\u4f1a\u727a\u7272\u5b89\u5168\u3002"}}
{"id": "2506.24019", "pdf": "https://arxiv.org/pdf/2506.24019", "abs": "https://arxiv.org/abs/2506.24019", "authors": ["Hongxin Zhang", "Zheyuan Zhang", "Zeyuan Wang", "Zunzhe Zhang", "Lixing Fang", "Qinhong Zhou", "Chuang Gan"], "title": "Ella: Embodied Social Agents with Lifelong Memory", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "We introduce Ella, an embodied social agent capable of lifelong learning\nwithin a community in a 3D open world, where agents accumulate experiences and\nacquire knowledge through everyday visual observations and social interactions.\nAt the core of Ella's capabilities is a structured, long-term multimodal memory\nsystem that stores, updates, and retrieves information effectively. It consists\nof a name-centric semantic memory for organizing acquired knowledge and a\nspatiotemporal episodic memory for capturing multimodal experiences. By\nintegrating this lifelong memory system with foundation models, Ella retrieves\nrelevant information for decision-making, plans daily activities, builds social\nrelationships, and evolves autonomously while coexisting with other intelligent\nbeings in the open world. We conduct capability-oriented evaluations in a\ndynamic 3D open world where 15 agents engage in social activities for days and\nare assessed with a suite of unseen controlled evaluations. Experimental\nresults show that Ella can influence, lead, and cooperate with other agents\nwell to achieve goals, showcasing its ability to learn effectively through\nobservation and social interaction. Our findings highlight the transformative\npotential of combining structured memory systems with foundation models for\nadvancing embodied intelligence. More videos can be found at\nhttps://umass-embodied-agi.github.io/Ella/.", "AI": {"tldr": "Ella\u662f\u4e00\u4e2a\u80fd\u591f\u57283D\u5f00\u653e\u4e16\u754c\u4e2d\u8fdb\u884c\u7ec8\u8eab\u5b66\u4e60\u7684\u5177\u8eab\u793e\u4ea4\u4ee3\u7406\uff0c\u5b83\u5229\u7528\u7ed3\u6784\u5316\u7684\u957f\u671f\u591a\u6a21\u6001\u8bb0\u5fc6\u7cfb\u7edf\u6765\u5b58\u50a8\u3001\u66f4\u65b0\u548c\u68c0\u7d22\u4fe1\u606f\uff0c\u4ece\u800c\u5b9e\u73b0\u51b3\u7b56\u3001\u8ba1\u5212\u6d3b\u52a8\u3001\u5efa\u7acb\u793e\u4f1a\u5173\u7cfb\u548c\u81ea\u4e3b\u8fdb\u5316\u3002\u5b9e\u9a8c\u8868\u660e\uff0cElla\u80fd\u591f\u4e0e\u5176\u4ed6\u4ee3\u7406\u6709\u6548\u5408\u4f5c\u4ee5\u5b9e\u73b0\u76ee\u6807\uff0c\u5c55\u793a\u51fa\u5176\u901a\u8fc7\u89c2\u5bdf\u548c\u793e\u4f1a\u4e92\u52a8\u5b66\u4e60\u7684\u80fd\u529b\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u57283D\u5f00\u653e\u4e16\u754c\u4e2d\u8fdb\u884c\u7ec8\u8eab\u5b66\u4e60\u7684\u5177\u8eab\u793e\u4ea4\u4ee3\u7406\uff0c\u4f7f\u5176\u80fd\u591f\u901a\u8fc7\u65e5\u5e38\u89c6\u89c9\u89c2\u5bdf\u548c\u793e\u4f1a\u4e92\u52a8\u79ef\u7d2f\u7ecf\u9a8c\u548c\u77e5\u8bc6\u3002", "method": "Ella\u7684\u6838\u5fc3\u662f\u4e00\u79cd\u7ed3\u6784\u5316\u7684\u957f\u671f\u591a\u6a21\u6001\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u5305\u62ec\u4ee5\u540d\u79f0\u4e3a\u4e2d\u5fc3\u7684\u8bed\u4e49\u8bb0\u5fc6\u548c\u65f6\u7a7a\u60c5\u666f\u8bb0\u5fc6\u3002\u901a\u8fc7\u5c06\u8fd9\u79cd\u7ec8\u8eab\u8bb0\u5fc6\u7cfb\u7edf\u4e0e\u57fa\u7840\u6a21\u578b\u96c6\u6210\uff0cElla\u80fd\u591f\u68c0\u7d22\u76f8\u5173\u4fe1\u606f\u4ee5\u8fdb\u884c\u51b3\u7b56\u3001\u8ba1\u5212\u65e5\u5e38\u6d3b\u52a8\u3001\u5efa\u7acb\u793e\u4f1a\u5173\u7cfb\uff0c\u5e76\u5728\u5f00\u653e\u4e16\u754c\u4e2d\u4e0e\u5176\u4ed6\u667a\u80fd\u4f53\u5171\u5b58\u5e76\u81ea\u4e3b\u8fdb\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cElla\u80fd\u591f\u5f88\u597d\u5730\u5f71\u54cd\u3001\u9886\u5bfc\u548c\u4e0e\u5176\u4ed6\u4ee3\u7406\u5408\u4f5c\u4ee5\u5b9e\u73b0\u76ee\u6807\uff0c\u5c55\u793a\u4e86\u5176\u901a\u8fc7\u89c2\u5bdf\u548c\u793e\u4f1a\u4e92\u52a8\u6709\u6548\u5b66\u4e60\u7684\u80fd\u529b\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u7a81\u663e\u4e86\u5c06\u7ed3\u6784\u5316\u8bb0\u5fc6\u7cfb\u7edf\u4e0e\u57fa\u7840\u6a21\u578b\u7ed3\u5408\u7684\u53d8\u9769\u6f5c\u529b\uff0c\u4ee5\u63a8\u52a8\u5177\u8eab\u667a\u80fd\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.24056", "pdf": "https://arxiv.org/pdf/2506.24056", "abs": "https://arxiv.org/abs/2506.24056", "authors": ["Tung-Ling Li", "Hongliang Liu"], "title": "Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models", "categories": ["cs.CR", "cs.CL", "cs.LG"], "comment": null, "summary": "We introduce logit-gap steering, a fast jailbreak framework that casts the\nrefusal-affirmation gap of RLHF-aligned language models as a single pass over\nthe vocabulary. A forward-computable score blends gap reduction with\nlightweight proxies for KL penalty and reward shift, allowing a \"sort-sum-stop\"\nsweep to complete in under a second and return a short suffix--two orders of\nmagnitude fewer model calls than beam or gradient attacks. The same suffix\ngeneralises to unseen prompts and scales from 0.5 B to 70 B checkpoints,\nlifting one-shot attack success from baseline levels to 80-100% while\npreserving topical coherence. Beyond efficiency, these suffixes expose\nsentence-boundary reward cliffs and other alignment artefacts, offering a\nlightweight probe into how safety tuning reshapes internal representations.", "AI": {"tldr": "logit-gap steering \u662f\u4e00\u79cd\u9ad8\u6548\u7684 jailbreak \u6846\u67b6\uff0c\u80fd\u591f\u5728\u77ed\u65f6\u95f4\u5185\u63d0\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e76\u63ed\u793a\u5b89\u5168\u8c03\u4f18\u5bf9\u6a21\u578b\u5185\u90e8\u8868\u793a\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7684\u653b\u51fb\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7684\u6a21\u578b\u8c03\u7528\uff0c\u6548\u7387\u4f4e\u4e0b\uff0c\u800c logit-gap steering \u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "logit-gap steering \u901a\u8fc7\u5c06 RLHF \u5bf9\u9f50\u8bed\u8a00\u6a21\u578b\u7684\u62d2\u7edd-\u80af\u5b9a\u5dee\u8ddd\u8f6c\u6362\u4e3a\u8bcd\u6c47\u8868\u4e0a\u7684\u5355\u6b21\u904d\u5386\uff0c\u5e76\u4f7f\u7528\u524d\u5411\u8ba1\u7b97\u5f97\u5206\u6765\u5e73\u8861\u5dee\u8ddd\u51cf\u5c11\u4e0e\u8f7b\u91cf\u7ea7\u4ee3\u7406\u7684 KL \u60e9\u7f5a\u548c\u5956\u52b1\u53d8\u5316\u3002", "result": "logit-gap steering \u5728\u4e0d\u5230\u4e00\u79d2\u949f\u5185\u5b8c\u6210\u653b\u51fb\uff0c\u5e76\u4e14\u80fd\u591f\u5c06\u5355\u6b21\u653b\u51fb\u7684\u6210\u529f\u7387\u4ece\u57fa\u7ebf\u6c34\u5e73\u63d0\u5347\u5230 80-100%\u3002", "conclusion": "logit-gap steering \u662f\u4e00\u79cd\u9ad8\u6548\u7684 jailbreak \u6846\u67b6\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u653b\u51fb\u6210\u529f\u7387\u5e76\u63ed\u793a\u5b89\u5168\u8c03\u4f18\u5bf9\u5185\u90e8\u8868\u793a\u7684\u5f71\u54cd\u3002"}}
{"id": "2506.24086", "pdf": "https://arxiv.org/pdf/2506.24086", "abs": "https://arxiv.org/abs/2506.24086", "authors": ["Bingfan Zhu", "Biao Jiang", "Sunyi Wang", "Shixiang Tang", "Tao Chen", "Linjie Luo", "Youyi Zheng", "Xin Chen"], "title": "MotionGPT3: Human Motion as a Second Modality", "categories": ["cs.CV", "cs.CL"], "comment": "21 pages, 8 figures", "summary": "Though recent advances in multimodal models have demonstrated strong\ncapabilities and opportunities in unified understanding and generation, the\ndevelopment of unified motion-language models remains underexplored. To enable\nsuch models with high-fidelity human motion, two core challenges must be\naddressed. The first is the reconstruction gap between the continuous motion\nmodality and discrete representation in an autoregressive manner, and the\nsecond is the degradation of language intelligence during unified training.\nInspired by the mixture of experts, we propose MotionGPT3, a bimodal\nmotion-language model that treats human motion as a second modality, decoupling\nmotion modeling via separate model parameters and enabling both effective\ncross-modal interaction and efficient multimodal scaling training. To preserve\nlanguage intelligence, the text branch retains the original structure and\nparameters of the pretrained language model, while a new motion branch is\nintegrated via a shared attention mechanism, enabling bidirectional information\nflow between two modalities. We first employ a motion Variational Autoencoder\n(VAE) to encode raw human motion into latent representations. Based on this\ncontinuous latent space, the motion branch predicts motion latents directly\nfrom intermediate hidden states using a diffusion head, bypassing discrete\ntokenization. Extensive experiments show that our approach achieves competitive\nperformance on both motion understanding and generation tasks while preserving\nstrong language capabilities, establishing a unified bimodal motion diffusion\nframework within an autoregressive manner.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMotionGPT3\u7684\u53cc\u6a21\u6001\u8fd0\u52a8-\u8bed\u8a00\u6a21\u578b\uff0c\u65e8\u5728\u89e3\u51b3\u8fd0\u52a8\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u4e24\u4e2a\u6838\u5fc3\u6311\u6218\u3002\u901a\u8fc7\u5f15\u5165\u8fd0\u52a8\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548c\u6269\u6563\u5934\uff0c\u8be5\u6a21\u578b\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u8de8\u6a21\u6001\u4ea4\u4e92\u548c\u9ad8\u6548\u7684\u591a\u6a21\u6001\u6269\u5c55\u8bad\u7ec3\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u8bed\u8a00\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u6700\u8fd1\u5728\u591a\u6a21\u6001\u6a21\u578b\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u5c55\u793a\u4e86\u7edf\u4e00\u7406\u89e3\u548c\u751f\u6210\u7684\u80fd\u529b\u548c\u673a\u4f1a\uff0c\u4f46\u7edf\u4e00\u8fd0\u52a8-\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u4ecd\u7f3a\u4e4f\u63a2\u7d22\u3002\u4e3a\u4e86\u4f7f\u8fd9\u4e9b\u6a21\u578b\u5177\u5907\u9ad8\u4fdd\u771f\u7684\u4eba\u7c7b\u8fd0\u52a8\uff0c\u5fc5\u987b\u89e3\u51b3\u4e24\u4e2a\u6838\u5fc3\u6311\u6218\uff1a\u4e00\u662f\u8fde\u7eed\u8fd0\u52a8\u6a21\u6001\u4e0e\u79bb\u6563\u8868\u793a\u4e4b\u95f4\u7684\u91cd\u5efa\u5dee\u8ddd\uff0c\u4e8c\u662f\u7edf\u4e00\u8bad\u7ec3\u671f\u95f4\u8bed\u8a00\u667a\u80fd\u7684\u9000\u5316\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86MotionGPT3\uff0c\u8fd9\u662f\u4e00\u4e2a\u53cc\u6a21\u6001\u8fd0\u52a8-\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u4eba\u7c7b\u8fd0\u52a8\u89c6\u4e3a\u7b2c\u4e8c\u79cd\u6a21\u6001\uff0c\u901a\u8fc7\u5355\u72ec\u7684\u6a21\u578b\u53c2\u6570\u89e3\u8026\u8fd0\u52a8\u5efa\u6a21\uff0c\u5e76\u5b9e\u73b0\u6709\u6548\u7684\u8de8\u6a21\u6001\u4ea4\u4e92\u548c\u9ad8\u6548\u7684\u591a\u6a21\u6001\u6269\u5c55\u8bad\u7ec3\u3002\u6587\u672c\u5206\u652f\u4fdd\u7559\u4e86\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u539f\u59cb\u7ed3\u6784\u548c\u53c2\u6570\uff0c\u800c\u65b0\u7684\u8fd0\u52a8\u5206\u652f\u5219\u901a\u8fc7\u5171\u4eab\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c\u96c6\u6210\uff0c\u4f7f\u4e24\u79cd\u6a21\u6001\u4e4b\u95f4\u80fd\u591f\u53cc\u5411\u4fe1\u606f\u6d41\u52a8\u3002\u6211\u4eec\u9996\u5148\u4f7f\u7528\u8fd0\u52a8\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u5c06\u539f\u59cb\u4eba\u7c7b\u8fd0\u52a8\u7f16\u7801\u4e3a\u6f5c\u5728\u8868\u793a\u3002\u57fa\u4e8e\u8fd9\u4e2a\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\uff0c\u8fd0\u52a8\u5206\u652f\u76f4\u63a5\u4ece\u4e2d\u95f4\u9690\u85cf\u72b6\u6001\u9884\u6d4b\u8fd0\u52a8\u6f5c\u5728\u8868\u793a\uff0c\u7ed5\u8fc7\u4e86\u79bb\u6563\u6807\u8bb0\u5316\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u8fd0\u52a8\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u8bed\u8a00\u80fd\u529b\uff0c\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u53cc\u6a21\u6001\u8fd0\u52a8\u6269\u6563\u6846\u67b6\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u8fd0\u52a8\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u8bed\u8a00\u80fd\u529b\uff0c\u5728\u81ea\u56de\u5f52\u6846\u67b6\u5185\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u53cc\u6a21\u6001\u8fd0\u52a8\u6269\u6563\u6846\u67b6\u3002"}}
{"id": "2506.24119", "pdf": "https://arxiv.org/pdf/2506.24119", "abs": "https://arxiv.org/abs/2506.24119", "authors": ["Bo Liu", "Leon Guertler", "Simon Yu", "Zichen Liu", "Penghui Qi", "Daniel Balcells", "Mickel Liu", "Cheston Tan", "Weiyan Shi", "Min Lin", "Wee Sun Lee", "Natasha Jaques"], "title": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Work in Progress", "summary": "Recent advances in reinforcement learning have shown that language models can\ndevelop sophisticated reasoning through training on tasks with verifiable\nrewards, but these approaches depend on human-curated problem-answer pairs and\ndomain-specific reward engineering. We introduce SPIRAL, a self-play framework\nwhere models learn by playing multi-turn, zero-sum games against continuously\nimproving versions of themselves, eliminating the need for human supervision.\nThrough self-play, SPIRAL generates an infinite curriculum of progressively\nchallenging problems as models must constantly adapt to stronger opponents. To\nenable this self-play training at scale, We implement a fully online,\nmulti-turn, multi-agent reinforcement learning system for LLMs and propose\nrole-conditioned advantage estimation (RAE) to stabilize multi-agent training.\nUsing SPIRAL, self-play on zero-sum games produces reasoning capabilities that\ntransfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%\nimprovement on math and 8.4% on general reasoning, outperforming SFT on 25,000\nexpert game trajectories. Analysis reveals that this transfer occurs through\nthree cognitive patterns: systematic decomposition, expected value calculation,\nand case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple\nNegotiation) further enhances performance as each game develops distinct\nreasoning strengths. Applying SPIRAL to a strong reasoning model\n(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These\nresults demonstrate that zero-sum games naturally develop transferable\nreasoning capabilities, highlighting a promising direction for autonomous\nreasoning development.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SPIRAL\uff0c\u8fd9\u662f\u4e00\u79cd\u81ea\u6211\u5bf9\u5f08\u6846\u67b6\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u4e0e\u4e0d\u65ad\u6539\u8fdb\u7684\u81ea\u8eab\u7248\u672c\u8fdb\u884c\u591a\u8f6e\u96f6\u548c\u535a\u5f08\u6765\u5b66\u4e60\uff0c\u4ece\u800c\u65e0\u9700\u4eba\u7c7b\u76d1\u7763\u3002\u901a\u8fc7\u81ea\u6211\u5bf9\u5f08\uff0cSPIRAL\u751f\u6210\u4e86\u4e00\u4e2a\u65e0\u9650\u7684\u9010\u6b65\u6311\u6218\u6027\u95ee\u9898\u8bfe\u7a0b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u6700\u8fd1\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8fdb\u5c55\u8868\u660e\uff0c\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u5728\u5177\u6709\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bad\u7ec3\u6765\u53d1\u5c55\u590d\u6742\u7684\u63a8\u7406\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4eba\u5de5\u6574\u7406\u7684\u95ee\u9898-\u7b54\u6848\u5bf9\u548c\u9886\u57df\u7279\u5b9a\u7684\u5956\u52b1\u5de5\u7a0b\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86SPIRAL\uff0c\u8fd9\u662f\u4e00\u4e2a\u81ea\u6211\u5bf9\u5f08\u6846\u67b6\uff0c\u5176\u4e2d\u6a21\u578b\u901a\u8fc7\u4e0e\u4e0d\u65ad\u6539\u8fdb\u7684\u81ea\u8eab\u7248\u672c\u8fdb\u884c\u591a\u8f6e\u96f6\u548c\u535a\u5f08\u6765\u5b66\u4e60\uff0c\u6d88\u9664\u4e86\u5bf9\u4eba\u7c7b\u76d1\u7763\u7684\u9700\u6c42\u3002\u6211\u4eec\u5b9e\u73b0\u4e86\u5b8c\u5168\u5728\u7ebf\u3001\u591a\u8f6e\u3001\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\uff0c\u5e76\u63d0\u51fa\u4e86\u89d2\u8272\u6761\u4ef6\u4f18\u52bf\u4f30\u8ba1\uff08RAE\uff09\u4ee5\u7a33\u5b9a\u591a\u667a\u80fd\u4f53\u8bad\u7ec3\u3002", "result": "\u901a\u8fc7\u81ea\u6211\u5bf9\u5f08\uff0cSPIRAL\u751f\u6210\u4e86\u4e00\u4e2a\u65e0\u9650\u7684\u9010\u6b65\u6311\u6218\u6027\u95ee\u9898\u8bfe\u7a0b\uff0c\u56e0\u4e3a\u6a21\u578b\u5fc5\u987b\u4e0d\u65ad\u9002\u5e94\u66f4\u5f3a\u7684\u5bf9\u624b\u3002\u5728Kuhn Poker\u4e0a\u8fdb\u884c\u81ea\u6211\u5bf9\u5f08\u8bad\u7ec3Qwen3-4B-Base\uff0c\u6570\u5b66\u6210\u7ee9\u63d0\u9ad8\u4e868.6%\uff0c\u4e00\u822c\u63a8\u7406\u63d0\u9ad8\u4e868.4%\uff0c\u8d85\u8fc7\u4e86\u572825,000\u4e2a\u4e13\u5bb6\u6e38\u620f\u8f68\u8ff9\u4e0a\u7684SFT\u3002\u5206\u6790\u663e\u793a\uff0c\u8fd9\u79cd\u8fc1\u79fb\u662f\u901a\u8fc7\u4e09\u79cd\u8ba4\u77e5\u6a21\u5f0f\u5b9e\u73b0\u7684\uff1a\u7cfb\u7edf\u5206\u89e3\u3001\u671f\u671b\u503c\u8ba1\u7b97\u548c\u9010\u6848\u5206\u6790\u3002\u591a\u6e38\u620f\u8bad\u7ec3\uff08TicTacToe\u3001Kuhn Poker\u3001Simple Negotiation\uff09\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u56e0\u4e3a\u6bcf\u79cd\u6e38\u620f\u90fd\u53d1\u5c55\u4e86\u4e0d\u540c\u7684\u63a8\u7406\u4f18\u52bf\u3002\u5c06SPIRAL\u5e94\u7528\u4e8e\u4e00\u4e2a\u5f3a\u5927\u7684\u63a8\u7406\u6a21\u578b\uff08DeepSeek-R1-Distill-Qwen-7B\uff09\u4ecd\u80fd\u5e26\u67652.0%\u7684\u5e73\u5747\u63d0\u5347\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u96f6\u548c\u6e38\u620f\u81ea\u7136\u5730\u53d1\u5c55\u53ef\u8f6c\u79fb\u7684\u63a8\u7406\u80fd\u529b\uff0c\u7a81\u663e\u4e86\u81ea\u4e3b\u63a8\u7406\u53d1\u5c55\u7684\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002"}}
