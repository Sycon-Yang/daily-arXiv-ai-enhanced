{"id": "2506.14900", "pdf": "https://arxiv.org/pdf/2506.14900", "abs": "https://arxiv.org/abs/2506.14900", "authors": ["Imane Guellil", "Salom\u00e9 Andres", "Atul Anand", "Bruce Guthrie", "Huayu Zhang", "Abul Hasan", "Honghan Wu", "Beatrice Alex"], "title": "Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings", "categories": ["cs.CL"], "comment": "Accepted and will be published at ACL2025 (main conference)", "summary": "In this work, we present a manually annotated corpus for Adverse Event (AE)\nextraction from discharge summaries of elderly patients, a population often\nunderrepresented in clinical NLP resources. The dataset includes 14 clinically\nsignificant AEs-such as falls, delirium, and intracranial haemorrhage, along\nwith contextual attributes like negation, diagnosis type, and in-hospital\noccurrence. Uniquely, the annotation schema supports both discontinuous and\noverlapping entities, addressing challenges rarely tackled in prior work. We\nevaluate multiple models using FlairNLP across three annotation granularities:\nfine-grained, coarse-grained, and coarse-grained with negation. While\ntransformer-based models (e.g., BERT-cased) achieve strong performance on\ndocument-level coarse-grained extraction (F1 = 0.943), performance drops\nnotably for fine-grained entity-level tasks (e.g., F1 = 0.675), particularly\nfor rare events and complex attributes. These results demonstrate that despite\nhigh-level scores, significant challenges remain in detecting underrepresented\nAEs and capturing nuanced clinical language. Developed within a Trusted\nResearch Environment (TRE), the dataset is available upon request via DataLoch\nand serves as a robust benchmark for evaluating AE extraction methods and\nsupporting future cross-dataset generalisation.", "AI": {"tldr": "This study presents a new corpus for adverse event extraction from elderly patient discharge summaries, showing mixed success with different NLP models.", "motivation": "To present a manually annotated corpus for AE extraction from discharge summaries of elderly patients, a population often underrepresented in clinical NLP resources.", "method": "Multiple models were evaluated using FlairNLP across three annotation granularities: fine-grained, coarse-grained, and coarse-grained with negation.", "result": "Transformer-based models achieved strong performance on document-level coarse-grained extraction but performance dropped notably for fine-grained entity-level tasks, especially for rare events and complex attributes.", "conclusion": "Despite high-level scores, significant challenges remain in detecting underrepresented Adverse Events (AEs) and capturing nuanced clinical language."}}
{"id": "2506.14901", "pdf": "https://arxiv.org/pdf/2506.14901", "abs": "https://arxiv.org/abs/2506.14901", "authors": ["Marija \u0160akota", "Robert West"], "title": "Combining Constrained and Unconstrained Decoding via Boosting: BoostCD and Its Application to Information Extraction", "categories": ["cs.CL"], "comment": null, "summary": "Many recent approaches to structured NLP tasks use an autoregressive language\nmodel $M$ to map unstructured input text $x$ to output text $y$ representing\nstructured objects (such as tuples, lists, trees, code, etc.), where the\ndesired output structure is enforced via constrained decoding. During training,\nthese approaches do not require the model to be aware of the constraints, which\nare merely implicit in the training outputs $y$. This is advantageous as it\nallows for dynamic constraints without requiring retraining, but can lead to\nlow-quality output during constrained decoding at test time. We overcome this\nproblem with Boosted Constrained Decoding (BoostCD), which combines constrained\nand unconstrained decoding in two phases: Phase 1 decodes from the base model\n$M$ twice, in constrained and unconstrained mode, obtaining two weak\npredictions. In phase 2, a learned autoregressive boosted model combines the\ntwo weak predictions into one final prediction. The mistakes made by the base\nmodel with vs. without constraints tend to be complementary, which the boosted\nmodel learns to exploit for improved performance. We demonstrate the power of\nBoostCD by applying it to closed information extraction. Our model, BoostIE,\noutperforms prior approaches both in and out of distribution, addressing\nseveral common errors identified in those approaches.", "AI": {"tldr": "Recent methods for structured NLP tasks use language models to convert input text to structured output, relying on constrained decoding. These methods face issues with low-quality output during testing due to constraints ignored during training. A new approach called Boosted Constrained Decoding (BoostCD) improves performance by combining constrained and unconstrained decoding predictions.", "motivation": "The issue of low-quality output during constrained decoding at test time despite advantages during training.", "method": "Introduces Boosted Constrained Decoding (BoostCD) that combines constrained and unconstrained decoding in two phases.", "result": "BoostCD improves performance and results in a model called BoostIE that outperforms previous approaches.", "conclusion": "BoostCD addresses several common errors found in previous approaches and enhances performance in structured NLP tasks."}}
{"id": "2506.14912", "pdf": "https://arxiv.org/pdf/2506.14912", "abs": "https://arxiv.org/abs/2506.14912", "authors": ["Dyah Adila", "Shuai Zhang", "Boran Han", "Bonan Min", "Yuyang Wang"], "title": "CrEst: Credibility Estimation for Contexts in LLMs via Weak Supervision", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "The integration of contextual information has significantly enhanced the\nperformance of large language models (LLMs) on knowledge-intensive tasks.\nHowever, existing methods often overlook a critical challenge: the credibility\nof context documents can vary widely, potentially leading to the propagation of\nunreliable information. In this paper, we introduce CrEst, a novel weakly\nsupervised framework for assessing the credibility of context documents during\nLLM inference--without requiring manual annotations. Our approach is grounded\nin the insight that credible documents tend to exhibit higher semantic\ncoherence with other credible documents, enabling automated credibility\nestimation through inter-document agreement. To incorporate credibility into\nLLM inference, we propose two integration strategies: a black-box approach for\nmodels without access to internal weights or activations, and a white-box\nmethod that directly modifies attention mechanisms. Extensive experiments\nacross three model architectures and five datasets demonstrate that CrEst\nconsistently outperforms strong baselines, achieving up to a 26.86% improvement\nin accuracy and a 3.49% increase in F1 score. Further analysis shows that CrEst\nmaintains robust performance even under high-noise conditions.", "AI": {"tldr": "This paper introduces CrEst, a weakly supervised framework for evaluating the credibility of context documents during LLM inference without manual annotations.", "motivation": "Existing methods often neglect the varying credibility of context documents, which may lead to the spread of unreliable information.", "method": "CrEst uses inter-document agreement to estimate credibility and offers both black-box and white-box integration strategies for LLMs.", "result": "CrEst surpasses strong baselines across three model architectures and five datasets, improving accuracy by up to 26.86% and increasing F1 score by 3.49%. It also demonstrates robustness under high-noise conditions.", "conclusion": "CrEst effectively enhances the credibility assessment of context documents during LLM inference without relying on manual annotations."}}
{"id": "2506.14927", "pdf": "https://arxiv.org/pdf/2506.14927", "abs": "https://arxiv.org/abs/2506.14927", "authors": ["Joseph J. Peper", "Wenzhao Qiu", "Ali Payani", "Lu Wang"], "title": "MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Findings", "summary": "Natural language processing evaluation has made significant progress, largely\ndriven by the proliferation of powerful large language mod-els (LLMs). New\nevaluation benchmarks are of increasing priority as the reasoning capabilities\nof LLMs are expanding at a rapid pace. In particular, while multi-document (MD)\nreasoning is an area of extreme relevance given LLM capabilities in handling\nlonger-context inputs, few benchmarks exist to rigorously examine model\nbehavior in this setting. Moreover, the multi-document setting is historically\nchallenging for benchmark creation due to the expensive cost of annotating long\ninputs. In this work, we introduce MDBench, a new dataset for evaluating LLMs\non the task of multi-document reasoning. Notably, MDBench is created through a\nnovel synthetic generation process, allowing us to controllably and efficiently\ngenerate challenging document sets and the corresponding question-answer (QA)\nexamples. Our novel technique operates on condensed structured seed knowledge,\nmodifying it through LLM-assisted edits to induce MD-specific reasoning\nchallenges. We then convert this structured knowledge into a natural text\nsurface form, generating a document set and corresponding QA example. We\nanalyze the behavior of popular LLMs and prompting techniques, finding that\nMDBENCH poses significant challenges for all methods, even with relatively\nshort document sets. We also see our knowledge-guided generation technique (1)\nallows us to readily perform targeted analysis of MD-specific reasoning\ncapabilities and (2) can be adapted quickly to account for new challenges and\nfuture modeling improvements.", "AI": {"tldr": "This paper introduces MDBench, a new dataset for evaluating LLMs on multi-document reasoning tasks, which is generated synthetically through a knowledge-guided approach.", "motivation": "There is a lack of rigorous benchmarks for evaluating LLMs' multi-document reasoning capabilities, especially given the difficulty and expense of creating such benchmarks.", "method": "MDBench is created using a novel synthetic generation process based on condensed structured seed knowledge, modified via LLM-assisted edits, and converted into natural text surface form to generate document sets and corresponding QA examples.", "result": "MDBench presents significant challenges for popular LLMs and prompting techniques, even with short document sets. The knowledge-guided generation technique allows for targeted analysis of MD-specific reasoning capabilities and can adapt to future challenges and modeling improvements.", "conclusion": "The introduction of MDBench provides a valuable tool for evaluating LLMs' multi-document reasoning capabilities, showcasing the potential of knowledge-guided synthetic data generation."}}
{"id": "2506.14949", "pdf": "https://arxiv.org/pdf/2506.14949", "abs": "https://arxiv.org/abs/2506.14949", "authors": ["Shadman Sakib", "Oishy Fatema Akhand", "Ajwad Abrar"], "title": "From Chat to Checkup: Can Large Language Models Assist in Diabetes Prediction?", "categories": ["cs.CL"], "comment": "Accepted in 1st IEEE QPAIN 2025", "summary": "While Machine Learning (ML) and Deep Learning (DL) models have been widely\nused for diabetes prediction, the use of Large Language Models (LLMs) for\nstructured numerical data is still not well explored. In this study, we test\nthe effectiveness of LLMs in predicting diabetes using zero-shot, one-shot, and\nthree-shot prompting methods. We conduct an empirical analysis using the Pima\nIndian Diabetes Database (PIDD). We evaluate six LLMs, including four\nopen-source models: Gemma-2-27B, Mistral-7B, Llama-3.1-8B, and Llama-3.2-2B. We\nalso test two proprietary models: GPT-4o and Gemini Flash 2.0. In addition, we\ncompare their performance with three traditional machine learning models:\nRandom Forest, Logistic Regression, and Support Vector Machine (SVM). We use\naccuracy, precision, recall, and F1-score as evaluation metrics. Our results\nshow that proprietary LLMs perform better than open-source ones, with GPT-4o\nand Gemma-2-27B achieving the highest accuracy in few-shot settings. Notably,\nGemma-2-27B also outperforms the traditional ML models in terms of F1-score.\nHowever, there are still issues such as performance variation across prompting\nstrategies and the need for domain-specific fine-tuning. This study shows that\nLLMs can be useful for medical prediction tasks and encourages future work on\nprompt engineering and hybrid approaches to improve healthcare predictions.", "AI": {"tldr": "This study explores using Large Language Models (LLMs) for diabetes prediction with zero-shot, one-shot, and three-shot prompting methods. The best performance was achieved by proprietary LLMs, particularly GPT-4o and Gemma-2-27B, which outperformed traditional ML models in few-shot settings.", "motivation": "To investigate the potential of LLMs in structured numerical data prediction, specifically for diabetes.", "method": "Testing LLMs using different prompting methods and comparing them with traditional ML models using accuracy, precision, recall, and F1-score.", "result": "Proprietary LLMs performed better than open-source ones. GPT-4o and Gemma-2-27B had the highest accuracy in few-shot settings and even outperformed traditional ML models in F1-score.", "conclusion": "LLMs show promise for medical prediction tasks, encouraging further research into prompt engineering and hybrid approaches."}}
{"id": "2506.15001", "pdf": "https://arxiv.org/pdf/2506.15001", "abs": "https://arxiv.org/abs/2506.15001", "authors": ["Ignacio Sastre", "Aiala Ros\u00e1"], "title": "Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "This paper will be presented at The First Workshop on Large Language\n  Model Memorization (L2M2) at ACL 2025", "summary": "In this work, we observe an interesting phenomenon: it is possible to\ngenerate reversible sentence embeddings that allow an LLM to reconstruct the\noriginal text exactly, without modifying the model's weights. This is achieved\nby introducing a special memory token, whose embedding is optimized through\ntraining on a fixed sequence. When prompted with this embedding, the model\nreconstructs the fixed sequence exactly. We evaluate this phenomenon across\nEnglish and Spanish datasets, sequences of up to approximately 240 tokens, and\nmodel scales ranging from 100M to 8B parameters. Notably, Llama 3.1 8B\nsuccessfully reconstructs all tested sequences. Our findings highlight an\ninteresting capability of LLMs and suggest potential applications in\nmemory-based retrieval, compression, and controlled text generation.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLMs\u80fd\u751f\u6210\u53ef\u9006\u53e5\u5b50\u5d4c\u5165\uff0c\u5141\u8bb8\u7cbe\u786e\u91cd\u6784\u539f\u59cb\u6587\u672c\uff0c\u5c55\u793a\u4e86\u5176\u5728\u57fa\u4e8e\u5185\u5b58\u7684\u68c0\u7d22\u3001\u538b\u7f29\u53ca\u53ef\u63a7\u6587\u672c\u751f\u6210\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u4e00\u4e2a\u6709\u8da3\u73b0\u8c61\uff1a\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u4f18\u5316\u5d4c\u5165\u6765\u751f\u6210\u53ef\u9006\u53e5\u5b50\u5d4c\u5165\uff0c\u4f7fLLMs\u80fd\u591f\u7cbe\u786e\u91cd\u6784\u539f\u59cb\u6587\u672c\u800c\u4e0d\u6539\u53d8\u6a21\u578b\u6743\u91cd\u3002", "method": "\u5f15\u5165\u7279\u6b8a\u8bb0\u5fc6\u6807\u8bb0\u5e76\u4f18\u5316\u5176\u5d4c\u5165\uff0c\u901a\u8fc7\u5728\u56fa\u5b9a\u5e8f\u5217\u4e0a\u8bad\u7ec3\u5b9e\u73b0\u53ef\u9006\u5d4c\u5165\u751f\u6210\u3002", "result": "\u5728\u82f1\u8bed\u548c\u897f\u73ed\u7259\u8bed\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u4e86\u8fd9\u4e00\u73b0\u8c61\uff0c\u6d89\u53ca\u957f\u5ea6\u8fbe\u7ea6240\u4e2a\u6807\u8bb0\u7684\u5e8f\u5217\u4ee5\u53ca\u53c2\u6570\u8303\u56f4\u4ece1\u4ebf\u523080\u4ebf\u7684\u6a21\u578b\u89c4\u6a21\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cLlama 3.1 8B\u6210\u529f\u5730\u91cd\u6784\u4e86\u6240\u6709\u6d4b\u8bd5\u5e8f\u5217\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u7279\u6b8a\u7684\u8bb0\u5fc6\u6807\u8bb0\uff0cLLMs\u53ef\u4ee5\u5728\u4e0d\u4fee\u6539\u6743\u91cd\u7684\u60c5\u51b5\u4e0b\u751f\u6210\u53ef\u9006\u53e5\u5b50\u5d4c\u5165\uff0c\u5e76\u7cbe\u786e\u91cd\u6784\u539f\u59cb\u6587\u672c\u3002\u6b64\u73b0\u8c61\u5728\u591a\u79cd\u6570\u636e\u96c6\u548c\u6a21\u578b\u89c4\u6a21\u4e0b\u5747\u88ab\u9a8c\u8bc1\u6709\u6548\uff0c\u5c24\u5176\u662fLlama 3.1 8B\u6210\u529f\u91cd\u6784\u4e86\u6240\u6709\u6d4b\u8bd5\u5e8f\u5217\u3002\u7814\u7a76\u5f3a\u8c03\u4e86LLMs\u7684\u6709\u8da3\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u5176\u5728\u57fa\u4e8e\u5185\u5b58\u68c0\u7d22\u3001\u538b\u7f29\u548c\u53ef\u63a7\u6587\u672c\u751f\u6210\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u3002"}}
{"id": "2506.15030", "pdf": "https://arxiv.org/pdf/2506.15030", "abs": "https://arxiv.org/abs/2506.15030", "authors": ["Drew Walker", "Swati Rajwal", "Sudeshna Das", "Snigdha Peddireddy", "Abeed Sarker"], "title": "Identifying social isolation themes in NVDRS text narratives using topic modeling and text-classification methods", "categories": ["cs.CL"], "comment": "22 pages, 2 figures, 5 tables", "summary": "Social isolation and loneliness, which have been increasing in recent years\nstrongly contribute toward suicide rates. Although social isolation and\nloneliness are not currently recorded within the US National Violent Death\nReporting System's (NVDRS) structured variables, natural language processing\n(NLP) techniques can be used to identify these constructs in law enforcement\nand coroner medical examiner narratives. Using topic modeling to generate\nlexicon development and supervised learning classifiers, we developed\nhigh-quality classifiers (average F1: .86, accuracy: .82). Evaluating over\n300,000 suicides from 2002 to 2020, we identified 1,198 mentioning chronic\nsocial isolation. Decedents had higher odds of chronic social isolation\nclassification if they were men (OR = 1.44; CI: 1.24, 1.69, p<.0001), gay (OR =\n3.68; 1.97, 6.33, p<.0001), or were divorced (OR = 3.34; 2.68, 4.19, p<.0001).\nWe found significant predictors for other social isolation topics of recent or\nimpending divorce, child custody loss, eviction or recent move, and break-up.\nOur methods can improve surveillance and prevention of social isolation and\nloneliness in the United States.", "AI": {"tldr": "This study uses NLP techniques to identify social isolation and loneliness in NVDRS narratives, developing high-quality classifiers and finding significant predictors.", "motivation": "Social isolation and loneliness are increasing and strongly contribute to suicide rates, but are not currently recorded in NVDRS structured variables.", "method": "Using topic modeling for lexicon development and supervised learning classifiers to develop high-quality classifiers.", "result": "Classifiers identified 1,198 mentions of chronic social isolation in over 300,000 suicides from 2002 to 2020, with certain groups having higher odds of classification.", "conclusion": "The methods developed can improve surveillance and prevention of social isolation and loneliness in the United States."}}
{"id": "2506.15068", "pdf": "https://arxiv.org/pdf/2506.15068", "abs": "https://arxiv.org/abs/2506.15068", "authors": ["Zongxia Li", "Yapei Chang", "Yuhang Zhou", "Xiyang Wu", "Zichao Liang", "Yoo Yeon Sung", "Jordan Lee Boyd-Graber"], "title": "Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form Generation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Evaluating open-ended long-form generation is challenging because it is hard\nto define what clearly separates good from bad outputs. Existing methods often\nmiss key aspects like coherence, style, or relevance, or are biased by\npretraining data, making open-ended long-form evaluation an underexplored\nproblem. To address this gap, we propose PrefBERT, a scoring model for\nevaluating open-ended long-form generation in GRPO and guiding its training\nwith distinct rewards for good and bad outputs. Trained on two response\nevaluation datasets with diverse long-form styles and Likert-rated quality,\nPrefBERT effectively supports GRPO by offering better semantic reward feedback\nthan traditional metrics ROUGE-L and BERTScore do. Through comprehensive\nevaluations, including LLM-as-a-judge, human ratings, and qualitative analysis,\nwe show that PrefBERT, trained on multi-sentence and paragraph-length\nresponses, remains reliable across varied long passages and aligns well with\nthe verifiable rewards GRPO needs. Human evaluations confirm that using\nPrefBERT as the reward signal to train policy models yields responses better\naligned with human preferences than those trained with traditional metrics. Our\ncode is available at https://github.com/zli12321/long_form_rl.", "AI": {"tldr": "Propose PrefBERT, a scoring model for evaluating open-ended long-form generation.", "motivation": "Existing methods often miss key aspects like coherence, style, or relevance, or are biased by pretraining data, making open-ended long-form evaluation an underexplored problem.", "method": "PrefBERT is trained on two response evaluation datasets with diverse long-form styles and Likert-rated quality.", "result": "PrefBERT effectively supports GRPO by offering better semantic reward feedback than traditional metrics ROUGE-L and BERTScore do.", "conclusion": "Using PrefBERT as the reward signal to train policy models yields responses better aligned with human preferences."}}
{"id": "2506.15076", "pdf": "https://arxiv.org/pdf/2506.15076", "abs": "https://arxiv.org/abs/2506.15076", "authors": ["Ruihan Wu", "Konstantin Garov", "Kamalika Chaudhuri"], "title": "Learning-Time Encoding Shapes Unlearning in LLMs", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in the real world,\nthe ability to ``unlearn'', or remove specific pieces of knowledge post hoc,\nhas become essential for a variety of reasons ranging from privacy regulations\nto correcting outdated or harmful content. Prior work has proposed unlearning\nbenchmarks and algorithms, and has typically assumed that the training process\nand the target model are fixed. In this work, we empirically investigate how\nlearning-time choices in knowledge encoding impact the effectiveness of\nunlearning factual knowledge. Our experiments reveal two key findings: (1)\nlearning with paraphrased descriptions improves unlearning performance and (2)\nunlearning individual piece of knowledge from a chunk of text is challenging.\nOur results suggest that learning-time knowledge encoding may play a central\nrole in enabling reliable post-hoc unlearning.", "AI": {"tldr": "This paper investigates the impact of learning-time knowledge encoding on the effectiveness of unlearning factual knowledge in large language models.", "motivation": "The motivation behind this study is the increasing need for large language models to 'unlearn' specific pieces of knowledge post hoc due to reasons such as privacy regulations and the need to correct outdated or harmful content.", "method": "Experiments were conducted to investigate the impact of learning-time choices in knowledge encoding on the effectiveness of unlearning factual knowledge.", "result": "Two key findings were revealed: 1) learning with paraphrased descriptions improves unlearning performance and 2) unlearning individual piece of knowledge from a chunk of text is challenging.", "conclusion": "The study concludes that learning-time knowledge encoding plays a crucial role in effective post-hoc unlearning."}}
{"id": "2506.15081", "pdf": "https://arxiv.org/pdf/2506.15081", "abs": "https://arxiv.org/abs/2506.15081", "authors": ["Yaxin Fan", "Peifeng Li", "Qiaoming Zhu"], "title": "Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ACL2025(main conference)", "summary": "Dialogue discourse parsing aims to identify and analyze discourse relations\nbetween the utterances within dialogues. However, linguistic features in\ndialogues, such as omission and idiom, frequently introduce ambiguities that\nobscure the intended discourse relations, posing significant challenges for\nparsers. To address this issue, we propose a Discourse-aware Clarification\nModule (DCM) to enhance the performance of the dialogue discourse parser. DCM\nemploys two distinct reasoning processes: clarification type reasoning and\ndiscourse goal reasoning. The former analyzes linguistic features, while the\nlatter distinguishes the intended relation from the ambiguous one. Furthermore,\nwe introduce Contribution-aware Preference Optimization (CPO) to mitigate the\nrisk of erroneous clarifications, thereby reducing cascading errors. CPO\nenables the parser to assess the contributions of the clarifications from DCM\nand provide feedback to optimize the DCM, enhancing its adaptability and\nalignment with the parser's requirements. Extensive experiments on the STAC and\nMolweni datasets demonstrate that our approach effectively resolves ambiguities\nand significantly outperforms the state-of-the-art (SOTA) baselines.", "AI": {"tldr": "Proposes a Discourse-aware Clarification Module (DCM) and Contribution-aware Preference Optimization (CPO) to improve dialogue discourse parsing by addressing ambiguities.", "motivation": "To address ambiguities in dialogue discourse parsing caused by linguistic features like omission and idiom.", "method": "Introduces DCM with two reasoning processes and CPO to reduce errors and optimize the module.", "result": "Experiments show the approach effectively resolves ambiguities and outperforms existing baselines on STAC and Molweni datasets.", "conclusion": "The proposed method improves dialogue discourse parsing performance by effectively handling ambiguities and optimizing the parsing process."}}
{"id": "2506.15118", "pdf": "https://arxiv.org/pdf/2506.15118", "abs": "https://arxiv.org/abs/2506.15118", "authors": ["Junke Wang", "Hongshun Ling", "Li Zhang", "Longqian Zhang", "Fang Wang", "Yuan Gao", "Zhi Li"], "title": "CKD-EHR:Clinical Knowledge Distillation for Electronic Health Records", "categories": ["cs.CL"], "comment": "20 pages,5 figures", "summary": "Electronic Health Records (EHR)-based disease prediction models have\ndemonstrated significant clinical value in promoting precision medicine and\nenabling early intervention. However, existing large language models face two\nmajor challenges: insufficient representation of medical knowledge and low\nefficiency in clinical deployment. To address these challenges, this study\nproposes the CKD-EHR (Clinical Knowledge Distillation for EHR) framework, which\nachieves efficient and accurate disease risk prediction through knowledge\ndistillation techniques. Specifically, the large language model Qwen2.5-7B is\nfirst fine-tuned on medical knowledge-enhanced data to serve as the teacher\nmodel.It then generates interpretable soft labels through a multi-granularity\nattention distillation mechanism. Finally, the distilled knowledge is\ntransferred to a lightweight BERT student model. Experimental results show that\non the MIMIC-III dataset, CKD-EHR significantly outperforms the baseline\nmodel:diagnostic accuracy is increased by 9%, F1-score is improved by 27%, and\na 22.2 times inference speedup is achieved. This innovative solution not only\ngreatly improves resource utilization efficiency but also significantly\nenhances the accuracy and timeliness of diagnosis, providing a practical\ntechnical approach for resource optimization in clinical settings. The code and\ndata for this research are available athttps://github.com/209506702/CKD_EHR.", "AI": {"tldr": "Proposes a framework called CKD-EHR that uses knowledge distillation to improve disease prediction in electronic health records. The method enhances both accuracy and speed of predictions compared to existing models.", "motivation": "The motivation is to overcome the challenges of insufficient medical knowledge representation and low efficiency in clinical deployment faced by existing large language models in disease prediction.", "method": "Fine-tune a large language model on medical knowledge-enhanced data to create a teacher model, generate soft labels with a multi-granularity attention distillation mechanism, and transfer knowledge to a lightweight BERT student model.", "result": "On the MIMIC-III dataset, CKD-EHR improves diagnostic accuracy by 9%, F1-score by 27%, and achieves a 22.2 times inference speedup over the baseline model.", "conclusion": "This study demonstrates that the CKD-EHR framework can greatly enhance resource utilization efficiency and diagnostic accuracy/timeliness in clinical settings."}}
{"id": "2506.15131", "pdf": "https://arxiv.org/pdf/2506.15131", "abs": "https://arxiv.org/abs/2506.15131", "authors": ["Jing Yang Lee", "Kong-Aik Lee", "Woon-Seng Gan"], "title": "Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Open-domain Dialogue (OD) exhibits a one-to-many (o2m) property, whereby\nmultiple appropriate responses exist for a single dialogue context. Despite\nprior research showing that modeling this property boosts response diversity,\nmost modern LLM-based dialogue agents do not explicitly do so. In this work, we\nmodel the o2m property of OD in LLMs by decomposing OD generation into two key\ntasks: Multi-Response Generation (MRG) and Preference-based Selection (PS),\nwhich entail generating a set of n semantically and lexically diverse\nhigh-quality responses for a given dialogue context, followed by selecting a\nsingle response based on human preference, respectively. To facilitate MRG and\nPS, we introduce o2mDial, a dialogue corpus explicitly designed to capture the\no2m property by featuring multiple plausible responses for each context.\nLeveraging o2mDial, we propose new in-context learning and instruction-tuning\nstrategies, as well as novel evaluation metrics for MRG, alongside a\nmodel-based approach for PS. Empirical results demonstrate that applying the\nproposed two-stage framework to smaller LLMs for OD generation enhances overall\nresponse diversity while maintaining contextual coherence, improving response\nquality by up to 90%, bringing them closer to the performance of larger models.", "AI": {"tldr": "This paper introduces a two-stage framework for open-domain dialogue generation in LLMs, enhancing response diversity while maintaining quality.", "motivation": "To model the one-to-many property of open-domain dialogues and improve response diversity in LLM-based dialogue agents.", "method": "Decomposing OD generation into Multi-Response Generation and Preference-based Selection tasks, introducing o2mDial corpus, and proposing new in-context learning, instruction-tuning strategies, and evaluation metrics.", "result": "The proposed framework improves response diversity and quality by up to 90% while maintaining contextual coherence.", "conclusion": "The two-stage framework can enhance smaller LLMs' performance in open-domain dialogue generation, making their responses more similar to those of larger models."}}
{"id": "2506.15138", "pdf": "https://arxiv.org/pdf/2506.15138", "abs": "https://arxiv.org/abs/2506.15138", "authors": ["Gyeongje Cho", "Yeonkyoun So", "Chanwoo Park", "Sangmin Lee", "Sungmok Jung", "Jaejin Lee"], "title": "Thunder-Tok: Minimizing Tokens per Word in Tokenizing Korean Texts for Generative Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This paper introduces Thunder-Tok, a new Korean tokenizer designed to reduce\ntoken fertility without compromising model performance. Our approach uses a\nrule-based pre-tokenization method that aligns with the linguistic structure of\nthe Korean language. We also create a seed vocabulary containing tokens that\nresemble linguistic units and employ a branching entropy-based selection\nalgorithm. These techniques increase the average token length, thus lowering\nfertility while preserving linguistic information. Experimental results\nindicate that Thunder-Tok reduces fertility by approximately 10% (i.e., reduces\nthe number of tokens by 10%, improving the inference speed by 10%) compared to\nBPE without compromising performance across various downstream tasks. These\nfindings demonstrate that our linguistically informed approach is effective and\npractical for designing efficient tokenizers for language models.", "AI": {"tldr": "Thunder-Tok is a new Korean tokenizer that improves inference speed by reducing token fertility without affecting model performance.", "motivation": "To develop a more efficient tokenizer for Korean language models by reducing token fertility.", "method": "A rule-based pre-tokenization method aligned with Korean linguistic structure, a seed vocabulary resembling linguistic units, and a branching entropy-based selection algorithm were used.", "result": "Thunder-Tok reduces fertility by 10%, decreases the number of tokens by 10%, and increases inference speed by 10% compared to BPE without impacting performance on various downstream tasks.", "conclusion": "The linguistically informed approach of Thunder-Tok is effective and practical for creating efficient tokenizers for language models."}}
{"id": "2506.15156", "pdf": "https://arxiv.org/pdf/2506.15156", "abs": "https://arxiv.org/abs/2506.15156", "authors": ["Muhammad Cendekia Airlangga", "Hilal AlQuabeh", "Munachiso S Nwadike", "Kentaro Inui"], "title": "Emergence of Primacy and Recency Effect in Mamba: A Mechanistic Point of View", "categories": ["cs.CL"], "comment": null, "summary": "We study memory in state-space language models using primacy and recency\neffects as behavioral tools to uncover how information is retained and\nforgotten over time. Applying structured recall tasks to the Mamba\narchitecture, we observe a consistent U-shaped accuracy profile, indicating\nstrong performance at the beginning and end of input sequences. We identify\nthree mechanisms that give rise to this pattern. First, long-term memory is\nsupported by a sparse subset of channels within the model's selective state\nspace block, which persistently encode early input tokens and are causally\nlinked to primacy effects. Second, short-term memory is governed by\ndelta-modulated recurrence: recent inputs receive more weight due to\nexponential decay, but this recency advantage collapses when distractor items\nare introduced, revealing a clear limit to memory depth. Third, we find that\nmemory allocation is dynamically modulated by semantic regularity: repeated\nrelations in the input sequence shift the delta gating behavior, increasing the\ntendency to forget intermediate items. We validate these findings via targeted\nablations and input perturbations on two large-scale Mamba-based language\nmodels: one with 1.4B and another with 7B parameters.", "AI": {"tldr": "This paper studies memory mechanisms in state-space language models using primacy and recency effects. It identifies three mechanisms contributing to a U-shaped accuracy profile: long-term memory in selective state space block, short-term memory affected by exponential decay, and dynamic modulation of memory allocation by semantic regularity.", "motivation": "To understand how information is retained and forgotten over time in state-space language models using behavioral tools like primacy and recency effects.", "method": "Applying structured recall tasks to the Mamba architecture and observing the accuracy profile. Identifying mechanisms through analysis and validating findings via targeted ablations and input perturbations.", "result": "A consistent U-shaped accuracy profile was observed, indicating strong performance at the beginning and end of input sequences. Three mechanisms were identified: long-term memory in selective state space block, short-term memory influenced by exponential decay, and dynamic modulation of memory allocation by semantic regularity.", "conclusion": "The study reveals insights into memory mechanisms in state-space language models, providing a better understanding of how these models retain and forget information over time."}}
{"id": "2506.15208", "pdf": "https://arxiv.org/pdf/2506.15208", "abs": "https://arxiv.org/abs/2506.15208", "authors": ["Andrea Cadeddu", "Alessandro Chessa", "Vincenzo De Leo", "Gianni Fenu", "Enrico Motta", "Francesco Osborne", "Diego Reforgiato Recupero", "Angelo Salatino", "Luca Secchi"], "title": "A Comparative Study of Task Adaptation Techniques of Large Language Models for Identifying Sustainable Development Goals", "categories": ["cs.CL", "cs.AI"], "comment": "Submitted to IEEE Access", "summary": "In 2012, the United Nations introduced 17 Sustainable Development Goals\n(SDGs) aimed at creating a more sustainable and improved future by 2030.\nHowever, tracking progress toward these goals is difficult because of the\nextensive scale and complexity of the data involved. Text classification models\nhave become vital tools in this area, automating the analysis of vast amounts\nof text from a variety of sources. Additionally, large language models (LLMs)\nhave recently proven indispensable for many natural language processing tasks,\nincluding text classification, thanks to their ability to recognize complex\nlinguistic patterns and semantics. This study analyzes various proprietary and\nopen-source LLMs for a single-label, multi-class text classification task\nfocused on the SDGs. Then, it also evaluates the effectiveness of task\nadaptation techniques (i.e., in-context learning approaches), namely Zero-Shot\nand Few-Shot Learning, as well as Fine-Tuning within this domain. The results\nreveal that smaller models, when optimized through prompt engineering, can\nperform on par with larger models like OpenAI's GPT (Generative Pre-trained\nTransformer).", "AI": {"tldr": "This study examines different LLMs for classifying text related to the UN's Sustainable Development Goals, finding that optimized smaller models can perform as well as larger ones.", "motivation": "Tracking progress towards the UN's 17 Sustainable Development Goals is challenging due to the vast and complex data involved. Text classification models, especially LLMs, are crucial for analyzing such data.", "method": "The study analyzes proprietary and open-source LLMs for a single-label, multi-class text classification task focused on the SDGs. It evaluates Zero-Shot, Few-Shot Learning, and Fine-Tuning methods.", "result": "Smaller models, when optimized through prompt engineering, can perform equally well as larger models like OpenAI's GPT.", "conclusion": "Optimized smaller models are effective for text classification tasks related to the SDGs."}}
{"id": "2506.15211", "pdf": "https://arxiv.org/pdf/2506.15211", "abs": "https://arxiv.org/abs/2506.15211", "authors": ["Feng He", "Zijun Chen", "Xinnian Liang", "Tingting Ma", "Yunqi Qiu", "Shuangzhi Wu", "Junchi Yan"], "title": "ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in Large Reasoning Models (LRMs) trained with Long\nChain-of-Thought (Long CoT) reasoning have demonstrated remarkable cross-domain\ngeneralization capabilities. However, the underlying mechanisms supporting such\ntransfer remain poorly understood. We hypothesize that cross-domain\ngeneralization arises from shared abstract reasoning prototypes -- fundamental\nreasoning patterns that capture the essence of problems across domains. These\nprototypes minimize the nuances of the representation, revealing that seemingly\ndiverse tasks are grounded in shared reasoning structures.Based on this\nhypothesis, we propose ProtoReasoning, a framework that enhances the reasoning\nability of LLMs by leveraging scalable and verifiable prototypical\nrepresentations (Prolog for logical reasoning, PDDL for\nplanning).ProtoReasoning features: (1) an automated prototype construction\npipeline that transforms problems into corresponding prototype representations;\n(2) a comprehensive verification system providing reliable feedback through\nProlog/PDDL interpreters; (3) the scalability to synthesize problems\narbitrarily within prototype space while ensuring correctness. Extensive\nexperiments show that ProtoReasoning achieves 4.7% improvement over baseline\nmodels on logical reasoning (Enigmata-Eval), 6.3% improvement on planning\ntasks, 4.0% improvement on general reasoning (MMLU) and 1.0% on mathematics\n(AIME24). Significantly, our ablation studies confirm that learning in\nprototype space also demonstrates enhanced generalization to structurally\nsimilar problems compared to training solely on natural language\nrepresentations, validating our hypothesis that reasoning prototypes serve as\nthe foundation for generalizable reasoning in large language models.", "AI": {"tldr": "Recent progress in Large Reasoning Models (LRMs) shows their impressive ability to generalize across domains. However, how they do so is unclear. This paper suggests that these models can generalize because they share abstract reasoning patterns. It introduces ProtoReasoning, a method that improves reasoning in LLMs using scalable and verifiable prototypical representations. Experiments show improvements on different tasks.", "motivation": "Understanding the mechanism behind the cross-domain generalization capability of LRMs.", "method": "Proposing ProtoReasoning, which uses prototypical representations (Prolog for logical reasoning, PDDL for planning) to enhance reasoning abilities.", "result": "ProtoReasoning improved performance on various tasks like logical reasoning, planning, general reasoning, and mathematics. Ablation studies confirmed better generalization in prototype space than in natural language representations.", "conclusion": "The paper concludes that reasoning prototypes are foundational for generalizable reasoning in large language models."}}
{"id": "2506.15215", "pdf": "https://arxiv.org/pdf/2506.15215", "abs": "https://arxiv.org/abs/2506.15215", "authors": ["Yongqi Fan", "Yating Wang", "Guandong Wang", "Jie Zhai", "Jingping Liu", "Qi Ye", "Tong Ruan"], "title": "MinosEval: Distinguishing Factoid and Non-Factoid for Tailored Open-Ended QA Evaluation with LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Open-ended question answering (QA) is a key task for evaluating the\ncapabilities of large language models (LLMs). Compared to closed-ended QA, it\ndemands longer answer statements, more nuanced reasoning processes, and diverse\nexpressions, making refined and interpretable automatic evaluation both crucial\nand challenging. Traditional metrics like ROUGE and BERTScore struggle to\ncapture semantic similarities due to different patterns between model responses\nand reference answers. Current LLM-based evaluation approaches, such as\npairwise or listwise comparisons of candidate answers, lack intuitive\ninterpretability. While pointwise scoring of each response provides some\ndescriptions, it fails to adapt across different question contents. Most\nnotably, existing methods overlook the distinction between factoid and\nnon-factoid questions. To address these challenges, we propose\n\\textbf{MinosEval}, a novel evaluation method that first distinguishes\nopen-ended questions and then ranks candidate answers using different\nevaluation strategies. For factoid questions, it applies an adaptive key-point\nscoring strategy, while for non-factoid questions, it uses an instance-aware\nlistwise ranking strategy. Experiments on multiple open-ended QA datasets,\nincluding self-built ones with more candidate responses to complement community\nresources, show that MinosEval better aligns with human annotations and offers\nmore interpretable results.", "AI": {"tldr": "Proposes MinosEval, a novel evaluation method for open-ended QA that improves alignment with human annotations and interpretability.", "motivation": "Traditional metrics and current LLM-based evaluation approaches fail to meet the requirements of open-ended QA, lacking intuitive interpretability and failing to adapt across different question contents.", "method": "Distinguishes open-ended questions and ranks candidate answers using different evaluation strategies. For factoid questions, it applies an adaptive key-point scoring strategy, while for non-factoid questions, it uses an instance-aware listwise ranking strategy.", "result": "Experiments on multiple open-ended QA datasets show that MinosEval better aligns with human annotations and offers more interpretable results.", "conclusion": "MinosEval provides better alignment with human annotations and more interpretable results."}}
{"id": "2506.15239", "pdf": "https://arxiv.org/pdf/2506.15239", "abs": "https://arxiv.org/abs/2506.15239", "authors": ["Jaione Bengoetxea", "Itziar Gonzalez-Dios", "Rodrigo Agerri"], "title": "Lost in Variation? Evaluating NLI Performance in Basque and Spanish Geographical Variants", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we evaluate the capacity of current language technologies to\nunderstand Basque and Spanish language varieties. We use Natural Language\nInference (NLI) as a pivot task and introduce a novel, manually-curated\nparallel dataset in Basque and Spanish, along with their respective variants.\nOur empirical analysis of crosslingual and in-context learning experiments\nusing encoder-only and decoder-based Large Language Models (LLMs) shows a\nperformance drop when handling linguistic variation, especially in Basque.\nError analysis suggests that this decline is not due to lexical overlap, but\nrather to the linguistic variation itself. Further ablation experiments\nindicate that encoder-only models particularly struggle with Western Basque,\nwhich aligns with linguistic theory that identifies peripheral dialects (e.g.,\nWestern) as more distant from the standard. All data and code are publicly\navailable.", "AI": {"tldr": "This paper evaluates current language technologies' ability to understand Basque and Spanish language varieties using NLI tasks and newly created parallel datasets. It finds performance drops in handling linguistic variation, especially in Basque, which isn't due to lexical overlap but linguistic variation itself.", "motivation": "To assess the capacity of current language technologies to understand Basque and Spanish language varieties.", "method": "Using Natural Language Inference as a pivot task and introducing a novel, manually-curated parallel dataset in Basque and Spanish, along with their respective variants. Conducting empirical analysis of crosslingual and in-context learning experiments using encoder-only and decoder-based Large Language Models.", "result": "Performance drop when handling linguistic variation, especially in Basque. This decline is not due to lexical overlap, but rather to the linguistic variation itself. Encoder-only models particularly struggle with Western Basque.", "conclusion": "Current language technologies face challenges in understanding linguistic variation, especially in Basque. Encoder-only models have more difficulty with peripheral dialects."}}
{"id": "2506.15241", "pdf": "https://arxiv.org/pdf/2506.15241", "abs": "https://arxiv.org/abs/2506.15241", "authors": ["Yang Fan", "Zhang Qi", "Xing Wenqian", "Liu Chang", "Liu Liu"], "title": "Research on Graph-Retrieval Augmented Generation Based on Historical Text Knowledge Graphs", "categories": ["cs.CL"], "comment": null, "summary": "This article addresses domain knowledge gaps in general large language models\nfor historical text analysis in the context of computational humanities and\nAIGC technology. We propose the Graph RAG framework, combining chain-of-thought\nprompting, self-instruction generation, and process supervision to create a The\nFirst Four Histories character relationship dataset with minimal manual\nannotation. This dataset supports automated historical knowledge extraction,\nreducing labor costs. In the graph-augmented generation phase, we introduce a\ncollaborative mechanism between knowledge graphs and retrieval-augmented\ngeneration, improving the alignment of general models with historical\nknowledge. Experiments show that the domain-specific model Xunzi-Qwen1.5-14B,\nwith Simplified Chinese input and chain-of-thought prompting, achieves optimal\nperformance in relation extraction (F1 = 0.68). The DeepSeek model integrated\nwith GraphRAG improves F1 by 11% (0.08-0.19) on the open-domain C-CLUE relation\nextraction dataset, surpassing the F1 value of Xunzi-Qwen1.5-14B (0.12),\neffectively alleviating hallucinations phenomenon, and improving\ninterpretability. This framework offers a low-resource solution for classical\ntext knowledge extraction, advancing historical knowledge services and\nhumanities research.", "AI": {"tldr": "This paper proposes the Graph RAG framework to address domain knowledge gaps in general large language models for historical text analysis.", "motivation": "To create a The First Four Histories character relationship dataset with minimal manual annotation and support automated historical knowledge extraction, reducing labor costs.", "method": "Combining chain-of-thought prompting, self-instruction generation, and process supervision to create the dataset and introducing a collaborative mechanism between knowledge graphs and retrieval-augmented generation.", "result": "The domain-specific model Xunzi-Qwen1.5-14B achieves optimal performance in relation extraction (F1 = 0.68). The DeepSeek model integrated with GraphRAG improves F1 by 11% on the open-domain C-CLUE relation extraction dataset.", "conclusion": "This framework offers a low-resource solution for classical text knowledge extraction, advancing historical knowledge services and humanities research."}}
{"id": "2506.15246", "pdf": "https://arxiv.org/pdf/2506.15246", "abs": "https://arxiv.org/abs/2506.15246", "authors": ["Juli Bakagianni", "John Pavlopoulos", "Aristidis Likas"], "title": "TopClustRAG at SIGIR 2025 LiveRAG Challenge", "categories": ["cs.CL"], "comment": null, "summary": "We present TopClustRAG, a retrieval-augmented generation (RAG) system\ndeveloped for the LiveRAG Challenge, which evaluates end-to-end question\nanswering over large-scale web corpora. Our system employs a hybrid retrieval\nstrategy combining sparse and dense indices, followed by K-Means clustering to\ngroup semantically similar passages. Representative passages from each cluster\nare used to construct cluster-specific prompts for a large language model\n(LLM), generating intermediate answers that are filtered, reranked, and finally\nsynthesized into a single, comprehensive response. This multi-stage pipeline\nenhances answer diversity, relevance, and faithfulness to retrieved evidence.\nEvaluated on the FineWeb Sample-10BT dataset, TopClustRAG ranked 2nd in\nfaithfulness and 7th in correctness on the official leaderboard, demonstrating\nthe effectiveness of clustering-based context filtering and prompt aggregation\nin large-scale RAG systems.", "AI": {"tldr": "TopClustRAG is a retrieval-augmented generation system that uses hybrid retrieval and clustering to improve question answering over large web corpora.", "motivation": "To develop an effective retrieval-augmented generation system for answering questions over large-scale web corpora.", "method": "A hybrid retrieval strategy combining sparse and dense indices, followed by K-Means clustering to group semantically similar passages. Representative passages are used to construct cluster-specific prompts for a large language model, which generates intermediate answers that are filtered, reranked, and synthesized into a final response.", "result": "TopClustRAG ranked 2nd in faithfulness and 7th in correctness on the official leaderboard when evaluated on the FineWeb Sample-10BT dataset.", "conclusion": "The study demonstrates the effectiveness of clustering-based context filtering and prompt aggregation in large-scale RAG systems."}}
{"id": "2506.15266", "pdf": "https://arxiv.org/pdf/2506.15266", "abs": "https://arxiv.org/abs/2506.15266", "authors": ["Sungen Hahm", "Heejin Kim", "Gyuseong Lee", "Hyunji Park", "Jaejin Lee"], "title": "Thunder-DeID: Accurate and Efficient De-identification Framework for Korean Court Judgments", "categories": ["cs.CL"], "comment": null, "summary": "To ensure a balance between open access to justice and personal data\nprotection, the South Korean judiciary mandates the de-identification of court\njudgments before they can be publicly disclosed. However, the current\nde-identification process is inadequate for handling court judgments at scale\nwhile adhering to strict legal requirements. Additionally, the legal\ndefinitions and categorizations of personal identifiers are vague and not\nwell-suited for technical solutions. To tackle these challenges, we propose a\nde-identification framework called Thunder-DeID, which aligns with relevant\nlaws and practices. Specifically, we (i) construct and release the first Korean\nlegal dataset containing annotated judgments along with corresponding lists of\nentity mentions, (ii) introduce a systematic categorization of Personally\nIdentifiable Information (PII), and (iii) develop an end-to-end deep neural\nnetwork (DNN)-based de-identification pipeline. Our experimental results\ndemonstrate that our model achieves state-of-the-art performance in the\nde-identification of court judgments.", "AI": {"tldr": "Propose a de-identification framework called Thunder-DeID for Korean court judgments.", "motivation": "To ensure a balance between open access to justice and personal data protection while adhering to strict legal requirements.", "method": "Construct a Korean legal dataset, categorize PII systematically, and develop a DNN-based de-identification pipeline.", "result": "The proposed model achieves state-of-the-art performance in de-identifying court judgments.", "conclusion": "Thunder-DeID aligns with relevant laws and practices and improves the efficiency and effectiveness of de-identification of court judgments."}}
{"id": "2506.15301", "pdf": "https://arxiv.org/pdf/2506.15301", "abs": "https://arxiv.org/abs/2506.15301", "authors": ["Shrestha Ghosh", "Moritz Schneider", "Carina Reinicke", "Carsten Eickhoff"], "title": "Cohort Discovery: A Survey on LLM-Assisted Clinical Trial Recruitment", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in LLMs have greatly improved general-domain NLP tasks. Yet,\ntheir adoption in critical domains, such as clinical trial recruitment, remains\nlimited. As trials are designed in natural language and patient data is\nrepresented as both structured and unstructured text, the task of matching\ntrials and patients benefits from knowledge aggregation and reasoning abilities\nof LLMs. Classical approaches are trial-specific and LLMs with their ability to\nconsolidate distributed knowledge hold the potential to build a more general\nsolution. Yet recent applications of LLM-assisted methods rely on proprietary\nmodels and weak evaluation benchmarks. In this survey, we are the first to\nanalyze the task of trial-patient matching and contextualize emerging LLM-based\napproaches in clinical trial recruitment. We critically examine existing\nbenchmarks, approaches and evaluation frameworks, the challenges to adopting\nLLM technologies in clinical research and exciting future directions.", "AI": {"tldr": "Survey on the application of large language models in clinical trial recruitment.", "motivation": "Limited adoption of LLMs in critical domains like clinical trial recruitment despite improvements in general-domain NLP tasks.", "method": "Analysis of trial-patient matching task and contextualization of emerging LLM-based approaches in clinical trial recruitment.", "result": "Critical examination of existing benchmarks, approaches and evaluation frameworks, challenges to adopting LLM technologies in clinical research and future directions.", "conclusion": "LLMs have the potential to build a more general solution for trial-patient matching but there are challenges in adopting these technologies in clinical research."}}
{"id": "2506.15304", "pdf": "https://arxiv.org/pdf/2506.15304", "abs": "https://arxiv.org/abs/2506.15304", "authors": ["Negar Foroutan", "Jakhongir Saydaliev", "Ye Eun Kim", "Antoine Bosselut"], "title": "ConLID: Supervised Contrastive Learning for Low-Resource Language Identification", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Submitted to EMNLP", "summary": "Language identification (LID) is a critical step in curating multilingual LLM\npretraining corpora from web crawls. While many studies on LID model training\nfocus on collecting diverse training data to improve performance, low-resource\nlanguages -- often limited to single-domain data, such as the Bible -- continue\nto perform poorly. To resolve these class imbalance and bias issues, we propose\na novel supervised contrastive learning (SCL) approach to learn\ndomain-invariant representations for low-resource languages. Through an\nextensive analysis, we show that our approach improves LID performance on\nout-of-domain data for low-resource languages by 3.2%, demonstrating its\neffectiveness in enhancing LID models.", "AI": {"tldr": "This paper introduces a new method using supervised contrastive learning to improve language identification performance for low-resource languages on out-of-domain data.", "motivation": "To address class imbalance and bias issues in low-resource languages with limited single-domain data.", "method": "Proposes a novel supervised contrastive learning approach to learn domain-invariant representations.", "result": "Improves LID performance on out-of-domain data for low-resource languages by 3.2%.", "conclusion": "The proposed method effectively enhances LID models for low-resource languages."}}
{"id": "2506.15339", "pdf": "https://arxiv.org/pdf/2506.15339", "abs": "https://arxiv.org/abs/2506.15339", "authors": ["Camila Zurdo Tagliabue", "Heloisa Oss Boll", "Aykut Erdem", "Erkut Erdem", "Iacer Calixto"], "title": "DeVisE: Behavioral Testing of Medical Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly used in clinical decision\nsupport, yet current evaluation methods often fail to distinguish genuine\nmedical reasoning from superficial patterns. We introduce DeVisE (Demographics\nand Vital signs Evaluation), a behavioral testing framework for probing\nfine-grained clinical understanding. We construct a dataset of ICU discharge\nnotes from MIMIC-IV, generating both raw (real-world) and template-based\n(synthetic) versions with controlled single-variable counterfactuals targeting\ndemographic (age, gender, ethnicity) and vital sign attributes. We evaluate\nfive LLMs spanning general-purpose and medically fine-tuned variants, under\nboth zero-shot and fine-tuned settings. We assess model behavior via (1)\ninput-level sensitivity - how counterfactuals alter the likelihood of a note;\nand (2) downstream reasoning - how they affect predicted hospital\nlength-of-stay. Our results show that zero-shot models exhibit more coherent\ncounterfactual reasoning patterns, while fine-tuned models tend to be more\nstable yet less responsive to clinically meaningful changes. Notably,\ndemographic factors subtly but consistently influence outputs, emphasizing the\nimportance of fairness-aware evaluation. This work highlights the utility of\nbehavioral testing in exposing the reasoning strategies of clinical LLMs and\ninforming the design of safer, more transparent medical AI systems.", "AI": {"tldr": "Introducing DeVisE to evaluate clinical LLMs' reasoning through demographic and vital sign counterfactuals.", "motivation": "To develop a method for distinguishing genuine medical reasoning from superficial patterns in LLMs.", "method": "Constructing a dataset of ICU discharge notes from MIMIC-IV, creating both real-world and synthetic versions with controlled counterfactuals, and evaluating five LLMs in zero-shot and fine-tuned settings.", "result": "Zero-shot models have coherent counterfactual reasoning patterns, while fine-tuned models are stable but less responsive to clinically significant changes.", "conclusion": "DeVisE reveals subtle but consistent demographic influences on LLM outputs, highlighting the need for fairness-aware evaluation."}}
{"id": "2506.15355", "pdf": "https://arxiv.org/pdf/2506.15355", "abs": "https://arxiv.org/abs/2506.15355", "authors": ["Arijit Maji", "Raghvendra Kumar", "Akash Ghosh", "Anushka", "Sriparna Saha"], "title": "SANSKRITI: A Comprehensive Benchmark for Evaluating Language Models' Knowledge of Indian Culture", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Language Models (LMs) are indispensable tools shaping modern workflows, but\ntheir global effectiveness depends on understanding local socio-cultural\ncontexts. To address this, we introduce SANSKRITI, a benchmark designed to\nevaluate language models' comprehension of India's rich cultural diversity.\nComprising 21,853 meticulously curated question-answer pairs spanning 28 states\nand 8 union territories, SANSKRITI is the largest dataset for testing Indian\ncultural knowledge. It covers sixteen key attributes of Indian culture: rituals\nand ceremonies, history, tourism, cuisine, dance and music, costume, language,\nart, festivals, religion, medicine, transport, sports, nightlife, and\npersonalities, providing a comprehensive representation of India's cultural\ntapestry. We evaluate SANSKRITI on leading Large Language Models (LLMs), Indic\nLanguage Models (ILMs), and Small Language Models (SLMs), revealing significant\ndisparities in their ability to handle culturally nuanced queries, with many\nmodels struggling in region-specific contexts. By offering an extensive,\nculturally rich, and diverse dataset, SANSKRITI sets a new standard for\nassessing and improving the cultural understanding of LMs.", "AI": {"tldr": "SANSKRITI\u662f\u4e00\u4e2a\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5bf9\u5370\u5ea6\u4e30\u5bcc\u6587\u5316\u591a\u6837\u6027\u7406\u89e3\u7684\u57fa\u51c6\u3002\u5b83\u5305\u542b\u6765\u81ea\u5370\u5ea6\u5404\u5730\u768421,853\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684\u95ee\u9898-\u7b54\u6848\u5bf9\uff0c\u6db5\u76d6\u4e8616\u4e2a\u5173\u952e\u7684\u6587\u5316\u5c5e\u6027\u3002\u8be5\u6570\u636e\u96c6\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u6587\u5316\u7ec6\u5fae\u5dee\u522b\u67e5\u8be2\u65f6\u7684\u80fd\u529b\u5dee\u5f02\u3002", "motivation": "\u4e3a\u4e86\u4f7f\u8bed\u8a00\u6a21\u578b\u66f4\u597d\u5730\u7406\u89e3\u548c\u9002\u5e94\u5f53\u5730\u793e\u4f1a\u6587\u5316\u80cc\u666f\uff0c\u7279\u522b\u662f\u5370\u5ea6\u7684\u6587\u5316\u591a\u6837\u6027\u3002", "method": "\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aSANSKRITI\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b21,853\u4e2a\u95ee\u9898-\u7b54\u6848\u5bf9\uff0c\u8986\u76d6\u4e86\u5370\u5ea6\u768428\u4e2a\u90a6\u548c8\u4e2a\u8054\u90a6\u76f4\u8f96\u533a\u3002", "result": "SANSKRITI\u662f\u6d4b\u8bd5\u5370\u5ea6\u6587\u5316\u77e5\u8bc6\u7684\u6700\u5927\u6570\u636e\u96c6\u3002\u5b83\u663e\u793a\u4e86\u8bb8\u591a\u6a21\u578b\u5728\u7279\u5b9a\u5730\u533a\u4e0a\u4e0b\u6587\u4e2d\u7684\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "SANSKRITI\u4e3a\u8bc4\u4f30\u548c\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u7684\u6587\u5316\u7406\u89e3\u8bbe\u5b9a\u4e86\u65b0\u7684\u6807\u51c6\u3002"}}
{"id": "2506.15372", "pdf": "https://arxiv.org/pdf/2506.15372", "abs": "https://arxiv.org/abs/2506.15372", "authors": ["Raghvendra Kumar", "S. A. Mohammed Salman", "Aryan Sahu", "Tridib Nandi", "Pragathi Y. P.", "Sriparna Saha", "Jose G. Moreno"], "title": "COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation", "categories": ["cs.CL"], "comment": "ACL 2025 MAINs", "summary": "Despite progress in comment-aware multimodal and multilingual summarization\nfor English and Chinese, research in Indian languages remains limited. This\nstudy addresses this gap by introducing COSMMIC, a pioneering comment-sensitive\nmultimodal, multilingual dataset featuring nine major Indian languages. COSMMIC\ncomprises 4,959 article-image pairs and 24,484 reader comments, with\nground-truth summaries available in all included languages. Our approach\nenhances summaries by integrating reader insights and feedback. We explore\nsummarization and headline generation across four configurations: (1) using\narticle text alone, (2) incorporating user comments, (3) utilizing images, and\n(4) combining text, comments, and images. To assess the dataset's\neffectiveness, we employ state-of-the-art language models such as LLama3 and\nGPT-4. We conduct a comprehensive study to evaluate different component\ncombinations, including identifying supportive comments, filtering out noise\nusing a dedicated comment classifier using IndicBERT, and extracting valuable\ninsights from images with a multilingual CLIP-based classifier. This helps\ndetermine the most effective configurations for natural language generation\n(NLG) tasks. Unlike many existing datasets that are either text-only or lack\nuser comments in multimodal settings, COSMMIC uniquely integrates text, images,\nand user feedback. This holistic approach bridges gaps in Indian language\nresources, advancing NLP research and fostering inclusivity.", "AI": {"tldr": "This study introduces COSMMIC, a novel dataset for comment-aware multimodal and multilingual summarization in nine major Indian languages, enhancing summaries by integrating text, images, and user feedback.", "motivation": "Addressing the gap in research for Indian languages in comment-aware multimodal and multilingual summarization.", "method": "Integrating reader insights and feedback across four configurations: article text alone, incorporating user comments, utilizing images, and combining text, comments, and images.", "result": "COSMMIC comprises 4,959 article-image pairs and 24,484 reader comments with ground-truth summaries in all included languages. It uses advanced language models and classifiers to filter noise and extract insights.", "conclusion": "COSMMIC advances NLP research and fosters inclusivity by bridging gaps in Indian language resources through its unique integration of text, images, and user feedback."}}
{"id": "2506.15415", "pdf": "https://arxiv.org/pdf/2506.15415", "abs": "https://arxiv.org/abs/2506.15415", "authors": ["Stanley Ngugi"], "title": "Targeted Lexical Injection: Unlocking Latent Cross-Lingual Alignment in Lugha-Llama via Early-Layer LoRA Fine-Tuning", "categories": ["cs.CL", "68T50", "I.2.7; I.2.6"], "comment": "11 pages, 3 figures, 2 tables. Research on parameter-efficient\n  fine-tuning (PEFT) for low-resource languages (Swahili). Investigates\n  cross-lingual lexical alignment in Lugha-Llama using LoRA and contrastive\n  learning", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities, yet\ntheir performance in low-resource languages (LRLs), such as Swahili, often lags\ndue to data scarcity and underrepresentation in pre-training. A key challenge\nis achieving robust cross-lingual lexical alignment, crucial for tasks like\ntranslation and cross-lingual information retrieval. This paper introduces\nTargeted Lexical Injection (TLI), a novel and efficient fine-tuning approach.\nWe first demonstrate that Lugha-Llama-8B-wura, a Swahili-centric LLM, exhibits\nstrong, near-perfect lexical alignment for Swahili-English word pairs in its\nearly internal layers (specifically Layer 2, with ~0.99998 average cosine\nsimilarity based on a pilot study), a capability not fully reflected in its\nfinal output representations (baseline ~0.32 similarity on our evaluation set).\nTLI leverages this insight by using Low-Rank Adaptation (LoRA) and a\ncontrastive learning objective to fine-tune the model, specifically targeting\nembeddings from this empirically identified optimal early layer. Our\nexperiments show that TLI significantly improves the output-level lexical\nalignment for 623 trained Swahili-English word pairs, increasing average cosine\nsimilarity from 0.3211 to 0.4113 (+28.08%, p < 1.33 x 10^-240). More\nimportantly, these improvements generalize remarkably well to 63 unseen control\nword pairs, with similarity increasing from 0.3143 to 0.4033 (+28.32%, p < 7.17\nx 10^-27). These findings suggest TLI enhances the model's ability to preserve\nand propagate its inherent early-layer cross-lingual knowledge, offering a\nparameter-efficient and effective strategy for improving lexical alignment in\nLRL-focused LLMs.", "AI": {"tldr": "This paper introduces Targeted Lexical Injection (TLI), a novel and efficient fine-tuning approach for large language models to improve their performance in low-resource languages.", "motivation": "To address the issue of poor performance of large language models in low-resource languages due to data scarcity and underrepresentation.", "method": "Using Low-Rank Adaptation (LoRA) and a contrastive learning objective to fine-tune the model targeting embeddings from an early layer.", "result": "Output-level lexical alignment for Swahili-English word pairs improved significantly.", "conclusion": "TLI significantly improves the lexical alignment for both trained and unseen Swahili-English word pairs."}}
