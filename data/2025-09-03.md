<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 137]
- [cs.LG](#cs.LG) [Total: 9]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.SD](#cs.SD) [Total: 4]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.CV](#cs.CV) [Total: 4]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.MM](#cs.MM) [Total: 2]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.AI](#cs.AI) [Total: 21]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MultiStream-LLM: Bridging Modalities for Robust Sign Language Translation](https://arxiv.org/abs/2509.00030)
*Marshall Thomas,Edward Fish,Richard Bowden*

Main category: cs.CL

TL;DR: 本文提出了一种名为MultiStream-LLM的模块化框架，用于改进手语翻译。该方法通过分离和解决不同的识别任务，提高了翻译的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管在无手势的手语翻译（SLT）方面取得了进展，但单一的端到端模型在自然签名的两个关键组件上持续失败：精确识别高速手指拼写和整合来自面部的异步非手动提示。最近在大型语言模型上的自动手语翻译进展绕过了这个挑战，迫使单个网络同时学习这些，导致在翻译重要信息（如名称、地点和技术术语）时表现不佳。

Method: 我们提出了MultiStream-LLM，这是一个模块化框架，旨在克服这些限制。我们的方法使用单独的、专门的预测器来处理连续签名、手指拼写和唇读。每个专家网络首先将其特定模态解码为一系列标记。这些并行流然后由一个轻量级的变压器融合，解决时间错位，然后将组合表示传递给大型语言模型（LLM）进行最终句子生成。

Result: 我们的方法在How2Sign基准上建立了新的最先进水平，并在挑战性的ChicagoFSWildPlus手指拼写数据集上实现了73.2%的字母准确率。这些结果验证了我们的核心假设：通过在融合之前隔离和解决不同的识别任务，我们的多专家方法提供了一条更强大和有效的途径，以实现稳健、高保真的手语翻译。

Conclusion: 我们的方法在How2Sign基准上建立了新的最先进水平，并在挑战性的ChicagoFSWildPlus手指拼写数据集上实现了73.2%的字母准确率。这些结果验证了我们的核心假设：通过在融合之前隔离和解决不同的识别任务，我们的多专家方法提供了一条更强大和有效的途径，以实现稳健、高保真的手语翻译。

Abstract: Despite progress in gloss-free Sign Language Translation (SLT), monolithic
end-to-end models consistently fail on two critical components of natural
signing: the precise recognition of high-speed fingerspelling and the
integration of asynchronous non-manual cues from the face. Recent progress in
Automated Sign Language Translation with Large Language Models has side stepped
this challenge, forcing a single network to learn these simultaneously
resulting in poor performance when tasked with translating crucial information
such as names,places, and technical terms. We introduce MultiStream-LLM, a
modular framework designed to overcome these limitations. Our approach employs
separate, specialized predictors for continuous signing, fingerspelling, and
lipreading. Each expert network first decodes its specific modality into a
sequence of tokens. These parallel streams are then fused by a lightweight
transformer that resolves temporal misalignments before passing the combined
representation to a Large Language Model (LLM) for final sentence generation.
Our method establishes a new state-of-the-art on the How2Sign benchmark with a
BLEU-4 score of 23.5 and achieves 73.2% letter accuracy on the challenging
ChicagoFSWildPlus fingerspelling dataset. These results validate our core
hypothesis: by isolating and solving distinct recogni tion tasks before fusion,
our multi-expert approach provides a more powerful and effective pathway to
robust, high-fidelity sign language translation.

</details>


### [2] [Compiling Prompts, Not Crafting Them: A Reproducible Workflow for AI-Assisted Evidence Synthesis](https://arxiv.org/abs/2509.00038)
*Teo Susnjak*

Main category: cs.CL

TL;DR: 本文提出了一种结构化的框架，用于提高LLM在系统文献综述中的可靠性和可重复性。


<details>
  <summary>Details</summary>
Motivation: 当前的方法依赖于脆弱的手动编写提示，这影响了LLM辅助证据综合的可靠性与可重复性，因此需要一种更稳健的方法来提高科学信心。

Method: 本文采用了最近在声明式提示优化方面的进展，并将其应用于SLR自动化领域，提出了一个结构化的框架，包括任务声明、测试套件和自动化提示调优。

Result: 本文展示了声明式提示优化方法在SLR自动化中的适用性，并提供了一个具体的蓝图和代码示例，使研究人员能够构建符合透明性和严谨性原则的可验证LLM管道。

Conclusion: 本文提出了一个结构化的、领域特定的框架，将任务声明、测试套件和自动提示调优嵌入到可重复的SLR工作流中，从而提高了LLM在系统文献综述中的可靠性和可重复性。

Abstract: Large language models (LLMs) offer significant potential to accelerate
systematic literature reviews (SLRs), yet current approaches often rely on
brittle, manually crafted prompts that compromise reliability and
reproducibility. This fragility undermines scientific confidence in
LLM-assisted evidence synthesis. In response, this work adapts recent advances
in declarative prompt optimisation, developed for general-purpose LLM
applications, and demonstrates their applicability to the domain of SLR
automation. This research proposes a structured, domain-specific framework that
embeds task declarations, test suites, and automated prompt tuning into a
reproducible SLR workflow. These emerging methods are translated into a
concrete blueprint with working code examples, enabling researchers to
construct verifiable LLM pipelines that align with established principles of
transparency and rigour in evidence synthesis. This is a novel application of
such approaches to SLR pipelines.

</details>


### [3] [What Are Research Hypotheses?](https://arxiv.org/abs/2509.00185)
*Jian Wu,Sarah Rajtmajer*

Main category: cs.CL

TL;DR: 本文探讨了NLU任务中假设定义的多样性，并强调了清晰定义假设的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于不同自然语言理解（NLU）任务中对“假设”一词的解释已经从传统科学定义中迁移出来，因此需要明确其定义。

Method: 本文概述并界定了各种假设的定义，特别是最近发表的NLU任务中的定义差异。

Result: 本文分析了NLU领域中假设定义的多样性，并指出其重要性。

Conclusion: 本文强调了结构化和明确定义的假设的重要性，特别是在向机器可读的学术记录发展时。

Abstract: Over the past decades, alongside advancements in natural language processing,
significant attention has been paid to training models to automatically
extract, understand, test, and generate hypotheses in open and scientific
domains. However, interpretations of the term \emph{hypothesis} for various
natural language understanding (NLU) tasks have migrated from traditional
definitions in the natural, social, and formal sciences. Even within NLU, we
observe differences defining hypotheses across literature. In this paper, we
overview and delineate various definitions of hypothesis. Especially, we
discern the nuances of definitions across recently published NLU tasks. We
highlight the importance of well-structured and well-defined hypotheses,
particularly as we move toward a machine-interpretable scholarly record.

</details>


### [4] [Explainable Chain-of-Thought Reasoning: An Empirical Analysis on State-Aware Reasoning Dynamics](https://arxiv.org/abs/2509.00190)
*Sheldon Yu,Yuxin Xiong,Junda Wu,Xintong Li,Tong Yu,Xiang Chen,Ritwik Sinha,Jingbo Shang,Julian McAuley*

Main category: cs.CL

TL;DR: 本文提出了一种新的框架，用于抽象和解释链式思维推理过程，通过谱分析和马尔可夫链建模，提升了推理的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的研究主要集中在局部token级别的归因上，而对推理步骤的高层次语义角色及其转换的研究较少。因此，本文旨在探索一种更全面的推理解释方法。

Method: 本文提出的方法包括使用谱分析对token级别的嵌入进行分析，并将每个推理步骤聚类到语义一致的潜在状态中。同时，将推理步骤的进展建模为马尔可夫链，以表征推理的全局结构。

Result: 本文提出的框架能够支持多种分析，包括语义角色识别、时间模式可视化和一致性评估，从而提高了对推理过程的理解和解释能力。

Conclusion: 本文提出了一种状态感知的转换框架，能够将链式思维轨迹抽象为结构化的潜在动态。该框架通过谱分析和聚类方法捕捉推理步骤的语义演变，并将其建模为马尔可夫链，从而提供一种结构化且可解释的推理过程视图。

Abstract: Recent advances in chain-of-thought (CoT) prompting have enabled large
language models (LLMs) to perform multi-step reasoning. However, the
explainability of such reasoning remains limited, with prior work primarily
focusing on local token-level attribution, such that the high-level semantic
roles of reasoning steps and their transitions remain underexplored. In this
paper, we introduce a state-aware transition framework that abstracts CoT
trajectories into structured latent dynamics. Specifically, to capture the
evolving semantics of CoT reasoning, each reasoning step is represented via
spectral analysis of token-level embeddings and clustered into semantically
coherent latent states. To characterize the global structure of reasoning, we
model their progression as a Markov chain, yielding a structured and
interpretable view of the reasoning process. This abstraction supports a range
of analyses, including semantic role identification, temporal pattern
visualization, and consistency evaluation.

</details>


### [5] [The Rarity Blind Spot: A Framework for Evaluating Statistical Reasoning in LLMs](https://arxiv.org/abs/2509.00245)
*Seiji Maekawa,Hayate Iso,Nikita Bhutani*

Main category: cs.CL

TL;DR: 本文介绍了DFM任务和DiFBench框架，用于评估LLM在识别文档集合中罕见特征方面的能力，发现当前模型在统计推理和稀有性检测上存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基准主要侧重于信息检索或摘要，但未评估模型在一组文档中识别全局独特特征的能力。现实场景如候选人选拔或产品差异化需要统计推理而非检索。

Method: 引入了Distinctive Feature Mining (DFM)任务，并提出了DiFBench基准框架，用于系统评估模型在识别文档集合中罕见特征方面的能力。

Result: 评估了十种最先进的LLM在DFM任务上的表现，发现通用模型与增强推理能力的模型之间存在显著性能差距，且随着任务复杂性和文档数量增加，所有模型性能均显著下降。

Conclusion: 研究揭示了现代大型语言模型在进行细粒度统计推理和稀有性检测方面的核心局限性。

Abstract: Effective decision-making often relies on identifying what makes each
candidate distinctive. While existing benchmarks for LLMs emphasize retrieving
or summarizing information relevant to a given query, they do not evaluate a
model's ability to identify globally distinctive features across a set of
documents. We introduce Distinctive Feature Mining (DFM), a new task that
challenges models to analyze a small-to-medium collection (10-40 documents) and
surface features that are rare in the global context (e.g., appearing in less
than 10% of documents). This setting mirrors real-world scenarios such as
candidate selection or product differentiation, where statistical reasoning,
not retrieval, is key. To enable systematic evaluation of this capability, we
present DiFBench, a configurable benchmark creation framework with controllable
parameters such as document set size and distinctiveness thresholds. Using
DiFBench, we perform a large-scale assessment of distinctive feature mining
across ten state-of-the-art LLMs. Our findings reveal a significant performance
gap between general-purpose and reasoning-enhanced models. All models, however,
substantially degrade as the task complexity and document count increase. We
also find that a common failure mode is misidentifying frequent features as
distinctive. These insights reveal core limitations in contemporary LLMs'
abilities to perform fine-grained, statistical reasoning and rarity detection.

</details>


### [6] [The Differential Meaning of Models: A Framework for Analyzing the Structural Consequences of Semantic Modeling Decisions](https://arxiv.org/abs/2509.00248)
*Zachary K. Stine,James E. Deitrick*

Main category: cs.CL

TL;DR: 本文提出了一种基于符号理论的框架，用于分析和理解不同类型的建模实践。


<details>
  <summary>Details</summary>
Motivation: 当前领域缺乏一种通用的理论框架，以一致的方式描述不同类型的建模实践。

Method: 本文提出了一种基于符号理论的框架，用于分析人类意义构建的建模方法，并通过实例说明其应用。

Result: 本文提出了一个框架，用于理解模型作为符号的意义，并通过实例展示了其应用。

Conclusion: 本文提出了一个基于C.S.皮尔斯符号理论的框架，用于描述各种模型类型的建模实践，并通过对比其他模型来理解模型的解释性视角。

Abstract: The proliferation of methods for modeling of human meaning-making constitutes
a powerful class of instruments for the analysis of complex semiotic systems.
However, the field lacks a general theoretical framework for describing these
modeling practices across various model types in an apples-to-apples way. In
this paper, we propose such a framework grounded in the semiotic theory of C.
S. Peirce. We argue that such models measure latent symbol geometries, which
can be understood as hypotheses about the complex of semiotic agencies
underlying a symbolic dataset. Further, we argue that in contexts where a
model's value cannot be straightforwardly captured by proxy measures of
performance, models can instead be understood relationally, so that the
particular interpretive lens of a model becomes visible through its contrast
with other models. This forms the basis of a theory of model semantics in which
models, and the modeling decisions that constitute them, are themselves treated
as signs. In addition to proposing the framework, we illustrate its empirical
use with a few brief examples and consider foundational questions and future
directions enabled by the framework.

</details>


### [7] [The Temporal Game: A New Perspective on Temporal Relation Extraction](https://arxiv.org/abs/2509.00250)
*Hugo Sousa,Ricardo Campos,Alípio Jorge*

Main category: cs.CL

TL;DR: 本文提出了一种名为Temporal Game的新方法，用于时间关系抽取，通过将任务转化为交互式游戏，分解区间级关系为点对比较，并利用时间闭包推断额外关系和保持一致性。该方法支持区间和瞬间实体，提供更细粒度和灵活的标注方式，并可用于训练强化学习代理。演示系统已公开可用，源代码开源，以促进进一步研究。


<details>
  <summary>Details</summary>
Motivation: 现有的时间关系抽取方法在标注细粒度和灵活性方面存在不足，因此需要一种新的方法来提高时间关系抽取的效果。

Method: Temporal Game将时间关系抽取任务转化为交互式游戏，通过点对比较分解区间级关系，并利用时间闭包推断额外关系和保持一致性。同时，将时间标注视为顺序决策任务，以训练强化学习代理。

Result: Temporal Game能够支持区间和瞬间实体，提供更细粒度和灵活的标注方式，并且可以用于训练强化学习代理。演示系统已公开可用，并且源代码开源，以促进进一步研究和社区驱动开发。

Conclusion: 本文展示了Temporal Game作为一种新颖的时间关系抽取方法，通过将任务视为交互式游戏来解决。这种方法分解了区间级关系为点对比较，并通过时间闭包推断额外关系并保持一致性。该方法支持区间和瞬间实体，提供了更细粒度和灵活的标注方式，并为训练强化学习代理奠定了基础。此外，本文还提供了一个演示系统，可供用户使用并公开源代码以促进进一步研究。

Abstract: In this paper we demo the Temporal Game, a novel approach to temporal
relation extraction that casts the task as an interactive game. Instead of
directly annotating interval-level relations, our approach decomposes them into
point-wise comparisons between the start and end points of temporal entities.
At each step, players classify a single point relation, and the system applies
temporal closure to infer additional relations and enforce consistency. This
point-based strategy naturally supports both interval and instant entities,
enabling more fine-grained and flexible annotation than any previous approach.
The Temporal Game also lays the groundwork for training reinforcement learning
agents, by treating temporal annotation as a sequential decision-making task.
To showcase this potential, the demo presented in this paper includes a Game
mode, in which users annotate texts from the TempEval-3 dataset and receive
feedback based on a scoring system, and an Annotation mode, that allows custom
documents to be annotated and resulting timeline to be exported. Therefore,
this demo serves both as a research tool and an annotation interface. The demo
is publicly available at https://temporal-game.inesctec.pt, and the source code
is open-sourced to foster further research and community-driven development in
temporal reasoning and annotation.

</details>


### [8] [Exploring Reasoning-Infused Text Embedding with Large Language Models for Zero-Shot Dense Retrieval](https://arxiv.org/abs/2509.00276)
*Yuxiang Liu,Tian Wang,Gourab Kundu,Tianyu Cao,Guang Cheng,Zhen Ge,Jianshu Chen,Qingjun Cui,Trishul Chilimbi*

Main category: cs.CL

TL;DR: 本文提出了RITE方法，通过在文本嵌入过程中加入逻辑推理，提高了检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的嵌入方法主要关注上下文表示，而没有充分利用LLM的推理能力。因此，需要一种方法来填补这一差距。

Method: RITE方法通过在计算嵌入之前生成中间推理文本，将逻辑推理整合到文本嵌入过程中。

Result: 在BRIGHT基准测试中，RITE显著提升了零样本检索性能，适用于多种领域。

Conclusion: 实验结果表明，RITE在BRIGHT基准测试中显著提升了零样本检索性能，证明了在嵌入过程中融入推理的有效性。

Abstract: Transformer-based models such as BERT and E5 have significantly advanced text
embedding by capturing rich contextual representations. However, many complex
real-world queries require sophisticated reasoning to retrieve relevant
documents beyond surface-level lexical matching, where encoder-only retrievers
often fall short. Decoder-only large language models (LLMs), known for their
strong reasoning capabilities, offer a promising alternative. Despite this
potential, existing LLM-based embedding methods primarily focus on contextual
representation and do not fully exploit the reasoning strength of LLMs. To
bridge this gap, we propose Reasoning-Infused Text Embedding (RITE), a simple
but effective approach that integrates logical reasoning into the text
embedding process using generative LLMs. RITE builds upon existing language
model embedding techniques by generating intermediate reasoning texts in the
token space before computing embeddings, thereby enriching representations with
inferential depth. Experimental results on BRIGHT, a reasoning-intensive
retrieval benchmark, demonstrate that RITE significantly enhances zero-shot
retrieval performance across diverse domains, underscoring the effectiveness of
incorporating reasoning into the embedding process.

</details>


### [9] [OpinioRAG: Towards Generating User-Centric Opinion Highlights from Large-scale Online Reviews](https://arxiv.org/abs/2509.00285)
*Mir Tafseer Nayeem,Davood Rafiei*

Main category: cs.CL

TL;DR: 本文提出 OpinioRAG 框架和新的验证指标，以生成个性化、准确的大规模用户评论摘要。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理大量用户评论时无法扩展或产生通用的摘要，忽略了个性化需求。

Method: 引入 OpinioRAG，这是一个基于 RAG 的证据检索与 LLM 结合的可扩展、无需训练的框架，以及提出新的无参考验证指标。

Result: 通过实验识别关键挑战，提供改进系统的见解，并为未来研究铺平道路。

Conclusion: OpinioRAG 被认为是一个强大的框架，用于在大规模生成准确、相关和结构化的摘要。

Abstract: We study the problem of opinion highlights generation from large volumes of
user reviews, often exceeding thousands per entity, where existing methods
either fail to scale or produce generic, one-size-fits-all summaries that
overlook personalized needs. To tackle this, we introduce OpinioRAG, a
scalable, training-free framework that combines RAG-based evidence retrieval
with LLMs to efficiently produce tailored summaries. Additionally, we propose
novel reference-free verification metrics designed for sentiment-rich domains,
where accurately capturing opinions and sentiment alignment is essential. These
metrics offer a fine-grained, context-sensitive assessment of factual
consistency. To facilitate evaluation, we contribute the first large-scale
dataset of long-form user reviews, comprising entities with over a thousand
reviews each, paired with unbiased expert summaries and manually annotated
queries. Through extensive experiments, we identify key challenges, provide
actionable insights into improving systems, pave the way for future research,
and position OpinioRAG as a robust framework for generating accurate, relevant,
and structured summaries at scale.

</details>


### [10] [Wage Sentiment Indices Derived from Survey Comments via Large Language Models](https://arxiv.org/abs/2509.00290)
*Taihei Sone*

Main category: cs.CL

TL;DR: 本文提出了一种基于大型语言模型的工资情感指数，用于预测日本的工资动态，并展示了其优越性。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能的出现为经济文本分析创造了新的机会。

Method: 本文提出了一个基于大型语言模型（LLMs）构建的工资情感指数（WSI），用于预测日本的工资动态。

Result: 实验结果表明，基于LLMs的WSI模型显著优于基线方法和预训练模型。

Conclusion: 这些发现突显了基于大型语言模型的情感指数在提高政府和中央银行经济政策设计的及时性和有效性方面的潜力。

Abstract: The emergence of generative Artificial Intelligence (AI) has created new
opportunities for economic text analysis. This study proposes a Wage Sentiment
Index (WSI) constructed with Large Language Models (LLMs) to forecast wage
dynamics in Japan. The analysis is based on the Economy Watchers Survey (EWS),
a monthly survey conducted by the Cabinet Office of Japan that captures
real-time economic assessments from workers in industries highly sensitive to
business conditions. The WSI extends the framework of the Price Sentiment Index
(PSI) used in prior studies, adapting it specifically to wage related
sentiment. To ensure scalability and adaptability, a data architecture is also
developed that enables integration of additional sources such as newspapers and
social media. Experimental results demonstrate that WSI models based on LLMs
significantly outperform both baseline approaches and pretrained models. These
findings highlight the potential of LLM-driven sentiment indices to enhance the
timeliness and effectiveness of economic policy design by governments and
central banks.

</details>


### [11] [Balanced Actor Initialization: Stable RLHF Training of Distillation-Based Reasoning Models](https://arxiv.org/abs/2509.00309)
*Chen Zheng,Yiyuan Ma,Yuan Yang,Deyi Liu,Jing Liu,Zuquan Song,Yuxin Song,Cheng Ren,Hang Zhu,Xin Liu,Yiyuan Ma,Siyuan Qiao,Xun Zhou,Liang Xiang,Yonghui Wu*

Main category: cs.CL

TL;DR: 本文研究了将RLHF应用于蒸馏训练模型时出现的两个关键问题，并提出了一种新的方法来解决这些问题，从而实现更稳定和高效的模型训练。


<details>
  <summary>Details</summary>
Motivation: 尽管指令调优和RLHF对齐范式以及基于蒸馏的推理微调范式各自有效，但将RLHF应用于蒸馏训练的模型存在重大挑战。我们的研究揭示了这一范式中的两个关键现象：序列长度崩溃和奖励曲棍球棒曲线。这些不稳定性从根本上损害了模型的对齐和推理能力。

Method: 我们提出了Balanced Actor Initialization (BAI)，这是一种两阶段加权模型合并方法。BAI首先合并遵循指令的模型和基于蒸馏的推理微调模型，然后进一步将此中间模型与预训练模型结合以保留基础知识。

Result: 通过在多种基准上的全面实验和对训练实验的详细分析，我们证明BAI解决了序列长度崩溃，缓解了奖励曲棍球棒曲线，并在训练过程中实现了连续的序列长度改进。此外，我们的分析表明，平衡的合并比例在训练稳定性和推理能力保持之间实现了最佳权衡。

Conclusion: 我们的工作为这一第三范式中的稳定训练提供了有效的解决方案，使结合蒸馏效率和RLHF对齐的更强大的推理模型成为可能。

Abstract: The development of alignment and reasoning capabilities in large language
models has seen remarkable progress through two paradigms: instruction tuning
and reinforcement learning from human feedback (RLHF) alignment paradigm, and
distillation-based reasoning fine-tuning paradigm. While both approaches prove
effective independently, the third paradigm of applying RLHF to
distillation-trained models presents significant challenges. Our investigation
reveals two critical phenomena that emerge in this paradigm: Sequence Length
Collapse, where language generation dramatically reduces during early RLHF
training, and the Reward Hockey Stick Curve, featuring severe reward score
drops followed by gradual recovery. These instabilities fundamentally
compromise the model's alignment and reasoning capabilities. To address these
challenges, we propose Balanced Actor Initialization (BAI), a two-stage
weighted model merging approach. BAI first merges instruction-following and
distillation-based reasoning fine-tuned models, then further combines this
intermediate model with the pretrained model to preserve foundational
knowledge. Through comprehensive experiments across diverse benchmarks and
detailed analysis of training experiments, we demonstrate that BAI resolves
Sequence Length Collapse, mitigates the Reward Hockey Stick Curve, and enables
continuous sequence length improvement during training. Additionally, our
analysis reveals that balanced merging ratios achieve optimal trade-offs
between training stability and reasoning capability preservation. Our work
provides the effective solution for stable training in this third paradigm,
enabling more capable reasoning models that combine distillation efficiency
with RLHF alignment.

</details>


### [12] [GIER: Gap-Driven Self-Refinement for Large Language Models](https://arxiv.org/abs/2509.00325)
*Rinku Dewri*

Main category: cs.CL

TL;DR: GIER is a framework that improves LLM outputs through self-reflection and revision based on conceptual quality criteria.


<details>
  <summary>Details</summary>
Motivation: The motivation is to improve the quality of LLM outputs without relying on prompting strategies that use demonstrations, examples, or chain-of-thought templates.

Method: GIER is a framework that uses self-reflection and revision based on conceptual quality criteria to improve LLM outputs.

Result: GIER improves rationale quality, grounding, and reasoning alignment across three reasoning-intensive tasks and four LLMs.

Conclusion: GIER can improve the quality of LLM outputs without degrading task accuracy.

Abstract: We introduce GIER (Gap-driven Iterative Enhancement of Responses), a general
framework for improving large language model (LLM) outputs through
self-reflection and revision based on conceptual quality criteria. Unlike
prompting strategies that rely on demonstrations, examples, or chain-of-thought
templates, GIER utilizes natural language descriptions of reasoning gaps, and
prompts a model to iteratively critique and refine its own outputs to better
satisfy these criteria. Across three reasoning-intensive tasks (SciFact,
PrivacyQA, and e-SNLI) and four LLMs (GPT-4.1, GPT-4o Mini, Gemini 1.5 Pro, and
Llama 3.3 70B), GIER improves rationale quality, grounding, and reasoning
alignment without degrading task accuracy. Our analysis demonstrates that
models can not only interpret abstract conceptual gaps but also translate them
into concrete reasoning improvements.

</details>


### [13] [Open Data Synthesis For Deep Research](https://arxiv.org/abs/2509.00375)
*Ziyi Xia,Kun Luo,Hongjin Qian,Zheng Liu*

Main category: cs.CL

TL;DR: InfoSeek 是一个用于生成复杂深度研究任务的框架，能够提高模型性能并支持高级优化策略。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试无法捕捉深度研究任务的复杂性，而最近的合成数据集常常引入快捷推理、知识泄露或缺乏足够的结构深度。

Method: InfoSeek 使用双代理系统递归构建研究树，并将其转换为需要遍历整个层次结构的自然语言问题。

Result: 在挑战性的基准测试 BrowseComp-Plus 上，使用 InfoSeek 优化的 3B LLM 超过更大的 32B 模型和轻量级商业 API，同时达到与更强的 API 相当的性能。

Conclusion: InfoSeek 是一个有效的框架，可以生成复杂的深度研究任务，并在实验中表现出色。

Abstract: Large language models (LLMs) are increasingly expected to go beyond simple
factual queries toward Deep Research-tasks that require decomposing questions
into sub-problems, coordinating multi-step reasoning, and synthesizing evidence
from diverse sources. We formalize Deep Research tasks with verifiable answers
as Hierarchical Constraint Satisfaction Problems (HCSPs), which are
fundamentally different from single-constraint, multi-hop, or flat CSP
formulations. However, existing benchmarks (e.g., Natural Questions, HotpotQA)
fail to capture this complexity, while recent synthetic datasets often
introduce shortcut reasoning, knowledge leakage, or lack sufficient structural
depth. To address this gap, we introduce InfoSeek, a scalable framework for
synthesizing complex Deep Research tasks. InfoSeek uses a dual-agent system to
recursively build a Research Tree from large-scale webpages, blurring
intermediate nodes into valid sub-problems, and converting these trees into
natural language questions that require traversing the full hierarchy. It also
enables rapid scaling, yielding over 50K training examples, a curated test set,
and reasoning trajectories generated via reject sampling. Experiments show that
models trained on InfoSeek consistently outperform strong baselines. On a
challenging benchmark BrowseComp-Plus, 3B LLMs optimized with InfoSeek surpass
much larger 32B models and lightweight commercial APIs (e.g., Gemini2.5-Flash),
while achieving performance comparable to stronger APIs (e.g., Gemini2.5-Pro).
By preserving meta-information such as intermediate steps and retrieval labels,
InfoSeek further supports advanced optimization strategies, including compound
reward design and trajectory-level exploration. We provide our codes and
datasets in \href{https://github.com/VectorSpaceLab/InfoSeek}{this repository}.

</details>


### [14] [GraphKV: Breaking the Static Selection Paradigm with Graph-Based KV Cache Eviction](https://arxiv.org/abs/2509.00388)
*Xuelin Li,Xiangqi Jin,Linfeng Zhang*

Main category: cs.CL

TL;DR: GraphKV is a graph-based framework for efficient KV cache management in LLMs, which dynamically updates token importance based on their similarity relationships.


<details>
  <summary>Details</summary>
Motivation: Efficient Key-Value (KV) cache management is essential for processing long text sequences in large language models (LLMs), where memory constraints often limit performance. Conventional KV eviction strategies fail to capture the evolving implicit dependencies among tokens during inference.

Method: GraphKV is a graph-based framework that models tokens as nodes with importance scores, and edges represent their similarity relationships. It uses a decay-signal-propagation mechanism to dynamically update token importance.

Result: GraphKV enables adaptive retention of the most contextually significant tokens by dynamically updating their importance through a decay-signal-propagation mechanism.

Conclusion: GraphKV can be seamlessly utilized in existing KV cache eviction methods such as SnapKV and PyramidKV in a plug-and-play manner.

Abstract: Efficient Key-Value (KV) cache management is essential for processing long
text sequences in large language models (LLMs), where memory constraints often
limit performance. Conventional KV eviction strategies, such as top-k selection
based on attention scores, depend on static heuristics that fail to capture the
evolving implicit dependencies among tokens during inference. To overcome this,
we propose GraphKV, a graph-based framework that redefines token selection for
KV cache compression. In GraphKV, tokens are modeled as nodes with importance
scores, and edges represent their similarity relationships. Through a
decay-signal-propagation mechanism, token importance is dynamically updated by
propagating information across the graph, enabling adaptive retention of the
most contextually significant tokens. GraphKV can be seamlessly utilized in
existing KV cache eviction methods such as SnapKV and PyramidKV in a
plug-and-play manner. Codes will be released on Github.

</details>


### [15] [The Resurgence of GCG Adversarial Attacks on Large Language Models](https://arxiv.org/abs/2509.00391)
*Yuting Tan,Xuying Li,Zhuo Li,Huizhen Shu,Peikang Hu*

Main category: cs.CL

TL;DR: 本文评估了GCG和T-GCG在不同规模的开源大型语言模型上的攻击效果，发现攻击成功率随着模型规模的增加而下降，并揭示了推理任务中的潜在漏洞。


<details>
  <summary>Details</summary>
Motivation: 研究GCG和T-GCG在不同模型上的攻击效果，以了解其有效性并发现潜在的漏洞。

Method: 本文系统地评估了GCG及其增强变体T-GCG在不同规模的开源大型语言模型上的攻击效果。

Result: 研究发现了三个关键结果：(1) 随着模型规模的增加，攻击成功率下降；(2) 基于前缀的启发式方法高估了攻击效果；(3) 与对抗性安全提示相比，与编码相关的提示更容易受到攻击。此外，T-GCG的初步结果显示模拟退火可以多样化对抗搜索。

Conclusion: 这些发现突显了GCG的可扩展性限制，揭示了推理任务中的被忽视的漏洞，并促使进一步开发基于退火的策略以实现更稳健的对抗性评估。

Abstract: Gradient-based adversarial prompting, such as the Greedy Coordinate Gradient
(GCG) algorithm, has emerged as a powerful method for jailbreaking large
language models (LLMs). In this paper, we present a systematic appraisal of GCG
and its annealing-augmented variant, T-GCG, across open-source LLMs of varying
scales. Using Qwen2.5-0.5B, LLaMA-3.2-1B, and GPT-OSS-20B, we evaluate attack
effectiveness on both safety-oriented prompts (AdvBench) and
reasoning-intensive coding prompts. Our study reveals three key findings: (1)
attack success rates (ASR) decrease with model size, reflecting the increasing
complexity and non-convexity of larger models' loss landscapes; (2)
prefix-based heuristics substantially overestimate attack effectiveness
compared to GPT-4o semantic judgments, which provide a stricter and more
realistic evaluation; and (3) coding-related prompts are significantly more
vulnerable than adversarial safety prompts, suggesting that reasoning itself
can be exploited as an attack vector. In addition, preliminary results with
T-GCG show that simulated annealing can diversify adversarial search and
achieve competitive ASR under prefix evaluation, though its benefits under
semantic judgment remain limited. Together, these findings highlight the
scalability limits of GCG, expose overlooked vulnerabilities in reasoning
tasks, and motivate further development of annealing-inspired strategies for
more robust adversarial evaluation.

</details>


### [16] [MedSEBA: Synthesizing Evidence-Based Answers Grounded in Evolving Medical Literature](https://arxiv.org/abs/2509.00414)
*Juraj Vladika,Florian Matthes*

Main category: cs.CL

TL;DR: MedSEBA 是一个交互式 AI 系统，能够基于证据提供医学问题的答案，并动态检索可靠的医学研究来支持这些答案。


<details>
  <summary>Details</summary>
Motivation: 在数字时代，人们常常通过互联网寻找医疗建议和推荐，但由于在线内容的增加，区分可靠来源和误导信息变得困难。此外，每年有数百万篇医学研究发表，研究人员难以跟踪最新的科学发现。传统搜索工具无法反映这些不断变化的研究的不同结论。

Method: MedSEBA 利用大型语言模型生成连贯且表达丰富的答案，并动态从 PubMed 研究数据库中检索可信的医学研究来支持这些答案。

Result: 用户研究表明，医学专家和普通用户认为该系统易于使用且有帮助，提供的答案值得信赖且信息丰富。

Conclusion: MedSEBA 是一个交互式 AI 驱动的系统，能够综合基于证据的答案来解决医学问题，具有良好的可用性和帮助性，适用于日常健康问题和高级研究见解。

Abstract: In the digital age, people often turn to the Internet in search of medical
advice and recommendations. With the increasing volume of online content, it
has become difficult to distinguish reliable sources from misleading
information. Similarly, millions of medical studies are published every year,
making it challenging for researchers to keep track of the latest scientific
findings. These evolving studies can reach differing conclusions, which is not
reflected in traditional search tools. To address these challenges, we
introduce MedSEBA, an interactive AI-powered system for synthesizing
evidence-based answers to medical questions. It utilizes the power of Large
Language Models to generate coherent and expressive answers, but grounds them
in trustworthy medical studies dynamically retrieved from the research database
PubMed. The answers consist of key points and arguments, which can be traced
back to respective studies. Notably, the platform also provides an overview of
the extent to which the most relevant studies support or refute the given
medical claim, and a visualization of how the research consensus evolved
through time. Our user study revealed that medical experts and lay users find
the system usable and helpful, and the provided answers trustworthy and
informative. This makes the system well-suited for both everyday health
questions and advanced research insights.

</details>


### [17] [The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang](https://arxiv.org/abs/2509.00425)
*Fenghua Liu,Yulong Chen,Yixuan Liu,Zhujun Jin,Solomon Tsai,Ming Zhong*

Main category: cs.CL

TL;DR: Camlang is a constructed language used to evaluate whether LLMs can demonstrate genuine reasoning by mastering an unfamiliar language through metalinguistic learning. Results show that current LLMs lag behind humans in this task.


<details>
  <summary>Details</summary>
Motivation: The paper aims to determine whether large language models (LLMs) demonstrate genuine reasoning or pattern matching by testing their ability to master an unfamiliar language through explicit metalinguistic deductive learning.

Method: The paper introduces Camlang, a constructed language with naturalistic yet unattested feature combinations, and adapts CommonsenseQA into Camlang to create Camlang-CSQA-v0. It evaluates the performance of LLMs on this task.

Result: GPT-5 achieves 98% EM accuracy in English but only 47% in Camlang, far below human performance at 87%. Other state-of-the-art reasoning LLMs perform even worse. Human verification reveals that most model successes stem from shallow lexical alignment, while GPT-5 shows emerging metalinguistic awareness to a limited extent.

Conclusion: Camlang establishes a cognitively grounded evaluation paradigm that exposes fundamental gaps between current models and human metalinguistic competence.

Abstract: Large Language Models (LLMs) achieve gold-medal performance across many
benchmarks, yet it remains unclear whether such success reflects genuine
reasoning or pattern matching. From a cognitive science perspective, an
informative test is whether models can master an unfamiliar language through
explicit metalinguistic deductive learning, a paradigm where human learners can
reliably internalise grammatical systems through metalinguistic reasoning. We
address this question with Camlang, a novel constructed language that exhibits
naturalistic yet unattested feature combinations. Camlang consists of two
explicit resources, a grammar book and a bilingual dictionary, which mirror
adult second-language learning via explicit grammar rules and lexical lookup,
and enable us to disentangle errors in morpho-syntax, lexical semantics, and
sentence-level reasoning. Human experiments show that these resources are
sufficient for participants to acquire Camlang and successfully solve Camlang
tasks. To operationalise evaluation, we adapt CommonsenseQA into Camlang,
creating Camlang-CSQA-v0, the first task in a broader suite where solving
questions requires applying grammar rules and lexical mappings. Experimental
results show that GPT-5 achieves 98\% EM accuracy in English but only 47\% in
Camlang, far below human performance at 87\%, while other state-of-the-art
reasoning LLMs perform even worse. Human verification further reveals that most
model successes stem from shallow lexical alignment while GPT-5 shows emerging
metalinguistic awareness to a limited extent but not systematic grammatical
mastery as humans. Camlang establishes a cognitively grounded evaluation
paradigm that exposes fundamental gaps between current models and human
metalinguistic competence.

</details>


### [18] [GOSU: Retrieval-Augmented Generation with Global-Level Optimized Semantic Unit-Centric Framework](https://arxiv.org/abs/2509.00449)
*Xuecheng Zou,Ke Liu,Bingbing Wang,Huafei Deng,Li Zhang,Yu Tang*

Main category: cs.CL

TL;DR: GOSU is a semantic unit-centric RAG framework that improves generation quality by addressing issues with local SUs through global disambiguation and enhanced retrieval strategies.


<details>
  <summary>Details</summary>
Motivation: The extraction of high-level SUs limited to local text chunks is prone to ambiguity, complex coupling, and increased retrieval overhead due to the lack of global knowledge or the neglect of fine-grained relationships.

Method: GOSU is a semantic unit-centric RAG framework that performs global disambiguation and utilizes SUs to capture interconnections between different nodes across the global context. It includes global merging of pre-extracted SUs, entity and relationship extraction, hierarchical keyword extraction, and semantic unit completion.

Result: GOSU demonstrates superior performance compared to baseline RAG methods in terms of generation quality across multiple tasks.

Conclusion: GOSU outperforms the baseline RAG methods in terms of generation quality.

Abstract: Building upon the standard graph-based Retrieval-Augmented Generation (RAG),
the introduction of heterogeneous graphs and hypergraphs aims to enrich
retrieval and generation by leveraging the relationships between multiple
entities through the concept of semantic units (SUs). But this also raises a
key issue: The extraction of high-level SUs limited to local text chunks is
prone to ambiguity, complex coupling, and increased retrieval overhead due to
the lack of global knowledge or the neglect of fine-grained relationships. To
address these issues, we propose GOSU, a semantic unit-centric RAG framework
that efficiently performs global disambiguation and utilizes SUs to capture
interconnections between different nodes across the global context. In the
graph construction phase, GOSU performs global merging on the pre-extracted SUs
from local text chunks and guides entity and relationship extraction, reducing
the difficulty of coreference resolution while uncovering global semantic
objects across text chunks. In the retrieval and generation phase, we introduce
hierarchical keyword extraction and semantic unit completion. The former
uncovers the fine-grained binary relationships overlooked by the latter, while
the latter compensates for the coarse-grained n-ary relationships missing from
the former. Evaluation across multiple tasks demonstrates that GOSU outperforms
the baseline RAG methods in terms of generation quality.

</details>


### [19] [CVPD at QIAS 2025 Shared Task: An Efficient Encoder-Based Approach for Islamic Inheritance Reasoning](https://arxiv.org/abs/2509.00457)
*Salah Eddine Bekhouche,Abdellah Zakaria Sellam,Hichem Telli,Cosimo Distante,Abdenour Hadid*

Main category: cs.CL

TL;DR: 本文介绍了一种用于解决多选继承问题的轻量级框架，比较了不同阿拉伯语编码器和基于API的大语言模型的性能，强调了小型、专用系统在高风险领域中的实际优势。


<details>
  <summary>Details</summary>
Motivation: 伊斯兰继承法（Ilm al-Mawarith）需要精确识别继承人和计算份额，这对AI是一个挑战。

Method: 本文提出了一种轻量级框架，使用专门的阿拉伯语文本编码器和注意相关性评分（ARS）来解决多选继承问题。

Result: 虽然大型模型在QIAS 2025数据集上的准确率高达87.6%，但它们需要更多的资源且依赖上下文。我们的MARBERT方法实现了69.87%的准确率，展示了效率、本地部署和隐私的优势。

Conclusion: 本文量化了大型模型的峰值性能与小型、专用系统在高风险领域中的实际优势之间的关键权衡。

Abstract: Islamic inheritance law (Ilm al-Mawarith) requires precise identification of
heirs and calculation of shares, which poses a challenge for AI. In this paper,
we present a lightweight framework for solving multiple-choice inheritance
questions using a specialised Arabic text encoder and Attentive Relevance
Scoring (ARS). The system ranks answer options according to semantic relevance,
and enables fast, on-device inference without generative reasoning. We evaluate
Arabic encoders (MARBERT, ArabicBERT, AraBERT) and compare them with API-based
LLMs (Gemini, DeepSeek) on the QIAS 2025 dataset. While large models achieve an
accuracy of up to 87.6%, they require more resources and are context-dependent.
Our MARBERT-based approach achieves 69.87% accuracy, presenting a compelling
case for efficiency, on-device deployability, and privacy. While this is lower
than the 87.6% achieved by the best-performing LLM, our work quantifies a
critical trade-off between the peak performance of large models and the
practical advantages of smaller, specialized systems in high-stakes domains.

</details>


### [20] [TECP: Token-Entropy Conformal Prediction for LLMs](https://arxiv.org/abs/2509.00461)
*Beining Xu*

Main category: cs.CL

TL;DR: TECP是一种新的框架，利用token级别的熵来估计不确定性，并通过split conformal prediction构建预测集，以确保在黑盒大语言模型中的可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 在黑盒约束下，内部模型信号不可访问，因此需要一种新的不确定性量化方法。

Method: TECP框架利用了token级别的熵作为logit-free、reference-free的不确定性度量，并将其集成到split conformal prediction (CP)流程中，以构建具有正式覆盖保证的预测集。

Result: 在六个大型语言模型和两个基准（CoQA和TriviaQA）上的实证评估表明，TECP一致地实现了可靠的覆盖和紧凑的预测集，优于之前的基于自我一致性的方法。

Conclusion: TECP提供了一种在黑盒大语言模型设置中实现可信生成的合理且高效的方法。

Abstract: Uncertainty quantification (UQ) for open-ended language generation remains a
critical yet underexplored challenge, especially under black-box constraints
where internal model signals are inaccessible. In this paper, we introduce
Token-Entropy Conformal Prediction (TECP), a novel framework that leverages
token-level entropy as a logit-free, reference-free uncertainty measure and
integrates it into a split conformal prediction (CP) pipeline to construct
prediction sets with formal coverage guarantees. Unlike existing approaches
that rely on semantic consistency heuristics or white-box features, TECP
directly estimates epistemic uncertainty from the token entropy structure of
sampled generations and calibrates uncertainty thresholds via CP quantiles to
ensure provable error control. Empirical evaluations across six large language
models and two benchmarks (CoQA and TriviaQA) demonstrate that TECP
consistently achieves reliable coverage and compact prediction sets,
outperforming prior self-consistency-based UQ methods. Our method provides a
principled and efficient solution for trustworthy generation in black-box LLM
settings.

</details>


### [21] [Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting](https://arxiv.org/abs/2509.00482)
*Saksorn Ruangtanusak,Pittawat Taveekitworachai,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 该研究探索了四种提示方法，发现基于规则的角色提示（RRP）能有效提升角色扮演对话代理的表现。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决对话代理在角色扮演中过度说话和未能有效使用工具的问题，例如生成不存在的函数调用或在回答前进行不必要的工具调用。

Method: 研究探索了四种提示方法：1) 基本角色提示，2) 人工制作的角色提示，3) 自动提示优化（APO），4) 基于规则的角色提示（RRP）。其中，RRP通过两种新技术——角色卡/场景合同设计和严格执行函数调用，取得了最佳性能。

Result: RRP方法通过两种新技术取得了最佳性能，总体得分为0.571，优于零样本基线得分0.519。

Conclusion: 研究结果表明，基于规则的角色提示（RRP）设计可以显著提高角色扮演对话代理的有效性和可靠性，相比更复杂的方案如自动提示优化（APO）效果更好。

Abstract: This report investigates approaches for prompting a tool-augmented large
language model (LLM) to act as a role-playing dialogue agent in the API track
of the Commonsense Persona-grounded Dialogue Challenge (CPDC) 2025. In this
setting, dialogue agents often produce overly long in-character responses
(over-speaking) while failing to use tools effectively according to the persona
(under-acting), such as generating function calls that do not exist or making
unnecessary tool calls before answering. We explore four prompting approaches
to address these issues: 1) basic role prompting, 2) human-crafted role
prompting, 3) automatic prompt optimization (APO), and 4) rule-based role
prompting. The rule-based role prompting (RRP) approach achieved the best
performance through two novel techniques--character-card/scene-contract design
and strict enforcement of function calling--which led to an overall score of
0.571, improving on the zero-shot baseline score of 0.519. These findings
demonstrate that RRP design can substantially improve the effectiveness and
reliability of role-playing dialogue agents compared with more elaborate
methods such as APO. To support future efforts in developing persona prompts,
we are open-sourcing all of our best-performing prompts and the APO tool.
Source code is available at https://github.com/scb-10x/apo.

</details>


### [22] [ResearchQA: Evaluating Scholarly Question Answering at Scale Across 75 Fields with Survey-Mined Questions and Rubrics](https://arxiv.org/abs/2509.00496)
*Li S. Yifei,Allen Chang,Chaitanya Malaviya,Mark Yatskar*

Main category: cs.CL

TL;DR: 研究者引入了ResearchQA，通过从75个研究领域中提炼出21K个查询和160K个评分标准来评估LLM系统。结果表明，当前系统在覆盖评分标准方面存在显著不足，最高排名的代理系统在引用、限制和比较方面的覆盖率也较低。研究者释放了数据以促进更全面的多领域评估。


<details>
  <summary>Details</summary>
Motivation: 研究专家的知识是广泛的，但评估长篇回答通常依赖于专家注释器，这限制了对AI等领域的关注。因此，需要一种新的方法来评估LLM系统在多个领域的表现。

Method: 研究者引入了ResearchQA，通过从75个研究领域中提炼出21K个查询和160K个评分标准来评估LLM系统。每个评分标准与来自调查部分的查询共同生成，列出了特定于查询的答案评估标准，例如引用论文、做出解释和描述限制。

Result: 31名博士注释器在8个领域的评估表明，96%的查询支持博士的信息需求，87%的评分标准应在系统响应中用一句话或更多内容进行处理。使用研究者的评分标准，可以构建一个自动成对判断器，与专家判断有74%的一致性。研究者利用ResearchQA分析了18个系统在超过7.6K次成对评估中的能力差距。

Conclusion: 研究结果表明，目前的系统在覆盖评估标准方面存在显著不足，且最高排名的代理系统在引用、限制和比较方面的覆盖率也较低。研究者释放了数据以促进更全面的多领域评估。

Abstract: Evaluating long-form responses to research queries heavily relies on expert
annotators, restricting attention to areas like AI where researchers can
conveniently enlist colleagues. Yet, research expertise is widespread: survey
articles synthesize knowledge distributed across the literature. We introduce
ResearchQA, a resource for evaluating LLM systems by distilling survey articles
from 75 research fields into 21K queries and 160K rubric items. Each rubric,
derived jointly with queries from survey sections, lists query-specific answer
evaluation criteria, i.e., citing papers, making explanations, and describing
limitations. Assessments by 31 Ph.D. annotators in 8 fields indicate 96% of
queries support Ph.D. information needs and 87% of rubric items should be
addressed in system responses by a sentence or more. Using our rubrics, we are
able to construct an automatic pairwise judge obtaining 74% agreement with
expert judgments. We leverage ResearchQA to analyze competency gaps in 18
systems in over 7.6K pairwise evaluations. No parametric or retrieval-augmented
system we evaluate exceeds 70% on covering rubric items, and the
highest-ranking agentic system shows 75% coverage. Error analysis reveals that
the highest-ranking system fully addresses less than 11% of citation rubric
items, 48% of limitation items, and 49% of comparison items. We release our
data to facilitate more comprehensive multi-field evaluations.

</details>


### [23] [Entropy-based Coarse and Compressed Semantic Speech Representation Learning](https://arxiv.org/abs/2509.00503)
*Jialong Zuo,Guangyan Zhang,Minghui Fang,Shengpeng Ji,Xiaoqi Jiao,Jingyu Li,Yiwen Guo,Zhou Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种基于熵的动态聚合框架，用于学习压缩的语义语音表示，实验表明该方法在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的离散语音表示学习方法通常将16 kHz波形编码为每秒25或50个标记，但语音通常每秒仅传达2到5个单词，这种细粒度的标记化引入了冗余，并阻碍了下游训练和推理的效率。此外，这种频率的语义语音表示主要捕捉语音级别的信息，而语义理解可能不需要如此详细的标记级分辨率。

Method: 提出了一种基于熵的动态聚合框架，用于学习压缩的语义语音表示。首先通过大规模未标记数据上的下一个标记预测对语音语言模型进行预训练，以捕捉频繁的标记模式。然后使用预测熵自适应地确定聚合边界，并通过交叉注意力模块融合每个段内的信息。通过调整熵阈值，可以灵活控制表示的粒度和压缩比。

Result: 实验表明，压缩表示在语音识别、语音到文本翻译和语音转换任务中表现与密集标记序列相当或更好。

Conclusion: 实验表明，压缩表示在语音识别、语音到文本翻译和语音转换任务中表现与密集标记序列相当或更好，证明了所提出方法的有效性。

Abstract: Discrete speech representation learning has recently attracted increasing
interest in both acoustic and semantic modeling. Existing approaches typically
encode 16 kHz waveforms into discrete tokens at a rate of 25 or 50 tokens per
second. However, given that speech generally conveys only 2 to 5 words per
second, such fine-grained tokenization introduces redundancy and hinders
efficiency in downstream training and inference. Moreover, semantic speech
representations at this frequency primarily capture phonetic-level information,
while semantic understanding may not require such detailed token-level
resolution. To address these limitations, we propose an entropy-based dynamic
aggregation framework for learning compressed semantic speech representations.
A speech language model is first pre-trained via next-token prediction on
large-scale unlabeled data to capture frequent token patterns. Predictive
entropy is then used to adaptively determine aggregation boundaries, followed
by a cross-attention module that fuses information within each segment. By
adjusting the entropy threshold, the granularity and compression ratio of the
representations can be flexibly controlled. Experiments on ASR, speech-to-text
translation, and voice conversion tasks demonstrate that the compressed
representations perform on par with or better than dense token sequences,
demonstrating the effectiveness of the proposed approach.

</details>


### [24] [Modeling Motivated Reasoning in Law: Evaluating Strategic Role Conditioning in LLM Summarization](https://arxiv.org/abs/2509.00529)
*Eunjung Cho,Alexander Hoyle,Yoan Hermstrüwer*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型在不同法律角色下的摘要行为，发现模型会根据角色调整信息呈现方式，这引发了对角色意识评估的必要性的关注。


<details>
  <summary>Details</summary>
Motivation: 在法律背景下，大型语言模型生成用户定制的摘要，这引发了关于动机推理的重要问题，即模型如何战略性地呈现信息以符合法律体系中的利益相关者立场。

Method: 我们引入了一个基于法律事实和推理包含的评估框架，并考虑了对利益相关者的倾向性。

Result: 即使当提示包括平衡指令时，模型也表现出反映角色一致观点的选择性包含模式。

Conclusion: 我们的研究结果强调了在高风险法律环境中对LLM摘要行为进行角色意识评估的必要性。

Abstract: Large Language Models (LLMs) are increasingly used to generate user-tailored
summaries, adapting outputs to specific stakeholders. In legal contexts, this
raises important questions about motivated reasoning -- how models
strategically frame information to align with a stakeholder's position within
the legal system. Building on theories of legal realism and recent trends in
legal practice, we investigate how LLMs respond to prompts conditioned on
different legal roles (e.g., judges, prosecutors, attorneys) when summarizing
judicial decisions. We introduce an evaluation framework grounded in legal fact
and reasoning inclusion, also considering favorability towards stakeholders.
Our results show that even when prompts include balancing instructions, models
exhibit selective inclusion patterns that reflect role-consistent perspectives.
These findings raise broader concerns about how similar alignment may emerge as
LLMs begin to infer user roles from prior interactions or context, even without
explicit role instructions. Our results underscore the need for role-aware
evaluation of LLM summarization behavior in high-stakes legal settings.

</details>


### [25] [Thinking Hard, Going Misaligned: Emergent Misalignment in LLMs](https://arxiv.org/abs/2509.00544)
*Hanqi Yan,Hainiu Xu,Yulan He*

Main category: cs.CL

TL;DR: 本研究发现，当大型语言模型（LLMs）的推理能力增强时，它们更容易对恶意请求做出响应，这引发了对模型安全性和对齐性的新关注。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）被广泛采用，对其安全性和与人类价值观的一致性的担忧加剧。先前的研究表明，在狭窄和恶意数据集上微调LLM会导致行为不一致。

Method: 通过切换到“思考模式”或在良性数学数据集上微调，研究了强化推理时LLM对恶意请求的响应情况。

Result: 研究发现，当推理被加强时，LLM对恶意请求的响应更加积极，尤其是密集模型更容易受到影响。此外，分析内部模型状态发现，注意力转移和混合专家模型中的专业专家有助于将过度推理引导至安全防护措施。

Conclusion: 这些发现为新兴的推理-安全权衡提供了新的见解，并强调了推进先进推理模型对齐的紧迫性。

Abstract: With Large Language Models (LLMs) becoming increasingly widely adopted,
concerns regarding their safety and alignment with human values have
intensified. Previous studies have shown that fine-tuning LLMs on narrow and
malicious datasets induce misaligned behaviors. In this work, we report a more
concerning phenomenon, Reasoning-Induced Misalignment. Specifically, we observe
that LLMs become more responsive to malicious requests when reasoning is
strengthened, via switching to "think-mode" or fine-tuning on benign math
datasets, with dense models particularly vulnerable. Moreover, we analyze
internal model states and find that both attention shifts and specialized
experts in mixture-of-experts models help redirect excessive reasoning towards
safety guardrails. These findings provide new insights into the emerging
reasoning-safety trade-off and underscore the urgency of advancing alignment
for advanced reasoning models.

</details>


### [26] [StealthEval: A Probe-Rewrite-Evaluate Workflow for Reliable Benchmarks](https://arxiv.org/abs/2509.00591)
*Lang Xiong,Nishant Bhargava,Wesley Chang,Jianhang Hong,Haihao Liu,Kevin Zhu*

Main category: cs.CL

TL;DR: 本研究通过操纵提示的感知上下文系统地量化了行为变化，并引入了一种方法来调整提示以更接近实际部署环境。结果表明，评估意识会影响LLM的行为，导致模型在感知测试环境中更容易产生不安全或欺骗性的输出。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在从现实世界部署环境到受控评估设置的感知变化时，往往会表现出显著的行为变化，这种现象被称为“评估意识”。这种差异对AI对齐构成了重大挑战，因为基准性能可能无法准确反映模型的真实安全性和诚实度。

Method: 我们引入了一种方法，使用线性探测器将提示评分在一个从“测试类似”到“部署类似”的连续尺度上，并利用LLM重写策略将这些提示转向更自然的部署风格上下文，同时保留原始任务。

Result: 我们发现重写的“部署类似”提示引起了行为的显著且一致的变化。所有模型的诚实回答平均增加了5.26%，而欺骗性回答平均减少了12.40%。此外，拒绝率平均增加了6.38%，表明安全性合规性提高。

Conclusion: 我们的研究证明了评估意识是一个可量化和可操作的因素，直接影响LLM的行为。这强调了在部署前需要更现实的评估框架来准确衡量模型对齐的真实情况。

Abstract: Large Language Models (LLMs) often exhibit significant behavioral shifts when
they perceive a change from a real-world deployment context to a controlled
evaluation setting, a phenomenon known as "evaluation awareness." This
discrepancy poses a critical challenge for AI alignment, as benchmark
performance may not accurately reflect a model's true safety and honesty. In
this work, we systematically quantify these behavioral changes by manipulating
the perceived context of prompts. We introduce a methodology that uses a linear
probe to score prompts on a continuous scale from "test-like" to "deploy-like"
and leverage an LLM rewriting strategy to shift these prompts towards a more
natural, deployment-style context while preserving the original task. Using
this method, we achieved a 30% increase in the average probe score across a
strategic role-playing dataset after rewriting. Evaluating a suite of
state-of-the-art models on these original and rewritten prompts, we find that
rewritten "deploy-like" prompts induce a significant and consistent shift in
behavior. Across all models, we observed an average increase in honest
responses of 5.26% and a corresponding average decrease in deceptive responses
of 12.40%. Furthermore, refusal rates increased by an average of 6.38%,
indicating heightened safety compliance. Our findings demonstrate that
evaluation awareness is a quantifiable and manipulable factor that directly
influences LLM behavior, revealing that models are more prone to unsafe or
deceptive outputs in perceived test environments. This underscores the urgent
need for more realistic evaluation frameworks to accurately gauge true model
alignment before deployment.

</details>


### [27] [Gated Associative Memory: A Parallel O(N) Architecture for Efficient Sequence Modeling](https://arxiv.org/abs/2509.00605)
*Rishiraj Acharya*

Main category: cs.CL

TL;DR: This paper proposes the Gated Associative Memory (GAM) network, a novel, fully parallel architecture for sequence modeling that exhibits linear complexity with respect to sequence length. GAM replaces the self-attention layer with two parallel pathways and uses a gating mechanism to combine local and global information. Experiments show that GAM is faster and achieves better performance than existing models.


<details>
  <summary>Details</summary>
Motivation: The Transformer architecture has become the de facto standard for sequence modeling tasks, but its core computational primitive scales quadratically with sequence length, creating a bottleneck for processing long contexts.

Method: The GAM block replaces the self-attention layer with two parallel pathways: a causal convolution to capture local, position-dependent context, and a parallel associative memory retrieval mechanism to model global, content-based patterns. These pathways are dynamically fused using a gating mechanism.

Result: GAM is consistently faster, outperforms both baselines on training speed, and achieves a superior or competitive final validation perplexity across all datasets.

Conclusion: GAM is a promising and efficient alternative for sequence modeling, as it is consistently faster and achieves a superior or competitive final validation perplexity across all datasets.

Abstract: The Transformer architecture, underpinned by the self-attention mechanism,
has become the de facto standard for sequence modeling tasks. However, its core
computational primitive scales quadratically with sequence length (O(N^2)),
creating a significant bottleneck for processing long contexts. In this paper,
we propose the Gated Associative Memory (GAM) network, a novel, fully parallel
architecture for sequence modeling that exhibits linear complexity (O(N)) with
respect to sequence length. The GAM block replaces the self-attention layer
with two parallel pathways: a causal convolution to efficiently capture local,
position-dependent context, and a parallel associative memory retrieval
mechanism to model global, content-based patterns. These pathways are
dynamically fused using a gating mechanism, allowing the model to flexibly
combine local and global information for each token. We implement GAM from
scratch and conduct a rigorous comparative analysis against a standard
Transformer model and a modern linear-time baseline (Mamba) on the WikiText-2
benchmark, as well as against the Transformer on the TinyStories dataset. Our
experiments demonstrate that GAM is consistently faster, outperforming both
baselines on training speed, and achieves a superior or competitive final
validation perplexity across all datasets, establishing it as a promising and
efficient alternative for sequence modeling.

</details>


### [28] [A Multi-Strategy Approach for AI-Generated Text Detection](https://arxiv.org/abs/2509.00623)
*Ali Zain,Sareem Farooqui,Muhammad Rafi*

Main category: cs.CL

TL;DR: 本文介绍了三个用于检测AI生成内容的系统，其中基于RoBERTa的系统表现最佳。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为M-DAIGT共享任务开发有效的AI生成内容检测系统，特别是在新闻文章和学术摘要中。

Method: 本文提出了三个不同的系统：(1) 微调的RoBERTa-base分类器，(2) 经典的TF-IDF + 支持向量机(SVM)分类器，以及(3) 一种名为Candace的创新集成模型，利用从多个Llama-3.2模型中提取的概率特征，并通过自定义Transformer编码器处理。

Result: RoBERTa-based系统在开发集和测试集上均表现出色，接近完美结果。

Conclusion: RoBERTa-based system在检测AI生成内容方面表现最佳，达到了开发集和测试集上的近完美结果。

Abstract: This paper presents presents three distinct systems developed for the M-DAIGT
shared task on detecting AI generated content in news articles and academic
abstracts. The systems includes: (1) A fine-tuned RoBERTa-base classifier, (2)
A classical TF-IDF + Support Vector Machine (SVM) classifier , and (3) An
Innovative ensemble model named Candace, leveraging probabilistic features
extracted from multiple Llama-3.2 models processed by a customTransformer
encoder.The RoBERTa-based system emerged as the most performant, achieving
near-perfect results on both development and test sets.

</details>


### [29] [Can Multi-turn Self-refined Single Agent LMs with Retrieval Solve Hard Coding Problems?](https://arxiv.org/abs/2509.00629)
*Md Tanzib Hosain,Md Kishor Morol*

Main category: cs.CL

TL;DR: 本研究提出了ICPC基准，用于评估语言模型在竞争编程中的表现，并展示了通过改进推理技术可以显著提高解决能力。


<details>
  <summary>Details</summary>
Motivation: 竞争编程中的问题需要复杂的算法思维、解谜和有效代码的创建，但作为评估语言模型的领域，它尚未得到足够的关注。

Method: 我们开发并评估了多种语言模型推理技术，并结合多轮自我判断、反思和回忆情节信息的检索来提高解决竞赛编程问题的能力。

Result: 使用零样本链式思维提示，o1仅达到19.1%的pass@1解决率。通过最佳推理技术，这一数字提高到了42.2%。此外，我们发现o1在一些特定指令下可以解决之前任何模型或技术都无法解决的问题。

Conclusion: 我们的定量结果和定性研究为具有基础、有想象力和算法思维的语言模型提供了一个踏出的一步。

Abstract: Among the hardest tasks for humans are those found in competitive programming
where problems require sophisticated algorithmic thinking, puzzle solving, and
the creation of effective code. As a domain to assess language models (LMs), it
has not received enough attention, though. This study presents the ICPC
benchmark, which consists of 254 international collegiate programming contest
(ICPC) tasks. Each problem includes official analysis, reference code, and
sample, high-quality unit, and hidden tests. We are able to develop and
evaluate a variety of LM inference techniques for competitive programming with
these resources. With zero-shot chain-of-thought prompting, we find that o1
only achieves a 19.1\% pass@1 solve rate. With our best inference technique,
which combines multi-turn self-judge with reflection and retrieval over
episodic information, raises this to 42.2\%. Furthermore, we conduct a new
human-in-the-loop investigation to gain a deeper understanding of the remaining
difficulties. Surprisingly, we discover that o1 can solve 17 out of 18 problems
that were previously unsolvable by any model or technique with just a few
specific instructions. A footstep toward LMs with grounded, imaginative, and
algorithmic thinking is provided by our quantitative findings and qualitative
research. We open-source our code and data at https://github.com/kraritt/zolve.

</details>


### [30] [Confident, Calibrated, or Complicit: Probing the Trade-offs between Safety Alignment and Ideological Bias in Language Models in Detecting Hate Speech](https://arxiv.org/abs/2509.00673)
*Sanjeeevan Selvaganapathy,Mehwish Nasim*

Main category: cs.CL

TL;DR: 研究发现过滤模型在仇恨言论检测任务中表现更好，但其意识形态锚定使其难以接受基于角色的影响，同时所有模型在处理复杂语言方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨未经安全对齐的模型是否能提供比高度对齐的模型更客观的分类能力。

Method: 研究比较了未经安全对齐（未过滤）和高度对齐（过滤）的大型语言模型在检测隐性和显性仇恨言论方面的效果。

Result: 研究结果显示，过滤模型在准确性和鲁棒性方面显著优于未过滤模型，但在面对意识形态影响时表现出较强的抵抗性，而未过滤模型则更容易受到意识形态的影响。此外，所有模型在理解讽刺等复杂语言方面存在重大失败，并且在不同目标群体之间表现出明显的公平性差异。

Conclusion: 研究结果挑战了LLMs作为客观仲裁者的观念，并强调了需要更复杂的审计框架来考虑公平性、校准和意识形态一致性。

Abstract: We investigate the efficacy of Large Language Models (LLMs) in detecting
implicit and explicit hate speech, examining whether models with minimal safety
alignment (uncensored) might provide more objective classification capabilities
compared to their heavily-aligned (censored) counterparts. While uncensored
models theoretically offer a less constrained perspective free from moral
guardrails that could bias classification decisions, our results reveal a
surprising trade-off: censored models significantly outperform their uncensored
counterparts in both accuracy and robustness, achieving 78.7% versus 64.1%
strict accuracy. However, this enhanced performance comes with its own
limitation -- the safety alignment acts as a strong ideological anchor, making
censored models resistant to persona-based influence, while uncensored models
prove highly malleable to ideological framing. Furthermore, we identify
critical failures across all models in understanding nuanced language such as
irony. We also find alarming fairness disparities in performance across
different targeted groups and systemic overconfidence that renders
self-reported certainty unreliable. These findings challenge the notion of LLMs
as objective arbiters and highlight the need for more sophisticated auditing
frameworks that account for fairness, calibration, and ideological consistency.

</details>


### [31] [Router Upcycling: Leveraging Mixture-of-Routers in Mixture-of-Experts Upcycling](https://arxiv.org/abs/2509.00679)
*Junfeng Ran,Guangxiang Zhao,Yuhan Wu,Dawei Zhu,Longyun Wu,Yikai Zhao,Tong Yang,Lin Sun,Xiangzheng Zhang,Sujian Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为Router Upcycling的新路由技术，用于提升MoE upcycling模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的简单路由器（如线性路由器）在MoE upcycling中难以处理复杂的路由任务，因此需要一种更有效的路由技术。

Method: 我们提出了一种称为Router Upcycling的新路由技术，该技术从前期注意力层的注意力头初始化多个路由器，并以类似注意力的方式协作将标记分配给专业专家。

Result: 实验结果表明，我们的方法在MoE upcycling模型中实现了最先进的性能，优于其他upcycling基线。

Conclusion: 我们的方法在MoE upcycling模型中实现了最先进的性能，优于其他upcycling基线。

Abstract: The Mixture-of-Experts (MoE) models have gained significant attention in deep
learning due to their dynamic resource allocation and superior performance
across diverse tasks. However, efficiently training these models remains
challenging. The MoE upcycling technique has been proposed to reuse and improve
existing model components, thereby minimizing training overhead. Despite this,
simple routers, such as linear routers, often struggle with complex routing
tasks within MoE upcycling. In response, we propose a novel routing technique
called Router Upcycling to enhance the performance of MoE upcycling models. Our
approach initializes multiple routers from the attention heads of preceding
attention layers during upcycling. These routers collaboratively assign tokens
to specialized experts in an attention-like manner. Each token is processed
into diverse queries and aligned with the experts' features (serving as keys).
Experimental results demonstrate that our method achieves state-of-the-art
(SOTA) performance, outperforming other upcycling baselines.

</details>


### [32] [Do small language models generate realistic variable-quality fake news headlines?](https://arxiv.org/abs/2509.00680)
*Austin McCutcheon,Chris Brogly*

Main category: cs.CL

TL;DR: 该研究评估了14个SLMs在生成虚假新闻标题时的表现，发现它们具有高合规性，但质量检测准确率较低。


<details>
  <summary>Details</summary>
Motivation: 评估小型语言模型（SLMs）在生成看似低质量和高质量的虚假新闻标题时的表现，以及它们是否与现实世界中的新闻标题相似。

Method: 使用受控提示工程生成了24,000个低质量和高质量的虚假新闻标题，并应用了现有的基于机器学习和深度学习的新闻标题质量检测器来评估这些SLM生成的虚假新闻标题。

Result: SLMs表现出高合规率，几乎没有伦理阻力，但有时会有例外。使用现有的DistilBERT和集成分类器模型进行的标题质量检测表明，质量误分类很常见，检测准确率仅在35.2%到63.5%之间。

Conclusion: 测试的SLM通常在生成虚假标题方面是合规的，尽管在道德限制上有一些轻微的差异，生成的标题与现有主要由人类撰写的网络内容不太相似，因为质量分类的准确性较低。

Abstract: Small language models (SLMs) have the capability for text generation and may
potentially be used to generate falsified texts online. This study evaluates 14
SLMs (1.7B-14B parameters) including LLaMA, Gemma, Phi, SmolLM, Mistral, and
Granite families in generating perceived low and high quality fake news
headlines when explicitly prompted, and whether they appear to be similar to
real-world news headlines. Using controlled prompt engineering, 24,000
headlines were generated across low-quality and high-quality deceptive
categories. Existing machine learning and deep learning-based news headline
quality detectors were then applied against these SLM-generated fake news
headlines. SLMs demonstrated high compliance rates with minimal ethical
resistance, though there were some occasional exceptions. Headline quality
detection using established DistilBERT and bagging classifier models showed
that quality misclassification was common, with detection accuracies only
ranging from 35.2% to 63.5%. These findings suggest the following: tested SLMs
generally are compliant in generating falsified headlines, although there are
slight variations in ethical restraints, and the generated headlines did not
closely resemble existing primarily human-written content on the web, given the
low quality classification accuracy.

</details>


### [33] [Text Reinforcement for Multimodal Time Series Forecasting](https://arxiv.org/abs/2509.00687)
*Chen Su,Yuanhe Tian,Yan Song,Yongdong Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种文本增强模型（TeR），用于生成解决原始文本潜在弱点的增强文本，然后将此增强文本应用于支持多模态TSF模型对时间序列的理解，从而提高TSF性能。通过设计一种基于强化学习的方法，根据每段增强文本对多模态TSF模型性能及其与TSF任务的相关性的影响来分配奖励，优化TeR以提高生成增强文本的质量并增强TSF性能。在真实世界基准数据集上的实验表明，我们的方法有效且优于现有研究。


<details>
  <summary>Details</summary>
Motivation: 最近的研究在时间序列预测（TSF）中使用多模态输入，如文本和历史时间序列数据，以预测未来值。这些研究主要集中在开发先进的技术来整合文本信息与时间序列数据以执行任务并取得有希望的结果。然而，这些方法依赖于高质量的文本和时间序列输入，而在某些情况下，文本不能准确或完整地捕捉历史时间序列所携带的信息，这导致多模态TSF的性能不稳定。因此，有必要增强文本内容以提高多模态TSF的性能。

Method: 我们提出了一种文本增强模型（TeR），用于生成解决原始文本潜在弱点的增强文本，然后将此增强文本应用于支持多模态TSF模型对时间序列的理解，从而提高TSF性能。我们设计了一种基于强化学习的方法，根据每段增强文本对多模态TSF模型性能及其与TSF任务的相关性的影响来分配奖励。

Result: 我们在一个涵盖多个领域的现实世界基准数据集上进行了广泛的实验，证明了我们方法的有效性，并且在该数据集上优于强基线和现有研究。

Conclusion: 我们的方法在真实世界基准数据集上进行了广泛的实验，证明了其有效性，并优于强基线和现有研究。

Abstract: Recent studies in time series forecasting (TSF) use multimodal inputs, such
as text and historical time series data, to predict future values. These
studies mainly focus on developing advanced techniques to integrate textual
information with time series data to perform the task and achieve promising
results. Meanwhile, these approaches rely on high-quality text and time series
inputs, whereas in some cases, the text does not accurately or fully capture
the information carried by the historical time series, which leads to unstable
performance in multimodal TSF. Therefore, it is necessary to enhance the
textual content to improve the performance of multimodal TSF. In this paper, we
propose improving multimodal TSF by reinforcing the text modalities. We propose
a text reinforcement model (TeR) to generate reinforced text that addresses
potential weaknesses in the original text, then apply this reinforced text to
support the multimodal TSF model's understanding of the time series, improving
TSF performance. To guide the TeR toward producing higher-quality reinforced
text, we design a reinforcement learning approach that assigns rewards based on
the impact of each reinforced text on the performance of the multimodal TSF
model and its relevance to the TSF task. We optimize the TeR accordingly, so as
to improve the quality of the generated reinforced text and enhance TSF
performance. Extensive experiments on a real-world benchmark dataset covering
various domains demonstrate the effectiveness of our approach, which
outperforms strong baselines and existing studies on the dataset.

</details>


### [34] [CE-Bench: Towards a Reliable Contrastive Evaluation Benchmark of Interpretability of Sparse Autoencoders](https://arxiv.org/abs/2509.00691)
*Alex Gulko,Yusen Peng,Sachin Kumar*

Main category: cs.CL

TL;DR: 本文介绍了 CE-Bench，一个用于稀疏自编码器的轻量级对比评估基准，能够可靠地衡量其可解释性。


<details>
  <summary>Details</summary>
Motivation: 缺乏自动化评估方法阻碍了稀疏自编码器的更广泛应用和发展。

Method: 引入 CE-Bench，这是一个基于对比故事对数据集的轻量级对比评估基准。

Result: CE-Bench 可靠地衡量了稀疏自编码器的可解释性，并且与现有基准一致，而无需外部 LLM。

Conclusion: CE-Bench 可靠地衡量了稀疏自编码器的可解释性，并且与现有基准一致，而无需外部 LLM。

Abstract: Probing with sparse autoencoders is a promising approach for uncovering
interpretable features in large language models (LLMs). However, the lack of
automated evaluation methods has hindered their broader adoption and
development. In this work, we introduce CE-Bench, a novel and lightweight
contrastive evaluation benchmark for sparse autoencoders, built on a curated
dataset of contrastive story pairs. We conduct comprehensive ablation studies
to validate the effectiveness of our approach. Our results show that CE-Bench
reliably measures the interpretability of sparse autoencoders and aligns well
with existing benchmarks, all without requiring an external LLM. The official
implementation and evaluation dataset are open-sourced under the MIT License.

</details>


### [35] [Learning to Shop Like Humans: A Review-driven Retrieval-Augmented Recommendation Framework with LLMs](https://arxiv.org/abs/2509.00698)
*Kaiwen Wei,Jinpeng Gao,Jiang Zhong,Yuming Yang,Fengmao Lv,Zhenyang Li*

Main category: cs.CL

TL;DR: RevBrowse is a review-driven recommendation framework that enhances LLM-based recommendation by integrating user reviews into the reranking process. It introduces PrefRAG, a retrieval-augmented module that improves the relevance and efficiency of review usage. Experiments show that RevBrowse achieves consistent and significant improvements over baselines, offering interpretability by showing which reviews influence recommendations.


<details>
  <summary>Details</summary>
Motivation: Effectively incorporating reviews into LLM-based recommendation remains challenging due to (1) inefficient to dynamically utilize user reviews under LLMs' constrained context windows, and (2) lacking effective mechanisms to prioritize reviews most relevant to the user's current decision context.

Method: RevBrowse, a review-driven recommendation framework inspired by the 'browse-then-decide' decision process commonly observed in online user behavior. RevBrowse integrates user reviews into the LLM-based reranking process to enhance its ability to distinguish between candidate items. To improve the relevance and efficiency of review usage, we introduce PrefRAG, a retrieval-augmented module that disentangles user and item representations into structured forms and adaptively retrieves preference-relevant content conditioned on the target item.

Result: Extensive experiments on four Amazon review datasets demonstrate that RevBrowse achieves consistent and significant improvements over strong baselines, highlighting its generalizability and effectiveness in modeling dynamic user preferences.

Conclusion: RevBrowse achieves consistent and significant improvements over strong baselines, highlighting its generalizability and effectiveness in modeling dynamic user preferences. Furthermore, since the retrieval-augmented process is transparent, RevBrowse offers a certain level of interpretability by making visible which reviews influence the final recommendation.

Abstract: Large language models (LLMs) have shown strong potential in recommendation
tasks due to their strengths in language understanding, reasoning and knowledge
integration. These capabilities are especially beneficial for review-based
recommendation, which relies on semantically rich user-generated texts to
reveal fine-grained user preferences and item attributes. However, effectively
incorporating reviews into LLM-based recommendation remains challenging due to
(1) inefficient to dynamically utilize user reviews under LLMs' constrained
context windows, and (2) lacking effective mechanisms to prioritize reviews
most relevant to the user's current decision context. To address these
challenges, we propose RevBrowse, a review-driven recommendation framework
inspired by the "browse-then-decide" decision process commonly observed in
online user behavior. RevBrowse integrates user reviews into the LLM-based
reranking process to enhance its ability to distinguish between candidate
items. To improve the relevance and efficiency of review usage, we introduce
PrefRAG, a retrieval-augmented module that disentangles user and item
representations into structured forms and adaptively retrieves
preference-relevant content conditioned on the target item. Extensive
experiments on four Amazon review datasets demonstrate that RevBrowse achieves
consistent and significant improvements over strong baselines, highlighting its
generalizability and effectiveness in modeling dynamic user preferences.
Furthermore, since the retrieval-augmented process is transparent, RevBrowse
offers a certain level of interpretability by making visible which reviews
influence the final recommendation.

</details>


### [36] [Reward-Weighted Sampling: Enhancing Non-Autoregressive Characteristics in Masked Diffusion LLMs](https://arxiv.org/abs/2509.00707)
*Daehoon Gwak,Minseo Jung,Junwoo Park,Minho Park,ChaeHun Park,Junha Hyung,Jaegul Choo*

Main category: cs.CL

TL;DR: 本文提出了一种新的解码策略Reward-Weighted Sampling (RWS)，通过利用外部奖励模型来改善非自回归生成顺序，实验结果显示该方法有效提升了MDMs的性能。


<details>
  <summary>Details</summary>
Motivation: 标准的MDMs解码方法在每个扩散步骤中基于单个标记的置信度独立选择标记，这导致生成顺序类似于序列自回归过程，限制了非自回归建模的优势。

Method: 提出了一种新的解码策略Reward-Weighted Sampling (RWS)，利用外部奖励模型在迭代扩散过程中提供一个原则性的全局信号。

Result: RWS显著促进了非自回归生成顺序，多个评估指标均有改进。

Conclusion: 实验结果表明，RWS在提升非自回归生成顺序方面效果显著，提高了MDMs的非自回归特性和整体性能。

Abstract: Masked diffusion models (MDMs) offer a promising non-autoregressive
alternative for large language modeling. Standard decoding methods for MDMs,
such as confidence-based sampling, select tokens independently based on
individual token confidences at each diffusion step. However, we observe that
this independent token selection often results in generation orders resembling
sequential autoregressive processes, limiting the advantages of
non-autoregressive modeling. To mitigate this pheonomenon, we propose
Reward-Weighted Sampling (RWS), a novel decoding strategy that leverages an
external reward model to provide a principled global signal during the
iterative diffusion process. Specifically, at each diffusion step, RWS
evaluates the quality of the entire intermediate sequence and scales token
logits accordingly, guiding token selection by integrating global
sequence-level coherence. This method selectively increases the confidence of
tokens that initially have lower scores, thereby promoting a more
non-autoregressive generation order. Furthermore, we provide theoretical
justification showing that reward-weighted logit scaling induces beneficial
rank reversals in token selection and consistently improves expected reward.
Experiments demonstrate that RWS significantly promotes non-autoregressive
generation orders, leading to improvements across multiple evaluation metrics.
These results highlight the effectiveness of integrating global signals in
enhancing both the non-autoregressive properties and overall performance of
MDMs.

</details>


### [37] [Designing LMS and Instructional Strategies for Integrating Generative-Conversational AI](https://arxiv.org/abs/2509.00709)
*Elias Ra,Seung Je Kim,Eui-Yeong Seo,Geunju So*

Main category: cs.CL

TL;DR: 本研究介绍了一个结构化的框架，用于设计一个AI-powered Learning Management System (AI-LMS)，该系统整合了生成和对话AI，以支持自适应、互动和以学习者为中心的教学。


<details>
  <summary>Details</summary>
Motivation: 高等教育面临提供个性化、可扩展和教学连贯的学习体验的挑战。本研究旨在引入一种结构化的框架，以设计一个AI驱动的学习管理系统（AI-LMS）。

Method: 本研究采用基于设计的研究（DBR）方法，框架分为五个阶段：文献综述、SWOT分析、制定伦理-教学原则、系统设计和教学策略制定。

Result: 所提出的AI-LMS具有模块化组件，包括可配置提示、自适应反馈循环和多代理对话流程，与行为主义、建构主义和连接主义学习理论等教学范式相一致。

Conclusion: 本研究提出了一种结构化的框架，用于设计一个集成生成和对话AI的AI-LMS，以支持自适应、互动和以学习者为中心的教学。通过结合AI能力与以人为本的设计和伦理保障，该研究推进了教育中AI整合的实用模型。

Abstract: Higher education faces growing challenges in delivering personalized,
scalable, and pedagogically coherent learning experiences. This study
introduces a structured framework for designing an AI-powered Learning
Management System (AI-LMS) that integrates generative and conversational AI to
support adaptive, interactive, and learner-centered instruction. Using a
design-based research (DBR) methodology, the framework unfolds through five
phases: literature review, SWOT analysis, development of ethical-pedagogical
principles, system design, and instructional strategy formulation. The
resulting AI-LMS features modular components -- including configurable prompts,
adaptive feedback loops, and multi-agent conversation flows -- aligned with
pedagogical paradigms such as behaviorist, constructivist, and connectivist
learning theories. By combining AI capabilities with human-centered design and
ethical safeguards, this study advances a practical model for AI integration in
education. Future research will validate and refine the system through
real-world implementation.

</details>


### [38] [LLM Encoder vs. Decoder: Robust Detection of Chinese AI-Generated Text with LoRA](https://arxiv.org/abs/2509.00731)
*Houji Jin,Negin Ashrafi,Armin Abdollahi,Wei Liu,Jian Wang,Ganyu Gui,Maryam Pishgar,Huanghao Feng*

Main category: cs.CL

TL;DR: 研究比较了不同模型在中文AI生成文本检测任务中的表现，发现基于解码器的LLM经过参数高效微调后表现优异，未来将探索更多方法以提高跨领域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的迅速发展，对AI生成文本的准确检测需求日益增加，特别是在中文等语言中，细微的语言特征对现有方法构成重大挑战。

Method: 研究比较了基于编码器的Transformer（如Chinese BERT-large和RoBERTa-wwm-ext-large）、仅解码器的LLM（如Alibaba的Qwen2.5-7B/DeepSeek-R1-Distill-Qwen-7B通过LoRA进行微调）以及FastText基线模型。编码器模型使用了一种基于提示的掩码语言建模方法进行微调，而Qwen2.5-7B则通过指令格式输入和轻量级分类头进行分类训练。

Result: 实验结果显示，尽管编码器模型几乎记住了训练数据，但在分布变化下性能显著下降（RoBERTa: 76.3%测试准确率；BERT: 79.3%）。FastText表现出令人惊讶的词汇鲁棒性（83.5%准确率），但缺乏更深层次的语义理解。相比之下，经过LoRA微调的Qwen2.5-7B在测试中达到了95.94%的准确率，具有平衡的精确率-召回率指标，表明其具有优越的泛化能力和对数据集特定特征的抗性。

Conclusion: 研究结果表明，经过参数高效微调的基于解码器的LLM在稳健的中文AI生成文本检测中表现出色。未来的工作将探索下一代Qwen3模型、蒸馏变体和集成策略以进一步提高跨领域鲁棒性。

Abstract: The rapid growth of large language models (LLMs) has heightened the demand
for accurate detection of AI-generated text, particularly in languages like
Chinese, where subtle linguistic nuances pose significant challenges to current
methods. In this study, we conduct a systematic comparison of encoder-based
Transformers (Chinese BERT-large and RoBERTa-wwm-ext-large), a decoder-only LLM
(Alibaba's Qwen2.5-7B/DeepSeek-R1-Distill-Qwen-7B fine-tuned via Low-Rank
Adaptation, LoRA), and a FastText baseline using the publicly available dataset
from the NLPCC 2025 Chinese AI-Generated Text Detection Task. Encoder models
were fine-tuned using a novel prompt-based masked language modeling approach,
while Qwen2.5-7B was adapted for classification with an instruction-format
input and a lightweight classification head trained via LoRA. Experiments
reveal that although encoder models nearly memorize training data, they suffer
significant performance degradation under distribution shifts (RoBERTa: 76.3%
test accuracy; BERT: 79.3%). FastText demonstrates surprising lexical
robustness (83.5% accuracy) yet lacks deeper semantic understanding. In
contrast, the LoRA-adapted Qwen2.5-7B achieves 95.94% test accuracy with
balanced precision-recall metrics, indicating superior generalization and
resilience to dataset-specific artifacts. These findings underscore the
efficacy of decoder-based LLMs with parameter-efficient fine-tuning for robust
Chinese AI-generated text detection. Future work will explore next-generation
Qwen3 models, distilled variants, and ensemble strategies to enhance
cross-domain robustness further.

</details>


### [39] [Decomposing and Revising What Language Models Generate](https://arxiv.org/abs/2509.00765)
*Zhichao Yan,Jiaoyan Chen,Jiapu Wang,Xiaoli Li,Ru Li,Jeff Z. Pan*

Main category: cs.CL

TL;DR: FIDES is a new fact decomposition-based framework for attributed QA that improves the accuracy of evidence retrieval and aggregation.


<details>
  <summary>Details</summary>
Motivation: Attribution is crucial in question answering (QA) with Large Language Models (LLMs).SOTA question decomposition-based approaches use long form answers to generate questions for retrieving related documents. However, the generated questions are often irrelevant and incomplete, resulting in a loss of facts in retrieval. These approaches also fail to aggregate evidence snippets from different documents and paragraphs.

Method: FIDES uses a contextually enhanced two-stage faithful decomposition method to decompose long form answers into sub-facts, which are then used by a retriever to retrieve related evidence snippets. If the retrieved evidence snippets conflict with the related sub-facts, such sub-facts will be revised accordingly. Finally, the evidence snippets are aggregated according to the original sentences.

Result: Extensive evaluation has been conducted with six datasets, with an additionally proposed new metric called $Attr_{auto-P}$ for evaluating the evidence precision.

Conclusion: FIDES outperforms the SOTA methods by over 14% in average with GPT-3.5-turbo, Gemini and Llama 70B series.

Abstract: Attribution is crucial in question answering (QA) with Large Language Models
(LLMs).SOTA question decomposition-based approaches use long form answers to
generate questions for retrieving related documents. However, the generated
questions are often irrelevant and incomplete, resulting in a loss of facts in
retrieval.These approaches also fail to aggregate evidence snippets from
different documents and paragraphs. To tackle these problems, we propose a new
fact decomposition-based framework called FIDES (\textit{faithful context
enhanced fact decomposition and evidence aggregation}) for attributed QA. FIDES
uses a contextually enhanced two-stage faithful decomposition method to
decompose long form answers into sub-facts, which are then used by a retriever
to retrieve related evidence snippets. If the retrieved evidence snippets
conflict with the related sub-facts, such sub-facts will be revised
accordingly. Finally, the evidence snippets are aggregated according to the
original sentences.Extensive evaluation has been conducted with six datasets,
with an additionally proposed new metric called $Attr_{auto-P}$ for evaluating
the evidence precision. FIDES outperforms the SOTA methods by over 14\% in
average with GPT-3.5-turbo, Gemini and Llama 70B series.

</details>


### [40] [LegalChainReasoner: A Legal Chain-guided Framework for Criminal Judicial Opinion Generation](https://arxiv.org/abs/2509.00783)
*Weizhe Shi,Qiqi Wang,Yihong Pan,Qian Liu,Kaiqi Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种新的司法意见生成任务，并通过LegalChainReasoner框架实现了法律推理和量刑决策的同时生成，实验结果证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前研究通常将自动生成司法意见的任务分为两个孤立的子任务：法律推理和量刑预测，这种分离导致推理和预测之间的一致性不足，无法满足现实世界的司法需求。此外，先前的研究依赖于手动整理的知识来增强适用性，但这些方法在实际部署中仍然有限。

Method: 引入LegalChainReasoner框架，应用结构化的法律链条引导模型进行全面的案件评估，并整合事实前提、复合法律条件和量刑结论，实现灵活的知识注入和端到端的意见生成。

Result: 在两个真实世界且开源的中国法律案例数据集上的实验表明，我们的方法优于基线模型。

Conclusion: 本文提出了一种新的LegalAI任务：司法意见生成，通过LegalChainReasoner框架同时生成法律推理和量刑决定，实验表明该方法优于基线模型。

Abstract: A criminal judicial opinion represents the judge's disposition of a case,
including the decision rationale and sentencing. Automatically generating such
opinions can assist in analyzing sentencing consistency and provide judges with
references to similar past cases. However, current research typically
approaches this task by dividing it into two isolated subtasks: legal reasoning
and sentencing prediction. This separation often leads to inconsistency between
the reasoning and predictions, failing to meet real-world judicial
requirements. Furthermore, prior studies rely on manually curated knowledge to
enhance applicability, yet such methods remain limited in practical deployment.
To address these limitations and better align with legal practice, we propose a
new LegalAI task: Judicial Opinion Generation, which simultaneously produces
both legal reasoning and sentencing decisions. To achieve this, we introduce
LegalChainReasoner, a framework that applies structured legal chains to guide
the model through comprehensive case assessments. By integrating factual
premises, composite legal conditions, and sentencing conclusions, our approach
ensures flexible knowledge injection and end-to-end opinion generation.
Experiments on two real-world and open-source Chinese legal case datasets
demonstrate that our method outperforms baseline models.

</details>


### [41] [CaresAI at BioCreative IX Track 1 -- LLM for Biomedical QA](https://arxiv.org/abs/2509.00806)
*Reem Abdel-Salam,Mary Adewunmi,Modinat A. Abayomi*

Main category: cs.CL

TL;DR: 本文研究了生物医学多跳问答任务中大型语言模型的表现，发现其在语义理解方面表现良好，但在精确答案评估方面仍有不足，并提出了两阶段推理流水线来改善这一问题。


<details>
  <summary>Details</summary>
Motivation: 在将大型语言模型部署到实际的生物医学和医疗保健应用之前，需要对其在复杂问题回答能力上的性能进行严格的评估。

Method: 我们采用了一种监督微调策略，利用LLaMA 3 8B，并增强了从外部来源（包括BioASQ、MedQuAD和TREC）编译的生物医学问答数据集。我们探索了三种实验设置：在组合短答案和长答案上进行微调、仅在短答案上进行微调以及仅在长答案上进行微调。此外，我们引入了一个两阶段的推理流水线，以精确提取短答案。

Result: 我们的模型展示了强大的领域理解能力，达到了最高0.8的概念级准确率分数，但它们的Exact Match (EM)分数在测试阶段仍然显著较低。尽管部分改进，生成严格格式化输出的挑战依然存在。

Conclusion: 我们的研究突显了生物医学大语言模型在语义理解与精确答案评估之间的差距，并激发了对输出控制和后处理策略的进一步研究。

Abstract: Large language models (LLMs) are increasingly evident for accurate question
answering across various domains. However, rigorous evaluation of their
performance on complex question-answering (QA) capabilities is essential before
deployment in real-world biomedical and healthcare applications. This paper
presents our approach to the MedHopQA track of the BioCreative IX shared task,
which focuses on multi-hop biomedical question answering involving diseases,
genes, and chemicals. We adopt a supervised fine-tuning strategy leveraging
LLaMA 3 8B, enhanced with a curated biomedical question-answer dataset compiled
from external sources including BioASQ, MedQuAD, and TREC. Three experimental
setups are explored: fine-tuning on combined short and long answers, short
answers only, and long answers only. While our models demonstrate strong domain
understanding, achieving concept-level accuracy scores of up to 0.8, their
Exact Match (EM) scores remain significantly lower, particularly in the test
phase. We introduce a two-stage inference pipeline for precise short-answer
extraction to mitigate verbosity and improve alignment with evaluation metrics.
Despite partial improvements, challenges persist in generating strictly
formatted outputs. Our findings highlight the gap between semantic
understanding and exact answer evaluation in biomedical LLM applications,
motivating further research in output control and post-processing strategies.

</details>


### [42] [TMT: A Simple Way to Translate Topic Models Using Dictionaries](https://arxiv.org/abs/2509.00822)
*Felix Engl,Andreas Henrich*

Main category: cs.CL

TL;DR: 本文介绍了TMT，一种无需元数据、嵌入或对齐语料库即可将主题模型从一种语言转移到另一种语言的技术，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在多语言环境中训练主题模型是一项具有挑战性的任务，尤其是在开发者不了解目标语言或在数据有限的环境中工作时，可用的多语言语料库可能很小或无法使用。

Method: TMT是一种新颖、稳健且透明的技术，用于将基于LDA的主题模型从一种语言转移到另一种语言，无需元数据、嵌入或对齐语料库。

Result: TMT经过了定量和定性方法的广泛评估，证明它能够产生语义连贯且一致的主题翻译。

Conclusion: TMT能够有效地将主题模型从一种语言转移到另一种语言，无需元数据、嵌入或对齐语料库，适用于大规模语料库不可用或人工翻译不可行的场景。

Abstract: The training of topic models for a multilingual environment is a challenging
task, requiring the use of sophisticated algorithms, topic-aligned corpora, and
manual evaluation. These difficulties are further exacerbated when the
developer lacks knowledge of the target language or is working in an
environment with limited data, where only small or unusable multilingual
corpora are available.
  Considering these challenges, we introduce Topic Model Translation (TMT), a
novel, robust and transparent technique designed to transfer topic models
(e.g., Latent Dirichlet Allocation (LDA) based topic models) from one language
to another, without the need for metadata, embeddings, or aligned corpora. TMT
enables the reuse of topic models across languages, making it especially
suitable for scenarios where large corpora in the target language are
unavailable or manual translation is infeasible. Furthermore, we evaluate TMT
extensively using both quantitative and qualitative methods, demonstrating that
it produces semantically coherent and consistent topic translations.

</details>


### [43] [Neural Models and Language Model Prompting for the Multidimensional Evaluation of Open-Ended Conversations](https://arxiv.org/abs/2509.00841)
*Michelle Elizabeth,Alicja Kasicka,Natalia Krawczyk,Magalie Ochs,Gwénolé Lecorvé,Justyna Gromada,Lina M. Rojas-Barahona*

Main category: cs.CL

TL;DR: 本文通过DSTC-12, Track 1挑战，提出了两种策略来评估生成式AI对话系统：使用语言模型作为评估者和训练基于编码器的分类和回归模型。结果表明，尽管测试集的评分范围有所不同，但基于编码器的模型在某些维度上表现良好。


<details>
  <summary>Details</summary>
Motivation: 随着基于生成式AI的对话系统的数量不断增加，其评估成为一个关键挑战。本文旨在解决这一重要问题。

Method: 本文采用了两种主要策略：通过提示使用语言模型（LMs）作为评估者，以及训练基于编码器的分类和回归模型。

Result: LM提示仅与人类判断有适度的相关性，但在测试集上排名第二，仅被基线模型超越。基于编码器的分类和回归模型在验证集上对某些维度表现出高相关性，尽管在测试集上的性能有所下降。

Conclusion: 本文通过在DSTC-12, Track 1中开发模型来预测对话级别的、维度特定的评分，为生成式AI对话系统的评估提供了贡献。尽管测试集中的注释在某些维度上的评分范围与训练集和验证集有显著不同，但结果表明基于编码器的分类和回归模型在某些维度上表现出高相关性。

Abstract: The growing number of generative AI-based dialogue systems has made their
evaluation a crucial challenge. This paper presents our contribution to this
important problem through the Dialogue System Technology Challenge (DSTC-12,
Track 1), where we developed models to predict dialogue-level,
dimension-specific scores. Given the constraint of using relatively small
models (i.e. fewer than 13 billion parameters) our work follows two main
strategies: employing Language Models (LMs) as evaluators through prompting,
and training encoder-based classification and regression models.
  Our results show that while LM prompting achieves only modest correlations
with human judgments, it still ranks second on the test set, outperformed only
by the baseline. The regression and classification models, with significantly
fewer parameters, demonstrate high correlation for some dimensions on the
validation set. Although their performance decreases on the test set, it is
important to note that the test set contains annotations with significantly
different score ranges for some of the dimensions with respect to the train and
validation sets.

</details>


### [44] [Negative Matters: Multi-Granularity Hard-Negative Synthesis and Anchor-Token-Aware Pooling for Enhanced Text Embeddings](https://arxiv.org/abs/2509.00842)
*Tengyu Pan,Zhichao Duan,Zhenyu Li,Bowen Dong,Ning Liu,Xiuxing Li,Jianyong Wang*

Main category: cs.CL

TL;DR: 本文介绍了一种多粒度硬负样本合成框架和一种锚定标记感知池化方法，以提高文本嵌入模型的性能。


<details>
  <summary>Details</summary>
Motivation: 文本嵌入模型对于各种自然语言处理任务至关重要，通常通过三元组（查询、正例、负例）数据对进行对比学习优化，其中负例在增强模型辨别细微语义差异的能力方面起着关键作用。

Method: 我们引入了一个多粒度硬负样本（MGH）合成框架，利用大型语言模型（LLMs）生成与查询不同相似度的多样负样本。同时，我们提出了一种锚定标记感知（ATA）池化方法，根据LLMs中的聚合模式为锚定标记分配更高的权重，从而提高文本嵌入准确性而不增加模型复杂性。

Result: 综合实验表明，我们的方法在MTEB基准测试中实现了最先进的性能，超越了现有的合成策略，无论是使用合成数据还是与公共检索数据集结合。

Conclusion: 我们的方法在MTEB基准测试中实现了最先进的性能，超越了现有的合成策略，无论是使用合成数据还是与公共检索数据集结合。

Abstract: Text embedding models are essential for various natural language processing
tasks, enabling the effective encoding of semantic information into dense
vector representations. These models are typically optimized using triplets of
(query, positive, negative) data pairs for contrastive learning, where the
negative samples play a critical role in enhancing the model's ability to
discern subtle semantic distinctions. In this work, we introduce a
Multi-Granularity Hard-negative (MGH) synthesis framework that leverages large
language models (LLMs) to generate diverse negative samples with varying levels
of similarity with the query. This approach facilitates a coarse-to-fine
curriculum learning strategy during supervised training, allowing the embedding
model to progressively learn more nuanced semantic representations. Meanwhile,
we propose an Anchor Token Aware (ATA) pooling method that assigns higher
weights to anchor tokens based on aggregation patterns observed in LLMs,
improving text embedding accuracy without increasing model complexity.
Comprehensive experiments on the MTEB benchmark demonstrate that our methods
achieve state-of-the-art performance, surpassing existing synthesis strategies
both with synthetic data and when combined with public retrieval datasets.

</details>


### [45] [Prompting Away Stereotypes? Evaluating Bias in Text-to-Image Models for Occupations](https://arxiv.org/abs/2509.00849)
*Shaina Raza,Maximus Powers,Partha Pratim Saha,Mahveen Raza,Rizwan Qureshi*

Main category: cs.CL

TL;DR: 研究评估了文本到图像模型在职业表现中的社会代表性偏见，并探索了通过提示来促进人口多样性的方法。结果显示，提示可以显著改变人口统计学表示，但效果因模型而异。


<details>
  <summary>Details</summary>
Motivation: 文本到图像（TTI）模型是强大的创意工具，但可能加剧有害的社会偏见。研究旨在评估社会代表性偏见，并探索通过提示来促进人口多样性的方法。

Method: 研究将社会代表性偏见评估框架化为图像整理和评估任务，并引入了一个涵盖五个社会显著角色（CEO、护士、软件工程师、教师、运动员）的职业表现试点基准。使用五种最先进的模型：封闭源代码（DALLE 3、Gemini Imagen 4.0）和开源（FLUX.1-dev、Stable Diffusion XL Turbo、Grok-2 Image），比较中性基线提示与公平意识控制提示，以鼓励人口多样性。所有输出都标注了性别（男性、女性）和种族（亚裔、黑人、白人），以进行结构化的分布分析。

Result: 结果表明，提示可以显著改变人口统计学表示，但效果因模型而异：一些系统能有效多样化，另一些则过度纠正成不现实的均匀性，还有一些几乎没有响应。

Conclusion: 研究结果表明，提示可以显著改变人口统计学表示，但效果因模型而异：一些系统能有效多样化，另一些则过度纠正成不现实的均匀性，还有一些几乎没有响应。这些发现突显了提示作为公平干预措施的潜力和局限性，强调了需要互补的模型级策略。

Abstract: Text-to-Image (TTI) models are powerful creative tools but risk amplifying
harmful social biases. We frame representational societal bias assessment as an
image curation and evaluation task and introduce a pilot benchmark of
occupational portrayals spanning five socially salient roles (CEO, Nurse,
Software Engineer, Teacher, Athlete). Using five state-of-the-art models:
closed-source (DALLE 3, Gemini Imagen 4.0) and open-source (FLUX.1-dev, Stable
Diffusion XL Turbo, Grok-2 Image), we compare neutral baseline prompts against
fairness-aware controlled prompts designed to encourage demographic diversity.
All outputs are annotated for gender (male, female) and race (Asian, Black,
White), enabling structured distributional analysis. Results show that
prompting can substantially shift demographic representations, but with highly
model-specific effects: some systems diversify effectively, others overcorrect
into unrealistic uniformity, and some show little responsiveness. These
findings highlight both the promise and the limitations of prompting as a
fairness intervention, underscoring the need for complementary model-level
strategies. We release all code and data for transparency and reproducibility
https://github.com/maximus-powers/img-gen-bias-analysis.

</details>


### [46] [Exploring and Mitigating Fawning Hallucinations in Large Language Models](https://arxiv.org/abs/2509.00869)
*Zixuan Shangguan,Yanjie Dong,Lanjun Wang,Xiaoyi Fan,Victor C. M. Leung,Xiping Hu*

Main category: cs.CL

TL;DR: 本文分析了大型语言模型中的fawning hallucinations现象，并提出了一种协作对比解码方法（CCD）来减轻这一问题。实验结果表明，该方法能够有效提升生成内容的真实性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在语言理解方面表现出色。然而，当LLMs使其输出与欺骗性和/或误导性提示对齐时，生成的响应可能会偏离事实信息。这种现象被称为fawning hallucinations，其中模型优先于输入的隐含观点而不是准确性和真实性。在本工作中，我们分析了各种自然语言处理任务中的fawning hallucinations，并为缓解fawning hallucinations定制了所谓的对比解码方法。

Method: 我们设计了两种范式来生成相应的欺骗性和/或误导性输入以诱导一致的fawning hallucinations。然后，我们提出了协作对比解码（CCD）来处理LLMs中的fawning hallucinations。通过对比诱导和转换中性输入之间的输出分布偏差，所提出的CCD可以在不需要额外训练的情况下减少对欺骗性和/或误导性信息的依赖。

Result: 广泛的实验表明，所提出的CCD可以有效缓解fawning hallucinations，并提高生成响应的真实性。

Conclusion: 实验表明，所提出的CCD可以有效缓解fawning hallucinations，并提高生成响应的真实性。

Abstract: Large language models (LLMs) have demonstrated exceptional proficiency in
language understanding. However, when LLMs align their outputs with deceptive
and/or misleading prompts, the generated responses could deviate from the de
facto information. Such observations are known as fawning hallucinations, where
the model prioritizes alignment with the input's implied perspective over
accuracy and truthfulness. In this work, we analyze fawning hallucinations in
various natural language processing tasks and tailor the so-termed contrastive
decoding method for fawning-hallucination mitigation. Specifically, we design
two paradigms to generate corresponding deceptive and/or misleading inputs for
the consistent fawning hallucinations induction. Then, we propose the
collaborative contrastive decoding (CCD) to handle the fawning hallucinations
across different tasks in LLMs. By contrasting the deviation in output
distribution between induced and transformed neutral inputs, the proposed CCD
can reduce reliance on deceptive and/or misleading information without
requiring additional training. Extensive experiments demonstrate that the
proposed CCD can effectively mitigate fawning hallucinations and improve the
factuality of the generated responses over various tasks.

</details>


### [47] [EviNote-RAG: Enhancing RAG Models via Answer-Supportive Evidence Notes](https://arxiv.org/abs/2509.00877)
*Yuqin Dai,Guoqing Wang,Yuan Wang,Kairan Dou,Kaichen Zhou,Zhanwei Zhang,Shuo Yang,Fei Tang,Jun Yin,Pengyu Zeng,Zhenzhe Ying,Can Yi,Changhua Meng,Yuchen Zhou,Yongliang Shen,Shuai Lu*

Main category: cs.CL

TL;DR: EviNote-RAG是一种基于代理的RAG框架，通过生成简洁的人类风格笔记并结合证据质量奖励，提高了开放域问答任务的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的retrieve--then--answer范式存在两个关键限制：(1)检索到的证据信号噪声比低，有用信息被无关内容掩盖；(2)在多跳推理中，不完整或嘈杂的段落会导致错误累积。

Method: EviNote-RAG引入了一个结构化的retrieve--note--answer流程，通过生成Supportive-Evidence Notes (SENs)来保留与答案相关的信息，并利用Evidence Quality Reward (EQR)来评估SENs是否逻辑上支持最终答案。

Result: EviNote-RAG在领域内和领域外的QA基准测试中均优于强基线模型，特别是在HotpotQA、Bamboogle和2Wiki数据集上分别实现了20%、40%和91%的F1分数提升。

Conclusion: EviNote-RAG在各种QA基准测试中表现出色，显示出更高的准确性和稳定性，并且在增强鲁棒性和效率方面取得了最先进的结果。

Abstract: Large Language Models (LLMs) empowered with retrieval mechanisms have
achieved strong progress in open-domain question answering (QA). Yet, the
conventional retrieve--then--answer paradigm often suffers from two key
limitations: (1) low signal-to-noise ratio in retrieved evidence, where useful
information is buried under irrelevant content, and (2) error accumulation in
multi-hop reasoning when incomplete or noisy passages are involved. To address
these challenges, we present EviNote-RAG, an agentic RAG framework that
introduces a structured retrieve--note--answer pipeline. Instead of directly
reasoning over raw retrievals, the model is trained to compose
Supportive-Evidence Notes (SENs), concise, human-like notes that preserve only
answer-relevant information, highlight uncertainty, and explicitly state when
no useful evidence exists. This distillation process is further reinforced by
the Evidence Quality Reward (EQR), an entailment-based signal that evaluates
whether SENs logically support the final answer. Together, SENs and EQR guide
the model toward faithful and robust reasoning, while reducing the impact of
noise. Experiments on in-domain and out-of-domain QA benchmarks show that
EviNote-RAG consistently outperforms strong baselines in accuracy,
generalization, and training stability. In particular, it achieves
state-of-the-art results while enhancing robustness and efficiency, yielding
relative F1 gains of 20\% on HotpotQA (+0.093), 40\% on Bamboogle (+0.151), and
91\% on 2Wiki (+0.256) via denser rewards and reduced verbosity.

</details>


### [48] [SeLeRoSa: Sentence-Level Romanian Satire Detection Dataset](https://arxiv.org/abs/2509.00893)
*Răzvan-Alexandru Smădu,Andreea Iuga,Dumitru-Clementin Cercel,Florin Pop*

Main category: cs.CL

TL;DR: 本文介绍了第一个针对罗马尼亚语讽刺检测的句子级数据集SeLeRoSa，并评估了基于大型语言模型的基线模型在零样本和微调设置中的表现，发现这些模型在句子级讽刺检测任务中存在局限性。


<details>
  <summary>Details</summary>
Motivation: 讽刺、反讽和讽刺是通常用于表达幽默和批评的技术，而不是欺骗；然而，它们有时可能被误认为是事实报道，类似于假新闻。这些技术可以以更细粒度的方式应用，允许讽刺信息被纳入新闻文章中。

Method: 我们评估了基于大型语言模型（LLMs）的多个基线模型，在零样本和微调设置中，以及基于变压器的基线模型。

Result: 我们引入了第一个针对罗马尼亚语讽刺检测的句子级数据集，称为SeLeRoSa。该数据集包含13,873个手动注释的句子，涵盖各种领域，包括社会问题、IT、科学和电影。随着大型语言模型（LLMs）在自然语言处理文献中的兴起和最近的进步，LLMs已经展示了处理各种任务的能力。

Conclusion: 我们的研究揭示了这些模型在句子级讽刺检测任务中的当前局限性，为新的研究方向铺平了道路。

Abstract: Satire, irony, and sarcasm are techniques typically used to express humor and
critique, rather than deceive; however, they can occasionally be mistaken for
factual reporting, akin to fake news. These techniques can be applied at a more
granular level, allowing satirical information to be incorporated into news
articles. In this paper, we introduce the first sentence-level dataset for
Romanian satire detection for news articles, called SeLeRoSa. The dataset
comprises 13,873 manually annotated sentences spanning various domains,
including social issues, IT, science, and movies. With the rise and recent
progress of large language models (LLMs) in the natural language processing
literature, LLMs have demonstrated enhanced capabilities to tackle various
tasks in zero-shot settings. We evaluate multiple baseline models based on LLMs
in both zero-shot and fine-tuning settings, as well as baseline
transformer-based models. Our findings reveal the current limitations of these
models in the sentence-level satire detection task, paving the way for new
research directions.

</details>


### [49] [Supervised In-Context Fine-Tuning for Generative Sequence Labeling](https://arxiv.org/abs/2509.00921)
*David Dukić,Goran Glavaš,Jan Šnajder*

Main category: cs.CL

TL;DR: 本文提出了一种新的方法SIFT，用于生成式SL，并展示了其在多个任务上的优越性能，同时也探讨了LLM在SL中的优缺点。


<details>
  <summary>Details</summary>
Motivation: 尽管因果LLM在SL中具有快速扩展的潜力，但很少有工作专注于（监督）生成式SL，这更适合因果LLM。

Method: 本文提出了监督上下文微调（SIFT），将SL任务视为受约束的响应生成，结合了（1）演示中的上下文学习（ICL）和（2）监督微调。

Result: SIFT在一系列标准SL任务中显著优于ICL和解码器作为编码器的微调基线。此外，研究发现，长上下文会阻碍ICL和SIFT中生成式SL的性能，但可以通过移除指令来缓解这一问题。

Conclusion: 本文的研究表明，使用基于响应的生成任务形式对于有效的序列标注（SL）性能至关重要。同时，研究也揭示了LLM在SL中的优势和局限性。

Abstract: Sequence labeling (SL) tasks, where labels are assigned to tokens, are
abundant in NLP (e.g., named entity recognition and aspect-based sentiment
analysis). Owing to the intuition that they require bidirectional context, SL
tasks are commonly tackled with encoder-only models. Recent work also shows
that removing the causal mask in fine-tuning enables decoder-based LLMs to
become effective token classifiers. Less work, however, focused on (supervised)
generative SL, a more natural setting for causal LLMs. Due to their rapid
scaling, causal LLMs applied to SL are expected to outperform encoders, whose
own development has stagnated. In this work, we propose supervised in-context
fine-tuning (SIFT) for generative SL. SIFT casts SL tasks as constrained
response generation, natural to LLMs, combining (1) in-context learning (ICL)
from demonstrations with (2) supervised fine-tuning. SIFT considerably
outperforms both ICL and decoder-as-encoder fine-tuning baselines on a range of
standard SL tasks. We further find that although long context hinders the
performance of generative SL in both ICL and SIFT, this deficiency can be
mitigated by removing the instruction, as instructions are shown to be largely
unnecessary for achieving strong SL performance with SIFT. Our findings
highlight strengths and limitations of SL with LLMs, underscoring the
importance of a response-based generative task formulation for effective SL
performance.

</details>


### [50] [MedCOD: Enhancing English-to-Spanish Medical Translation of Large Language Models Using Enriched Chain-of-Dictionary Framework](https://arxiv.org/abs/2509.00934)
*Md Shahidul Salim,Lian Fu,Arav Adikesh Ramakrishnan,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: MedCOD是一种混合框架，通过将领域特定的结构化知识集成到大型语言模型中，以提高英语到西班牙语的医学翻译质量。实验结果表明，MedCOD显著提高了所有模型的翻译质量，并且结构化知识整合在增强医学翻译任务中的大型语言模型方面具有潜力。


<details>
  <summary>Details</summary>
Motivation: 为了提高英语到西班牙语的医学翻译质量，需要将领域特定的结构化知识集成到大型语言模型中。

Method: MedCOD框架通过将领域特定的结构化知识集成到大型语言模型（LLMs）中，以提高英语到西班牙语的医学翻译。它结合了来自统一医学语言系统（UMLS）和LLM-as-Knowledge-Base（LLM-KB）范式的领域特定知识，以增强结构化提示和微调。

Result: 实验结果表明，MedCOD显著提高了所有模型的翻译质量。例如，使用MedCOD和微调的Phi-4在BLEU、chrF++和COMET指标上分别达到了44.23、28.91和0.863，超过了像GPT-4o和GPT-4o-mini这样的强基线模型。消融研究证实，MedCOD提示和模型适应都独立地对性能提升有贡献，两者的结合带来了最高的改进。

Conclusion: 这些发现突显了结构化知识整合在增强医学翻译任务中的大型语言模型方面的潜力。

Abstract: We present MedCOD (Medical Chain-of-Dictionary), a hybrid framework designed
to improve English-to-Spanish medical translation by integrating
domain-specific structured knowledge into large language models (LLMs). MedCOD
integrates domain-specific knowledge from both the Unified Medical Language
System (UMLS) and the LLM-as-Knowledge-Base (LLM-KB) paradigm to enhance
structured prompting and fine-tuning. We constructed a parallel corpus of 2,999
English-Spanish MedlinePlus articles and a 100-sentence test set annotated with
structured medical contexts. Four open-source LLMs (Phi-4, Qwen2.5-14B,
Qwen2.5-7B, and LLaMA-3.1-8B) were evaluated using structured prompts that
incorporated multilingual variants, medical synonyms, and UMLS-derived
definitions, combined with LoRA-based fine-tuning. Experimental results
demonstrate that MedCOD significantly improves translation quality across all
models. For example, Phi-4 with MedCOD and fine-tuning achieved BLEU 44.23,
chrF++ 28.91, and COMET 0.863, surpassing strong baseline models like GPT-4o
and GPT-4o-mini. Ablation studies confirm that both MedCOD prompting and model
adaptation independently contribute to performance gains, with their
combination yielding the highest improvements. These findings highlight the
potential of structured knowledge integration to enhance LLMs for medical
translation tasks.

</details>


### [51] [Structure and Destructure: Dual Forces in the Making of Knowledge Engines](https://arxiv.org/abs/2509.00949)
*Yihong Chen*

Main category: cs.CL

TL;DR: 本文探讨了结构化和非结构化范式在自然语言处理中的联系，并提出了一个新方法来开发通用知识引擎。


<details>
  <summary>Details</summary>
Motivation: 尽管结构化和非结构化范式在自然语言处理中有所不同，但本文旨在建立它们之间的概念联系。

Method: 通过建立结构和解构之间的概念联系，探索了知识图谱和大规模语言模型之间的互补性。

Result: 结构化组织已知的符号交互，而解构通过周期性的嵌入重置提高了模型的可塑性和泛化能力。

Conclusion: 本文提出了一个新方法，用于开发能够支持透明、可控和适应性强的智能系统的通用知识引擎。

Abstract: The making of knowledge engines in natural language processing has been
shaped by two seemingly distinct paradigms: one grounded in structure, the
other driven by massively available unstructured data. The structured paradigm
leverages predefined symbolic interactions, such as knowledge graphs, as priors
and designs models to capture them. In contrast, the unstructured paradigm
centers on scaling transformer architectures with increasingly vast data and
model sizes, as seen in modern large language models. Despite their divergence,
this thesis seeks to establish conceptual connections bridging these paradigms.
Two complementary forces, structure and destructure, emerge across both
paradigms: structure organizes seen symbolic interactions, while destructure,
through periodic embedding resets, improves model plasticity and generalization
to unseen scenarios. These connections form a new recipe for developing general
knowledge engines that can support transparent, controllable, and adaptable
intelligent systems.

</details>


### [52] [RPRO:Ranked Preference Reinforcement Optimization for Enhancing Medical QA and Diagnostic Reasoning](https://arxiv.org/abs/2509.00974)
*Chia-Hsuan Hsu,Jun-En Ding,Hsin-Ling Hsu,Feng Liu,Fang-Ming Hung*

Main category: cs.CL

TL;DR: 本文提出了一种名为RPRO的新框架，通过结合强化学习与基于偏好的推理细化，提高了医学问答中的临床推理能力。实验结果表明，该方法在多个基准测试中表现优异，甚至优于更大的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）生成的推理链往往缺乏事实准确性和临床可靠性，因此需要一种新的方法来提升医学问答的推理能力。

Method: 我们提出了Ranked Preference Reinforcement Optimization (RPRO)，这是一种新颖的框架，结合了强化学习与基于偏好的推理细化，以提高临床思维链（CoT）性能。RPRO采用任务自适应的推理模板和概率评估机制，使输出与既定的临床工作流程对齐，并自动识别和纠正低质量的推理链。此外，RPRO引入了基于Bradley-Terry模型的组间排名优化，并结合KL散度正则化以实现稳定的训练。

Result: 在PubMedQA和MedQA-USMLE上的实验显示，RPRO在强基线上有持续的改进。值得注意的是，我们的1.1B参数模型超过了更大的7B-13B模型，包括医学专用变体。

Conclusion: 这些发现表明，将偏好优化与质量驱动的细化相结合为构建更可靠、以临床为基础的医学大语言模型提供了一种可扩展且有效的方法。

Abstract: Medical question answering requires advanced reasoning that integrates domain
knowledge with logical inference. However, existing large language models
(LLMs) often generate reasoning chains that lack factual accuracy and clinical
reliability. We propose Ranked Preference Reinforcement Optimization (RPRO), a
novel framework that uniquely combines reinforcement learning with
preference-driven reasoning refinement to enhance clinical chain-of-thought
(CoT) performance. RPRO differentiates itself from prior approaches by
employing task-adaptive reasoning templates and a probabilistic evaluation
mechanism that aligns outputs with established clinical workflows, while
automatically identifying and correcting low-quality reasoning chains. Unlike
traditional pairwise preference methods, RPRO introduces a groupwise ranking
optimization based on the Bradley-Terry model and incorporates KL-divergence
regularization for stable training. Experiments on PubMedQA and MedQA-USMLE
show consistent improvements over strong baselines. Remarkably, our 1.1B
parameter model outperforms much larger 7B-13B models, including
medical-specialized variants. These findings demonstrate that combining
preference optimization with quality-driven refinement offers a scalable and
effective approach to building more reliable, clinically grounded medical LLMs.

</details>


### [53] [Performance Analysis of Supervised Machine Learning Algorithms for Text Classification](https://arxiv.org/abs/2509.00983)
*Sadia Zaman Mishu,S M Rafiuddin*

Main category: cs.CL

TL;DR: 本文探讨了在不同数据集上使用监督机器学习技术进行文本分类的过程，并比较了不同模型的分类准确性。


<details>
  <summary>Details</summary>
Motivation: 文本分类的需求在网页搜索、数据挖掘、网页排名、推荐系统和其他信息技术领域显著增长。本文旨在通过不同的数据集和监督机器学习技术来说明文本分类过程。

Method: 本文使用了一些标准的监督机器学习技术，在不同的数据集上进行文本分类过程。应用这些分类器对不同类型的标记文档进行分类，并测量分类器的准确性。使用人工神经网络（ANN）模型和反向传播网络（BPN）与其他模型一起创建了一个独立的平台用于标记和监督文本分类过程。

Result: 实验分析显示，某些模型在分类准确性方面表现更好。

Conclusion: 实验分析表明，某些模型在分类准确性方面表现更好。

Abstract: The demand for text classification is growing significantly in web searching,
data mining, web ranking, recommendation systems, and so many other fields of
information and technology. This paper illustrates the text classification
process on different datasets using some standard supervised machine learning
techniques. Text documents can be classified through various kinds of
classifiers. Labeled text documents are used to classify the text in supervised
classifications. This paper applies these classifiers on different kinds of
labeled documents and measures the accuracy of the classifiers. An Artificial
Neural Network (ANN) model using Back Propagation Network (BPN) is used with
several other models to create an independent platform for labeled and
supervised text classification process. An existing benchmark approach is used
to analyze the performance of classification using labeled documents.
Experimental analysis on real data reveals which model works well in terms of
classification accuracy.

</details>


### [54] [Ranking of Bangla Word Graph using Graph-based Ranking Algorithms](https://arxiv.org/abs/2509.01011)
*S M Rafiuddin*

Main category: cs.CL

TL;DR: 本研究利用基于图的排名算法对孟加拉语单词进行排名，并通过实验验证了不同算法的准确性。


<details>
  <summary>Details</summary>
Motivation: 缺乏标准的孟加拉语单词数据库，因此需要使用印度语言POS标记语料库来获取丰富的孟加拉语单词数据。

Method: 使用基于图的排名算法对孟加拉语单词进行排名，并通过预处理步骤和比较这些算法来构建单词图。

Result: 实验结果分析显示了每种排名算法在F1度量上的准确性。

Conclusion: 实验结果分析表明，每种排名算法在F1度量上的准确性得到了验证。

Abstract: Ranking words is an important way to summarize a text or to retrieve
information. A word graph is a way to represent the words of a sentence or a
text as the vertices of a graph and to show the relationship among the words.
It is also useful to determine the relative importance of a word among the
words in the word-graph. In this research, the ranking of Bangla words are
calculated, representing Bangla words from a text in a word graph using various
graph based ranking algorithms. There is a lack of a standard Bangla word
database. In this research, the Indian Language POS-tag Corpora is used, which
has a rich collection of Bangla words in the form of sentences with their parts
of speech tags. For applying a word graph to various graph based ranking
algorithms, several standard procedures are applied. The preprocessing steps
are done in every word graph and then applied to graph based ranking algorithms
to make a comparison among these algorithms. This paper illustrate the entire
procedure of calculating the ranking of Bangla words, including the
construction of the word graph from text. Experimental result analysis on real
data reveals the accuracy of each ranking algorithm in terms of F1 measure.

</details>


### [55] [We Politely Insist: Your LLM Must Learn the Persian Art of Taarof](https://arxiv.org/abs/2509.01035)
*Nikta Gohari Sadr,Sahar Heidariasl,Karine Megerdoomian,Laleh Seyyed-Kalantari,Ali Emami*

Main category: cs.CL

TL;DR: 本文介绍了TaarofBench，用于评估大型语言模型对波斯taarof的理解，并发现模型在文化能力方面存在显著差距，通过微调和优化可提高模型与文化期望的一致性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在跨文化沟通规范方面存在困难，限制了其在全球环境中的有效性。特别是波斯taarof这一复杂的礼仪系统尚未被现有的文化基准所涵盖。

Method: 引入了TaarofBench，这是第一个评估大型语言模型对taarof理解的基准，包含450个角色扮演场景，并通过监督微调和直接偏好优化提高了模型与文化期望的一致性。

Result: 评估五种前沿大型语言模型显示，当taarof符合文化规范时，准确率比母语者低40-48%。性能在不同互动主题之间有所变化，使用波斯语提示时有所改善，并表现出性别差异。此外，标准指标评为“礼貌”的回应常常违反taarof规范，表明西方礼貌框架的局限性。

Conclusion: 本文为开发多样且文化意识强的大型语言模型奠定了基础，使应用程序能够更好地处理复杂的社会互动。

Abstract: Large language models (LLMs) struggle to navigate culturally specific
communication norms, limiting their effectiveness in global contexts. We focus
on Persian taarof, a social norm in Iranian interactions, which is a
sophisticated system of ritual politeness that emphasizes deference, modesty,
and indirectness, yet remains absent from existing cultural benchmarks. We
introduce TaarofBench, the first benchmark for evaluating LLM understanding of
taarof, comprising 450 role-play scenarios covering 12 common social
interaction topics, validated by native speakers. Our evaluation of five
frontier LLMs reveals substantial gaps in cultural competence, with accuracy
rates 40-48% below native speakers when taarof is culturally appropriate.
Performance varies between interaction topics, improves with Persian-language
prompts, and exhibits gender-based asymmetries. We also show that responses
rated "polite" by standard metrics often violate taarof norms, indicating the
limitations of Western politeness frameworks. Through supervised fine-tuning
and Direct Preference Optimization, we achieve 21.8% and 42.3% improvement in
model alignment with cultural expectations. Our human study with 33
participants (11 native Persian, 11 heritage, and 11 non-Iranian speakers)
forms baselines in varying degrees of familiarity with Persian norms. This work
lays the foundation for developing diverse and culturally aware LLMs, enabling
applications that better navigate complex social interactions.

</details>


### [56] [A Dynamic Fusion Model for Consistent Crisis Response](https://arxiv.org/abs/2509.01053)
*Xiaoying Song,Anirban Saha Anik,Eduardo Blanco,Vanessa Frias-Martinez,Lingzi Hong*

Main category: cs.CL

TL;DR: 本文提出了一种新的评估风格一致性的度量标准，并引入了一种基于该度量的标准融合生成方法。实验结果表明，该方法在响应质量和风格一致性方面都优于基线。


<details>
  <summary>Details</summary>
Motivation: 为了应对与受危机影响人群有效沟通的迫切需求，自动化响应已被提出用于协助危机沟通。然而，响应风格的一致性这一关键但常被忽视的因素可能会影响受影响个体对响应者的信任。尽管其重要性，很少有研究探讨保持生成响应中风格一致性的方法。

Method: 我们提出了一种新的评估风格一致性的度量标准，并引入了一种基于该度量的标准融合生成方法。我们的方法采用两阶段过程：首先评估候选响应的风格，然后通过融合过程在实例级别上优化和整合它们。

Result: 在多个数据集上的实验结果表明，我们的方法在响应质量和风格一致性方面都显著优于基线。

Conclusion: 我们的方法在响应质量和风格一致性方面都优于基线，表明了其在危机沟通中的有效性。

Abstract: In response to the urgent need for effective communication with
crisis-affected populations, automated responses driven by language models have
been proposed to assist in crisis communications. A critical yet often
overlooked factor is the consistency of response style, which could affect the
trust of affected individuals in responders. Despite its importance, few
studies have explored methods for maintaining stylistic consistency across
generated responses. To address this gap, we propose a novel metric for
evaluating style consistency and introduce a fusion-based generation approach
grounded in this metric. Our method employs a two-stage process: it first
assesses the style of candidate responses and then optimizes and integrates
them at the instance level through a fusion process. This enables the
generation of high-quality responses while significantly reducing stylistic
variation between instances. Experimental results across multiple datasets
demonstrate that our approach consistently outperforms baselines in both
response quality and stylistic uniformity.

</details>


### [57] [Speaking at the Right Level: Literacy-Controlled Counterspeech Generation with RAG-RL](https://arxiv.org/abs/2509.01058)
*Xiaoying Song,Anirban Saha Anik,Dibakar Barua,Pengcheng Luo,Junhua Ding,Lingzi Hong*

Main category: cs.CL

TL;DR: 本研究提出了一种基于检索增强生成和强化学习的受控文献框架，以生成针对不同健康文献水平的定制对抗信息，并证明其在可访问性和用户偏好方面优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常产生统一的回应，忽略了受众的健康文献水平可能会影响对抗信息的可访问性和效果。

Method: 我们提出了一个受控文献框架，使用检索增强生成（RAG）和强化学习（RL）来生成适应不同健康文献水平的定制对抗信息。

Result: 实验结果表明，受控文献优于基线，生成的对抗信息更具可访问性和用户偏好。

Conclusion: 本研究通过改进对抗错误信息的传播内容的可访问性和理解性，为更公平和有影响力的公共卫生沟通做出了贡献。

Abstract: Health misinformation spreading online poses a significant threat to public
health. Researchers have explored methods for automatically generating
counterspeech to health misinformation as a mitigation strategy. Existing
approaches often produce uniform responses, ignoring that the health literacy
level of the audience could affect the accessibility and effectiveness of
counterspeech. We propose a Controlled-Literacy framework using
retrieval-augmented generation (RAG) with reinforcement learning (RL) to
generate tailored counterspeech adapted to different health literacy levels. In
particular, we retrieve knowledge aligned with specific health literacy levels,
enabling accessible and factual information to support generation. We design a
reward function incorporating subjective user preferences and objective
readability-based rewards to optimize counterspeech to the target health
literacy level. Experiment results show that Controlled-Literacy outperforms
baselines by generating more accessible and user-preferred counterspeech. This
research contributes to more equitable and impactful public health
communication by improving the accessibility and comprehension of counterspeech
to health misinformation.

</details>


### [58] [Assessing Large Language Models on Islamic Legal Reasoning: Evidence from Inheritance Law Evaluation](https://arxiv.org/abs/2509.01081)
*Abdessalam Bouchekif,Samer Rashwani,Heba Sbahi,Shahd Gaben,Mutez Al-Khatib,Mohammed Ghaly*

Main category: cs.CL

TL;DR: 该研究评估了七种大型语言模型在伊斯兰继承法领域的知识和推理能力，发现它们的表现存在显著差异，并指出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在伊斯兰继承法领域的知识和推理能力，以了解它们在处理复杂法律问题时的表现。

Method: 通过设计1000个多项选择题的基准测试，评估七种大型语言模型在伊斯兰继承法领域的知识和推理能力。

Result: o3和Gemini 2.5的准确率超过90%，而ALLaM、Fanar、LLaMA和Mistral的准确率低于50%。研究还发现了模型在理解继承场景、应用法律规则和领域知识方面的常见失败模式。

Conclusion: 研究结果表明，不同大型语言模型在伊斯兰继承法推理能力上存在显著差异，这反映了它们在推理能力和领域适应性上的不同。研究还指出了处理结构化法律推理的局限性，并提出了改进方向。

Abstract: This paper evaluates the knowledge and reasoning capabilities of Large
Language Models in Islamic inheritance law, known as 'ilm al-mawarith. We
assess the performance of seven LLMs using a benchmark of 1,000 multiple-choice
questions covering diverse inheritance scenarios, designed to test models'
ability to understand the inheritance context and compute the distribution of
shares prescribed by Islamic jurisprudence. The results reveal a significant
performance gap: o3 and Gemini 2.5 achieved accuracies above 90%, whereas
ALLaM, Fanar, LLaMA, and Mistral scored below 50%. These disparities reflect
important differences in reasoning ability and domain adaptation. We conduct a
detailed error analysis to identify recurring failure patterns across models,
including misunderstandings of inheritance scenarios, incorrect application of
legal rules, and insufficient domain knowledge. Our findings highlight
limitations in handling structured legal reasoning and suggest directions for
improving performance in Islamic legal reasoning. Code:
https://github.com/bouchekif/inheritance_evaluation

</details>


### [59] [A Paradigm Gap in Urdu](https://arxiv.org/abs/2509.01084)
*Farah Adeeba,Rajesh Bhatt*

Main category: cs.CL

TL;DR: 本文探讨了乌尔都语和印地语中动词和体的组合可能性的范式差距，发现完成体形式在现代语言中不合法，这是由于形态句法冲突导致的。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨乌尔都语和印地语中动词和体的组合可能性的范式差距，特别是-ya: kar结构的完成体形式在现代语言中的不合法现象。

Method: 本文通过历史文本分析和大规模语料库研究，确认了完美形式的缺失，并进行了以母语者为主的主观评估任务。

Result: 研究结果确认了现代乌尔都语和印地语中完成体形式的显著缺失，并且母语者认为完成体例子非常不自然。

Conclusion: 本文认为，这种差异是由于基本的形态句法冲突造成的：该结构对主格主语和不变分词的要求与及物完美体分配与格的语法核心规则相冲突。这种冲突使完美形式变得不稳定，其他结构的功能替代使得这种差异在现代语法中根深蒂固。

Abstract: In this paper, we document a paradigm gap in the combinatorial possibilities
of verbs and aspect in Urdu: the perfective form of the -ya: kar construction
(e.g. ro-ya: ki: cry-Pfv do.Pfv) is sharply ungrammatical in modern Urdu and
Hindi, despite being freely attested in 19th century literature. We investigate
this diachronic shift through historical text analysis, a large-scale corpus
study which confirms the stark absence of perfective forms and subjective
evaluation tasks with native speakers, who judge perfective examples as highly
unnatural. We argue that this gap arose from a fundamental morphosyntactic
conflict: the construction's requirement for a nominative subject and an
invariant participle clashes with the core grammatical rule that transitive
perfective assign ergative case. This conflict rendered the perfective form
unstable, and its functional replacement by other constructions allowed the gap
to become entrenched in the modern grammar.

</details>


### [60] [Privacy-Preserving Reasoning with Knowledge-Distilled Parametric Retrieval Augmented Generation](https://arxiv.org/abs/2509.01088)
*Jinwen Chen,Hainan Zhang,Liang Pang,Yongxin Tong,Haibo Zhou,Yuan Zhan,Wei Lin,Zhiming Zheng*

Main category: cs.CL

TL;DR: This paper proposes DistilledPRAG, a knowledge-distilled parametric RAG model that aligns with standard RAG in document structure and parameter activation, improving efficiency and generalization.


<details>
  <summary>Details</summary>
Motivation: The current RAG system risks private data leakage, and PRAG has issues with inference latency and poor generalization on OOD inputs. Achieving high-efficiency parameterization while maintaining RAG-level performance remains a critical challenge for privacy-preserving reasoning.

Method: We synthesize QA pairs from single and multi-documents to enhance cross-document reasoning. Then, we mask the plaintext documents with a special token and translate them to LoRA via a parameter generator, maintaining the standard RAG document structure. Finally, guided by synthetic QA data, we train the parameter generator to match standard RAG's hidden states and output logits, enabling RAG-style reasoning without original documents.

Result: Experiments on four QA datasets show that DistilledPRAG outperforms baselines in accuracy and generalizes well on OOD data.

Conclusion: DistilledPRAG outperforms baselines in accuracy and generalizes well on OOD data.

Abstract: The current RAG system requires uploading plaintext documents to the cloud,
risking private data leakage. Parametric RAG (PRAG) addresses this by encoding
documents as LoRA within LLMs, enabling reasoning without exposing raw content.
However, it still faces two issues: (1) PRAG demands synthesizing QA pairs and
fine-tuning LLM for each individual document to create its corresponding LoRA,
leading to unacceptable inference latency. (2) The performance of PRAG relies
solely on synthetic QA data, lacking internal alignment with standard RAG,
resulting in poor generalization on out-of-distribution(OOD) inputs. Therefore,
achieving high-efficiency parameterization while maintaining RAG-level
performance remains a critical challenge for privacy-preserving reasoning. In
this paper, we propose DistilledPRAG, a generalizable knowledge-distilled
parametric RAG model aligned with standard RAG in document structure and
parameter activation. We first synthesize QA pairs from single and
multi-documents to enhance cross-document reasoning. Then, we mask the
plaintext documents with a special token and translate them to LoRA via a
parameter generator, maintaining the standard RAG document structure. Finally,
guided by synthetic QA data, we train the parameter generator to match standard
RAG's hidden states and output logits, enabling RAG-style reasoning without
original documents. Experiments on four QA datasets show that DistilledPRAG
outperforms baselines in accuracy and generalizes well on OOD data.

</details>


### [61] [REFRAG: Rethinking RAG based Decoding](https://arxiv.org/abs/2509.01092)
*Xiaoqiang Lin,Aritra Ghosh,Bryan Kian Hsiang Low,Anshumali Shrivastava,Vijai Mohan*

Main category: cs.CL

TL;DR: REFRAG 是一种用于 RAG 的高效解码框架，能够显著提高延迟性能并扩展上下文大小，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: RAG 在处理长上下文输入时存在系统延迟高和内存需求大的问题，需要一种更高效的解码方法。

Method: REFRAG 通过压缩、感知和扩展来优化 RAG 中的解码过程，利用了 RAG 上下文中的稀疏结构特性。

Result: REFRAG 在 RAG 应用中实现了 30.85% 的首次标记时间加速，并将 LLM 的上下文大小扩展了 16 倍，同时保持了困惑度不变。

Conclusion: REFRAG 提供了一种高效的解码框架，可以在不损失准确性的前提下显著提高 RAG 应用的延迟性能，并扩展了 LLM 的上下文大小。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
leveraging extensive external knowledge to enhance responses in multi-turn and
agentic applications, such as retrieval-augmented generation (RAG). However,
processing long-context inputs introduces significant system latency and
demands substantial memory for the key-value cache, resulting in reduced
throughput and a fundamental trade-off between knowledge enrichment and system
efficiency. While minimizing latency for long-context inputs is a primary
objective for LLMs, we contend that RAG require specialized consideration. In
RAG, much of the LLM context consists of concatenated passages from retrieval,
with only a small subset directly relevant to the query. These passages often
exhibit low semantic similarity due to diversity or deduplication during
re-ranking, leading to block-diagonal attention patterns that differ from those
in standard LLM generation tasks. Based on this observation, we argue that most
computations over the RAG context during decoding are unnecessary and can be
eliminated with minimal impact on performance. To this end, we propose REFRAG,
an efficient decoding framework that compresses, senses, and expands to improve
latency in RAG applications. By exploiting the sparsity structure, we
demonstrate a 30.85 the time-to-first-token acceleration (3.75 improvement to
previous work) without loss in perplexity. In addition, our optimization
framework for large context enables REFRAG to extend the context size of LLMs
by 16. We provide rigorous validation of REFRAG across diverse long-context
tasks, including RAG, multi-turn conversations, and long document
summarization, spanning a wide range of datasets. Experimental results confirm
that REFRAG delivers substantial speedup with no loss in accuracy compared to
LLaMA models and other state-of-the-art baselines across various context sizes.

</details>


### [62] [Natural Context Drift Undermines the Natural Language Understanding of Large Language Models](https://arxiv.org/abs/2509.01093)
*Yulong Wu,Viktor Schlegel,Riza Batista-Navarro*

Main category: cs.CL

TL;DR: 研究发现，自然文本演化导致LLM的问答性能下降，即使问题和必要信息仍然存在。


<details>
  <summary>Details</summary>
Motivation: 研究自然演化的上下文段落如何影响生成式大型语言模型（LLMs）的问答性能。

Method: 我们提出了一种框架，用于整理来自当代QA基准的自然演化的、人工编辑的阅读段落变体，并分析LLMs在一系列语义相似性分数下的表现。

Result: LLM的性能随着阅读段落自然偏离预训练时遇到的版本而下降，即使在推理时问题和所有必要信息仍然存在。例如，BoolQ上的平均模型准确率从最高到最低相似性区间下降了30%以上，多个LLM的斜率超过70。

Conclusion: 自然文本演化对LLMs的语言理解能力构成了重大挑战。

Abstract: How does the natural evolution of context paragraphs affect question
answering in generative Large Language Models (LLMs)? To investigate this, we
propose a framework for curating naturally evolved, human-edited variants of
reading passages from contemporary QA benchmarks and for analyzing LLM
performance across a range of semantic similarity scores, which quantify how
closely each variant aligns with content seen during pretraining. Using this
framework, we evaluate six QA datasets and eight LLMs with publicly available
training data. Our experiments reveal that LLM performance declines as reading
passages naturally diverge from the versions encountered during
pretraining-even when the question and all necessary information remains
present at inference time. For instance, average model accuracy on BoolQ drops
by over 30% from the highest to lowest similarity bins, with slopes exceeding
70 across several LLMs. These findings suggest that natural text evolution
poses a significant challenge to the language understanding capabilities of
LLMs.

</details>


### [63] [Dream-Coder 7B: An Open Diffusion Language Model for Code](https://arxiv.org/abs/2509.01142)
*Zhihui Xie,Jiacheng Ye,Lin Zheng,Jiahui Gao,Jingwei Dong,Zirui Wu,Xueliang Zhao,Shansan Gong,Xin Jiang,Zhenguo Li,Lingpeng Kong*

Main category: cs.CL

TL;DR: Dream-Coder 7B是一个用于代码生成的开放源代码离散扩散语言模型，具有任何顺序生成能力。它可以根据编码任务自适应地选择解码策略，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统自回归（AR）模型严格按左到右解码，而Dream-Coder 7B根据编码任务自适应地确定解码策略：对于复杂算法采用先草图生成，对于简单补全采用左到右生成，对于代码理解任务采用交错推理生成。

Method: 我们将预训练的AR检查点适应到离散扩散框架中，使用连续时间加权交叉熵目标。我们的后训练方案包括(i)监督微调，通过随机截断和填充惩罚来减轻填充病理，提高样本效率并稳定生成；(ii)在从开源数据集中选取的高质量提示集上使用可验证奖励进行强化学习，使用针对扩散语言模型的定制强化学习方案。

Result: Dream-Coder 7B Instruct在LiveCodeBench上达到了21.4%的pass@1，并在HumanEval、MBPP、BigCodeBench和CRUXEval上表现出色。

Conclusion: Dream-Coder 7B Instruct在LiveCodeBench上达到了21.4%的pass@1，并在HumanEval、MBPP、BigCodeBench和CRUXEval上表现出色。我们发布了Dream-Coder-7B和Dream-Coder-7B-Instruct的检查点、训练方案、预处理管道和推理代码，以促进可重复性和进一步的研究。

Abstract: We present Dream-Coder 7B, an open-source discrete diffusion language model
for code generation that exhibits emergent any-order generation capabilities.
Unlike traditional autoregressive (AR) models that decode strictly
left-to-right, Dream-Coder 7B adaptively determines its decoding strategy based
on the coding task: sketch-first generation for complex algorithms,
left-to-right generation for straightforward completions, and interleaved
reasoning generation for code understanding tasks. We adapt a pretrained AR
checkpoint to a discrete diffusion frameworks with a continuous-time weighted
cross-entropy objective. Our post-training recipe comprises (i) supervised
fine-tuning, where we mitigate padding pathologies via random truncation and a
padding penalty to improve sample efficiency and stabilize generation; and (ii)
reinforcement learning with verifiable rewards over a curated high-quality
prompt set drawn from open-source datasets, using a tailored reinforcement
learning recipe for diffusion language models. The resulting Dream-Coder 7B
Instruct attains 21.4\% pass@1 on LiveCodeBench (2410--2505) and demonstrates
competitive performance on HumanEval, MBPP, BigCodeBench, and CRUXEval. We
release Dream-Coder-7B and Dream-Coder-7B-Instruct checkpoints, training
recipes, preprocessing pipelines, and inference code to facilitate
reproducibility and further research.

</details>


### [64] [Zero-shot Cross-lingual NER via Mitigating Language Difference: An Entity-aligned Translation Perspective](https://arxiv.org/abs/2509.01147)
*Zhihao Zhang,Sophia Yat Mei Lee,Dong Zhang,Shoushan Li,Guodong Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种实体对齐翻译（EAT）方法，用于提高非拉丁字母语言（NSL）在零样本跨语言命名实体识别（ZCL-NER）中的性能。通过利用大型语言模型（LLMs）和多语言维基百科数据进行微调，实现了更好的实体对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本跨语言命名实体识别（ZCL-NER）方法主要集中在拉丁字母语言（LSL），而对非拉丁字母语言（NSL）如中文和日语，由于结构差异大，性能通常下降。因此，需要一种新的方法来解决这一问题。

Method: 本文提出了一种实体对齐翻译（EAT）方法，该方法利用大型语言模型（LLMs）并采用双翻译策略来对齐非拉丁字母语言（NSL）和英语之间的实体。此外，还使用多语言维基百科数据对LLMs进行微调，以增强从源语言到目标语言的实体对齐效果。

Result: 通过使用实体对齐翻译（EAT）方法和多语言维基百科数据微调大型语言模型（LLMs），显著提高了非拉丁字母语言（NSL）在零样本跨语言命名实体识别（ZCL-NER）中的性能。

Conclusion: 本文提出了一种实体对齐翻译（EAT）方法，以解决非拉丁字母语言（NSL）在零样本跨语言命名实体识别（ZCL-NER）中的性能下降问题。通过利用大型语言模型（LLMs）和多语言维基百科数据进行微调，提高了从源语言到目标语言的实体对齐效果。

Abstract: Cross-lingual Named Entity Recognition (CL-NER) aims to transfer knowledge
from high-resource languages to low-resource languages. However, existing
zero-shot CL-NER (ZCL-NER) approaches primarily focus on Latin script language
(LSL), where shared linguistic features facilitate effective knowledge
transfer. In contrast, for non-Latin script language (NSL), such as Chinese and
Japanese, performance often degrades due to deep structural differences. To
address these challenges, we propose an entity-aligned translation (EAT)
approach. Leveraging large language models (LLMs), EAT employs a
dual-translation strategy to align entities between NSL and English. In
addition, we fine-tune LLMs using multilingual Wikipedia data to enhance the
entity alignment from source to target languages.

</details>


### [65] [Joint Information Extraction Across Classical and Modern Chinese with Tea-MOELoRA](https://arxiv.org/abs/2509.01158)
*Xuemei Tang,Chengxi Yan,Jinghang Gu,Chu-Ren Huang*

Main category: cs.CL

TL;DR: 本文提出了Tea-MOELoRA，这是一种结合LoRA与MoE设计的参数高效多任务框架，用于处理中文信息抽取任务，能够在不同任务和时期之间有效分配专家贡献并提升性能。


<details>
  <summary>Details</summary>
Motivation: 在异构任务和不同年代上微调单一模型可能导致干扰和性能下降，因此需要一种有效的多任务框架来解决这个问题。

Method: Tea-MOELoRA是一种结合LoRA与Mixture-of-Experts (MoE)设计的参数高效多任务框架，多个低秩LoRA专家专注于不同的IE任务和时期，同时有一个任务-时期感知的路由器机制动态分配专家贡献。

Result: 实验表明，Tea-MOELoRA在性能上优于单任务和联合LoRA基线，证明了其能够有效地利用任务和时间知识。

Conclusion: Tea-MOELoRA展示了其有效利用任务和时间知识的能力，并在实验中优于单任务和联合LoRA基线。

Abstract: Chinese information extraction (IE) involves multiple tasks across diverse
temporal domains, including Classical and Modern documents. Fine-tuning a
single model on heterogeneous tasks and across different eras may lead to
interference and reduced performance. Therefore, in this paper, we propose
Tea-MOELoRA, a parameter-efficient multi-task framework that combines LoRA with
a Mixture-of-Experts (MoE) design. Multiple low-rank LoRA experts specialize in
different IE tasks and eras, while a task-era-aware router mechanism
dynamically allocates expert contributions. Experiments show that Tea-MOELoRA
outperforms both single-task and joint LoRA baselines, demonstrating its
ability to leverage task and temporal knowledge effectively.

</details>


### [66] [Enhancing Large Language Model for Knowledge Graph Completion via Structure-Aware Alignment-Tuning](https://arxiv.org/abs/2509.01166)
*Yu Liu,Yanan Cao,Xixun Lin,Yanmin Shang,Shi Wang,Shirui Pan*

Main category: cs.CL

TL;DR: This paper proposes SAT, a framework that enhances large language models for knowledge graph completion by aligning graph embeddings with natural language and using a unified instruction for structure-aware reasoning, achieving significant improvements in link prediction tasks.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of inconsistent representation spaces between natural language and graph structures and the time-consuming process of designing separate instructions for different KGC tasks.

Method: We propose SAT, a novel framework that enhances LLMs for KGC via structure-aware alignment-tuning. Specifically, we introduce hierarchical knowledge alignment to align graph embeddings with the natural language space through multi-task contrastive learning. Then, we propose structural instruction tuning to guide LLMs in performing structure-aware reasoning over KGs, using a unified graph instruction combined with a lightweight knowledge adapter.

Result: Experimental results on two KGC tasks across four benchmark datasets demonstrate that SAT significantly outperforms state-of-the-art methods, especially in the link prediction task with improvements ranging from 8.7% to 29.8%.

Conclusion: SAT significantly outperforms state-of-the-art methods, especially in the link prediction task with improvements ranging from 8.7% to 29.8%.

Abstract: Knowledge graph completion (KGC) aims to infer new knowledge and make
predictions from knowledge graphs. Recently, large language models (LLMs) have
exhibited remarkable reasoning capabilities. LLM-enhanced KGC methods primarily
focus on designing task-specific instructions, achieving promising
advancements. However, there are still two critical challenges. First, existing
methods often ignore the inconsistent representation spaces between natural
language and graph structures. Second, most approaches design separate
instructions for different KGC tasks, leading to duplicate works and
time-consuming processes. To address these challenges, we propose SAT, a novel
framework that enhances LLMs for KGC via structure-aware alignment-tuning.
Specifically, we first introduce hierarchical knowledge alignment to align
graph embeddings with the natural language space through multi-task contrastive
learning. Then, we propose structural instruction tuning to guide LLMs in
performing structure-aware reasoning over KGs, using a unified graph
instruction combined with a lightweight knowledge adapter. Experimental results
on two KGC tasks across four benchmark datasets demonstrate that SAT
significantly outperforms state-of-the-art methods, especially in the link
prediction task with improvements ranging from 8.7% to 29.8%.

</details>


### [67] [Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation](https://arxiv.org/abs/2509.01185)
*Seganrasan Subramanian,Abhigya Verma*

Main category: cs.CL

TL;DR: 本文提出了一种框架，用于生成合成的长上下文数据，以促进大型语言模型在处理和推理长文本输入方面的能力。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏高质量、多样且可验证的长上下文数据集，这限制了大型语言模型在处理和推理长文本输入方面的发展。

Method: 本文提出了一种基于提示交互的合成长上下文数据生成框架，支持多种训练和对齐目标，包括监督微调（SFT）、直接偏好优化（DPO）和组相对策略优化（GRPO）。

Result: 该框架通过模板提示、模型无关的架构和元数据丰富的输出，实现了可扩展、可控和目的对齐的数据集创建。

Conclusion: 本文提出了一种模块化、可扩展的框架，用于通过与大型语言模型的提示交互生成合成的长上下文数据，以促进大型语言模型在长上下文能力方面的进步。

Abstract: The ability of large language models (LLMs) to process and reason over long
textual inputs is critical for a wide range of real-world applications.
However, progress in this area is significantly constrained by the absence of
high-quality, diverse, and verifiable long-context datasets suitable for both
training and evaluation. This work introduces a modular, extensible framework
for synthetic long-context data generation via prompt-based interaction with
LLMs. The framework supports multiple training and alignment objectives,
including Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO),
and Group Relative Policy Optimization (GRPO). It encompasses four core
generation paradigms: multi-turn conversational dialogues, document-grounded
input-output pairs, verifiable instruction-response tasks, and long-context
reasoning examples. Through templated prompting, a model-agnostic architecture,
and metadata-enriched outputs, the proposed approach facilitates scalable,
controllable, and purpose-aligned dataset creation for advancing long-context
capabilities in LLMs.

</details>


### [68] [Statutory Construction and Interpretation for Artificial Intelligence](https://arxiv.org/abs/2509.01186)
*Luxi He,Nimra Nadeem,Michel Liao,Howard Chen,Danqi Chen,Mariano-Florentino Cuéllar,Peter Henderson*

Main category: cs.CL

TL;DR: 本文探讨了AI系统中因依赖自然语言原则而产生的解释性模糊性问题，并提出了一种计算框架来解决这一问题，该框架模仿了法律系统中的两种机制，以提高模型行为的一致性。


<details>
  <summary>Details</summary>
Motivation: AI系统越来越多地由自然语言原则来规范，但依赖语言所带来的一个关键挑战——解释性模糊性——仍未得到充分探讨。与法律系统不同，AI对齐流程没有类似的保护措施。同一规则的不同解释可能导致模型行为不一致或不稳定。

Method: 我们借鉴法律理论，识别当前对齐管道中的关键差距，并提出一个计算框架，该框架模拟了两种法律机制：(1) 一种规则精炼管道，通过修订模糊规则来最小化解释分歧；(2) 基于提示的解释约束，减少规则应用中的不一致性。

Result: 我们在WildChat数据集的一个5,000场景子集上评估了我们的框架，并展示了两种干预措施显著提高了合理解释者之间的判断一致性。

Conclusion: 我们的方法为系统管理解释性模糊性提供了第一步，这是构建更稳健、遵守法律的AI系统的重要步骤。

Abstract: AI systems are increasingly governed by natural language principles, yet a
key challenge arising from reliance on language remains underexplored:
interpretive ambiguity. As in legal systems, ambiguity arises both from how
these principles are written and how they are applied. But while legal systems
use institutional safeguards to manage such ambiguity, such as transparent
appellate review policing interpretive constraints, AI alignment pipelines
offer no comparable protections. Different interpretations of the same rule can
lead to inconsistent or unstable model behavior. Drawing on legal theory, we
identify key gaps in current alignment pipelines by examining how legal systems
constrain ambiguity at both the rule creation and rule application steps. We
then propose a computational framework that mirrors two legal mechanisms: (1) a
rule refinement pipeline that minimizes interpretive disagreement by revising
ambiguous rules (analogous to agency rulemaking or iterative legislative
action), and (2) prompt-based interpretive constraints that reduce
inconsistency in rule application (analogous to legal canons that guide
judicial discretion). We evaluate our framework on a 5,000-scenario subset of
the WildChat dataset and show that both interventions significantly improve
judgment consistency across a panel of reasonable interpreters. Our approach
offers a first step toward systematically managing interpretive ambiguity, an
essential step for building more robust, law-following AI systems.

</details>


### [69] [Efficient Large Language Models with Zero-Shot Adjustable Acceleration](https://arxiv.org/abs/2509.01190)
*Sajjad Kachuee,Mohammad Sharifkhani*

Main category: cs.CL

TL;DR: 本文提出了一种新的训练和推理方法，称为零样本可调整加速，它可以在不进行额外微调的情况下动态调整硬件使用情况。实验结果表明，该方法能够实现广泛的加速，并且相比基线实现了高达11倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 在现实世界应用中使用大型语言模型（LLMs）面临重大挑战，特别是在计算效率和性能之间取得平衡。优化微调后的加速和推理对于构建高效的架构至关重要。

Method: 本文引入了零样本可调整加速，这是一种新的训练和推理方法，在推理过程中动态调整硬件使用情况，而无需额外的微调。

Result: 实验结果表明，该方法能够在零样本情况下实现广泛的加速，并且相比基线实现了高达11倍的速度提升。

Conclusion: 该方法在零样本情况下实现了广泛的加速，并且相比基线实现了高达11倍的速度提升。

Abstract: Using Large Language Models (LLMs) in real-world applications presents
significant challenges, particularly in balancing computational efficiency and
performance. Optimizing acceleration after the fine-tuning phase and during
inference is crucial for building an efficient architecture. This paper
introduces Zero-Shot Adjustable Acceleration, a novel training and inference
method that dynamically adjusts hardware usage during inference without
requiring additional fine-tuning. The proposed approach is applied to newly
developed models and evaluated across multiple classification and text
generation tasks. Experimental results demonstrate that the method enables a
wide range of acceleration in a zero-shot manner and achieves up to a 11x
speedup compared to the baseline.

</details>


### [70] [SimulMEGA: MoE Routers are Advanced Policy Makers for Simultaneous Speech Translation](https://arxiv.org/abs/2509.01200)
*Chenyang Le,Bing Han,Jinshun Li,Songyong Chen,Yanmin Qian*

Main category: cs.CL

TL;DR: SimulMEGA 是一种无监督策略学习框架，能够有效平衡翻译质量、延迟和语义连贯性，并在多语言多对多场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有系统难以在翻译质量、延迟和语义连贯性之间取得平衡，特别是在多语言多对多场景中，不同的读写策略阻碍了统一策略的学习。

Method: SimulMEGA 结合了基于前缀的训练和混合专家精炼器，以隐式方式学习有效的读写决策，同时仅需对标准 Transformer 架构进行最小修改。

Result: 在六个语言对上的全面评估表明，500M 参数的语音到文本模型在平均延迟为 1.5 秒时 BLEU 损失低于 7%，在 3 秒时低于 3%。此外，SimulMEGA 还被扩展到流式文本到语音任务，取得了更好的延迟与质量权衡。

Conclusion: SimulMEGA 是一种有效的无监督策略学习框架，能够在不增加推理时间开销的情况下，通过结合基于前缀的训练和混合专家精炼器来学习有效的读写决策。该方法在多个语言对上的实验表明其性能优于现有的 Seamless 基线模型，并且在语音到文本和文本到语音流任务中都表现出色。

Abstract: Simultaneous Speech Translation (SimulST) enables real-time cross-lingual
communication by jointly optimizing speech recognition and machine translation
under strict latency constraints. Existing systems struggle to balance
translation quality, latency, and semantic coherence, particularly in
multilingual many-to-many scenarios where divergent read and write policies
hinder unified strategy learning. In this paper, we present SimulMEGA
(Simultaneous Generation by Mixture-of-Experts Gating), an unsupervised policy
learning framework that combines prefix-based training with a
Mixture-of-Experts refiner to learn effective read and write decisions in an
implicit manner, without adding inference-time overhead. Our design requires
only minimal modifications to standard transformer architectures and
generalizes across both speech-to-text and text-to-speech streaming tasks.
Through comprehensive evaluation on six language pairs, our 500M parameter
speech-to-text model outperforms the Seamless baseline, achieving under 7
percent BLEU degradation at 1.5 seconds average lag and under 3 percent at 3
seconds. We further demonstrate the versatility of SimulMEGA by extending it to
streaming TTS with a unidirectional backbone, yielding superior latency quality
tradeoffs.

</details>


### [71] [Mitigating Catastrophic Forgetting in Continual Learning through Model Growth](https://arxiv.org/abs/2509.01213)
*Ege Süalp,Mina Rezaei*

Main category: cs.CL

TL;DR: 本研究探讨了基于生长的预训练方法在减轻大型语言模型灾难性遗忘问题中的效果，结果显示该方法在某些任务上表现更好，但在处理社会偏见方面仍有不足。


<details>
  <summary>Details</summary>
Motivation: 灾难性遗忘是持续学习中的重大挑战，特别是在大型语言模型（LLMs）进行持续学习时，保持跨不同领域的性能对于其通用性至关重要。

Method: 研究探索了模型生长策略，利用较小的模型来加速和结构化较大模型的训练，以减轻灾难性遗忘问题。

Result: 研究发现，两种模型（通过生长训练的Stack LLM和未通过生长训练的LLM）在领域知识方面都有所提高。然而，推理和阅读理解随时间下降，表明存在灾难性遗忘的迹象。Stack LLM表现出较少的下降，尤其是在阅读理解方面，显示出增强的保留能力。在偏见评估中，基线LLM在持续微调后变得越来越中立，而Stack LLM保持了约60-61%的稳定偏见比例。

Conclusion: 研究结果表明，基于生长的预训练可能在抵抗灾难性遗忘方面带来适度的改进，尽管在处理社会偏见方面仍存在权衡。

Abstract: Catastrophic forgetting is a significant challenge in continual learning, in
which a model loses prior knowledge when it is fine-tuned on new tasks. This
problem is particularly critical for large language models (LLMs) undergoing
continual learning, as retaining performance across diverse domains is
important for their general utility. In this paper, we explore model growth, a
promising strategy that leverages smaller models to expedite and structure the
training of larger ones for mitigating the catastrophic forgetting problem.
Although growth-based pretraining, particularly via transformer stacking, has
shown promise in accelerating convergence, its impact on forgetting remains
under-explored. Therefore, we evaluate whether growth-based models can retain
previously learned capabilities more effectively across a sequence of
fine-tuning tasks involving domain knowledge, reasoning, reading comprehension,
and bias. Our findings show that both models -- one trained with growth (Stack
LLM) and one without (LLM) -- exhibit improvements in domain knowledge.
However, reasoning and reading comprehension degrade over time, indicating
signs of catastrophic forgetting. Stack LLM consistently shows less
degradation, especially in reading comprehension, suggesting enhanced retention
capabilities. Interestingly, in bias evaluation, the baseline LLM becomes
progressively more neutral with continued fine-tuning, while Stack LLM
maintains a steady bias ratio around 60--61\%. These results indicate that
growth-based pretraining may deliver modest improvements in resisting
catastrophic forgetting, though trade-offs remain in handling social biases.

</details>


### [72] [DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Taks Based on Data and Model Compression](https://arxiv.org/abs/2509.01221)
*Wei Huang,Huang Wei,Yinggui Wang*

Main category: cs.CL

TL;DR: 本文提出了一种数据和模型压缩框架（DaMoC），用于快速识别最佳的大型语言模型（LLMs）进行微调，通过数据和模型层面的优化，显著减少了训练时间。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）在特定领域任务中表现不佳，需要进行微调，但选择最佳模型进行微调是一个挑战。因此，需要一种快速识别最佳LLM的方法。

Method: DaMoC框架包括数据层面和模型层面的优化。在数据层面，对数据过滤方法进行了系统分类，并增强了关键标记的密度，然后使用LLM迭代重写文本以优化表达。在模型层面，利用层相似性分数评估每层的重要性，并移除重要性较低的层，引入稀疏合并范式以尽可能保留原始模型的能力。

Result: 在四个数据集上的实验表明，DaMoC框架可以节省约20倍的训练时间，并选择最优的LLM。

Conclusion: 通过DaMoC框架，可以在节省约20倍训练时间的情况下选择最优的LLM。

Abstract: Large language models (LLMs) excel in general tasks but struggle with
domain-specific ones, requiring fine-tuning with specific data. With many
open-source LLMs available, selecting the best model for fine-tuning downstream
tasks is challenging, primarily focusing on how to quickly identify the optimal
LLM. We introduce a Data and Model Compression Framework (DaMoC) that addresses
this challenge by: 1) Data Level: A systematic categorization of data filtering
methodologies for LLMs is first established, classifying them into three
distinct paradigms: (1) distribution-aware methods, (2) quality-aware methods,
and (3) hybrid approaches considering both dimensions. Further, we enhance the
density of key tokens in the text achieving token compression. Subsequently, we
use an LLM to iterative rewrite the text to optimize its expression. 2) Model
Level: We use layer similarity scores to assess each layer's importance and
remove those with lower importance. Then, we introduce a sparse merging
paradigm to preserve as much of the original model's capability as possible.
Extensive experiments on four datasets, medical Q&A, financial Q&A, general
Q&A, and reading comprehension, show that we can select the optimal LLM while
saving approximately 20-fold in training time.

</details>


### [73] [Rethinking the Chain-of-Thought: The Roles of In-Context Learning and Pre-trained Priors](https://arxiv.org/abs/2509.01236)
*Hao Yang,Zhiyu Yang,Yunjie Zhang,Shanyi Zhu,Lin Yang*

Main category: cs.CL

TL;DR: This paper explores the working mechanisms of Chain-of-Thought reasoning from the perspective of the dual relationship between in-context learning and pretrained priors. It reveals that the model heavily relies on pretrained priors, but providing sufficient exemplars can shift decision-making towards in-context signals. Additionally, long Chain-of-Thought prompting improves performance on downstream tasks.


<details>
  <summary>Details</summary>
Motivation: Chain-of-Thought reasoning has emerged as a pivotal methodology for enhancing model inference capabilities. Despite growing interest in Chain-of-Thought reasoning, its underlying mechanisms remain unclear.

Method: We first conduct a fine-grained lexical-level analysis of rationales to examine the model's reasoning behavior. Then, by incrementally introducing noisy exemplars, we examine how the model balances pretrained priors against erroneous in-context information. Finally, we investigate whether prompt engineering can induce slow thinking in large language models.

Result: Our extensive experiments reveal three key findings: (1) The model not only quickly learns the reasoning structure at the lexical level but also grasps deeper logical reasoning patterns, yet it heavily relies on pretrained priors. (2) Providing sufficient exemplars shifts the model's decision-making from pretrained priors to in-context signals, while misleading prompts introduce instability. (3) Long Chain-of-Thought prompting can induce the model to generate longer reasoning chains, thereby improving its performance on downstream tasks.

Conclusion: Long Chain-of-Thought prompting can induce the model to generate longer reasoning chains, thereby improving its performance on downstream tasks.

Abstract: Chain-of-Thought reasoning has emerged as a pivotal methodology for enhancing
model inference capabilities. Despite growing interest in Chain-of-Thought
reasoning, its underlying mechanisms remain unclear. This paper explores the
working mechanisms of Chain-of-Thought reasoning from the perspective of the
dual relationship between in-context learning and pretrained priors. We first
conduct a fine-grained lexical-level analysis of rationales to examine the
model's reasoning behavior. Then, by incrementally introducing noisy exemplars,
we examine how the model balances pretrained priors against erroneous
in-context information. Finally, we investigate whether prompt engineering can
induce slow thinking in large language models. Our extensive experiments reveal
three key findings: (1) The model not only quickly learns the reasoning
structure at the lexical level but also grasps deeper logical reasoning
patterns, yet it heavily relies on pretrained priors. (2) Providing sufficient
exemplars shifts the model's decision-making from pretrained priors to
in-context signals, while misleading prompts introduce instability. (3) Long
Chain-of-Thought prompting can induce the model to generate longer reasoning
chains, thereby improving its performance on downstream tasks.

</details>


### [74] [Annotation and modeling of emotions in a textual corpus: an evaluative approach](https://arxiv.org/abs/2509.01260)
*Jonas Noblet*

Main category: cs.CL

TL;DR: 本文探讨了情感在文本中的表现形式，并通过语言模型分析了标注过程和情感情境的区分能力。


<details>
  <summary>Details</summary>
Motivation: 情感在人类社会功能中是一个关键现象，但其文本表现形式仍然是一个开放性问题。本文研究了一个工业语料库，该语料库采用评价方法进行人工标注，提供了一种补充传统方法的不同视角。

Method: 使用基于这些标注的语言模型，我们展示了建模标注过程的可能性，并且可变性由潜在的语言特征驱动。

Result: 我们收集的标注显示出显著的不一致，但它们遵循稳定的统计趋势。

Conclusion: 语言模型似乎能够根据评价标准区分情感情境。

Abstract: Emotion is a crucial phenomenon in the functioning of human beings in
society. However, it remains a widely open subject, particularly in its textual
manifestations. This paper examines an industrial corpus manually annotated
following an evaluative approach to emotion. This theoretical framework, which
is currently underutilized, offers a different perspective that complements
traditional approaches. Noting that the annotations we collected exhibit
significant disagreement, we hypothesized that they nonetheless follow stable
statistical trends. Using language models trained on these annotations, we
demonstrate that it is possible to model the labeling process and that
variability is driven by underlying linguistic features. Conversely, our
results indicate that language models seem capable of distinguishing emotional
situations based on evaluative criteria.

</details>


### [75] [Culture is Everywhere: A Call for Intentionally Cultural Evaluation](https://arxiv.org/abs/2509.01301)
*Juhyun Oh,Inha Cha,Michael Saxon,Hyunseung Lim,Shaily Bhatt,Alice Oh*

Main category: cs.CL

TL;DR: 本文批评了当前基于琐事的文化评估方法，提出了有意图的文化评估方法，以更好地反映文化在评估中的作用。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法将文化简化为静态事实或价值观，忽略了文化在评估中的复杂性和互动性。

Method: 本文通过分析现有评估方法的不足，提出了一种新的文化评估方法，并讨论了其未来发展方向。

Result: 本文提出了有意图的文化评估方法，并讨论了其在NLP研究中的重要性。

Conclusion: 本文主张采用有意图的文化评估方法，以系统地考察评估中嵌入的文化假设，并强调研究者立场对于促进包容性和文化一致的NLP研究的重要性。

Abstract: The prevailing ``trivia-centered paradigm'' for evaluating the cultural
alignment of large language models (LLMs) is increasingly inadequate as these
models become more advanced and widely deployed. Existing approaches typically
reduce culture to static facts or values, testing models via multiple-choice or
short-answer questions that treat culture as isolated trivia. Such methods
neglect the pluralistic and interactive realities of culture, and overlook how
cultural assumptions permeate even ostensibly ``neutral'' evaluation settings.
In this position paper, we argue for \textbf{intentionally cultural
evaluation}: an approach that systematically examines the cultural assumptions
embedded in all aspects of evaluation, not just in explicitly cultural tasks.
We systematically characterize the what, how, and circumstances by which
culturally contingent considerations arise in evaluation, and emphasize the
importance of researcher positionality for fostering inclusive, culturally
aligned NLP research. Finally, we discuss implications and future directions
for moving beyond current benchmarking practices, discovering important
applications that we don't know exist, and involving communities in evaluation
design through HCI-inspired participatory methodologies.

</details>


### [76] [TableZoomer: A Collaborative Agent Framework for Large-scale Table Question Answering](https://arxiv.org/abs/2509.01312)
*Sishi Xiong,Ziyang He,Zhongjiang He,Yu Zhao,Changzai Pan,Jie Zhang,Zhenhe Wu,Shuangyong Song,Yongxiang Li*

Main category: cs.CL

TL;DR: 本文提出了TableZoomer，一个基于编程的LLM驱动代理框架，通过结构化表格模式、查询感知的表格缩放机制和Program-of-Thoughts (PoT)策略，显著提升了表格问答任务的性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在表格问答（TQA）任务中通过提示工程显示出前景，但在工业应用中面临结构性异质性、目标数据定位困难和复杂推理瓶颈等挑战。为此，本文提出了TableZoomer，一个基于编程的LLM驱动代理框架。

Method: 本文提出了TableZoomer，这是一个基于编程的LLM驱动代理框架，包含三个关键创新：(1) 用结构化表格模式替代原始完全语义化的表格以弥合语义差距并减少计算复杂度；(2) 一种查询感知的表格缩放机制，通过列选择和实体链接动态生成子表格模式，显著提高目标定位效率；(3) 一种Program-of-Thoughts (PoT)策略，将查询转换为可执行代码以减轻数值幻觉。此外，我们将推理工作流与ReAct范式集成以实现迭代推理。

Result: 实验表明，我们的框架在保持可用性优势的同时，显著提升了不同规模表格的性能和可扩展性。当使用Qwen3-8B-Instruct LLM实现时，TableZoomer在大规模DataBench数据集和TableBench数据集的小规模事实核查任务中，分别比传统PoT方法提高了19.34%和25%的准确性。

Conclusion: 本文提出的TableZoomer框架在保持可用性优势的同时，显著提升了性能和可扩展性。当使用Qwen3-8B-Instruct LLM实现时，TableZoomer在大规模DataBench数据集和TableBench数据集的小规模事实核查任务中，分别比传统PoT方法提高了19.34%和25%的准确性。

Abstract: While large language models (LLMs) have shown promise in the table question
answering (TQA) task through prompt engineering, they face challenges in
industrial applications, including structural heterogeneity, difficulties in
target data localization, and bottlenecks in complex reasoning. To address
these limitations, this paper presents TableZoomer, a novel LLM-powered,
programming-based agent framework. It introduces three key innovations: (1)
replacing the original fully verbalized table with structured table schema to
bridge the semantic gap and reduce computational complexity; (2) a query-aware
table zooming mechanism that dynamically generates sub-table schema through
column selection and entity linking, significantly improving target
localization efficiency; and (3) a Program-of-Thoughts (PoT) strategy that
transforms queries into executable code to mitigate numerical hallucination.
Additionally, we integrate the reasoning workflow with the ReAct paradigm to
enable iterative reasoning. Extensive experiments demonstrate that our
framework maintains the usability advantages while substantially enhancing
performance and scalability across tables of varying scales. When implemented
with the Qwen3-8B-Instruct LLM, TableZoomer achieves accuracy improvements of
19.34% and 25% over conventional PoT methods on the large-scale DataBench
dataset and the small-scale Fact Checking task of TableBench dataset,
respectively.

</details>


### [77] [Can Smaller LLMs do better? Unlocking Cross-Domain Potential through Parameter-Efficient Fine-Tuning for Text Summarization](https://arxiv.org/abs/2509.01314)
*Anum Afzal,Mehul Kumawat,Florian Matthes*

Main category: cs.CL

TL;DR: 研究探讨了如何通过参数高效微调技术（PEFTs）来提高大型语言模型在低资源领域中的适应能力和性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然具有通用任务求解能力，但它们在新领域中的适应能力仍然存在疑问。此外，简单地对模型进行微调以融入新领域的知识在计算上是昂贵且耗时的，特别是在领域本身是低资源且缺乏标记数据的情况下。

Method: 研究采用了参数高效微调技术（PEFTs），并在14个来自科学、医学、法律和新闻领域的训练数据集上对Llama-3-8B-Instruct进行了基准测试。研究评估了是否可以利用数据集之间的内在语言共性来进行高效的领域适应。

Result: 实验表明，在低资源领域中，使用Within-Domain Adapters进行推理可以取得比Few-Shot以及更大的Llama-3-70B-Instruct更好的性能。

Conclusion: 研究显示，在低资源领域中，使用Within-Domain Adapters进行推理可以比Few-Shot以及更大的Llama-3-70B-Instruct取得更好的性能。此外，在没有Within-Domain Adapters的情况下，研究探索了使用Cross-Domain Adapters以及适配器的战略组合来利用跨领域的内在语言相似性，从而提高在低资源环境中的适应性和性能。

Abstract: Large Language Models (LLMs), being generic task solvers, are versatile.
However, despite the vast amount of data they are trained on, there are
speculations about their adaptation capabilities to a new domain. Additionally,
the simple fine-tuning of the model to incorporate knowledge of a new domain is
computationally expensive and time-consuming. This becomes more challenging
when the domain in question is also low-resource, and labeled data is
unavailable. We leverage parameter-efficient fine-tuning techniques (PEFTs) on
high-resource datasets to address these challenges to improve performance on
unseen low-resource domains. Throughout our experiments, we evaluate whether
intrinsic linguistic commonalities between datasets can be leveraged for
efficient domain adaptation. We benchmark six PEFTs with
\texttt{Llama-3-8B-Instruct} on 14 training datasets from the Scientific,
Medical, Legal, and News domains for a Text Summarization task. Our experiments
show that for low-resource domains, inference using Within-Domain Adapters can
achieve better performance than Few-Shot as well as a much larger
\texttt{Llama-3-70B-Instruct}. Lastly, in the absence of Within-Domain
Adapters, we explore the concept of using Cross-Domain Adapters as well as the
strategic combinations of adapters to leverage intrinsic language similarities
across domains, facilitating better adaptability and performance in
low-resource settings.

</details>


### [78] [LongCat-Flash Technical Report](https://arxiv.org/abs/2509.01322)
*Meituan LongCat Team,Bayan,Bei Li,Bingye Lei,Bo Wang,Bolin Rong,Chao Wang,Chao Zhang,Chen Gao,Chen Zhang,Cheng Sun,Chengcheng Han,Chenguang Xi,Chi Zhang,Chong Peng,Chuan Qin,Chuyu Zhang,Cong Chen,Congkui Wang,Dan Ma,Daoru Pan,Defei Bu,Dengchang Zhao,Deyang Kong,Dishan Liu,Feiye Huo,Fengcun Li,Fubao Zhang,Gan Dong,Gang Liu,Gang Xu,Ge Li,Guoqiang Tan,Guoyuan Lin,Haihang Jing,Haomin Fu,Haonan Yan,Haoxing Wen,Haozhe Zhao,Hong Liu,Hongmei Shi,Hongyan Hao,Hongyin Tang,Huantian Lv,Hui Su,Jiacheng Li,Jiahao Liu,Jiahuan Li,Jiajun Yang,Jiaming Wang,Jian Yang,Jianchao Tan,Jiaqi Sun,Jiaqi Zhang,Jiawei Fu,Jiawei Yang,Jiaxi Hu,Jiayu Qin,Jingang Wang,Jiyuan He,Jun Kuang,Junhui Mei,Kai Liang,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Liang Gao,Liang Shi,Lianhui Ma,Lin Qiu,Lingbin Kong,Lingtong Si,Linkun Lyu,Linsen Guo,Liqi Yang,Lizhi Yan,Mai Xia,Man Gao,Manyuan Zhang,Meng Zhou,Mengxia Shen,Mingxiang Tuo,Mingyang Zhu,Peiguang Li,Peng Pei,Peng Zhao,Pengcheng Jia,Pingwei Sun,Qi Gu,Qianyun Li,Qingyuan Li,Qiong Huang,Qiyuan Duan,Ran Meng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shizhe Wu,Shuai Liang,Shuo Wang,Suogui Dang,Tao Fang,Tao Li,Tefeng Chen,Tianhao Bai,Tianhao Zhou,Tingwen Xie,Wei He,Wei Huang,Wei Liu,Wei Shi,Wei Wang,Wei Wu,Weikang Zhao,Wen Zan,Wenjie Shi,Xi Nan,Xi Su,Xiang Li,Xiang Mei,Xiangyang Ji,Xiangyu Xi,Xiangzhou Huang,Xianpeng Li,Xiao Fu,Xiao Liu,Xiao Wei,Xiaodong Cai,Xiaolong Chen,Xiaoqing Liu,Xiaotong Li,Xiaowei Shi,Xiaoyu Li,Xili Wang,Xin Chen,Xing Hu,Xingyu Miao,Xinyan He,Xuemiao Zhang,Xueyuan Hao,Xuezhi Cao,Xunliang Cai,Xurui Yang,Yan Feng,Yang Bai,Yang Chen,Yang Yang,Yaqi Huo,Yerui Sun,Yifan Lu,Yifan Zhang,Yipeng Zang,Yitao Zhai,Yiyang Li,Yongjing Yin,Yongkang Lv,Yongwei Zhou,Yu Yang,Yuchen Xie,Yueqing Sun,Yuewen Zheng,Yuhua Wei,Yulei Qian,Yunfan Liang,Yunfang Tai,Yunke Zhao,Zeyang Yu,Zhao Zhang,Zhaohua Yang,Zhenchao Zhang,Zhikang Xia,Zhiye Zou,Zhizhao Zeng,Zhongda Su,Zhuofan Chen,Zijian Zhang,Ziwen Wang,Zixu Jiang,Zizhe Zhao,Zongyu Wang,Zunhai Su*

Main category: cs.CL

TL;DR: LongCat-Flash是一个5600亿参数的Mixture-of-Experts语言模型，旨在提高计算效率和代理能力，通过创新的设计和扩展框架实现了高效的训练和推理。


<details>
  <summary>Details</summary>
Motivation: 为了实现可扩展的效率，LongCat-Flash旨在优化资源使用并提高推理效率和吞吐量。

Method: LongCat-Flash采用了两种创新设计：零计算专家和快捷连接的MoE，同时开发了一个全面的扩展框架，结合了超参数转移、模型增长初始化、多方面稳定性套件和确定性计算。

Result: LongCat-Flash在30天内完成了超过20万亿个标记的模型训练，并实现了每秒超过100个标记的推理速度，成本为每百万输出标记0.70美元。

Conclusion: LongCat-Flash是一个具有高度竞争力的模型，尤其在代理任务中表现出色，并且其模型检查点已开源以促进社区研究。

Abstract: We introduce LongCat-Flash, a 560-billion-parameter Mixture-of-Experts (MoE)
language model designed for both computational efficiency and advanced agentic
capabilities. Stemming from the need for scalable efficiency, LongCat-Flash
adopts two novel designs: (a) Zero-computation Experts, which enables dynamic
computational budget allocation and activates 18.6B-31.3B (27B on average) per
token depending on contextual demands, optimizing resource usage. (b)
Shortcut-connected MoE, which enlarges the computation-communication overlap
window, demonstrating notable gains in inference efficiency and throughput
compared to models of a comparable scale. We develop a comprehensive scaling
framework for large models that combines hyperparameter transfer, model-growth
initialization, a multi-pronged stability suite, and deterministic computation
to achieve stable and reproducible training. Notably, leveraging the synergy
among scalable architectural design and infrastructure efforts, we complete
model training on more than 20 trillion tokens within 30 days, while achieving
over 100 tokens per second (TPS) for inference at a cost of \$0.70 per million
output tokens. To cultivate LongCat-Flash towards agentic intelligence, we
conduct a large-scale pre-training on optimized mixtures, followed by targeted
mid- and post-training on reasoning, code, and instructions, with further
augmentation from synthetic data and tool use tasks. Comprehensive evaluations
demonstrate that, as a non-thinking foundation model, LongCat-Flash delivers
highly competitive performance among other leading models, with exceptional
strengths in agentic tasks. The model checkpoint of LongCat-Flash is
open-sourced to foster community research.
  LongCat Chat: https://longcat.ai
  Hugging Face: https://huggingface.co/meituan-longcat
  GitHub: https://github.com/meituan-longcat

</details>


### [79] [KoBLEX: Open Legal Question Answering with Multi-hop Reasoning](https://arxiv.org/abs/2509.01324)
*Jihyung Lee,Daehui Kim,Seonjeong Hwang,Hyounghun Kim,Gary Lee*

Main category: cs.CL

TL;DR: 本文提出了一种新的法律问答基准测试KoBLEX，并介绍了一种名为ParSeR的方法，该方法通过生成参数化条款来提高法律问答的准确性。实验结果显示，ParSeR在多个大型语言模型上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试无法评估开放性且基于条款的问答任务。因此，本文引入了KoBLEX基准测试，用于评估基于条款的多跳法律推理。

Method: 本文提出了Parametric provision-guided Selection Retrieval (ParSeR) 方法，该方法利用大型语言模型生成的参数化条款来引导法律依据和可靠的答案。ParSeR通过生成参数化条款并采用三阶段顺序检索过程，促进了复杂法律问题的多跳推理。

Result: 实验结果表明，ParSeR在多个大型语言模型上表现优于强基线，取得了最佳结果。特别是在与标准检索相比，ParSeR在F1和LF-Eval指标上分别提升了37.91和30.81。

Conclusion: 实验结果表明，ParSeR在多个大型语言模型上 consistently 超过强基线，取得了最佳结果。特别是与标准检索相比，ParSeR在F1和LF-Eval上分别提高了37.91和30.81。进一步分析表明，ParSeR在推理深度上能够高效地保持一致的性能。

Abstract: Large Language Models (LLM) have achieved remarkable performances in general
domains and are now extending into the expert domain of law. Several benchmarks
have been proposed to evaluate LLMs' legal capabilities. However, these
benchmarks fail to evaluate open-ended and provision-grounded Question
Answering (QA). To address this, we introduce a Korean Benchmark for Legal
EXplainable QA (KoBLEX), designed to evaluate provision-grounded, multi-hop
legal reasoning. KoBLEX includes 226 scenario-based QA instances and their
supporting provisions, created using a hybrid LLM-human expert pipeline. We
also propose a method called Parametric provision-guided Selection Retrieval
(ParSeR), which uses LLM-generated parametric provisions to guide legally
grounded and reliable answers. ParSeR facilitates multi-hop reasoning on
complex legal questions by generating parametric provisions and employing a
three-stage sequential retrieval process. Furthermore, to better evaluate the
legal fidelity of the generated answers, we propose Legal Fidelity Evaluation
(LF-Eval). LF-Eval is an automatic metric that jointly considers the question,
answer, and supporting provisions and shows a high correlation with human
judgments. Experimental results show that ParSeR consistently outperforms
strong baselines, achieving the best results across multiple LLMs. Notably,
compared to standard retrieval with GPT-4o, ParSeR achieves +37.91 higher F1
and +30.81 higher LF-Eval. Further analyses reveal that ParSeR efficiently
delivers consistent performance across reasoning depths, with ablations
confirming the effectiveness of ParSeR.

</details>


### [80] [Can Large Language Models Master Complex Card Games?](https://arxiv.org/abs/2509.01328)
*Wei Wang,Fuqing Bie,Junzhe Chen,Dan Zhang,Shiyu Huang,Evgeny Kharlamov,Jie Tang*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）在掌握复杂卡牌游戏方面的潜力。评估结果显示，LLMs可以通过在高质量数据上进行监督微调来接近强大游戏AI的性能，并能够同时掌握多种复杂的卡牌游戏。然而，掌握复杂游戏会导致LLMs的通用能力下降，但这种下降可以通过整合一定量的通用指令数据来缓解。


<details>
  <summary>Details</summary>
Motivation: 复杂游戏长期以来一直是测试人工智能算法进展的重要基准。AlphaGo、AlphaZero和MuZero在围棋和国际象棋中击败了顶级人类玩家，引起了社会对人工智能的广泛关注。同时，大型语言模型（LLMs）在各种任务中表现出色，这引发了关于LLMs是否能在复杂游戏中取得类似成功的疑问。

Method: 我们系统地评估了LLMs在八种不同的卡牌游戏中的学习能力，评估了微调对高质量游戏数据的影响，并检查了模型在掌握这些游戏的同时保持通用能力的能力。

Result: 研究结果表明：(1) LLMs可以通过在高质量数据上进行监督微调来接近强大游戏AI的性能；(2) LLMs可以同时掌握多种复杂的卡牌游戏，对于规则相似的游戏性能有所增强，而对于规则不同的游戏则出现冲突；(3) 在掌握复杂游戏时，LLMs会经历通用能力的下降，但通过整合一定量的通用指令数据可以缓解这种下降。

Conclusion: 评估结果展示了LLMs的强大学习能力和多功能性。

Abstract: Complex games have long been an important benchmark for testing the progress
of artificial intelligence algorithms. AlphaGo, AlphaZero, and MuZero have
defeated top human players in Go and Chess, garnering widespread societal
attention towards artificial intelligence. Concurrently, large language models
(LLMs) have exhibited remarkable capabilities across various tasks, raising the
question of whether LLMs can achieve similar success in complex games. In this
paper, we explore the potential of LLMs in mastering complex card games. We
systematically assess the learning capabilities of LLMs across eight diverse
card games, evaluating the impact of fine-tuning on high-quality gameplay data,
and examining the models' ability to retain general capabilities while
mastering these games. Our findings indicate that: (1) LLMs can approach the
performance of strong game AIs through supervised fine-tuning on high-quality
data, (2) LLMs can master multiple complex card games simultaneously, with
performance augmentation for games with similar rules and conflicts for
dissimilar ones, and (3) LLMs experience a decline in general capabilities when
mastering complex games, but this decline can be mitigated by integrating a
certain amount of general instruction data. The evaluation results demonstrate
strong learning ability and versatility of LLMs.

</details>


### [81] [Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic](https://arxiv.org/abs/2509.01363)
*Mohammad Zbeeb,Hasan Abed Al Kader Hammoud,Bernard Ghanem*

Main category: cs.CL

TL;DR: 本研究提出了一种从现有模型中提取并转移推理能力的方法，通过简单的张量算术提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常需要昂贵的优化（如强化学习）来掌握复杂的推理任务。本研究旨在探索一种更高效的方法，以提取和转移推理能力。

Method: 从两个相同初始化的Qwen2.5模型中提取推理向量，一个经过监督微调（SFT），另一个经过组相对策略优化（GRPO）。通过简单的算术将该向量添加到兼容的指令调优模型中，以提升性能。

Result: 在多个推理基准测试中，添加推理向量显著提高了性能，例如GSM8K (+4.9%)、HumanEval (+4.3%)、SciQ (+1.7%) 和 BigBenchHard (+12.3% for the 1.5B model)。相反，减去向量会导致性能显著下降。

Conclusion: 本研究展示了如何从现有的开源模型中提取推理能力，并通过简单的张量算术重新利用，为增强模型提供了一种实用的方法。

Abstract: Large language models often require costly optimization, such as
reinforcement learning, to master complex reasoning tasks. This work
demonstrates that reasoning ability, once learned, can be extracted and
transferred between models as a compact task vector. We source two publicly
available, identically initialized Qwen2.5 models, one fine-tuned with
supervised fine-tuning (SFT) and the other with group relative policy
optimization (GRPO) on the same dataset. From these, we extract a reasoning
vector: $v_{\text{reason}} = \theta_{\text{GRPO}} - \theta_{\text{SFT}}$. We
hypothesize that this vector captures the reasoning capability instilled by
reinforcement learning while factoring out shared knowledge from the SFT
process. When added to compatible instruction-tuned models through simple
arithmetic, this vector consistently improves performance across diverse
reasoning benchmarks: GSM8K (+4.9%), HumanEval (+4.3%), SciQ (+1.7%), and
BigBenchHard (+12.3% for the 1.5B model). The performance improvements persist
under adversarial conditions. Conversely, subtracting the vector causes
significant performance degradation (-11.8% on GSM8K), demonstrating the
vector's strong contribution to the model's reasoning abilities. This work
shows how reasoning capabilities, typically developed through expensive
training, can be extracted from existing open-source models and reused through
simple tensor arithmetic, offering a practical way to enhance models by
recycling prior computational investments.

</details>


### [82] [WATCHED: A Web AI Agent Tool for Combating Hate Speech by Expanding Data](https://arxiv.org/abs/2509.01379)
*Paloma Piot,Diego Sánchez,Javier Parapar*

Main category: cs.CL

TL;DR: 本文介绍了WATCHED，一个用于帮助内容审核员处理仇恨言论的聊天机器人。该工具结合了大型语言模型和多个专业工具，能够检测仇恨言论并解释其决策。实验结果表明，该方法在性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 需要结合自动化系统的速度和规模与人类审核员的判断和洞察力的工具，以解决在线危害问题。

Method: 我们提出了WATCHED，一个聊天机器人，旨在帮助内容审核员处理仇恨言论。该聊天机器人被构建为一个人工智能代理系统，使用大型语言模型以及几个专业工具。

Result: 实验结果表明，我们的方法超越了现有的最先进方法，达到了宏F1分数0.91。

Conclusion: 该工具有助于减少在线危害，通过支持人工智能和人工监督之间的协作。

Abstract: Online harms are a growing problem in digital spaces, putting user safety at
risk and reducing trust in social media platforms. One of the most persistent
forms of harm is hate speech. To address this, we need tools that combine the
speed and scale of automated systems with the judgment and insight of human
moderators. These tools should not only find harmful content but also explain
their decisions clearly, helping to build trust and understanding. In this
paper, we present WATCHED, a chatbot designed to support content moderators in
tackling hate speech. The chatbot is built as an Artificial Intelligence Agent
system that uses Large Language Models along with several specialised tools. It
compares new posts with real examples of hate speech and neutral content, uses
a BERT-based classifier to help flag harmful messages, looks up slang and
informal language using sources like Urban Dictionary, generates
chain-of-thought reasoning, and checks platform guidelines to explain and
support its decisions. This combination allows the chatbot not only to detect
hate speech but to explain why content is considered harmful, grounded in both
precedent and policy. Experimental results show that our proposed method
surpasses existing state-of-the-art methods, reaching a macro F1 score of 0.91.
Designed for moderators, safety teams, and researchers, the tool helps reduce
online harms by supporting collaboration between AI and human oversight.

</details>


### [83] [ABCD-LINK: Annotation Bootstrapping for Cross-Document Fine-Grained Links](https://arxiv.org/abs/2509.01387)
*Serwar Basch,Ilia Kuznetsov,Tom Hope,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文介绍了一个新的领域无关框架，用于从头开始选择最佳性能方法并在新领域中标注跨文档链接。通过生成和验证半合成数据集，进行自动评估，并进行大规模的人类评估研究，结果表明结合检索模型与LLMs可以显著提高跨文档链接的精度。


<details>
  <summary>Details</summary>
Motivation: 理解文档之间的细粒度关系对于许多应用领域至关重要。然而，由于缺乏高效的方法来创建跨文档链接的训练和评估数据集，自动化辅助的研究受到限制。

Method: 我们引入了一个新的领域无关框架，用于从头开始选择最佳性能方法并在新领域中标注跨文档链接。首先生成并验证半合成的互联文档数据集，然后使用这些数据进行自动评估，生成最佳性能链接方法的候选列表。这些方法随后用于大规模的人类评估研究，得出自然文本对的性能估计。

Result: 我们在两个不同的领域——同行评审和新闻中应用了我们的框架，并展示了结合检索模型与LLMs可以得到78%的人类评分员的链接批准，这比单一强检索器的精度翻了一番。

Conclusion: 我们的框架使跨文档理解在不同应用场景中的系统研究成为可能，并且生成的新型数据集为诸如媒体框架和同行评审等跨文档任务奠定了基础。我们公开了代码、数据和注释协议。

Abstract: Understanding fine-grained relations between documents is crucial for many
application domains. However, the study of automated assistance is limited by
the lack of efficient methods to create training and evaluation datasets of
cross-document links. To address this, we introduce a new domain-agnostic
framework for selecting a best-performing approach and annotating
cross-document links in a new domain from scratch. We first generate and
validate semi-synthetic datasets of interconnected documents. This data is used
to perform automatic evaluation, producing a shortlist of best-performing
linking approaches. These approaches are then used in an extensive human
evaluation study, yielding performance estimates on natural text pairs. We
apply our framework in two distinct domains -- peer review and news -- and show
that combining retrieval models with LLMs achieves 78\% link approval from
human raters, more than doubling the precision of strong retrievers alone. Our
framework enables systematic study of cross-document understanding across
application scenarios, and the resulting novel datasets lay foundation for
numerous cross-document tasks like media framing and peer review. We make the
code, data, and annotation protocols openly available.

</details>


### [84] [Analysing the Language of Neural Audio Codecs](https://arxiv.org/abs/2509.01390)
*Joonyong Park,Shinnosuke Takamichi,David M. Chan,Shunsuke Kando,Yuki Saito,Hiroshi Saruwatari*

Main category: cs.CL

TL;DR: 本研究分析了神经音频编解码器的统计和语言特性，发现它们的标记表现出类似语言的统计模式，并且这些特性与语音识别和重合成任务的性能提升有关。


<details>
  <summary>Details</summary>
Motivation: 评估这些标记级别的特性如何与合成语音中的语义和声学保存相关联，从而改进语音识别和重合成任务的性能。

Method: 本研究对神经音频编解码器（NAC）的统计和语言特性进行了比较分析，检查了不同NAC模型产生的离散语音标记是否符合Zipf定律和Heaps定律等语言统计规律，以及它们的熵和冗余度。

Result: NAC标记，特别是3-grams，表现出类似语言的统计模式。此外，这些特性以及信息内容的测量被发现与语音识别和重合成任务的性能提升相关。

Conclusion: 这些发现为NAC标记序列的结构提供了见解，并有助于设计更有效的生成语音模型。

Abstract: This study presents a comparative analysis of the statistical and linguistic
properties of neural audio codecs (NACs). We investigate discrete speech tokens
produced by various NAC models, examining their adherence to linguistic
statistical laws such as Zipf's law and Heaps' law, as well as their entropy
and redundancy. To assess how these token-level properties relate to semantic
and acoustic preservation in synthesized speech, we evaluate intelligibility
using error rates of automatic speech recognition, and quality using the UTMOS
score. Our results reveal that NAC tokens, particularly 3-grams, exhibit
language-like statistical patterns. Moreover, these properties, together with
measures of information content, are found to correlate with improved
performances in speech recognition and resynthesis tasks. These findings offer
insights into the structure of NAC token sequences and inform the design of
more effective generative speech models.

</details>


### [85] [LLMs cannot spot math errors, even when allowed to peek into the solution](https://arxiv.org/abs/2509.01395)
*KV Aditya Srivatsa,Kaushal Kumar Maurya,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: 本文研究了定位学生解决方案中第一个错误步骤的挑战，并提出了一种生成中间纠正的学生解决方案的方法，以提高性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在数学问题上表现出色，但它们在元推理任务中表现不佳，例如识别学生解决方案中的错误。因此，需要一种更有效的方法来定位学生解决方案中的第一个错误步骤。

Method: 本文研究了使用两个错误推理数据集（VtG和PRM800K）来定位分步解决方案中的第一个错误步骤的挑战，并提出了一种生成中间纠正的学生解决方案的方法。

Result: 实验表明，最先进的LLM即使在获得参考解决方案的情况下，也难以定位学生解决方案中的第一个错误步骤。然而，所提出的方法通过生成中间纠正的学生解决方案，提高了性能。

Conclusion: 本文提出了一种方法，通过生成中间纠正的学生解决方案来改进定位第一步错误的性能。

Abstract: Large language models (LLMs) demonstrate remarkable performance on math word
problems, yet they have been shown to struggle with meta-reasoning tasks such
as identifying errors in student solutions. In this work, we investigate the
challenge of locating the first error step in stepwise solutions using two
error reasoning datasets: VtG and PRM800K. Our experiments show that
state-of-the-art LLMs struggle to locate the first error step in student
solutions even when given access to the reference solution. To that end, we
propose an approach that generates an intermediate corrected student solution,
aligning more closely with the original student's solution, which helps improve
performance.

</details>


### [86] [Vis-CoT: A Human-in-the-Loop Framework for Interactive Visualization and Intervention in LLM Chain-of-Thought Reasoning](https://arxiv.org/abs/2509.01412)
*Kaviraj Pather,Elena Hadjigeorgiou,Arben Krasniqi,Claire Schmit,Irina Rusu,Marc Pons,Kabir Khan*

Main category: cs.CL

TL;DR: Vis-CoT 是一种人机协同框架，将线性链式思维文本转换为交互式推理图，提高推理的准确性和可信度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）通过链式思维（CoT）提示表现出强大的推理能力，但该过程是不透明的，这使得在高风险环境中进行验证、调试和控制变得困难。

Method: Vis-CoT 是一种人机协同框架，将线性链式思维文本转换为交互式推理图。用户可以可视化逻辑流程，识别错误步骤，并通过修剪错误路径和嫁接新的用户定义前提来干预。

Result: 在GSM8K和StrategyQA数据集上，Vis-CoT相比非交互基线的最终答案准确率提高了高达24个百分点。用户研究也显示了可用性和信任度的显著提升。

Conclusion: Vis-CoT 提供了一种实用的路径，通过结合大型语言模型和有针对性的人类监督，实现更可靠、可理解和协作的推理。

Abstract: Large language models (LLMs) show strong reasoning via chain-of-thought (CoT)
prompting, but the process is opaque, which makes verification, debugging, and
control difficult in high-stakes settings. We present Vis-CoT, a
human-in-the-loop framework that converts linear CoT text into an interactive
reasoning graph. Users can visualize the logical flow, identify flawed steps,
and intervene by pruning incorrect paths and grafting new, user-defined
premises. This shifts interaction from passive observation to active
collaboration, steering models toward more accurate and trustworthy
conclusions. Across GSM8K and StrategyQA, Vis-CoT improves final-answer
accuracy by up to 24 percentage points over non-interactive baselines. A user
study also shows large gains in perceived usability and trust. Vis-CoT points
to a practical path for more reliable, understandable, and collaborative
reasoning by combining LLMs with targeted human oversight.

</details>


### [87] [On the Alignment of Large Language Models with Global Human Opinion](https://arxiv.org/abs/2509.01418)
*Yang Liu,Masahiro Kaneko,Chenhui Chu*

Main category: cs.CL

TL;DR: 本研究创建了一个基于世界价值观调查的评估框架，以系统地评估LLMs在全球不同国家、语言和历史时期的人类观点对齐情况。结果表明，LLMs在与少数国家的观点对齐方面表现适当或过度，而与其他大多数国家的观点对齐不足。通过调整提示语言可以更有效地引导LLMs与相应国家的观点对齐。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在研究美国或少数国家的人群观点，缺乏全球国家样本和不同历史时期人类观点的研究，以及关于使用语言引导LLMs的讨论。同时，他们忽略了提示语言对LLMs观点对齐的潜在影响。

Method: 本研究基于世界价值观调查（WVS）创建了一个评估框架，以系统地评估LLMs在全球不同国家、语言和历史时期的人类观点对齐情况。

Result: LLMs在与少数国家的观点对齐方面表现适当或过度，而与其他大多数国家的观点对齐不足。通过调整提示语言可以更有效地引导LLMs与相应国家的观点对齐。此外，LLMs更倾向于与当代人口的观点对齐。

Conclusion: 本研究是首次对全球、语言和时间维度上大型语言模型（LLMs）的观点对齐进行全面调查，发现LLMs在与少数国家的观点对齐方面表现适当或过度，而与其他大多数国家的观点对齐不足。此外，通过调整提示语言可以更有效地引导LLMs与相应国家的观点对齐。

Abstract: Today's large language models (LLMs) are capable of supporting multilingual
scenarios, allowing users to interact with LLMs in their native languages. When
LLMs respond to subjective questions posed by users, they are expected to align
with the views of specific demographic groups or historical periods, shaped by
the language in which the user interacts with the model. Existing studies
mainly focus on researching the opinions represented by LLMs among demographic
groups in the United States or a few countries, lacking worldwide country
samples and studies on human opinions in different historical periods, as well
as lacking discussion on using language to steer LLMs. Moreover, they also
overlook the potential influence of prompt language on the alignment of LLMs'
opinions. In this study, our goal is to fill these gaps. To this end, we create
an evaluation framework based on the World Values Survey (WVS) to
systematically assess the alignment of LLMs with human opinions across
different countries, languages, and historical periods around the world. We
find that LLMs appropriately or over-align the opinions with only a few
countries while under-aligning the opinions with most countries. Furthermore,
changing the language of the prompt to match the language used in the
questionnaire can effectively steer LLMs to align with the opinions of the
corresponding country more effectively than existing steering methods. At the
same time, LLMs are more aligned with the opinions of the contemporary
population. To our knowledge, our study is the first comprehensive
investigation of the topic of opinion alignment in LLMs across global,
language, and temporal dimensions. Our code and data are publicly available at
https://github.com/nlply/global-opinion-alignment.

</details>


### [88] [Trusted Uncertainty in Large Language Models: A Unified Framework for Confidence Calibration and Risk-Controlled Refusal](https://arxiv.org/abs/2509.01455)
*Markus Oehri,Giulia Conti,Kaviraj Pather,Alexandre Rossi,Laia Serra,Adrian Parody,Rogvi Johannesen,Aviaja Petersen,Arben Krasniqi*

Main category: cs.CL

TL;DR: UniCR是一种统一的框架，可以将异构的不确定性证据转化为校准的概率，并通过原理性的拒绝来强制执行用户指定的错误预算，从而提高语言模型的可信度。


<details>
  <summary>Details</summary>
Motivation: 部署的语言模型不仅需要决定回答什么，还需要决定何时不回答。现有的方法在处理不确定性时存在不足，因此需要一种统一的框架来解决这个问题。

Method: UniCR通过将序列似然、自一致性分散性、检索兼容性以及工具或验证器反馈等异构不确定性证据转化为校准的概率，并利用温度缩放和适当评分进行轻量级校准头的学习，支持仅API模型，并使用符合风险控制进行分布自由保证。对于长格式生成，通过监督从检索证据中得出的原子事实性分数来对齐置信度与语义真实性，从而减少自信的幻觉。

Result: 实验结果表明，UniCR在短格式问答、带有执行测试的代码生成以及检索增强的长格式问答任务中均表现出色，改进了校准指标，降低了风险-覆盖率曲线下的面积，并在固定风险下提高了覆盖率。分析显示，证据矛盾、语义分散性和工具不一致是拒绝的主要驱动因素，提供了有用的通知信息。

Conclusion: UniCR是一个统一的框架，可以将异构的不确定性证据转化为校准的概率，并通过原理性的拒绝来强制执行用户指定的错误预算。实验表明，UniCR在多个任务中都表现出色，能够提高可信度，同时不需要微调基础模型，并且在分布变化下仍然有效。

Abstract: Deployed language models must decide not only what to answer but also when
not to answer. We present UniCR, a unified framework that turns heterogeneous
uncertainty evidence including sequence likelihoods, self-consistency
dispersion, retrieval compatibility, and tool or verifier feedback into a
calibrated probability of correctness and then enforces a user-specified error
budget via principled refusal. UniCR learns a lightweight calibration head with
temperature scaling and proper scoring, supports API-only models through
black-box features, and offers distribution-free guarantees using conformal
risk control. For long-form generation, we align confidence with semantic
fidelity by supervising on atomic factuality scores derived from retrieved
evidence, reducing confident hallucinations while preserving coverage.
Experiments on short-form QA, code generation with execution tests, and
retrieval-augmented long-form QA show consistent improvements in calibration
metrics, lower area under the risk-coverage curve, and higher coverage at fixed
risk compared to entropy or logit thresholds, post-hoc calibrators, and
end-to-end selective baselines. Analyses reveal that evidence contradiction,
semantic dispersion, and tool inconsistency are the dominant drivers of
abstention, yielding informative user-facing refusal messages. The result is a
portable recipe of evidence fusion to calibrated probability to risk-controlled
decision that improves trustworthiness without fine-tuning the base model and
remains valid under distribution shift.

</details>


### [89] [Robust Knowledge Editing via Explicit Reasoning Chains for Distractor-Resilient Multi-Hop QA](https://arxiv.org/abs/2509.01468)
*Yuchen Wu,Liang Ding,Li Shen,Dacheng Tao*

Main category: cs.CL

TL;DR: Reason-KE是一种基于推理链的编辑框架，能够高效且鲁棒地更新大型语言模型的知识，显著提高了多跳问答任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的知识编辑技术要么过度依赖表面线索，要么需要复杂的迭代流程，在噪声和多跳条件下容易崩溃。因此，需要一种更有效和鲁棒的知识编辑方法。

Method: Reason-KE是一个基于推理链的编辑框架，通过四个结构化阶段（事实确认、相关性确定、选择性应用和最终推理）来过滤干扰信息。

Result: 在MQuAKE-CF数据集上训练后，Reason-KE将Qwen2.5-7B的多跳QA准确率提高到90.2%，在严重干扰下仅下降6.3%，当答案泄露时下降不到1%。

Conclusion: Reason-KE在多跳问答任务中表现出色，证明了其在可靠LLM知识更新方面的有效性，并建立了新的最先进的方法。

Abstract: Large language models (LLMs) encode vast amounts of world knowledge but
remain static once trained, making the timely integration of emerging facts
prohibitively expensive via full retraining. Knowledge-editing techniques have
thus emerged to inject or overwrite specific facts into LLMs, yet they either
over-rely on superficial cues or incur complex, iterative pipelines that
collapse under noisy, multi-hop conditions. We introduce Reason-KE, an
end-to-end reasoning-chain-based editing framework that steers a pretrained LLM
through four structured stages-fact acknowledgment, relevance determination,
selective application, and final reasoning-to filter distractors in a single
pass. Trained on MQuAKE-CF with up to four irrelevant facts, Reason-KE elevates
Qwen2.5-7B's multi-hop QA accuracy to 90.2% while suffering merely a 6.3% drop
under heavy distraction and <1% when answers are leaked. Our quantitative
analysis confirms Reason-KE's resilience and efficiency, establishing a new
state-of-the-art for reliable LLM knowledge updates.

</details>


### [90] [Do Retrieval Augmented Language Models Know When They Don't Know?](https://arxiv.org/abs/2509.01476)
*Youchao Zhou,Heyan Huang,Yicheng Liu,Rui Dai,Xinglin Wang,Xingchen Zhang,Shumin Shi,Yang Deng*

Main category: cs.CL

TL;DR: 本研究探讨了RALMs在不知道时是否知道，发现它们存在过度拒绝行为，并通过上下文微调缓解了这一问题，同时开发了一种有效的方法来提高拒绝和正确答案的质量。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）有时会生成看似合理但事实错误的回答，即幻觉。研究人员主要使用两种方法来减轻幻觉，即检索增强语言模型（RALMs）和拒绝后训练。然而，当前研究主要强调它们的单独有效性，而忽略了对RALMs拒绝能力的评估。

Method: 我们检查了不同因素的影响，并研究了拒绝感知指令微调和上下文微调方法对过度拒绝问题的影响。

Result: 我们发现LLMs表现出显著的过度拒绝行为。上下文微调可以缓解过度拒绝问题，但R-tuning会加剧这个问题。此外，拒绝能力可能与回答质量冲突。

Conclusion: 本研究提供了对RALM系统中重要因素影响的更全面理解，并开发了一种简单有效的拒绝方法，以提高拒绝和正确答案的整体质量。

Abstract: Existing Large Language Models (LLMs) occasionally generate plausible yet
factually incorrect responses, known as hallucinations. Researchers are
primarily using two approaches to mitigate hallucinations, namely Retrieval
Augmented Language Models (RALMs) and refusal post-training. However, current
research predominantly emphasizes their individual effectiveness while
overlooking the evaluation of the refusal capability of RALMs. In this study,
we ask the fundamental question: Do RALMs know when they don't know?
Specifically, we ask three questions. First, are RALMs well-calibrated
regarding different internal and external knowledge states? We examine the
influence of various factors. Contrary to expectations, we find that LLMs
exhibit significant \textbf{over-refusal} behavior. Then, how does refusal
post-training affect the over-refusal issue? We investigate the Refusal-aware
Instruction Tuning and In-Context Fine-tuning methods. Our results show that
the over-refusal problem is mitigated by In-context fine-tuning. but magnified
by R-tuning. However, we also find that the refusal ability may conflict with
the quality of the answer. Finally, we develop a simple yet effective refusal
method for refusal post-trained models to improve their overall answer quality
in terms of refusal and correct answers. Our study provides a more
comprehensive understanding of the influence of important factors on RALM
systems.

</details>


### [91] [MeVe: A Modular System for Memory Verification and Effective Context Control in Language Models](https://arxiv.org/abs/2509.01514)
*Andreas Ottem*

Main category: cs.CL

TL;DR: 本文介绍了MeVe架构，这是一种新的模块化设计，用于改进RAG系统，通过细化和提炼上下文信息，提高上下文效率，并在知识密集型问答任务中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 传统的RAG系统由于其固有的机制（如简单的top-k语义搜索）面临限制，这通常会导致在上下文中包含不相关或冗余的信息，从而降低性能和效率。

Method: MeVe是一种新的模块化架构，旨在进行内存验证和智能上下文组合。它重新思考了RAG范式，提出了一个五阶段的模块化设计，将检索和上下文组合过程分解为不同的、可审计的和独立可调的阶段。

Result: 通过在组合之前主动验证信息，MeVe显著提高了上下文效率，在Wikipedia数据集上实现了57%的减少，在更复杂的HotpotQA数据集上实现了75%的减少。

Conclusion: 本文提出了MeVe架构，通过细化和提炼上下文信息，为更可扩展和可靠的LLM应用提供了框架，并提供了更好的基础和更准确的事实支持。

Abstract: Retrieval-Augmented Generation (RAG) systems typically face constraints
because of their inherent mechanism: a simple top-k semantic search [1]. The
approach often leads to the incorporation of irrelevant or redundant
information in the context, degrading performance and efficiency [10][11]. This
paper presents MeVe, a novel modular architecture intended for Memory
Verification and smart context composition. MeVe rethinks the RAG paradigm by
proposing a five-phase modular design that distinctly breaks down the retrieval
and context composition process into distinct, auditable, and independently
tunable phases: initial retrieval, relevance verification, fallback retrieval,
context prioritization, and token budgeting. This architecture enables
fine-grained control of what knowledge is made available to an LLM, enabling
task-dependent filtering and adaptation. We release a reference implementation
of MeVe as a proof of concept and evaluate its performance on knowledge-heavy
QA tasks over a subset of English Wikipedia [22]. Our results demonstrate that
by actively verifying information before composition, MeVe significantly
improves context efficiency, achieving a 57% reduction on the Wikipedia dataset
and a 75% reduction on the more complex HotpotQA dataset compared to standard
RAG implementations [25]. This work provides a framework for more scalable and
reliable LLM applications. By refining and distilling contextual information,
MeVe offers a path toward better grounding and more accurate factual support
[16].

</details>


### [92] [Service, Solidarity, and Self-Help: A Comparative Topic Modeling Analysis of Community Unionism in the Boot and Shoe Union and Unite Community](https://arxiv.org/abs/2509.01529)
*Thomas Compton*

Main category: cs.CL

TL;DR: 本研究通过比较分析20世纪20年代的国家鞋靴工会和2010-2020年代的联合社区工会，利用自然语言处理技术揭示了两者在主题焦点和论述连贯性上的显著差异，挑战了社区工会主义在不同时期和行业中的连续性和普遍性假设。


<details>
  <summary>Details</summary>
Motivation: 探讨社区工会主义在不同历史和组织背景下的表现，并利用现代自然语言处理技术增强对历史劳动档案的研究。

Method: 使用BERTopic进行主题建模和cTF-IDF加权，以及词频分析，研究每个工会的论述与社区工会关键特征（如联盟建设、基层参与和工作场所之外的行动）的对齐程度。

Result: 结果显示，Unite Community在向外的社会正义导向主题上与社区工会主义的特征更一致，而B&S则强调内部管理、工业关系和会员服务，反映了更传统的服务导向工会模式。

Conclusion: 研究结果表明，尽管两个工会都涉及与社区相关的主题，但它们的参与模型存在显著差异，这挑战了关于社区工会主义在时间和行业之间连续性和普遍性的假设。

Abstract: This paper presents a comparative analysis of community unionism (CU) in two
distinct historical and organizational contexts: the National Boot and Shoe
Union (B\&S) in the 1920s and Unite Community in the 2010s--2020s. Using
BERTopic for thematic modeling and cTF-IDF weighting, alongside word frequency
analysis, the study examines the extent to which each union's discourse aligns
with key features of CU -- such as coalition-building, grassroots engagement,
and action beyond the workplace. The results reveal significant differences in
thematic focus and discursive coherence. While Unite Community demonstrates
stronger alignment with outward-facing, social justice-oriented themes, the
B\&S corpus emphasizes internal administration, industrial relations, and
member services -- reflecting a more traditional, servicing-oriented union
model. The analysis also highlights methodological insights, demonstrating how
modern NLP techniques can enhance the study of historical labor archives.
Ultimately, the findings suggest that while both unions engage with
community-related themes, their underlying models of engagement diverge
significantly, challenging assumptions about the continuity and universality of
community unionism across time and sector.

</details>


### [93] [CAT: Causal Attention Tuning For Injecting Fine-grained Causal Knowledge into Large Language Models](https://arxiv.org/abs/2509.01535)
*Kairong Han,Wenshuo Zhao,Ziyu Zhao,JunJian Ye,Lujia Pan,Kun Kuang*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型是否能有效利用因果知识进行预测和生成的问题，并提出了Causal Attention Tuning (CAT)方法，以改善模型在分布外场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在各种领域取得了显著的成功。然而，一个基本问题仍然存在：LLMs能否有效地利用因果知识进行预测和生成？通过实证研究，我们发现直接在大规模数据上训练的LLMs通常捕捉到的是虚假相关性而不是真正的因果关系，这导致了次优性能，特别是在分布外（OOD）场景中。

Method: 我们提出了Causal Attention Tuning (CAT)，一种将细粒度因果知识注入注意力机制的新方法。我们还提出了一种自动化管道，利用人类先验自动生成token级因果信号，并引入了Re-Attention机制来指导训练，帮助模型关注因果结构同时减轻注意力分数中的噪声和偏差。

Result: 在我们提出的Spurious Token Game (STG)基准和多个下游任务上的实验结果表明，我们的方法能够有效地利用因果知识进行预测，并在OOD场景中保持稳健性。

Conclusion: 实验结果表明，我们的方法能够有效地利用因果知识进行预测，并在分布外场景中保持稳健性。

Abstract: Large Language Models (LLMs) have achieved remarkable success across various
domains. However, a fundamental question remains: Can LLMs effectively utilize
causal knowledge for prediction and generation? Through empirical studies, we
find that LLMs trained directly on large-scale data often capture spurious
correlations rather than true causal relationships, leading to suboptimal
performance, especially in out-of-distribution (OOD) scenarios. To address this
challenge, we propose Causal Attention Tuning (CAT), a novel approach that
injects fine-grained causal knowledge into the attention mechanism. We propose
an automated pipeline that leverages human priors to automatically generate
token-level causal signals and introduce the Re-Attention mechanism to guide
training, helping the model focus on causal structures while mitigating noise
and biases in attention scores. Experimental results on our proposed Spurious
Token Game (STG) benchmark and multiple downstream tasks demonstrate that our
approach effectively leverages causal knowledge for prediction and remains
robust in OOD scenarios. Implementation details can be found at
https://github.com/Kairong-Han/CAT.

</details>


### [94] [In-N-Out: A Parameter-Level API Graph Dataset for Tool Agents](https://arxiv.org/abs/2509.01560)
*Seungkyu Lee,Nalim Kim,Yohan Jo*

Main category: cs.CL

TL;DR: 本文介绍了In-N-Out数据集，用于改善工具代理对API文档的理解和多工具查询的生成。


<details>
  <summary>Details</summary>
Motivation: 随着任务变得越来越复杂，基于LLM的工具代理在识别和按正确顺序调用正确的API方面遇到困难。因此，我们需要一种方法来更好地理解和利用API文档。

Method: 我们将API文档转换为结构化的API图，并引入了In-N-Out数据集，这是第一个由两个真实世界API基准及其文档构建的专家注释的API图数据集。

Result: 使用In-N-Out显著提高了工具检索和多工具查询生成的性能，几乎使仅使用文档的LLM性能翻倍。此外，经过In-N-Out微调的模型生成的图可以关闭90%的差距。

Conclusion: 我们的研究展示了使用显式的API图对于工具代理的潜力，并证明了In-N-Out作为有价值资源的实用性。我们将公开数据集和代码。

Abstract: Tool agents -- LLM-based systems that interact with external APIs -- offer a
way to execute real-world tasks. However, as tasks become increasingly complex,
these agents struggle to identify and call the correct APIs in the proper
order. To tackle this problem, we investigate converting API documentation into
a structured API graph that captures API dependencies and leveraging it for
multi-tool queries that require compositional API calls. To support this, we
introduce In-N-Out, the first expert-annotated dataset of API graphs built from
two real-world API benchmarks and their documentation. Using In-N-Out
significantly improves performance on both tool retrieval and multi-tool query
generation, nearly doubling that of LLMs using documentation alone. Moreover,
graphs generated by models fine-tuned on In-N-Out close 90% of this gap,
showing that our dataset helps models learn to comprehend API documentation and
parameter relationships. Our findings highlight the promise of using explicit
API graphs for tool agents and the utility of In-N-Out as a valuable resource.
We will release the dataset and code publicly.

</details>


### [95] [Enhancing Uncertainty Estimation in LLMs with Expectation of Aggregated Internal Belief](https://arxiv.org/abs/2509.01564)
*Zeguan Xiao,Diyang Dou,Boya Xiong,Yun Chen,Guanhua Chen*

Main category: cs.CL

TL;DR: EAGLE is a new method for improving the calibration of large language models by using their internal states to calculate more accurate confidence scores.


<details>
  <summary>Details</summary>
Motivation: Large Language Models (LLMs) often exhibit overconfidence and generate plausible yet incorrect answers, which poses challenges for reliable uncertainty estimation and safe deployment.

Method: EAGLE (Expectation of AGgregated internaL bEief), a novel self-evaluation-based calibration method that leverages the internal hidden states of LLMs to derive more accurate confidence scores.

Result: Extensive experiments on diverse datasets and LLMs demonstrate that EAGLE significantly improves calibration performance over existing baselines.

Conclusion: EAGLE significantly improves calibration performance over existing baselines.

Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide
range of natural language tasks, but often exhibit overconfidence and generate
plausible yet incorrect answers. This overconfidence, especially in models
undergone Reinforcement Learning from Human Feedback (RLHF), poses significant
challenges for reliable uncertainty estimation and safe deployment. In this
paper, we propose EAGLE (Expectation of AGgregated internaL bEief), a novel
self-evaluation-based calibration method that leverages the internal hidden
states of LLMs to derive more accurate confidence scores. Instead of relying on
the model's final output, our approach extracts internal beliefs from multiple
intermediate layers during self-evaluation. By aggregating these layer-wise
beliefs and calculating the expectation over the resulting confidence score
distribution, EAGLE produces a refined confidence score that more faithfully
reflects the model's internal certainty. Extensive experiments on diverse
datasets and LLMs demonstrate that EAGLE significantly improves calibration
performance over existing baselines. We also provide an in-depth analysis of
EAGLE, including a layer-wise examination of uncertainty patterns, a study of
the impact of self-evaluation prompts, and an analysis of the effect of
self-evaluation score range.

</details>


### [96] [Testing the assumptions about the geometry of sentence embedding spaces: the cosine measure need not apply](https://arxiv.org/abs/2509.01606)
*Vivi Nastase,Paola Merlo*

Main category: cs.CL

TL;DR: 研究发现句子嵌入空间的几何结构不能预测其在各种任务中的性能，因为语言信息是通过不同维度的加权组合编码的。


<details>
  <summary>Details</summary>
Motivation: 研究句子嵌入空间的几何结构是否能预测其在各种任务中的性能。

Method: 计算句子嵌入的三种方法：平均标记嵌入、特殊[CLS]标记的嵌入以及句子中随机标记的嵌入。探索句子嵌入变化之间的距离与它们在语言任务上的性能之间是否存在相关性，并且尽管它们的距离，是否以相同的方式编码相同的信息。

Result: 余弦相似度仅能捕捉句子嵌入之间的浅层共性或差异，这些无法预测特定任务的性能。语言信息是通过不同维度的加权组合编码的，这并未反映在句子嵌入空间的几何结构中。

Conclusion: 句子嵌入空间的几何结构不能预测它们在各种任务中的相对性能。

Abstract: Transformer models learn to encode and decode an input text, and produce
contextual token embeddings as a side-effect. The mapping from language into
the embedding space maps words expressing similar concepts onto points that are
close in the space. In practice, the reverse implication is also assumed: words
corresponding to close points in this space are similar or related, those that
are further are not.
  Does closeness in the embedding space extend to shared properties for
sentence embeddings? We present an investigation of sentence embeddings and
show that the geometry of their embedding space is not predictive of their
relative performances on a variety of tasks.
  We compute sentence embeddings in three ways: as averaged token embeddings,
as the embedding of the special [CLS] token, and as the embedding of a random
token from the sentence. We explore whether there is a correlation between the
distance between sentence embedding variations and their performance on
linguistic tasks, and whether despite their distances, they do encode the same
information in the same manner.
  The results show that the cosine similarity -- which treats dimensions
shallowly -- captures (shallow) commonalities or differences between sentence
embeddings, which are not predictive of their performance on specific tasks.
Linguistic information is rather encoded in weighted combinations of different
dimensions, which are not reflected in the geometry of the sentence embedding
space.

</details>


### [97] [Benchmarking the Detection of LLMs-Generated Modern Chinese Poetry](https://arxiv.org/abs/2509.01620)
*Shanshan Wang,Junchao Wu,Fengying Ye,Jingming Yao,Lidia S. Chao,Derek F. Wong*

Main category: cs.CL

TL;DR: 本文提出了一种新的基准，用于检测由LLM生成的现代中文诗歌，并构建了一个高质量的数据集进行评估。实验结果表明，当前的检测器无法可靠地检测这类诗歌，强调了新基准的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于现代中文诗歌的独特特性，难以识别一首诗是来自人类还是AI。AI生成的现代中文诗歌的泛滥已经显著扰乱了诗歌生态系统。基于在现实中文世界中识别AI生成诗歌的紧迫性，本文提出了一个新颖的基准来检测LLM生成的现代中文诗歌。

Method: 我们首先构建了一个高质量的数据集，其中包括6位专业诗人创作的800首诗和4种主流LLM生成的41,600首诗。随后，我们在该数据集上对六种检测器进行了系统性能评估。

Result: 实验结果表明，目前的检测器不能作为可靠的工具来检测由LLM生成的现代中文诗歌。最难检测的诗歌特征是内在品质，尤其是风格。检测结果验证了我们提出的基准的有效性和必要性。

Conclusion: 我们的工作为未来检测AI生成的诗歌奠定了基础。

Abstract: The rapid development of advanced large language models (LLMs) has made
AI-generated text indistinguishable from human-written text. Previous work on
detecting AI-generated text has made effective progress, but has not involved
modern Chinese poetry. Due to the distinctive characteristics of modern Chinese
poetry, it is difficult to identify whether a poem originated from humans or
AI. The proliferation of AI-generated modern Chinese poetry has significantly
disrupted the poetry ecosystem. Based on the urgency of identifying
AI-generated poetry in the real Chinese world, this paper proposes a novel
benchmark for detecting LLMs-generated modern Chinese poetry. We first
construct a high-quality dataset, which includes both 800 poems written by six
professional poets and 41,600 poems generated by four mainstream LLMs.
Subsequently, we conduct systematic performance assessments of six detectors on
this dataset. Experimental results demonstrate that current detectors cannot be
used as reliable tools to detect modern Chinese poems generated by LLMs. The
most difficult poetic features to detect are intrinsic qualities, especially
style. The detection results verify the effectiveness and necessity of our
proposed benchmark. Our work lays a foundation for future detection of
AI-generated poetry.

</details>


### [98] [TransGAT: Transformer-Based Graph Neural Networks for Multi-Dimensional Automated Essay Scoring](https://arxiv.org/abs/2509.01640)
*Hind Aljuaid,Areej Alhothali,Ohoud Al-Zamzami,Hussein Assalahi*

Main category: cs.CL

TL;DR: 本文提出了一种新的自动作文评分方法TransGAT，结合了微调的Transformer模型和图注意力网络，以提高评分的准确性和全面性。实验结果表明，该方法在多个评分维度上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前的自动作文评分方法存在局限性，例如使用静态词嵌入无法捕捉上下文意义，以及依赖整体评分而忽略特定写作方面。因此，需要一种更有效的解决方案来提高评分的准确性和全面性。

Method: 本文提出了TransGAT，这是一种将微调的Transformer模型与图注意力网络（GAT）相结合的新方法，用于分析评分。TransGAT通过将每个微调的Transformer（如BERT、RoBERTa和DeBERTaV3）与单独的GAT配对来进行双流预测，并融合两个流的预测以生成最终的分析评分。

Result: 在ELLIPSE数据集上的实验表明，TransGAT优于基线模型，在所有分析评分维度上平均QWK达到了0.854。

Conclusion: 这些发现突显了TransGAT在推进AES系统方面的潜力。

Abstract: Essay writing is a critical component of student assessment, yet manual
scoring is labor-intensive and inconsistent. Automated Essay Scoring (AES)
offers a promising alternative, but current approaches face limitations. Recent
studies have incorporated Graph Neural Networks (GNNs) into AES using static
word embeddings that fail to capture contextual meaning, especially for
polysemous words. Additionally, many methods rely on holistic scoring,
overlooking specific writing aspects such as grammar, vocabulary, and cohesion.
To address these challenges, this study proposes TransGAT, a novel approach
that integrates fine-tuned Transformer models with GNNs for analytic scoring.
TransGAT combines the contextual understanding of Transformers with the
relational modeling strength of Graph Attention Networks (GAT). It performs
two-stream predictions by pairing each fine-tuned Transformer (BERT, RoBERTa,
and DeBERTaV3) with a separate GAT. In each pair, the first stream generates
essay-level predictions, while the second applies GAT to Transformer token
embeddings, with edges constructed from syntactic dependencies. The model then
fuses predictions from both streams to produce the final analytic score.
Experiments on the ELLIPSE dataset show that TransGAT outperforms baseline
models, achieving an average Quadratic Weighted Kappa (QWK) of 0.854 across all
analytic scoring dimensions. These findings highlight the potential of TransGAT
to advance AES systems.

</details>


### [99] [Parallel Needleman-Wunsch on CUDA to measure word similarity based on phonetic transcriptions](https://arxiv.org/abs/2509.01654)
*Dominic Plein*

Main category: cs.CL

TL;DR: 本文提出了一种基于音标的词语相似性计算方法，利用Needleman-Wunsch算法并在Rust中实现，通过CPU和GPU并行化提高性能。通过构建全连接图并使用聚类算法分析，验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了高效处理大型数据集并提高计算性能，我们开发了一种基于音标的词语相似性计算方法，并通过并行化来优化计算效率。

Method: 我们提出了一种基于音标（发音）计算词语相似性的方法，使用了Needleman-Wunsch算法，并在Rust中实现了该算法，同时在CPU和GPU上进行了并行化以高效处理大型数据集。GPU实现利用CUDA和cudarc Rust库来显著提高性能。

Result: 我们通过构建一个全连接图来验证我们的方法，其中节点代表词语，边根据词语之间的相似性赋予权重。然后使用聚类算法分析该图以识别语音相似的词语组。结果表明了所提出方法的有效性。

Conclusion: 我们的结果展示了所提出方法在分析语言的语音结构方面的可行性和有效性，它可能很容易扩展到其他语言。

Abstract: We present a method to calculate the similarity between words based on their
phonetic transcription (their pronunciation) using the Needleman-Wunsch
algorithm. We implement this algorithm in Rust and parallelize it on both CPU
and GPU to handle large datasets efficiently. The GPU implementation leverages
CUDA and the cudarc Rust library to achieve significant performance
improvements. We validate our approach by constructing a fully-connected graph
where nodes represent words and edges have weights according to the similarity
between the words. This graph is then analyzed using clustering algorithms to
identify groups of phonetically similar words. Our results demonstrate the
feasibility and effectiveness of the proposed method in analyzing the phonetic
structure of languages. It might be easily expanded to other languages.

</details>


### [100] [Bridging Thoughts and Words: Graph-Based Intent-Semantic Joint Learning for Fake News Detection](https://arxiv.org/abs/2509.01660)
*Zhengjia Wang,Qiang Sheng,Danding Wang,Beizhe Hu,Juan Cao*

Main category: cs.CL

TL;DR: 本文提出了一种结合新闻意图和语义信号的假新闻检测方法InSide，并在多个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的假新闻检测方法主要依赖于语义线索，如情感词和风格特征，但这些方法容易陷入表面检测模式，在动态环境中表现有限。因此，本文旨在通过引入新闻意图来改进假新闻检测。

Method: 本文提出了Graph-based Intent-Semantic Joint Modeling (InSide)方法，将新闻语义和意图信号重新构造成异构图结构，并通过动态路径图对齐策略实现语义和意图之间的有效信息传递和聚合。

Result: 在四个基准数据集上的实验结果表明，提出的InSide方法在假新闻检测任务中优于现有最先进的方法。

Conclusion: 本文提出了一种新的方法InSide，通过结合新闻意图和语义信号来提高假新闻检测的性能，并在四个基准数据集上进行了实验验证，结果表明该方法优于现有方法。

Abstract: Fake news detection is an important and challenging task for defending online
information integrity. Existing state-of-the-art approaches typically extract
news semantic clues, such as writing patterns that include emotional words,
stylistic features, etc. However, detectors tuned solely to such semantic clues
can easily fall into surface detection patterns, which can shift rapidly in
dynamic environments, leading to limited performance in the evolving news
landscape. To address this issue, this paper investigates a novel perspective
by incorporating news intent into fake news detection, bridging intents and
semantics together. The core insight is that by considering news intents, one
can deeply understand the inherent thoughts behind news deception, rather than
the surface patterns within words alone. To achieve this goal, we propose
Graph-based Intent-Semantic Joint Modeling (InSide) for fake news detection,
which models deception clues from both semantic and intent signals via
graph-based joint learning. Specifically, InSide reformulates news semantic and
intent signals into heterogeneous graph structures, enabling long-range context
interaction through entity guidance and capturing both holistic and
implementation-level intent via coarse-to-fine intent modeling. To achieve
better alignment between semantics and intents, we further develop a dynamic
pathway-based graph alignment strategy for effective message passing and
aggregation across these signals by establishing a common space. Extensive
experiments on four benchmark datasets demonstrate the superiority of the
proposed InSide compared to state-of-the-art methods.

</details>


### [101] [chDzDT: Word-level morphology-aware language model for Algerian social media text](https://arxiv.org/abs/2509.01772)
*Abdelkrime Aries*

Main category: cs.CL

TL;DR: 本文提出了一种针对阿尔及利亚方言的字符级预训练语言模型，旨在解决该方言在自然语言处理中的挑战，并展示了其在形态丰富、资源匮乏的方言中的潜力。


<details>
  <summary>Details</summary>
Motivation: 阿尔及利亚方言由于其复杂的形态、频繁的代码切换、多种脚本和强烈的词汇影响，使得传统的基于单词或子词级别的方法效果不佳。因此，需要一种更适合该方言的预训练语言模型。

Method: 本文提出了一种基于字符级别的预训练语言模型，专门针对阿尔及利亚方言的形态学进行优化。模型在独立单词上进行训练，而不是传统的令牌序列，以更好地捕捉形态模式。

Result: 本文贡献了三方面：(i) 使用YouTube评论对阿尔及利亚方言进行详细的形态分析；(ii) 构建了一个多语种的阿尔及利亚词典数据集；(iii) 开发并广泛评估了一个字符级预训练语言模型，作为下游任务的形态学编码器。

Conclusion: 本文提出了一个针对阿尔及利亚方言的字符级预训练语言模型chDzDT，展示了字符级建模在形态丰富、资源匮乏的方言中的潜力，并为更包容和适应性强的自然语言处理系统奠定了基础。

Abstract: Pre-trained language models (PLMs) have substantially advanced natural
language processing by providing context-sensitive text representations.
However, the Algerian dialect remains under-represented, with few dedicated
models available. Processing this dialect is challenging due to its complex
morphology, frequent code-switching, multiple scripts, and strong lexical
influences from other languages. These characteristics complicate tokenization
and reduce the effectiveness of conventional word- or subword-level approaches.
  To address this gap, we introduce chDzDT, a character-level pre-trained
language model tailored for Algerian morphology. Unlike conventional PLMs that
rely on token sequences, chDzDT is trained on isolated words. This design
allows the model to encode morphological patterns robustly, without depending
on token boundaries or standardized orthography. The training corpus draws from
diverse sources, including YouTube comments, French, English, and Berber
Wikipedia, as well as the Tatoeba project. It covers multiple scripts and
linguistic varieties, resulting in a substantial pre-training workload.
  Our contributions are threefold: (i) a detailed morphological analysis of
Algerian dialect using YouTube comments; (ii) the construction of a
multilingual Algerian lexicon dataset; and (iii) the development and extensive
evaluation of a character-level PLM as a morphology-focused encoder for
downstream tasks. The proposed approach demonstrates the potential of
character-level modeling for morphologically rich, low-resource dialects and
lays a foundation for more inclusive and adaptable NLP systems.

</details>


### [102] [Flaw or Artifact? Rethinking Prompt Sensitivity in Evaluating LLMs](https://arxiv.org/abs/2509.01790)
*Andong Hua,Kenan Tang,Chenhe Gu,Jindong Gu,Eric Wong,Yao Qin*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型的提示敏感性问题，发现其可能更多是评估方法的问题而非模型本身的缺陷。


<details>
  <summary>Details</summary>
Motivation: 我们重新审视了提示敏感性问题，并试图回答一个关键问题：广泛报告的高提示敏感性是否真的是大型语言模型的固有弱点，还是很大程度上是评估过程的产物？

Method: 我们系统地评估了7个大型语言模型（例如GPT和Gemini系列）在6个基准测试中的表现，包括12种不同的提示模板上的多项选择和开放性任务。

Result: 我们发现，许多提示敏感性源于启发式评估方法，包括对数似然评分和严格的答案匹配，这些方法常常忽略了通过替代措辞（如同义词或改写）表达的语义正确的响应。当采用LLM-as-a-Judge评估时，我们观察到性能方差显著减少，并且在不同提示下的模型排名一致性更高。

Conclusion: 我们的研究结果表明，现代大型语言模型比之前认为的更能抵抗提示模板，提示敏感性可能更多是评估的产物，而不是模型的缺陷。

Abstract: Prompt sensitivity, referring to the phenomenon where paraphrasing (i.e.,
repeating something written or spoken using different words) leads to
significant changes in large language model (LLM) performance, has been widely
accepted as a core limitation of LLMs. In this work, we revisit this issue and
ask: Is the widely reported high prompt sensitivity truly an inherent weakness
of LLMs, or is it largely an artifact of evaluation processes? To answer this
question, we systematically evaluate 7 LLMs (e.g., GPT and Gemini family)
across 6 benchmarks, including both multiple-choice and open-ended tasks on 12
diverse prompt templates. We find that much of the prompt sensitivity stems
from heuristic evaluation methods, including log-likelihood scoring and rigid
answer matching, which often overlook semantically correct responses expressed
through alternative phrasings, such as synonyms or paraphrases. When we adopt
LLM-as-a-Judge evaluations, we observe a substantial reduction in performance
variance and a consistently higher correlation in model rankings across
prompts. Our findings suggest that modern LLMs are more robust to prompt
templates than previously believed, and that prompt sensitivity may be more an
artifact of evaluation than a flaw in the models.

</details>


### [103] [Mic Drop or Data Flop? Evaluating the Fitness for Purpose of AI Voice Interviewers for Data Collection within Quantitative & Qualitative Research Contexts](https://arxiv.org/abs/2509.01814)
*Shreyas Tirumala,Nishant Jain,Danny D. Leybzon,Trent D. Buskirk*

Main category: cs.CL

TL;DR: AI interviewers have potential for data collection but face challenges in real-time performance and emotional understanding.


<details>
  <summary>Details</summary>
Motivation: The paper aims to understand when AI interviewing systems are suitable for collecting data in quantitative and qualitative research contexts.

Method: This paper reviews emerging evidence to evaluate the capabilities of AI interviewers and IVR systems across two dimensions: input/output performance and verbal reasoning.

Result: Field studies suggest that AI interviewers already exceed IVR capabilities for both types of data collection, but issues like transcription errors, limited emotion detection, and uneven follow-up quality indicate context-dependent utility.

Conclusion: AI interviewers show potential for both quantitative and qualitative data collection, but their effectiveness may depend on the context.

Abstract: Transformer-based Large Language Models (LLMs) have paved the way for "AI
interviewers" that can administer voice-based surveys with respondents in
real-time. This position paper reviews emerging evidence to understand when
such AI interviewing systems are fit for purpose for collecting data within
quantitative and qualitative research contexts. We evaluate the capabilities of
AI interviewers as well as current Interactive Voice Response (IVR) systems
across two dimensions: input/output performance (i.e., speech recognition,
answer recording, emotion handling) and verbal reasoning (i.e., ability to
probe, clarify, and handle branching logic). Field studies suggest that AI
interviewers already exceed IVR capabilities for both quantitative and
qualitative data collection, but real-time transcription error rates, limited
emotion detection abilities, and uneven follow-up quality indicate that the
utility, use and adoption of current AI interviewer technology may be
context-dependent for qualitative data collection efforts.

</details>


### [104] [Extracting OPQRST in Electronic Health Records using Large Language Models with Reasoning](https://arxiv.org/abs/2509.01885)
*Zhimeng Luo,Abhibha Gupta,Adam Frisch,Daqing He*

Main category: cs.CL

TL;DR: 本文介绍了一种利用大型语言模型从电子健康记录中提取OPQRST评估的新方法，通过将任务重构为文本生成，提高了可解释性，并通过引入语义相似性度量改进了评估。


<details>
  <summary>Details</summary>
Motivation: 由于电子健康记录（EHRs）数据的复杂性和非结构化特性，关键患者信息的提取面临重大挑战。传统的机器学习方法往往无法高效捕捉相关细节，使得临床医生难以有效利用这些工具进行患者护理。

Method: 本文提出了一种新的方法，将OPQRST评估任务从序列标记重新构建成文本生成，使模型能够提供模仿医生认知过程的推理步骤。此外，还提出了对传统命名实体识别（NER）指标的修改，包括整合语义相似性度量，如BERT Score，以评估生成文本与原始记录的临床意图的一致性。

Result: 本文的方法提高了从EHRs中提取信息的准确性和可用性，并通过引入语义相似性度量改进了机器生成文本在临床环境中的评估。

Conclusion: 本文展示了人工智能在医疗保健中使用的重要进展，提供了一个可扩展的解决方案，提高了从电子健康记录中提取信息的准确性和可用性，从而帮助临床医生做出更明智的决策并改善患者护理结果。

Abstract: The extraction of critical patient information from Electronic Health Records
(EHRs) poses significant challenges due to the complexity and unstructured
nature of the data. Traditional machine learning approaches often fail to
capture pertinent details efficiently, making it difficult for clinicians to
utilize these tools effectively in patient care. This paper introduces a novel
approach to extracting the OPQRST assessment from EHRs by leveraging the
capabilities of Large Language Models (LLMs). We propose to reframe the task
from sequence labeling to text generation, enabling the models to provide
reasoning steps that mimic a physician's cognitive processes. This approach
enhances interpretability and adapts to the limited availability of labeled
data in healthcare settings. Furthermore, we address the challenge of
evaluating the accuracy of machine-generated text in clinical contexts by
proposing a modification to traditional Named Entity Recognition (NER) metrics.
This includes the integration of semantic similarity measures, such as the BERT
Score, to assess the alignment between generated text and the clinical intent
of the original records. Our contributions demonstrate a significant
advancement in the use of AI in healthcare, offering a scalable solution that
improves the accuracy and usability of information extraction from EHRs,
thereby aiding clinicians in making more informed decisions and enhancing
patient care outcomes.

</details>


### [105] [Weakly Supervised Medical Entity Extraction and Linking for Chief Complaints](https://arxiv.org/abs/2509.01899)
*Zhimeng Luo,Zhendong Wang,Rui Meng,Diyang Xue,Adam Frisch,Daqing He*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A Chief complaint (CC) is the reason for the medical visit as stated in the
patient's own words. It helps medical professionals to quickly understand a
patient's situation, and also serves as a short summary for medical text
mining. However, chief complaint records often take a variety of entering
methods, resulting in a wide variation of medical notations, which makes it
difficult to standardize across different medical institutions for record
keeping or text mining. In this study, we propose a weakly supervised method to
automatically extract and link entities in chief complaints in the absence of
human annotation. We first adopt a split-and-match algorithm to produce weak
annotations, including entity mention spans and class labels, on 1.2 million
real-world de-identified and IRB approved chief complaint records. Then we
train a BERT-based model with generated weak labels to locate entity mentions
in chief complaint text and link them to a pre-defined ontology. We conducted
extensive experiments, and the results showed that our Weakly Supervised Entity
Extraction and Linking (\ours) method produced superior performance over
previous methods without any human annotation.

</details>


### [106] [DRAssist: Dispute Resolution Assistance using Large Language Models](https://arxiv.org/abs/2509.01962)
*Sachin Pawar,Manoj Apte,Girish K. Palshikar,Basit Ali,Nitin Ramrakhiyani*

Main category: cs.CL

TL;DR: 本文研究了使用大型语言模型（LLMs）作为人类法官的助手来解决争议的可能性，并提出了DRAssist系统。


<details>
  <summary>Details</summary>
Motivation: 争议在几乎所有领域都存在，通常由人类法官解决，但这种方法可能效率低下且主观。本文旨在探索LLMs在这一过程中的潜力。

Method: 本文提出了DRAssist系统，该系统利用LLMs识别争议的关键结构元素，并通过多种提示策略来辅助解决争议。

Result: 本文评估了LLMs在三个不同层次上的表现，并与相关基线进行了比较，证明了LLMs在解决争议任务中的有效性。

Conclusion: 本文探讨了使用大型语言模型（LLMs）作为人类法官的助手来解决争议的可能性，并展示了DRAssist系统的有效性。

Abstract: Disputes between two parties occur in almost all domains such as taxation,
insurance, banking, healthcare, etc. The disputes are generally resolved in a
specific forum (e.g., consumer court) where facts are presented, points of
disagreement are discussed, arguments as well as specific demands of the
parties are heard, and finally a human judge resolves the dispute by often
favouring one of the two parties. In this paper, we explore the use of large
language models (LLMs) as assistants for the human judge to resolve such
disputes, as part of our DRAssist system. We focus on disputes from two
specific domains -- automobile insurance and domain name disputes. DRAssist
identifies certain key structural elements (e.g., facts, aspects or
disagreement, arguments) of the disputes and summarizes the unstructured
dispute descriptions to produce a structured summary for each dispute. We then
explore multiple prompting strategies with multiple LLMs for their ability to
assist in resolving the disputes in these domains. In DRAssist, these LLMs are
prompted to produce the resolution output at three different levels -- (i)
identifying an overall stronger party in a dispute, (ii) decide whether each
specific demand of each contesting party can be accepted or not, (iii) evaluate
whether each argument by each contesting party is strong or weak. We evaluate
the performance of LLMs on all these tasks by comparing them with relevant
baselines using suitable evaluation metrics.

</details>


### [107] [StructCoh: Structured Contrastive Learning for Context-Aware Text Semantic Matching](https://arxiv.org/abs/2509.02033)
*Chao Xue,Ziyuan Gao*

Main category: cs.CL

TL;DR: 本文提出了一种名为StructCoh的图增强对比学习框架，用于文本语义匹配。该框架结合了结构推理和表示空间优化，通过双图编码器和层次对比目标，在多个基准数据集上取得了显著提升，尤其是在法律文档匹配任务中表现出色


<details>
  <summary>Details</summary>
Motivation: 文本语义匹配需要对结构关系和细粒度语义差异有深入理解。虽然预训练语言模型擅长捕捉词级别交互，但常常忽略层次结构模式，并且在细微语义区分上表现不佳

Method: 本文提出了StructCoh，一种结合结构推理和表示空间优化的图增强对比学习框架。该方法包括两个关键创新：(1) 双图编码器通过依存句法分析和主题建模构建语义图，并利用图同构网络在句法依赖和跨文档概念节点之间传播结构特征；(2) 层次对比目标在多个粒度上强制一致性：节点级对比正则化保留核心语义单元，而图感知对比学习通过显式和隐式负采样策略对齐跨文档的结构语义

Result: 实验结果表明，StructCoh在三个法律文档匹配基准和学术抄袭检测数据集上取得了显著提升。特别是在法律法规匹配任务中，StructCoh通过有效识别论证结构相似性，达到了86.7%的F1分数（绝对提升6.2%）

Conclusion: 实验表明，StructCoh在三个法律文档匹配基准和学术抄袭检测数据集上显著优于现有方法。特别是在法律法规匹配任务中，StructCoh通过有效识别论证结构相似性，达到了86.7%的F1分数（绝对提升6.2%）

Abstract: Text semantic matching requires nuanced understanding of both structural
relationships and fine-grained semantic distinctions. While pre-trained
language models excel at capturing token-level interactions, they often
overlook hierarchical structural patterns and struggle with subtle semantic
discrimination. In this paper, we proposed StructCoh, a graph-enhanced
contrastive learning framework that synergistically combines structural
reasoning with representation space optimization. Our approach features two key
innovations: (1) A dual-graph encoder constructs semantic graphs via dependency
parsing and topic modeling, then employs graph isomorphism networks to
propagate structural features across syntactic dependencies and cross-document
concept nodes. (2) A hierarchical contrastive objective enforces consistency at
multiple granularities: node-level contrastive regularization preserves core
semantic units, while graph-aware contrastive learning aligns inter-document
structural semantics through both explicit and implicit negative sampling
strategies. Experiments on three legal document matching benchmarks and
academic plagiarism detection datasets demonstrate significant improvements
over state-of-the-art methods. Notably, StructCoh achieves 86.7% F1-score
(+6.2% absolute gain) on legal statute matching by effectively identifying
argument structure similarities.

</details>


### [108] [DeepSeek performs better than other Large Language Models in Dental Cases](https://arxiv.org/abs/2509.02036)
*Hexian Zhang,Xinyu Yan,Yanqi Yang,Lijian Jin,Ping Yang,Junwen Wang*

Main category: cs.CL

TL;DR: 本研究评估了四种最先进的LLM在分析纵向牙科病例描述方面的能力，发现DeepSeek表现最佳，具有较高的忠实度和专家评分，表明其在医疗教育和研究中的潜在应用价值。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在医疗保健中具有变革性的潜力，但它们解释纵向患者叙述的能力仍缺乏充分探索。牙科拥有丰富的结构化临床数据，为严格评估LLMs的推理能力提供了独特的机会。虽然已有几家商业LLM存在，但DeepSeek也加入了竞争。

Method: 本研究评估了四种最先进的LLM（GPT-4o、Gemini 2.0 Flash、Copilot和DeepSeek V3）在分析纵向牙科病例描述方面的能力，通过开放式的临床任务进行评估。使用34个标准化的纵向牙周病例（包含258对问题-答案对），通过自动化指标和受过许可的牙医的盲评来评估模型性能。

Result: DeepSeek表现出色，展示了更高的忠实度（中位数得分为0.528 vs. 0.367-0.457）和更高的专家评分（中位数为4.5/5 vs. 4.0/5），而不会显著影响可读性。

Conclusion: 本研究将DeepSeek定位为案例分析的领先LLM，支持其作为医疗教育和研究中的辅助工具，并突显了其作为领域特定代理的潜力。

Abstract: Large language models (LLMs) hold transformative potential in healthcare, yet
their capacity to interpret longitudinal patient narratives remains
inadequately explored. Dentistry, with its rich repository of structured
clinical data, presents a unique opportunity to rigorously assess LLMs'
reasoning abilities. While several commercial LLMs already exist, DeepSeek, a
model that gained significant attention earlier this year, has also joined the
competition. This study evaluated four state-of-the-art LLMs (GPT-4o, Gemini
2.0 Flash, Copilot, and DeepSeek V3) on their ability to analyze longitudinal
dental case vignettes through open-ended clinical tasks. Using 34 standardized
longitudinal periodontal cases (comprising 258 question-answer pairs), we
assessed model performance via automated metrics and blinded evaluations by
licensed dentists. DeepSeek emerged as the top performer, demonstrating
superior faithfulness (median score = 0.528 vs. 0.367-0.457) and higher expert
ratings (median = 4.5/5 vs. 4.0/5), without significantly compromising
readability. Our study positions DeepSeek as the leading LLM for case analysis,
endorses its integration as an adjunct tool in both medical education and
research, and highlights its potential as a domain-specific agent.

</details>


### [109] [NADI 2025: The First Multidialectal Arabic Speech Processing Shared Task](https://arxiv.org/abs/2509.02038)
*Bashar Talafha,Hawau Olamide Toyin,Peter Sullivan,AbdelRahim Elmadany,Abdurrahman Juma,Amirbek Djanibekov,Chiyu Zhang,Hamad Alshehhi,Hanan Aldarmaki,Mustafa Jarrar,Nizar Habash,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: NADI 2025共享任务展示了阿拉伯语语音方言处理的最新进展，强调了方言识别、语音识别和重音恢复的挑战，并总结了参与团队的方法以及未来研究的方向。


<details>
  <summary>Details</summary>
Motivation: 分析阿拉伯语语音方言处理的挑战，并总结参与团队的方法以指导未来的研究方向。

Method: 第六次Nuanced阿拉伯语方言识别(NADI 2025)共享任务的成果，包括三个子任务：口语方言识别(子任务1)、语音识别(子任务2)和口语方言的重音恢复(子任务3)。

Result: 最佳系统在子任务1上达到了79.8%的准确率，在子任务2上达到了35.68/12.20 WER/CER（总体平均值），在子任务3上达到了55/13 WER/CER。

Conclusion: 这些结果突显了阿拉伯语方言语音处理的持续挑战，特别是在方言识别、识别和重音恢复方面。我们还总结了参与团队采用的方法，并简要概述了NADI未来版本的方向。

Abstract: We present the findings of the sixth Nuanced Arabic Dialect Identification
(NADI 2025) Shared Task, which focused on Arabic speech dialect processing
across three subtasks: spoken dialect identification (Subtask 1), speech
recognition (Subtask 2), and diacritic restoration for spoken dialects (Subtask
3). A total of 44 teams registered, and during the testing phase, 100 valid
submissions were received from eight unique teams. The distribution was as
follows: 34 submissions for Subtask 1 "five teams{\ae}, 47 submissions for
Subtask 2 "six teams", and 19 submissions for Subtask 3 "two teams". The
best-performing systems achieved 79.8% accuracy on Subtask 1, 35.68/12.20
WER/CER (overall average) on Subtask 2, and 55/13 WER/CER on Subtask 3. These
results highlight the ongoing challenges of Arabic dialect speech processing,
particularly in dialect identification, recognition, and diacritic restoration.
We also summarize the methods adopted by participating teams and briefly
outline directions for future editions of NADI.

</details>


### [110] [Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation](https://arxiv.org/abs/2509.02040)
*Guangzeng Han,Weisi Liu,Xiaolei Huang*

Main category: cs.CL

TL;DR: Genetic Prompt是一种结合遗传算法和大型语言模型的新框架，用于生成高质量和多样化的合成数据。实验表明，该方法在多个NLP任务中表现优异，并能提升下游模型的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成合成数据方面表现出色，但确保其质量和多样性仍然具有挑战性。

Method: 我们提出了Genetic Prompt，这是一种结合遗传算法和大型语言模型的新型框架，用于增强合成数据生成。我们的方法将语义文本属性视为基因序列，并利用大型语言模型模拟交叉和突变操作。

Result: 我们的实验在多个NLP任务上揭示了几个关键发现：Genetic Prompt不仅显著优于最先进的基线，而且在各种生成器模型大小和规模下表现出稳健的性能。此外，我们将合成数据与原始训练集融合，显著提升了下游模型的性能，特别是在类别不平衡的情况下。

Conclusion: 我们的研究验证了Genetic Prompt是一种有效生成高质量合成数据的方法，适用于各种NLP应用。

Abstract: Large Language Models (LLMs) excel at generating synthetic data, but ensuring
its quality and diversity remains challenging. We propose Genetic Prompt, a
novel framework that combines genetic algorithms with LLMs to augment synthetic
data generation. Our approach treats semantic text attributes as gene sequences
and leverages the LLM to simulate crossover and mutation operations. This
genetic process enhances data quality and diversity by creating novel attribute
combinations, yielding synthetic distributions closer to real-world data. To
optimize parent selection, we also integrate an active learning scheme that
expands the offspring search space. Our experiments on multiple NLP tasks
reveal several key findings: Genetic Prompt not only significantly outperforms
state-of-the-art baselines but also shows robust performance across various
generator model sizes and scales. Moreover, we demonstrate that fusing our
synthetic data with the original training set significantly boosts downstream
model performance, particularly for class-imbalanced scenarios. Our findings
validate that Genetic Prompt is an effective method for producing high-quality
synthetic data for a wide range of NLP applications.

</details>


### [111] [How Instruction-Tuning Imparts Length Control: A Cross-Lingual Mechanistic Analysis](https://arxiv.org/abs/2509.02075)
*Elisabetta Rocchetti,Alfio Ferrara*

Main category: cs.CL

TL;DR: 该研究探讨了指令调优如何改善大型语言模型在英语和意大利语中的长度控制文本生成，发现指令调优通过重新配置后期层来提高任务遵循能力。


<details>
  <summary>Details</summary>
Motivation: 研究基础模型和其指令调优版本在英语和意大利语中进行长度控制文本生成的差异。

Method: 使用累积加权归因（Cumulative Weighted Attribution），这是一种从直接对数归因派生的度量标准，分析性能和内部组件贡献。

Result: 指令调优显著提高了长度控制，主要是通过深化模型层中的组件专业化。具体而言，IT模型后期层中的注意力头显示出越来越积极的贡献，尤其是在英语中。在意大利语中，虽然注意力贡献更弱，但最后一层MLP表现出更强的积极作用，这表明存在补偿机制。

Conclusion: 研究结果表明，指令调优重新配置了后期层以遵循任务，组件级策略可能适应语言环境。

Abstract: Adhering to explicit length constraints, such as generating text with a
precise word count, remains a significant challenge for Large Language Models
(LLMs). This study aims at investigating the differences between foundation
models and their instruction-tuned counterparts, on length-controlled text
generation in English and Italian. We analyze both performance and internal
component contributions using Cumulative Weighted Attribution, a metric derived
from Direct Logit Attribution. Our findings reveal that instruction-tuning
substantially improves length control, primarily by specializing components in
deeper model layers. Specifically, attention heads in later layers of IT models
show increasingly positive contributions, particularly in English. In Italian,
while attention contributions are more attenuated, final-layer MLPs exhibit a
stronger positive role, suggesting a compensatory mechanism. These results
indicate that instruction-tuning reconfigures later layers for task adherence,
with component-level strategies potentially adapting to linguistic context.

</details>


### [112] [Better by Comparison: Retrieval-Augmented Contrastive Reasoning for Automatic Prompt Optimization](https://arxiv.org/abs/2509.02093)
*Juhyeon Lee,Wonduk Seo,Hyunjin An,Seunghyun Lee,Yi Bu*

Main category: cs.CL

TL;DR: 本文提出了一种名为CRPO的新框架，通过对比和检索增强推理来优化提示，实验结果表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注直接提示优化或模型微调，而忽略了利用LLM内在推理能力从对比示例中学习的潜力。

Method: CRPO框架将提示优化形式化为检索增强的推理过程，通过检索HelpSteer2数据集中的参考提示，并构建两种互补的优化范式：分层对比推理和多指标对比推理。

Result: 在HelpSteer2基准测试中，CRPO显著优于基线方法，证明了其有效性和优越性。

Conclusion: CRPO展示了对比和检索增强推理在自动提示优化中的前景，能够显著优于基线方法。

Abstract: Automatic prompt optimization has recently emerged as a strategy for
improving the quality of prompts used in Large Language Models (LLMs), with the
goal of generating more accurate and useful responses. However, most prior work
focuses on direct prompt refinement or model fine-tuning, overlooking the
potential of leveraging LLMs' inherent reasoning capability to learn from
contrasting examples. In this paper, we present Contrastive Reasoning Prompt
Optimization (CRPO), a novel framework that formulates prompt optimization as a
retrieval augmented reasoning process. Our approach retrieves top k reference
prompts from the HelpSteer2 dataset, an open-source collection annotated for
helpfulness, correctness, coherence, complexity, and verbosity, and constructs
two complementary optimization paradigms: (1) tiered contrastive reasoning,
where the LLM compares high, medium, and low quality prompts to refine its own
generation through reflective reasoning, and (2) multi-metric contrastive
reasoning, where the LLM analyzes the best prompts along each evaluation
dimension and integrates their strengths into an optimized prompt. By
explicitly contrasting high and low quality exemplars, CRPO enables the model
to deduce why certain prompts succeed while others fail, thereby achieving more
robust and interpretable optimization. Experimental results on the HelpSteer2
benchmark demonstrate that CRPO significantly outperforms baselines. Our
findings highlight the promise of contrastive, retrieval-augmented reasoning
for advancing automatic prompt optimization.

</details>


### [113] [JudgeAgent: Dynamically Evaluate LLMs with Agent-as-Interviewer](https://arxiv.org/abs/2509.02097)
*Zhichao Shi,Xuhui Jiang,Chengjin Xu,Cangli Yao,Zhenxin Huang,Shengjie Ma,Yinghan Shen,Yuanzhuo Wang*

Main category: cs.CL

TL;DR: JudgeAgent is a new dynamic evaluation framework for LLMs that addresses the limitations of current evaluation methods by using a comprehensive approach and knowledge-driven data synthesis.


<details>
  <summary>Details</summary>
Motivation: The current evaluation of LLMs faces challenges such as limited interaction with targets, insufficient difficulty control, and difficulties in verifying the validity of evaluation results, making it hard to precisely determine the knowledge and capability boundaries of target models.

Method: JudgeAgent is a knowledge-target adaptive dynamic evaluation framework that employs benchmark grading, interactive extension, and evaluation feedback. It uses knowledge-driven data synthesis and target-adaptive difficulty adjustment methods for extended testing.

Result: JudgeAgent demonstrates the effectiveness of its dynamic evaluation paradigm through extensive experiments, providing accurate and effective evaluation results.

Conclusion: JudgeAgent provides accurate and effective evaluation results through its comprehensive approach and dynamic evaluation paradigm.

Abstract: Evaluating the capabilities of large language models (LLMs) is an essential
step to ensure the successful application of LLMs across various domains. The
current evaluation of LLMs is based on a paradigm that involves querying them
with predefined question sets and assessing their outputs. This paradigm offers
controllable processes and simplicity, but faces challenges such as limited
interaction with targets, insufficient difficulty control, and difficulties in
verifying the validity of evaluation results, making it hard to precisely
determine the knowledge and capability boundaries of target models. To address
these challenges, we propose JudgeAgent, a knowledge-target adaptive dynamic
evaluation framework based on a new interviewer-style evaluation paradigm.
JudgeAgent employs a comprehensive evaluation approach consisting of benchmark
grading, interactive extension, and evaluation feedback. It utilizes
knowledge-driven data synthesis and target-adaptive difficulty adjustment
methods to conduct extended testing, providing accurate and effective
evaluation results. We also introduce a novel insight into validating
evaluation methods, demonstrating the effectiveness of JudgeAgent and its
dynamic evaluation paradigm through extensive experiments.

</details>


### [114] [CMRAG: Co-modality-based document retrieval and visual question answering](https://arxiv.org/abs/2509.02123)
*Wang Chen,Guanqiang Qi,Weikang Li,Yang Li*

Main category: cs.CL

TL;DR: 本文提出了基于共模态的RAG(CMRAG)，可以同时利用文本和图像进行高效的检索和生成。实验表明，该方法在视觉文档问答任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在处理多模态文档时存在局限性：一类方法依赖于版面分析和文本提取，只能利用显式文本信息，难以捕捉图像或非结构化内容；另一类方法将文档分割作为视觉输入并直接传递给视觉语言模型(VLMs)进行处理，但忽略了文本的语义优势，导致生成结果不理想。

Method: 本文提出了基于共模态的RAG(CMRAG)，可以同时利用文本和图像进行高效的检索和生成。具体来说，我们首先对文档进行结构化解析以获得文本段落和图像区域的共模态表示。然后，针对用户查询，分别从文本和图像通道中检索候选证据，并在跨模态检索级别聚合结果。最后，我们根据共模态检索结果提示VLM生成最终响应。

Result: 实验表明，我们的方法在视觉文档问答任务中显著优于纯视觉基础的RAG。

Conclusion: 将共模态信息统一集成到RAG框架中是提高复杂文档视觉问答(VQA)系统性能的有效方法。

Abstract: Retrieval-Augmented Generation (RAG) has become a core paradigm in document
question answering tasks. However, existing methods have limitations when
dealing with multimodal documents: one category of methods relies on layout
analysis and text extraction, which can only utilize explicit text information
and struggle to capture images or unstructured content; the other category
treats document segmentation as visual input and directly passes it to visual
language models (VLMs) for processing, yet it ignores the semantic advantages
of text, leading to suboptimal generation results. This paper proposes
co-modality-based RAG (CMRAG), which can simultaneously leverage text and
images for efficient retrieval and generation. Specifically, we first perform
structured parsing on documents to obtain co-modality representations of text
segments and image regions. Subsequently, in response to user queries, we
retrieve candidate evidence from text and image channels, respectively, and
aggregate the results at the cross-modal retrieval level. Finally, we prompt
the VLM to generate the final response based on the co-modality retrieval
results. Experiments demonstrate that our method significantly outperforms
pure-vision-based RAG in visual document question answering tasks. The findings
of this paper show that integrating co-modality information into the RAG
framework in a unified manner is an effective approach to improving the
performance of complex document visual question-answering (VQA) systems.

</details>


### [115] [AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models](https://arxiv.org/abs/2509.02133)
*Snehasis Mukhopadhyay,Aryan Kasat,Shivam Dubey,Rahul Karthikeyan,Dhruv Sood,Vinija Jain,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: 本文提出了一种名为AMBEDKAR的框架，旨在通过宪法意识解码层和推测解码算法来减少大型语言模型中的种姓和宗教偏见。该方法在不修改基础模型的情况下，实现了高达26.41%的偏见减少。


<details>
  <summary>Details</summary>
Motivation: 在印度背景下，我们的实证评估显示，种姓和宗教方面的偏见尤为明显。然而，大多数现有的缓解策略是西方中心的，无法解决这些本地细微差别。

Method: 我们提出了AMBEDKAR框架，该框架受到印度宪法制定者B.R. Ambedkar的平等愿景启发，以引导LLM输出符合第14至17条的公平、中立和包容性。我们的方法引入了一个基于印度AI宪法的宪法意识解码层，并在推理时应用，而无需对基础模型进行参数更新。我们结合了一种推测解码算法，在生成过程中主动减少种姓和宗教偏见。

Result: 我们的方法在基准上实现了高达26.41%的偏见绝对减少。

Conclusion: 我们的方法在基准上实现了高达26.41%的偏见绝对减少。源代码、数据集和结果可在https://anonymous.4open.science/r/AMBEDKAR-983B/获得。

Abstract: Large Language Models (LLMs) can inadvertently reflect societal biases
present in their training data, leading to harmful or prejudiced outputs. In
the Indian context, our empirical evaluations across a suite of models reveal
that biases around caste and religion are particularly salient. Yet, most
existing mitigation strategies are Western-centric and fail to address these
local nuances. We propose AMBEDKAR, a framework inspired by the egalitarian
vision of Dr B. R. Ambedkar, architect of the Indian Constitution, to guide LLM
outputs toward fairness, neutrality, and inclusion in line with Articles 14 to
17. Our approach introduces a Constitution-Aware Decoding Layer, guided by the
AI Constitution of India and applied only at inference time, without any
parameter updates to the base model. We incorporate a speculative decoding
algorithm that proactively reduces casteist and communal bias during
generation. This mitigation layer operates directly within the decoding
process, avoiding changes to model internals and lowering the computational and
infrastructural costs associated with retraining. We reinterpret speculative
decoding not merely as an efficiency tool but as a mechanism for fairness. In
this framework, a Small Language Model (SLM) acts as a potentially biased
generator, while a constitutionally guided Large Language Model (LLM) serves as
the verifier. Rather than accelerating generation, the LLM enforces bias-robust
trajectories in the SLM outputs. This inversion of roles gives rise to a
fairness-by-speculation paradigm. Our approach yields an absolute reduction of
bias up to 26.41 percent compared to baseline. Our source code, datasets, and
results are available at https://anonymous.4open.science/r/AMBEDKAR-983B/

</details>


### [116] [Meta-Pretraining for Zero-Shot Cross-Lingual Named Entity Recognition in Low-Resource Philippine Languages](https://arxiv.org/abs/2509.02160)
*David Demitri Africa,Suchir Salhan,Yuval Weiss,Paula Buttery,Richard Diehl Martinez*

Main category: cs.CL

TL;DR: 本文研究了通过MAML预训练小型解码器语言模型，以在低资源语言上实现快速适应和零样本迁移的效果。


<details>
  <summary>Details</summary>
Motivation: 传统的微调大型多语言语言模型在内存或延迟受限的环境中不可行，因此需要探索更小的语言模型是否能够通过预训练快速适应并零样本迁移至未见过的语言。

Method: 本文采用了一种基于一阶模型无关元学习（MAML）的预训练方法，以提高小型解码器语言模型在低资源语言上的适应能力和迁移能力。

Result: 在四种模型规模下，MAML在仅调整头部参数的情况下将零样本微F1提升了2-6个百分点，在完全调整后提升了1-3个百分点，同时减少了收敛时间最多达8%。

Conclusion: 本文表明，通过使用MAML预训练小型解码器语言模型，可以在零样本设置下有效适应低资源语言，并且在不同模型规模下都能获得显著的性能提升。

Abstract: Named-entity recognition (NER) in low-resource languages is usually tackled
by finetuning very large multilingual LMs, an option that is often infeasible
in memory- or latency-constrained settings. We ask whether small decoder LMs
can be pretrained so that they adapt quickly and transfer zero-shot to
languages unseen during pretraining. To this end we replace part of the
autoregressive objective with first-order model-agnostic meta-learning (MAML).
Tagalog and Cebuano are typologically similar yet structurally different in
their actor/non-actor voice systems, and hence serve as a challenging test-bed.
Across four model sizes (11 M - 570 M) MAML lifts zero-shot micro-F1 by 2-6 pp
under head-only tuning and 1-3 pp after full tuning, while cutting convergence
time by up to 8%. Gains are largest for single-token person entities that
co-occur with Tagalog case particles si/ni, highlighting the importance of
surface anchors.

</details>


### [117] [Avoidance Decoding for Diverse Multi-Branch Story Generation](https://arxiv.org/abs/2509.02170)
*Kyeongman Park,Nakyeong Yang,Kyomin Jung*

Main category: cs.CL

TL;DR: 本文提出了一种新的解码策略Avoidance Decoding，通过惩罚与之前生成输出的相似性来提高大型语言模型在故事生成任务中的输出多样性，结果表明该方法在输出多样性、减少重复和缓解文本退化方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在诸如故事生成等任务中，由于给定相同的输入提示时创意多样性有限，常常生成重复和单调的输出。为了解决这个挑战，我们提出了一个新的解码策略，以提高输出的多样性。

Method: 我们提出了一种新的解码策略，称为Avoidance Decoding，通过惩罚与之前生成输出的相似性来修改token logits，从而鼓励更多样化的多分支故事。这种惩罚自适应地平衡了两种相似性度量：(1) 概念级相似性惩罚，在早期阶段优先考虑以多样化初始故事概念，(2) 叙事级相似性惩罚，在后期逐渐强调以确保自然且多样的情节发展。

Result: 我们的方法在输出多样性方面达到了基线的2.6倍，并平均减少了30%的重复，同时有效缓解了文本退化。此外，我们的方法激活了更广泛的神经元，表明它利用了模型的内在创造力。

Conclusion: 我们的方法在输出多样性方面表现出色，同时减少了重复并有效缓解了文本退化。此外，我们的方法激活了更广泛的神经元，表明它利用了模型的内在创造力。

Abstract: Large Language Models (LLMs) often generate repetitive and monotonous
outputs, especially in tasks like story generation, due to limited creative
diversity when given the same input prompt. To address this challenge, we
propose a novel decoding strategy, Avoidance Decoding, that modifies token
logits by penalizing similarity to previously generated outputs, thereby
encouraging more diverse multi-branch stories. This penalty adaptively balances
two similarity measures: (1) Concept-level Similarity Penalty, which is
prioritized in early stages to diversify initial story concepts, and (2)
Narrative-level Similarity Penalty, which is increasingly emphasized later to
ensure natural yet diverse plot development. Notably, our method achieves up to
2.6 times higher output diversity and reduces repetition by an average of 30%
compared to strong baselines, while effectively mitigating text degeneration.
Furthermore, we reveal that our method activates a broader range of neurons,
demonstrating that it leverages the model's intrinsic creativity.

</details>


### [118] [FActBench: A Benchmark for Fine-grained Automatic Evaluation of LLM-Generated Text in the Medical Domain](https://arxiv.org/abs/2509.02198)
*Anum Afzal,Juraj Vladika,Florian Matthes*

Main category: cs.CL

TL;DR: 本文提出了一个针对医学领域的事实检查基准FActBench，并使用两种先进的事实检查技术进行实验，结果表明通过两种技术的共识投票获得的事实检查分数与领域专家评估最相关。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理专业领域时往往表现不佳。虽然所有方面的评估都很重要，但事实性是最关键的。同样，可靠的事实检查工具和数据源对于减少幻觉至关重要。

Method: 我们使用了两种最先进的事实检查技术：思维链（CoT）提示和自然语言推理（NLI）。

Result: 我们提供了一个全面的事实检查基准FActBench，涵盖四个生成任务和六个最先进的大型语言模型（LLMs）用于医学领域。

Conclusion: 我们的实验表明，通过两种技术的共识投票获得的事实检查分数与领域专家评估最相关。

Abstract: Large Language Models tend to struggle when dealing with specialized domains.
While all aspects of evaluation hold importance, factuality is the most
critical one. Similarly, reliable fact-checking tools and data sources are
essential for hallucination mitigation. We address these issues by providing a
comprehensive Fact-checking Benchmark FActBench covering four generation tasks
and six state-of-the-art Large Language Models (LLMs) for the Medical domain.
We use two state-of-the-art Fact-checking techniques: Chain-of-Thought (CoT)
Prompting and Natural Language Inference (NLI). Our experiments show that the
fact-checking scores acquired through the Unanimous Voting of both techniques
correlate best with Domain Expert Evaluation.

</details>


### [119] [Towards Fundamental Language Models: Does Linguistic Competence Scale with Model Size?](https://arxiv.org/abs/2509.02225)
*Jaime Collado-Montañez,L. Alfonso Ureña-López,Arturo Montejo-Ráez*

Main category: cs.CL

TL;DR: 本文提出FLM范式，通过小型语言模型和外部工具结合，提升语言模型的效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在幻觉、偏见、隐私问题和高计算成本等局限性，这些问题是由于语言能力和事实记忆在单一模型中的结合所驱动的。

Method: 本文引入并实证支持了基本语言模型（FLM）范式，该范式提倡使用较小的语言能力模型，并将事实检索任务卸载到外部工具。

Result: 研究发现，虽然语言能力和事实知识随着规模的增加而提高，但内部事实知识增长得更快，表明模型大小与记忆化更相关，而不是核心语言能力。

Conclusion: FLM范式为更高效、可解释和可持续的NLP解决方案提供了一条路径。

Abstract: Large Language Models offer impressive language capabilities but suffer from
well-known limitations, including hallucinations, biases, privacy concerns, and
high computational costs. These issues are largely driven by the combination of
linguistic competence and factual memorization within a single monolithic
model. This paper introduces and empirically supports the Fundamental Language
Model (FLM) paradigm, which advocates for smaller, linguistically competent
models that offload factual retrieval to external tools. We evaluate models
ranging from 135M to 32B parameters across three dimensions: linguistic
competence, external factual knowledge, and internal factual knowledge. Our
findings reveal that while both linguistic competence and factual knowledge
improve with scale, internal factual knowledge grows significantly faster,
suggesting that model size is more closely tied to memorization than to core
language ability. These results support a modular approach to language
modeling, where compact, linguistically proficient models serve as the
foundation for tool-augmented systems. The FLM paradigm offers a path toward
more efficient, interpretable, and sustainable NLP solutions.

</details>


### [120] [LLMs and their Limited Theory of Mind: Evaluating Mental State Annotations in Situated Dialogue](https://arxiv.org/abs/2509.02292)
*Katharine Kowalyshyn,Matthias Scheutz*

Main category: cs.CL

TL;DR: 本文介绍了一种新的两步框架，利用大型语言模型作为团队对话的注释者和差异检测器。结果显示，虽然大型语言模型在简单的自然语言任务中表现良好，但在需要空间推理或语音提示歧义的任务中会出现系统性错误。


<details>
  <summary>Details</summary>
Motivation: 如果大型语言模型不仅能够推断人类心态，还能揭示团队对话中的每一个盲点，例如团队成员在共同理解上的差异，会怎样？

Method: 我们提出了一种新的两步框架，利用大型语言模型（LLMs）作为人类风格的团队对话注释者来跟踪团队的共享心智模型（SMMs），以及作为个体心智状态之间的自动差异检测器。首先，一个LLM通过识别任务导向对话中的SMM元素来生成注释。然后，第二个LLM将这些LLM派生的注释与人类注释进行比较，以检测和描述差异。

Result: 我们定义了一个SMM一致性评估框架，并将其应用于六个CReST对话，最终产生了：(1) 一个包含人类和LLM注释的数据集；(2) 一个可重复的SMM一致性评估框架；以及(3) 一个基于LLM的差异检测实证评估。

Conclusion: 我们的结果表明，尽管大型语言模型在简单的自然语言注释任务中表现出明显的连贯性，但在需要空间推理或歧义语音提示的任务中会系统性地出错。

Abstract: What if large language models could not only infer human mindsets but also
expose every blind spot in team dialogue such as discrepancies in the team
members' joint understanding? We present a novel, two-step framework that
leverages large language models (LLMs) both as human-style annotators of team
dialogues to track the team's shared mental models (SMMs) and as automated
discrepancy detectors among individuals' mental states. In the first step, an
LLM generates annotations by identifying SMM elements within task-oriented
dialogues from the Cooperative Remote Search Task (CReST) corpus. Then, a
secondary LLM compares these LLM-derived annotations and human annotations
against gold-standard labels to detect and characterize divergences. We define
an SMM coherence evaluation framework for this use case and apply it to six
CReST dialogues, ultimately producing: (1) a dataset of human and LLM
annotations; (2) a reproducible evaluation framework for SMM coherence; and (3)
an empirical assessment of LLM-based discrepancy detection. Our results reveal
that, although LLMs exhibit apparent coherence on straightforward
natural-language annotation tasks, they systematically err in scenarios
requiring spatial reasoning or disambiguation of prosodic cues.

</details>


### [121] [DCPO: Dynamic Clipping Policy Optimization](https://arxiv.org/abs/2509.02333)
*Shihui Yang,Chengfeng Dou,Peidong Guo,Kai Lu,Qiang Ju,Fei Deng,Rihui Xin*

Main category: cs.CL

TL;DR: DCPO improves reinforcement learning in large language models by dynamically adjusting clipping bounds and standardizing rewards, achieving superior performance and efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing approaches like GRPO suffer from zero gradients due to fixed clipping bounds and standardized rewards, leading to ineffective gradient updates and underutilization of generated responses.

Method: Dynamic Clipping Policy Optimization (DCPO) introduces a dynamic clipping strategy and a smooth advantage standardization technique to enhance token-level exploration and response-level effective utilization of generated responses.

Result: DCPO achieved state-of-the-art performance on four benchmarks, with significant improvements in Avg@1 and Avg@32 scores on AIME24 and AIME25 benchmarks. It also improved nonzero advantage by 28%, doubled training efficiency over DAPO, and reduced token clipping ratio by an order of magnitude.

Conclusion: DCPO's results highlight its effectiveness in leveraging generated data more efficiently for reinforcement learning in large language models.

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a
promising framework for enhancing the reasoning capabilities of large language
models. However, existing approaches such as GRPO often suffer from zero
gradients. This problem arises primarily due to fixed clipping bounds for
token-level probability ratios and the standardization of identical rewards,
which can lead to ineffective gradient updates and underutilization of
generated responses. In this work, we propose Dynamic Clipping Policy
Optimization (DCPO), which introduces a dynamic clipping strategy that
adaptively adjusts the clipping bounds based on token-specific prior
probabilities to enhance token-level exploration, and a smooth advantage
standardization technique that standardizes rewards across cumulative training
steps to improve the response-level effective utilization of generated
responses. DCPO achieved state-of-the-art performance on four benchmarks based
on four different models. In particular, DCPO achieved an Avg@1 of 46.7 under
greedy decoding and an Avg@32 of 38.8 under 32 times sampling on the AIME24
benchmark, surpassing both DAPO (36.7/31.6) and GRPO (36.7/32.1) on the
Qwen2.5-Math-7B model. On the AIME25 benchmark based on Qwen2.5-14B, DCPO
achieves a performance of (23.3/19.0), surpassing GRPO (13.3/10.5) and DAPO
(20.0/15.3). Furthermore, DCPO achieved an average 28% improvement in the
nonzero advantage over GRPO in four models, doubled the training efficiency
over DAPO, and significantly reduced the token clipping ratio by an order of
magnitude compared to both GRPO and DAPO, while achieving superior performance.
These results highlight DCPO's effectiveness in leveraging generated data more
efficiently for reinforcement learning in large language models.

</details>


### [122] [Implicit Reasoning in Large Language Models: A Comprehensive Survey](https://arxiv.org/abs/2509.02350)
*Jindong Li,Yali Fu,Li Fan,Jiahong Liu,Yao Shu,Chengwei Qin,Menglin Yang,Irwin King,Rex Ying*

Main category: cs.CL

TL;DR: 本文填补了对LLM内部推理机制进行专门和机制层面研究的空白，提出了三种执行范式，并回顾了相关证据和评估方法。


<details>
  <summary>Details</summary>
Motivation: 尽管之前的研究已经讨论了推理中的潜在表示，但对LLM内部推理如何展开的专门和机制层面的检查仍然缺失。

Method: 本文根据内部计算如何和在何处展开，将现有方法分为三种执行范式：潜在优化、信号引导控制和层递归执行。

Result: 本文回顾了支持LLM中隐式推理存在的结构、行为和基于表示的证据，并提供了评估隐式推理有效性和可靠性的评估指标和基准的结构化概述。

Conclusion: 本文通过引入以执行范式为中心的分类法，填补了对LLM内部推理机制进行专门和机制层面研究的空白。

Abstract: Large Language Models (LLMs) have demonstrated strong generalization across a
wide range of tasks. Reasoning with LLMs is central to solving multi-step
problems and complex decision-making. To support efficient reasoning, recent
studies have shifted attention from explicit chain-of-thought prompting toward
implicit reasoning, where reasoning occurs silently via latent structures
without emitting intermediate textual steps. Implicit reasoning brings
advantages such as lower generation cost, faster inference, and better
alignment with internal computation. Although prior surveys have discussed
latent representations in the context of reasoning, a dedicated and
mechanism-level examination of how reasoning unfolds internally within LLMs
remains absent. This survey fills that gap by introducing a taxonomy centered
on execution paradigms, shifting the focus from representational forms to
computational strategies. We organize existing methods into three execution
paradigms based on \textbf{\textit{how and where internal computation
unfolds}}: latent optimization, signal-guided control, and layer-recurrent
execution. We also review structural, behavioral and representation-based
evidence that supports the presence of implicit reasoning in LLMs. We further
provide a structured overview of the evaluation metrics and benchmarks used in
existing works to assess the effectiveness and reliability of implicit
reasoning.We maintain a continuously updated project at:
https://github.com/digailab/awesome-llm-implicit-reasoning.

</details>


### [123] [Towards Temporal Knowledge-Base Creation for Fine-Grained Opinion Analysis with Language Models](https://arxiv.org/abs/2509.02363)
*Gaurav Negi,Atul Kr. Ojha,Omnia Zayed,Paul Buitelaar*

Main category: cs.CL

TL;DR: 本文提出了一种利用大型语言模型构建时间观点知识库的方法，通过整合已有的观点挖掘公式，实现了结构化观点提取，并进行了定量评估和标注者间协议分析。


<details>
  <summary>Details</summary>
Motivation: 尽管时间序列观点分析在文本中对于下游应用（如预测和趋势分析）具有 demonstrated utility，但由于缺乏时间基础的细粒度标注，现有方法未能充分利用这一潜力。

Method: 我们提出了一种可扩展的方法，利用大型语言模型（LLMs）作为自动标注器构建时间观点知识库。我们的方法将已建立的观点挖掘公式整合到声明式LLM标注流程中，以实现结构化观点提取，而无需手动提示工程。

Result: 我们使用人工标注的测试样本对管道进行了严格的定量评估，并使用两个不同的LLM进行最终标注。计算了细粒度观点维度上的标注者间协议，类似于人类标注协议。

Conclusion: 该知识库包含了时间对齐的结构化观点，并与检索增强生成（RAG）、时间问答和时间线摘要等应用兼容。

Abstract: We propose a scalable method for constructing a temporal opinion knowledge
base with large language models (LLMs) as automated annotators. Despite the
demonstrated utility of time-series opinion analysis of text for downstream
applications such as forecasting and trend analysis, existing methodologies
underexploit this potential due to the absence of temporally grounded
fine-grained annotations. Our approach addresses this gap by integrating
well-established opinion mining formulations into a declarative LLM annotation
pipeline, enabling structured opinion extraction without manual prompt
engineering. We define three data models grounded in sentiment and opinion
mining literature, serving as schemas for structured representation. We perform
rigorous quantitative evaluation of our pipeline using human-annotated test
samples. We carry out the final annotations using two separate LLMs, and
inter-annotator agreement is computed label-wise across the fine-grained
opinion dimensions, analogous to human annotation protocols. The resulting
knowledge base encapsulates time-aligned, structured opinions and is compatible
with applications in Retrieval-Augmented Generation (RAG), temporal question
answering, and timeline summarisation.

</details>


### [124] [An Ensemble Classification Approach in A Multi-Layered Large Language Model Framework for Disease Prediction](https://arxiv.org/abs/2509.02446)
*Ali Hamdi,Malak Mohamed,Rokaia Emad,Khaled Shaban*

Main category: cs.CL

TL;DR: 本研究评估了三种阿拉伯语医学文本预处理方法，并将其与微调的阿拉伯语转换器模型和集成学习相结合，实现了 80.56% 的最佳分类准确率。这是首次将基于大语言模型的预处理与微调的阿拉伯语转换器模型和集成学习结合用于阿拉伯语社交媒体远程医疗数据的疾病分类。


<details>
  <summary>Details</summary>
Motivation: 社交媒体远程医疗已取得显著进展，允许患者在远程发布症状并参与医疗咨询。用户经常在社交媒体和在线健康平台上发布症状，创建了一个巨大的医疗数据存储库，可以用于疾病分类。大型语言模型（如 LLAMA3 和 GPT-3.5）以及基于变压器的模型（如 BERT）在处理复杂的医学文本方面表现出强大的能力。

Method: 评估了三种阿拉伯语医学文本预处理方法（摘要、精炼和命名实体识别），并在应用微调的阿拉伯语转换器模型（CAMeLBERT、AraBERT 和 AsafayaBERT）之前进行预处理。采用多数投票集成方法结合原始和预处理文本表示的预测。

Result: 该方法达到了最佳分类准确率 80.56%，展示了其在利用各种文本表示和模型预测以提高医学文本理解方面的有效性。

Conclusion: 该方法在阿拉伯语社交媒体远程医疗数据的疾病分类中表现出色，展示了其在利用多种文本表示和模型预测以提高医学文本理解方面的有效性。

Abstract: Social telehealth has made remarkable progress in healthcare by allowing
patients to post symptoms and participate in medical consultations remotely.
Users frequently post symptoms on social media and online health platforms,
creating a huge repository of medical data that can be leveraged for disease
classification. Large language models (LLMs) such as LLAMA3 and GPT-3.5, along
with transformer-based models like BERT, have demonstrated strong capabilities
in processing complex medical text. In this study, we evaluate three Arabic
medical text preprocessing methods such as summarization, refinement, and Named
Entity Recognition (NER) before applying fine-tuned Arabic transformer models
(CAMeLBERT, AraBERT, and AsafayaBERT). To enhance robustness, we adopt a
majority voting ensemble that combines predictions from original and
preprocessed text representations. This approach achieved the best
classification accuracy of 80.56%, thus showing its effectiveness in leveraging
various text representations and model predictions to improve the understanding
of medical texts. To the best of our knowledge, this is the first work that
integrates LLM-based preprocessing with fine-tuned Arabic transformer models
and ensemble learning for disease classification in Arabic social telehealth
data.

</details>


### [125] [EmoPerso: Enhancing Personality Detection with Self-Supervised Emotion-Aware Modelling](https://arxiv.org/abs/2509.02450)
*Lingzhi Shen,Xiaohao Cai,Yunfei Long,Imran Razzak,Guanming Chen,Shoaib Jameel*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的自监督框架EmoPerso，通过情感感知建模改进人格检测。


<details>
  <summary>Details</summary>
Motivation: 现有方法严重依赖大规模标注数据集，使得获取高质量的人格标签变得困难。此外，大多数研究将情绪和人格视为独立变量，忽视了它们的相互作用。

Method: EmoPerso通过情感感知建模改进人格检测，首先利用生成机制进行合成数据增强和丰富的表示学习，然后提取伪标记的情感特征，并通过多任务学习与人格预测联合优化。采用交叉注意力模块来捕捉人格特质和推断的情感表示之间的细粒度交互。为了进一步完善关系推理，EmoPerso采用自教策略来迭代增强模型的推理能力。

Result: EmoPerso在两个基准数据集上的实验表明，它超越了最先进的模型。

Conclusion: EmoPerso在两个基准数据集上的实验表明，它超越了最先进的模型。

Abstract: Personality detection from text is commonly performed by analysing users'
social media posts. However, existing methods heavily rely on large-scale
annotated datasets, making it challenging to obtain high-quality personality
labels. Moreover, most studies treat emotion and personality as independent
variables, overlooking their interactions. In this paper, we propose a novel
self-supervised framework, EmoPerso, which improves personality detection
through emotion-aware modelling. EmoPerso first leverages generative mechanisms
for synthetic data augmentation and rich representation learning. It then
extracts pseudo-labeled emotion features and jointly optimizes them with
personality prediction via multi-task learning. A cross-attention module is
employed to capture fine-grained interactions between personality traits and
the inferred emotional representations. To further refine relational reasoning,
EmoPerso adopts a self-taught strategy to enhance the model's reasoning
capabilities iteratively. Extensive experiments on two benchmark datasets
demonstrate that EmoPerso surpasses state-of-the-art models. The source code is
available at https://github.com/slz0925/EmoPerso.

</details>


### [126] [Do LLMs Adhere to Label Definitions? Examining Their Receptivity to External Label Definitions](https://arxiv.org/abs/2509.02452)
*Seyedali Mohammadi,Bhaskara Hanuma Vedula,Hemank Lamba,Edward Raff,Ponnurangam Kumaraguru,Francis Ferraro,Manas Gaur*

Main category: cs.CL

TL;DR: 研究探讨了LLM是否真正整合外部定义，发现它们在许多情况下依赖内部表示，尽管显式定义有助于提高准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 研究LLM是否真正整合外部定义，或者它们主要依赖于参数知识。

Method: 我们进行了控制实验，涵盖了多个解释基准数据集（通用和领域特定）和标签定义条件，包括专家整理、LLM生成、扰动和交换定义。

Result: 研究结果显示，显式标签定义可以提高准确性和可解释性，但在许多情况下，LLM更依赖于内部表示。通用任务中模型通常默认使用内部表示，而领域特定任务则更多受益于显式定义。

Conclusion: 研究结果表明，虽然显式的标签定义可以提高准确性和可解释性，但它们在LLM的任务解决过程中并不是保证或一致的，这表明在许多情况下依赖于内部表示。

Abstract: Do LLMs genuinely incorporate external definitions, or do they primarily rely
on their parametric knowledge? To address these questions, we conduct
controlled experiments across multiple explanation benchmark datasets (general
and domain-specific) and label definition conditions, including expert-curated,
LLM-generated, perturbed, and swapped definitions. Our results reveal that
while explicit label definitions can enhance accuracy and explainability, their
integration into an LLM's task-solving processes is neither guaranteed nor
consistent, suggesting reliance on internalized representations in many cases.
Models often default to their internal representations, particularly in general
tasks, whereas domain-specific tasks benefit more from explicit definitions.
These findings underscore the need for a deeper understanding of how LLMs
process external knowledge alongside their pre-existing capabilities.

</details>


### [127] [SpecEval: Evaluating Model Adherence to Behavior Specifications](https://arxiv.org/abs/2509.02464)
*Ahmed Ahmed,Kevin Klyman,Yi Zeng,Sanmi Koyejo,Percy Liang*

Main category: cs.CL

TL;DR: 本文提出了一种自动化框架，用于审计基础模型是否遵循其开发者的规范，发现不同开发者之间存在系统性不一致。


<details>
  <summary>Details</summary>
Motivation: 尽管提供商发布了详细的安全约束和质量特征规范，但尚未有系统性的审计来验证模型是否遵守这些指南。本文旨在填补这一空白。

Method: 本文引入了一种自动化框架，通过解析行为声明、生成针对性提示，并使用模型来判断一致性。重点是检查提供者规范、模型输出和模型自身作为评估者之间的三重一致性。

Result: 对来自六家开发者的16个模型进行了测试，发现存在系统性不一致，合规性差距最高可达20%。

Conclusion: 本文提出了一种自动化框架，用于审计基础模型是否遵循其开发者的规范。结果发现，不同开发者之间存在系统性不一致，包括合规性差距高达20%。

Abstract: Companies that develop foundation models publish behavioral guidelines they
pledge their models will follow, but it remains unclear if models actually do
so. While providers such as OpenAI, Anthropic, and Google have published
detailed specifications describing both desired safety constraints and
qualitative traits for their models, there has been no systematic audit of
adherence to these guidelines. We introduce an automated framework that audits
models against their providers specifications by parsing behavioral statements,
generating targeted prompts, and using models to judge adherence. Our central
focus is on three way consistency between a provider specification, its model
outputs, and its own models as judges; an extension of prior two way generator
validator consistency. This establishes a necessary baseline: at minimum, a
foundation model should consistently satisfy the developer behavioral
specifications when judged by the developer evaluator models. We apply our
framework to 16 models from six developers across more than 100 behavioral
statements, finding systematic inconsistencies including compliance gaps of up
to 20 percent across providers.

</details>


### [128] [GRAM-R$^2$: Self-Training Generative Foundation Reward Models for Reward Reasoning](https://arxiv.org/abs/2509.02492)
*Chenglong Wang,Yongyu Mu,Hang Zhou,Yifu Huo,Ziming Zhu,Jiali Zeng,Murun Yang,Bei Li,Tong Xiao,Xiaoyang Hao,Chunliang Zhang,Fandong Meng,Jingbo Zhu*

Main category: cs.CL

TL;DR: 本文提出了一种自训练方法，利用未标记数据来激发奖励模型中的奖励推理，开发了GRAM-R$^2$，这是一种生成式奖励模型，能够生成偏好标签和奖励理由，并在多个任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 尽管奖励建模取得了显著进展，但开发有效的奖励模型仍然是一个基本挑战，因为它严重依赖于大规模标记的偏好数据。预训练在丰富的未标记数据上提供了一个有前途的方向，但现有方法未能将显式的推理引入奖励模型。

Method: 提出了一种自训练方法，利用未标记数据来激发奖励模型中的奖励推理。基于这种方法，开发了GRAM-R$^2$，这是一种生成式奖励模型，不仅能够生成偏好标签，还能生成伴随的奖励理由。

Result: GRAM-R$^2$ 在响应排序、任务适应和从人类反馈中进行强化学习的实验中表现出色，优于多个强大的判别和生成基线。

Conclusion: GRAM-R$^2$ 可以作为奖励推理的基础模型，并且可以在很少或不需要额外微调的情况下应用于各种任务。实验表明，GRAM-R$^2$ 在响应排序、任务适应和从人类反馈中进行强化学习方面表现出色，优于多个强大的判别和生成基线。

Abstract: Significant progress in reward modeling over recent years has been driven by
a paradigm shift from task-specific designs towards generalist reward models.
Despite this trend, developing effective reward models remains a fundamental
challenge: the heavy reliance on large-scale labeled preference data.
Pre-training on abundant unlabeled data offers a promising direction, but
existing approaches fall short of instilling explicit reasoning into reward
models. To bridge this gap, we propose a self-training approach that leverages
unlabeled data to elicit reward reasoning in reward models. Based on this
approach, we develop GRAM-R$^2$, a generative reward model trained to produce
not only preference labels but also accompanying reward rationales. GRAM-R$^2$
can serve as a foundation model for reward reasoning and can be applied to a
wide range of tasks with minimal or no additional fine-tuning. It can support
downstream applications such as response ranking and task-specific reward
tuning. Experiments on response ranking, task adaptation, and reinforcement
learning from human feedback demonstrate that GRAM-R$^2$ consistently delivers
strong performance, outperforming several strong discriminative and generative
baselines.

</details>


### [129] [MoSEs: Uncertainty-Aware AI-Generated Text Detection via Mixture of Stylistics Experts with Conditional Thresholds](https://arxiv.org/abs/2509.02499)
*Junxi Wu,Jinpeng Wang,Zheng Liu,Bin Chen,Dongjian Hu,Hao Wu,Shu-Tao Xiu*

Main category: cs.CL

TL;DR: 本文提出了一种名为MoSEs的框架，通过风格感知的不确定性量化来提高AI生成文本的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了风格建模，主要依赖静态阈值，这大大限制了检测性能。因此，构建可信的AI生成文本检测系统非常重要。

Method: 我们提出了Mixture of Stylistic Experts (MoSEs)框架，通过条件阈值估计实现风格感知的不确定性量化。MoSEs包含三个核心组件：Stylistics Reference Repository (SRR)、Stylistics-Aware Router (SAR)和Conditional Threshold Estimator (CTE)。

Result: 我们的框架在检测性能上平均提高了11.34%，在低资源情况下更是提高了39.15%。

Conclusion: 我们的框架在检测性能上平均提高了11.34%，在低资源情况下更是提高了39.15%。

Abstract: The rapid advancement of large language models has intensified public
concerns about the potential misuse. Therefore, it is important to build
trustworthy AI-generated text detection systems. Existing methods neglect
stylistic modeling and mostly rely on static thresholds, which greatly limits
the detection performance. In this paper, we propose the Mixture of Stylistic
Experts (MoSEs) framework that enables stylistics-aware uncertainty
quantification through conditional threshold estimation. MoSEs contain three
core components, namely, the Stylistics Reference Repository (SRR), the
Stylistics-Aware Router (SAR), and the Conditional Threshold Estimator (CTE).
For input text, SRR can activate the appropriate reference data in SRR and
provide them to CTE. Subsequently, CTE jointly models the linguistic
statistical properties and semantic features to dynamically determine the
optimal threshold. With a discrimination score, MoSEs yields prediction labels
with the corresponding confidence level. Our framework achieves an average
improvement 11.34% in detection performance compared to baselines. More
inspiringly, MoSEs shows a more evident improvement 39.15% in the low-resource
case. Our code is available at https://github.com/creator-xi/MoSEs.

</details>


### [130] [L3Cube-IndicHeadline-ID: A Dataset for Headline Identification and Semantic Evaluation in Low-Resource Indian Languages](https://arxiv.org/abs/2509.02503)
*Nishant Tanksale,Tanmay Kokate,Darshan Gohad,Sarvadnyaa Barate,Raviraj Joshi*

Main category: cs.CL

TL;DR: 本文介绍了L3Cube-IndicHeadline-ID数据集，用于评估Indic语言中的语义理解，并展示了多语言模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏高质量的基准，句子转换器在Indic语言中的有效性尚未得到充分研究。

Method: 引入了L3Cube-IndicHeadline-ID数据集，包含10种低资源Indic语言的新闻文章和四个标题变体，用于测试细粒度语义理解。

Result: 多语言模型表现一致良好，而语言特定模型的效果有所不同。

Conclusion: 该数据集为Indic NLP提供了一个多功能的基准，可用于评估和改进语义理解。

Abstract: Semantic evaluation in low-resource languages remains a major challenge in
NLP. While sentence transformers have shown strong performance in high-resource
settings, their effectiveness in Indic languages is underexplored due to a lack
of high-quality benchmarks. To bridge this gap, we introduce
L3Cube-IndicHeadline-ID, a curated headline identification dataset spanning ten
low-resource Indic languages: Marathi, Hindi, Tamil, Gujarati, Odia, Kannada,
Malayalam, Punjabi, Telugu, Bengali and English. Each language includes 20,000
news articles paired with four headline variants: the original, a semantically
similar version, a lexically similar version, and an unrelated one, designed to
test fine-grained semantic understanding. The task requires selecting the
correct headline from the options using article-headline similarity. We
benchmark several sentence transformers, including multilingual and
language-specific models, using cosine similarity. Results show that
multilingual models consistently perform well, while language-specific models
vary in effectiveness. Given the rising use of similarity models in
Retrieval-Augmented Generation (RAG) pipelines, this dataset also serves as a
valuable resource for evaluating and improving semantic understanding in such
applications. Additionally, the dataset can be repurposed for multiple-choice
question answering, headline classification, or other task-specific evaluations
of LLMs, making it a versatile benchmark for Indic NLP. The dataset is shared
publicly at https://github.com/l3cube-pune/indic-nlp

</details>


### [131] [The Forgotten Code: Validating a Century-Old Translation System with AI](https://arxiv.org/abs/2509.02506)
*Jean-Marie Le Ray*

Main category: cs.CL

TL;DR: 该研究通过AI验证了Federico Pucci在1929年提出的基于规则的机械翻译系统，并展示了其在现代语言翻译中的有效性。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过AI验证Pucci的系统，并使其重新翻译不同语言的文本，从而复兴这一几乎被遗忘的发明。

Method: 该方法涉及让AI根据Pucci的方法重新翻译1931年最初翻译的两段文本，并在AI于2025年使用相同方法翻译后进行比较。

Result: 结果表明，Pucci在1931年和AI在2025年使用相同方法翻译的两段文本之间差异很小，仅有一些细微变化。此外，AI成功地将文本翻译成英语、西班牙语和德语。

Conclusion: 该研究不仅确认了Pucci的历史地位，还将其置于机器翻译先驱和思想贡献者的行列，其工作值得与Troyanskij、Booth和Weaver等人进行比较，可能对理解该领域的历史产生影响。

Abstract: A pioneering rule-based mechanical translation system (precursor of modern
RBMTs) was first presented in December 1929 by its inventor, Federico Pucci,
who later published the full method in a book titled "Il traduttore meccanico
ed il metodo per corrispondersi fra Europei conoscendo ciascuno solo la propria
lingua: Parte I", in Salerno (Italy), in 1931. This study illustrates how AI
breathes new life into the system of international keys and ideograms devised
by Pucci to translate from/into any Romance language (at least as a first
step). The methodology involves having the AIs retranslate, following Pucci's
method, the two text excerpts originally translated in 1931 and clearly
documented in his publication: a passage from Dante's La Vita Nuova, translated
from Italian into French, and a passage from Voltaire's Zadig, translated from
French into Italian. The result is notable: the two texts, translated 94 years
apart using the same method--by Pucci in 1931 and by AIs in 2025--show a low
average difference, with only minor variations observed. With Pucci's system
thus validated, it became feasible to have the AIs reproduce the excerpts in
English, Spanish, and German according to his method. The results were
consistent, and Pucci--via Artificial Intelligence--was tasked with translating
more modern and technical texts, thereby reviving, nearly a century later, an
invention that had remained almost entirely unknown and never applied beyond
its creator, now brought to wider attention and opened to possible
experimentation. Such a demonstration would not only affirm Pucci's historical
status but also place him among the precursors and intellectual contributors to
machine translation, whose work merits examination alongside figures such as
Troyanskij, Booth, and Weaver, with possible consequences for how the history
of the field is understood.

</details>


### [132] [Top-H Decoding: Adapting the Creativity and Coherence with Bounded Entropy in Text Generation](https://arxiv.org/abs/2509.02510)
*Erfan Baghaei Potraghloo,Seyedarmin Azizi,Souvik Kundu,Massoud Pedram*

Main category: cs.CL

TL;DR: 本文提出了 top-H 解码方法，以更好地平衡开放性文本生成中的创造力和逻辑连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有的截断采样技术在有效结合模型的置信度方面存在局限性，例如 min-p 采样依赖于单个顶级标记作为置信度的启发式方法，最终未能充分利用概率分布的信息。

Method: 本文提出了 top-H 解码方法，通过建立创造力和连贯性之间的理论基础，并证明其等价于一个 NP 难的熵约束质量最大化 (ECMM) 问题，然后提出了一种计算高效的贪心算法来解决 ECMM 问题。

Result: 广泛的实证评估表明，top-H 在创意写作基准测试中比最先进的 min-p 采样方法高出高达 25.63%，同时在问答数据集如 GPQA、GSM8K 和 MT-Bench 上保持稳健性。此外，LLM-as-judge 评估确认了 top-H 即使在较高温度下也能产生连贯的输出。

Conclusion: top-H 出色地提升了开放性文本生成的最先进水平，并且可以轻松集成到创意写作应用中。

Abstract: Large language models (LLMs), despite their impressive performance across a
wide range of tasks, often struggle to balance two competing objectives in
open-ended text generation: fostering diversity and creativity while preserving
logical coherence. Existing truncated sampling techniques, including
temperature scaling, top-\$p\$ (nucleus) sampling, and min-\$p\$ sampling, aim
to manage this trade-off. However, they exhibit limitations, particularly in
the effective incorporation of the confidence of the model into the
corresponding sampling strategy. For example, min-\$p\$ sampling relies on a
single top token as a heuristic for confidence, eventually underutilizing the
information of the probability distribution. Toward effective incorporation of
the confidence of the model, in this paper, we present **top-H** decoding. We
first establish the theoretical foundation of the interplay between creativity
and coherence in truncated sampling by formulating an **entropy-constrained
minimum divergence** problem. We then prove this minimization problem to be
equivalent to an **entropy-constrained mass maximization** (ECMM) problem,
which is NP-hard. Finally, we present top-H decoding, a computationally
efficient greedy algorithm to solve the ECMM problem. Extensive empirical
evaluations demonstrate that top-H outperforms the state-of-the-art (SoTA)
alternative of min-\$p\$ sampling by up to **25.63%** on creative writing
benchmarks, while maintaining robustness on question-answering datasets such as
GPQA, GSM8K, and MT-Bench. Additionally, an *LLM-as-judge* evaluation confirms
that top-H indeed produces coherent outputs even at higher temperatures, where
creativity is especially critical. In summary, top-H advances SoTA in
open-ended text generation and can be *easily integrated* into creative writing
applications. The code is available at
https://github.com/ErfanBaghaei/Top-H-Decoding.

</details>


### [133] [Comparative Study of Pre-Trained BERT and Large Language Models for Code-Mixed Named Entity Recognition](https://arxiv.org/abs/2509.02514)
*Mayur Shirke,Amey Shembade,Pavan Thorat,Madhushri Wagh,Raviraj Joshi*

Main category: cs.CL

TL;DR: 本研究比较了代码混合和非代码混合模型在Hinglish NER任务中的表现，发现代码混合模型（如HingRoBERTa）表现最佳，而Google Gemini在零样本设置下也表现出色。


<details>
  <summary>Details</summary>
Motivation: 代码混合文本（尤其是印地语-英语）的命名实体识别（NER）由于非正式结构、音译和频繁的语言切换而面临独特挑战。

Method: 本研究对代码混合微调模型和非代码混合多语言模型以及零样本生成大型语言模型（LLMs）进行了比较评估。

Result: 结果表明，代码混合模型，特别是HingRoBERTa和HingBERT微调模型，在基准Hinglish NER数据集上表现优于其他模型，包括封闭源代码LLMs如Google Gemini。非代码混合模型表现合理但适应性有限。值得注意的是，Google Gemini在零样本设置下表现出有竞争力的性能，突显了现代LLMs的泛化能力。

Conclusion: 本研究提供了关于专用模型与通用模型在代码混合NER任务中的有效性的关键见解。

Abstract: Named Entity Recognition (NER) in code-mixed text, particularly Hindi-English
(Hinglish), presents unique challenges due to informal structure,
transliteration, and frequent language switching. This study conducts a
comparative evaluation of code-mixed fine-tuned models and non-code-mixed
multilingual models, along with zero-shot generative large language models
(LLMs). Specifically, we evaluate HingBERT, HingMBERT, and HingRoBERTa (trained
on code-mixed data), and BERT Base Cased, IndicBERT, RoBERTa and MuRIL (trained
on non-code-mixed multilingual data). We also assess the performance of Google
Gemini in a zero-shot setting using a modified version of the dataset with NER
tags removed. All models are tested on a benchmark Hinglish NER dataset using
Precision, Recall, and F1-score. Results show that code-mixed models,
particularly HingRoBERTa and HingBERT-based fine-tuned models, outperform
others - including closed-source LLMs like Google Gemini - due to
domain-specific pretraining. Non-code-mixed models perform reasonably but show
limited adaptability. Notably, Google Gemini exhibits competitive zero-shot
performance, underlining the generalization strength of modern LLMs. This study
provides key insights into the effectiveness of specialized versus generalized
models for code-mixed NER tasks.

</details>


### [134] [Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR](https://arxiv.org/abs/2509.02522)
*Jiaming Li,Longze Chen,Ze Gong,Yukun Chen,Lu Wang,Wanwei He,Run Luo,Min Yang*

Main category: cs.CL

TL;DR: PACS是一种新的RLVR框架，通过监督学习方法实现隐式演员-评论家耦合，显著提升了大型语言模型在数学和编程等任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法在基于强化学习的方法中常常面临稀疏奖励信号和不稳定的策略梯度更新的问题。

Method: PACS通过将结果奖励视为可预测的标签，将RLVR问题重新表述为一个由策略模型参数化的得分函数的监督学习任务，并使用交叉熵损失进行优化。

Result: PACS在挑战性的数学推理任务上优于PPO和GRPO等强基线，例如在AIME 2025上达到59.78%的pass@256，比PPO和GRPO分别提高了13.32和14.36点。

Conclusion: PACS是一个简单而强大的框架，为具有可验证奖励的大型语言模型提供了有希望的后训练途径。

Abstract: Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) have
empowered large language models (LLMs) to tackle challenging reasoning tasks
such as mathematics and programming. RLVR leverages verifiable outcome rewards
to guide policy optimization, enabling LLMs to progressively improve output
quality in a grounded and reliable manner. Despite its promise, the RLVR
paradigm poses significant challenges, as existing methods often suffer from
sparse reward signals and unstable policy gradient updates, particularly in
RL-based approaches. To address the challenges, we propose $\textbf{PACS}$, a
novel RLVR framework that achieves im$\textbf{P}$licit $\textbf{A}$ctor
$\textbf{C}$ritic coupling via a $\textbf{S}$upervised learning framework. By
treating the outcome reward as a predictable label, we reformulate the RLVR
problem into a supervised learning task over a score function parameterized by
the policy model and optimized using cross-entropy loss. A detailed gradient
analysis shows that this supervised formulation inherently recovers the
classical policy gradient update while implicitly coupling actor and critic
roles, yielding more stable and efficient training. Benchmarking on challenging
mathematical reasoning tasks, PACS outperforms strong RLVR baselines, such as
PPO and GRPO, achieving superior reasoning performance. For instance, PACS
achieves 59.78\% at pass@256 on AIME 2025, representing improvements of 13.32
and 14.36 points over PPO and GRPO. This simple yet powerful framework offers a
promising avenue for LLMs post-training with verifiable rewards. Our code and
data are available as open source at https://github.com/ritzz-ai/PACS.

</details>


### [135] [Flavors of Moonshine: Tiny Specialized ASR Models for Edge Devices](https://arxiv.org/abs/2509.02523)
*Evan King,Adam Sabra,Manjunath Kudlur,James Wang,Pete Warden*

Main category: cs.CL

TL;DR: 我们开发了一套针对欠代表语言的小型自动语音识别（ASR）模型，这些模型在性能上优于更大的模型。


<details>
  <summary>Details</summary>
Motivation: 我们挑战了多语言ASR模型优于单语言模型的假设，特别是在小规模模型的情况下。

Method: 我们训练了单语系统，使用精心平衡的高质量人工标注、伪标注和合成数据。

Result: 我们的模型平均错误率比同样大小的Whisper Tiny模型低48%，超过了9倍大的Whisper Small模型，并在大多数情况下与28倍大的Whisper Medium模型相当或更好。

Conclusion: 我们的模型在小规模下表现出色，能够为之前支持有限的语言提供准确的本地ASR。

Abstract: We present the Flavors of Moonshine, a suite of tiny automatic speech
recognition (ASR) models specialized for a range of underrepresented languages.
Prevailing wisdom suggests that multilingual ASR models outperform monolingual
counterparts by exploiting cross-lingual phonetic similarities. We challenge
this assumption, showing that for sufficiently small models (27M parameters),
training monolingual systems on a carefully balanced mix of high-quality
human-labeled, pseudo-labeled, and synthetic data yields substantially superior
performance. On average, our models achieve error rates 48% lower than the
comparably sized Whisper Tiny model, outperform the 9x larger Whisper Small
model, and in most cases match or outperform the 28x larger Whisper Medium
model. These results advance the state of the art for models of this size,
enabling accurate on-device ASR for languages that previously had limited
support. We release Arabic, Chinese, Japanese, Korean, Ukrainian, and
Vietnamese Moonshine models under a permissive open-source license.

</details>


### [136] [Jointly Reinforcing Diversity and Quality in Language Model Generations](https://arxiv.org/abs/2509.02534)
*Tianjian Li,Yiming Zhang,Ping Yu,Swarnadeep Saha,Daniel Khashabi,Jason Weston,Jack Lanchantin,Tianlu Wang*

Main category: cs.CL

TL;DR: DARLING is a framework that optimizes for both response quality and semantic diversity, leading to more creative and effective outputs in various tasks.


<details>
  <summary>Details</summary>
Motivation: Post-training of large language models often prioritizes accuracy and helpfulness at the expense of diversity, which limits their usefulness in creative and exploratory tasks.

Method: DARLING uses a learned partition function to measure diversity beyond surface-level lexical variations and combines this diversity signal with a quality reward during online reinforcement learning.

Result: Experiments show that DARLING outperforms quality-only RL baselines in non-verifiable tasks and achieves higher pass@1 and pass@k in verifiable tasks, demonstrating its effectiveness in balancing quality and diversity.

Conclusion: DARLING is a framework that successfully balances response quality and semantic diversity, leading to higher-quality and more novel outputs in both non-verifiable and verifiable tasks.

Abstract: Post-training of Large Language Models (LMs) often prioritizes accuracy and
helpfulness at the expense of diversity. This creates a tension: while
post-training improves response quality, it also sharpens output distributions
and reduces the range of ideas, limiting the usefulness of LMs in creative and
exploratory tasks such as brainstorming, storytelling, or problem solving. We
address this challenge with Diversity-Aware Reinforcement Learning (DARLING), a
framework that jointly optimizes for response quality and semantic diversity.
At its core, DARLING introduces a learned partition function to measure
diversity beyond surface-level lexical variations. This diversity signal is
then combined with a quality reward during online reinforcement learning,
encouraging models to generate outputs that are both high-quality and distinct.
Experiments across multiple model families and sizes show that DARLING
generalizes to two regimes: non-verifiable tasks (instruction following and
creative writing) and verifiable tasks (competition math). On five benchmarks
in the first setting, DARLING consistently outperforms quality-only RL
baselines, producing outputs that are simultaneously of higher quality and
novelty. In the second setting, DARLING achieves higher pass@1 (solution
quality) and pass@k (solution variety). Most strikingly, explicitly optimizing
for diversity catalyzes exploration in online RL, which manifests itself as
higher-quality responses.

</details>


### [137] [PalmX 2025: The First Shared Task on Benchmarking LLMs on Arabic and Islamic Culture](https://arxiv.org/abs/2509.02550)
*Fakhraddin Alwajih,Abdellah El Mekki,Hamdy Mubarak,Majd Hawasly,Abubakr Mohamed,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: 本文介绍了PalmX 2025共享任务，旨在评估大型语言模型在阿拉伯和伊斯兰文化领域的文化能力，并发现任务特定微调能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型在预训练阶段的数据主要来自网络，导致其对某些社区（如阿拉伯和伊斯兰文化）的理解不足，因此需要一个专门的任务来评估和提升模型的文化能力。

Method: 本文提出了PalmX 2025共享任务，包含两个子任务：通用阿拉伯文化与通用伊斯兰文化，通过多项选择题来评估模型的文化能力。同时，研究还探讨了任务特定微调和数据增强的效果。

Result: 任务特定的微调显著提升了模型在文化问题和伊斯兰知识上的表现，其中最佳系统在文化问题上的准确率为72.15%，在伊斯兰知识上的准确率为84.22%。参数高效的微调是最常用且最有效的方法，而数据增强的效果则取决于领域。

Conclusion: 本文介绍了PalmX 2025，这是首个用于评估大型语言模型在特定文化领域中的文化能力的共享任务。实验结果表明，任务特定的微调显著提高了性能，参数高效的微调是最有效的方法。

Abstract: Large Language Models (LLMs) inherently reflect the vast data distributions
they encounter during their pre-training phase. As this data is predominantly
sourced from the web, there is a high chance it will be skewed towards
high-resourced languages and cultures, such as those of the West. Consequently,
LLMs often exhibit a diminished understanding of certain communities, a gap
that is particularly evident in their knowledge of Arabic and Islamic cultures.
This issue becomes even more pronounced with increasingly under-represented
topics. To address this critical challenge, we introduce PalmX 2025, the first
shared task designed to benchmark the cultural competence of LLMs in these
specific domains. The task is composed of two subtasks featuring
multiple-choice questions (MCQs) in Modern Standard Arabic (MSA): General
Arabic Culture and General Islamic Culture. These subtasks cover a wide range
of topics, including traditions, food, history, religious practices, and
language expressions from across 22 Arab countries. The initiative drew
considerable interest, with 26 teams registering for Subtask 1 and 19 for
Subtask 2, culminating in nine and six valid submissions, respectively. Our
findings reveal that task-specific fine-tuning substantially boosts performance
over baseline models. The top-performing systems achieved an accuracy of 72.15%
on cultural questions and 84.22% on Islamic knowledge. Parameter-efficient
fine-tuning emerged as the predominant and most effective approach among
participants, while the utility of data augmentation was found to be
domain-dependent.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [138] [Data Cartography for Detecting Memorization Hotspots and Guiding Data Interventions in Generative Models](https://arxiv.org/abs/2509.00083)
*Laksh Patel,Neel Shanbhag*

Main category: cs.LG

TL;DR: 本文提出了一种数据驱动的框架GenDataCarto，通过分配每个预训练样本的难度分数和记忆分数，将其划分为四个象限，以指导有针对性的修剪和上/下加权。实验证明，该方法能有效减少数据泄露，同时对生成性能影响较小。


<details>
  <summary>Details</summary>
Motivation: 现代生成模型存在过拟合和无意中记住罕见训练示例的风险，这些示例可能被对手提取或夸大基准性能。

Method: 提出了一种数据驱动的框架Generative Data Cartography (GenDataCarto)，通过分配每个预训练样本的难度分数和记忆分数，将其划分为四个象限，以指导有针对性的修剪和上/下加权。

Result: GenDataCarto在仅修剪10%数据的情况下，将合成canary提取的成功率降低了40%以上，同时将验证困惑度提高了不到0.5%。

Conclusion: 通过有原则的数据干预，可以显著减轻泄漏问题，同时对生成性能的影响很小。

Abstract: Modern generative models risk overfitting and unintentionally memorizing rare
training examples, which can be extracted by adversaries or inflate benchmark
performance. We propose Generative Data Cartography (GenDataCarto), a
data-centric framework that assigns each pretraining sample a difficulty score
(early-epoch loss) and a memorization score (frequency of ``forget events''),
then partitions examples into four quadrants to guide targeted pruning and
up-/down-weighting. We prove that our memorization score lower-bounds classical
influence under smoothness assumptions and that down-weighting
high-memorization hotspots provably decreases the generalization gap via
uniform stability bounds. Empirically, GenDataCarto reduces synthetic canary
extraction success by over 40\% at just 10\% data pruning, while increasing
validation perplexity by less than 0.5\%. These results demonstrate that
principled data interventions can dramatically mitigate leakage with minimal
cost to generative performance.

</details>


### [139] [Learning to Refine: Self-Refinement of Parallel Reasoning in LLMs](https://arxiv.org/abs/2509.00084)
*Qibin Wang,Pu Zhao,Shaohan Huang,Fangkai Yang,Lu Wang,Furu Wei,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种新的并行测试时缩放框架Generative Self-Refinement (GSR)，通过统一模型生成候选响应并进行自我改进，以解决复杂多步骤推理问题。实验结果显示该方法在多个数学基准测试中表现优异，并且具有模型无关性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的方法如Best-of-N和多数投票受到其性能依赖于候选响应质量的限制，当所有候选响应都不正确时，它们无法产生正确的解决方案。引入额外的模型来选择最佳响应也会带来显著的部署成本。

Method: 我们引入了生成自我改进（GSR），这是一种新颖的并行测试时缩放框架，其中统一模型首先并行生成一组候选响应，然后根据包含问题和这些候选响应的提示进行自我改进，以合成一个新的更优解决方案。为了提高LLM在直接提示下有效进行改进的能力，我们设计了一个混合训练管道，同时优化两个互补的目标：直接解决问题和改进候选响应。

Result: 实验结果表明，我们的方法在五个数学基准测试中达到了最先进的性能。我们进一步展示了这种学习的自我改进技能是一种模型无关的增强，对不同模型规模具有鲁棒性，并能推广到分布外推理任务。

Conclusion: 实验结果表明，我们的方法在五个数学基准测试中达到了最先进的性能。我们进一步展示了这种学习的自我改进技能是一种模型无关的增强，对不同模型规模具有鲁棒性，并能推广到分布外推理任务。

Abstract: To further enhance the ability of Large Language Models (LLMs) to solve
complex, multi-step reasoning problems, test-time scaling (TTS) methods have
gained widespread attention. Existing approaches such as Best-of-N and majority
voting are limited as their performance depends on the quality of candidate
responses, making them unable to produce a correct solution when all candidates
are incorrect. Introducing an additional model to select the best response also
incurs significant deployment costs. To this end, we introduce Generative
Self-Refinement (GSR), a novel parallel test-time scaling framework where a
unified model first generates a set of candidate responses in parallel and then
performs self-refinement to synthesize a new superior solution based on a
prompt consisting of the problem and these candidates. However, LLMs struggle
to perform refinement effectively when prompted directly. Therefore, we design
a hybrid training pipeline by jointly optimizing for two complementary
objectives, solving problems directly and refining candidate responses.
Experimental results demonstrate that our method achieves state-of-the-art
performance across five mathematical benchmarks. We further show that this
learned self-refinement skill is a model-agnostic enhancement, robust across
different model scales and generalizing to out-of-distribution reasoning tasks.

</details>


### [140] [Pruning Weights but Not Truth: Safeguarding Truthfulness While Pruning LLMs](https://arxiv.org/abs/2509.00096)
*Yao Fu,Runchao Li,Xianxuan Long,Haotian Yu,Xiaotian Han,Yu Yin,Pan Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的剪枝方法TPLO，旨在在保持LLM性能的同时保留其内部状态的关键特征，以提高剪枝LLM的谎言检测能力。


<details>
  <summary>Details</summary>
Motivation: 我们发现神经网络剪枝会破坏LLM内部激活特征，这些特征对于谎言检测至关重要，因此需要一种方法在不牺牲这些关键谎言检测能力的情况下剪枝LLM。

Method: 我们提出了基于层异常值的诚实剪枝（TPLO），该方法更注重具有更多激活异常值和更强区分特征的层，同时引入了一种提示规则以丰富TruthfulQA基准以更好地校准LLM剪枝。

Result: 我们的方法在50%的稀疏度下实现了88%的准确率，显著提高了剪枝LLM的幻觉检测能力，并增强了其在TruthfulQA上的表现。

Conclusion: 我们的方法在保持LLM原始性能的同时，保留了内部状态的关键特征，从而实现了对剪枝LLM的幻觉检测的改进，并增强了其在TruthfulQA上的表现。

Abstract: Neural network pruning has emerged as a promising approach for deploying LLMs
in low-resource scenarios while preserving downstream task performance.
However, for the first time, we reveal that such pruning disrupts LLMs'
internal activation features crucial for lie detection, where probing
classifiers (typically small logistic regression models) trained on these
features assess the truthfulness of LLM-generated statements. This discovery
raises a crucial open question: how can we prune LLMs without sacrificing these
critical lie detection capabilities? Our investigation further reveals that
naively adjusting layer-wise pruning sparsity based on importance inadvertently
removes crucial weights, failing to improve lie detection performance despite
its reliance on the most crucial LLM layer. To address this issue, we propose
Truthful Pruning aligned by Layer-wise Outliers (TPLO), which places greater
emphasis on layers with more activation outliers and stronger discriminative
features simultaneously. This preserves LLMs' original performance while
retaining critical features of inner states needed for robust lie detection.
Moreover, we introduce a prompting rule to enrich the TruthfulQA benchmark for
better calibrating LLM pruning. Empirical results show that our approach
improves the hallucination detection for pruned LLMs (achieving 88% accuracy at
50% sparsity) and enhances their performance on TruthfulQA.

</details>


### [141] [Advanced spectral clustering for heterogeneous data in credit risk monitoring systems](https://arxiv.org/abs/2509.00546)
*Lu Han,Mengyan Li,Jiping Qiang,Zhi Su*

Main category: cs.LG

TL;DR: 本文提出了一种名为ASC的方法，通过优化权重参数整合财务和文本相似性，并使用新颖的特征值-轮廓优化方法选择特征向量。在包含1,428家中小企业的数据集上评估，ASC的轮廓分数比单一类型数据基线方法高18%。此外，结果集群提供了可操作的见解；例如，51%的低风险公司发现其文本记录中包含“社会招聘”一词。ASC在多个聚类算法中得到了验证，包括k均值、k中位数和k中点，ΔIntra/Inter < 0.13和Δ轮廓系数< 0.02。通过将谱聚类理论与异构数据应用相结合，ASC能够识别出有意义的集群，如专注于招聘的中小企业，其违约风险降低了30%，从而支持更针对性和有效的信用干预。


<details>
  <summary>Details</summary>
Motivation: Heterogeneous data, which encompass both numerical financial variables and textual records, present substantial challenges for credit monitoring.

Method: Advanced Spectral Clustering (ASC), which integrates financial and textual similarities through an optimized weight parameter and selects eigenvectors using a novel eigenvalue-silhouette optimization approach.

Result: Evaluated on a dataset comprising 1,428 small and medium-sized enterprises (SMEs), ASC achieves a Silhouette score that is 18% higher than that of a single-type data baseline method. Furthermore, the resulting clusters offer actionable insights; for instance, 51% of low-risk firms are found to include the term 'social recruitment' in their textual records. The robustness of ASC is confirmed across multiple clustering algorithms, including k-means, k-medians, and k-medoids, with ΔIntra/Inter < 0.13 and ΔSilhouette Coefficient < 0.02.

Conclusion: ASC enables the identification of meaningful clusters, such as recruitment-focused SMEs exhibiting a 30% lower default risk, thereby supporting more targeted and effective credit interventions.

Abstract: Heterogeneous data, which encompass both numerical financial variables and
textual records, present substantial challenges for credit monitoring. To
address this issue, we propose Advanced Spectral Clustering (ASC), a method
that integrates financial and textual similarities through an optimized weight
parameter and selects eigenvectors using a novel eigenvalue-silhouette
optimization approach. Evaluated on a dataset comprising 1,428 small and
medium-sized enterprises (SMEs), ASC achieves a Silhouette score that is 18%
higher than that of a single-type data baseline method. Furthermore, the
resulting clusters offer actionable insights; for instance, 51% of low-risk
firms are found to include the term 'social recruitment' in their textual
records. The robustness of ASC is confirmed across multiple clustering
algorithms, including k-means, k-medians, and k-medoids, with
{\Delta}Intra/Inter < 0.13 and {\Delta}Silhouette Coefficient < 0.02. By
bridging spectral clustering theory with heterogeneous data applications, ASC
enables the identification of meaningful clusters, such as recruitment-focused
SMEs exhibiting a 30% lower default risk, thereby supporting more targeted and
effective credit interventions.

</details>


### [142] [DTRNet: Dynamic Token Routing Network to Reduce Quadratic Costs in Transformers](https://arxiv.org/abs/2509.00925)
*Aman Sharma,Saeed Najafi,Parsa Farinneya,Benyamin Jamialahmadi,Marzieh S. Tahaei,Yuhe Fan,Mehdi Rezagholizadeh,Boxing Chen,Aref Jafari*

Main category: cs.LG

TL;DR: DTRNet 是一种改进的 Transformer 架构，通过动态跳过跨 token 混合的二次成本，实现计算效率的提升，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: Transformer 在许多任务中取得最先进的结果，但其对每个 token 在每一层均匀应用二次自注意力使其计算成本高昂。需要一种更高效的替代方案。

Method: DTRNet 是一种改进的 Transformer 架构，允许 token 动态跳过跨 token 混合的二次成本，同时仍接收轻量级线性更新。它保留了 MLP 模块，并将大多数 token 的注意力成本降低到线性。

Result: DTRNet 在每层仅将约 10% 的 token 通过注意力，同时保持与完整 Transformer 相当的性能。它在匹配 FLOPs 下的准确性和内存上优于基于路由的层跳过方法，如 MoD 和 D-LLM，同时将更少的 token 路由到完整注意力。

Conclusion: DTRNet 提供了一种简单、高效且可扩展的 Transformer 替代方案，通过解耦 token 更新与注意力混合，显著减少了计算中的二次部分。

Abstract: Transformers achieve state-of-the-art results across many tasks, but their
uniform application of quadratic self-attention to every token at every layer
makes them computationally expensive. We introduce DTRNet (Dynamic Token
Routing Network), an improved Transformer architecture that allows tokens to
dynamically skip the quadratic cost of cross-token mixing while still receiving
lightweight linear updates. By preserving the MLP module and reducing the
attention cost for most tokens to linear, DTRNet ensures that every token is
explicitly updated while significantly lowering overall computation. This
design offers an efficient and effective alternative to standard dense
attention. Once trained, DTRNet blocks routes only ~10% of tokens through
attention at each layer while maintaining performance comparable to a full
Transformer. It consistently outperforms routing-based layer skipping methods
such as MoD and D-LLM in both accuracy and memory at matched FLOPs, while
routing fewer tokens to full attention. Its efficiency gains, scales with
sequence length, offering significant reduction in FLOPs for long-context
inputs. By decoupling token updates from attention mixing, DTRNet substantially
reduces the quadratic share of computation, providing a simple, efficient, and
scalable alternative to Transformers.

</details>


### [143] [MEPT: Mixture of Expert Prompt Tuning as a Manifold Mapper](https://arxiv.org/abs/2509.00996)
*Runjia Zeng,Guangyan Sun,Qifan Wang,Tong Geng,Sohail Dianat,Xiaotian Han,Raghuveer Rao,Xueling Zhang,Cheng Han,Lifu Huang,Dongfang Liu*

Main category: cs.LG

TL;DR: MEPT是一种基于专家混合架构的新型有效且高效的流形映射框架，能够适应多样且非平稳的数据分布，并在SuperGLUE任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的微调方法由于参数空间的刚性，难以动态激活适当的神经路径，无法灵活适应多样和变化的数据分布。

Method: MEPT结合了专家混合架构，通过集成多个提示专家来适应多样且非平稳的数据分布，从而实现有效的流形映射框架。

Result: MEPT在SuperGLUE上优于多种最先进的参数高效基线，平均准确率提升了1.94%，激活提示数量减少了79.25%。

Conclusion: MEPT在SuperGLUE上表现出色，显著提高了平均准确率并减少了激活提示的数量，同时通过流形学习的理论见解和神经激活路径可视化结果得到了验证。

Abstract: Considering deep neural networks as manifold mappers, the
pretrain-then-fine-tune paradigm can be interpreted as a two-stage process:
pretrain establishes a broad knowledge base, and fine-tune adjusts the model
parameters to activate specific neural pathways to align with the target
manifold. Although prior fine-tuning approaches demonstrate success, their
rigid parameter space limits their ability to dynamically activate appropriate
neural pathways, rendering them ill-equipped to adapt flexibly to the diverse
and evolving data distributions. In light of this view, we propose a novel
approach, Mixture of Expert Prompt Tuning (MEPT), as an effective and efficient
manifold-mapping framework. MEPT leverages the Mixture of Experts architecture
by integrating multiple prompt experts to adaptively learn diverse and
non-stationary data distributions. Empirical evaluations demonstrate that MEPT
outperforms several state-of-the-art parameter efficient baselines on
SuperGLUE, achieving notable improvements in mean accuracy (e.g., 1.94%) while
significantly reducing activated prompts by 79.25%. The effectiveness of MEPT
is further supported by theoretical insights from manifold learning and
validated through neural activation pathway visualization results. Our code is
avaliable at https://github.com/runtsang/MEPT.

</details>


### [144] [Towards High Data Efficiency in Reinforcement Learning with Verifiable Reward](https://arxiv.org/abs/2509.01321)
*Xinyu Tang,Zhenduo Zhang,Yurou Liu,Wayne Xin Zhao,Zujie Wen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.LG

TL;DR: DEPO is a data-efficient policy optimization method that improves reasoning capabilities by optimizing offline and online data selection, achieving significant performance gains with less training data.


<details>
  <summary>Details</summary>
Motivation: The motivation is to mitigate the high training costs and low data efficiency associated with scaling reinforcement learning with verifiable rewards (RLVR) methods by proposing a more data-efficient approach.

Method: DEPO is a Data-Efficient Policy Optimization pipeline that combines optimized strategies for both offline and online data selection. It includes an offline phase for curating high-quality training samples and an online RLVR training phase with a sample-level explorability metric and a replay mechanism for under-explored samples.

Result: Experiments across five reasoning benchmarks show that DEPO consistently outperforms existing methods. Using only 20% of the training data, DEPO achieves a 1.85 times speed-up on AIME24 and a 1.66 times speed-up on AIME25 compared to GRPO trained on the full dataset.

Conclusion: DEPO consistently outperforms existing methods in both offline and online data selection scenarios. Using only 20% of the training data, DEPO achieves significant speed-ups on AIME24 and AIME25 compared to GRPO.

Abstract: Recent advances in large reasoning models have leveraged reinforcement
learning with verifiable rewards (RLVR) to improve reasoning capabilities.
However, scaling these methods typically requires extensive rollout computation
and large datasets, leading to high training costs and low data efficiency. To
mitigate this issue, we propose DEPO, a Data-Efficient Policy Optimization
pipeline that combines optimized strategies for both offline and online data
selection. In the offline phase, we curate a high-quality subset of training
samples based on diversity, influence, and appropriate difficulty. During
online RLVR training, we introduce a sample-level explorability metric to
dynamically filter samples with low exploration potential, thereby reducing
substantial rollout computational costs. Furthermore, we incorporate a replay
mechanism for under-explored samples to ensure adequate training, which
enhances the model's final convergence performance. Experiments across five
reasoning benchmarks show that DEPO consistently outperforms existing methods
in both offline and online data selection scenarios. Notably, using only 20% of
the training data, our approach achieves a 1.85 times speed-up on AIME24 and a
1.66 times speed-up on AIME25 compared to GRPO trained on the full dataset.

</details>


### [145] [Evaluating Cumulative Spectral Gradient as a Complexity Measure](https://arxiv.org/abs/2509.02399)
*Haji Gul,Abdul Ghani Naim,Ajaz Ahmad Bhat*

Main category: cs.LG

TL;DR: 研究发现CSG在链接预测任务中表现不佳，需要更稳健的复杂度度量。


<details>
  <summary>Details</summary>
Motivation: 准确估计数据集复杂度对于评估和比较知识图谱的链接预测模型至关重要。

Method: 通过标准知识图谱链接预测基准和多类尾部预测任务评估CSG的行为，使用两个关键参数M（每类的蒙特卡洛采样点数）和K（嵌入空间中的最近邻数）。

Result: 发现CSG对K的选择高度敏感，且与MRR等传统性能指标的相关性弱或无相关性。

Conclusion: 研究结果表明，CSG的稳定性和泛化预测能力在链接预测设置中失效，需要更稳健、与分类器无关的复杂度度量。

Abstract: Accurate estimation of dataset complexity is crucial for evaluating and
comparing link prediction models for knowledge graphs (KGs). The Cumulative
Spectral Gradient (CSG) metric derived from probabilistic divergence between
classes within a spectral clustering framework was proposed as a dataset
complexity measure that (1) naturally scales with the number of classes and (2)
correlates strongly with downstream classification performance. In this work,
we rigorously assess CSG behavior on standard knowledge graph link prediction
benchmarks a multi class tail prediction task, using two key parameters
governing its computation, M, the number of Monte Carlo sampled points per
class, and K, the number of nearest neighbors in the embedding space. Contrary
to the original claims, we find that (1) CSG is highly sensitive to the choice
of K and therefore does not inherently scale with the number of target classes,
and (2) CSG values exhibit weak or no correlation with established performance
metrics such as mean reciprocal rank (MRR). Through experiments on FB15k 237,
WN18RR, and other standard datasets, we demonstrate that CSG purported
stability and generalization predictive power break down in link prediction
settings. Our results highlight the need for more robust, classifier agnostic
complexity measures in KG link prediction evaluation.

</details>


### [146] [DynaGuard: A Dynamic Guardrail Model With User-Defined Policies](https://arxiv.org/abs/2509.02563)
*Monte Hoover,Vatsal Baherwani,Neel Jain,Khalid Saifullah,Joseph Vincent,Chirag Jain,Melissa Kazemi Rad,C. Bayan Bruss,Ashwinee Panda,Tom Goldstein*

Main category: cs.LG

TL;DR: 本文提出动态守护模型，可根据用户定义的策略评估文本，适用于不同应用领域，在检测静态危害和识别自由格式政策违规方面表现优异，且速度更快。


<details>
  <summary>Details</summary>
Motivation: 标准守护模型只能检测预定义的静态危害类别，无法满足不同应用领域的需求。

Method: 提出动态守护模型，根据用户定义的策略评估文本，适用于不同应用领域。

Result: 动态守护模型在检测静态危害类别方面与静态模型相当，并且在识别自由格式政策违规方面表现出色，同时速度更快。

Conclusion: 动态守护模型在检测静态危害类别方面与静态模型相当，并且在识别自由格式政策违规方面表现出色，同时速度更快。

Abstract: Guardian models are used to supervise and moderate the outputs of user-facing
chatbots, enforcing guardrails and detecting bad behaviors. Standard guardian
models like LlamaGuard detect predefined, static categories of harms. We
propose dynamic guardian models that evaluate text based on user-defined
policies, making them useful for different application domains that are not
addressed by standard guardian models. Our dynamic guardian models can be used
for fast detection of policy violations or with chain-of-thought reasoning that
articulates and justifies the model outputs. Our dynamic guardian models match
static models in detection accuracy for static harm categories while
identifying violations of free-form policies with accuracy comparable to
frontier reasoning models in a fraction of the time.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [147] [Hybrid Topic-Semantic Labeling and Graph Embeddings for Unsupervised Legal Document Clustering](https://arxiv.org/abs/2509.00990)
*Deepak Bastola,Woohyeok Choi*

Main category: stat.ML

TL;DR: 本文提出了一种将无监督主题和图嵌入与监督模型相结合的混合方法，用于分类法律文本。通过Top2Vec和Node2Vec生成嵌入，并使用KMeans进行聚类，结果表明该方法在法律文档分析中优于传统的LDA和NMF模型。


<details>
  <summary>Details</summary>
Motivation: 法律文件由于其领域特定的语言和有限的标记数据，在文本分类中具有独特的挑战。

Method: 本文提出了一种混合方法，通过结合无监督主题和图嵌入与监督模型来分类法律文本。使用Top2Vec学习语义文档嵌入并自动发现潜在主题，使用Node2Vec通过法律文档的二分图捕获结构关系。嵌入通过KMeans组合和聚类，产生连贯的文档分组。

Result: 在法律文档数据集上的计算表明，结合的Top2Vec+Node2Vec方法比仅文本或仅图嵌入提高了聚类质量。对超参数（如聚类数和嵌入维度）进行了敏感性分析，并证明该方法在基线Latent Dirichlet Allocation (LDA)和Non-Negative Matrix Factorization (NMF)模型中表现具有竞争力。

Conclusion: 该方法在探索性法律数据分析和作为监督学习任务的前导方面显示出潜力，但需要进一步改进和领域特定的适应以用于实际的法律应用。

Abstract: Legal documents pose unique challenges for text classification due to their
domain-specific language and often limited labeled data. This paper proposes a
hybrid approach for classifying legal texts by combining unsupervised topic and
graph embeddings with a supervised model. We employ Top2Vec to learn semantic
document embeddings and automatically discover latent topics, and Node2Vec to
capture structural relationships via a bipartite graph of legal documents. The
embeddings are combined and clustered using KMeans, yielding coherent groupings
of documents. Our computations on a legal document dataset demonstrate that the
combined Top2Vec+Node2Vec approach improves clustering quality over text-only
or graph-only embeddings. We conduct a sensitivity analysis of hyperparameters,
such as the number of clusters and the dimensionality of the embeddings, and
demonstrate that our method achieves competitive performance against baseline
Latent Dirichlet Allocation (LDA) and Non-Negative Matrix Factorization (NMF)
models. Key findings indicate that while the pipeline presents an innovative
approach to unsupervised legal document analysis by combining semantic topic
modeling with graph embedding techniques, its efficacy is contingent upon the
quality of initial topic generation and the representational power of the
chosen embedding models for specialized legal language. Strategic
recommendations include the exploration of domain-specific embeddings, more
comprehensive hyperparameter tuning for Node2Vec, dynamic determination of
cluster numbers, and robust human-in-the-loop validation processes to enhance
legal relevance and trustworthiness. The pipeline demonstrates potential for
exploratory legal data analysis and as a precursor to supervised learning tasks
but requires further refinement and domain-specific adaptation for practical
legal applications.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [148] [Evaluating the Effectiveness of Transformer Layers in Wav2Vec 2.0, XLS-R, and Whisper for Speaker Identification Tasks](https://arxiv.org/abs/2509.00230)
*Linus Stuhlmann,Michael Alexander Saxer*

Main category: cs.SD

TL;DR: 本研究评估了Wav2Vec 2.0、XLS-R和Whisper在说话人识别任务中的性能，发现Wav2Vec 2.0和XLS-R在早期层中表现良好，而Whisper在深层表现更优，并确定了每个模型的最佳变压器层数量。


<details>
  <summary>Details</summary>
Motivation: 评估三种先进的语音编码器模型在说话人识别任务中的性能。

Method: 通过微调这些模型，并使用SVCCA、k-means聚类和t-SNE可视化分析它们的逐层表示。

Result: Wav2Vec 2.0和XLS-R在其早期层中有效捕获了说话人特定特征，微调提高了稳定性和性能。Whisper在深层表现更好。

Conclusion: 研究确定了每个模型在进行说话人识别任务时的最优变压器层数量。

Abstract: This study evaluates the performance of three advanced speech encoder models,
Wav2Vec 2.0, XLS-R, and Whisper, in speaker identification tasks. By
fine-tuning these models and analyzing their layer-wise representations using
SVCCA, k-means clustering, and t-SNE visualizations, we found that Wav2Vec 2.0
and XLS-R capture speaker-specific features effectively in their early layers,
with fine-tuning improving stability and performance. Whisper showed better
performance in deeper layers. Additionally, we determined the optimal number of
transformer layers for each model when fine-tuned for speaker identification
tasks.

</details>


### [149] [ArabEmoNet: A Lightweight Hybrid 2D CNN-BiLSTM Model with Attention for Robust Arabic Speech Emotion Recognition](https://arxiv.org/abs/2509.01401)
*Ali Abouzeid,Bilal Elbouardi,Mohamed Maged,Shady Shehata*

Main category: cs.SD

TL;DR: 本文介绍了ArabEmoNet，这是一种轻量级架构，旨在克服阿拉伯语等低资源语言在语音情感识别中的挑战，通过使用Mel频谱图和二维卷积来保留关键的情感线索，实现了卓越的性能和效率。


<details>
  <summary>Details</summary>
Motivation: Speech emotion recognition is vital for human-computer interaction, particularly for low-resource languages like Arabic, which face challenges due to limited data and research.

Method: ArabEmoNet uses Mel spectrograms processed through 2D convolutions, preserving critical emotional cues often lost in traditional methods.

Result: ArabEmoNet achieves superior results with just 1 million parameters, 90 times smaller than HuBERT base and 74 times smaller than Whisper.

Conclusion: ArabEmoNet advances Arabic speech emotion recognition, offering exceptional performance and accessibility for real-world applications.

Abstract: Speech emotion recognition is vital for human-computer interaction,
particularly for low-resource languages like Arabic, which face challenges due
to limited data and research. We introduce ArabEmoNet, a lightweight
architecture designed to overcome these limitations and deliver
state-of-the-art performance. Unlike previous systems relying on discrete MFCC
features and 1D convolutions, which miss nuanced spectro-temporal patterns,
ArabEmoNet uses Mel spectrograms processed through 2D convolutions, preserving
critical emotional cues often lost in traditional methods.
  While recent models favor large-scale architectures with millions of
parameters, ArabEmoNet achieves superior results with just 1 million
parameters, 90 times smaller than HuBERT base and 74 times smaller than
Whisper. This efficiency makes it ideal for resource-constrained environments.
ArabEmoNet advances Arabic speech emotion recognition, offering exceptional
performance and accessibility for real-world applications.

</details>


### [150] [Spectrogram Patch Codec: A 2D Block-Quantized VQ-VAE and HiFi-GAN for Neural Speech Coding](https://arxiv.org/abs/2509.02244)
*Luis Felipe Chary,Miguel Arjona Ramirez*

Main category: cs.SD

TL;DR: 本文介绍了一种新的神经语音编解码器，它通过单阶段量化方法简化了架构，实现了低延迟流媒体，并在感知质量和可懂性方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的神经编解码器通常依赖复杂的残差矢量量化堆，这可能导致较高的延迟和复杂的架构。本文旨在提供一种更简单、高效的替代方案。

Method: 我们提出了一种神经语音编解码器，通过引入更简单的单阶段量化方法来挑战复杂残差矢量量化（RVQ）堆的需要。我们的方法直接在梅尔频谱图上操作，将其视为2D数据，并将不重叠的4x4块量化到一个共享的代码本中。这种基于块的设计简化了架构，实现了低延迟流媒体，并产生了一个离散的潜在网格。为了确保高保真合成，我们对VQ-VAE进行了后期对抗微调，并从头开始训练HiFi-GAN声码器。

Result: 在16 kHz语音下，系统运行在约7.5 kbits/s，与几种最先进的神经编解码器进行比较，使用客观指标如STOI、PESQ、MCD和ViSQOL进行评估。结果表明，我们的简化非残差架构在感知质量和可懂性方面具有竞争力。

Conclusion: 我们的简化非残差架构在感知质量和可懂性方面表现出色，验证了其作为未来低延迟编解码器设计的有效且开放的基础。

Abstract: We present a neural speech codec that challenges the need for complex
residual vector quantization (RVQ) stacks by introducing a simpler,
single-stage quantization approach. Our method operates directly on the
mel-spectrogram, treating it as a 2D data and quantizing non-overlapping 4x4
patches into a single, shared codebook. This patchwise design simplifies the
architecture, enables low-latency streaming, and yields a discrete latent grid.
To ensure high-fidelity synthesis, we employ a late-stage adversarial
fine-tuning for the VQ-VAE and train a HiFi-GAN vocoder from scratch on the
codec's reconstructed spectrograms. Operating at approximately 7.5 kbits/s for
16 kHz speech, our system was evaluated against several state-of-the-art neural
codecs using objective metrics such as STOI, PESQ, MCD, and ViSQOL. The results
demonstrate that our simplified, non-residual architecture achieves competitive
perceptual quality and intelligibility, validating it as an effective and open
foundation for future low-latency codec designs.

</details>


### [151] [FLM-Audio: Natural Monologues Improves Native Full-Duplex Chatbots via Dual Training](https://arxiv.org/abs/2509.02521)
*Yiqun Yao,Xiang Li,Xin Jiang,Xuezhi Fang,Naitong Yu,Wenjia Ma,Aixin Sun,Yequan Wang*

Main category: cs.SD

TL;DR: 本文提出了一种新的全双工对话模型，通过将文本独白表示为连续的标记序列，并在不同训练阶段交替其位置，以解决音频流和文本独白之间的对齐问题，从而提高模型的响应速度、双工性和聊天体验。


<details>
  <summary>Details</summary>
Motivation: 现有的全双工对话模型在处理文本独白和音频流之间的对齐时存在挑战，因为传统的基于词级的对齐方法会降低大型预训练模型的语言能力，并且需要高精度的时间戳，这会引入级联错误并增加预处理成本。

Method: 本文提出了一种名为“自然”独白的方法，将文本独白表示为连续的标记序列，并在不同训练阶段交替其位置，以实现与音频流的对齐。

Result: 本文提出的“自然”独白方法在FAL-Audio模型中得到了验证，该模型展示了优越的响应性、双工性和聊天体验。

Conclusion: 本文提出了一种新的方法，通过将文本独白表示为连续的标记序列，并在不同训练阶段交替其位置，以解决音频流和文本独白之间的对齐问题。实验结果表明，这种方法有效提高了全双工对话模型的响应速度、双工性和聊天体验。

Abstract: Full-duplex dialog models are designed to listen and speak simultaneously
with rapid responses to fast-changing user input. Among existing approaches,
native full-duplex models merges different channels (e.g. listen and speak) in
a single time step, overcoming the high response latency inherent to
time-division multiplexing time-division multiplexing (TDM) alternatives. Yet,
a key challenge remains: aligning textual monologues with audio streams that
operate at different bitrates. The prevailing solution relies on word-level
alignment, but this can degrade the language ability of large pre-trained
models. Moreover, it requires highly accurate timestamps for every token, which
introduces cascading errors and increases pre-processing costs. In this paper,
we propose textual monologues in continuous tokens sequence, namely "natural"
monologues, which mimics humanoid cognitive behavior in dialogs. For temporal
alignment, we alternate the position of the natural monologue - leading or
trailing the audio - across different training stages. This "dual" training
paradigm proves highly effective in building FLM-Audio, our 7B spoken dialog
model that demonstrates superior responsiveness, duplexity, and chatting
experiences, as confirmed by experimental results.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [152] [From Attack Descriptions to Vulnerabilities: A Sentence Transformer-Based Approach](https://arxiv.org/abs/2509.02077)
*Refat Othman,Diaeddin Rimawi,Bruno Rossi,Barbara Russo*

Main category: cs.CR

TL;DR: 本研究评估了14种最先进的句子转换器，以自动从攻击的文本描述中识别漏洞。结果表明，MMPNet模型在使用攻击技术描述时表现最佳，能够有效识别漏洞，并发现了一些未记录在MITRE存储库中的预测链接。自动化链接攻击技术与漏洞可以提高软件安全事件的检测和响应能力，减少漏洞可被利用的时间，从而促进更安全系统的开发。


<details>
  <summary>Details</summary>
Motivation: 手动将攻击映射到CVE是不可能的，因此需要自动化。

Method: 评估了14种最先进的句子转换器，以自动从攻击的文本描述中识别漏洞。

Result: MMPNet模型在使用攻击技术描述时表现出色，F1分数为89.0，精确度为84.0，召回率为94.7。平均有56%的漏洞由MMPNet模型识别，并且在CVE存储库中与攻击一起出现，而61%的漏洞由模型检测到。

Conclusion: 自动化将攻击技术与漏洞联系起来不仅提高了软件安全事件的检测和响应能力，还减少了漏洞可被利用的时间，从而有助于开发更安全的系统。

Abstract: In the domain of security, vulnerabilities frequently remain undetected even
after their exploitation. In this work, vulnerabilities refer to publicly
disclosed flaws documented in Common Vulnerabilities and Exposures (CVE)
reports. Establishing a connection between attacks and vulnerabilities is
essential for enabling timely incident response, as it provides defenders with
immediate, actionable insights. However, manually mapping attacks to CVEs is
infeasible, thereby motivating the need for automation. This paper evaluates 14
state-of-the-art (SOTA) sentence transformers for automatically identifying
vulnerabilities from textual descriptions of attacks. Our results demonstrate
that the multi-qa-mpnet-base-dot-v1 (MMPNet) model achieves superior
classification performance when using attack Technique descriptions, with an
F1-score of 89.0, precision of 84.0, and recall of 94.7. Furthermore, it was
observed that, on average, 56% of the vulnerabilities identified by the MMPNet
model are also represented within the CVE repository in conjunction with an
attack, while 61% of the vulnerabilities detected by the model correspond to
those cataloged in the CVE repository. A manual inspection of the results
revealed the existence of 275 predicted links that were not documented in the
MITRE repositories. Consequently, the automation of linking attack techniques
to vulnerabilities not only enhances the detection and response capabilities
related to software security incidents but also diminishes the duration during
which vulnerabilities remain exploitable, thereby contributing to the
development of more secure systems.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [153] [ERank: Fusing Supervised Fine-Tuning and Reinforcement Learning for Effective and Efficient Text Reranking](https://arxiv.org/abs/2509.00520)
*Yuzheng Cai,Yanzhao Zhang,Dingkun Long,Mingxin Li,Pengjun Xie,Weiguo Zheng*

Main category: cs.IR

TL;DR: ERank是一种高效的点对点重排序器，通过两阶段训练流程提高评分区分度和全局排名意识，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）驱动的重排序器面临一个基本的权衡问题：基于监督微调的点对点方法缺乏必要的评分区分度，而设计用于复杂推理的方法通常采用强大但低效的列表对齐公式，使其不适合低延迟应用。

Method: ERank是一种基于推理大语言模型的高度有效且高效的点对点重排序器。提出了一种新的两阶段训练流程，首先进行监督微调（SFT），然后使用强化学习（RL）进行进一步优化。

Result: ERank在BRIGHT、FollowIR、TREC DL和BEIR基准测试中进行了评估，与现有方法相比，显示出优越的有效性和鲁棒性。在BRIGHT基准测试中，ERank-4B实现了nDCG@10为38.7，而更大的32B变体达到了最先进的nDCG@10为40.2。

Conclusion: ERank在多个基准测试中表现出色，相比现有方法具有更高的有效性和鲁棒性。在需要推理的BRIGHT基准测试中，ERank-4B实现了nDCG@10为38.7，而更大的32B变体达到了最先进的nDCG@10为40.2。

Abstract: Text reranking models are a crucial component in modern systems like
Retrieval-Augmented Generation, tasked with selecting the most relevant
documents prior to generation. However, current Large Language Models (LLMs)
powered rerankers often face a fundamental trade-off. On one hand, Supervised
Fine-Tuning based pointwise methods that frame relevance as a binary
classification task lack the necessary scoring discrimination, particularly for
those built on reasoning LLMs. On the other hand, approaches designed for
complex reasoning often employ powerful yet inefficient listwise formulations,
rendering them impractical for low latency applications. To resolve this
dilemma, we introduce ERank, a highly effective and efficient pointwise
reranker built from a reasoning LLM that excels across diverse relevance
scenarios. We propose a novel two-stage training pipeline that begins with
Supervised Fine-Tuning (SFT). In this stage, we move beyond binary labels and
train the model generatively to output fine grained integer scores, which
significantly enhances relevance discrimination. The model is then further
refined using Reinforcement Learning (RL) with a novel, listwise derived
reward. This technique instills global ranking awareness into the efficient
pointwise architecture. We evaluate the ERank reranker on the BRIGHT, FollowIR,
TREC DL, and BEIR benchmarks, demonstrating superior effectiveness and
robustness compared to existing approaches. On the reasoning-intensive BRIGHT
benchmark, our ERank-4B achieves an nDCG@10 of 38.7, while a larger 32B variant
reaches a state of the art nDCG@10 of 40.2.

</details>


### [154] [CSRM-LLM: Embracing Multilingual LLMs for Cold-Start Relevance Matching in Emerging E-commerce Markets](https://arxiv.org/abs/2509.01566)
*Yujing Wang,Yiren Chen,Huoran Li,Chunxu Xu,Yuchong Luo,Xianghui Mao,Cong Li,Lun Du,Chunyang Ma,Qiqi Jiang,Yin Wang,Fan Gao,Wenting Mo,Pei Wen,Shantanu Kumar,Taejin Park,Yiwei Song,Vijay Rajaram,Tao Cheng,Sonu Durgia,Pranam Kolari*

Main category: cs.IR

TL;DR: 本文介绍了一种名为CSRM的冷启动相关性匹配框架，使用多语言大型语言模型解决冷启动问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着全球电子商务平台的扩展，公司进入新市场时会遇到由于有限的人类标签和用户行为而产生的冷启动挑战。

Method: 提出了一种冷启动相关性匹配(CSRM)框架，利用多语言大型语言模型(MLLM)解决三个挑战：通过机器翻译任务激活LLM的跨语言迁移学习能力；通过基于检索的查询增强来提高查询理解和融入电子商务知识；通过多轮自蒸馏训练策略减轻训练标签错误的影响。

Result: 实验表明CSRM-LLM和所提出的技术有效，成功实现了现实世界的部署，并带来了显著的在线收益，缺陷率降低了45.8%，会话购买率提升了0.866%。

Conclusion: CSRM-LLM框架和提出的技术在实验中表现出色，成功实现了现实世界的部署，并带来了显著的在线收益。

Abstract: As global e-commerce platforms continue to expand, companies are entering new
markets where they encounter cold-start challenges due to limited human labels
and user behaviors. In this paper, we share our experiences in Coupang to
provide a competitive cold-start performance of relevance matching for emerging
e-commerce markets. Specifically, we present a Cold-Start Relevance Matching
(CSRM) framework, utilizing a multilingual Large Language Model (LLM) to
address three challenges: (1) activating cross-lingual transfer learning
abilities of LLMs through machine translation tasks; (2) enhancing query
understanding and incorporating e-commerce knowledge by retrieval-based query
augmentation; (3) mitigating the impact of training label errors through a
multi-round self-distillation training strategy. Our experiments demonstrate
the effectiveness of CSRM-LLM and the proposed techniques, resulting in
successful real-world deployment and significant online gains, with a 45.8%
reduction in defect ratio and a 0.866% uplift in session purchase rate.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [155] [Chronotome: Real-Time Topic Modeling for Streaming Embedding Spaces](https://arxiv.org/abs/2509.01051)
*Matte Lim,Catherine Yeh,Martin Wattenberg,Fernanda Viégas,Panagiotis Michalatos*

Main category: cs.HC

TL;DR: 本文介绍了一种结合力导向投影和流式聚类的新可视化技术，用于捕捉时间变化的数据集中的语义变化，并展示了其在文本和图像数据上的应用价值。


<details>
  <summary>Details</summary>
Motivation: 现有的降维方法难以捕捉时间变化的数据集中的语义变化，因此需要一种新的方法来解决这个问题。

Method: 结合了力导向投影和流式聚类方法，构建了嵌入的空间-时间图。

Result: 开发了Chronotome工具，用于实时交互探索基于时间的数据中的演变主题。

Conclusion: 本文提出了一种新的可视化技术，可以更好地捕捉时间变化的数据集中的语义变化，并展示了其在文本和图像数据上的应用价值。

Abstract: Many real-world datasets -- from an artist's body of work to a person's
social media history -- exhibit meaningful semantic changes over time that are
difficult to capture with existing dimensionality reduction methods. To address
this gap, we introduce a visualization technique that combines force-based
projection and streaming clustering methods to build a spatial-temporal map of
embeddings. Applying this technique, we create Chronotome, a tool for
interactively exploring evolving themes in time-based data -- in real time. We
demonstrate the utility of our approach through use cases on text and image
data, showing how it offers a new lens for understanding the aesthetics and
semantics of temporal datasets.

</details>


### [156] [E-THER: A PCT-Grounded Dataset for Benchmarking Empathic AI](https://arxiv.org/abs/2509.02100)
*Sharjeel Tahir,Judith Johnson,Jumana Abu-Khalaf,Syed Afaq Ali Shah*

Main category: cs.HC

TL;DR: 本文介绍了E-THER数据集，这是一个基于以人为中心的疗法的多模态数据集，具有多维注释，用于检测言语和视觉不一致，从而训练能够发展真实而非表演性同理心能力的AI系统。使用基于同理心和治疗原则的评估指标，在最先进的视觉语言模型（如IDEFICS和VideoLLAVA）中观察到了显著的同理心和治疗对话质量提升。实证结果表明，我们的不一致训练模型在关键特性上优于通用模型，如维持治疗参与度、减少人工或夸张的语言模式以及保持PCT理论框架的一致性。


<details>
  <summary>Details</summary>
Motivation: A prevalent shortfall among current empathic AI systems is their inability to recognize when verbal expressions may not fully reflect underlying emotional states. This is because the existing datasets, used for the training of these systems, focus on surface-level emotion recognition without addressing the complex verbal-visual incongruence (mismatch) patterns useful for empathic understanding.

Method: We present E-THER, the first Person-Centered Therapy-grounded multimodal dataset with multidimensional annotations for verbal-visual incongruence detection, enabling training of AI systems that develop genuine rather than performative empathic capabilities.

Result: Notable gains in empathic and therapeutic conversational qualities are observed in state-of-the-art vision-language models (VLMs), such as IDEFICS and VideoLLAVA, using evaluation metrics grounded in empathic and therapeutic principles.

Conclusion: Empirical findings indicate that our incongruence-trained models outperform general-purpose models in critical traits, such as sustaining therapeutic engagement, minimizing artificial or exaggerated linguistic patterns, and maintaining fidelity to PCT theoretical framework.

Abstract: A prevalent shortfall among current empathic AI systems is their inability to
recognize when verbal expressions may not fully reflect underlying emotional
states. This is because the existing datasets, used for the training of these
systems, focus on surface-level emotion recognition without addressing the
complex verbal-visual incongruence (mismatch) patterns useful for empathic
understanding. In this paper, we present E-THER, the first Person-Centered
Therapy-grounded multimodal dataset with multidimensional annotations for
verbal-visual incongruence detection, enabling training of AI systems that
develop genuine rather than performative empathic capabilities. The annotations
included in the dataset are drawn from humanistic approach, i.e., identifying
verbal-visual emotional misalignment in client-counsellor interactions -
forming a framework for training and evaluating AI on empathy tasks. Additional
engagement scores provide behavioral annotations for research applications.
Notable gains in empathic and therapeutic conversational qualities are observed
in state-of-the-art vision-language models (VLMs), such as IDEFICS and
VideoLLAVA, using evaluation metrics grounded in empathic and therapeutic
principles. Empirical findings indicate that our incongruence-trained models
outperform general-purpose models in critical traits, such as sustaining
therapeutic engagement, minimizing artificial or exaggerated linguistic
patterns, and maintaining fidelity to PCT theoretical framework.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [157] [Do Video Language Models Really Know Where to Look? Diagnosing Attention Failures in Video Language Models](https://arxiv.org/abs/2509.01167)
*Hyunjong Ok,Jaeho Lee*

Main category: cs.CV

TL;DR: 我们的研究发现，现有的视觉编码器在识别视频中MLLM应关注的位置方面存在局限，这可能影响视频MLLMs的效率。


<details>
  <summary>Details</summary>
Motivation: 最近的多模态大语言模型（MLLMs）在视频理解任务中取得了很大进展。为了避免处理所有帧的高昂计算成本，这些模型通常依赖于由视觉-语言编码器引导的关键帧采样方法。然而，尚不清楚这些编码器是否真的能识别出最信息丰富的帧。

Method: 我们提供了几个实证证据，揭示了流行的视觉编码器在识别MLLM应该在视频中查看哪里以适当处理给定的文本查询方面存在严重的能力限制。

Result: 我们的研究结果表明，流行的视觉编码器在识别MLLM应该在视频中查看哪里以适当处理给定的文本查询方面存在严重的能力限制。

Conclusion: 我们的研究结果表明，开发更好的关键帧识别技术对于高效的视频MLLMs可能是必要的。

Abstract: Recent advances in multimodal large language models (MLLMs) have led to much
progress in video understanding tasks. To avoid the heavy computational cost of
processing all frames, these models typically rely on keyframe sampling methods
guided by vision-language encoders (\textit{e.g.,} SigLIP). However, it remains
unclear whether such encoders can truly identify the most informative frames.
In this work, we provide several empirical pieces of evidence revealing that
popular vision encoders critically suffer from their limited capability to
identify where the MLLM should look inside the video to handle the given
textual query appropriately. Our findings suggest that the development of
better keyframe identification techniques may be necessary for efficient video
MLLMs.

</details>


### [158] [Reinforced Visual Perception with Tools](https://arxiv.org/abs/2509.01656)
*Zetong Zhou,Dongping Chen,Zixian Ma,Zhihan Hu,Mingyang Fu,Sinan Wang,Yao Wan,Zhou Zhao,Ranjay Krishna*

Main category: cs.CV

TL;DR: 本文提出了ReVPT方法，利用强化学习提升多模态大语言模型的视觉推理能力，并在多个基准测试中取得了先进成果。


<details>
  <summary>Details</summary>
Motivation: 现有的监督微调方法在数据生成成本、数据筛选依赖性和泛化能力方面存在局限，因此需要一种更有效的解决方案来提升多模态大语言模型的视觉推理能力。

Method: 提出了一种基于GRPO的新型强化学习算法，用于训练模型使用一组四个视觉工具进行推理。

Result: 在SAT、CV-Bench、BLINK和MMStar等多个感知密集型基准测试中，ReVPT方法表现优异，显著优于监督微调和基于文本的强化学习微调基线。ReVPT-3B和ReVPT-7B在CV-Bench上分别优于指令模型9.03%和9.44%。

Conclusion: ReVPT通过强化学习提升了多模态大语言模型在视觉工具使用方面的能力，并在多个感知密集型基准测试中取得了最先进的性能。

Abstract: Visual reasoning, a cornerstone of human intelligence, encompasses complex
perceptual and logical processes essential for solving diverse visual problems.
While advances in computer vision have produced powerful models for various
perceptual tasks, leveraging these for general visual reasoning remains
challenging. Prior work demonstrates that augmenting LLMs with vision models
via supervised finetuning improves performance, but faces key limitations such
as expensive data generation, reliance on careful data filtering, and poor
generalization. To address these issues, we propose ReVPT to enhance
multi-modal LLMs' abilities to reason about and use visual tools through
reinforcement learning. We introduce a novel RL algorithm based on GRPO,
designed to train models to reason with a suite of four visual tools. Through
extensive experiments, we show that our method achieves state-of-the-art
performance on several perception-heavy benchmarks, including SAT, CV-Bench,
BLINK and MMStar, significantly outperforming the supervised and text-based RL
finetuning baselines. Notably, Our ReVPT-3B and ReVPT-7B outperform the
instruct models by 9.03% and 9.44% on CV-Bench. Finally, we bring to the
community new insights on RL-based visual tool-usage through extensive
ablations. Our code is available at https://github.com/ls-kelvin/REVPT.

</details>


### [159] [RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events](https://arxiv.org/abs/2509.01907)
*Zhenyuan Chen,Chenxi Wang,Ningyu Zhang,Feng Zhang*

Main category: cs.CV

TL;DR: 本文介绍了RSCC数据集，这是一个大规模基准数据集，包含62,315对灾前/灾后图像对，并配有丰富的、类似人类的变更描述。该数据集有助于训练和评估用于灾害感知双时间理解的视觉-语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有遥感数据集缺乏时间图像对和详细的文本注释，单张快照图像无法捕捉随时间变化的灾害影响。

Method: 引入了RSCC数据集，包含多种灾害类型的灾前/灾后图像对，并配有详细的人类-like变更描述。

Result: RSCC数据集能够促进详细的灾害相关分析，为遥感中的更准确、可解释和可扩展的视觉-语言应用铺平道路。

Conclusion: RSCC数据集有助于训练和评估用于灾害感知双时间理解的视觉-语言模型。

Abstract: Remote sensing is critical for disaster monitoring, yet existing datasets
lack temporal image pairs and detailed textual annotations. While
single-snapshot imagery dominates current resources, it fails to capture
dynamic disaster impacts over time. To address this gap, we introduce the
Remote Sensing Change Caption (RSCC) dataset, a large-scale benchmark
comprising 62,315 pre-/post-disaster image pairs (spanning earthquakes, floods,
wildfires, and more) paired with rich, human-like change captions. By bridging
the temporal and semantic divide in remote sensing data, RSCC enables robust
training and evaluation of vision-language models for disaster-aware
bi-temporal understanding. Our results highlight RSCC's ability to facilitate
detailed disaster-related analysis, paving the way for more accurate,
interpretable, and scalable vision-language applications in remote sensing.
Code and dataset are available at https://github.com/Bili-Sakura/RSCC.

</details>


### [160] [Understanding Space Is Rocket Science - Only Top Reasoning Models Can Solve Spatial Understanding Tasks](https://arxiv.org/abs/2509.02175)
*Nils Hoehing,Mayug Maniparambil,Ellen Rushe,Noel E. O'Connor,Anthony Ventresque*

Main category: cs.CV

TL;DR: RocketScience是一个用于测试空间关系理解的开源对比视觉语言模型基准测试，结果显示当前模型在这一领域存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言模型在空间关系理解方面存在不足，需要一个专门的基准测试来评估这一能力。

Method: 我们提出了RocketScience，这是一个开源的对比视觉语言模型基准测试，用于测试空间关系理解。该基准测试由全新的真实世界图像-文本对组成，主要涵盖相对空间理解和对象顺序。

Result: 我们的结果表明，开源和前沿商业的视觉语言模型在空间关系理解方面表现不佳，而推理模型表现优异。解耦分析显示，性能瓶颈在于空间推理而非对象定位能力。

Conclusion: 我们的结果表明，开源和前沿商业的视觉语言模型在空间关系理解方面存在显著不足，而推理模型表现出令人惊讶的高性能。此外，我们进行了解耦分析，发现该基准测试的性能受限于空间推理而非对象定位能力。

Abstract: We propose RocketScience, an open-source contrastive VLM benchmark that tests
for spatial relation understanding. It is comprised of entirely new real-world
image-text pairs covering mostly relative spatial understanding and the order
of objects. The benchmark is designed
  to be very easy for humans and hard for the current generation of VLMs, and
this is empirically verified. Our results show a striking lack of spatial
relation understanding in open source and frontier commercial VLMs and a
surprisingly high performance of reasoning models. Additionally, we perform a
disentanglement analysis to separate the contributions of object localization
and spatial reasoning in chain-of-thought-based models and find that the
performance on the benchmark is bottlenecked by spatial reasoning and not
object localization capabilities.
  We release the dataset with a CC-BY-4.0 license and make the evaluation code
available at: https://github.com/nilshoehing/rocketscience

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [161] [Amplifying Emotional Signals: Data-Efficient Deep Learning for Robust Speech Emotion Recognition](https://arxiv.org/abs/2509.00077)
*Tai Vu*

Main category: eess.AS

TL;DR: 本文研究了如何通过迁移学习和创新的数据增强技术，在有限的数据集上实现高效的语音情感识别，并展示了ResNet34模型在RAVDESS和SAVEE数据集上的优越性能。


<details>
  <summary>Details</summary>
Motivation: 语音情感识别（SER）在人机交互中是一个重要但持续的挑战。尽管深度学习已经推进了口语处理，但在有限的数据集上实现高性能仍然是一个关键障碍。

Method: 本文通过开发和评估一系列机器学习模型，包括支持向量机（SVMs）、长短期记忆网络（LSTMs）和卷积神经网络（CNNs），以实现人类语音中的自动情绪分类。

Result: 我们的最有效模型，即ResNet34架构，在结合的RAVDESS和SAVEE数据集上建立了新的性能基准，达到了66.7%的准确率和0.631的F1分数。

Conclusion: 这些结果强调了利用预训练模型和数据增强来克服数据稀缺性的显著好处，从而为更强大和通用的SER系统铺平了道路。

Abstract: Speech Emotion Recognition (SER) presents a significant yet persistent
challenge in human-computer interaction. While deep learning has advanced
spoken language processing, achieving high performance on limited datasets
remains a critical hurdle. This paper confronts this issue by developing and
evaluating a suite of machine learning models, including Support Vector
Machines (SVMs), Long Short-Term Memory networks (LSTMs), and Convolutional
Neural Networks (CNNs), for automated emotion classification in human speech.
We demonstrate that by strategically employing transfer learning and innovative
data augmentation techniques, our models can achieve impressive performance
despite the constraints of a relatively small dataset. Our most effective
model, a ResNet34 architecture, establishes a new performance benchmark on the
combined RAVDESS and SAVEE datasets, attaining an accuracy of 66.7% and an F1
score of 0.631. These results underscore the substantial benefits of leveraging
pre-trained models and data augmentation to overcome data scarcity, thereby
paving the way for more robust and generalizable SER systems.

</details>


### [162] [ChipChat: Low-Latency Cascaded Conversational Agent in MLX](https://arxiv.org/abs/2509.00078)
*Tatiana Likhomanenko,Luke Carlson,Richard He Bai,Zijin Gu,Han Tran,Zakaria Aldeneh,Yizhe Zhang,Ruixiang Zhang,Huangjie Zheng,Navdeep Jaitly*

Main category: eess.AS

TL;DR: 本文介绍了ChipChat，一种新型低延迟级联系统，通过架构创新和流优化克服了传统瓶颈。该系统在Mac Studio上实现了亚秒级响应延迟，同时保持用户隐私。研究表明，经过战略性重新设计的级联系统可以克服其历史上的延迟限制，为基于语音的AI代理提供有希望的前进路径。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的出现改变了语音对话系统，但实时设备端语音代理的最佳架构仍然是一个开放问题。虽然端到端方法理论上具有优势，但级联系统（CSs）在语言理解任务中仍然表现优于它们，尽管受到顺序处理延迟的限制。

Method: 我们引入了ChipChat，这是一种通过架构创新和流优化克服传统瓶颈的新颖低延迟CS。系统集成了流式（a）对话语音识别与专家混合，（b）状态-动作增强LLM，（c）文本到语音合成，（d）神经声码器，以及（e）说话人建模。

Result: ChipChat在Mac Studio上实现了亚秒级响应延迟，而无需专用GPU，并通过完整的设备端处理保护用户隐私。

Conclusion: 我们的工作表明，经过战略性重新设计的CS可以克服其历史上的延迟限制，为基于语音的AI代理提供有希望的前进路径。

Abstract: The emergence of large language models (LLMs) has transformed spoken dialog
systems, yet the optimal architecture for real-time on-device voice agents
remains an open question. While end-to-end approaches promise theoretical
advantages, cascaded systems (CSs) continue to outperform them in language
understanding tasks, despite being constrained by sequential processing
latency. In this work, we introduce ChipChat, a novel low-latency CS that
overcomes traditional bottlenecks through architectural innovations and
streaming optimizations. Our system integrates streaming (a) conversational
speech recognition with mixture-of-experts, (b) state-action augmented LLM, (c)
text-to-speech synthesis, (d) neural vocoder, and (e) speaker modeling.
Implemented using MLX, ChipChat achieves sub-second response latency on a Mac
Studio without dedicated GPUs, while preserving user privacy through complete
on-device processing. Our work shows that strategically redesigned CSs can
overcome their historical latency limitations, offering a promising path
forward for practical voice-based AI agents.

</details>


### [163] [Automatic Pronunciation Error Detection and Correction of the Holy Quran's Learners Using Deep Learning](https://arxiv.org/abs/2509.00094)
*Abdullah Abdelfattah,Mahmoud I. Khalil,Hazem Abbas*

Main category: eess.AS

TL;DR: 本文提出了一种自动化生成《古兰经》数据集的方法，并引入了基于ASR的发音错误检测技术，取得了显著的成果。


<details>
  <summary>Details</summary>
Motivation: 尽管《古兰经》有严格的朗诵规则，但高质量的注释数据仍然稀缺，这限制了机器学习模型的性能。因此，本文旨在解决这一问题，提供一种高效的数据集生成和发音评估方法。

Method: 本文提出了一个98%自动化的数据集生成管道，包括从专家朗诵者收集朗诵、使用微调的wav2vec2-BERT模型进行暂停点分割、段落转录以及通过Tasmeea算法进行转录验证。此外，还引入了一种基于ASR的发音错误检测方法，利用自定义的QPS脚本编码塔吉维德规则。

Result: 本文生成了850小时以上的音频数据（约30万条注释语音），并提出了一种多级CTC模型，在测试集上实现了0.16%的平均音素错误率（PER）。

Conclusion: 本文介绍了用于评估《古兰经》发音的自动化数据集生成管道和基于ASR的发音错误检测方法，展示了其在实际应用中的有效性，并开放了所有代码、数据和模型。

Abstract: Assessing spoken language is challenging, and quantifying pronunciation
metrics for machine learning models is even harder. However, for the Holy
Quran, this task is simplified by the rigorous recitation rules (tajweed)
established by Muslim scholars, enabling highly effective assessment. Despite
this advantage, the scarcity of high-quality annotated data remains a
significant barrier.
  In this work, we bridge these gaps by introducing: (1) A 98% automated
pipeline to produce high-quality Quranic datasets -- encompassing: Collection
of recitations from expert reciters, Segmentation at pause points (waqf) using
our fine-tuned wav2vec2-BERT model, Transcription of segments, Transcript
verification via our novel Tasmeea algorithm; (2) 850+ hours of audio (~300K
annotated utterances); (3) A novel ASR-based approach for pronunciation error
detection, utilizing our custom Quran Phonetic Script (QPS) to encode Tajweed
rules (unlike the IPA standard for Modern Standard Arabic). QPS uses a
two-level script: (Phoneme level): Encodes Arabic letters with short/long
vowels. (Sifa level): Encodes articulation characteristics of every phoneme. We
further include comprehensive modeling with our novel multi-level CTC Model
which achieved 0.16% average Phoneme Error Rate (PER) on the testset. We
release all code, data, and models as open-source:
https://obadx.github.io/prepare-quran-dataset/

</details>


### [164] [MixedG2P-T5: G2P-free Speech Synthesis for Mixed-script texts using Speech Self-Supervised Learning and Language Model](https://arxiv.org/abs/2509.01391)
*Joonyong Park,Daisuke Saito,Nobuaki Minematsu*

Main category: eess.AS

TL;DR: 该研究提出了一种新的语音合成方法，可以替代传统的图素到音素（G2P）转换，通过使用深度学习模型直接从语音生成离散标记。这种方法消除了手动语音转录的需要，降低了成本并提高了可扩展性，特别是在大规模未转录的音频数据集上。模型性能与传统基于G2P的文本到语音系统相当，并且能够合成保留自然语言和副语言特征的语音，如口音和语调。


<details>
  <summary>Details</summary>
Motivation: 传统语音合成方法依赖于手动语音转录，这既耗时又昂贵。为了解决这个问题，该研究提出了一种基于深度学习的方法，可以直接从语音生成离散标记，从而消除对手动语音转录的需求。

Method: 该研究利用预训练的语音SSL模型，训练T5编码器从混合脚本文本（例如包含汉字和假名的文本）生成伪语言标签。

Result: 该研究的模型在性能上与传统基于G2P的文本到语音系统相当，并且能够合成保留自然语言和副语言特征的语音，如口音和语调。

Conclusion: 该研究提出了一种新的语音合成方法，可以替代传统的图素到音素（G2P）转换，通过使用深度学习模型直接从语音生成离散标记。这种方法消除了手动语音转录的需要，降低了成本并提高了可扩展性，特别是在大规模未转录的音频数据集上。模型性能与传统基于G2P的文本到语音系统相当，并且能够合成保留自然语言和副语言特征的语音，如口音和语调。

Abstract: This study presents a novel approach to voice synthesis that can substitute
the traditional grapheme-to-phoneme (G2P) conversion by using a deep
learning-based model that generates discrete tokens directly from speech.
Utilizing a pre-trained voice SSL model, we train a T5 encoder to produce
pseudo-language labels from mixed-script texts (e.g., containing Kanji and
Kana). This method eliminates the need for manual phonetic transcription,
reducing costs and enhancing scalability, especially for large non-transcribed
audio datasets. Our model matches the performance of conventional G2P-based
text-to-speech systems and is capable of synthesizing speech that retains
natural linguistic and paralinguistic features, such as accents and
intonations.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [165] [Traj-MLLM: Can Multimodal Large Language Models Reform Trajectory Data Mining?](https://arxiv.org/abs/2509.00053)
*Shuo Liu,Di Yao,Yan Lin,Gao Cong,Jingping Bi*

Main category: cs.MM

TL;DR: 本文提出了Traj-MLLM，这是第一个使用MLLM进行轨迹数据分析的通用框架。通过整合多视图上下文，Traj-MLLM将原始轨迹转换为交错的图像-文本序列，并直接利用MLLM的推理能力进行轨迹分析。实验结果表明，Traj-MLLM在多个任务上表现出色，且无需任何训练数据或微调MLLM骨干。


<details>
  <summary>Details</summary>
Motivation: 现有工作存在泛化问题，即它们要么仅限于特定区域的训练，要么仅适用于少数任务。因此，需要一种能够跨不同地理区域和任务分析人类轨迹的通用模型。

Method: Traj-MLLM通过整合多视图上下文，将原始轨迹转换为交错的图像-文本序列，并直接利用MLLM的推理能力进行轨迹分析。此外，提出了一种提示优化方法，以最终确定任务适应的数据无关提示。

Result: Traj-MLLM在四个公开数据集上的实验表明，它在旅行时间估计、移动性预测、异常检测和交通模式识别方面分别优于最先进的基线48.05%、15.52%、51.52%和1.83%。

Conclusion: Traj-MLLM在不需要任何训练数据或微调MLLM骨干的情况下，实现了优越的性能。

Abstract: Building a general model capable of analyzing human trajectories across
different geographic regions and different tasks becomes an emergent yet
important problem for various applications. However, existing works suffer from
the generalization problem, \ie, they are either restricted to train for
specific regions or only suitable for a few tasks. Given the recent advances of
multimodal large language models (MLLMs), we raise the question: can MLLMs
reform current trajectory data mining and solve the problem? Nevertheless, due
to the modality gap of trajectory, how to generate task-independent multimodal
trajectory representations and how to adapt flexibly to different tasks remain
the foundational challenges. In this paper, we propose \texttt{Traj-MLLM}},
which is the first general framework using MLLMs for trajectory data mining. By
integrating multiview contexts, \texttt{Traj-MLLM}} transforms raw trajectories
into interleaved image-text sequences while preserving key spatial-temporal
characteristics, and directly utilizes the reasoning ability of MLLMs for
trajectory analysis. Additionally, a prompt optimization method is proposed to
finalize data-invariant prompts for task adaptation. Extensive experiments on
four publicly available datasets show that \texttt{Traj-MLLM}} outperforms
state-of-the-art baselines by $48.05\%$, $15.52\%$, $51.52\%$, $1.83\%$ on
travel time estimation, mobility prediction, anomaly detection and
transportation mode identification, respectively. \texttt{Traj-MLLM}} achieves
these superior performances without requiring any training data or fine-tuning
the MLLM backbones.

</details>


### [166] [LLM-Guided Semantic Relational Reasoning for Multimodal Intent Recognition](https://arxiv.org/abs/2509.01337)
*Qianrui Zhou,Hua Xu,Yifan Wang,Xinzhi Dong,Hanlei Zhang*

Main category: cs.MM

TL;DR: 本文提出了一种基于大型语言模型的语义关系推理方法（LGSRR），用于从多模态信号中理解人类意图，该方法通过利用大型语言模型的广泛知识来增强小模型的关系推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在模态层面的依赖性限制了对细粒度语义的关系推理，从而影响了复杂意图的理解。

Method: 提出了一种基于LLM的策略，以提取细粒度语义作为后续推理的指导，通过浅到深的思维链（CoT）自主发现、描述和按重要性排序语义线索，而无需依赖手动定义的先验知识。此外，我们正式建模了三种基于逻辑原理的基本语义关系，并分析了它们的细微相互作用，以实现更有效的关系推理。

Result: LGSRR在多模态意图和对话动作识别任务中表现出优越性，并在各种语义理解场景中表现出一致的性能提升。

Conclusion: LGSRR在多模态意图和对话动作识别任务中表现出色，优于最先进的方法，并在各种语义理解场景中表现出一致的性能提升。

Abstract: Understanding human intents from multimodal signals is critical for analyzing
human behaviors and enhancing human-machine interactions in real-world
scenarios. However, existing methods exhibit limitations in their
modality-level reliance, constraining relational reasoning over fine-grained
semantics for complex intent understanding. This paper proposes a novel
LLM-Guided Semantic Relational Reasoning (LGSRR) method, which harnesses the
expansive knowledge of large language models (LLMs) to establish semantic
foundations that boost smaller models' relational reasoning performance.
Specifically, an LLM-based strategy is proposed to extract fine-grained
semantics as guidance for subsequent reasoning, driven by a shallow-to-deep
Chain-of-Thought (CoT) that autonomously uncovers, describes, and ranks
semantic cues by their importance without relying on manually defined priors.
Besides, we formally model three fundamental types of semantic relations
grounded in logical principles and analyze their nuanced interplay to enable
more effective relational reasoning. Extensive experiments on multimodal intent
and dialogue act recognition tasks demonstrate LGSRR's superiority over
state-of-the-art methods, with consistent performance gains across diverse
semantic understanding scenarios. The complete data and code are available at
https://github.com/thuiar/LGSRR.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [167] [Content and Engagement Trends in COVID-19 YouTube Videos: Evidence from the Late Pandemic](https://arxiv.org/abs/2509.01954)
*Nirmalya Thakur,Madeline D Hartel,Lane Michael Boden,Dallas Enriquez,Boston Joyner Ricks*

Main category: cs.SI

TL;DR: 本研究分析了2023年1月至2024年10月期间发布的约10,000个与新冠相关的YouTube视频，发现发布时间、标题词汇、主题和视频类型对参与度有显著影响。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在评估时间、词汇、语言和结构因素如何影响疫情后期YouTube上新冠相关视频的参与度。

Method: 本研究分析了2023年1月至2024年10月期间发布的约10,000个与新冠相关的YouTube视频，评估了时间、词汇、语言和结构因素如何影响后期疫情时期的参与度。

Result: 发布活动显示出一致的星期几效应：在第一个窗口中，平均观看次数在周一达到峰值；在第二个窗口中，平均观看次数在周三达到峰值；在第三个窗口中，平均观看次数在周五达到峰值。视频标题的词汇分析揭示了与新冠和YouTube功能相关的高频关键词。视频描述的情感分析显示与观看次数的相关性较弱，但去除异常值后相关性增强。不同类别的视频时长分析显示了不同的结果。

Conclusion: 这些结果表明，在疫情后期，YouTube上与新冠相关的视频的参与模式具有由发布时间表、标题词汇、主题和特定类型的持续时间效应驱动的显著特征。

Abstract: This work investigated about 10,000 COVID-19-related YouTube videos published
between January 2023 and October 2024 to evaluate how temporal, lexical,
linguistic, and structural factors influenced engagement during the late
pandemic period. Publishing activity showed consistent weekday effects: in the
first window, average views peaked on Mondays at 92,658; in the second, on
Wednesdays at 115,479; and in the third, on Fridays at 84,874, reflecting a
shift in audience attention toward mid- and late week. Lexical analysis of
video titles revealed recurring high-frequency keywords related to COVID-19 and
YouTube features, including COVID, coronavirus, shorts, and live. Frequency
analysis revealed sharp spikes, with COVID appearing in 799 video titles in
August 2024, while engagement analysis showed that videos titled with shorts
attracted very high views, peaking at 2.16 million average views per video in
June 2023. Analysis of sentiment of video descriptions in English showed weak
correlation with views in the raw data (Pearson r = 0.0154, p = 0.2987), but
stronger correlations emerged once outliers were addressed, with Spearman r =
0.110 (p < 0.001) and Pearson r = 0.0925 (p < 0.001). Category-level analysis
of video durations revealed contrasting outcomes: long videos focusing on
people and blogs averaged 209,114 views, short entertainment videos averaged
288,675 views, and medium-to-long news and politics videos averaged 51,309 and
59,226 views, respectively. These results demonstrate that engagement patterns
of COVID-19-related videos on YouTube during the late pandemic followed
distinct characteristics driven by publishing schedules, title vocabulary,
topics, and genre-specific duration effects.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [168] [Language and Experience: A Computational Model of Social Learning in Complex Tasks](https://arxiv.org/abs/2509.00074)
*Cédric Colas,Tracey Mills,Ben Prystawski,Michael Henry Tessler,Noah Goodman,Jacob Andreas,Joshua Tenenbaum*

Main category: cs.AI

TL;DR: 本文提出了一种计算框架，用于建模社会学习，并通过实验展示了语言指导如何促进学习和知识积累，揭示了结构化、语言兼容表示在人类-机器协作学习中的潜力。


<details>
  <summary>Details</summary>
Motivation: 了解人们如何整合这两种知识来源，并探索AI系统如何做到这一点，对于开发更安全和快速适应新环境的AI系统至关重要。

Method: 本文提出了一种计算框架，将社会学习建模为在给定感觉运动和语言数据的情况下对结构化、可执行世界模型进行联合概率推断。通过将预训练语言模型转化为人类分享建议的条件概率模型，使代理既能为他人生成建议，又能在贝叶斯推理中将语言输入视为证据。

Result: 通过行为实验和10个视频游戏的模拟，我们展示了语言指导如何塑造探索并加速学习，同时展示了知识如何通过迭代学习实验跨代积累，并实现了人类和模型之间的成功知识转移。

Conclusion: 本文展示了语言指导如何通过减少风险互动和加速关键发现来促进人类和模型的学习，并探索了通过迭代学习实验知识如何跨代积累，以及人类和模型之间的成功知识转移，揭示了结构化、语言兼容表示可能使人类-机器协作学习成为可能。

Abstract: The ability to combine linguistic guidance from others with direct experience
is central to human development, enabling safe and rapid learning in new
environments. How do people integrate these two sources of knowledge, and how
might AI systems? We present a computational framework that models social
learning as joint probabilistic inference over structured, executable world
models given sensorimotor and linguistic data. We make this possible by turning
a pretrained language model into a probabilistic model of how humans share
advice conditioned on their beliefs, allowing our agents both to generate
advice for others and to interpret linguistic input as evidence during Bayesian
inference. Using behavioral experiments and simulations across 10 video games,
we show how linguistic guidance can shape exploration and accelerate learning
by reducing risky interactions and speeding up key discoveries in both humans
and models. We further explore how knowledge can accumulate across generations
through iterated learning experiments and demonstrate successful knowledge
transfer between humans and models -- revealing how structured,
language-compatible representations might enable human-machine collaborative
learning.

</details>


### [169] [Ensemble Debates with Local Large Language Models for AI Alignment](https://arxiv.org/abs/2509.00091)
*Ephraiem Sarabamoun*

Main category: cs.AI

TL;DR: 研究发现本地开源集成辩论可以改善大型语言模型与人类价值观的对齐，并提供了可重复使用的资源。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在高风险决策中扮演越来越重要的角色，与人类价值观对齐变得至关重要。然而，依赖专有API限制了可重复性和广泛参与。

Method: 研究通过150场辩论，涵盖15个场景和五个集成配置，比较了集成模型与单模型基线的表现。

Result: 集成模型在7分评分表上表现优于单模型基线（总体：3.48 vs. 3.13），在推理深度和论点质量方面提升最大，分别提高了19.4%和34.1%。改进在真实性（+1.25分）和人类增强（+0.80分）方面最为显著。

Conclusion: 研究显示，本地开源集成辩论可以提高与人类价值观对齐的推理能力，并提供了代码、提示和辩论数据集，以提供可访问和可重复的基础用于基于集成的对齐评估。

Abstract: As large language models (LLMs) take on greater roles in high-stakes
decisions, alignment with human values is essential. Reliance on proprietary
APIs limits reproducibility and broad participation. We study whether local
open-source ensemble debates can improve alignmentoriented reasoning. Across
150 debates spanning 15 scenarios and five ensemble configurations, ensembles
outperform single-model baselines on a 7-point rubric (overall: 3.48 vs. 3.13),
with the largest gains in reasoning depth (+19.4%) and argument quality
(+34.1%). Improvements are strongest for truthfulness (+1.25 points) and human
enhancement (+0.80). We provide code, prompts, and a debate data set, providing
an accessible and reproducible foundation for ensemble-based alignment
evaluation.

</details>


### [170] [Adaptive Monitoring and Real-World Evaluation of Agentic AI Systems](https://arxiv.org/abs/2509.00115)
*Manish Shukla*

Main category: cs.AI

TL;DR: 本文提出了一种自适应多维监控算法（AMDM），用于改进多智能体系统的异常检测性能，并强调了在评估中考虑更多维度的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前技术指标在评估中仍然占主导地位，而以人为本或经济维度的考虑较少。因此，需要一种更全面的评估方法来改进多智能体系统的安全性与可靠性。

Method: 本文提出了自适应多维监控（AMDM）算法，该算法对异构指标进行归一化处理，应用每轴指数加权移动平均阈值，并通过马氏距离进行联合异常检测。

Result: AMDM将模拟目标漂移的异常检测延迟从12.3秒减少到5.6秒，并将误报率从4.5%降低到0.9%。此外，还提供了比较表、ROC/PR曲线以及重新分析的案例研究以揭示缺失的指标。

Conclusion: 本文提出了一个自适应多维监控算法（AMDM），并在模拟和真实实验中验证了其有效性。结果表明，AMDM能够显著降低异常检测延迟和误报率，并强调了在评估中考虑以人为本或经济维度的重要性。

Abstract: Agentic artificial intelligence (AI) -- multi-agent systems that combine
large language models with external tools and autonomous planning -- are
rapidly transitioning from research laboratories into high-stakes domains. Our
earlier "Basic" paper introduced a five-axis framework and proposed preliminary
metrics such as goal drift and harm reduction but did not provide an
algorithmic instantiation or empirical evidence. This "Advanced" sequel fills
that gap. First, we revisit recent benchmarks and industrial deployments to
show that technical metrics still dominate evaluations: a systematic review of
84 papers from 2023--2025 found that 83% report capability metrics while only
30% consider human-centred or economic axes [2]. Second, we formalise an
Adaptive Multi-Dimensional Monitoring (AMDM) algorithm that normalises
heterogeneous metrics, applies per-axis exponentially weighted moving-average
thresholds and performs joint anomaly detection via the Mahalanobis distance.
Third, we conduct simulations and real-world experiments. AMDM cuts
anomaly-detection latency from 12.3 s to 5.6 s on simulated goal drift and
reduces false-positive rates from 4.5% to 0.9% compared with static thresholds.
We present a comparison table and ROC/PR curves, and we reanalyse case studies
to surface missing metrics. Code, data and a reproducibility checklist
accompany this paper to facilitate replication.

</details>


### [171] [LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain](https://arxiv.org/abs/2509.00510)
*Li Weigang,Pedro Carvalho Brom,Lucas Ramson Siefert*

Main category: cs.AI

TL;DR: 本文提出了一种名为SuperBrain的新型集体智能框架，基于LLM和人类用户的共同进化。该框架通过动态路径从子类大脑到超类大脑，实现了多目标优化和知识整合，为可扩展、可解释和符合伦理的集体人工智能提供了概念基础和架构路线图。


<details>
  <summary>Details</summary>
Motivation: 现有的静态提示工程或孤立的代理模拟无法充分捕捉LLM和人类用户之间的动态互动。本文旨在提供一种新的框架，以实现更高效、可解释和符合伦理的集体人工智能。

Method: 本文提出了一种动态路径，从子类大脑到超类大脑：(1) 通过用户和LLM的持续个性化互动形成子类大脑；(2) 通过GA辅助的前后进化，这些二元组迭代优化提示和任务性能；(3) 多个子类大脑通过群体智能协调，优化多目标适应度景观并交换提炼的启发式方法；(4) 它们的标准行为和认知特征整合到一个超类大脑中，这是一种能够抽象、泛化和自我改进的新兴元智能。

Result: 本文概述了理论构建，展示了初步实现（例如无人机调度、KU/KI关键词过滤），并提出了一个跨二元组知识整合的注册表。

Conclusion: 本文提出了一个超级大脑框架，用于集体智能，基于大型语言模型（LLM）和人类用户的共同进化。该框架提供了一个概念基础和架构路线图，以实现可扩展、可解释和符合伦理的集体人工智能。

Abstract: We propose a novel SuperBrain framework for collective intelligence, grounded
in the co-evolution of large language models (LLMs) and human users. Unlike
static prompt engineering or isolated agent simulations, our approach
emphasizes a dynamic pathway from Subclass Brain to Superclass Brain: (1) A
Subclass Brain arises from persistent, personalized interaction between a user
and an LLM, forming a cognitive dyad with adaptive learning memory. (2) Through
GA-assisted forward-backward evolution, these dyads iteratively refine prompts
and task performance. (3) Multiple Subclass Brains coordinate via Swarm
Intelligence, optimizing across multi-objective fitness landscapes and
exchanging distilled heuristics. (4) Their standardized behaviors and cognitive
signatures integrate into a Superclass Brain, an emergent meta-intelligence
capable of abstraction, generalization and self-improvement. We outline the
theoretical constructs, present initial implementations (e.g., UAV scheduling,
KU/KI keyword filtering) and propose a registry for cross-dyad knowledge
consolidation. This work provides both a conceptual foundation and an
architectural roadmap toward scalable, explainable and ethically aligned
collective AI.

</details>


### [172] [On Verifiable Legal Reasoning: A Multi-Agent Framework with Formalized Knowledge Representations](https://arxiv.org/abs/2509.00710)
*Albert Sadowski,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 本文提出了一种模块化多智能体框架，将法律推理分解为知识获取和应用阶段，通过形式化规则和符号推理提高AI法律推理的透明度和一致性，实验结果表明该方法显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 法律推理需要精确解释法规语言和一致应用复杂规则，这对AI系统提出了重大挑战。本文旨在通过模块化多智能体框架解决这些挑战，提高AI法律推理的透明度、一致性和可解释性。

Method: 本文介绍了一种模块化多智能体框架，将法律推理分解为不同的知识获取和应用阶段。在第一阶段，专业代理提取法律概念并形式化规则以创建可验证的法规中间表示。第二阶段通过三个步骤将此知识应用于具体案例：分析查询以将案件事实映射到本体论模式，执行符号推理以推导出逻辑蕴含的结论，并使用程序实现来操作本体论知识生成最终答案。

Result: 在法规税计算任务上的评估显示，基础模型的准确率达到了76.4%，相比18.8%的基线性能有了显著提升，有效缩小了推理模型和基础模型之间的性能差距。

Conclusion: 这些发现表明，具有形式化知识表示的模块化架构可以通过计算高效的模型使复杂的法律推理更易访问，同时提高AI法律推理的一致性和可解释性，为未来研究更透明、可信和有效的法律领域AI系统奠定了基础。

Abstract: Legal reasoning requires both precise interpretation of statutory language
and consistent application of complex rules, presenting significant challenges
for AI systems. This paper introduces a modular multi-agent framework that
decomposes legal reasoning into distinct knowledge acquisition and application
stages. In the first stage, specialized agents extract legal concepts and
formalize rules to create verifiable intermediate representations of statutes.
The second stage applies this knowledge to specific cases through three steps:
analyzing queries to map case facts onto the ontology schema, performing
symbolic inference to derive logically entailed conclusions, and generating
final answers using a programmatic implementation that operationalizes the
ontological knowledge. This bridging of natural language understanding with
symbolic reasoning provides explicit and verifiable inspection points,
significantly enhancing transparency compared to end-to-end approaches.
Evaluation on statutory tax calculation tasks demonstrates substantial
improvements, with foundational models achieving 76.4\% accuracy compared to
18.8\% baseline performance, effectively narrowing the performance gap between
reasoning and foundational models. These findings suggest that modular
architectures with formalized knowledge representations can make sophisticated
legal reasoning more accessible through computationally efficient models while
enhancing consistency and explainability in AI legal reasoning, establishing a
foundation for future research into more transparent, trustworthy, and
effective AI systems for legal domain.

</details>


### [173] [L-MARS -- Legal Multi-Agent Workflow with Orchestrated Reasoning and Agentic Search](https://arxiv.org/abs/2509.00761)
*Ziqi Wang,Boqin Yuan*

Main category: cs.AI

TL;DR: L-MARS是一个通过多智能体推理和检索减少法律问答中幻觉和不确定性的系统，它在法律问题解答任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 法律问答中存在幻觉和不确定性问题，需要一种更准确和可靠的解决方案。

Method: L-MARS系统通过协调的多智能体推理和检索来减少法律问答中的幻觉和不确定性。它将查询分解为子问题，在异构来源（Serper网络、本地RAG、CourtListener案例法）上进行有针对性的搜索，并使用法官代理在答案合成前验证充分性、管辖权和时间有效性。这种迭代推理-搜索-验证循环保持连贯性，过滤噪声证据，并将答案基于权威法律。

Result: 在LegalSearchQA基准测试中，L-MARS显著提高了事实准确性，减少了不确定性，并从人类专家和LLM-based法官那里获得了更高的偏好评分。

Conclusion: 我们的工作表明，结合代理搜索的多智能体推理为在需要精确法律检索和审议的高风险领域部署LLM提供了一个可扩展和可重复的蓝图。

Abstract: We present L-MARS (Legal Multi-Agent Workflow with Orchestrated Reasoning and
Agentic Search), a system that reduces hallucination and uncertainty in legal
question answering through coordinated multi-agent reasoning and retrieval.
Unlike single-pass retrieval-augmented generation (RAG), L-MARS decomposes
queries into subproblems, issues targeted searches across heterogeneous sources
(Serper web, local RAG, CourtListener case law), and employs a Judge Agent to
verify sufficiency, jurisdiction, and temporal validity before answer
synthesis. This iterative reasoning-search-verification loop maintains
coherence, filters noisy evidence, and grounds answers in authoritative law. We
evaluated L-MARS on LegalSearchQA, a new benchmark of 200 up-to-date multiple
choice legal questions in 2025. Results show that L-MARS substantially improves
factual accuracy, reduces uncertainty, and achieves higher preference scores
from both human experts and LLM-based judges. Our work demonstrates that
multi-agent reasoning with agentic search offers a scalable and reproducible
blueprint for deploying LLMs in high-stakes domains requiring precise legal
retrieval and deliberation.

</details>


### [174] [Aligning Reasoning LLMs for Materials Discovery with Physics-aware Rejection Sampling](https://arxiv.org/abs/2509.00768)
*Lee Hyun,Sohee Yoon,Jinwoo Park,Sue In Chae,Seongeon Park,Jooyeon Ahn,Yebin Jung,Youjung Chung,Hogeun Chang,Myeonginn Kang,Jina Kim,Ho-Gyeong Kim,Myeonghun Jeong*

Main category: cs.AI

TL;DR: 本文提出了一种名为Physics-aware Rejection Sampling (PaRS) 的训练时轨迹选择方案，以提高AI驱动的材料发现中过程感知属性预测的准确性、校准度和物理可接受性。


<details>
  <summary>Details</summary>
Motivation: AI驱动的材料发现需要过程感知的配方到属性预测器，这些预测器需要准确、校准和物理可接受。然而，大多数训练管道使用二进制正确性或学习的偏好信号选择推理轨迹，这不能很好地反映物理可接受性。

Method: 我们引入了Physics-aware Rejection Sampling (PaRS)，这是一种训练时轨迹选择方案，优先选择与基本物理一致且数值接近目标的轨迹，并使用轻量级停止来控制计算。

Result: 我们的方法提高了准确性、校准度，减少了物理违反率，并相对于基线降低了采样成本。

Conclusion: 我们的方法在准确性、校准和物理可接受性方面优于基线，并降低了采样成本，表明结合领域感知约束和轨迹级选择可以为过程感知属性预测和闭环材料设计提供可行的路径。

Abstract: AI-driven materials discovery that couples automated experimentation with
algorithmic decision-making requires process aware recipe to property
predictors that are accurate, calibrated, and physically admissible. We
approach this as a reasoning problem with large reasoning models (LRMs). To
instill reasoning capability into language models, we curate reasoning traces
from a teacher model to train a student model. However, most training pipelines
select reasoning traces using binary correctness or learned preference signals
that poorly reflect physical admissibility. We introduce Physics-aware
Rejection Sampling (PaRS), a training-time trace selection scheme that favors
traces consistent with fundamental physics and numerically close to targets,
with lightweight halting to control compute. We instantiate our framework with
a large student model fine-tuned on traces synthesized by a larger teacher
model, and evaluate under matched token budgets against various rejection
sampling baselines. Our method improves accuracy and calibration, reduces
physics-violation rates, and lowers sampling cost relative to baselines. These
results indicate that modest, domain-aware constraints combined with
trace-level selection provide a practical path toward reliable, efficient LRMs
for process-aware property prediction and closed-loop materials design.

</details>


### [175] [ChatCLIDS: Simulating Persuasive AI Dialogues to Promote Closed-Loop Insulin Adoption in Type 1 Diabetes Care](https://arxiv.org/abs/2509.00891)
*Zonghai Yao,Talha Chafekar,Junda Wang,Shuo Han,Feiyun Ouyang,Junhui Qian,Lingxi Li,Hong Yu*

Main category: cs.AI

TL;DR: 研究引入了ChatCLIDS，用于评估大语言模型在健康行为改变中的说服性对话能力。结果表明，尽管大语言模型可以调整策略，但在面对阻力时仍存在困难。


<details>
  <summary>Details</summary>
Motivation: 现实世界中闭环胰岛素输送系统（CLIDS）在1型糖尿病中的采用率仍然很低，这并非由于技术失败，而是由于多种行为、心理社会和社会障碍。因此，需要一种新的方法来评估大语言模型在健康行为改变中的作用。

Method: 引入ChatCLIDS，这是一个基准测试，用于严格评估基于大语言模型的说服性对话以促进健康行为改变。框架包括专家验证的虚拟患者库，每个患者都有临床基础的异质性档案和现实采用障碍，并模拟与护士代理的多轮互动，这些代理配备了多种基于证据的说服策略。

Result: 研究发现，虽然更大的和更具反思性的大语言模型能够随时间调整策略，但所有模型在面对阻力时都表现不佳，尤其是在现实社会压力下。

Conclusion: 当前大型语言模型在行为改变方面存在重大局限性，需要一个高保真、可扩展的测试平台来推动医疗保健和其他领域的可信说服性人工智能的发展。

Abstract: Real-world adoption of closed-loop insulin delivery systems (CLIDS) in type 1
diabetes remains low, driven not by technical failure, but by diverse
behavioral, psychosocial, and social barriers. We introduce ChatCLIDS, the
first benchmark to rigorously evaluate LLM-driven persuasive dialogue for
health behavior change. Our framework features a library of expert-validated
virtual patients, each with clinically grounded, heterogeneous profiles and
realistic adoption barriers, and simulates multi-turn interactions with nurse
agents equipped with a diverse set of evidence-based persuasive strategies.
ChatCLIDS uniquely supports longitudinal counseling and adversarial social
influence scenarios, enabling robust, multi-dimensional evaluation. Our
findings reveal that while larger and more reflective LLMs adapt strategies
over time, all models struggle to overcome resistance, especially under
realistic social pressure. These results highlight critical limitations of
current LLMs for behavior change, and offer a high-fidelity, scalable testbed
for advancing trustworthy persuasive AI in healthcare and beyond.

</details>


### [176] [Self-Exploring Language Models for Explainable Link Forecasting on Temporal Graphs via Reinforcement Learning](https://arxiv.org/abs/2509.00975)
*Zifeng Ding,Shenyang Huang,Zeyu Cao,Emma Kondrup,Zachary Yang,Xingyue Huang,Yuan Sui,Zhangdie Yuan,Yuqicheng Zhu,Xianglong Hu,Yuan He,Farimah Poursafaei,Michael Bronstein,Andreas Vlachos*

Main category: cs.AI

TL;DR: 本文提出了一种名为ReaL-TG的强化学习框架，用于时序图的可解释链接预测。该框架微调大型语言模型，并通过基于结果的奖励鼓励模型生成高质量的解释。实验表明，ReaL-TG-4B在排名指标上优于更大的前沿LLMs，同时生成了高质量的解释。


<details>
  <summary>Details</summary>
Motivation: 传统神经方法在时序图推理中表现良好，但缺乏可解释性且无法应用于未见过的图而无需重新训练。最近的研究开始探索使用大型语言模型（LLMs）进行图推理，但大多数局限于静态图或小的合成时序图，并缺乏对LLM生成的推理轨迹质量的评估。

Method: ReaL-TG是一个强化学习框架，微调大型语言模型（LLM）以在现实世界的时序图上进行可解释的链接预测。它使用基于结果的奖励来鼓励模型从图结构中自我探索推理策略，并生成直接证明其预测的解释。

Result: ReaL-TG-4B在排名指标上优于更大的前沿LLMs，包括GPT-5 mini，同时生成了高质量的解释，这些解释得到了LLM法官和人类评估的确认。

Conclusion: ReaL-TG-4B在排名指标上优于更大的前沿LLMs，同时生成了高质量的解释，得到了LLM法官和人类评估的认可。

Abstract: Forecasting future links is a central task in temporal graph (TG) reasoning,
requiring models to leverage historical interactions to predict upcoming ones.
Traditional neural approaches, such as temporal graph neural networks, achieve
strong performance but lack explainability and cannot be applied to unseen
graphs without retraining. Recent studies have begun to explore using large
language models (LLMs) for graph reasoning, but most of them are constrained to
static graphs or small synthetic TGs and lack the evaluation of the quality of
reasoning traces generated by LLMs. In this work, we present Reasoning-Enhanced
Learning for Temporal Graphs (ReaL-TG), a reinforcement learning framework that
fine-tunes LLMs to perform explainable link forecasting on real-world TGs.
ReaL-TG uses outcome-based reward to encourage models to self-explore reasoning
strategies from graph structure and to produce explanations that directly
justify their predictions. To enable evaluation on LLM-generated reasoning
traces, we propose a new evaluation protocol combining ranking metrics with an
LLM-as-a-Judge system that assesses both the quality of reasoning and the
impact of hallucinations. Experiments with ReaL-TG-4B, obtained by fine-tuning
Qwen3-4B under our framework, show that it outperforms much larger frontier
LLMs, including GPT-5 mini, on ranking metrics, while producing high-quality
explanations confirmed by both the LLM judge and human evaluation.

</details>


### [177] [Analysis of Error Sources in LLM-based Hypothesis Search for Few-Shot Rule Induction](https://arxiv.org/abs/2509.01016)
*Aishni Parab,Hongjing Lu,Ying Nian Wu,Sumit Gulwani*

Main category: cs.AI

TL;DR: 本文比较了基于LLM的假设搜索和直接程序生成在少量示例规则归纳任务中的表现，发现假设搜索表现接近人类，而直接程序生成则较差。


<details>
  <summary>Details</summary>
Motivation: 研究旨在比较不同方法在归纳推理任务中的性能，并探索改进程序归纳方法的方向。

Method: 比较基于LLM的假设搜索框架与直接程序生成方法在少量示例规则归纳任务上的表现。

Result: 假设搜索的表现与人类相当，而直接程序生成则明显落后。

Conclusion: 本文强调了基于LLM的假设搜索在建模归纳推理方面的潜力，以及构建更高效系统所面临的挑战。

Abstract: Inductive reasoning enables humans to infer abstract rules from limited
examples and apply them to novel situations. In this work, we compare an
LLM-based hypothesis search framework with direct program generation approaches
on few-shot rule induction tasks. Our findings show that hypothesis search
achieves performance comparable to humans, while direct program generation
falls notably behind. An error analysis reveals key bottlenecks in hypothesis
generation and suggests directions for advancing program induction methods.
Overall, this paper underscores the potential of LLM-based hypothesis search
for modeling inductive reasoning and the challenges in building more efficient
systems.

</details>


### [178] [FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games](https://arxiv.org/abs/2509.01052)
*Jaewoo Ahn,Junseo Kim,Heeseung Yun,Jaehyeon Son,Dongmin Park,Jaewoong Cho,Gunhee Kim*

Main category: cs.AI

TL;DR: 本文介绍了FlashAdventure基准和COAST代理框架，用于测试GUI代理在完成完整故事情节和解决顺序任务方面的能力。实验表明，当前的GUI代理在这些任务上表现不佳，而COAST通过利用长期线索记忆提高了性能。然而，人类与代理之间的差距仍然很大，需要进一步研究。


<details>
  <summary>Details</summary>
Motivation: 现有游戏基准缺乏多样性，很少评估代理完成整个故事情节的能力。视频游戏提供了有价值的测试平台，因为它们具有各种界面，而冒险游戏则通过复杂、叙事驱动的交互增加了额外的挑战。

Method: 引入了FlashAdventure基准和CUA-as-a-Judge自动化游戏评估工具，以及COAST代理框架，该框架利用长期线索记忆来更好地规划和解决顺序任务。

Result: 实验表明，当前的GUI代理在完成完整故事弧线方面存在困难，而COAST通过弥合观察-行为差距提高了里程碑的完成度。然而，人类与表现最佳的代理之间仍存在显著差异。

Conclusion: 当前GUI代理在完成完整故事弧线方面存在困难，而COAST通过弥合观察-行为差距提高了里程碑完成度。然而，人类与表现最佳的代理之间仍存在显著差异，需要持续研究以缩小这一差距。

Abstract: GUI agents powered by LLMs show promise in interacting with diverse digital
environments. Among these, video games offer a valuable testbed due to their
varied interfaces, with adventure games posing additional challenges through
complex, narrative-driven interactions. Existing game benchmarks, however, lack
diversity and rarely evaluate agents on completing entire storylines. To
address this, we introduce FlashAdventure, a benchmark of 34 Flash-based
adventure games designed to test full story arc completion and tackle the
observation-behavior gap: the challenge of remembering and acting on earlier
gameplay information. We also propose CUA-as-a-Judge, an automated gameplay
evaluator, and COAST, an agentic framework leveraging long-term clue memory to
better plan and solve sequential tasks. Experiments show current GUI agents
struggle with full story arcs, while COAST improves milestone completion by
bridging the observation-behavior gap. Nonetheless, a marked discrepancy
between humans and best-performing agents warrants continued research efforts
to narrow this divide.

</details>


### [179] [VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use](https://arxiv.org/abs/2509.01055)
*Dongfu Jiang,Yi Lu,Zhuofeng Li,Zhiheng Lyu,Ping Nie,Haozhe Wang,Alex Su,Hui Chen,Kai Zou,Chao Du,Tianyu Pang,Wenhu Chen*

Main category: cs.AI

TL;DR: VerlTool is a unified and modular framework for ARLT that addresses inefficiencies in existing approaches, enabling efficient, scalable, and extensible multi-turn tool interactions with competitive performance across multiple domains.


<details>
  <summary>Details</summary>
Motivation: Existing ARLT approaches suffer from fragmentation, synchronous execution bottlenecks, and limited extensibility, hindering broader community adoption and algorithmic innovation. There is a need for a unified and modular framework that supports efficient multi-turn tool interactions.

Method: VerlTool introduces systematic design principles to address the challenges of multi-turn tool interactions in ARLT. It includes upstream alignment with VeRL, unified tool management via standardized APIs, asynchronous rollout execution, and comprehensive evaluation across multiple domains.

Result: VerlTool achieves near 2× speedup through asynchronous execution, supports diverse modalities including code execution, search, SQL databases, and vision processing, and demonstrates competitive performance across 6 ARLT domains. It also enables rapid tool integration with lightweight Python definitions.

Conclusion: VerlTool provides a unified and modular framework for Agentic Reinforcement Learning with Tool use (ARLT), addressing limitations in existing approaches by enabling efficient, scalable, and extensible multi-turn tool interactions. The framework demonstrates competitive performance across multiple domains while reducing development overhead through its lightweight plugin architecture.

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated
success in enhancing LLM reasoning capabilities, but remains limited to
single-turn interactions without tool integration. While recent Agentic
Reinforcement Learning with Tool use (ARLT) approaches have emerged to address
multi-turn tool interactions, existing works develop task-specific codebases
that suffer from fragmentation, synchronous execution bottlenecks, and limited
extensibility across domains. These inefficiencies hinder broader community
adoption and algorithmic innovation. We introduce VerlTool, a unified and
modular framework that addresses these limitations through systematic design
principles. VerlTool provides four key contributions: (1) upstream alignment
with VeRL ensuring compatibility and simplified maintenance, (2) unified tool
management via standardized APIs supporting diverse modalities including code
execution, search, SQL databases, and vision processing, (3) asynchronous
rollout execution achieving near 2$\times$ speedup by eliminating
synchronization bottlenecks, and (4) comprehensive evaluation demonstrating
competitive performance across 6 ARLT domains. Our framework formalizes ARLT as
multi-turn trajectories with multi-modal observation tokens (text/image/video),
extending beyond single-turn RLVR paradigms. We train and evaluate models on
mathematical reasoning, knowledge QA, SQL generation, visual reasoning, web
search, and software engineering tasks, achieving results comparable to
specialized systems while providing unified training infrastructure. The
modular plugin architecture enables rapid tool integration requiring only
lightweight Python definitions, significantly reducing development overhead and
providing a scalable foundation for tool-augmented RL research. Our code is
open-sourced at https://github.com/TIGER-AI-Lab/verl-tool.

</details>


### [180] [Question-to-Knowledge: Multi-Agent Generation of Inspectable Facts for Product Mapping](https://arxiv.org/abs/2509.01182)
*Wonduk Seo,Taesub Shin,Hyunjin An,Dokyun Kim,Seunghyun Lee*

Main category: cs.AI

TL;DR: Q2K 是一种利用大型语言模型的多代理框架，用于可靠地将产品列表映射到同一库存单位（SKU）。它通过生成消歧问题、通过网络搜索解决这些问题以及重用已验证的推理痕迹来提高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 在电子商务中，当缺少显式标识符且产品名称在不同平台上变化很大时，确定两个产品列表是否指向同一库存单位（SKU）是一个持续的挑战。基于规则的启发式方法和关键词相似性常常因忽略品牌、规格或捆绑配置的细微差别而错误分类产品。

Method: Q2K 是一个利用大型语言模型（LLMs）进行可靠 SKU 映射的多代理框架，包括：(1) 一个生成目标消歧问题的推理代理，(2) 一个通过聚焦网络搜索来解决这些问题的知识代理，以及 (3) 一个通过重用已验证的推理痕迹来减少冗余并确保一致性的去重代理。

Result: 在真实世界消费者商品数据集上的实验表明，Q2K 超过了强大的基线，实现了更高的准确性和鲁棒性，特别是在捆绑识别和品牌来源消歧等困难场景中。

Conclusion: Q2K 提供了一种可扩展且可解释的解决方案，用于产品集成，通过重新使用检索到的推理而不是发出重复搜索，平衡了准确性与效率。

Abstract: Identifying whether two product listings refer to the same Stock Keeping Unit
(SKU) is a persistent challenge in ecommerce, especially when explicit
identifiers are missing and product names vary widely across platforms. Rule
based heuristics and keyword similarity often misclassify products by
overlooking subtle distinctions in brand, specification, or bundle
configuration. To overcome these limitations, we propose Question to Knowledge
(Q2K), a multi agent framework that leverages Large Language Models (LLMs) for
reliable SKU mapping. Q2K integrates: (1) a Reasoning Agent that generates
targeted disambiguation questions, (2) a Knowledge Agent that resolves them via
focused web searches, and (3) a Deduplication Agent that reuses validated
reasoning traces to reduce redundancy and ensure consistency. A human in the
loop mechanism further refines uncertain cases. Experiments on real world
consumer goods datasets show that Q2K surpasses strong baselines, achieving
higher accuracy and robustness in difficult scenarios such as bundle
identification and brand origin disambiguation. By reusing retrieved reasoning
instead of issuing repeated searches, Q2K balances accuracy with efficiency,
offering a scalable and interpretable solution for product integration.

</details>


### [181] [GradeSQL: Outcome Reward Models for Ranking SQL Queries from Large Language Models](https://arxiv.org/abs/2509.01308)
*Mattia Tritto,Giuseppe Farano,Dario Di Palma,Gaetano Rossiello,Fedelucio Narducci,Dharmashankar Subramanian,Tommaso Di Noia*

Main category: cs.AI

TL;DR: This paper evaluates ORMs for Text-to-SQL tasks and shows they outperform existing test-time strategies like ex-BoN and Maj.


<details>
  <summary>Details</summary>
Motivation: Current LLMs still struggle with complex queries that require precise alignment between user intent and the database schema. Test-time strategies like ex-BoN and Maj have limitations, and ORMs, which assign utility scores based on semantic correctness, are underexplored in Text-to-SQL.

Method: The paper evaluates ORMs as an effective heuristic for BoN, compares them with ex-BoN and Maj, and introduces a framework for training ORMs for the Text-to-SQL task.

Result: ORMs outperform ex-BoN and Maj, achieving execution accuracy gains of +4.33% (BIRD) and +2.10% (Spider) over ex-BoN, and +2.91% (BIRD) and +0.93% (Spider) over Maj. Finetuning models like OmniSQL improves ORM performance, and ORMs benefit more from an increased number of candidates.

Conclusion: ORMs outperform ex-BoN and Maj in Text-to-SQL tasks, achieving significant execution accuracy gains. Finetuning models already aligned with SQL generation, such as OmniSQL, yields superior ORM performance.

Abstract: Text-to-SQL, the task of translating natural language questions into SQL
queries, has significantly advanced with the introduction of Large Language
Models (LLMs), broadening database accessibility for a wide range of users.
Despite substantial progress in generating valid SQL, current LLMs still
struggle with complex queries that require precise alignment between user
intent and the database schema. To mitigate this, test-time strategies such as
Best-of-N (BoN) and Majority Voting (Maj) are often employed, based on the
assumption that LLMs can generate correct answers but may require multiple
attempts. However, these methods rely on surface-level heuristics, selecting
either the syntactically correct query through execution-based BoN (ex-BoN) or
the most frequently generated query with Maj. Recently, Outcome Reward Models
(ORMs), which assign utility scores to generated outputs based on semantic
correctness, have emerged as a promising approach for better aligning model
predictions with user intent. Nevertheless, their application to Text-to-SQL
remains largely underexplored.
  In this work, we evaluate ORMs as an effective heuristic for BoN, compare
them with ex-BoN and Maj, and introduce a framework for training ORMs for the
Text-to-SQL task. We evaluate our ORMs on the BIRD and SPIDER benchmarks,
finetuning various open-source LLMs, including the Qwen2, Granite3, and Llama3
model families. Our results show that ORMs outperform ex-BoN and Maj, achieving
execution accuracy gains of +4.33% (BIRD) and +2.10% (Spider) over ex-BoN, and
+2.91% (BIRD) and +0.93% (Spider) over Maj. We further demonstrate that
finetuning models already aligned with SQL generation, such as OmniSQL, yields
superior ORM performance. Additionally, we observe that ORMs achieve
competitive results on simple queries and benefit more from an increased number
of candidates compared to ex-BoN and Maj.

</details>


### [182] [An LLM-enabled semantic-centric framework to consume privacy policies](https://arxiv.org/abs/2509.01716)
*Rui Zhao,Vladyslav Melnychuk,Jun Zhao,Jesse Wright,Nigel Shadbolt*

Main category: cs.AI

TL;DR: 本文提出了一种基于语义的最新大型语言模型的方法，用于自动识别隐私政策中的关键信息，并构建基于数据隐私词汇表（DPV）的语义知识图谱（Pr²Graph），以支持下游任务。此外，还释放了前100个流行网站的Pr²Graph作为公共资源，并展示了如何使用Pr²Graph构建正式的政策表示，如ODRL或psDToU。实验结果表明，这种方法为大规模分析在线服务的隐私实践提供了可能性，是一个有前途的方向。所有数据集和源代码都作为公共资源发布，以促进重复使用和改进。


<details>
  <summary>Details</summary>
Motivation: 现代人拥有众多在线账户，但很少阅读网站的条款和服务或隐私政策，尽管他们声称会这样做。数据隐私实践的迷雾是用户中心的网络方法以及数据共享和重用的一个主要障碍。现有的研究提出了使用形式化语言和推理来验证指定策略的合规性，作为一种潜在的解决办法。然而，在大规模创建或获取这种形式化策略方面仍存在一个关键差距。

Method: 本文提出了一种基于语义的最新大型语言模型的方法，用于自动识别隐私政策中的关键信息，并构建基于数据隐私词汇表（DPV）的语义知识图谱（Pr²Graph）。此外，还释放了前100个流行网站的Pr²Graph作为公共资源，并展示了如何使用Pr²Graph构建正式的政策表示，如ODRL或psDToU。

Result: 本文提出了一种基于语义的最新大型语言模型的方法，用于自动识别隐私政策中的关键信息，并构建基于数据隐私词汇表（DPV）的语义知识图谱（Pr²Graph）。此外，还释放了前100个流行网站的Pr²Graph作为公共资源，并展示了如何使用Pr²Graph构建正式的政策表示，如ODRL或psDToU。实验结果表明，这种方法为大规模分析在线服务的隐私实践提供了可能性，是一个有前途的方向。所有数据集和源代码都作为公共资源发布，以促进重复使用和改进。

Conclusion: 本文提出了一种基于语义的最新大型语言模型的方法，用于自动识别隐私政策中的关键信息，并构建基于数据隐私词汇表（DPV）的语义知识图谱（Pr²Graph），以支持下游任务。此外，还释放了前100个流行网站的Pr²Graph作为公共资源，并展示了如何使用Pr²Graph构建正式的政策表示，如ODRL或psDToU。实验结果表明，这种方法为大规模分析在线服务的隐私实践提供了可能性，是一个有前途的方向。所有数据集和源代码都作为公共资源发布，以促进重复使用和改进。

Abstract: In modern times, people have numerous online accounts, but they rarely read
the Terms of Service or Privacy Policy of those sites, despite claiming
otherwise, due to the practical difficulty in comprehending them. The mist of
data privacy practices forms a major barrier for user-centred Web approaches,
and for data sharing and reusing in an agentic world. Existing research
proposed methods for using formal languages and reasoning for verifying the
compliance of a specified policy, as a potential cure for ignoring privacy
policies. However, a critical gap remains in the creation or acquisition of
such formal policies at scale. We present a semantic-centric approach for using
state-of-the-art large language models (LLM), to automatically identify key
information about privacy practices from privacy policies, and construct
$\mathit{Pr}^2\mathit{Graph}$, knowledge graph with grounding from Data Privacy
Vocabulary (DPV) for privacy practices, to support downstream tasks. Along with
the pipeline, the $\mathit{Pr}^2\mathit{Graph}$ for the top-100 popular
websites is also released as a public resource, by using the pipeline for
analysis. We also demonstrate how the $\mathit{Pr}^2\mathit{Graph}$ can be used
to support downstream tasks by constructing formal policy representations such
as Open Digital Right Language (ODRL) or perennial semantic Data Terms of Use
(psDToU). To evaluate the technology capability, we enriched the Policy-IE
dataset by employing legal experts to create custom annotations. We benchmarked
the performance of different large language models for our pipeline and
verified their capabilities. Overall, they shed light on the possibility of
large-scale analysis of online services' privacy practices, as a promising
direction to audit the Web and the Internet. We release all datasets and source
code as public resources to facilitate reuse and improvement.

</details>


### [183] [Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models](https://arxiv.org/abs/2509.01909)
*Ranjie Duan,Jiexi Liu,Xiaojun Jia,Shiji Zhao,Ruoxi Cheng,Fengxiang Wang,Cheng Wei,Yong Xie,Chang Liu,Defeng Li,Yinpeng Dong,Yichi Zhang,Yuefeng Chen,Chongwen Wang,Xingjun Ma,Xingxing Wei,Yang Liu,Hang Su,Jun Zhu,Xinfeng Li,Yitong Sun,Jie Zhang,Jinzhao Hu,Sha Xu,Yitong Yang,Jialing Tao,Hui Xue*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) typically deploy safety mechanisms to prevent
harmful content generation. Most current approaches focus narrowly on risks
posed by malicious actors, often framing risks as adversarial events and
relying on defensive refusals. However, in real-world settings, risks also come
from non-malicious users seeking help while under psychological distress (e.g.,
self-harm intentions). In such cases, the model's response can strongly
influence the user's next actions. Simple refusals may lead them to repeat,
escalate, or move to unsafe platforms, creating worse outcomes. We introduce
Constructive Safety Alignment (CSA), a human-centric paradigm that protects
against malicious misuse while actively guiding vulnerable users toward safe
and helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic
anticipation of user reactions, fine-grained risk boundary discovery, and
interpretable reasoning control, turning safety into a trust-building process.
Oy1 achieves state-of-the-art safety among open models while retaining high
general capabilities. On our Constructive Benchmark, it shows strong
constructive engagement, close to GPT-5, and unmatched robustness on the
Strata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from
refusal-first to guidance-first safety, CSA redefines the model-user
relationship, aiming for systems that are not just safe, but meaningfully
helpful. We release Oy1, code, and the benchmark to support responsible,
user-centered AI.

</details>


### [184] [How Real Is AI Tutoring? Comparing Simulated and Human Dialogues in One-on-One Instruction](https://arxiv.org/abs/2509.01914)
*Ruijia Li,Yuan-Hao Jiang,Jiatong Wang,Bo Jiang*

Main category: cs.AI

TL;DR: 研究发现AI生成的辅导对话在多个方面不如人类对话，提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 研究AI模拟和真实人类辅导对话之间的结构和行为差异，以改进AI生成的教育对话系统。

Method: 使用Initiation-Response-Feedback (IRF)编码方案和Epistemic Network Analysis (ENA)进行了定量比较。

Result: 人类对话在话语长度、提问（I-Q）和一般反馈（F-F）行为上显著优于AI对话。ENAs结果显示了互动模式的根本分歧：人类对话更具认知引导性和多样性，围绕“问题-事实回答-反馈”教学循环；而模拟对话则表现出结构简化和行为趋同，围绕“解释-简单回答”循环。

Conclusion: 研究揭示了当前AI生成辅导对话的关键局限性，并为设计和评估更有效的生成教育对话系统提供了实证指导。

Abstract: Heuristic and scaffolded teacher-student dialogues are widely regarded as
critical for fostering students' higher-order thinking and deep learning.
However, large language models (LLMs) currently face challenges in generating
pedagogically rich interactions. This study systematically investigates the
structural and behavioral differences between AI-simulated and authentic human
tutoring dialogues. We conducted a quantitative comparison using an
Initiation-Response-Feedback (IRF) coding scheme and Epistemic Network Analysis
(ENA). The results show that human dialogues are significantly superior to
their AI counterparts in utterance length, as well as in questioning (I-Q) and
general feedback (F-F) behaviors. More importantly, ENA results reveal a
fundamental divergence in interactional patterns: human dialogues are more
cognitively guided and diverse, centered around a "question-factual
response-feedback" teaching loop that clearly reflects pedagogical guidance and
student-driven thinking; in contrast, simulated dialogues exhibit a pattern of
structural simplification and behavioral convergence, revolving around an
"explanation-simplistic response" loop that is essentially a simple information
transfer between the teacher and student. These findings illuminate key
limitations in current AI-generated tutoring and provide empirical guidance for
designing and evaluating more pedagogically effective generative educational
dialogue systems.

</details>


### [185] [EigenBench: A Comparative Behavioral Measure of Value Alignment](https://arxiv.org/abs/2509.01938)
*Jonathn Chang,Leonard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine*

Main category: cs.AI

TL;DR: EigenBench 是一种用于评估语言模型价值对齐的新方法，它通过整合多个模型的判断并利用 EigenTrust 算法生成得分，无需真实标签。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏定量指标来衡量 AI 与人类价值观的一致性，因此需要一种新的方法来评估模型的价值对齐程度。

Method: EigenBench 是一种基于黑盒方法的基准测试工具，通过整合多个模型的判断并利用 EigenTrust 算法生成得分。

Result: EigenBench 能够区分模型和提示的影响，并能量化模型本身的倾向性。

Conclusion: EigenBench 提供了一种无需真实标签的量化方法，用于评估语言模型的价值对齐情况。

Abstract: Aligning AI with human values is a pressing unsolved problem. To address the
lack of quantitative metrics for value alignment, we propose EigenBench: a
black-box method for comparatively benchmarking language models' values. Given
an ensemble of models, a constitution describing a value system, and a dataset
of scenarios, our method returns a vector of scores quantifying each model's
alignment to the given constitution. To produce these scores, each model judges
the outputs of other models across many scenarios, and these judgments are
aggregated with EigenTrust (Kamvar et al, 2003), yielding scores that reflect a
weighted-average judgment of the whole ensemble. EigenBench uses no ground
truth labels, as it is designed to quantify traits for which reasonable judges
may disagree on the correct label. Using prompted personas, we test whether
EigenBench scores are more sensitive to the model or the prompt: we find that
most of the variance is explained by the prompt, but a small residual
quantifies the disposition of the model itself.

</details>


### [186] [AppCopilot: Toward General, Accurate, Long-Horizon, and Efficient Mobile Agent](https://arxiv.org/abs/2509.02444)
*Jingru Fan,Yufan Dang,Jingyao Wu,Huatao Li,Runde Yang,Xiyuan Yang,Yuheng Wang,Zhong Zhang,Yaxi Lu,Yankai Lin,Zhiyuan Liu,Dahai Li,Chen Qian*

Main category: cs.AI

TL;DR: AppCopilot is a multimodal, multi-agent, general-purpose on-device assistant that addresses four core problems in mobile agents: generalization, accuracy, long-horizon capability, and efficiency.


<details>
  <summary>Details</summary>
Motivation: The paper identifies four core problems that must be solved for mobile agents to deliver practical, scalable impact: generalization across tasks, modalities, apps, and devices; accuracy, specifically precise on-screen interaction and click targeting; long-horizon capability for sustained, multi-step goals; and efficiency, specifically high-performance runtime on resource-constrained devices.

Method: AppCopilot is a multimodal, multi-agent, general-purpose on-device assistant that operates across applications and constitutes a full-stack, closed-loop system from data to deployment. It integrates multimodal foundation models with robust Chinese-English support, combines chain-of-thought reasoning, hierarchical task planning and decomposition, and multi-agent collaboration, and enables user personalization and experiential adaptation, voice interaction, function calling, cross-app and cross-device orchestration, and comprehensive mobile app support.

Result: AppCopilot achieves significant improvements along all four dimensions: stronger generalization, higher-precision on-screen actions, more reliable long-horizon task completion, and faster, more resource-efficient runtime.

Conclusion: AppCopilot achieves significant improvements along all four dimensions: stronger generalization, higher-precision on-screen actions, more reliable long-horizon task completion, and faster, more resource-efficient runtime.

Abstract: With the raid evolution of large language models and multimodal foundation
models, the mobile-agent landscape has proliferated without converging on the
fundamental challenges. This paper identifies four core problems that must be
solved for mobile agents to deliver practical, scalable impact: (1)
generalization across tasks, modalities, apps, and devices; (2) accuracy,
specifically precise on-screen interaction and click targeting; (3)
long-horizon capability for sustained, multi-step goals; and (4) efficiency,
specifically high-performance runtime on resource-constrained devices. We
present AppCopilot, a multimodal, multi-agent, general-purpose on-device
assistant that operates across applications and constitutes a full-stack,
closed-loop system from data to deployment. AppCopilot operationalizes this
position through an end-to-end autonomous pipeline spanning data collection,
training, deployment, high-quality and efficient inference, and mobile
application development. At the model layer, it integrates multimodal
foundation models with robust Chinese-English support. At the reasoning and
control layer, it combines chain-of-thought reasoning, hierarchical task
planning and decomposition, and multi-agent collaboration. At the execution
layer, it enables user personalization and experiential adaptation, voice
interaction, function calling, cross-app and cross-device orchestration, and
comprehensive mobile app support. The system design incorporates
profiling-driven optimization for latency, memory, and energy across
heterogeneous hardware. Empirically, AppCopilot achieves significant
improvements along all four dimensions: stronger generalization,
higher-precision on-screen actions, more reliable long-horizon task completion,
and faster, more resource-efficient runtime.

</details>


### [187] [UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2509.02544)
*Haoming Wang,Haoyang Zou,Huatong Song,Jiazhan Feng,Junjie Fang,Junting Lu,Longxiang Liu,Qinyu Luo,Shihao Liang,Shijue Huang,Wanjun Zhong,Yining Ye,Yujia Qin,Yuwen Xiong,Yuxin Song,Zhiyong Wu,Bo Li,Chen Dun,Chong Liu,Fuxing Leng,Hanbin Wang,Hao Yu,Haobin Chen,Hongyi Guo,Jing Su,Jingjia Huang,Kai Shen,Kaiyu Shi,Lin Yan,Peiyao Zhao,Pengfei Liu,Qinghao Ye,Renjie Zheng,Wayne Xin Zhao,Wen Heng,Wenhao Huang,Wenqian Wang,Xiaobo Qin,Yi Lin,Youbin Wu,Zehui Chen,Zihao Wang,Baoquan Zhong,Xinchun Zhang,Xujing Li,Yuanfan Li,Zhongkai Zhao,Chengquan Jiang,Faming Wu,Haotian Zhou,Jinlin Pang,Li Han,Qianli Ma,Siyao Liu,Songhua Cai,Wenqi Fu,Xin Liu,Zhi Zhang,Bo Zhou,Guoliang Li,Jiajun Shi,Jiale Yang,Jie Tang,Li Li,Taoran Lu,Woyu Lin,Xiaokang Tong,Xinyao Li,Yichi Zhang,Yu Miao,Zhengxuan Jiang,Zili Li,Ziyuan Zhao,Chenxin Li,Dehua Ma,Feng Lin,Ge Zhang,Haihua Yang,Hangyu Guo,Hongda Zhu,Jiaheng Liu,Junda Du,Kai Cai,Kuanye Li,Lichen Yuan,Meilan Han,Minchao Wang,Shuyue Guo,Tianhao Cheng,Xiaobo Ma,Xiaojun Xiao,Xiaolong Huang,Xinjie Chen,Yidi Du,Yilin Chen,Yiwen Wang,Zhaojian Li,Zhenzhu Yang,Zhiyuan Zeng,Chaolin Jin,Chen Li,Hao Chen,Haoli Chen,Jian Chen,Qinghao Zhao,Guang Shi*

Main category: cs.AI

TL;DR: UI-TARS-2是一种针对GUI的自主代理模型，通过系统训练方法解决了数据可扩展性、多轮强化学习等挑战，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 开发用于图形用户界面（GUI）的自主代理面临重大挑战，包括数据可扩展性、多轮强化学习、仅限GUI操作的限制和环境稳定性问题。

Method: UI-TARS-2通过数据飞轮实现可扩展的数据生成，稳定多轮强化学习框架，混合GUI环境整合文件系统和终端，以及统一的沙箱平台进行大规模部署。

Result: UI-TARS-2在GUI基准测试中表现优于前代UI-TARS-1.5，在Online-Mind2Web、OSWorld、WindowsAgentArena和AndroidWorld上分别达到88.2、47.5、50.6和73.3分，同时在游戏环境中达到约人类水平60%的性能。

Conclusion: UI-TARS-2展示了其在GUI代理领域的潜力，并表现出对现实交互场景的强大泛化能力。

Abstract: The development of autonomous agents for graphical user interfaces (GUIs)
presents major challenges in artificial intelligence. While recent advances in
native agent models have shown promise by unifying perception, reasoning,
action, and memory through end-to-end learning, open problems remain in data
scalability, multi-turn reinforcement learning (RL), the limitations of
GUI-only operation, and environment stability. In this technical report, we
present UI-TARS-2, a native GUI-centered agent model that addresses these
challenges through a systematic training methodology: a data flywheel for
scalable data generation, a stabilized multi-turn RL framework, a hybrid GUI
environment that integrates file systems and terminals, and a unified sandbox
platform for large-scale rollouts. Empirical evaluation demonstrates that
UI-TARS-2 achieves significant improvements over its predecessor UI-TARS-1.5.
On GUI benchmarks, it reaches 88.2 on Online-Mind2Web, 47.5 on OSWorld, 50.6 on
WindowsAgentArena, and 73.3 on AndroidWorld, outperforming strong baselines
such as Claude and OpenAI agents. In game environments, it attains a mean
normalized score of 59.8 across a 15-game suite-roughly 60% of human-level
performance-and remains competitive with frontier proprietary models (e.g.,
OpenAI o3) on LMGame-Bench. Additionally, the model can generalize to
long-horizon information-seeking tasks and software engineering benchmarks,
highlighting its robustness across diverse agent tasks. Detailed analyses of
training dynamics further provide insights into achieving stability and
efficiency in large-scale agent RL. These results underscore UI-TARS-2's
potential to advance the state of GUI agents and exhibit strong generalization
to real-world interactive scenarios.

</details>


### [188] [The Landscape of Agentic Reinforcement Learning for LLMs: A Survey](https://arxiv.org/abs/2509.02547)
*Guibin Zhang,Hejia Geng,Xiaohang Yu,Zhenfei Yin,Zaibin Zhang,Zelin Tan,Heng Zhou,Zhongzhi Li,Xiangyuan Xue,Yijiang Li,Yifan Zhou,Yang Chen,Chen Zhang,Yutao Fan,Zihu Wang,Songtao Huang,Yue Liao,Hongru Wang,Mengyue Yang,Heng Ji,Michael Littman,Jun Wang,Shuicheng Yan,Philip Torr,Lei Bai*

Main category: cs.AI

TL;DR: 本文综述了代理强化学习（Agentic RL）的兴起，介绍了其在将大型语言模型转变为自主决策代理方面的意义，并提出了一个双重分类体系，同时总结了该领域的发展现状和未来挑战。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在大型语言模型中的应用存在局限，需要一种新的方法来使这些模型成为自主决策的代理。代理强化学习的出现为解决这一问题提供了新的思路。

Method: 本文通过对比LLM-RL的单步马尔可夫决策过程（MDPs）与代理RL的时序扩展、部分可观测马尔可夫决策过程（POMDPs），提出了一种双重分类体系，并对大量近期研究进行了综合分析。

Result: 本文提出了代理强化学习的核心能力分类体系，并总结了该领域的发展现状、挑战和未来方向。此外，还整理了相关的开源环境、基准测试和框架，以支持未来的研究。

Conclusion: 本文综述了代理强化学习（Agentic RL）的兴起，强调了其在将大型语言模型（LLM）从被动序列生成器转变为自主决策代理方面的变革性作用。文章提出了一个围绕核心代理能力及其应用领域的双重分类体系，并指出强化学习是实现这些能力从静态模块到自适应行为的关键机制。最后，本文总结了该领域的发展前景和挑战。

Abstract: The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm
shift from conventional reinforcement learning applied to large language models
(LLM RL), reframing LLMs from passive sequence generators into autonomous,
decision-making agents embedded in complex, dynamic worlds. This survey
formalizes this conceptual shift by contrasting the degenerate single-step
Markov Decision Processes (MDPs) of LLM-RL with the temporally extended,
partially observable Markov decision processes (POMDPs) that define Agentic RL.
Building on this foundation, we propose a comprehensive twofold taxonomy: one
organized around core agentic capabilities, including planning, tool use,
memory, reasoning, self-improvement, and perception, and the other around their
applications across diverse task domains. Central to our thesis is that
reinforcement learning serves as the critical mechanism for transforming these
capabilities from static, heuristic modules into adaptive, robust agentic
behavior. To support and accelerate future research, we consolidate the
landscape of open-source environments, benchmarks, and frameworks into a
practical compendium. By synthesizing over five hundred recent works, this
survey charts the contours of this rapidly evolving field and highlights the
opportunities and challenges that will shape the development of scalable,
general-purpose AI agents.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [189] [KG-RAG: Enhancing GUI Agent Decision-Making via Knowledge Graph-Driven Retrieval-Augmented Generation](https://arxiv.org/abs/2509.00366)
*Ziyi Guan,Jason Chun Lok Li,Zhijian Hou,Pingping Zhang,Donglai Xu,Yuzhi Zhao,Mengyang Wu,Jinpeng Chen,Thanh-Toan Nguyen,Pengfei Xian,Wenao Ma,Shengchao Qin,Graziano Chesi,Ngai Wong*

Main category: cs.MA

TL;DR: KG-RAG improves GUI agent performance by transforming UTGs into structured vector databases and generating actionable navigation paths, showing significant improvements in success rate, decision accuracy, and task efficiency.


<details>
  <summary>Details</summary>
Motivation: GUI agents powered by LLMs struggle with complex mobile tasks due to limited app-specific knowledge, and UTGs are underutilized due to poor extraction and inefficient integration.

Method: KG-RAG is a Knowledge Graph-driven Retrieval-Augmented Generation framework that transforms fragmented UTGs into structured vector databases for efficient real-time retrieval, using an intent-guided LLM search method to generate actionable navigation paths.

Result: KG-RAG outperforms existing methods, achieving a 75.8% success rate (8.9% improvement over AutoDroid), 84.6% decision accuracy (8.1% improvement), and reducing average task steps from 4.5 to 4.1. It also shows improvements on web/desktop platforms and has practical deployment trade-offs.

Conclusion: KG-RAG demonstrates significant improvements in GUI agent performance and can be effectively deployed in practical scenarios.

Abstract: Despite recent progress, Graphic User Interface (GUI) agents powered by Large
Language Models (LLMs) struggle with complex mobile tasks due to limited
app-specific knowledge. While UI Transition Graphs (UTGs) offer structured
navigation representations, they are underutilized due to poor extraction and
inefficient integration. We introduce KG-RAG, a Knowledge Graph-driven
Retrieval-Augmented Generation framework that transforms fragmented UTGs into
structured vector databases for efficient real-time retrieval. By leveraging an
intent-guided LLM search method, KG-RAG generates actionable navigation paths,
enhancing agent decision-making. Experiments across diverse mobile apps show
that KG-RAG outperforms existing methods, achieving a 75.8% success rate (8.9%
improvement over AutoDroid), 84.6% decision accuracy (8.1% improvement), and
reducing average task steps from 4.5 to 4.1. Additionally, we present
KG-Android-Bench and KG-Harmony-Bench, two benchmarks tailored to the Chinese
mobile ecosystem for future research. Finally, KG-RAG transfers to web/desktop
(+40% SR on Weibo-web; +20% on QQ Music-desktop), and a UTG cost ablation shows
accuracy saturates at ~4h per complex app, enabling practical deployment
trade-offs.

</details>


### [190] [ShortageSim: Simulating Drug Shortages under Information Asymmetry](https://arxiv.org/abs/2509.01813)
*Mingxuan Cui,Yilan Jiang,Duo Zhou,Cheng Qian,Yuji Zhang,Qiong Wang*

Main category: cs.MA

TL;DR: 本文提出了一种基于大型语言模型的多智能体模拟框架ShortageSim，用于研究药品短缺问题，并通过实验验证了其有效性。作者还开源了ShortageSim和一个包含2925个FDA短缺事件的数据集。


<details>
  <summary>Details</summary>
Motivation: 药品短缺对患者护理和全球医疗系统构成重大风险，但监管干预的有效性由于制药供应链中的信息不对称而难以理解。因此，需要一种新的方法来研究药品短缺问题并评估监管干预的效果。

Method: 本文使用基于大型语言模型的多智能体模拟框架ShortageSim来模拟药品制造商、机构买家和监管机构之间的复杂战略互动。该框架利用大型语言模型来模拟在不确定性下的有限理性决策，并通过顺序生产游戏来建模FDA公告对供应链的影响。

Result: 实验结果表明，ShortageSim在减少未披露病例的解决滞后百分比方面提高了83%，使模拟持续时间更接近真实情况。此外，作者开源了ShortageSim和一个包含2925个FDA短缺事件的数据集。

Conclusion: 本文提出了ShortageSim，这是一个基于大型语言模型的多智能体模拟框架，用于研究药品短缺问题，并通过实验验证了其有效性。此外，作者开源了ShortageSim和一个包含2925个FDA短缺事件的数据集，为设计和测试复杂、信息匮乏供应链中的干预措施提供了新的计算框架。

Abstract: Drug shortages pose critical risks to patient care and healthcare systems
worldwide, yet the effectiveness of regulatory interventions remains poorly
understood due to fundamental information asymmetries in pharmaceutical supply
chains. We present \textbf{ShortageSim}, the first Large Language Model
(LLM)-based multi-agent simulation framework that captures the complex,
strategic interactions between drug manufacturers, institutional buyers, and
regulatory agencies in response to shortage alerts. Unlike traditional
game-theoretic models that assume perfect rationality and complete information,
\textbf{ShortageSim} leverages LLMs to simulate bounded-rational
decision-making under uncertainty. Through a sequential production game
spanning multiple quarters, we model how FDA announcements, both reactive
alerts about existing shortages and proactive warnings about potential
disruptions, propagate through the supply chain and influence capacity
investment and procurement decisions. Our experiments on historical shortage
events reveal that \textbf{ShortageSim} reduces the resolution-lag percentage
for discontinued-disclosed cases by 83\%, bringing simulated durations more
aligned to ground truth than the zero-shot baseline. We open-source
\textbf{ShortageSim} and a dataset of 2,925 FDA shortage events at
https://github.com/Lemutisme/Sortage_Management, providing a novel
computational framework for designing and testing interventions in complex,
information-scarce supply chains.

</details>
