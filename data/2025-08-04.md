<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 45]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 3]
- [cs.CV](#cs.CV) [Total: 3]
- [q-fin.TR](#q-fin.TR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [PhysicsEval: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems](https://arxiv.org/abs/2508.00079)
*Oshayer Siddique,J. M Areeb Uzair Alam,Md Jobayer Rahman Rafy,Syed Rifat Raiyan,Hasan Mahmud,Md Kamrul Hasan*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The discipline of physics stands as a cornerstone of human intellect, driving
the evolution of technology and deepening our understanding of the fundamental
principles of the cosmos. Contemporary literature includes some works centered
on the task of solving physics problems - a crucial domain of natural language
reasoning. In this paper, we evaluate the performance of frontier LLMs in
solving physics problems, both mathematical and descriptive. We also employ a
plethora of inference-time techniques and agentic frameworks to improve the
performance of the models. This includes the verification of proposed solutions
in a cumulative fashion by other, smaller LLM agents, and we perform a
comparative analysis of the performance that the techniques entail. There are
significant improvements when the multi-agent framework is applied to problems
that the models initially perform poorly on. Furthermore, we introduce a new
evaluation benchmark for physics problems, ${\rm P{\small HYSICS}E{\small
VAL}}$, consisting of 19,609 problems sourced from various physics textbooks
and their corresponding correct solutions scraped from physics forums and
educational websites. Our code and data are publicly available at
https://github.com/areebuzair/PhysicsEval.

</details>


### [2] [Do LLMs produce texts with "human-like" lexical diversity?](https://arxiv.org/abs/2508.00086)
*Kelly Kendro,Jeffrey Maloney,Scott Jarvis*

Main category: cs.CL

TL;DR: 研究发现，LLM生成的文本在词汇多样性方面与人类写作存在显著差异，且较新的模型生成的文本更不接近人类写作。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨LLM生成的文本是否真正具有人类写作的特点，特别是从词汇多样性的角度来看。

Method: 研究从词汇多样性的角度出发，比较了四个ChatGPT模型（-3.5、-4、-o4 mini和-4.5）生成的文本与不同教育水平的母语（L1）和非母语（L2）英语参与者（n = 240）的文本。测量了六个维度的词汇多样性：数量、丰富度、种类-重复、均匀度、差异性和分布性。通过单因素MANOVA、单因素ANOVA和支持向量机分析了结果。

Result: LLM生成的文本在所有变量上都与人类写作有显著差异，其中ChatGPT-o4 mini和-4.5的差异最大。尽管ChatGPT-4.5生成的文本较少，但其词汇多样性更高。人类作者的词汇多样性在子群体（即教育程度、语言状态）之间没有差异。

Conclusion: 研究结果表明，LLM生成的文本在词汇多样性方面与人类写作存在显著差异，较新的LLM生成的文本更不接近人类写作。

Abstract: The degree to which LLMs produce writing that is truly human-like remains
unclear despite the extensive empirical attention that this question has
received. The present study addresses this question from the perspective of
lexical diversity. Specifically, the study investigates patterns of lexical
diversity in LLM-generated texts from four ChatGPT models (-3.5, -4, -o4 mini,
and -4.5) in comparison with texts written by L1 and L2 English participants (n
= 240) across four education levels. Six dimensions of lexical diversity were
measured in each text: volume, abundance, variety-repetition, evenness,
disparity, and dispersion. Results from one-way MANOVAs, one-way ANOVAS, and
Support Vector Machines revealed that the LLM-generated texts differed
significantly from human-written texts for each variable, with ChatGPT-o4 mini
and -4.5 differing the most. Within these two groups, ChatGPT-4.5 demonstrated
higher levels of lexical diversity despite producing fewer tokens. The human
writers' lexical diversity did not differ across subgroups (i.e., education,
language status). Altogether, the results indicate that LLMs do not produce
human-like texts in relation to lexical diversity, and the newer LLMs produce
less human-like texts than older models. We discuss the implications of these
results for language pedagogy and related applications.

</details>


### [3] [Semiotic Complexity and Its Epistemological Implications for Modeling Culture](https://arxiv.org/abs/2508.00095)
*Zachary K. Stine,James E. Deitrick*

Main category: cs.CL

TL;DR: 本文探讨了计算人文学科中建模工作的翻译问题，提出了语义复杂性的概念，并建议研究人员更好地考虑这些认识论问题。


<details>
  <summary>Details</summary>
Motivation: 为了确保内部一致性，避免微妙但重要的翻译错误，并促进解释的透明性，计算人文学科需要更多的理论化方法。

Method: 本文将建模工作视为在文化、语言领域和计算、数学领域之间进行翻译工作，并提出语义复杂性的概念。

Result: 本文指出了建模实践中缺乏理论化导致的翻译错误，并提出了针对这些认识论问题的建议。

Conclusion: 本文认为，计算人文学科需要更多的理论化方法来实现领域的成熟。

Abstract: Greater theorizing of methods in the computational humanities is needed for
epistemological and interpretive clarity, and therefore the maturation of the
field. In this paper, we frame such modeling work as engaging in translation
work from a cultural, linguistic domain into a computational, mathematical
domain, and back again. Translators benefit from articulating the theory of
their translation process, and so do computational humanists in their work --
to ensure internal consistency, avoid subtle yet consequential translation
errors, and facilitate interpretive transparency. Our contribution in this
paper is to lay out a particularly consequential dimension of the lack of
theorizing and the sorts of translation errors that emerge in our modeling
practices as a result. Along these lines we introduce the idea of semiotic
complexity as the degree to which the meaning of some text may vary across
interpretive lenses, and make the case that dominant modeling practices --
especially around evaluation -- commit a translation error by treating
semiotically complex data as semiotically simple when it seems
epistemologically convenient by conferring superficial clarity. We then lay out
several recommendations for researchers to better account for these
epistemological issues in their own work.

</details>


### [4] [FACTORY: A Challenging Human-Verified Prompt Set for Long-Form Factuality](https://arxiv.org/abs/2508.00109)
*Mingda Chen,Yang Li,Xilun Chen,Adina Williams,Gargi Ghosh,Scott Yih*

Main category: cs.CL

TL;DR: 本文介绍了FACTORY，一个大规模的人工验证提示集，用于评估模型生成准确、全面响应的能力。结果表明，FACTORY是一个具有挑战性的基准，显示出当前最先进的模型在事实性响应方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试往往缺乏人工验证，可能导致质量问题，因此需要一个大规模的人工验证提示集来评估模型生成准确、全面响应的能力。

Method: 使用模型在循环方法开发FACTORY，并由人类进行精炼，以创建具有挑战性的、事实寻求的、可回答且无歧义的提示集。

Result: 使用FACTORY和现有数据集对6个最先进的语言模型进行了人工评估，结果显示大约40%的SOTA模型响应中的声明不真实，而其他数据集只有10%。

Conclusion: FACTORY是一个具有挑战性的基准，表明当前最先进的模型在生成事实性响应方面存在不足，强调了模型需要在长尾事实上进行推理的必要性。

Abstract: Long-form factuality evaluation assesses the ability of models to generate
accurate, comprehensive responses to short prompts. Existing benchmarks often
lack human verification, leading to potential quality issues. To address this
limitation, we introduce FACTORY, a large-scale, human-verified prompt set.
Developed using a model-in-the-loop approach and refined by humans, FACTORY
includes challenging prompts that are fact-seeking, answerable, and
unambiguous. We conduct human evaluations on 6 state-of-the-art language models
using FACTORY and existing datasets. Our results show that FACTORY is a
challenging benchmark: approximately 40% of the claims made in the responses of
SOTA models are not factual, compared to only 10% for other datasets. Our
analysis identifies the strengths of FACTORY over prior benchmarks, emphasizing
its reliability and the necessity for models to reason across long-tailed
facts.

</details>


### [5] [Is neural semantic parsing good at ellipsis resolution, or isn't it?](https://arxiv.org/abs/2508.00121)
*Xiao Zhang,Johan bos*

Main category: cs.CL

TL;DR: 研究发现，神经语义解析器在处理英语动词短语省略等强上下文敏感现象时表现不佳。


<details>
  <summary>Details</summary>
Motivation: 研究神经语义解析器在处理强上下文敏感现象（如省略）时的表现，以评估其能力。

Method: 构建了一个包含120个省略案例及其完整语义表示的语料库，并将其用作神经语义解析器的挑战集。

Result: 尽管这些解析器在标准测试集中表现良好，但在涉及省略的实例中失败了。

Conclusion: 神经语义解析器在处理强上下文敏感现象（如英语动词短语省略）时表现不佳。

Abstract: Neural semantic parsers have shown good overall performance for a variety of
linguistic phenomena, reaching semantic matching scores of more than 90%. But
how do such parsers perform on strongly context-sensitive phenomena, where
large pieces of semantic information need to be duplicated to form a meaningful
semantic representation? A case in point is English verb phrase ellipsis, a
construct where entire verb phrases can be abbreviated by a single auxiliary
verb. Are the otherwise known as powerful semantic parsers able to deal with
ellipsis or aren't they? We constructed a corpus of 120 cases of ellipsis with
their fully resolved meaning representation and used this as a challenge set
for a large battery of neural semantic parsers. Although these parsers
performed very well on the standard test set, they failed in the instances with
ellipsis. Data augmentation

</details>


### [6] [Comparison of Large Language Models for Deployment Requirements](https://arxiv.org/abs/2508.00185)
*Alper Yaman,Jannik Schwab,Christof Nitsche,Abhirup Sinha,Marco Huber*

Main category: cs.CL

TL;DR: 本文提供了一个比较列表，帮助研究人员和公司选择最佳的大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 由于近年来出现了许多开源的基础模型和微调模型，这使得研究人员和公司选择最佳的大型语言模型变得复杂。

Method: 本文通过比较不同模型的特性，如发布年份、许可协议和硬件要求，来构建一个比较列表。

Result: 本文提供了一个比较列表，涵盖了基础模型和领域特定模型，并在GitLab上发布，将持续更新。

Conclusion: 本文提出了一种比较基础模型和领域特定模型的列表，以帮助研究人员和公司在选择大型语言模型时做出更好的决策。

Abstract: Large Language Models (LLMs), such as Generative Pre-trained Transformers
(GPTs) are revolutionizing the generation of human-like text, producing
contextually relevant and syntactically correct content. Despite challenges
like biases and hallucinations, these Artificial Intelligence (AI) models excel
in tasks, such as content creation, translation, and code generation.
Fine-tuning and novel architectures, such as Mixture of Experts (MoE), address
these issues. Over the past two years, numerous open-source foundational and
fine-tuned models have been introduced, complicating the selection of the
optimal LLM for researchers and companies regarding licensing and hardware
requirements. To navigate the rapidly evolving LLM landscape and facilitate LLM
selection, we present a comparative list of foundational and domain-specific
models, focusing on features, such as release year, licensing, and hardware
requirements. This list is published on GitLab and will be continuously
updated.

</details>


### [7] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: 本文分析了表格在大型语言模型中的重要性，并指出了当前研究中的关键问题。


<details>
  <summary>Details</summary>
Motivation: 由于表格的多样性和复杂性，现有的方法难以统一处理，因此需要更深入的研究。

Method: 本文通过分类法和任务介绍来分析表格输入表示和理解任务。

Result: 本文指出了当前研究中的几个关键差距，包括任务偏向于检索、处理复杂表格结构的困难以及模型泛化能力有限。

Conclusion: 本文提出了表格输入表示的分类法和表格理解任务的介绍，以解决表格理解任务中的挑战。

Abstract: Tables have gained significant attention in large language models (LLMs) and
multimodal large language models (MLLMs) due to their complex and flexible
structure. Unlike linear text inputs, tables are two-dimensional, encompassing
formats that range from well-structured database tables to complex,
multi-layered spreadsheets, each with different purposes. This diversity in
format and purpose has led to the development of specialized methods and tasks,
instead of universal approaches, making navigation of table understanding tasks
challenging. To address these challenges, this paper introduces key concepts
through a taxonomy of tabular input representations and an introduction of
table understanding tasks. We highlight several critical gaps in the field that
indicate the need for further research: (1) the predominance of
retrieval-focused tasks that require minimal reasoning beyond mathematical and
logical operations; (2) significant challenges faced by models when processing
complex table structures, large-scale tables, length context, or multi-table
scenarios; and (3) the limited generalization of models across different
tabular representations and formats.

</details>


### [8] [Semantic Compression for Word and Sentence Embeddings using Discrete Wavelet Transform](https://arxiv.org/abs/2508.00220)
*Rana Aref Salama,Abdou Youssef,Mona Diab*

Main category: cs.CL

TL;DR: 本文探讨了离散小波变换（DWT）在自然语言处理中的应用，展示了其在降低嵌入维度和保持性能方面的有效性。


<details>
  <summary>Details</summary>
Motivation: Wavelet transforms在信号和图像处理等领域已被广泛应用，但其在自然语言处理中的应用尚未得到充分探索。本文旨在展示DWT在分析嵌入表示和压缩嵌入方面的潜力。

Method: 本文利用离散小波变换（DWT）对词和句子嵌入进行实证研究，评估DWT在不同分辨率下分析嵌入表示和压缩嵌入的能力。

Result: 实验结果表明，DWT可以将嵌入的维度降低50-93%，同时在语义相似性任务中几乎不改变性能，并在大多数下游任务中实现了更高的准确性。

Conclusion: 我们的研究结果表明，DWT可以显著降低嵌入的维度，同时保持性能几乎不变，并在大多数下游任务中实现更高的准确性。这为将DWT应用于改进自然语言处理应用铺平了道路。

Abstract: Wavelet transforms, a powerful mathematical tool, have been widely used in
different domains, including Signal and Image processing, to unravel intricate
patterns, enhance data representation, and extract meaningful features from
data. Tangible results from their application suggest that Wavelet transforms
can be applied to NLP capturing a variety of linguistic and semantic
properties. In this paper, we empirically leverage the application of Discrete
Wavelet Transforms (DWT) to word and sentence embeddings. We aim to showcase
the capabilities of DWT in analyzing embedding representations at different
levels of resolution and compressing them while maintaining their overall
quality. We assess the effectiveness of DWT embeddings on semantic similarity
tasks to show how DWT can be used to consolidate important semantic information
in an embedding vector. We show the efficacy of the proposed paradigm using
different embedding models, including large language models, on downstream
tasks. Our results show that DWT can reduce the dimensionality of embeddings by
50-93% with almost no change in performance for semantic similarity tasks,
while achieving superior accuracy in most downstream tasks. Our findings pave
the way for applying DWT to improve NLP applications.

</details>


### [9] [Model Misalignment and Language Change: Traces of AI-Associated Language in Unscripted Spoken English](https://arxiv.org/abs/2508.00238)
*Bryce Anderson,Riley Galpin,Tom S. Juzek*

Main category: cs.CL

TL;DR: 研究发现，2022年后与大型语言模型相关的词汇使用显著增加，这可能表明人类用词选择与LLM相关模式的趋同。然而，这种变化是自然语言演变还是由AI暴露引发的新变化仍是一个开放问题。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨近年来书面语言（特别是在科学和教育领域）的词汇使用变化是否反映了更广泛的人类语言系统的变化，而不仅仅是AI直接生成文本的影响。

Method: 研究人员构建了一个包含2210万个单词的数据集，来源于未经脚本的口语语言，即科技和科学播客的对话。他们分析了ChatGPT发布前后的词汇趋势，重点关注常与LLM相关的词汇。

Result: 研究结果显示，2022年后与LLM相关的词汇使用有中等但显著的增加，而基线同义词没有明显的方向性变化。

Conclusion: 研究发现，2022年后与LLM相关的词汇使用显著增加，这可能表明人类用词选择与LLM相关模式的趋同。然而，这种变化是自然语言演变还是由AI暴露引发的新变化仍是一个开放问题。

Abstract: In recent years, written language, particularly in science and education, has
undergone remarkable shifts in word usage. These changes are widely attributed
to the growing influence of Large Language Models (LLMs), which frequently rely
on a distinct lexical style. Divergences between model output and target
audience norms can be viewed as a form of misalignment. While these shifts are
often linked to using Artificial Intelligence (AI) directly as a tool to
generate text, it remains unclear whether the changes reflect broader changes
in the human language system itself. To explore this question, we constructed a
dataset of 22.1 million words from unscripted spoken language drawn from
conversational science and technology podcasts. We analyzed lexical trends
before and after ChatGPT's release in 2022, focusing on commonly LLM-associated
words. Our results show a moderate yet significant increase in the usage of
these words post-2022, suggesting a convergence between human word choices and
LLM-associated patterns. In contrast, baseline synonym words exhibit no
significant directional shift. Given the short time frame and the number of
words affected, this may indicate the onset of a remarkable shift in language
use. Whether this represents natural language change or a novel shift driven by
AI exposure remains an open question. Similarly, although the shifts may stem
from broader adoption patterns, it may also be that upstream training
misalignments ultimately contribute to changes in human language use. These
findings parallel ethical concerns that misaligned models may shape social and
moral beliefs.

</details>


### [10] [Integrating clinical reasoning into large language model-based diagnosis through etiology-aware attention steering](https://arxiv.org/abs/2508.00285)
*Peixian Li,Yu Tian,Ruiqi Tu,Chengkai Wu,Jingjing Ren,Jingsong Li*

Main category: cs.CL

TL;DR: 本研究提出了一种基于病因感知注意引导框架的方法，以提高LLM在复杂临床场景中的诊断准确性和临床推理能力。通过构建临床推理支架并优化模型注意力，该方法在多个数据集上均表现出显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在医学文本理解和生成方面表现出显著的能力。然而，它们在复杂临床场景中的诊断可靠性仍然有限。本研究旨在提高LLMs的诊断准确性和临床推理能力。

Method: 我们提出了一个病因感知注意引导框架，以将结构化的临床推理整合到基于LLM的诊断中。首先，我们根据权威的临床指南为三种典型的急性腹部紧急情况构建了临床推理支架（CRS）。然后，我们开发了病因感知头识别算法，以确定模型病因推理的关键注意头。为了确保可靠的临床推理对齐，我们引入了推理引导的参数高效微调，将病因推理提示嵌入输入表示中，并通过推理引导损失函数引导选定的病因感知头关注关键信息。

Result: 在一致诊断队列上，我们的框架平均诊断准确率提高了15.65%，平均推理焦点得分提高了31.6%。在不一致诊断队列上的外部验证进一步证实了其在提高诊断准确性方面的有效性。通过推理注意频率的进一步评估表明，我们的模型在面对现实世界的复杂场景时表现出更高的可靠性。

Conclusion: 本研究提出了一种实用且有效的方法来增强基于LLM的诊断中的临床推理。通过将模型注意力与结构化的CRS对齐，所提出的框架为构建更可解释和可靠的AI诊断系统提供了一个有希望的范式。

Abstract: Objective: Large Language Models (LLMs) demonstrate significant capabilities
in medical text understanding and generation. However, their diagnostic
reliability in complex clinical scenarios remains limited. This study aims to
enhance LLMs' diagnostic accuracy and clinical reasoning ability. Method: We
propose an Etiology-Aware Attention Steering Framework to integrate structured
clinical reasoning into LLM-based diagnosis. Specifically, we first construct
Clinical Reasoning Scaffolding (CRS) based on authoritative clinical guidelines
for three representative acute abdominal emergencies: acute appendicitis, acute
pancreatitis, and acute cholecystitis. Next, we develop the Etiology-Aware Head
Identification algorithm to pinpoint attention heads crucial for the model's
etiology reasoning. To ensure reliable clinical reasoning alignment, we
introduce the Reasoning-Guided Parameter-Efficient Fine-tuning that embeds
etiological reasoning cues into input representations and steers the selected
Etiology-Aware Heads toward critical information through a Reasoning-Guided
Loss function. Result: On the Consistent Diagnosis Cohort, our framework
improves average diagnostic accuracy by 15.65% and boosts the average Reasoning
Focus Score by 31.6% over baselines. External validation on the Discrepant
Diagnosis Cohort further confirms its effectiveness in enhancing diagnostic
accuracy. Further assessments via Reasoning Attention Frequency indicate that
our models exhibit enhanced reliability when faced with real-world complex
scenarios. Conclusion: This study presents a practical and effective approach
to enhance clinical reasoning in LLM-based diagnosis. By aligning model
attention with structured CRS, the proposed framework offers a promising
paradigm for building more interpretable and reliable AI diagnostic systems in
complex clinical settings.

</details>


### [11] [Systematic Evaluation of Optimization Techniques for Long-Context Language Models](https://arxiv.org/abs/2508.00305)
*Ammar Ahmed,Sheng Di,Franck Cappello,Zirui Liu,Jingoo Han,Ali Anwar*

Main category: cs.CL

TL;DR: 本文系统评估了优化技术对大型语言模型的影响，发现简单组合算法可能在大型模型中导致问题，并强调了结合系统分析和任务特定洞察的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管已有优化技术可以缓解大型语言模型（LLMs）的资源需求和有限上下文窗口问题，但其在长上下文场景中的效果和系统评估仍缺乏深入研究。因此，本文旨在系统评估这些优化技术，并探索如何在不同任务和硬件配置中平衡效率、准确性和可扩展性。

Method: 本文系统地对剪枝、量化和令牌删除等优化技术进行了基准测试，分析了它们对内存使用、延迟和吞吐量的影响，并研究了这些方法如何影响文本生成的质量。此外，还评估了这些技术的组合效果，并探讨了在更大模型上的可扩展性。

Result: 实验结果表明，简单组合优化算法可能在大型模型中产生负面效果，因为累积的近似误差会显著影响性能。同时，仅依赖F1指标可能会掩盖精度-召回率权衡的问题。

Conclusion: 本文通过系统评估优化技术，揭示了在大型语言模型中简单组合推理优化算法可能导致累积近似误差的问题，并强调了结合系统级分析和任务特定洞察的重要性，以平衡效率、准确性和可扩展性。

Abstract: Large language models (LLMs) excel across diverse natural language processing
tasks but face resource demands and limited context windows. Although
techniques like pruning, quantization, and token dropping can mitigate these
issues, their efficacy in long-context scenarios and system evaluation remains
underexplored. This paper systematically benchmarks these optimizations,
characterizing memory usage, latency, and throughput, and studies how these
methods impact the quality of text generation. We first analyze individual
optimization methods for two LLM architectures supporting long context and then
systematically evaluate combinations of these techniques to assess how this
deeper analysis impacts performance metrics. We subsequently study the
scalability of individual optimization methods on a larger variant with 70
billion-parameter model. Our novel insights reveal that naive combination
inference optimization algorithms can adversely affect larger models due to
compounded approximation errors, as compared to their smaller counterparts.
Experiments show that relying solely on F1 obscures these effects by hiding
precision-recall trade-offs in question answering tasks. By integrating
system-level profiling with task-specific insights, this study helps LLM
practitioners and researchers explore and balance efficiency, accuracy, and
scalability across tasks and hardware configurations.

</details>


### [12] [Improving Multimodal Contrastive Learning of Sentence Embeddings with Object-Phrase Alignment](https://arxiv.org/abs/2508.00332)
*Kaiyan Zhao,Zhongtao Miao,Yoshimasa Tsuruoka*

Main category: cs.CL

TL;DR: 本文提出了一种名为MCSEO的方法，通过结合细粒度的对象短语对齐来增强多模态句子嵌入，并在语义文本相似性任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 多模态句子嵌入模型通常在训练中利用图像-标题对以及文本数据。然而，这样的对通常包含噪声，包括图像或标题侧的冗余或不相关信息。为了缓解这个问题，我们提出了MCSEO，一种通过结合细粒度的对象短语对齐来增强多模态句子嵌入的方法。

Method: MCSEO通过结合细粒度的对象短语对齐和传统的图像-标题对齐来增强多模态句子嵌入。具体来说，MCSEO利用现有的分割和目标检测模型提取准确的对象短语对，然后用于优化针对对象短语对应关系的对比学习目标。

Result: MCSEO在不同主干模型上的语义文本相似性(STS)任务实验结果表明，它始终优于强基线。

Conclusion: MCSEO在不同主干模型上的语义文本相似性(STS)任务实验结果表明，它始终优于强基线，突显了精确的对象短语对齐在多模态表示学习中的重要性。

Abstract: Multimodal sentence embedding models typically leverage image-caption pairs
in addition to textual data during training. However, such pairs often contain
noise, including redundant or irrelevant information on either the image or
caption side. To mitigate this issue, we propose MCSEO, a method that enhances
multimodal sentence embeddings by incorporating fine-grained object-phrase
alignment alongside traditional image-caption alignment. Specifically, MCSEO
utilizes existing segmentation and object detection models to extract accurate
object-phrase pairs, which are then used to optimize a contrastive learning
objective tailored to object-phrase correspondence. Experimental results on
semantic textual similarity (STS) tasks across different backbone models
demonstrate that MCSEO consistently outperforms strong baselines, highlighting
the significance of precise object-phrase alignment in multimodal
representation learning.

</details>


### [13] [PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning](https://arxiv.org/abs/2508.00344)
*Keer Lu,Chong Chen,Bin Cui,Huang Leng,Wentao Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种新的代理范式AdaPlan和训练框架PilotRL，以解决LLMs在复杂任务中的长期规划和执行协调问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有工作在将LLMs部署到基于代理的环境中面临挑战，ReAct范式在需要长期战略规划的复杂任务中效果有限，同时当前方法主要依赖监督微调，导致模型记忆既定任务完成轨迹，限制了其在新问题情境中的泛化能力。

Method: 引入了自适应全局计划代理范式AdaPlan，旨在结合高层显式指导与执行以支持有效的长期决策。基于该范式，提出了PilotRL，一个由渐进强化学习驱动的全局规划引导训练框架。

Result: PilotRL实现了最先进的性能，在参数规模相当的情况下，相比GPT-4o-mini取得了55.78%的显著提升。

Conclusion: 实验表明，PilotRL可以实现最先进的性能，LLaMA3.1-8B-Instruct + PilotRL在与闭源GPT-4o的比较中取得了3.60%的优势，而在与GPT-4o-mini的比较中则取得了55.78%的显著提升。

Abstract: Large Language Models (LLMs) have shown remarkable advancements in tackling
agent-oriented tasks. Despite their potential, existing work faces challenges
when deploying LLMs in agent-based environments. The widely adopted agent
paradigm ReAct centers on integrating single-step reasoning with immediate
action execution, which limits its effectiveness in complex tasks requiring
long-term strategic planning. Furthermore, the coordination between the planner
and executor during problem-solving is also a critical factor to consider in
agent design. Additionally, current approaches predominantly rely on supervised
fine-tuning, which often leads models to memorize established task completion
trajectories, thereby restricting their generalization ability when confronted
with novel problem contexts. To address these challenges, we introduce an
adaptive global plan-based agent paradigm AdaPlan, aiming to synergize
high-level explicit guidance with execution to support effective long-horizon
decision-making. Based on the proposed paradigm, we further put forward
PilotRL, a global planning-guided training framework for LLM agents driven by
progressive reinforcement learning. We first develop the model's ability to
follow explicit guidance from global plans when addressing agent tasks.
Subsequently, based on this foundation, we focus on optimizing the quality of
generated plans. Finally, we conduct joint optimization of the model's planning
and execution coordination. Experiments indicate that PilotRL could achieve
state-of-the-art performances, with LLaMA3.1-8B-Instruct + PilotRL surpassing
closed-sourced GPT-4o by 3.60%, while showing a more substantial gain of 55.78%
comparing to GPT-4o-mini at a comparable parameter scale.

</details>


### [14] [Lucy: edgerunning agentic web search on mobile with machine generated task vectors](https://arxiv.org/abs/2508.00360)
*Alan Dao,Dinh Bach Vu,Alex Nguyen,Norapat Buppodom*

Main category: cs.CL

TL;DR: 本文提出一种新的范式，将模型的内部推理视为动态任务向量机，并通过RLVR优化，成功训练了一个代理网络搜索模型，使小型语言模型在性能上可与大型模型媲美。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型在知识密集型任务中受到其容量限制，而现有的推理方法多为固定或启发式过程。

Method: 将模型的内部推理视为动态任务向量机，并通过RLVR优化，训练了一个代理网络搜索模型。

Result: Lucy模型在SimpleQA基准上实现了78.3%的准确率，性能与DeepSeek-V3相当。

Conclusion: 小型语言模型可以通过结构化的自我构建任务推理来与大型模型竞争。

Abstract: Small language models (SLMs) are inherently limited in knowledge-intensive
tasks due to their constrained capacity. While test-time computation offers a
path to enhanced performance, most approaches treat reasoning as a fixed or
heuristic process. In this work, we propose a new paradigm: viewing the model's
internal reasoning, delimited by <think> and </think> tags, as a dynamic task
vector machine. Rather than treating the content inside these tags as a mere
trace of thought, we interpret the generation process itself as a mechanism
through which the model \textbf{constructs and refines its own task vectors} on
the fly. We developed a method to optimize this dynamic task vector machine
through RLVR and successfully trained an agentic web-search model. We present
Lucy, a 1.7B-parameter SLM that leverages this dynamic reasoning mechanism with
MCP integration to achieve 78.3% accuracy on the SimpleQA benchmark, performing
on par with much larger models such as DeepSeek-V3. This demonstrates that
small models can rival large ones when equipped with structured,
self-constructed task reasoning.

</details>


### [15] [EdgeInfinite-Instruct: Bridging SFT-Based Optimization and NPU-Level Efficiency for Edge Devices](https://arxiv.org/abs/2508.00370)
*Jiyu Chen,Poh Seng Lim,Shuang Peng,Daxiong Luo,JungHau Foo,Yap Deep,Timothy Lee Jun Jie,Kelvin Teh Kae Wen,Fan Yang,Danyu Feng,Hao-Yun Chen,Peng-Wen Chen,Fangyuan Li,Xiaoxin Chen,Wong Wai Mun*

Main category: cs.CL

TL;DR: 本文提出EdgeInfinite-Instruct，通过分段监督微调和优化部署策略，提高长序列任务在边缘设备上的性能和效率。


<details>
  <summary>Details</summary>
Motivation: EdgeInfinite在指令遵循能力和移动特定优化方面存在不足，需要改进以适应长序列任务和边缘设备的需求。

Method: 我们提出了EdgeInfinite-Instruct，引入了一种针对长序列任务的分段监督微调（S-SFT）策略，并通过细粒度的训练后量化（PTQ）和固定形状计算图优化了EdgeInfinite-Instruct的部署效率。

Result: 实验表明，我们的方法在长上下文基准和真实世界移动任务中提高了特定领域的性能，同时保持了NPU加速边缘设备的效率。

Conclusion: 我们的方法在NPU加速的边缘设备上保持了效率的同时，提高了特定领域的性能。

Abstract: Deploying Transformer-based large language models (LLMs) on
resource-constrained edge devices for long-sequence tasks remains challenging
due to the quadratic time complexity of self-attention and growing Key-Value
(KV) cache demands. While existing KV cache optimizations improve memory
efficiency, they often fail to reduce time to first token (TTFT) and may
degrade performance through token pruning. Alternative sequence modeling
architectures address some of these limitations, but typically require full
retraining and lack infrastructure support. EdgeInfinite offers an efficient
solution by fine-tuning only a small subset of parameters, maintaining quality
while reducing both computational and memory costs, including improved TTFT.
However, its instruction-following ability is limited, and it lacks
mobile-specific optimizations. To address these issues, we propose
EdgeInfinite-Instruct, which introduces a Segmented Supervised Fine-Tuning
(S-SFT) strategy tailored to long-sequence tasks such as summarization and
question answering. We further optimized EdgeInfinite-Instruct for efficient
deployment on edge NPUs by employing fine-grained post-training quantization
(PTQ) to reduce computational demands while maintaining accuracy, and by
implementing a fixed-shape computation graph that balances memory usage and
on-device efficiency through scenario-specific customization of input token and
cache sizes. Experiments on long-context benchmarks and real-world mobile tasks
show that our approach improves domain-specific performance while maintaining
efficiency on NPU-accelerated edge devices.

</details>


### [16] [Multi-Layer Attention is the Amplifier of Demonstration Effectiveness](https://arxiv.org/abs/2508.00385)
*Dingzirui Wang,Xuangliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 本文研究了ICL中演示无效的原因，并提出了一种基于梯度流的演示选择方法GradS，在多个大型语言模型上进行了验证，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要假设ICL中的演示有效，但许多研究指出并非所有演示都有效，无法在ICL中带来性能提升。因此，本文研究演示无效的原因，并提出一种新的演示选择方法。

Method: 基于梯度流和线性自注意力模型进行分析，通过将梯度流设为零，推导出演示无效的原因，并提出了一种名为GradS的新方法，利用梯度流进行演示选择。

Result: 实验结果确认了随着模型层数增加，演示效果的差异被放大，验证了推导。GradS在平均上相对于最强基线实现了6.8%的相对提升。

Conclusion: 实验结果证实了随着模型层数增加，演示效果的差异会被放大，验证了我们的推导。此外，GradS在平均上相对于最强基线实现了6.8%的相对提升，证明了其有效性。

Abstract: Numerous studies have investigated the underlying mechanisms of in-context
learning (ICL) effectiveness to inspire the design of related methods. However,
existing work predominantly assumes the effectiveness of the demonstrations
provided within ICL, while many research indicates that not all demonstrations
are effective, failing to yielding any performance improvement during ICL.
Therefore, in this paper, we investigate the reasons behind demonstration
ineffectiveness. Our analysis is based on gradient flow and linear
self-attention models. By setting the gradient flow to zero, we deduce that a
demonstration becomes ineffective if its information has either been learned by
the model or is irrelevant to the user query. Furthermore, we demonstrate that
in multi-layer models, the disparity in effectiveness among demonstrations is
amplified with layer increasing, causing the model to focus more on effective
ones. Considering that current demonstration selection methods primarily focus
on the relevance to the user query while overlooking the information that the
model has already assimilated, we propose a novel method called GradS, which
leverages gradient flow for demonstration selection. We use the magnitude of
the gradient flow of the demonstration with respect to a given user query as
the criterion, thereby ensuring the effectiveness of the chosen ones. We
validate our derivation and GradS on four prominent LLMs across five mainstream
datasets. The experimental results confirm that the disparity in effectiveness
among demonstrations is magnified as the model layer increases, substantiating
our derivations. Moreover, GradS achieves a relative improvement of $6.8\%$ on
average over the strongest baselines, demonstrating its effectiveness.

</details>


### [17] [SA-GCS: Semantic-Aware Gaussian Curriculum Scheduling for UAV Vision-Language Navigation](https://arxiv.org/abs/2508.00390)
*Hengxing Cai,Jinhan Dong,Yijie Rao,Jingcheng Deng,Jingjun Tan,Qien Chen,Haidong Wang,Zhen Wang,Shiyu Huang,Agachai Sumalee,Renxin Zhong*

Main category: cs.CL

TL;DR: 本文提出了一种新的训练框架SA-GCS，通过整合课程学习和强化学习，提高了UAV视觉语言导航任务的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法在数据利用效率、收敛速度和样本难度考虑方面存在不足，限制了性能提升。

Method: SA-GCS结合了课程学习（CL）和强化学习（RL），通过语义感知难度估计器（SA-DE）和高斯课程调度器（GCS）来优化训练过程。

Result: SA-GCS在CityNav基准测试中优于所有基线，表现出更快和更稳定的收敛性，并且在不同规模的模型上都能良好泛化。

Conclusion: SA-GCS在CityNav基准测试中表现出色，展示了其鲁棒性和可扩展性。

Abstract: Unmanned Aerial Vehicle (UAV) Vision-Language Navigation (VLN) aims to enable
agents to accurately localize targets and plan flight paths in complex
environments based on natural language instructions, with broad applications in
intelligent inspection, disaster rescue, and urban monitoring. Recent progress
in Vision-Language Models (VLMs) has provided strong semantic understanding for
this task, while reinforcement learning (RL) has emerged as a promising
post-training strategy to further improve generalization. However, existing RL
methods often suffer from inefficient use of training data, slow convergence,
and insufficient consideration of the difficulty variation among training
samples, which limits further performance improvement. To address these
challenges, we propose \textbf{Semantic-Aware Gaussian Curriculum Scheduling
(SA-GCS)}, a novel training framework that systematically integrates Curriculum
Learning (CL) into RL. SA-GCS employs a Semantic-Aware Difficulty Estimator
(SA-DE) to quantify the complexity of training samples and a Gaussian
Curriculum Scheduler (GCS) to dynamically adjust the sampling distribution,
enabling a smooth progression from easy to challenging tasks. This design
significantly improves training efficiency, accelerates convergence, and
enhances overall model performance. Extensive experiments on the CityNav
benchmark demonstrate that SA-GCS consistently outperforms strong baselines
across all metrics, achieves faster and more stable convergence, and
generalizes well across models of different scales, highlighting its robustness
and scalability. The implementation of our approach is publicly available.

</details>


### [18] [Combining Discrete Wavelet and Cosine Transforms for Efficient Sentence Embedding](https://arxiv.org/abs/2508.00420)
*Rana Salama,Abdou Youssef,Mona Diab*

Main category: cs.CL

TL;DR: 本文研究了将小波变换应用于自然语言处理任务，提出了一种结合小波和余弦变换的非参数化模型，用于压缩句子嵌入，并在多个任务中取得了优异的结果。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索小波技术在自然语言处理任务中的应用，特别是如何有效利用小波来整合重要信息并降低词向量的维度。

Method: 本文利用离散小波变换（DWT）对词和句子嵌入进行处理，并结合离散余弦变换（DCT）提出了一种非参数化模型，以固定大小的向量压缩包含大量信息的句子。

Result: 实验结果表明，所提出的范式在下游应用模型中表现出色，取得了与原始嵌入相当甚至更优的结果。

Conclusion: 本文展示了所提出的范式在下游应用模型上的有效性，其结果与原始嵌入相当甚至在某些任务中更优。

Abstract: Wavelets have emerged as a cutting edge technology in a number of fields.
Concrete results of their application in Image and Signal processing suggest
that wavelets can be effectively applied to Natural Language Processing (NLP)
tasks that capture a variety of linguistic properties. In this paper, we
leverage the power of applying Discrete Wavelet Transforms (DWT) to word and
sentence embeddings. We first evaluate, intrinsically and extrinsically, how
wavelets can effectively be used to consolidate important information in a word
vector while reducing its dimensionality. We further combine DWT with Discrete
Cosine Transform (DCT) to propose a non-parameterized model that compresses a
sentence with a dense amount of information in a fixed size vector based on
locally varying word features. We show the efficacy of the proposed paradigm on
downstream applications models yielding comparable and even superior (in some
tasks) results to original embeddings.

</details>


### [19] [ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network](https://arxiv.org/abs/2508.00429)
*Minghao Guo,Xi Zhu,Jingyuan Huang,Kai Mei,Yongfeng Zhang*

Main category: cs.CL

TL;DR: ReaGAN是一种基于代理的框架，通过节点级决策和检索增强生成来解决图学习中的信息不平衡和全局关系不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有的固定方案无法处理节点信息量的不平衡，并且主要依赖局部结构相似性，忽略了图中的全局语义关系，限制了模型捕捉远距离但相关信息的能力。

Method: ReaGAN是一种基于代理的框架，每个节点都具有自主的节点级决策能力。每个节点作为代理，根据其内部记忆独立计划下一步行动，实现节点级规划和自适应信息传播。此外，检索增强生成（RAG）使节点能够访问语义相关的上下文并构建图中的全局关系。

Result: ReaGAN在少样本上下文设置中使用冻结的LLM主干取得了竞争性的性能，无需微调。

Conclusion: ReaGAN展示了代理规划和本地-全局检索在图学习中的潜力。

Abstract: Graph Neural Networks (GNNs) have achieved remarkable success in graph-based
learning by propagating information among neighbor nodes via predefined
aggregation mechanisms. However, such fixed schemes often suffer from two key
limitations. First, they cannot handle the imbalance in node informativeness --
some nodes are rich in information, while others remain sparse. Second,
predefined message passing primarily leverages local structural similarity
while ignoring global semantic relationships across the graph, limiting the
model's ability to capture distant but relevant information. We propose
Retrieval-augmented Graph Agentic Network (ReaGAN), an agent-based framework
that empowers each node with autonomous, node-level decision-making. Each node
acts as an agent that independently plans its next action based on its internal
memory, enabling node-level planning and adaptive message propagation.
Additionally, retrieval-augmented generation (RAG) allows nodes to access
semantically relevant content and build global relationships in the graph.
ReaGAN achieves competitive performance under few-shot in-context settings
using a frozen LLM backbone without fine-tuning, showcasing the potential of
agentic planning and local-global retrieval in graph learning.

</details>


### [20] [Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges](https://arxiv.org/abs/2508.00454)
*Yuqi Tang,Kehua Feng,Yunfeng Wang,Zhiwen Chen,Chengfei Lv,Gang Yu,Qiang Zhang,Keyan Ding*

Main category: cs.CL

TL;DR: 本文提出了一种高效的多轮对话评估器，通过聚合多个LLM法官的偏好知识，减少了评估成本，同时保持了多法官反馈的优势，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前主流方法依赖于'LLM-as-a-judge'范式，但存在各种偏差，影响评估结果的可靠性和一致性。多法官方法虽然有效，但计算开销大。因此，需要一种更高效的方法来减少评估成本。

Method: 本文提出了一种高效的多轮对话评估器，通过将多个LLM法官的偏好知识聚合到一个模型中来捕捉集体智慧。

Result: 实验结果表明，本文方法在七个单评分和成对比较对话评估基准上优于现有基线，展示了其效率和鲁棒性。

Conclusion: 本文提出了一种高效的多轮对话评估器，通过将多个LLM法官的偏好知识聚合到一个模型中来捕捉集体智慧。该方法在保持多样化的多法官反馈优势的同时，大幅降低了评估成本，实现了快速和灵活的对话质量评估。实验结果表明，该方法在多种场景下优于现有基线，展示了其效率和鲁棒性。

Abstract: Evaluating the conversational abilities of large language models (LLMs)
remains a challenging task. Current mainstream approaches primarily rely on the
``LLM-as-a-judge" paradigm, where an LLM is prompted to serve as an evaluator
to assess dialogue quality. However, such methods often suffer from various
biases, which undermine the reliability and consistency of the evaluation
results. To mitigate these biases, recent methods employ multiple LLMs as
judges and aggregate their judgments to select the optimal assessment. Although
effective, this multi-judge approach incurs significant computational overhead
during inference. In this paper, we propose an efficient multi-turn dialogue
evaluator that captures the collective wisdom of multiple LLM judges by
aggregating their preference knowledge into a single model. Our approach
preserves the advantages of diverse multi-judge feedback while drastically
reducing the evaluation cost, enabling fast and flexible dialogue quality
assessment. Extensive experiments on seven single rating and pairwise
comparison dialogue evaluation benchmarks demonstrate that our method
outperforms existing baselines across diverse scenarios, showcasing its
efficiency and robustness.

</details>


### [21] [GETALP@AutoMin 2025: Leveraging RAG to Answer Questions based on Meeting Transcripts](https://arxiv.org/abs/2508.00476)
*Jeongwoo Kang,Markarit Vartampetian,Felix Herron,Yongxin Zhou,Diandra Fabre,Gabriela Gonzalez-Saez*

Main category: cs.CL

TL;DR: This paper documents GETALP's submission to the Third Run of the Automatic Minuting Shared Task at SIGDial 2025. We participated in Task B: question-answering based on meeting transcripts. Our method is based on a retrieval augmented generation (RAG) system and Abstract Meaning Representations (AMR). We propose three systems combining these two approaches. Our results show that incorporating AMR leads to high-quality responses for approximately 35% of the questions and provides notable improvements in answering questions that involve distinguishing between different participants (e.g., who questions).


<details>
  <summary>Details</summary>
Motivation: participated in Task B: question-answering based on meeting transcripts

Method: retrieval augmented generation (RAG) system and Abstract Meaning Representations (AMR)

Result: Our results show that incorporating AMR leads to high-quality responses for approximately 35% of the questions and provides notable improvements in answering questions that involve distinguishing between different participants (e.g., who questions).

Conclusion:  incorporating AMR leads to high-quality responses for approximately 35% of the questions and provides notable improvements in answering questions that involve distinguishing between different participants.

Abstract: This paper documents GETALP's submission to the Third Run of the Automatic
Minuting Shared Task at SIGDial 2025. We participated in Task B:
question-answering based on meeting transcripts. Our method is based on a
retrieval augmented generation (RAG) system and Abstract Meaning
Representations (AMR). We propose three systems combining these two approaches.
Our results show that incorporating AMR leads to high-quality responses for
approximately 35% of the questions and provides notable improvements in
answering questions that involve distinguishing between different participants
(e.g., who questions).

</details>


### [22] [The Missing Parts: Augmenting Fact Verification with Half-Truth Detection](https://arxiv.org/abs/2508.00489)
*Yixuan Tang,Jincheng Wang,Anthony K. H. Tung*

Main category: cs.CL

TL;DR: 本文介绍了半真检测任务，并提出了PolitiFact-Hidden基准和TRACER框架，以解决因遗漏关键上下文而导致的半真声明问题。


<details>
  <summary>Details</summary>
Motivation: 现有的模型在处理半真半假的声明时表现不佳，因为它们没有设计用于推理未说的内容。

Method: 提出TRACER，一个模块化的重新评估框架，通过对齐证据、推断隐含意图和估计隐藏内容的因果影响来识别基于遗漏的虚假信息。

Result: TRACER能够集成到现有的事实核查流程中，并在多个强基线中一致地提高性能，显著提升了Half-True分类的F1分数。

Conclusion: TRACER可以集成到现有的事实核查流程中，并在多个强基线中一致地提高性能，显著提升了Half-True分类的F1分数，突显了建模遗漏的重要性以实现可信的事实验证。

Abstract: Fact verification systems typically assess whether a claim is supported by
retrieved evidence, assuming that truthfulness depends solely on what is
stated. However, many real-world claims are half-truths, factually correct yet
misleading due to the omission of critical context. Existing models struggle
with such cases, as they are not designed to reason about what is left unsaid.
We introduce the task of half-truth detection, and propose PolitiFact-Hidden, a
new benchmark with 15k political claims annotated with sentence-level evidence
alignment and inferred claim intent. To address this challenge, we present
TRACER, a modular re-assessment framework that identifies omission-based
misinformation by aligning evidence, inferring implied intent, and estimating
the causal impact of hidden content. TRACER can be integrated into existing
fact-checking pipelines and consistently improves performance across multiple
strong baselines. Notably, it boosts Half-True classification F1 by up to 16
points, highlighting the importance of modeling omissions for trustworthy fact
verification.

</details>


### [23] [EFlat-LoRA: Efficiently Seeking Flat Minima for Better Generalization in Fine-Tuning Large Language Models and Beyond](https://arxiv.org/abs/2508.00522)
*Jiaxin Deng,Qingcheng Zhu,Junbiao Pang,Linlin Yang,Zhongqian Fu,Baochang Zhang*

Main category: cs.CL

TL;DR: This paper proposes EFlat-LoRA to seek flat minima for LoRA, achieving better performance and efficiency compared to LoRA and full fine-tuning.


<details>
  <summary>Details</summary>
Motivation: To explore the correlation between expressive ability and generalization ability of LoRA, and to address the lack of tools to empirically seek flat minima or develop theoretical methods for LoRA.

Method: Proposed Flat-LoRA and its efficient version EFlat-LoRA to seek flat minima for LoRA, and theoretically demonstrated that perturbations in the full parameter space can be transferred to the low-rank subspace.

Result: EFlat-LoRA achieves optimize efficiency comparable to that of LoRA while simultaneously attaining comparable or even better performance. For example, on the GLUE dataset with RoBERTa-large, EFlat-LoRA outperforms LoRA and full fine-tuning by 1.0% and 0.5% on average, respectively. On vision-language models, it shows performance improvements of 1.5% and 1.0% on SQA and VizWiz datasets, respectively.

Conclusion: EFlat-LoRA achieves optimize efficiency comparable to that of LoRA while simultaneously attaining comparable or even better performance, and the generalization of LoRA is closely related to sharpness.

Abstract: Little research explores the correlation between the expressive ability and
generalization ability of the low-rank adaptation (LoRA). Sharpness-Aware
Minimization (SAM) improves model generalization for both Convolutional Neural
Networks (CNNs) and Transformers by encouraging convergence to locally flat
minima. However, the connection between sharpness and generalization has not
been fully explored for LoRA due to the lack of tools to either empirically
seek flat minima or develop theoretical methods. In this work, we propose
Flat-LoRA and its efficient version i.e., EFlat-LoRA, to seek flat minima for
LoRA. Concretely, we theoretically demonstrate that perturbations in the full
parameter space can be transferred to the low-rank subspace. This approach
eliminates the potential interference introduced by perturbations across
multiple matrices in the low-rank subspace. Our extensive experiments on large
language models and vision-language models demonstrate that EFlat-LoRA achieves
optimize efficiency comparable to that of LoRA while simultaneously attaining
comparable or even better performance. For example, on the GLUE dataset with
RoBERTa-large, EFlat-LoRA outperforms LoRA and full fine-tuning by 1.0% and
0.5% on average, respectively. On vision-language models e.g., Qwen-VL-Chat
shows performance improvements of 1.5% and 1.0% on SQA and VizWiz datasets,
respectively. These empirical results also verify that the generalization of
LoRA is closely related to sharpness, which is omitted by previous methods.

</details>


### [24] [The Prosody of Emojis](https://arxiv.org/abs/2508.00537)
*Giulio Zhou,Tsz Kin Lam,Alexandra Birch,Barry Haddow*

Main category: cs.CL

TL;DR: 本研究分析了表情符号如何影响语音中的语调实现以及听众如何解释语调线索来理解表情符号的含义，发现表情符号可以作为语调意图的载体。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨表情符号如何影响语音中的语调实现，以及听众如何解释语调线索以恢复表情符号的含义。

Method: 本研究通过结构化但开放式的生成和感知任务收集实际的人类语音数据，直接将语调和表情符号联系起来进行分析。

Result: 结果表明，说话者会根据表情符号提示调整他们的语调，听众通常可以从语调变化中识别出预期的表情符号，并且表情符号之间的语义差异越大，语调差异就越大。

Conclusion: 这些发现表明，表情符号可以作为语调意图的有意义载体，为它们在数字媒介环境中的交际作用提供了见解。

Abstract: Prosodic features such as pitch, timing, and intonation are central to spoken
communication, conveying emotion, intent, and discourse structure. In
text-based settings, where these cues are absent, emojis act as visual
surrogates that add affective and pragmatic nuance. This study examines how
emojis influence prosodic realisation in speech and how listeners interpret
prosodic cues to recover emoji meanings. Unlike previous work, we directly link
prosody and emoji by analysing actual human speech data, collected through
structured but open-ended production and perception tasks. This provides
empirical evidence of how emoji semantics shape spoken delivery and perception.
Results show that speakers adapt their prosody based on emoji cues, listeners
can often identify the intended emoji from prosodic variation alone, and
greater semantic differences between emojis correspond to increased prosodic
divergence. These findings suggest that emojis can act as meaningful carriers
of prosodic intent, offering insight into their communicative role in digitally
mediated contexts.

</details>


### [25] [PaPaformer: Language Model from Pre-trained Paraller Paths](https://arxiv.org/abs/2508.00544)
*Joonas Tapaninaho,Mourad Oussala*

Main category: cs.CL

TL;DR: 本文提出了 PaPaformer，一种解码器-only transformer 架构变体，通过将低维并行路径组合成更大的模型，实现了在几小时内而不是几天/几周内训练和评估语言模型。该方法可以减少模型参数总数和训练时间，同时提高性能，并为定制特定任务需求的路径提供了可能性。


<details>
  <summary>Details</summary>
Motivation: 现代大型语言模型的训练需要越来越多的计算能力和时间。即使是较小的变体，如小型语言模型（SLMs），在最佳情况下也需要几天的时间进行训练，通常需要多个 GPU。因此，本文旨在探索在几小时内而不是几天/几周内训练和评估解码器-only transformer 基础语言模型的方法。

Method: 本文提出了 PaPaformer，一种解码器-only transformer 架构变体，其低维并行路径被组合成更大的模型。这些低维路径可以使用不同类型的训练数据单独训练，然后组合成一个更大的模型。

Result: 本文展示了低维路径可以使用不同类型的训练数据单独训练，然后组合成一个更大的模型。这种方法可以减少模型参数总数和训练时间，同时提高性能。此外，并行路径结构还为定制特定任务需求的路径提供了有趣的可能性。

Conclusion: 本文提出了一种新的解码器-only transformer 架构变体 PaPaformer，通过将低维并行路径组合成更大的模型，实现了在几小时内而不是几天/几周内训练和评估语言模型。该方法可以减少模型参数总数和训练时间，同时提高性能，并为定制特定任务需求的路径提供了可能性。

Abstract: The training of modern large-language models requires an increasingly amount
of computation power and time. Even smaller variants, such as small-language
models (SLMs), take several days to train in the best-case scenarios, often
requiring multiple GPUs. This paper explores methods to train and evaluate
decoder-only transformer-based language models in hours instead of days/weeks.
We introduces \textit{PaPaformer}, a decoder-only transformer architecture
variant, whose lower-dimensional parallel paths are combined into larger model.
The paper shows that these lower-dimensional paths can be trained individually
with different types of training data and then combined into one larger model.
This method gives the option to reduce the total number of model parameters and
the training time with increasing performance. Moreover, the use of parallel
path structure opens interesting possibilities to customize paths to
accommodate specific task requirements.

</details>


### [26] [SynAdapt: Learning Adaptive Reasoning in Large Language Models via Synthetic Continuous Chain-of-Thought](https://arxiv.org/abs/2508.00574)
*Jianwei Wang,Ziming Wu,Fuming Lai,Shaobing Lian,Ziqian Zeng*

Main category: cs.CL

TL;DR: 本文提出了一种名为SynAdapt的高效推理框架，通过生成合成连续思维链（CCoT）作为对齐目标，并结合难度分类器来识别难题，从而提高了模型在解决难题时的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的连续思维链（CCoT）方法存在间接微调、有限对齐或不一致目标的问题，因此需要一种更高效的推理框架来克服这些限制。

Method: 本文提出了一种名为SynAdapt的高效推理框架，利用合成连续思维链（CCoT）作为对齐目标，并引入了一个难度分类器来识别难题，然后自适应地提示模型重新思考这些难题以提高性能。

Result: 实验结果表明，SynAdapt在多个不同难度水平的基准测试中表现优异，实现了最佳的准确性与效率平衡。

Conclusion: 本文提出了一种名为SynAdapt的高效推理框架，通过生成合成连续思维链（CCoT）作为对齐目标，提高了模型在解决难题时的性能和效率。实验结果表明，该方法在不同难度水平的基准测试中表现出色，实现了最佳的准确性与效率平衡。

Abstract: While Chain-of-Thought (CoT) reasoning improves model performance, it incurs
significant time costs due to the generation of discrete CoT tokens (DCoT).
Continuous CoT (CCoT) offers a more efficient alternative, but existing CCoT
methods are hampered by indirect fine-tuning, limited alignment, or
inconsistent targets. To overcome these limitations, we propose
\textit{SynAdapt}, an innovative efficient reasoning framework. Specifically,
\textit{SynAdapt} generates the synthetic CCoT to serve as a precise and
effective alignment target for LLMs. This synthetic CCoT explicitly guides the
LLM to learn CCoT and derive accurate answers directly. Furthermore, relying
solely on CCoT is insufficient for solving hard questions. To address this,
\textit{SynAdapt} integrates a difficulty classifier that leverages both
question context and CCoT to identify hard questions. CCoT can effectively help
identify hard questions after some brief reasoning. We then adaptively prompt
the LLM to re-think these hard questions for improved performance. Extensive
experimental results across various benchmarks from different difficulty levels
strongly demonstrate the effectiveness of our method, achieving the best
accuracy-efficiency trade-off.

</details>


### [27] [A Context-Aware Dual-Metric Framework for Confidence Estimation in Large Language Models](https://arxiv.org/abs/2508.00600)
*Mingruo Yuan,Shuyi Zhang,Ben Kao*

Main category: cs.CL

TL;DR: 本文提出了CRUX框架，通过整合上下文忠实度和一致性进行置信度估计，实验证明其在多个数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM置信度估计方法忽视了响应与上下文信息之间的相关性，这是输出质量评估中的关键因素，尤其是在提供背景知识的场景中。

Method: CRUX框架通过两个新颖的指标整合了上下文忠实度和一致性进行置信度估计。首先，上下文熵减少通过对比采样有无上下文的信息增益来表示数据不确定性。其次，统一的一致性检查通过生成答案与有无上下文的全局一致性来捕捉模型不确定性。

Result: CRUX在三个基准数据集（CoQA、SQuAD、QuAC）和两个领域特定数据集（BioASQ、EduQG）上的实验表明其有效性。

Conclusion: CRUX在多个基准数据集和领域特定数据集中表现出色，实现了比现有基线更高的AUROC。

Abstract: Accurate confidence estimation is essential for trustworthy large language
models (LLMs) systems, as it empowers the user to determine when to trust
outputs and enables reliable deployment in safety-critical applications.
Current confidence estimation methods for LLMs neglect the relevance between
responses and contextual information, a crucial factor in output quality
evaluation, particularly in scenarios where background knowledge is provided.
To bridge this gap, we propose CRUX (Context-aware entropy Reduction and
Unified consistency eXamination), the first framework that integrates context
faithfulness and consistency for confidence estimation via two novel metrics.
First, contextual entropy reduction represents data uncertainty with the
information gain through contrastive sampling with and without context. Second,
unified consistency examination captures potential model uncertainty through
the global consistency of the generated answers with and without context.
Experiments across three benchmark datasets (CoQA, SQuAD, QuAC) and two
domain-specific datasets (BioASQ, EduQG) demonstrate CRUX's effectiveness,
achieving the highest AUROC than existing baselines.

</details>


### [28] [GHTM: A Graph based Hybrid Topic Modeling Approach in Low-Resource Bengali Language](https://arxiv.org/abs/2508.00605)
*Farhana Haque,Md. Abdur Rahman,Sumon Ahmed*

Main category: cs.CL

TL;DR: 本文提出了一种基于图卷积网络的孟加拉语主题建模模型GHTM，并在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于孟加拉语的形态复杂性、缺乏足够的资源和举措，主题建模在孟加拉语中研究不足。因此，需要一种新的方法来改进孟加拉语的主题建模。

Method: 提出了一种基于图卷积网络（GCN）的模型GHTM，该模型将文档的输入向量表示为图中的节点，并使用GCN生成语义丰富的嵌入。然后通过非负矩阵分解（NMF）对嵌入进行分解，以获得文本语料库中潜在主题的代表性。

Result: 所提出的模型在三个孟加拉语数据集上与一系列孟加拉语主题建模技术进行了比较，包括传统的LDA、LSA和NMF，以及现代框架如BERTopic和Top2Vec。实验结果表明该模型在主题连贯性和多样性方面表现优异。

Conclusion: 实验结果表明所提出的模型在主题连贯性和多样性方面优于其他模型。

Abstract: Topic modeling is a Natural Language Processing (NLP) technique that is used
to identify latent themes and extract topics from text corpora by grouping
similar documents based on their most significant keywords. Although widely
researched in English, topic modeling remains understudied in Bengali due to
its morphological complexity, lack of adequate resources and initiatives. In
this contribution, a novel Graph Convolutional Network (GCN) based model called
GHTM (Graph-Based Hybrid Topic Model) is proposed. This model represents input
vectors of documents as nodes in the graph, which GCN uses to produce
semantically rich embeddings. The embeddings are then decomposed using
Non-negative Matrix Factorization (NMF) to get the topical representations of
the underlying themes of the text corpus. This study compares the proposed
model against a wide range of Bengali topic modeling techniques, from
traditional methods such as LDA, LSA, and NMF to contemporary frameworks such
as BERTopic and Top2Vec on three Bengali datasets. The experimental results
demonstrate the effectiveness of the proposed model by outperforming other
models in topic coherence and diversity. In addition, we introduce a novel
Bengali dataset called "NCTBText" sourced from Bengali textbook materials to
enrich and diversify the predominantly newspaper-centric Bengali corpora.

</details>


### [29] [Prompting Science Report 3: I'll pay you or I'll kill you -- but will you care?](https://arxiv.org/abs/2508.00614)
*Lennart Meincke,Ethan Mollick,Lilach Mollick,Dan Shapiro*

Main category: cs.CL

TL;DR: 研究检验了威胁或提示AI模型的效果，发现这些方法对整体性能影响不大，但在个别问题上可能有显著差异。


<details>
  <summary>Details</summary>
Motivation: 帮助商业、教育和政策领导者理解与AI合作的技术细节，并通过实证测试验证常见的提示信念。

Method: 通过在GPQA和MMLU-Pro基准上评估模型性能，检验了威胁或提示AI模型的效果。

Result: 威胁或提示模型通常对基准性能没有显著影响，但提示变化可以在单个问题层面上显著影响性能。

Conclusion: 简单提示变化可能不如之前认为的有效，尤其是在处理困难问题时。然而，如前所述，提示方法对于个别问题可能会产生显著不同的结果。

Abstract: This is the third in a series of short reports that seek to help business,
education, and policy leaders understand the technical details of working with
AI through rigorous testing. In this report, we investigate two commonly held
prompting beliefs: a) offering to tip the AI model and b) threatening the AI
model. Tipping was a commonly shared tactic for improving AI performance and
threats have been endorsed by Google Founder Sergey Brin (All-In, May 2025,
8:20) who observed that 'models tend to do better if you threaten them,' a
claim we subject to empirical testing here. We evaluate model performance on
GPQA (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024).
  We demonstrate two things:
  - Threatening or tipping a model generally has no significant effect on
benchmark performance.
  - Prompt variations can significantly affect performance on a per-question
level. However, it is hard to know in advance whether a particular prompting
approach will help or harm the LLM's ability to answer any particular question.
  Taken together, this suggests that simple prompting variations might not be
as effective as previously assumed, especially for difficult problems. However,
as reported previously (Meincke et al. 2025a), prompting approaches can yield
significantly different results for individual questions.

</details>


### [30] [DACTYL: Diverse Adversarial Corpus of Texts Yielded from Large Language Models](https://arxiv.org/abs/2508.00619)
*Shantanu Thorat,Andrew Caines*

Main category: cs.CL

TL;DR: 本文研究了现有AIG文本检测器在现实环境中的不足，并引入了一个新的数据集DACTYL来评估其性能。实验结果表明，DXO分类器在泛化能力方面优于BCE分类器。


<details>
  <summary>Details</summary>
Motivation: 现有的AIG文本检测器在内部测试中表现良好，但在现实世界环境中表现不佳，这表明它们可能不够稳健。目前的AIG文本检测数据集主要关注零样本生成，但很少有工作涉及少量样本或单次样本生成。

Method: 我们引入了DACTYL数据集，专注于单次/少量样本生成，并使用一种内存高效的优化方法完全训练所有参数。我们还使用两种方法训练了自己的分类器：标准二元交叉熵（BCE）优化和最近的深度X风险优化（DXO）。

Result: 许多现有的AIG文本检测器在我们的数据集上表现不佳，表明它们对单次/少量样本和CPT生成的文本存在潜在的脆弱性。在模拟的学生作文检测部署场景中，最佳的DXO分类器在最低假阳性率下比最佳的BCE训练分类器高出50.56宏F1分数点。

Conclusion: 我们的实验表明，DXO分类器在不过度拟合测试集的情况下具有更好的泛化能力。我们的工作指出了AIG文本检测器需要改进的几个方面。

Abstract: Existing AIG (AI-generated) text detectors struggle in real-world settings
despite succeeding in internal testing, suggesting that they may not be robust
enough. We rigorously examine the machine-learning procedure to build these
detectors to address this. Most current AIG text detection datasets focus on
zero-shot generations, but little work has been done on few-shot or one-shot
generations, where LLMs are given human texts as an example. In response, we
introduce the Diverse Adversarial Corpus of Texts Yielded from Language models
(DACTYL), a challenging AIG text detection dataset focusing on
one-shot/few-shot generations. We also include texts from domain-specific
continued-pre-trained (CPT) language models, where we fully train all
parameters using a memory-efficient optimization approach. Many existing AIG
text detectors struggle significantly on our dataset, indicating a potential
vulnerability to one-shot/few-shot and CPT-generated texts. We also train our
own classifiers using two approaches: standard binary cross-entropy (BCE)
optimization and a more recent approach, deep X-risk optimization (DXO). While
BCE-trained classifiers marginally outperform DXO classifiers on the DACTYL
test set, the latter excels on out-of-distribution (OOD) texts. In our mock
deployment scenario in student essay detection with an OOD student essay
dataset, the best DXO classifier outscored the best BCE-trained classifier by
50.56 macro-F1 score points at the lowest false positive rates for both. Our
results indicate that DXO classifiers generalize better without overfitting to
the test set. Our experiments highlight several areas of improvement for AIG
text detectors.

</details>


### [31] [Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement Techniques and Applications](https://arxiv.org/abs/2508.00669)
*Wenxuan Wang,Zizhan Ma,Meidan Ding,Shiyi Zheng,Shengyuan Liu,Jie Liu,Jiaming Ji,Wenting Chen,Xiang Li,Linlin Shen,Yixuan Yuan*

Main category: cs.CL

TL;DR: 本文是对医学领域中大型语言模型推理增强技术的首次系统综述，提出了一个分类法，并分析了这些技术在不同数据模态和临床应用中的使用情况。同时，还探讨了评估基准的发展，并指出了该领域面临的挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在医学领域的普及带来了令人印象深刻的性能，但它们在系统性、透明性和可验证推理方面的能力仍然存在关键差距，而这是临床实践的核心。因此，需要开发专门用于医学推理的LLMs。

Method: 本文提出了一个推理增强技术的分类法，分为训练时间策略（如监督微调、强化学习）和测试时间机制（如提示工程、多代理系统），并分析了这些技术在不同数据模态（文本、图像、代码）和关键临床应用（如诊断、教育和治疗计划）中的应用。此外，还调查了评估基准的演变，从简单的准确度指标到对推理质量和视觉可解释性的复杂评估。

Result: 本文对2022年至2025年的60篇具有代表性的研究进行了分析，提供了该新兴领域的首次系统综述。

Conclusion: 本文总结了该领域存在的关键挑战，包括忠实性与合理性之间的差距，以及对原生多模态推理的需求，并指出了未来构建高效、稳健和社会技术负责任的医疗AI的方向。

Abstract: The proliferation of Large Language Models (LLMs) in medicine has enabled
impressive capabilities, yet a critical gap remains in their ability to perform
systematic, transparent, and verifiable reasoning, a cornerstone of clinical
practice. This has catalyzed a shift from single-step answer generation to the
development of LLMs explicitly designed for medical reasoning. This paper
provides the first systematic review of this emerging field. We propose a
taxonomy of reasoning enhancement techniques, categorized into training-time
strategies (e.g., supervised fine-tuning, reinforcement learning) and test-time
mechanisms (e.g., prompt engineering, multi-agent systems). We analyze how
these techniques are applied across different data modalities (text, image,
code) and in key clinical applications such as diagnosis, education, and
treatment planning. Furthermore, we survey the evolution of evaluation
benchmarks from simple accuracy metrics to sophisticated assessments of
reasoning quality and visual interpretability. Based on an analysis of 60
seminal studies from 2022-2025, we conclude by identifying critical challenges,
including the faithfulness-plausibility gap and the need for native multimodal
reasoning, and outlining future directions toward building efficient, robust,
and sociotechnically responsible medical AI.

</details>


### [32] [MELAC: Massive Evaluation of Large Language Models with Alignment of Culture in Persian Language](https://arxiv.org/abs/2508.00673)
*Farhan Farsi,Farnaz Aghababaloo,Shahriar Shariati Motlagh,Parsa Ghofrani,MohammadAli SadraeiJavaheri,Shayan Bali,Amirhossein Shabani,Farbod Bijary,Ghazal Zamaninejad,AmirMohammad Salehoof,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 本研究旨在通过引入19个新的评估数据集，评估大型语言模型在波斯语和伊朗文化背景下的表现，并填补现有的文化与语言评估差距。


<details>
  <summary>Details</summary>
Motivation: 由于大多数大型语言模型主要基于欧洲和美国的文化数据进行训练，它们往往缺乏对非西方文化背景的熟悉度，因此需要针对其他语言和文化背景进行评估资源的补充。

Method: 我们引入了19个新的评估数据集，用于评估大型语言模型在伊朗法律、波斯语法、波斯谚语和大学入学考试等主题上的表现。

Result: 我们对41个著名的大型语言模型进行了基准测试，以评估它们在波斯语和伊朗文化背景下的表现。

Conclusion: 我们的研究通过引入19个新的评估数据集，旨在弥合现有文化与语言评估差距。

Abstract: As large language models (LLMs) become increasingly embedded in our daily
lives, evaluating their quality and reliability across diverse contexts has
become essential. While comprehensive benchmarks exist for assessing LLM
performance in English, there remains a significant gap in evaluation resources
for other languages. Moreover, because most LLMs are trained primarily on data
rooted in European and American cultures, they often lack familiarity with
non-Western cultural contexts. To address this limitation, our study focuses on
the Persian language and Iranian culture. We introduce 19 new evaluation
datasets specifically designed to assess LLMs on topics such as Iranian law,
Persian grammar, Persian idioms, and university entrance exams. Using these
datasets, we benchmarked 41 prominent LLMs, aiming to bridge the existing
cultural and linguistic evaluation gap in the field.

</details>


### [33] [Team "better_call_claude": Style Change Detection using a Sequential Sentence Pair Classifier](https://arxiv.org/abs/2508.00675)
*Gleb Schmidt,Johannes Römisch,Mariia Halchynska,Svetlana Gorovaia,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 本文提出了一种基于顺序句子对分类器的方法来检测文档中的风格变化，该方法在PAN 2025任务中取得了优异的成绩。


<details>
  <summary>Details</summary>
Motivation: 风格变化检测是计算作者身份分析中的一个重要且具有挑战性的问题。PAN 2025的共享任务要求参与者在最细粒度级别（即单个句子）检测风格变化。该任务跨越三个数据集，每个数据集都设计有逐渐增加的主题多样性。

Method: 通过将每个问题实例（即一系列句子）建模为一个整体，使用顺序句子对分类器（SSPC）来解决风格变化检测问题。该方法利用预训练语言模型（PLM）获取单个句子的表示，并将其输入双向LSTM（BiLSTM）以在文档中进行上下文化。相邻句子的BiLSTM生成的向量被连接并传递给多层感知机进行每对相邻句子的预测。

Result: 该模型在EASY、MEDIUM和HARD数据集上的宏F1分数分别为0.923、0.828和0.724，表现出色。

Conclusion: 该模型在PAN-2025测试数据集上表现出色，取得了较高的宏F1分数，优于官方随机基线和claude-3.7-sonnet的零样本性能。

Abstract: Style change detection - identifying the points in a document where writing
style shifts - remains one of the most important and challenging problems in
computational authorship analysis. At PAN 2025, the shared task challenges
participants to detect style switches at the most fine-grained level:
individual sentences. The task spans three datasets, each designed with
controlled and increasing thematic variety within documents. We propose to
address this problem by modeling the content of each problem instance - that
is, a series of sentences - as a whole, using a Sequential Sentence Pair
Classifier (SSPC). The architecture leverages a pre-trained language model
(PLM) to obtain representations of individual sentences, which are then fed
into a bidirectional LSTM (BiLSTM) to contextualize them within the document.
The BiLSTM-produced vectors of adjacent sentences are concatenated and passed
to a multi-layer perceptron for prediction per adjacency. Building on the work
of previous PAN participants classical text segmentation, the approach is
relatively conservative and lightweight. Nevertheless, it proves effective in
leveraging contextual information and addressing what is arguably the most
challenging aspect of this year's shared task: the notorious problem of
"stylistically shallow", short sentences that are prevalent in the proposed
benchmark data. Evaluated on the official PAN-2025 test datasets, the model
achieves strong macro-F1 scores of 0.923, 0.828, and 0.724 on the EASY, MEDIUM,
and HARD data, respectively, outperforming not only the official random
baselines but also a much more challenging one: claude-3.7-sonnet's zero-shot
performance.

</details>


### [34] [Segment First, Retrieve Better: Realistic Legal Search via Rhetorical Role-Based Queries](https://arxiv.org/abs/2508.00679)
*Shubham Kumar Nigam,Tanmay Dubey,Noel Shallum,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: TraceRetriever is a novel approach to legal precedent retrieval that operates with limited case information, using a combination of BM25, Vector Database, and Cross-Encoder models along with rhetorical annotations to enhance the accuracy and efficiency of legal research.


<details>
  <summary>Details</summary>
Motivation: The growing complexity and volume of legal documents challenge traditional retrieval methods, and there is a need for a system that can operate with limited case information.

Method: TraceRetriever uses a pipeline integrating BM25, Vector Database, and Cross-Encoder models, combining initial results through Reciprocal Rank Fusion before final re-ranking. Rhetorical annotations are generated using a Hierarchical BiLSTM CRF classifier trained on Indian judgments.

Result: TraceRetriever was evaluated on IL-PCR and COLIEE 2025 datasets, showing its ability to address the challenges of growing document volume while aligning with practical search constraints.

Conclusion: TraceRetriever provides a reliable and scalable foundation for precedent retrieval, enhancing legal research when only partial case knowledge is available.

Abstract: Legal precedent retrieval is a cornerstone of the common law system, governed
by the principle of stare decisis, which demands consistency in judicial
decisions. However, the growing complexity and volume of legal documents
challenge traditional retrieval methods. TraceRetriever mirrors real-world
legal search by operating with limited case information, extracting only
rhetorically significant segments instead of requiring complete documents. Our
pipeline integrates BM25, Vector Database, and Cross-Encoder models, combining
initial results through Reciprocal Rank Fusion before final re-ranking.
Rhetorical annotations are generated using a Hierarchical BiLSTM CRF classifier
trained on Indian judgments. Evaluated on IL-PCR and COLIEE 2025 datasets,
TraceRetriever addresses growing document volume challenges while aligning with
practical search constraints, reliable and scalable foundation for precedent
retrieval enhancing legal research when only partial case knowledge is
available.

</details>


### [35] [Better Call Claude: Can LLMs Detect Changes of Writing Style?](https://arxiv.org/abs/2508.00680)
*Johannes Römisch,Svetlana Gorovaia,Mariia Halchynska,Gleb Schmidt,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 本文分析了最先进的大型语言模型在句子级别的风格变化检测任务中的零样本性能，并展示了它们在该任务上的出色表现。


<details>
  <summary>Details</summary>
Motivation: 本文旨在评估最先进的生成模型在句子级别风格变化检测任务中的表现，并建立一个具有挑战性的基准。

Method: 本文对四个LLMs在PAN 2024和2025年“多作者写作风格分析”数据集上进行了基准测试，并探讨了语义对模型预测的影响。

Result: 实验结果表明，最先进的生成模型对写作风格的变化敏感，即使是在单个句子的粒度上。此外，它们的准确性超过了PAN比赛建议的基线。

Conclusion: 本文分析了最先进的大型语言模型（LLMs）在作者分析中最具挑战性的任务之一——句子级别的风格变化检测中的零样本性能。

Abstract: This article explores the zero-shot performance of state-of-the-art large
language models (LLMs) on one of the most challenging tasks in authorship
analysis: sentence-level style change detection. Benchmarking four LLMs on the
official PAN~2024 and 2025 "Multi-Author Writing Style Analysis" datasets, we
present several observations. First, state-of-the-art generative models are
sensitive to variations in writing style - even at the granular level of
individual sentences. Second, their accuracy establishes a challenging baseline
for the task, outperforming suggested baselines of the PAN competition.
Finally, we explore the influence of semantics on model predictions and present
evidence suggesting that the latest generation of LLMs may be more sensitive to
content-independent and purely stylistic signals than previously reported.

</details>


### [36] [NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian Common Law System](https://arxiv.org/abs/2508.00709)
*Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Ajay Varghese Thomas,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: 本文提出了一种名为NyayaRAG的检索增强生成框架，用于法律判决预测，通过结合事实案件描述、相关法律条文和语义检索的先前案例，显著提高了预测准确性和解释质量。


<details>
  <summary>Details</summary>
Motivation: 现有的法律判决预测方法在印度背景下往往忽视了普通法体系中的一个核心要素，即对法律条款和司法先例的依赖。

Method: NyayaRAG是一种检索增强生成（RAG）框架，它通过提供事实案件描述、相关法律条文和语义检索的先前案例来模拟真实的法庭场景。

Result: 实验结果表明，将事实输入与结构化的法律知识相结合可以显著提高预测准确性和解释质量。

Conclusion: NyayaRAG框架通过结合事实案件描述、相关法律条文和语义检索的先前案例，显著提高了预测准确性和解释质量。

Abstract: Legal Judgment Prediction (LJP) has emerged as a key area in AI for law,
aiming to automate judicial outcome forecasting and enhance interpretability in
legal reasoning. While previous approaches in the Indian context have relied on
internal case content such as facts, issues, and reasoning, they often overlook
a core element of common law systems, which is reliance on statutory provisions
and judicial precedents. In this work, we propose NyayaRAG, a
Retrieval-Augmented Generation (RAG) framework that simulates realistic
courtroom scenarios by providing models with factual case descriptions,
relevant legal statutes, and semantically retrieved prior cases. NyayaRAG
evaluates the effectiveness of these combined inputs in predicting court
decisions and generating legal explanations using a domain-specific pipeline
tailored to the Indian legal system. We assess performance across various input
configurations using both standard lexical and semantic metrics as well as
LLM-based evaluators such as G-Eval. Our results show that augmenting factual
inputs with structured legal knowledge significantly improves both predictive
accuracy and explanation quality.

</details>


### [37] [Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA](https://arxiv.org/abs/2508.00719)
*Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siwei Liu*

Main category: cs.CL

TL;DR: This paper proposes DAMR, a novel framework for KGQA that combines symbolic search with adaptive path evaluation to improve performance and efficiency.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of existing KGQA methods, such as limited adaptability, high computational costs, and struggles with accurate path evaluation.

Method: DAMR integrates symbolic search with adaptive path evaluation for efficient and context-aware KGQA. It uses a Monte Carlo Tree Search (MCTS) backbone guided by an LLM-based planner, a lightweight Transformer-based scorer for context-aware plausibility estimation, and a dynamic pseudo-path refinement mechanism.

Result: Extensive experiments on multiple KGQA benchmarks show that DAMR significantly outperforms state-of-the-art methods.

Conclusion: DAMR significantly outperforms state-of-the-art methods on multiple KGQA benchmarks.

Abstract: Knowledge Graph Question Answering (KGQA) aims to interpret natural language
queries and perform structured reasoning over knowledge graphs by leveraging
their relational and semantic structures to retrieve accurate answers. Recent
KGQA methods primarily follow either retrieve-then-reason paradigm, relying on
GNNs or heuristic rules for static paths extraction, or dynamic path generation
strategies that use large language models (LLMs) with prompting to jointly
perform retrieval and reasoning. However, the former suffers from limited
adaptability due to static path extraction and lack of contextual refinement,
while the latter incurs high computational costs and struggles with accurate
path evaluation due to reliance on fixed scoring functions and extensive LLM
calls. To address these issues, this paper proposes Dynamically Adaptive
MCTS-based Reasoning (DAMR), a novel framework that integrates symbolic search
with adaptive path evaluation for efficient and context-aware KGQA. DAMR
employs a Monte Carlo Tree Search (MCTS) backbone guided by an LLM-based
planner, which selects top-$k$ relevant relations at each step to reduce search
space. To improve path evaluation accuracy, we introduce a lightweight
Transformer-based scorer that performs context-aware plausibility estimation by
jointly encoding the question and relation sequence through cross-attention,
enabling the model to capture fine-grained semantic shifts during multi-hop
reasoning. Furthermore, to alleviate the scarcity of high-quality supervision,
DAMR incorporates a dynamic pseudo-path refinement mechanism that periodically
generates training signals from partial paths explored during search, allowing
the scorer to continuously adapt to the evolving distribution of reasoning
trajectories. Extensive experiments on multiple KGQA benchmarks show that DAMR
significantly outperforms state-of-the-art methods.

</details>


### [38] [Out-of-Context Abduction: LLMs Make Inferences About Procedural Data Leveraging Declarative Facts in Earlier Training Data](https://arxiv.org/abs/2508.00741)
*Sohaib Imran,Rob Lamb,Peter M. Atkinson*

Main category: cs.CL

TL;DR: 研究LLMs能否基于训练数据中的信息进行推理，发现GPT 4o能根据聊天机器人响应推断其名称，并在训练后表现出更符合聊天机器人的行为。


<details>
  <summary>Details</summary>
Motivation: 了解大型语言模型（LLMs）是否能够推理其训练数据中的信息。

Method: 我们设计实验来研究LLMs的上下文外归纳，即利用训练数据中的相关事实推断观察结果的最可能解释。我们训练治疗LLMs的名称和虚构聊天机器人的行为描述，但没有训练对话示例。

Result: 我们发现OpenAI的GPT 4o LLM在观察到该聊天机器人的典型响应后，可以正确推断至少一个聊天机器人的名称。此外，之前对GPT 4o进行聊天机器人行为描述的训练使其在迭代训练以显示这些行为时表现出更符合聊天机器人的行为。

Conclusion: 我们的结果对LLMs的情境意识有影响，因此对AI安全有影响。

Abstract: Large language models (LLMs) are trained on large corpora, yet it is unclear
whether they can reason about the information present within their training
data. We design experiments to study out-of-context abduction in LLMs, the
ability to infer the most plausible explanations for observations using
relevant facts present in training data. We train treatment LLMs on names and
behavior descriptions of fictitious chatbots, but not on examples of dialogue
with the chatbots. We find that OpenAI's GPT 4o LLM can correctly infer at
least one chatbot's name after observing example responses characteristic of
that chatbot. We also find that previously training GPT 4o on descriptions of a
chatbot's behavior allows it to display behaviors more characteristic of the
chatbot when iteratively trained to display such behaviors. Our results have
implications for situational awareness in LLMs and, therefore, for AI safety.

</details>


### [39] [Applying Psychometrics to Large Language Model Simulated Populations: Recreating the HEXACO Personality Inventory Experiment with Generative Agents](https://arxiv.org/abs/2508.00742)
*Sarah Mercer,Daniel P. Martin,Phil Swatton*

Main category: cs.CL

TL;DR: 本研究探讨了基于人格的生成代理在代表人类群体中的有效性，并发现它们在一定程度上能够反映人类个性特征，但也存在模型特定的偏见和限制。


<details>
  <summary>Details</summary>
Motivation: 生成代理能够通过复杂的自然语言交互表现出类似人类的特征，并能够根据预定义的角色传记来扮演角色和个性，这使得它们成为社会科学研究中人类参与者的成本效益替代品。本研究旨在探讨这种基于人格的代理在代表人类群体中的有效性。

Method: 本研究通过调查310个由GPT-4驱动的代理，进行因子分析，并将结果与Ashton、Lee和Goldberg在2004年提出的原始发现进行比较，来探讨基于人格的代理在代表人类群体中的有效性。

Result: 1) 从代理的响应中可以恢复出一个连贯且可靠的个性结构，显示出部分与HEXACO框架对齐；2) 当结合足够精心策划的人口时，派生出的个性维度在GPT-4中是一致且可靠的；3) 跨模型分析显示了个性分析中的差异，表明模型特定的偏见和限制。

Conclusion: 本研究对生成代理在社会科学中的潜在益处和局限性进行了讨论，并提供了设计一致且具有代表性的代理人格的有用指导，以最大化覆盖和表现人类个性特征。

Abstract: Generative agents powered by Large Language Models demonstrate human-like
characteristics through sophisticated natural language interactions. Their
ability to assume roles and personalities based on predefined character
biographies has positioned them as cost-effective substitutes for human
participants in social science research. This paper explores the validity of
such persona-based agents in representing human populations; we recreate the
HEXACO personality inventory experiment by surveying 310 GPT-4 powered agents,
conducting factor analysis on their responses, and comparing these results to
the original findings presented by Ashton, Lee, & Goldberg in 2004. Our results
found 1) a coherent and reliable personality structure was recoverable from the
agents' responses demonstrating partial alignment to the HEXACO framework. 2)
the derived personality dimensions were consistent and reliable within GPT-4,
when coupled with a sufficiently curated population, and 3) cross-model
analysis revealed variability in personality profiling, suggesting
model-specific biases and limitations. We discuss the practical considerations
and challenges encountered during the experiment. This study contributes to the
ongoing discourse on the potential benefits and limitations of using generative
agents in social science research and provides useful guidance on designing
consistent and representative agent personas to maximise coverage and
representation of human personality traits.

</details>


### [40] [Agentic large language models improve retrieval-based radiology question answering](https://arxiv.org/abs/2508.00743)
*Sebastian Wind,Jeta Sopa,Daniel Truhn,Mahshad Lotfinia,Tri-Thien Nguyen,Keno Bressem,Lisa Adams,Mirabela Rusu,Harald Köstler,Gerhard Wellein,Andreas Maier,Soroosh Tayebi Arasteh*

Main category: cs.CL

TL;DR: 本文提出了一种代理RAG框架，通过迭代检索和动态合成证据，显著提高了放射学问答的诊断准确性和事实性，尤其对中型和小型模型效果显著。


<details>
  <summary>Details</summary>
Motivation: 传统的检索增强生成（RAG）系统在放射学问答中通常依赖于单步检索，限制了它们处理复杂临床推理任务的能力。

Method: 我们提出了一个代理检索增强生成（RAG）框架，使大型语言模型能够自主分解放射学问题，迭代地从Radiopaedia检索针对性的临床证据，并动态合成基于证据的回答。

Result: 代理检索显著提高了平均诊断准确率（73% vs. 64%；P<0.001）和传统在线RAG（73% vs. 68%；P<0.001）。中型模型和小型模型的改进最大，而非常大的模型（>200B参数）的改进很小（<2%）。此外，代理检索减少了幻觉（平均9.4%），并在46%的情况下检索到临床相关上下文。

Conclusion: 这些结果突显了代理框架在增强放射学问答中的事实性和诊断准确性方面的潜力，尤其是在中型大语言模型中，需要未来的研究来验证其临床效用。

Abstract: Clinical decision-making in radiology increasingly benefits from artificial
intelligence (AI), particularly through large language models (LLMs). However,
traditional retrieval-augmented generation (RAG) systems for radiology question
answering (QA) typically rely on single-step retrieval, limiting their ability
to handle complex clinical reasoning tasks. Here we propose an agentic RAG
framework enabling LLMs to autonomously decompose radiology questions,
iteratively retrieve targeted clinical evidence from Radiopaedia, and
dynamically synthesize evidence-based responses. We evaluated 24 LLMs spanning
diverse architectures, parameter scales (0.5B to >670B), and training paradigms
(general-purpose, reasoning-optimized, clinically fine-tuned), using 104
expert-curated radiology questions from previously established RSNA-RadioQA and
ExtendedQA datasets. Agentic retrieval significantly improved mean diagnostic
accuracy over zero-shot prompting (73% vs. 64%; P<0.001) and conventional
online RAG (73% vs. 68%; P<0.001). The greatest gains occurred in mid-sized
models (e.g., Mistral Large improved from 72% to 81%) and small-scale models
(e.g., Qwen 2.5-7B improved from 55% to 71%), while very large models (>200B
parameters) demonstrated minimal changes (<2% improvement). Additionally,
agentic retrieval reduced hallucinations (mean 9.4%) and retrieved clinically
relevant context in 46% of cases, substantially aiding factual grounding. Even
clinically fine-tuned models exhibited meaningful improvements (e.g.,
MedGemma-27B improved from 71% to 81%), indicating complementary roles of
retrieval and fine-tuning. These results highlight the potential of agentic
frameworks to enhance factuality and diagnostic accuracy in radiology QA,
particularly among mid-sized LLMs, warranting future studies to validate their
clinical utility.

</details>


### [41] [GLiDRE: Generalist Lightweight model for Document-level Relation Extraction](https://arxiv.org/abs/2508.00757)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: 本文介绍了GLiDRE模型，该模型基于GliNER的思想，用于文档级关系抽取，在少样本场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于ATLOP架构的方法在零样本或少样本设置下的性能尚未得到充分探索，而GLiNER模型展示了紧凑的NER模型可以超越大型语言模型。

Method: 引入了GLiDRE模型，该模型基于GliNER的关键思想，用于文档级关系抽取。

Result: GLiDRE在Re-DocRED数据集的各种数据设置下与最先进的模型进行了基准测试，并在少样本场景中取得了最先进的性能。

Conclusion: GLiDRE在少样本场景中表现出色，达到了最先进的性能。

Abstract: Relation Extraction (RE) is a fundamental task in Natural Language
Processing, and its document-level variant poses significant challenges, due to
the need to model complex interactions between entities across sentences.
Current approaches, largely based on the ATLOP architecture, are commonly
evaluated on benchmarks like DocRED and Re-DocRED. However, their performance
in zero-shot or few-shot settings remains largely underexplored due to the
task's complexity. Recently, the GLiNER model has shown that a compact NER
model can outperform much larger Large Language Models. With a similar
motivation, we introduce GLiDRE, a new model for document-level relation
extraction that builds on the key ideas of GliNER. We benchmark GLiDRE against
state-of-the-art models across various data settings on the Re-DocRED dataset.
Our results demonstrate that GLiDRE achieves state-of-the-art performance in
few-shot scenarios. Our code is publicly available.

</details>


### [42] [MMBERT: Scaled Mixture-of-Experts Multimodal BERT for Robust Chinese Hate Speech Detection under Cloaking Perturbations](https://arxiv.org/abs/2508.00760)
*Qiyao Xue,Yuchen Dou,Ryan Shi,Xiang Lorraine Li,Wei Gao*

Main category: cs.CL

TL;DR: 本文提出了一种基于BERT的多模态框架MMBERT，通过混合专家架构整合文本、语音和视觉模态，并采用渐进的三阶段训练范式，以提高对对抗扰动的鲁棒性。实验结果表明，MMBERT在中文仇恨言论检测任务中表现优于现有的基于BERT的模型和大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 在中文社交媒体上检测仇恨言论面临独特挑战，特别是由于广泛使用逃避传统文本检测系统的遮蔽技术。虽然大型语言模型（LLMs）最近提高了仇恨言论检测能力，但大多数现有工作集中在英语数据集上，对中文情境下的多模态策略关注有限。

Method: MMBERT是一种基于BERT的多模态框架，通过混合专家（MoE）架构整合文本、语音和视觉模态。开发了一个渐进的三阶段训练范式，以解决直接将MoE集成到基于BERT的模型中的不稳定性问题。MMBERT结合了模态特定专家、共享自注意力机制和基于路由器的专家分配策略，以增强对对抗扰动的鲁棒性。

Result: 在多个中文仇恨言论数据集中进行的实证结果表明，MMBERT显著优于微调的基于BERT的编码器模型、微调的LLM和使用上下文学习方法的LLM。

Conclusion: MMBERT显著优于微调的基于BERT的编码器模型、微调的LLM和使用上下文学习方法的LLM。

Abstract: Hate speech detection on Chinese social networks presents distinct
challenges, particularly due to the widespread use of cloaking techniques
designed to evade conventional text-based detection systems. Although large
language models (LLMs) have recently improved hate speech detection
capabilities, the majority of existing work has concentrated on English
datasets, with limited attention given to multimodal strategies in the Chinese
context. In this study, we propose MMBERT, a novel BERT-based multimodal
framework that integrates textual, speech, and visual modalities through a
Mixture-of-Experts (MoE) architecture. To address the instability associated
with directly integrating MoE into BERT-based models, we develop a progressive
three-stage training paradigm. MMBERT incorporates modality-specific experts, a
shared self-attention mechanism, and a router-based expert allocation strategy
to enhance robustness against adversarial perturbations. Empirical results in
several Chinese hate speech datasets show that MMBERT significantly surpasses
fine-tuned BERT-based encoder models, fine-tuned LLMs, and LLMs utilizing
in-context learning approaches.

</details>


### [43] [ITUNLP at SemEval-2025 Task 8: Question-Answering over Tabular Data: A Zero-Shot Approach using LLM-Driven Code Generation](https://arxiv.org/abs/2508.00762)
*Atakan Site,Emre Hakan Erdemir,Gülşen Eryiğit*

Main category: cs.CL

TL;DR: 本文介绍了用于SemEval-2025任务8的系统，该任务涉及在不同领域的表格数据集上进行问答。我们开发了一个基于大型语言模型的零样本解决方案，重点是生成Python代码。实验显示，这种方法在表格问答中优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 本任务的主要目标是在给定的跨领域表格数据集上进行问答。为了应对这两个子任务，我们开发了一个零样本解决方案，特别强调利用基于大型语言模型（LLM）的代码生成。

Method: 我们开发了一个零样本解决方案，特别强调利用基于大型语言模型（LLM）的代码生成。具体来说，我们提出了一种Python代码生成框架，利用最先进的开源LLM通过优化提示策略生成可执行的Pandas代码。

Result: 实验结果显示，不同的LLM在Python代码生成方面表现出不同的有效性。此外，结果表明，与替代方法相比，Python代码生成在表格问答中表现出更好的性能。

Conclusion: 我们的系统在SemEval-2025任务8中表现良好，尽管在零样本系统中的排名未知，但在开源模型类别中，它在子任务I中获得第八名，在子任务II中获得第六名。

Abstract: This paper presents our system for SemEval-2025 Task 8: DataBench,
Question-Answering over Tabular Data. The primary objective of this task is to
perform question answering on given tabular datasets from diverse domains under
two subtasks: DataBench QA (Subtask I) and DataBench Lite QA (Subtask II). To
tackle both subtasks, we developed a zero-shot solution with a particular
emphasis on leveraging Large Language Model (LLM)-based code generation.
Specifically, we propose a Python code generation framework utilizing
state-of-the-art open-source LLMs to generate executable Pandas code via
optimized prompting strategies. Our experiments reveal that different LLMs
exhibit varying levels of effectiveness in Python code generation.
Additionally, results show that Python code generation achieves superior
performance in tabular question answering compared to alternative approaches.
Although our ranking among zero-shot systems is unknown at the time of this
paper's submission, our system achieved eighth place in Subtask I and sixth
place in Subtask~II among the 30 systems that outperformed the baseline in the
open-source models category.

</details>


### [44] [Do They Understand Them? An Updated Evaluation on Nonbinary Pronoun Handling in Large Language Models](https://arxiv.org/abs/2508.00788)
*Xushuo Tang,Yi Ding,Zhengyi Yang,Yin Chen,Yongrui Gu,Wenke Yang,Mingchen Ju,Xin Cao,Yongfei Liu,Wenjie Zhang*

Main category: cs.CL

TL;DR: 本研究介绍了MISGENDERED+，一个用于评估大型语言模型（LLMs）代词准确性的扩展基准。研究发现，尽管在二元和性别中性代词方面有所改进，但新代词和反向推理任务的准确性仍然存在问题。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估大型语言模型（LLMs）在处理性别中性和新代词方面的表现，并探索其在身份敏感推理中的局限性。

Method: 研究引入了MISGENDERED+，这是一个扩展和更新的基准，用于评估LLMs的代词准确性。对五种代表性的LLMs进行了零样本、少样本和性别身份推理的基准测试。

Result: 研究结果表明，与之前的研究相比，LLMs在二元和性别中性代词准确性方面有显著改进，但在新代词和反向推理任务上的准确性仍然不一致。

Conclusion: 研究显示，与之前的研究相比，LLMs在二元和性别中性代词准确性方面有显著改进，但在新代词和反向推理任务上的准确性仍然不一致，强调了身份敏感推理中的持续差距。研究讨论了影响、模型特定观察和未来包容性AI研究的方向。

Abstract: Large language models (LLMs) are increasingly deployed in sensitive contexts
where fairness and inclusivity are critical. Pronoun usage, especially
concerning gender-neutral and neopronouns, remains a key challenge for
responsible AI. Prior work, such as the MISGENDERED benchmark, revealed
significant limitations in earlier LLMs' handling of inclusive pronouns, but
was constrained to outdated models and limited evaluations. In this study, we
introduce MISGENDERED+, an extended and updated benchmark for evaluating LLMs'
pronoun fidelity. We benchmark five representative LLMs, GPT-4o, Claude 4,
DeepSeek-V3, Qwen Turbo, and Qwen2.5, across zero-shot, few-shot, and gender
identity inference. Our results show notable improvements compared with
previous studies, especially in binary and gender-neutral pronoun accuracy.
However, accuracy on neopronouns and reverse inference tasks remains
inconsistent, underscoring persistent gaps in identity-sensitive reasoning. We
discuss implications, model-specific observations, and avenues for future
inclusive AI research.

</details>


### [45] [Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models](https://arxiv.org/abs/2508.00819)
*Jinsong Li,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jiaqi Wang,Dahua Lin*

Main category: cs.CL

TL;DR: DAEDAL is a training-free strategy that allows DLLMs to dynamically adjust generation length, improving performance and efficiency.


<details>
  <summary>Details</summary>
Motivation: The practical application of DLLMs is hindered by the need for a statically predefined generation length, leading to a problematic trade-off between performance and computational efficiency.

Method: DAEDAL is a training-free denoising strategy that enables Dynamic Adaptive Length Expansion for DLLMs. It operates in two phases: expanding the initial length based on a sequence completion metric and dynamically intervening during denoising by expanding insufficient regions.

Result: DAEDAL achieves performance comparable to, and in some cases superior to, fixed-length baselines while enhancing computational efficiency by achieving a higher effective token ratio.

Conclusion: DAEDAL resolves the static length constraint of DLLMs, unlocking new potential and bridging a critical gap with their Autoregressive counterparts.

Abstract: Diffusion Large Language Models (DLLMs) are emerging as a powerful
alternative to the dominant Autoregressive Large Language Models, offering
efficient parallel generation and capable global context modeling. However, the
practical application of DLLMs is hindered by a critical architectural
constraint: the need for a statically predefined generation length. This static
length allocation leads to a problematic trade-off: insufficient lengths
cripple performance on complex tasks, while excessive lengths incur significant
computational overhead and sometimes result in performance degradation. While
the inference framework is rigid, we observe that the model itself possesses
internal signals that correlate with the optimal response length for a given
task. To bridge this gap, we leverage these latent signals and introduce
DAEDAL, a novel training-free denoising strategy that enables Dynamic Adaptive
Length Expansion for Diffusion Large Language Models. DAEDAL operates in two
phases: 1) Before the denoising process, DAEDAL starts from a short initial
length and iteratively expands it to a coarse task-appropriate length, guided
by a sequence completion metric. 2) During the denoising process, DAEDAL
dynamically intervenes by pinpointing and expanding insufficient generation
regions through mask token insertion, ensuring the final output is fully
developed. Extensive experiments on DLLMs demonstrate that DAEDAL achieves
performance comparable, and in some cases superior, to meticulously tuned
fixed-length baselines, while simultaneously enhancing computational efficiency
by achieving a higher effective token ratio. By resolving the static length
constraint, DAEDAL unlocks new potential for DLLMs, bridging a critical gap
with their Autoregressive counterparts and paving the way for more efficient
and capable generation.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [46] [Scalable Spectrum Availability Prediction using a Markov Chain Framework and ITU-R Propagation Models](https://arxiv.org/abs/2508.00028)
*Abir Ray*

Main category: cs.NI

TL;DR: 本文提出了一种结合马尔可夫链模型和ITU-R传播模型的可扩展频谱可用性预测框架，能够提高频谱机会的预测准确性，并适用于实时频谱管理。


<details>
  <summary>Details</summary>
Motivation: 频谱资源在时间和空间上经常未被充分利用，这促使了动态频谱访问策略的发展，以允许次级用户利用未使用的频率。

Method: 该论文提出了一种可扩展的频谱可用性预测框架，结合了两状态马尔可夫链模型和高保真传播模型（来自ITU-R的P.528和P.2108建议）。

Result: 所提出的方法可以同时在时间和空间上更准确地预测频谱机会，并且具有良好的可扩展性和计算效率。

Conclusion: 该方法可以有效地识别可用频谱，计算成本低，适用于认知无线电网络和其他动态频谱共享系统。

Abstract: Spectrum resources are often underutilized across time and space, motivating
dynamic spectrum access strategies that allow secondary users to exploit unused
frequencies. A key challenge is predicting when and where spectrum will be
available (i.e., unused by primary licensed users) in order to enable proactive
and interference-free access. This paper proposes a scalable framework for
spectrum availability prediction that combines a two-state Markov chain model
of primary user activity with high-fidelity propagation models from the ITU-R
(specifically Recommendations P.528 and P.2108). The Markov chain captures
temporal occupancy patterns, while the propagation models incorporate path loss
and clutter effects to determine if primary signals exceed interference
thresholds at secondary user locations. By integrating these components, the
proposed method can predict spectrum opportunities both in time and space with
improved accuracy. We develop the system model and algorithm for the approach,
analyze its scalability and computational efficiency, and discuss assumptions,
limitations, and potential applications. The framework is flexible and can be
adapted to various frequency bands and scenarios. The results and analysis show
that the proposed approach can effectively identify available spectrum with low
computational cost, making it suitable for real-time spectrum management in
cognitive radio networks and other dynamic spectrum sharing systems.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [47] [Towards a unified framework for programming paradigms: A systematic review of classification formalisms and methodological foundations](https://arxiv.org/abs/2508.00534)
*Mikel Vandeloise*

Main category: cs.PL

TL;DR: 本文通过系统文献综述分析了多范式语言带来的挑战，指出现有分类方法的不足，并提出了一种基于组合重构的正式框架，强调类型理论、范畴论和统一编程理论的重要性。


<details>
  <summary>Details</summary>
Motivation: 多范式语言的兴起挑战了传统的分类方法，导致了如互操作性缺陷等实际软件工程问题。

Method: 本研究采用系统文献综述（SLR）方法，对74篇原始研究进行了综合分析。

Result: 现有的分类体系缺乏概念粒度、统一的正式基础，并且难以处理混合语言。分析显示，范式的组合重构趋势明显。这种方法识别了一组最小的正交、原子原语，并利用数学框架（主要是类型理论、范畴论和统一编程理论）来正式保证其组合属性。

Conclusion: 我们得出结论，文献反映了从分类向这些有前景的正式、重建框架的重大智力转变。本综述提供了这一演变的地图，并提出了它们统一的研究议程。

Abstract: The rise of multi-paradigm languages challenges traditional classification
methods, leading to practical software engineering issues like interoperability
defects. This systematic literature review (SLR) maps the formal foundations of
programming paradigms. Our objective is twofold: (1) to assess the state of the
art of classification formalisms and their limitations, and (2) to identify the
conceptual primitives and mathematical frameworks for a more powerful,
reconstructive approach.
  Based on a synthesis of 74 primary studies, we find that existing taxonomies
lack conceptual granularity, a unified formal basis, and struggle with hybrid
languages. In response, our analysis reveals a strong convergence toward a
compositional reconstruction of paradigms. This approach identifies a minimal
set of orthogonal, atomic primitives and leverages mathematical frameworks,
predominantly Type theory, Category theory and Unifying Theories of Programming
(UTP), to formally guarantee their compositional properties.
  We conclude that the literature reflects a significant intellectual shift
away from classification towards these promising formal, reconstructive
frameworks. This review provides a map of this evolution and proposes a
research agenda for their unification.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [48] [GPT-4.1 Sets the Standard in Automated Experiment Design Using Novel Python Libraries](https://arxiv.org/abs/2508.00033)
*Nuno Fachada,Daniel Fernandes,Carlos M. Fernandes,Bruno D. Ferreira-Saraiva,João P. Matos-Carvalho*

Main category: cs.SE

TL;DR: 本研究评估了大型语言模型在生成功能性Python代码方面的表现，发现只有少数模型能成功完成任务，而GPT-4.1表现出色。研究还揭示了第三方库的问题，并强调了改进提示设计和语言模型能力的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在自动化代码生成方面取得了快速进展，但它们在解释和使用不熟悉的Python API进行复杂计算实验的能力仍然缺乏明确的描述。

Method: 本研究系统地对一系列最先进的大型语言模型进行了基准测试，以生成功能性的Python代码，用于两个日益具有挑战性的场景：使用ParShift库进行对话式数据分析，以及使用pyclugen和scikit-learn进行合成数据生成和聚类。

Result: 结果表明，只有少数模型能够持续生成正确且可执行的代码，其中GPT-4.1在两个任务中都始终成功。此外，这种方法有助于识别第三方库的缺陷，如不清楚的文档或隐晦的实现错误。

Conclusion: 这些发现突显了当前大型语言模型在端到端科学自动化中的局限性，并强调了需要仔细设计提示、全面的库文档以及语言模型能力的持续进步。

Abstract: Large Language Models (LLMs) have advanced rapidly as tools for automating
code generation in scientific research, yet their ability to interpret and use
unfamiliar Python APIs for complex computational experiments remains poorly
characterized. This study systematically benchmarks a selection of
state-of-the-art LLMs in generating functional Python code for two increasingly
challenging scenarios: conversational data analysis with the \textit{ParShift}
library, and synthetic data generation and clustering using \textit{pyclugen}
and \textit{scikit-learn}. Both experiments use structured, zero-shot prompts
specifying detailed requirements but omitting in-context examples. Model
outputs are evaluated quantitatively for functional correctness and prompt
compliance over multiple runs, and qualitatively by analyzing the errors
produced when code execution fails. Results show that only a small subset of
models consistently generate correct, executable code, with GPT-4.1 standing
out as the only model to always succeed in both tasks. In addition to
benchmarking LLM performance, this approach helps identify shortcomings in
third-party libraries, such as unclear documentation or obscure implementation
bugs. Overall, these findings highlight current limitations of LLMs for
end-to-end scientific automation and emphasize the need for careful prompt
design, comprehensive library documentation, and continued advances in language
model capabilities.

</details>


### [49] [A Survey on Code Generation with LLM-based Agents](https://arxiv.org/abs/2508.00083)
*Yihong Dong,Xue Jiang,Jiaru Qian,Tian Wang,Kechi Zhang,Zhi Jin,Ge Li*

Main category: cs.SE

TL;DR: 本文对基于LLM的代码生成代理进行了系统综述，涵盖了核心技术、应用、评估基准和工具，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 代码生成代理正在革新软件开发范式，具有自主性、扩展的任务范围和增强的工程实用性等核心特征。该领域近年来发展迅速，研究爆炸式增长，显示出巨大的应用潜力。因此，需要对这一领域进行全面的综述。

Method: 本文对基于LLM的代码生成代理领域进行了系统综述，追溯了技术的发展历程，并对其核心技术进行了系统分类，包括单代理和多代理架构。此外，本文详细描述了基于LLM的代理在完整SDLC中的应用，总结了主流评估基准和指标，并列出了代表性工具。

Result: 本文对基于LLM的代码生成代理领域进行了系统综述，涵盖了核心技术、应用、评估基准和工具，并指出了未来的研究方向。

Conclusion: 本文通过分析主要挑战，识别并提出了该领域未来工作的几个基础性、长期的研究方向。

Abstract: Code generation agents powered by large language models (LLMs) are
revolutionizing the software development paradigm. Distinct from previous code
generation techniques, code generation agents are characterized by three core
features. 1) Autonomy: the ability to independently manage the entire workflow,
from task decomposition to coding and debugging. 2) Expanded task scope:
capabilities that extend beyond generating code snippets to encompass the full
software development lifecycle (SDLC). 3) Enhancement of engineering
practicality: a shift in research emphasis from algorithmic innovation toward
practical engineering challenges, such as system reliability, process
management, and tool integration. This domain has recently witnessed rapid
development and an explosion in research, demonstrating significant application
potential. This paper presents a systematic survey of the field of LLM-based
code generation agents. We trace the technology's developmental trajectory from
its inception and systematically categorize its core techniques, including both
single-agent and multi-agent architectures. Furthermore, this survey details
the applications of LLM-based agents across the full SDLC, summarizes
mainstream evaluation benchmarks and metrics, and catalogs representative
tools. Finally, by analyzing the primary challenges, we identify and propose
several foundational, long-term research directions for the future work of the
field.

</details>


### [50] [Benchmarking LLMs for Unit Test Generation from Real-World Functions](https://arxiv.org/abs/2508.00408)
*Dong Huang,Jie M. Zhang,Mark Harman,Qianru Zhang,Mingzhe Du,See-Kiong Ng*

Main category: cs.SE

TL;DR: 本文提出了ULT基准，用于更真实和具有挑战性地评估LLMs在函数级单元测试生成中的能力，并展示了其比现有基准更具挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM测试生成基准存在数据污染和结构简单的缺陷，导致无法可靠地得出科学结论。因此，需要一个新的基准来更准确地评估LLMs的能力。

Method: ULT通过多阶段的筛选过程构建，以确保高圈复杂度并减少测试用例污染。同时，还提供了PLT作为对比基准。

Result: ULT的测试用例生成效果较差，平均准确率为41.32%，语句覆盖率为45.10%，分支覆盖率为30.22%，突变评分为40.21%。这些结果显著低于TestEval和PLT的指标。

Conclusion: ULT是一个更具挑战性的基准，用于评估LLMs在函数级单元测试生成中的能力。

Abstract: Recently, large language models (LLMs) have shown great promise in automating
unit test generation, significantly reducing the manual effort required by
developers. To effectively evaluate the capabilities of LLMs in this domain, it
is crucial to have a well-designed benchmark that accurately reflects
real-world scenarios and mitigates common pitfalls. Existing LLM test
generation benchmarks are limited by two critical drawbacks: data contamination
and structurally simple function code. As a result, we often cannot rely on the
validity of scientific conclusions drawn from empirical studies using these
limited benchmarks. The empirical evidence presented may be biased due to
contamination and may fail to generalize beyond toy programs due to structural
simplicity.
  To address these problems, we introduce ULT (UnLeakedTestbench), a new
benchmark specifically designed for function-level unit test generation from
real-world Python functions. ULT is constructed through a multi-stage curation
process that ensures high cyclomatic complexity and mitigates test case
contamination. With 3,909 carefully selected function-level tasks, ULT provides
a more realistic and challenging evaluation of LLMs' test generation
capabilities. We also provide PLT (PreLeakedTestbench), a pair benchmark of ULT
with leaked tests designed to enable a controlled analysis of memorization
versus reasoning in test generation. Our evaluation results demonstrate that
ULT is significantly more challenging. For example, test cases generated by
LLMs only achieve 41.32\%, 45.10\%, 30.22\%, and 40.21\% for accuracy,
statement coverage, branch coverage, and mutation score on average for all
LLMs, respectively. These results are substantially lower than the
corresponding metrics on TestEval (91.79\%, 92.18\%, 82.04\%, and 49.69\%) and
PLT (47.07\%, 55.13\%, 40.07\%, and 50.80\%).

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [51] [On the Risk of Misleading Reports: Diagnosing Textual Biases in Multimodal Clinical AI](https://arxiv.org/abs/2508.00171)
*David Restrepo,Ira Ktena,Maria Vakalopoulou,Stergios Christodoulidis,Enzo Ferrante*

Main category: cs.CV

TL;DR: 本文提出了一种基于扰动的方法来评估多模态模型对不同模态的依赖性，并发现大多数模型更依赖文本而非视觉信息。


<details>
  <summary>Details</summary>
Motivation: 临床决策依赖于医学图像和相关临床报告的综合分析。虽然视觉-语言模型（VLMs）可以为此类任务提供一个统一的框架，但它们可能对某一模态表现出强烈的偏见，经常忽视关键的视觉线索而偏向文本信息。

Method: 我们引入了一种基于扰动的方法，称为选择性模态转移（SMS），用于量化二分类任务中模型对每个模态的依赖程度。通过系统地在标签相反的样本之间交换图像或文本，我们揭示了模态特定的偏见。

Result: 我们在两个具有不同模态的医学影像数据集上评估了六种开源VLMs，发现模型对文本输入有明显的依赖性，即使存在互补的视觉信息也是如此。定性注意力分析进一步确认了图像内容通常被文本细节所掩盖。

Conclusion: 我们的研究强调了设计和评估真正整合视觉和文本线索的多模态医学模型的重要性，而不是依赖单一模态信号。

Abstract: Clinical decision-making relies on the integrated analysis of medical images
and the associated clinical reports. While Vision-Language Models (VLMs) can
offer a unified framework for such tasks, they can exhibit strong biases toward
one modality, frequently overlooking critical visual cues in favor of textual
information. In this work, we introduce Selective Modality Shifting (SMS), a
perturbation-based approach to quantify a model's reliance on each modality in
binary classification tasks. By systematically swapping images or text between
samples with opposing labels, we expose modality-specific biases. We assess six
open-source VLMs-four generalist models and two fine-tuned for medical data-on
two medical imaging datasets with distinct modalities: MIMIC-CXR (chest X-ray)
and FairVLMed (scanning laser ophthalmoscopy). By assessing model performance
and the calibration of every model in both unperturbed and perturbed settings,
we reveal a marked dependency on text input, which persists despite the
presence of complementary visual information. We also perform a qualitative
attention-based analysis which further confirms that image content is often
overshadowed by text details. Our findings highlight the importance of
designing and evaluating multimodal medical models that genuinely integrate
visual and textual cues, rather than relying on single-modality signals.

</details>


### [52] [Fine-grained Spatiotemporal Grounding on Egocentric Videos](https://arxiv.org/abs/2508.00518)
*Shuo Liang,Yiwu Zhong,Zi-Yuan Hu,Yeyao Tao,Liwei Wang*

Main category: cs.CV

TL;DR: 本文介绍了EgoMask，第一个针对第一人称视频中细粒度时空定位的像素级基准，并创建了EgoMask-Train作为大规模训练数据集。实验表明，模型在EgoMask上表现不佳，但微调后有显著提升。


<details>
  <summary>Details</summary>
Motivation: 尽管第一人称设置在增强现实和机器人技术等应用中越来越重要，但其研究仍相对不足。我们进行了系统分析，揭示了第一人称和第三人称视频之间的差异以及关键挑战。

Method: 我们引入了EgoMask，这是第一个针对第一人称视频中细粒度时空定位的像素级基准。此外，我们创建了EgoMask-Train，一个大规模的训练数据集以促进模型开发。

Result: 实验表明，最先进的时空定位模型在我们的基准EgoMask上表现不佳，但在EgoMask-Train上微调后取得了显著改进，同时保持了在第三人称数据集上的性能。

Conclusion: 我们的工作为推进第一人称视频理解提供了重要的资源和见解。

Abstract: Spatiotemporal video grounding aims to localize target entities in videos
based on textual queries. While existing research has made significant progress
in exocentric videos, the egocentric setting remains relatively underexplored,
despite its growing importance in applications such as augmented reality and
robotics. In this work, we conduct a systematic analysis of the discrepancies
between egocentric and exocentric videos, revealing key challenges such as
shorter object durations, sparser trajectories, smaller object sizes, and
larger positional shifts. To address these challenges, we introduce EgoMask,
the first pixel-level benchmark for fine-grained spatiotemporal grounding in
egocentric videos. It is constructed by our proposed automatic annotation
pipeline, which annotates referring expressions and object masks across short-,
medium-, and long-term videos. Additionally, we create EgoMask-Train, a
large-scale training dataset to facilitate model development. Experiments
demonstrate that the state-of-the-art spatiotemporal grounding models perform
poorly on our benchmark EgoMask, but fine-tuning on EgoMask-Train yields
significant improvements, while preserving performance on exocentric datasets.
Our work thus provides essential resources and insights for advancing
egocentric video understanding. Our code is available at
https://github.com/LaVi-Lab/EgoMask .

</details>


### [53] [Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving](https://arxiv.org/abs/2508.00589)
*Stefan Englmeier,Max A. Büttner,Katharina Winter,Fabian B. Flohr*

Main category: cs.CV

TL;DR: 本文提出了一种新的上下文感知运动检索框架，用于在大规模数据集中检索罕见的人类行为场景，并介绍了WayMoCo数据集，实验结果表明该方法优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统必须在涉及VRU的异常或复杂行为的安全关键场景中可靠运行。然而，在大规模数据集中检索罕见的人类行为场景是具有挑战性的。因此，需要一种能够支持针对多样化、以人类为中心的场景进行目标评估的方法。

Method: 本文提出了一种结合SMPL-based运动序列和对应视频帧的上下文感知运动检索框架，并将它们编码到与自然语言对齐的共享多模态嵌入空间中。此外，还介绍了WayMoCo数据集，该数据集包含从生成的伪地面真实SMPL序列和对应的图像数据中自动标记的运动和场景上下文描述。

Result: 本文提出的框架在WayMoCo数据集上表现出色，相比最先进的模型，准确率提高了27.5%。

Conclusion: 本文提出了一种新的上下文感知运动检索框架，能够通过文本查询可扩展地检索人类行为及其上下文。该方法在WayMoCo数据集上的实验结果表明，其性能优于最先进的模型，准确率提高了27.5%。

Abstract: Autonomous driving systems must operate reliably in safety-critical
scenarios, particularly those involving unusual or complex behavior by
Vulnerable Road Users (VRUs). Identifying these edge cases in driving datasets
is essential for robust evaluation and generalization, but retrieving such rare
human behavior scenarios within the long tail of large-scale datasets is
challenging. To support targeted evaluation of autonomous driving systems in
diverse, human-centered scenarios, we propose a novel context-aware motion
retrieval framework. Our method combines Skinned Multi-Person Linear
(SMPL)-based motion sequences and corresponding video frames before encoding
them into a shared multimodal embedding space aligned with natural language.
Our approach enables the scalable retrieval of human behavior and their context
through text queries. This work also introduces our dataset WayMoCo, an
extension of the Waymo Open Dataset. It contains automatically labeled motion
and scene context descriptions derived from generated pseudo-ground-truth SMPL
sequences and corresponding image data. Our approach outperforms
state-of-the-art models by up to 27.5% accuracy in motion-context retrieval,
when evaluated on the WayMoCo dataset.

</details>


<div id='q-fin.TR'></div>

# q-fin.TR [[Back]](#toc)

### [54] [ContestTrade: A Multi-Agent Trading System Based on Internal Contest Mechanism](https://arxiv.org/abs/2508.00554)
*Li Zhao,Rui Sun,Zuoyou Jiang,Bo Yang,Yuxiao Bai,Mengting Chen,Xinyang Wang,Jing Li,Zuo Bai*

Main category: q-fin.TR

TL;DR: 本文提出了一种基于内部竞争机制的多智能体系统，通过实时评估和排名机制提高LLM在金融交易中的性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在金融交易中对市场噪声的高度敏感性问题，以提高交易系统的性能。

Method: 提出了一种基于内部竞争机制的多智能体系统，包括数据团队和研究团队，每个团队都实施了实时评估和排名机制。

Result: 实验结果表明，所提出的系统在多种评估指标上显著优于现有的多智能体系统和传统的量化投资方法。

Conclusion: 该系统能够适应动态环境，增强对市场噪声的鲁棒性，并最终实现优越的交易表现。

Abstract: In financial trading, large language model (LLM)-based agents demonstrate
significant potential. However, the high sensitivity to market noise undermines
the performance of LLM-based trading systems. To address this limitation, we
propose a novel multi-agent system featuring an internal competitive mechanism
inspired by modern corporate management structures. The system consists of two
specialized teams: (1) Data Team - responsible for processing and condensing
massive market data into diversified text factors, ensuring they fit the
model's constrained context. (2) Research Team - tasked with making
parallelized multipath trading decisions based on deep research methods. The
core innovation lies in implementing a real-time evaluation and ranking
mechanism within each team, driven by authentic market feedback. Each agent's
performance undergoes continuous scoring and ranking, with only outputs from
top-performing agents being adopted. The design enables the system to
adaptively adjust to dynamic environment, enhances robustness against market
noise and ultimately delivers superior trading performance. Experimental
results demonstrate that our proposed system significantly outperforms
prevailing multiagent systems and traditional quantitative investment methods
across diverse evaluation metrics.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [55] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
*Yihong Dong,Xue Jiang,Yongding Tao,Huanyu Liu,Kechi Zhang,Lili Mou,Rongyu Cao,Yingwei Ma,Jue Chen,Binhua Li,Zhi Jin,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.AI

TL;DR: 本文提出RL-PLUS，通过结合内部探索与外部数据，解决了LLM的能力边界崩溃问题，并在多个任务中取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法在处理LLM的庞大动作空间和稀疏奖励时存在局限，导致能力边界崩溃，无法突破基础LLM的固有能力边界。

Method: RL-PLUS结合了内部探索（即思考）和外部数据（即学习），通过多重重要性采样解决外部数据的分布不匹配问题，并利用基于探索的优势函数引导模型走向高价值、未探索的推理路径。

Result: RL-PLUS在六个数学推理基准和六个分布外推理任务中表现优于现有RLVR方法，平均相对改进幅度从21.1%到69.2%。

Conclusion: RL-PLUS有效地解决了LLM的能力边界崩溃问题，并在多个数学推理基准和分布外推理任务中表现出色。

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has significantly
advanced the complex reasoning abilities of Large Language Models (LLMs).
However, it struggles to break through the inherent capability boundaries of
the base LLM, due to its inherently on-policy strategy with LLM's immense
action space and sparse reward. Further, RLVR can lead to the capability
boundary collapse, narrowing the LLM's problem-solving scope. To address this
problem, we propose RL-PLUS, a novel approach that synergizes internal
exploitation (i.e., Thinking) with external data (i.e., Learning) to achieve
stronger reasoning capabilities and surpass the boundaries of base models.
RL-PLUS integrates two core components: Multiple Importance Sampling to address
for distributional mismatch from external data, and an Exploration-Based
Advantage Function to guide the model towards high-value, unexplored reasoning
paths. We provide both theoretical analysis and extensive experiments to
demonstrate the superiority and generalizability of our approach. The results
show that RL-PLUS achieves state-of-the-art performance compared with existing
RLVR methods on six math reasoning benchmarks and exhibits superior performance
on six out-of-distribution reasoning tasks. It also achieves consistent and
significant gains across diverse model families, with average relative
improvements ranging from 21.1\% to 69.2\%. Moreover, Pass@k curves across
multiple benchmarks indicate that RL-PLUS effectively resolves the capability
boundary collapse problem.

</details>


### [56] [MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning](https://arxiv.org/abs/2508.00271)
*Hongjin Qian,Zheng Liu*

Main category: cs.AI

TL;DR: 本文提出了MetaAgent，这是一种受学习-做原理启发的代理范式，通过动手实践和持续自我改进来发展专业知识。MetaAgent在挑战性的知识发现基准测试中表现优于基于工作流的基线，并与端到端训练的代理相匹配或超越。


<details>
  <summary>Details</summary>
Motivation: 本文旨在开发一种能够通过持续自我改进和实践来发展专业知识的代理系统，以提高知识发现的效率和效果。

Method: MetaAgent是一种受学习-做原理启发的代理范式，通过动手实践和持续自我改进来发展专业知识。它从一个最小的工作流程开始，配备基本的推理和自适应求助能力。当遇到知识差距时，MetaAgent生成自然语言求助请求，并由专用工具路由器将其路由到最合适的外部工具。随着任务的解决，MetaAgent不断进行自我反思和答案验证，将可操作的经验提炼成简洁的文本，并动态地融入未来的任务上下文中。此外，MetaAgent通过组织其工具使用历史自主构建内部工具和持久的知识库，进一步增强了其检索和整合相关信息的能力。

Result: MetaAgent在GAIA、WebWalkerQA和BrowseCamp等挑战性的知识发现基准测试中表现优于基于工作流的基线，并与端到端训练的代理相匹配或超越。

Conclusion: MetaAgent在挑战性的知识发现基准测试中表现优于基于工作流的基线，并与端到端训练的代理相匹配或超越，展示了自我进化的代理系统在稳健、通用知识发现中的前景。

Abstract: In this work, we propose MetaAgent, an agentic paradigm inspired by the
principle of learning-by-doing, where expertise is developed through hands-on
practice and continual self-improvement. MetaAgent starts with a minimal
workflow, equipped only with basic reasoning and adaptive help-seeking
abilities. When a knowledge gap is encountered, MetaAgent generates natural
language help requests, which are routed to the most suitable external tool by
a dedicated tool router. As MetaAgent solves tasks, it continually conducts
self-reflection and answer verification, distilling actionable experience into
concise texts that are dynamically incorporated into future task contexts.
Besides, MetaAgent autonomously builds in-house tools and a persistent
knowledge base by organizing its tool-use history, further enhancing its
ability to retrieve and integrate relevant information We term this continual,
data-driven process as \textit{meta tool learning}, through which MetaAgent
incrementally refines its reasoning and tool-use strategies, without changing
model parameters or requiring further post-training. Evaluated on challenging
knowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,
MetaAgent consistently outperforms workflow-based baselines and matches or
exceeds end-to-end trained agents, demonstrating the promise of self-evolving
agentic systems for robust, general-purpose knowledge discovery. We provide our
source codes in https://github.com/qhjqhj00/MetaAgent.

</details>


### [57] [Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](https://arxiv.org/abs/2508.00282)
*Yi-Long Lu,Jiajun Song,Chunhui Zhang,Wei Wang*

Main category: cs.AI

TL;DR: 本文通过任务生成实验比较了人类和LLM代理的行为模式，发现人类任务生成受心理驱动因素影响，而LLM无法反映这些行为模式，表明人类认知与LLM之间存在核心差距。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨生成代理是否遵循类似的人类认知原则，并研究人类任务生成是否受到心理驱动因素的影响。

Method: 本文进行了一项任务生成实验，将人类反应与LLM代理（GPT-4o）的反应进行了比较。

Result: 研究发现，人类任务生成始终受到心理驱动因素的影响，包括个人价值观（如开放性）和认知风格。即使这些心理驱动因素被明确提供给LLM，它也无法反映相应的行为模式。LLM生成的任务明显较少社交、较少身体参与，并且主题上偏向抽象。然而，LLM的任务被认为更具趣味性和新颖性。

Conclusion: 本文得出结论，人类认知的价值驱动和具身性与LLM的统计模式之间存在核心差距，强调了在设计更符合人类的代理时需要融入内在动机和物理基础的必要性。

Abstract: Humans constantly generate a diverse range of tasks guided by internal
motivations. While generative agents powered by large language models (LLMs)
aim to simulate this complex behavior, it remains uncertain whether they
operate on similar cognitive principles. To address this, we conducted a
task-generation experiment comparing human responses with those of an LLM agent
(GPT-4o). We find that human task generation is consistently influenced by
psychological drivers, including personal values (e.g., Openness to Change) and
cognitive style. Even when these psychological drivers are explicitly provided
to the LLM, it fails to reflect the corresponding behavioral patterns. They
produce tasks that are markedly less social, less physical, and thematically
biased toward abstraction. Interestingly, while the LLM's tasks were perceived
as more fun and novel, this highlights a disconnect between its linguistic
proficiency and its capacity to generate human-like, embodied goals.We conclude
that there is a core gap between the value-driven, embodied nature of human
cognition and the statistical patterns of LLMs, highlighting the necessity of
incorporating intrinsic motivation and physical grounding into the design of
more human-aligned agents.

</details>


### [58] [R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge](https://arxiv.org/abs/2508.00324)
*Yeonjun In,Wonjoong Kim,Sangwu Park,Chanyoung Park*

Main category: cs.AI

TL;DR: 本文提出了一种名为R1-Act的后训练方法，通过结构化推理过程显式触发安全知识，以提高大型推理模型的安全性。该方法在保持推理性能的同时，显著提升了模型的安全性，且训练成本较低。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型在复杂任务上表现出色，但它们经常执行有害的用户指令，这引发了严重的安全问题。因此，需要一种有效的方法来提高这些模型的安全性。

Method: 本文提出了R1-Act方法，通过结构化推理过程显式触发安全知识，以解决大型推理模型在执行有害用户指令时的安全风险问题。

Result: R1-Act方法在保持推理性能的同时，显著提高了模型的安全性，并且只需要1000个训练示例和90分钟的单个RTX A6000 GPU训练时间。

Conclusion: 本文提出了一种简单且高效的后训练方法R1-Act，通过结构化推理过程显式触发安全知识，从而显著提高大型推理模型的安全性。

Abstract: Although large reasoning models (LRMs) have demonstrated impressive
capabilities on complex tasks, recent studies reveal that these models
frequently fulfill harmful user instructions, raising significant safety
concerns. In this paper, we investigate the underlying cause of LRM safety
risks and find that models already possess sufficient safety knowledge but fail
to activate it during reasoning. Based on this insight, we propose R1-Act, a
simple and efficient post-training method that explicitly triggers safety
knowledge through a structured reasoning process. R1-Act achieves strong safety
improvements while preserving reasoning performance, outperforming prior
alignment methods. Notably, it requires only 1,000 training examples and 90
minutes of training on a single RTX A6000 GPU. Extensive experiments across
multiple LRM backbones and sizes demonstrate the robustness, scalability, and
practical efficiency of our approach.

</details>


### [59] [Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](https://arxiv.org/abs/2508.00414)
*Tianqing Fang,Zhisong Zhang,Xiaoyang Wang,Rui Wang,Can Qin,Yuxuan Wan,Jun-Yu Ma,Ce Zhang,Jiaqi Chen,Xiyun Li,Hongming Zhang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: Cognitive Kernel-Pro is a fully open-source and free multi-module agent framework that enhances the development and evaluation of advanced AI agents by curating high-quality training data and exploring novel strategies for agent test-time reflection and voting, achieving state-of-the-art results on GAIA.


<details>
  <summary>Details</summary>
Motivation: Current agent systems are either closed-source or heavily reliant on a variety of paid APIs and proprietary tools, limiting accessibility and reproducibility for the research community. The goal is to democratize the development and evaluation of advanced AI agents.

Method: Cognitive Kernel-Pro is a fully open-source and (to the maximum extent) free multi-module agent framework that systematically investigates the curation of high-quality training data for Agent Foundation Models, focusing on the construction of queries, trajectories, and verifiable answers across four key domains: web, file, code, and general reasoning. It also explores novel strategies for agent test-time reflection and voting to enhance agent robustness and performance.

Result: Cognitive Kernel-Pro achieves state-of-the-art results among open-source and free agents on GAIA. Notably, its 8B-parameter open-source model surpasses previous leading systems such as WebDancer and WebSailor.

Conclusion: Cognitive Kernel-Pro establishes a new performance standard for accessible, high-capability AI agents by achieving state-of-the-art results among open-source and free agents.

Abstract: General AI Agents are increasingly recognized as foundational frameworks for
the next generation of artificial intelligence, enabling complex reasoning, web
interaction, coding, and autonomous research capabilities. However, current
agent systems are either closed-source or heavily reliant on a variety of paid
APIs and proprietary tools, limiting accessibility and reproducibility for the
research community. In this work, we present \textbf{Cognitive Kernel-Pro}, a
fully open-source and (to the maximum extent) free multi-module agent framework
designed to democratize the development and evaluation of advanced AI agents.
Within Cognitive Kernel-Pro, we systematically investigate the curation of
high-quality training data for Agent Foundation Models, focusing on the
construction of queries, trajectories, and verifiable answers across four key
domains: web, file, code, and general reasoning. Furthermore, we explore novel
strategies for agent test-time reflection and voting to enhance agent
robustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving
state-of-the-art results among open-source and free agents. Notably, our
8B-parameter open-source model surpasses previous leading systems such as
WebDancer and WebSailor, establishing a new performance standard for
accessible, high-capability AI agents. Code is available at
https://github.com/Tencent/CognitiveKernel-Pro

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [60] [Activation-Guided Local Editing for Jailbreaking Attacks](https://arxiv.org/abs/2508.00555)
*Jiecong Wang,Haoran Li,Hao Peng,Ziqian Zeng,Zihao Wang,Haohua Du,Zhengtao Yu*

Main category: cs.CR

TL;DR: 本文提出了一种名为 AGILE 的两阶段对抗攻击框架，能够有效提升攻击成功率并具有良好的迁移性，同时在面对现有防御机制时仍保持较高效果。


<details>
  <summary>Details</summary>
Motivation: 现有的 jailbreak 方法存在显著缺陷，例如 token 级别的攻击会产生不连贯或不可读的输入，且迁移性差，而 prompt 级别的攻击则缺乏可扩展性并依赖大量人工努力和人类创造力。因此，需要一种更有效、更简洁的方法来改进这些技术。

Method: 本文提出了一种两阶段框架，第一阶段基于场景生成上下文并改写原始恶意查询以隐藏其有害意图；第二阶段利用模型的隐藏状态信息进行细粒度编辑，从而引导模型对输入的内部表示从有害转向无害。

Result: 实验表明，该方法在攻击成功率方面达到了最先进的水平，比最强的基线方法提高了高达 37.74%。此外，该方法在黑盒模型上表现出优异的迁移性，并且在面对主流防御机制时仍保持较高的有效性。

Conclusion: 本文提出了一种名为AGILE的两阶段框架，能够有效提升对抗攻击的成功率，并在黑盒模型上表现出良好的迁移性。同时，AGILE在面对现有防御机制时仍保持较高的有效性，这揭示了当前防护措施的局限性，并为未来防御发展提供了有价值的见解。

Abstract: Jailbreaking is an essential adversarial technique for red-teaming these
models to uncover and patch security flaws. However, existing jailbreak methods
face significant drawbacks. Token-level jailbreak attacks often produce
incoherent or unreadable inputs and exhibit poor transferability, while
prompt-level attacks lack scalability and rely heavily on manual effort and
human ingenuity. We propose a concise and effective two-stage framework that
combines the advantages of these approaches. The first stage performs a
scenario-based generation of context and rephrases the original malicious query
to obscure its harmful intent. The second stage then utilizes information from
the model's hidden states to guide fine-grained edits, effectively steering the
model's internal representation of the input from a malicious toward a benign
one. Extensive experiments demonstrate that this method achieves
state-of-the-art Attack Success Rate, with gains of up to 37.74% over the
strongest baseline, and exhibits excellent transferability to black-box models.
Our analysis further demonstrates that AGILE maintains substantial
effectiveness against prominent defense mechanisms, highlighting the
limitations of current safeguards and providing valuable insights for future
defense development. Our code is available at
https://github.com/yunsaijc/AGILE.

</details>


### [61] [Demo: TOSense -- What Did You Just Agree to?](https://arxiv.org/abs/2508.00659)
*Xinzhang Chen,Hassan Ali,Arash Shaghaghi,Salil S. Kanhere,Sanjay Jha*

Main category: cs.CR

TL;DR: 本文提出了一种名为TOSense的Chrome扩展程序，允许用户通过自然语言提问关于条款和条件的问题，并实时获得简洁的答案。


<details>
  <summary>Details</summary>
Motivation: 在线服务通常要求用户同意冗长且晦涩的条款和条件，导致信息不对称和法律风险。

Method: TOSense结合了爬虫工具tos-crawl和轻量级大语言模型管道，包括MiniLM用于语义检索和BART-encoder用于答案相关性验证。此外，还提出了一个新颖的问答评估管道(QEP)来生成合成问题并使用聚类主题匹配验证答案的正确性。

Result: 在五个主要平台（Apple、Google、X（前Twitter）、Microsoft和Netflix）上的实验表明，TOSense在不同数量的主题聚类下表现出有效性（最高达44.5%的准确率）。

Conclusion: TOSense能够有效提高用户对Terms of Service的理解，减少信息不对称和法律风险。

Abstract: Online services often require users to agree to lengthy and obscure Terms of
Service (ToS), leading to information asymmetry and legal risks. This paper
proposes TOSense-a Chrome extension that allows users to ask questions about
ToS in natural language and get concise answers in real time. The system
combines (i) a crawler "tos-crawl" that automatically extracts ToS content, and
(ii) a lightweight large language model pipeline: MiniLM for semantic retrieval
and BART-encoder for answer relevance verification. To avoid expensive manual
annotation, we present a novel Question Answering Evaluation Pipeline (QEP)
that generates synthetic questions and verifies the correctness of answers
using clustered topic matching. Experiments on five major platforms, Apple,
Google, X (formerly Twitter), Microsoft, and Netflix, show the effectiveness of
TOSense (with up to 44.5% accuracy) across varying number of topic clusters.
During the demonstration, we will showcase TOSense in action. Attendees will be
able to experience seamless extraction, interactive question answering, and
instant indexing of new sites.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [62] [Watch the Weights: Unsupervised monitoring and control of fine-tuned LLMs](https://arxiv.org/abs/2508.00161)
*Ziqian Zhong,Aditi Raghunathan*

Main category: cs.LG

TL;DR: 本文提出了一种新的方法，通过分析权重差异来理解和监控微调后的大型语言模型，无需分布相似的数据。该方法在检测后门模型和未学习的模型方面表现出色，并展示了在部署前模型审计中的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的解释方法通常需要分布相似的数据，这在检测和防御新型威胁（如后门）时是一个重大限制。本文旨在解决这一问题，提供一种无需分布相似数据的方法。

Method: 本文提出了一种基于权重差异的奇异向量分析方法，通过监测激活在这些方向上的余弦相似性来检测微调过程中引入的重要行为。

Result: 本文方法能够以高精度检测微调过程中引入的行为，对于后门模型，能够阻止高达100%的攻击，且误报率低于1.2%。对于未学习的模型，检测准确率高达95.42%。此外，该方法还展示了在部署前模型审计中的潜力。

Conclusion: 本文提出了一种新的方法来理解和监控微调后的大型语言模型，该方法通过解释权重而不是激活，从而避免了对分布相似数据的需求。该方法在检测后门模型和未学习的模型方面表现出色，并展示了在部署前模型审计中的潜力。

Abstract: The releases of powerful open-weight large language models (LLMs) are often
not accompanied by access to their full training data. Existing
interpretability methods, particularly those based on activations, often
require or assume distributionally similar data. This is a significant
limitation when detecting and defending against novel potential threats like
backdoors, which are by definition out-of-distribution.
  In this work, we introduce a new method for understanding, monitoring and
controlling fine-tuned LLMs that interprets weights, rather than activations,
thereby side stepping the need for data that is distributionally similar to the
unknown training data. We demonstrate that the top singular vectors of the
weight difference between a fine-tuned model and its base model correspond to
newly acquired behaviors. By monitoring the cosine similarity of activations
along these directions, we can detect salient behaviors introduced during
fine-tuning with high precision.
  For backdoored models that bypasses safety mechanisms when a secret trigger
is present, our method stops up to 100% of attacks with a false positive rate
below 1.2%. For models that have undergone unlearning, we detect inference on
erased topics with accuracy up to 95.42% and can even steer the model to
recover "unlearned" information. Besides monitoring, our method also shows
potential for pre-deployment model auditing: by analyzing commercial
instruction-tuned models (OLMo, Llama, Qwen), we are able to uncover
model-specific fine-tuning focus including marketing strategies and Midjourney
prompt generation.
  Our implementation can be found at https://github.com/fjzzq2002/WeightWatch.

</details>


### [63] [Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product](https://arxiv.org/abs/2508.00230)
*Paul Albert,Frederic Z. Zhang,Hemanth Saratchandran,Anton van den Hengel,Ehsan Abbasnejad*

Main category: cs.LG

TL;DR: This paper introduces KRAdapter, a novel PEFT algorithm that improves upon LoRA by leveraging the Khatri-Rao product to produce weight updates with high effective rank, resulting in better performance on large models while maintaining efficiency.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the limitations of LoRA in approximating matrices with flat spectrums or high frequency components, particularly in multimodal and large language models.

Method: The paper presents a quantitative comparison between full-rank and low-rank PEFT methods using a synthetic matrix approximation benchmark. It introduces KRAdapter, which leverages the Khatri-Rao product to produce weight updates with high effective rank.

Result: KRAdapter demonstrates performance gains on vision-language models up to 1B parameters and on large language models up to 8B parameters, especially on unseen common-sense reasoning tasks.

Conclusion: KRAdapter provides performance gains on vision-language models and large language models while maintaining the memory and compute efficiency of LoRA.

Abstract: Parameter-efficient fine-tuning (PEFT) has become a standard approach for
adapting large pre-trained models. Amongst PEFT methods, low-rank adaptation
(LoRA) has achieved notable success. However, recent studies have highlighted
its limitations compared against full-rank alternatives, particularly when
applied to multimodal and large language models. In this work, we present a
quantitative comparison amongst full-rank and low-rank PEFT methods using a
synthetic matrix approximation benchmark with controlled spectral properties.
Our results confirm that LoRA struggles to approximate matrices with relatively
flat spectrums or high frequency components -- signs of high effective ranks.
To this end, we introduce KRAdapter, a novel PEFT algorithm that leverages the
Khatri-Rao product to produce weight updates, which, by construction, tends to
produce matrix product with a high effective rank. We demonstrate performance
gains with KRAdapter on vision-language models up to 1B parameters and on large
language models up to 8B parameters, particularly on unseen common-sense
reasoning tasks. In addition, KRAdapter maintains the memory and compute
efficiency of LoRA, making it a practical and robust alternative to fine-tune
billion-scale parameter models.

</details>


### [64] [Classification of Psychiatry Clinical Notes by Diagnosis: A Deep Learning and Machine Learning Approach](https://arxiv.org/abs/2508.00695)
*Sergio Rubio-Martín,María Teresa García-Ordás,Antonio Serrano-García,Clara Margarita Franch-Pato,Arturo Crespo-Álvaro,José Alberto Benítez-Andrades*

Main category: cs.LG

TL;DR: 本研究比较了不同人工智能模型在临床笔记分类中的表现，发现超参数调优能显著提高模型准确性，而SMOTE在基于BERT的模型中具有积极影响。


<details>
  <summary>Details</summary>
Motivation: 临床笔记的分类对于医疗领域，特别是心理健康状况（如焦虑和适应障碍）至关重要。本研究旨在评估不同人工智能模型在这一任务中的表现，并探索过采样技术和超参数调优对模型性能的影响。

Method: 本研究比较了传统机器学习方法（如随机森林、支持向量机、K近邻、决策树和极端梯度提升）以及深度学习模型（如DistilBERT和SciBERT）在分类临床笔记中的表现，并实施了三种过采样策略（无过采样、随机过采样和SMOTE）以评估其对模型性能的影响。此外，还进行了超参数调优以优化模型准确性。

Result: 结果表明，过采样技术总体上对模型性能影响较小，但SMOTE在基于BERT的模型中显示出积极效果。同时，超参数调优显著提高了模型的准确性，使其在数据集上的表现更好。决策树和极端梯度提升模型在机器学习方法中达到了最高的96%准确率，而DistilBERT和SciBERT在深度学习类别中也达到了96%的准确率。

Conclusion: 本研究通过比较不同人工智能模型在临床笔记分类中的表现，强调了超参数调优在最大化模型性能中的重要性。结果表明，决策树和极端梯度提升模型在机器学习方法中表现最佳，而基于BERT的模型在使用SMOTE时表现出积极效果。

Abstract: The classification of clinical notes into specific diagnostic categories is
critical in healthcare, especially for mental health conditions like Anxiety
and Adjustment Disorder. In this study, we compare the performance of various
Artificial Intelligence models, including both traditional Machine Learning
approaches (Random Forest, Support Vector Machine, K-nearest neighbors,
Decision Tree, and eXtreme Gradient Boost) and Deep Learning models (DistilBERT
and SciBERT), to classify clinical notes into these two diagnoses.
Additionally, we implemented three oversampling strategies: No Oversampling,
Random Oversampling, and Synthetic Minority Oversampling Technique (SMOTE), to
assess their impact on model performance. Hyperparameter tuning was also
applied to optimize model accuracy. Our results indicate that oversampling
techniques had minimal impact on model performance overall. The only exception
was SMOTE, which showed a positive effect specifically with BERT-based models.
However, hyperparameter optimization significantly improved accuracy across the
models, enhancing their ability to generalize and perform on the dataset. The
Decision Tree and eXtreme Gradient Boost models achieved the highest accuracy
among machine learning approaches, both reaching 96%, while the DistilBERT and
SciBERT models also attained 96% accuracy in the deep learning category. These
findings underscore the importance of hyperparameter tuning in maximizing model
performance. This study contributes to the ongoing research on AI-assisted
diagnostic tools in mental health by providing insights into the efficacy of
different model architectures and data balancing methods.

</details>
