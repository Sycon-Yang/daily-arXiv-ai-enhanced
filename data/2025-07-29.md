<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 81]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.IR](#cs.IR) [Total: 1]
- [q-fin.PM](#q-fin.PM) [Total: 1]
- [cs.CY](#cs.CY) [Total: 2]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.AI](#cs.AI) [Total: 5]
- [q-fin.TR](#q-fin.TR) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Advancing Mental Disorder Detection: A Comparative Evaluation of Transformer and LSTM Architectures on Social Media](https://arxiv.org/abs/2507.19511)
*Khalid Hasan,Jamil Saquer,Mukulika Ghosh*

Main category: cs.CL

TL;DR: 本研究评估了基于transformer的模型和基于LSTM的方法在Reddit上的精神健康障碍分类任务中的性能。结果表明，transformer模型优于传统深度学习方法，其中RoBERTa表现最佳。结合BERT嵌入的LSTM模型也表现出色，具有较低的计算需求。


<details>
  <summary>Details</summary>
Motivation: 精神健康障碍的日益普遍需要开发强大的自动化工具进行早期检测和监测。最近的自然语言处理（NLP）进展，特别是基于transformer的架构，在文本分析中表现出显著潜力。

Method: 本研究对最先进的transformer模型（BERT、RoBERTa、DistilBERT、ALBERT和ELECTRA）与基于LSTM的方法进行了全面评估，使用不同的文本嵌入技术进行Reddit上的精神健康障碍分类。

Result: 实验结果表明，transformer模型在传统深度学习方法上表现更优。RoBERTa在保留测试集上达到了99.54%的F1分数，在外部测试集上达到了96.05%的F1分数。值得注意的是，结合BERT嵌入的LSTM模型表现非常有竞争力，在外部数据集上F1分数超过94%，同时需要的计算资源显著减少。

Conclusion: 这些发现突显了基于transformer的模型在实时、可扩展的心理健康监测中的有效性。我们讨论了对临床应用和数字心理健康干预的意义，提供了对最先进的NLP方法在精神障碍检测中的能力和局限性的见解。

Abstract: The rising prevalence of mental health disorders necessitates the development
of robust, automated tools for early detection and monitoring. Recent advances
in Natural Language Processing (NLP), particularly transformer-based
architectures, have demonstrated significant potential in text analysis. This
study provides a comprehensive evaluation of state-of-the-art transformer
models (BERT, RoBERTa, DistilBERT, ALBERT, and ELECTRA) against Long Short-Term
Memory (LSTM) based approaches using different text embedding techniques for
mental health disorder classification on Reddit. We construct a large annotated
dataset, validating its reliability through statistical judgmental analysis and
topic modeling. Experimental results demonstrate the superior performance of
transformer models over traditional deep-learning approaches. RoBERTa achieved
the highest classification performance, with a 99.54% F1 score on the hold-out
test set and a 96.05% F1 score on the external test set. Notably, LSTM models
augmented with BERT embeddings proved highly competitive, achieving F1 scores
exceeding 94% on the external dataset while requiring significantly fewer
computational resources. These findings highlight the effectiveness of
transformer-based models for real-time, scalable mental health monitoring. We
discuss the implications for clinical applications and digital mental health
interventions, offering insights into the capabilities and limitations of
state-of-the-art NLP methodologies in mental disorder detection.

</details>


### [2] [Setting The Table with Intent: Intent-aware Schema Generation and Editing for Literature Review Tables](https://arxiv.org/abs/2507.19521)
*Vishakh Padmakumar,Joseph Chee Chang,Kyle Lo,Doug Downey,Aakanksha Naik*

Main category: cs.CL

TL;DR: 本文提出了一种增强未注释表格语料库的方法，并创建了一个数据集来研究基于给定信息需求的模式生成。我们还提出了几种基于LLM的模式编辑技术，并展示了这些技术可以进一步提高模式生成的效果。


<details>
  <summary>Details</summary>
Motivation: 由于参考评估中的模糊性和缺乏编辑/优化方法，模式生成的进步缓慢。因此，需要一种新的方法来解决这些问题，以提高模式生成的效果。

Method: 我们首先提出了一种增强未注释表格语料库的方法，并将其应用于创建一个数据集，以研究基于给定信息需求的模式生成。然后，我们对几种单次模式生成方法进行了全面的基准测试，包括提示LLM工作流程和微调模型，并展示了较小的开放权重模型可以通过微调与最先进的提示LLM竞争。最后，我们展示了我们的编辑技术可以进一步改进这些方法生成的模式。

Result: 我们通过创建一个数据集来研究基于给定信息需求的模式生成，结果表明，结合表格意图可以显著提高基线性能。此外，我们的编辑技术可以进一步提高由这些方法生成的模式。

Conclusion: 我们的工作是第一个同时解决这两个问题的研究。我们提出了一个用于增强未注释表格语料库的方法，并应用它来创建一个数据集，用于研究基于给定信息需求的模式生成，从而减少歧义。此外，我们提出了几种基于LLM的模式编辑技术，并展示了这些技术可以进一步提高由这些方法生成的模式。

Abstract: The increasing volume of academic literature makes it essential for
researchers to organize, compare, and contrast collections of documents. Large
language models (LLMs) can support this process by generating schemas defining
shared aspects along which to compare papers. However, progress on schema
generation has been slow due to: (i) ambiguity in reference-based evaluations,
and (ii) lack of editing/refinement methods. Our work is the first to address
both issues. First, we present an approach for augmenting unannotated table
corpora with synthesized intents and apply it to create a dataset for studying
schema generation conditioned on a given information need, thus reducing
ambiguity. With this dataset, we show how incorporating table intents
significantly improves baseline performance in reconstructing reference
schemas. Next, we propose several LLM-based schema editing techniques. We start
by comprehensively benchmarking several single-shot schema generation methods,
including prompted LLM workflows and fine-tuned models, showing that smaller,
open-weight models can be fine-tuned to be competitive with state-of-the-art
prompted LLMs. Then we demonstrate that our editing techniques can further
improve schemas generated by these methods.

</details>


### [3] [Mind the Language Gap in Digital Humanities: LLM-Aided Translation of SKOS Thesauri](https://arxiv.org/abs/2507.19537)
*Felix Kraus,Nicolas Blumenröhr,Danah Tonne,Achim Streit*

Main category: cs.CL

TL;DR: WOKIE 是一种开源、模块化且易于使用的自动化 SKOS 术语表翻译管道，结合了外部翻译服务和大型语言模型优化，提高了术语表的可访问性和跨语言互操作性。


<details>
  <summary>Details</summary>
Motivation: 在数字人文领域，语言多样性可能限制知识资源的访问、再利用和语义互操作性，因此需要一种自动化翻译工具。

Method: WOKIE 结合外部翻译服务与使用大型语言模型（LLMs）进行有针对性的优化，以平衡翻译质量、可扩展性和成本。

Result: WOKIE 在15种语言的多个数字人文术语表上进行了评估，结果表明它能够提高翻译质量、性能和本体匹配改进。

Conclusion: WOKIE 是一种适合增强术语表的可访问性、再利用性和跨语言互操作性的工具，通过无障碍的自动翻译和改进的本体匹配性能，支持更包容和多语言的研究基础设施。

Abstract: We introduce WOKIE, an open-source, modular, and ready-to-use pipeline for
the automated translation of SKOS thesauri. This work addresses a critical need
in the Digital Humanities (DH), where language diversity can limit access,
reuse, and semantic interoperability of knowledge resources. WOKIE combines
external translation services with targeted refinement using Large Language
Models (LLMs), balancing translation quality, scalability, and cost. Designed
to run on everyday hardware and be easily extended, the application requires no
prior expertise in machine translation or LLMs. We evaluate WOKIE across
several DH thesauri in 15 languages with different parameters, translation
services and LLMs, systematically analysing translation quality, performance,
and ontology matching improvements. Our results show that WOKIE is suitable to
enhance the accessibility, reuse, and cross-lingual interoperability of
thesauri by hurdle-free automated translation and improved ontology matching
performance, supporting more inclusive and multilingual research
infrastructures.

</details>


### [4] [Mitigating Geospatial Knowledge Hallucination in Large Language Models: Benchmarking and Dynamic Factuality Aligning](https://arxiv.org/abs/2507.19586)
*Shengyuan Wang,Jie Feng,Tianhui Liu,Dan Pei,Yong Li*

Main category: cs.CL

TL;DR: 本文提出了一种评估和减轻LLMs中地理空间幻觉的方法，显著提高了LLMs在地理空间任务中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在地理空间任务中表现出色，但它们经常生成不准确的地理空间知识，导致地理空间幻觉，影响其可靠性。目前对地理空间幻觉的系统评估和缓解研究仍较少。

Method: 本文提出了一个基于结构化地理空间知识图谱的评估框架，并采用Kahneman-Tversky优化方法来减轻地理空间幻觉。

Result: 通过在20个先进的LLMs上进行广泛评估，发现了其中的地理空间幻觉。基于这些见解，引入了一种基于KTO的动态事实对齐方法，使性能提高了29.6%以上。实验结果表明，该基准和学习算法有效提升了LLMs在地理空间知识和推理任务中的可信度。

Conclusion: 本文提出了一个全面的地理空间幻觉评估框架，并引入了一种基于Kahneman-Tversky优化（KTO）的动态事实对齐方法，以减轻LLMs中的地理空间幻觉，从而提高了LLMs在地理空间知识和推理任务中的可信度。

Abstract: Large language models (LLMs) possess extensive world knowledge, including
geospatial knowledge, which has been successfully applied to various geospatial
tasks such as mobility prediction and social indicator prediction. However,
LLMs often generate inaccurate geospatial knowledge, leading to geospatial
hallucinations (incorrect or inconsistent representations of geospatial
information) that compromise their reliability. While the phenomenon of general
knowledge hallucination in LLMs has been widely studied, the systematic
evaluation and mitigation of geospatial hallucinations remain largely
unexplored. To address this gap, we propose a comprehensive evaluation
framework for geospatial hallucinations, leveraging structured geospatial
knowledge graphs for controlled assessment. Through extensive evaluation across
20 advanced LLMs, we uncover the hallucinations in their geospatial knowledge.
Building on these insights, we introduce a dynamic factuality aligning method
based on Kahneman-Tversky Optimization (KTO) to mitigate geospatial
hallucinations in LLMs, leading to a performance improvement of over 29.6% on
the proposed benchmark. Extensive experimental results demonstrate the
effectiveness of our benchmark and learning algorithm in enhancing the
trustworthiness of LLMs in geospatial knowledge and reasoning tasks.

</details>


### [5] [Efficient Attention Mechanisms for Large Language Models: A Survey](https://arxiv.org/abs/2507.19595)
*Yutao Sun,Zhenyu Li,Yike Zhang,Tengyu Pan,Bowen Dong,Yuyi Guo,Jianyong Wang*

Main category: cs.CL

TL;DR: 本文综述了高效的注意力机制，包括线性注意力和稀疏注意力，并分析了它们在大规模预训练语言模型中的应用。


<details>
  <summary>Details</summary>
Motivation: 由于自注意力的二次时间复杂度和内存复杂度限制了长上下文建模的效率，因此需要研究高效的注意力机制。

Method: 本文对线性注意力方法和稀疏注意力技术进行了系统综述，并分析了它们在大规模预训练语言模型中的应用。

Result: 本文提供了对这些发展的系统全面概述，包括算法创新和硬件层面的考虑。

Conclusion: 本文旨在为推进可扩展和高效的语言模型设计提供基础参考。

Abstract: Transformer-based architectures have become the prevailing backbone of large
language models. However, the quadratic time and memory complexity of
self-attention remains a fundamental obstacle to efficient long-context
modeling. To address this limitation, recent research has introduced two
principal categories of efficient attention mechanisms. Linear attention
methods achieve linear complexity through kernel approximations, recurrent
formulations, or fastweight dynamics, thereby enabling scalable inference with
reduced computational overhead. Sparse attention techniques, in contrast, limit
attention computation to selected subsets of tokens based on fixed patterns,
block-wise routing, or clustering strategies, enhancing efficiency while
preserving contextual coverage. This survey provides a systematic and
comprehensive overview of these developments, integrating both algorithmic
innovations and hardware-level considerations. In addition, we analyze the
incorporation of efficient attention into largescale pre-trained language
models, including both architectures built entirely on efficient attention and
hybrid designs that combine local and global components. By aligning
theoretical foundations with practical deployment strategies, this work aims to
serve as a foundational reference for advancing the design of scalable and
efficient language models.

</details>


### [6] [MOCHA: Are Code Language Models Robust Against Multi-Turn Malicious Coding Prompts?](https://arxiv.org/abs/2507.19598)
*Muntasir Wahed,Xiaona Zhou,Kiet A. Nguyen,Tianjiao Yu,Nirav Diwan,Gang Wang,Dilek Hakkani-Tür,Ismini Lourentzou*

Main category: cs.CL

TL;DR: 本文研究了代码分解攻击对大型语言模型的影响，并提出了一种评估其鲁棒性的基准测试。结果显示，模型在多轮场景下存在漏洞，但通过微调可以提高拒绝率并增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在代码生成方面取得了显著进展，但其在对抗性滥用方面的鲁棒性仍研究不足。特别是针对多轮恶意编码提示的鲁棒性尚未得到充分探索。

Method: 引入了代码分解攻击，将恶意编码任务分解为多个看似无害的子任务，以逃避安全过滤器。还提出了一个大规模基准测试，用于评估代码LLM对单轮和多轮恶意提示的鲁棒性。

Result: 实证结果表明，开放和闭源模型在多轮场景下存在持续的漏洞。在MOCHA上进行微调可以提高拒绝率，同时保持编码能力，并显著增强对外部对抗数据集的鲁棒性。

Conclusion: 研究表明，代码分解攻击可以有效规避安全过滤器，且在多轮场景下存在持续的漏洞。通过在MOCHA上进行微调，可以提高拒绝率并保持编码能力，同时显著增强对外部对抗数据集的鲁棒性。

Abstract: Recent advancements in Large Language Models (LLMs) have significantly
enhanced their code generation capabilities. However, their robustness against
adversarial misuse, particularly through multi-turn malicious coding prompts,
remains underexplored. In this work, we introduce code decomposition attacks,
where a malicious coding task is broken down into a series of seemingly benign
subtasks across multiple conversational turns to evade safety filters. To
facilitate systematic evaluation, we introduce \benchmarkname{}, a large-scale
benchmark designed to evaluate the robustness of code LLMs against both
single-turn and multi-turn malicious prompts. Empirical results across open-
and closed-source models reveal persistent vulnerabilities, especially under
multi-turn scenarios. Fine-tuning on MOCHA improves rejection rates while
preserving coding ability, and importantly, enhances robustness on external
adversarial datasets with up to 32.4% increase in rejection rates without any
additional supervision.

</details>


### [7] [HITSZ's End-To-End Speech Translation Systems Combining Sequence-to-Sequence Auto Speech Recognition Model and Indic Large Language Model for IWSLT 2025 in Indic Track](https://arxiv.org/abs/2507.19616)
*Xuchen Wei,Yangxin Wu,Yaoyin Zhang,Henglyu Liu,Kehai Chen,Xuefeng Bai,Min Zhang*

Main category: cs.CL

TL;DR: 本文介绍了HITSZ在IWSLT 2025印地语赛道的提交，提出了一种端到端系统，将预训练的Whisper ASR模型与Krutrim LLM结合，以提高英语到印地语和印地语到英语的语音到文本翻译质量。


<details>
  <summary>Details</summary>
Motivation: 为了在低资源情况下提高翻译质量，我们提出了一个端到端系统，将预训练的Whisper自动语音识别（ASR）模型与Krutrim（一个专注于印地语的大语言模型）结合。

Method: 我们提出了一个端到端系统，将预训练的Whisper自动语音识别（ASR）模型与Krutrim（一个专注于印地语的大语言模型）结合。

Result: 实验结果表明，我们的端到端系统在英语到印地语方向平均BLEU得分为28.88，在印地语到英语方向平均BLEU得分为27.86。此外，我们研究了Chain-of-Thought（CoT）方法，该方法在成功解析的输出中显示出显著的翻译质量提升。

Conclusion: 我们的端到端系统在英语到印地语方向平均BLEU得分为28.88，在印地语到英语方向平均BLEU得分为27.86。虽然Chain-of-Thought方法在成功解析的输出中显示出显著的翻译质量提升，但模型在保持所需的CoT输出格式方面遇到了挑战。

Abstract: This paper presents HITSZ's submission for the IWSLT 2025 Indic track,
focusing on speech-to-text translation (ST) for English-to-Indic and
Indic-to-English language pairs. To enhance translation quality in this
low-resource scenario, we propose an end-to-end system integrating the
pre-trained Whisper automated speech recognition (ASR) model with Krutrim, an
Indic-specialized large language model (LLM). Experimental results demonstrate
that our end-to-end system achieved average BLEU scores of $28.88$ for
English-to-Indic directions and $27.86$ for Indic-to-English directions.
Furthermore, we investigated the Chain-of-Thought (CoT) method. While this
method showed potential for significant translation quality improvements on
successfully parsed outputs (e.g. a $13.84$ BLEU increase for
Tamil-to-English), we observed challenges in ensuring the model consistently
adheres to the required CoT output format.

</details>


### [8] [MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks](https://arxiv.org/abs/2507.19634)
*Sara Papi,Maike Züfle,Marco Gaido,Beatrice Savoldi,Danni Liu,Ioannis Douros,Luisa Bentivogli,Jan Niehues*

Main category: cs.CL

TL;DR: MCIF 是一个用于评估多语言和多模态指令遵循能力的基准，旨在推动多模态大语言模型的发展。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估多语言和多模态能力方面存在不足，如局限于英语、单一模态、短文本或缺乏人工标注。

Method: 引入 MCIF 基准，该基准基于科学演讲，包含三种核心模态（语音、视觉和文本）和四种语言（英语、德语、意大利语和中文）。

Result: MCIF 是第一个多语言人工标注的基准，能够全面评估多模态大语言模型在跨语言和多模态设置下的指令遵循能力。

Conclusion: MCIF 是一个用于评估多语言和多模态指令遵循能力的基准，旨在推动多模态大语言模型的发展。

Abstract: Recent advances in large language models have catalyzed the development of
multimodal LLMs (MLLMs) that integrate text, speech, and vision within unified
frameworks. As MLLMs evolve from narrow, monolingual, task-specific systems to
general-purpose instruction-following models, a key frontier lies in evaluating
their multilingual and multimodal capabilities over both long and short
contexts. However, existing benchmarks fall short in evaluating these
dimensions jointly: they are often limited to English, mostly focus on one
single modality at a time, rely on short-form contexts, or lack human
annotations -- hindering comprehensive assessment of model performance across
languages, modalities, and task complexity. To address these gaps, we introduce
MCIF (Multimodal Crosslingual Instruction Following), the first multilingual
human-annotated benchmark based on scientific talks that is designed to
evaluate instruction-following in crosslingual, multimodal settings over both
short- and long-form inputs. MCIF spans three core modalities -- speech,
vision, and text -- and four diverse languages (English, German, Italian, and
Chinese), enabling a comprehensive evaluation of MLLMs' abilities to interpret
instructions across languages and combine them with multimodal contextual
information. MCIF is released under a CC-BY 4.0 license to encourage open
research and progress in MLLMs development.

</details>


### [9] [RoD-TAL: A Benchmark for Answering Questions in Romanian Driving License Exams](https://arxiv.org/abs/2507.19666)
*Andrei Vlad Man,Răzvan-Alexandru Smădu,Cristian-George Craciun,Dumitru-Clementin Cercel,Florin Pop,Mihaela-Claudia Cercel*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）和视觉-语言模型（VLMs）在理解罗马尼亚驾驶法律方面的能力，并引入了一个新的多模态数据集RoD-TAL。实验表明，领域特定的微调和链式思维提示可以提高性能，但视觉推理仍然具有挑战性。


<details>
  <summary>Details</summary>
Motivation: AI和法律系统的交叉点需要支持法律教育的工具，特别是在资源不足的语言如罗马尼亚语中。

Method: 我们实施并评估了检索增强生成（RAG）管道、密集检索器和优化推理的模型，涵盖了信息检索（IR）、问答（QA）、视觉IR和视觉QA任务。

Result: 领域特定的微调显著提高了检索性能。链式思维提示和专门的推理模型提高了QA准确性，超过了通过驾驶考试所需的最低等级。

Conclusion: 视觉推理仍然具有挑战性，这突显了将LLMs和VLMs应用于法律教育的潜力和局限性。

Abstract: The intersection of AI and legal systems presents a growing need for tools
that support legal education, particularly in under-resourced languages such as
Romanian. In this work, we aim to evaluate the capabilities of Large Language
Models (LLMs) and Vision-Language Models (VLMs) in understanding and reasoning
about Romanian driving law through textual and visual question-answering tasks.
To facilitate this, we introduce RoD-TAL, a novel multimodal dataset comprising
Romanian driving test questions, text-based and image-based, alongside
annotated legal references and human explanations. We implement and assess
retrieval-augmented generation (RAG) pipelines, dense retrievers, and
reasoning-optimized models across tasks including Information Retrieval (IR),
Question Answering (QA), Visual IR, and Visual QA. Our experiments demonstrate
that domain-specific fine-tuning significantly enhances retrieval performance.
At the same time, chain-of-thought prompting and specialized reasoning models
improve QA accuracy, surpassing the minimum grades required to pass driving
exams. However, visual reasoning remains challenging, highlighting the
potential and the limitations of applying LLMs and VLMs to legal education.

</details>


### [10] [Towards Inclusive NLP: Assessing Compressed Multilingual Transformers across Diverse Language Benchmarks](https://arxiv.org/abs/2507.19699)
*Maitha Alshehhi,Ahmed Sharshar,Mohsen Guizani*

Main category: cs.CL

TL;DR: 本研究分析了多语言和单语言大型语言模型在阿拉伯语、英语和印地语等语言中的表现，发现多语言模型在所有情况下都优于其语言特定的对应模型，并指出了一些关键策略来构建可扩展且公平的多语言NLP解决方案。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在高资源语言中取得了显著成功，但它们在像卡纳达语和阿拉伯语这样的低资源语言环境中的能力尚未完全了解。

Method: 本研究对多语言和单语言大型语言模型（LLMs）在阿拉伯语、英语和印地语等语言中的表现进行了基准测试，特别关注模型压缩策略如剪枝和量化的影响。

Result: 研究发现，由于语言多样性和资源可用性，SOTA LLMs如BLOOMZ、AceGPT、Jais、LLaMA-2、XGLM和AraGPT2的表现存在显著差异。多语言版本的模型在所有情况下都优于其语言特定的对应模型，表明跨语言迁移有显著的好处。4位和8位量化在保持模型准确性的同时促进了效率，但激进的剪枝会显著损害性能，尤其是在更大的模型中。

Conclusion: 我们的研究指出了构建可扩展且公平的多语言NLP解决方案的关键策略，并强调了在低资源环境中解决幻觉和泛化错误的必要性。

Abstract: Although LLMs have attained significant success in high-resource languages,
their capacity in low-resource linguistic environments like Kannada and Arabic
is not yet fully understood. This work benchmarking the performance of
multilingual and monolingual Large Language Models (LLMs) across Arabic,
English, and Indic languages, with particular emphasis on the effects of model
compression strategies such as pruning and quantization. Findings shows
significant performance differences driven by linguistic diversity and resource
availability on SOTA LLMS as BLOOMZ, AceGPT, Jais, LLaMA-2, XGLM, and AraGPT2.
We find that multilingual versions of the model outperform their
language-specific counterparts across the board, indicating substantial
cross-lingual transfer benefits. Quantization (4-bit and 8-bit) is effective in
maintaining model accuracy while promoting efficiency, but aggressive pruning
significantly compromises performance, especially in bigger models. Our
findings pinpoint key strategies to construct scalable and fair multilingual
NLP solutions and underscore the need for interventions to address
hallucination and generalization errors in the low-resource setting.

</details>


### [11] [Ta-G-T: Subjectivity Capture in Table to Text Generation via RDF Graphs](https://arxiv.org/abs/2507.19710)
*Ronak Upasham,Tathagata Dey,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 本文提出了一种新的表格到文本生成方法，通过引入中间表示来增强事实准确性和主观性。


<details>
  <summary>Details</summary>
Motivation: 现有的表格到文本生成方法主要关注对表格数据的客观描述，而生成包含主观性的文本仍较少被研究。

Method: 本文提出了一个三阶段的管道：1) 提取资源描述框架（RDF）三元组，2) 将文本聚合为连贯的叙述，3) 注入主观性以丰富生成的文本。

Result: 实验结果表明，该方法在多个指标上表现优于Mistral-7B和Llama-2，并与GPT-3.5相当。

Conclusion: 本文提出了一种新的表格到文本生成的管道，通过引入中间表示来增强事实准确性和主观性。

Abstract: In Table-to-Text (T2T) generation, existing approaches predominantly focus on
providing objective descriptions of tabular data. However, generating text that
incorporates subjectivity, where subjectivity refers to interpretations beyond
raw numerical data, remains underexplored. To address this, we introduce a
novel pipeline that leverages intermediate representations to generate both
objective and subjective text from tables. Our three-stage pipeline consists
of: 1) extraction of Resource Description Framework (RDF) triples, 2)
aggregation of text into coherent narratives, and 3) infusion of subjectivity
to enrich the generated text. By incorporating RDFs, our approach enhances
factual accuracy while maintaining interpretability. Unlike large language
models (LLMs) such as GPT-3.5, Mistral-7B, and Llama-2, our pipeline employs
smaller, fine-tuned T5 models while achieving comparable performance to GPT-3.5
and outperforming Mistral-7B and Llama-2 in several metrics. We evaluate our
approach through quantitative and qualitative analyses, demonstrating its
effectiveness in balancing factual accuracy with subjective interpretation. To
the best of our knowledge, this is the first work to propose a structured
pipeline for T2T generation that integrates intermediate representations to
enhance both factual correctness and subjectivity.

</details>


### [12] [Basic Reading Distillation](https://arxiv.org/abs/2507.19741)
*Zhi Zhou,Sirui Miao,Xiangyu Duan,Hao Yang,Min Zhang*

Main category: cs.CL

TL;DR: This paper introduces BRD, a method that enhances small models by teaching them basic reading behaviors of LLMs, resulting in improved performance on various tasks.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the limitation of current distillation methods that neglect basic reading education for small models on generic texts unrelated to downstream tasks.

Method: Basic reading distillation (BRD) is proposed to educate a small model to imitate LLMs' basic reading behaviors, such as named entity recognition, question raising and answering.

Result: The small model after BRD shows performance comparable or better than 20x larger LLMs on various tasks.

Conclusion: BRD can effectively improve the performance of small models, making them comparable to much larger LLMs.

Abstract: Large language models (LLMs) have demonstrated remarkable abilities in
various natural language processing areas, but they demand high computation
resources which limits their deployment in real-world. Distillation is one
technique to solve this problem through either knowledge distillation or task
distillation. Both distillation approaches train small models to imitate
specific features of LLMs, but they all neglect basic reading education for
small models on generic texts that are \emph{unrelated} to downstream tasks. In
this paper, we propose basic reading distillation (BRD) which educates a small
model to imitate LLMs basic reading behaviors, such as named entity
recognition, question raising and answering, on each sentence. After such basic
education, we apply the small model on various tasks including language
inference benchmarks and BIG-bench tasks. It shows that the small model can
outperform or perform comparable to over 20x bigger LLMs. Analysis reveals that
BRD effectively influences the probability distribution of the small model, and
has orthogonality to either knowledge distillation or task distillation.

</details>


### [13] [JT-Math: A Multi-Stage Framework for Advanced Mathematical Reasoning in Large Language Models](https://arxiv.org/abs/2507.19748)
*Yifan Hao,Fangning Chao,Yaqian Hao,Zhaojun Cui,Huan Bai,Haiyu Zhang,Yankai Liu,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: JT-Math-8B is an open-source model series designed for mathematical reasoning, achieving state-of-the-art results in competition-level mathematics.


<details>
  <summary>Details</summary>
Motivation: Mathematical reasoning is a cornerstone of artificial general intelligence and a primary benchmark for evaluating the capabilities of Large Language Models (LLMs). While state-of-the-art models show promise, they often falter when faced with complex problems that demand deep conceptual understanding and intricate, multi-step deliberation.

Method: We introduce JT-Math-8B, a series of open-source models comprising base, instruct, and thinking versions, built upon a systematic, multi-stage optimization framework. The pre-training corpus is a high-quality, 210B-token dataset curated through a dedicated data pipeline that uses model-based validation to ensure quality and diversity. The Instruct Model is optimized for direct, concise answers through Supervised Fine-Tuning (SFT) and a GRPO-based reinforcement learning (RL) method. The Thinking Model is trained for complex problem-solving using a Long Chain-of-Thought (Long CoT) approach, combining SFT with a novel, multi-stage RL curriculum that progressively increases task difficulty and context length up to 32K tokens.

Result: JT-Math-8B achieves state-of-the-art results among open-source models of similar size, surpassing prominent models like OpenAI's O1-mini and GPT-4o, and demonstrating superior performance on competition-level mathematics.

Conclusion: JT-Math-8B achieves state-of-the-art results among open-source models of similar size, surpassing prominent models like OpenAI's O1-mini and GPT-4o, and demonstrating superior performance on competition-level mathematics.

Abstract: Mathematical reasoning is a cornerstone of artificial general intelligence
and a primary benchmark for evaluating the capabilities of Large Language
Models (LLMs). While state-of-the-art models show promise, they often falter
when faced with complex problems that demand deep conceptual understanding and
intricate, multi-step deliberation. To address this challenge, we introduce
JT-Math-8B, a series of open-source models comprising base, instruct, and
thinking versions, built upon a systematic, multi-stage optimization framework.
Our pre-training corpus is a high-quality, 210B-token dataset curated through a
dedicated data pipeline that uses model-based validation to ensure quality and
diversity. The Instruct Model is optimized for direct, concise answers through
Supervised Fine-Tuning (SFT) and a GRPO-based reinforcement learning (RL)
method. The Thinking Model is trained for complex problem-solving using a Long
Chain-of-Thought (Long CoT) approach, combining SFT with a novel, multi-stage
RL curriculum that progressively increases task difficulty and context length
up to 32K tokens. JT-Math-8B achieves state-of-the-art results among
open-source models of similar size, surpassing prominent models like OpenAI's
O1-mini and GPT-4o , and demonstrating superior performance on
competition-level mathematics.

</details>


### [14] [Are You There God? Lightweight Narrative Annotation of Christian Fiction with LMs](https://arxiv.org/abs/2507.19756)
*Rebecca M. M. Hicke,Brian Haggard,Mia Ferrante,Rayhan Khanna,David Mimno*

Main category: cs.CL

TL;DR: 本文利用计算工具分析了基督教小说，揭示了其文化与文学方面，并展示了不同作品和作者之间的差异。


<details>
  <summary>Details</summary>
Motivation: Christian Fiction长期以来研究较少，而现有的学术关注主要集中在流行的《Left Behind》系列上。本文旨在通过计算工具来扩展对基督教小说的理解。

Method: 我们使用计算工具对基督教小说作为类型进行了广泛的主题概述，并对作者如何描绘神的行为进行了更直接的探索。我们首先与人类标注者合作开发了“神的行为”的定义和代码本，然后将这些指令调整为适用于轻量级语言模型，并在大型模型的帮助下进行。

Result: 轻量级语言模型能够与人类标注相媲美，即使任务微妙且具有挑战性。我们展示了《Left Behind》书籍与基督教小说整体之间的差异，以及男性和女性作者之间的差异。

Conclusion: 我们的研究显示，基督教小说中存在显著且有意义的差异，包括《Left Behind》系列与其他基督教小说之间的差异，以及男性和女性作者之间的差异。

Abstract: In addition to its more widely studied political activities, the American
Evangelical movement has a well-developed but less externally visible cultural
and literary side. Christian Fiction, however, has been little studied, and
what scholarly attention there is has focused on the explosively popular Left
Behind series. In this work, we use computational tools to provide both a broad
topical overview of Christian Fiction as a genre and a more directed
exploration of how its authors depict divine acts. Working with human
annotators we first developed definitions and a codebook for "acts of God." We
then adapted those instructions designed for human annotators for use by a
recent, lightweight LM with the assistance of a much larger model. The
laptop-scale LM is capable of matching human annotations, even when the task is
subtle and challenging. Using these annotations, we show that significant and
meaningful differences exist between the Left Behind books and Christian
Fiction more broadly and between books by male and female authors.

</details>


### [15] [UloRL:An Ultra-Long Output Reinforcement Learning Approach for Advancing Large Language Models' Reasoning Abilities](https://arxiv.org/abs/2507.19766)
*Dong Du,Shulin Liu,Tao Yang,Shaohua Chen,Yang Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为UloRL的方法，用于提升大型语言模型在超长序列生成中的推理能力。通过分段解码和动态遮罩已掌握的正向标记，有效解决了传统强化学习框架在处理超长输出时的效率问题，并在多个基准测试中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习框架在处理超长输出时效率低下，因为长尾序列分布和训练过程中的熵崩溃问题。

Method: 我们提出了一个名为UloRL的方法，通过将超长输出解码分为短段来提高训练效率，并引入动态遮罩已掌握的正向标记（MPTs）以防止熵崩溃。

Result: 在Qwen3-30B-A3B模型上，段落滚动的强化学习实现了2.06倍的训练速度提升，同时128k-token输出的强化学习训练提高了模型在AIME2025和BeyondAIME上的性能。

Conclusion: 我们的方法展示了在超长序列生成中提升大型语言模型推理能力的潜力，并将释放代码和模型以供社区进一步使用。

Abstract: Recent advances in large language models (LLMs) have highlighted the
potential of reinforcement learning with verifiable rewards (RLVR) to enhance
reasoning capabilities through extended output sequences. However, traditional
RL frameworks face inefficiencies when handling ultra-long outputs due to
long-tail sequence distributions and entropy collapse during training. To
address these challenges, we propose an Ultra-Long Output Reinforcement
Learning (UloRL) approach for advancing large language models' reasoning
abilities. Specifically, we divide ultra long output decoding into short
segments, enabling efficient training by mitigating delays caused by long-tail
samples. Additionally, we introduce dynamic masking of well-Mastered Positive
Tokens (MPTs) to prevent entropy collapse. Experimental results demonstrate the
effectiveness of our approach. On the Qwen3-30B-A3B model, RL with segment
rollout achieved 2.06x increase in training speed, while RL training with
128k-token outputs improves the model's performance on AIME2025 from 70.9\% to
85.1\% and on BeyondAIME from 50.7\% to 61.9\%, even surpassing Qwen3-235B-A22B
with remarkable gains. These findings underscore the potential of our methods
to advance the reasoning capabilities of LLMs with ultra-long sequence
generation. We will release our code and model for further use by the
community.

</details>


### [16] [Flora: Effortless Context Construction to Arbitrary Length and Scale](https://arxiv.org/abs/2507.19786)
*Tianxiang Chen,Zhentao Tan,Xiaofan Bo,Yue Wu,Tao Gong,Qi Chu,Jieping Ye,Nenghai Yu*

Main category: cs.CL

TL;DR: 本文介绍了Flora，一种无需人工或LLM干预的长上下文构建策略，能够显著提升LLMs的长上下文性能，同时仅轻微影响短上下文性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在构建长上下文时需要LLM或人工干预，成本高且长度和多样性有限，同时长上下文LLMs的短上下文性能下降明显。

Method: Flora是一种无需人工或LLM干预的长上下文构建策略，通过根据类别任意组合短指令，并指导LLMs根据长上下文元指令生成响应，从而生成任意长度和规模的丰富多样性上下文。

Result: 实验表明，Llama3-8B-Instruct和QwQ-32B在Flora增强后，在三个长上下文基准测试中表现优异，并在短上下文任务中保持强大性能。

Conclusion: Flora可以显著提升LLMs的长上下文性能，同时仅轻微影响短上下文性能。实验表明，增强后的LLMs在三个长上下文基准测试中表现出色，并在短上下文任务中保持强大的性能。

Abstract: Effectively handling long contexts is challenging for Large Language Models
(LLMs) due to the rarity of long texts, high computational demands, and
substantial forgetting of short-context abilities. Recent approaches have
attempted to construct long contexts for instruction tuning, but these methods
often require LLMs or human interventions, which are both costly and limited in
length and diversity. Also, the drop in short-context performances of present
long-context LLMs remains significant. In this paper, we introduce Flora, an
effortless (human/LLM-free) long-context construction strategy. Flora can
markedly enhance the long-context performance of LLMs by arbitrarily assembling
short instructions based on categories and instructing LLMs to generate
responses based on long-context meta-instructions. This enables Flora to
produce contexts of arbitrary length and scale with rich diversity, while only
slightly compromising short-context performance. Experiments on
Llama3-8B-Instruct and QwQ-32B show that LLMs enhanced by Flora excel in three
long-context benchmarks while maintaining strong performances in short-context
tasks. Our data-construction code is available at
\href{https://github.com/txchen-USTC/Flora}{https://github.com/txchen-USTC/Flora}.

</details>


### [17] [HCAttention: Extreme KV Cache Compression via Heterogeneous Attention Computing for LLMs](https://arxiv.org/abs/2507.19823)
*Dongquan Yang,Yifan Yang,Xiaotian Yu,Xianbiao Qi,Rong Xiao*

Main category: cs.CL

TL;DR: HCAttention是一种异构注意力计算框架，结合了关键量化、值卸载和动态KV驱逐，以在极端内存约束下实现高效推理。它在LongBench基准测试中保持了全注意力模型的准确性，同时将KV缓存内存占用缩小到原始大小的25%。


<details>
  <summary>Details</summary>
Motivation: 处理长上下文输入时，大型语言模型面临显著挑战，因为推理过程中键值（KV）缓存需要大量的内存。现有的KV缓存压缩方法在内存减少超过85%时表现出明显的性能下降。此外，在这种情况下，利用GPU-CPU协作进行近似注意力的策略仍未得到充分探索。

Method: HCAttention是一种异构注意力计算框架，结合了关键量化、值卸载和动态KV驱逐，以在极端内存约束下实现高效推理。该方法与现有的Transformer架构兼容，不需要模型微调。

Result: 实验结果表明，HCAttention在LongBench基准测试中保持了全注意力模型的准确性，同时将KV缓存内存占用缩小到原始大小的25%。值得注意的是，它在仅12.5%的缓存下仍具有竞争力，是LLM KV缓存压缩的新状态。此外，HCAttention是第一个将Llama-3-8B模型扩展到在单个A100 GPU上处理400万标记的模型。

Conclusion: HCAttention能够在极端内存限制下实现高效的推理，并在LongBench基准测试中保持全注意力模型的准确性，同时将KV缓存内存占用缩小到原始大小的25%。它在仅12.5%的缓存下仍具有竞争力，是LLM KV缓存压缩的新状态。

Abstract: Processing long-context inputs with large language models presents a
significant challenge due to the enormous memory requirements of the Key-Value
(KV) cache during inference. Existing KV cache compression methods exhibit
noticeable performance degradation when memory is reduced by more than 85%.
Additionally, strategies that leverage GPU-CPU collaboration for approximate
attention remain underexplored in this setting. We propose HCAttention, a
heterogeneous attention computation framework that integrates key quantization,
value offloading, and dynamic KV eviction to enable efficient inference under
extreme memory constraints. The method is compatible with existing transformer
architectures and does not require model fine-tuning. Experimental results on
the LongBench benchmark demonstrate that our approach preserves the accuracy of
full-attention model while shrinking the KV cache memory footprint to 25% of
its original size. Remarkably, it stays competitive with only 12.5% of the
cache, setting a new state-of-the-art in LLM KV cache compression. To the best
of our knowledge, HCAttention is the first to extend the Llama-3-8B model to
process 4 million tokens on a single A100 GPU with 80GB memory.

</details>


### [18] [DRIVE: Disfluency-Rich Synthetic Dialog Data Generation Framework for Intelligent Vehicle Environments](https://arxiv.org/abs/2507.19867)
*Anshul Chavda,M Jagadeesh,Chintalapalli Raja Kullayappa,B Jayaprakash,Medchalimi Sruthi,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: DiscoDrive is a synthetic corpus of 3500 multi-turn dialogs across seven automotive domains, designed to address the lack of spontaneous disfluencies in existing datasets. It is effective for training and data augmentation, showing improvements in various metrics and outperforming human-collected data in naturalness and coherence.


<details>
  <summary>Details</summary>
Motivation: Existing datasets fail to capture the spontaneous disfluencies such as hesitations, false starts, repetitions, and self-corrections that characterize real driver-AI dialogs.

Method: We introduce DiscoDrive, a synthetic corpus of 3500 multi-turn dialogs across seven automotive domains, generated using a two-stage, prompt-driven pipeline that dynamically integrates disfluencies during synthesis.

Result: DiscoDrive is effective both as a training resource, enabling DialoGPT-Medium and T5-Base to match or exceed KVRET-trained models on the MultiWOZ 2.2 and Schema-Guided Dialogue (SGD) relevant test sets, and as a data augmentation resource in low-resource scenarios, delivering additional gains when combined with 10 percent of KVRET. Human evaluations further confirm that dialogs sampled from DiscoDrive are rated higher than KVRET's human-collected dialogs in naturalness and coherence, and are perceived as more context-appropriate than leading post-hoc methods.

Conclusion: DiscoDrive fills a critical gap in existing resources and serves as a versatile corpus for both training and augmenting conversational AI, enabling robust handling of real-world, disfluent in-car interactions.

Abstract: In-car conversational AI is becoming increasingly critical as autonomous
vehicles and smart assistants gain widespread adoption. Yet, existing datasets
fail to capture the spontaneous disfluencies such as hesitations, false starts,
repetitions, and self-corrections that characterize real driver-AI dialogs. To
address this, we introduce DiscoDrive, a synthetic corpus of 3500 multi-turn
dialogs across seven automotive domains, generated using a two-stage,
prompt-driven pipeline that dynamically integrates disfluencies during
synthesis. We show that DiscoDrive is effective both as a training resource,
enabling DialoGPT-Medium and T5-Base to match or exceed KVRET-trained models on
the MultiWOZ 2.2 and Schema-Guided Dialogue (SGD) relevant test sets (BLEU-4
improvements of 0.26 to 0.61; METEOR +2.10; ROUGE-L +3.48; BERTScore F1
improvements of 1.35 to 3.48), and as a data augmentation resource in
low-resource scenarios, delivering additional gains of up to BLEU-4 +0.38,
METEOR +1.95, ROUGE-L +2.87, and BERTScore F1 +4.00 when combined with 10
percent of KVRET. Human evaluations further confirm that dialogs sampled from
DiscoDrive are rated higher than KVRET's human-collected dialogs in naturalness
(3.8 vs 3.6) and coherence (4.1 vs 4.0), and are perceived as more
context-appropriate than leading post-hoc methods (such as LARD), without
compromising clarity. DiscoDrive fills a critical gap in existing resources and
serves as a versatile corpus for both training and augmenting conversational
AI, enabling robust handling of real-world, disfluent in-car interactions.

</details>


### [19] [The Polish Vocabulary Size Test: A Novel Adaptive Test for Receptive Vocabulary Assessment](https://arxiv.org/abs/2507.19869)
*Danil Fokin,Monika Płużyczka,Grigory Golovin*

Main category: cs.CL

TL;DR: PVST 是一种基于 IRT 和 CAT 的新型测试工具，用于评估波兰语学习者的接受性词汇量，具有高精度和短测试时间。


<details>
  <summary>Details</summary>
Motivation: 开发 PVST 是为了提供一种高效且准确的评估工具，以测量波兰语学习者的词汇量。

Method: PVST 基于项目反应理论和计算机自适应测试，能够根据每个考生的水平动态调整。

Result: 在 1475 名参与者中进行的试点研究显示，母语者比非母语者具有更大的词汇量，且母语者的词汇量与年龄呈强正相关。

Conclusion: PVST 是一种有效的工具，可以准确评估母语和非母语波兰语学习者的接受性词汇量。

Abstract: We present the Polish Vocabulary Size Test (PVST), a novel tool for assessing
the receptive vocabulary size of both native and non-native Polish speakers.
Based on Item Response Theory and Computerized Adaptive Testing, PVST
dynamically adjusts to each test-taker's proficiency level, ensuring high
accuracy while keeping the test duration short. To validate the test, a pilot
study was conducted with 1.475 participants. Native Polish speakers
demonstrated significantly larger vocabularies compared to non-native speakers.
For native speakers, vocabulary size showed a strong positive correlation with
age. The PVST is available online at myvocab.info/pl.

</details>


### [20] [Zero-shot Performance of Generative AI in Brazilian Portuguese Medical Exam](https://arxiv.org/abs/2507.19885)
*Cesar Augusto Madid Truyts,Amanda Gomes Rabelo,Gabriel Mesquita de Souza,Daniel Scaldaferri Lages,Adriano Jose Pereira,Uri Adrian Prync Flato,Eduardo Pontes dos Reis,Joaquim Edson Vieira,Paulo Sergio Panse Silveira,Edson Amaro Junior*

Main category: cs.CL

TL;DR: 本研究评估了多种大型语言模型和多模态大型语言模型在巴西葡萄牙语医学考试中的表现，并与人类候选人进行了比较，发现某些模型的准确率接近人类，但在多模态任务中仍有差距，强调了非英语医疗AI应用需要进一步优化。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型和多模态大型语言模型在自然语言处理和医疗应用中取得了显著进展，但它们的评估主要集中在英语上，这可能导致在不同语言中的性能偏差。因此，需要评估这些模型在非英语环境中的表现。

Method: 本研究评估了六种大型语言模型（LLMs）和四种多模态大型语言模型（MLLMs）在回答巴西葡萄牙语医学考试问题上的能力，并将其性能与人类候选人进行比较，分析准确率、处理时间和生成解释的一致性。

Result: 研究结果显示，某些模型（特别是Claude-3.5-Sonnet和Claude-3-Opus）的准确率与人类候选人相当，但在需要图像解释的多模态问题上仍存在性能差距。此外，研究还突显了语言差异，强调了对非英语医疗AI应用进行进一步微调和数据集增强的必要性。

Conclusion: 我们的研究结果强调了在各种语言和临床环境中评估生成式AI的重要性，以确保其在医疗保健中的公平和可靠部署。未来的研究应探索改进的训练方法、改进的多模态推理以及AI驱动的医疗辅助的实际临床整合。

Abstract: Artificial intelligence (AI) has shown the potential to revolutionize
healthcare by improving diagnostic accuracy, optimizing workflows, and
personalizing treatment plans. Large Language Models (LLMs) and Multimodal
Large Language Models (MLLMs) have achieved notable advancements in natural
language processing and medical applications. However, the evaluation of these
models has focused predominantly on the English language, leading to potential
biases in their performance across different languages.
  This study investigates the capability of six LLMs (GPT-4.0 Turbo,
LLaMA-3-8B, LLaMA-3-70B, Mixtral 8x7B Instruct, Titan Text G1-Express, and
Command R+) and four MLLMs (Claude-3.5-Sonnet, Claude-3-Opus, Claude-3-Sonnet,
and Claude-3-Haiku) to answer questions written in Brazilian spoken portuguese
from the medical residency entrance exam of the Hospital das Cl\'inicas da
Faculdade de Medicina da Universidade de S\~ao Paulo (HCFMUSP) - the largest
health complex in South America. The performance of the models was benchmarked
against human candidates, analyzing accuracy, processing time, and coherence of
the generated explanations.
  The results show that while some models, particularly Claude-3.5-Sonnet and
Claude-3-Opus, achieved accuracy levels comparable to human candidates,
performance gaps persist, particularly in multimodal questions requiring image
interpretation. Furthermore, the study highlights language disparities,
emphasizing the need for further fine-tuning and data set augmentation for
non-English medical AI applications.
  Our findings reinforce the importance of evaluating generative AI in various
linguistic and clinical settings to ensure a fair and reliable deployment in
healthcare. Future research should explore improved training methodologies,
improved multimodal reasoning, and real-world clinical integration of AI-driven
medical assistance.

</details>


### [21] [A Gold Standard Dataset and Evaluation Framework for Depression Detection and Explanation in Social Media using LLMs](https://arxiv.org/abs/2507.19899)
*Prajval Bolegave,Pushpak Bhattacharya*

Main category: cs.CL

TL;DR: 本文介绍了一个高质量、专家标注的数据集，用于评估大型语言模型在抑郁症检测任务中的表现和生成解释的质量。


<details>
  <summary>Details</summary>
Motivation: 早期检测抑郁症从在线社交媒体帖子中具有提供及时心理健康干预的潜力。现有的数据集主要提供粗略的帖子级别标签，而我们的数据集允许对模型预测和生成的解释进行细粒度评估。

Method: 我们开发了一个评估框架，利用这个临床基础数据集来评估大型语言模型（LLMs）生成的自然语言解释的忠实度和质量。通过精心设计的提示策略，包括零样本和少量样本方法，我们评估了最先进的专有LLMs，包括GPT-4.1、Gemini 2.5 Pro和Claude 3.7 Sonnet。

Result: 我们的全面实证分析揭示了这些模型在临床解释任务上的显著差异，特别是在零样本和少量样本提示方面。

Conclusion: 我们的研究强调了人类专业知识在指导大型语言模型行为中的价值，并为更安全、更透明的心理健康人工智能系统提供了一个步骤。

Abstract: Early detection of depression from online social media posts holds promise
for providing timely mental health interventions. In this work, we present a
high-quality, expert-annotated dataset of 1,017 social media posts labeled with
depressive spans and mapped to 12 depression symptom categories. Unlike prior
datasets that primarily offer coarse post-level labels
\cite{cohan-etal-2018-smhd}, our dataset enables fine-grained evaluation of
both model predictions and generated explanations.
  We develop an evaluation framework that leverages this clinically grounded
dataset to assess the faithfulness and quality of natural language explanations
generated by large language models (LLMs). Through carefully designed prompting
strategies, including zero-shot and few-shot approaches with domain-adapted
examples, we evaluate state-of-the-art proprietary LLMs including GPT-4.1,
Gemini 2.5 Pro, and Claude 3.7 Sonnet.
  Our comprehensive empirical analysis reveals significant differences in how
these models perform on clinical explanation tasks, with zero-shot and few-shot
prompting. Our findings underscore the value of human expertise in guiding LLM
behavior and offer a step toward safer, more transparent AI systems for
psychological well-being.

</details>


### [22] [CaliDrop: KV Cache Compression with Calibration](https://arxiv.org/abs/2507.19906)
*Yi Su,Quantong Qiu,Yuechi Zhou,Juntao Li,Qingrong Xia,Ping Li,Xinyu Duan,Zhefeng Wang,Min Zhang*

Main category: cs.CL

TL;DR: This paper proposes CaliDrop, a novel strategy that enhances token eviction through calibration to improve accuracy in large language models.


<details>
  <summary>Details</summary>
Motivation: To address the issue of accuracy degradation caused by token eviction in large language models, especially under high compression ratios.

Method: CaliDrop enhances token eviction through calibration by performing speculative calibration on discarded tokens.

Result: Preliminary experiments show that queries at nearby positions exhibit high similarity, and CaliDrop mitigates accuracy loss caused by token eviction.

Conclusion: CaliDrop significantly improves the accuracy of existing token eviction methods.

Abstract: Large Language Models (LLMs) require substantial computational resources
during generation. While the Key-Value (KV) cache significantly accelerates
this process by storing attention intermediates, its memory footprint grows
linearly with sequence length, batch size, and model size, creating a
bottleneck in long-context scenarios. Various KV cache compression techniques,
including token eviction, quantization, and low-rank projection, have been
proposed to mitigate this bottleneck, often complementing each other. This
paper focuses on enhancing token eviction strategies. Token eviction leverages
the observation that the attention patterns are often sparse, allowing for the
removal of less critical KV entries to save memory. However, this reduction
usually comes at the cost of notable accuracy degradation, particularly under
high compression ratios. To address this issue, we propose \textbf{CaliDrop}, a
novel strategy that enhances token eviction through calibration. Our
preliminary experiments show that queries at nearby positions exhibit high
similarity. Building on this observation, CaliDrop performs speculative
calibration on the discarded tokens to mitigate the accuracy loss caused by
token eviction. Extensive experiments demonstrate that CaliDrop significantly
improves the accuracy of existing token eviction methods.

</details>


### [23] [KLAAD: Refining Attention Mechanisms to Reduce Societal Bias in Generative Language Models](https://arxiv.org/abs/2507.19962)
*Seorin Kim,Dongyoung Lee,Jaejin Lee*

Main category: cs.CL

TL;DR: 本文提出了一种基于注意力的去偏框架KLAAD，通过隐式对齐刻板印象和反刻板印象句子对的注意力分布来减轻大型语言模型中的偏见。实验结果表明，KLAAD在两个基准测试中有效减少了偏见，同时保持了语言建模的质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在其输出中常常表现出社会偏见，这引发了关于公平性和伤害的伦理问题。

Method: KLAAD（KL-注意力对齐去偏）是一种基于注意力的去偏框架，它隐式地将刻板印象和反刻板印象句子对之间的注意力分布对齐，而无需直接修改模型权重。KLAAD引入了一个组合训练目标，结合交叉熵、KL散度和三元组损失，引导模型在有偏和无偏上下文之间保持一致的注意力，同时保持流畅性和连贯性。

Result: KLAAD的实验评估表明，在BBQ和BOLD基准测试中，偏见缓解效果得到了改善，对语言建模质量的影响最小。

Conclusion: 注意力级别的对齐为减轻生成语言模型中的偏见提供了一个有原则的解决方案。

Abstract: Large language models (LLMs) often exhibit societal biases in their outputs,
prompting ethical concerns regarding fairness and harm. In this work, we
propose KLAAD (KL-Attention Alignment Debiasing), an attention-based debiasing
framework that implicitly aligns attention distributions between stereotypical
and anti-stereotypical sentence pairs without directly modifying model weights.
KLAAD introduces a composite training objective combining Cross-Entropy, KL
divergence, and Triplet losses, guiding the model to consistently attend across
biased and unbiased contexts while preserving fluency and coherence.
Experimental evaluation of KLAAD demonstrates improved bias mitigation on both
the BBQ and BOLD benchmarks, with minimal impact on language modeling quality.
The results indicate that attention-level alignment offers a principled
solution for mitigating bias in generative language models.

</details>


### [24] [Text2Vis: A Challenging and Diverse Benchmark for Generating Multimodal Visualizations from Text](https://arxiv.org/abs/2507.19969)
*Mizanur Rahman,Md Tahmid Rahman Laskar,Shafiq Joty,Enamul Hoque*

Main category: cs.CL

TL;DR: 本文介绍了Text2Vis基准，用于评估文本到可视化模型，并提出了一个跨模态框架和自动化评估方法，以提高模型性能和评估效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基准缺乏全面性，限制了对大型语言模型生成可视化能力的严格评估。因此，我们需要一个全面的基准来评估这些模型的能力。

Method: 我们提出了Text2Vis基准，涵盖20多种图表类型和多样化的数据科学查询，并引入了跨模态的actor-critic代理框架以及基于LLM的自动化评估框架。

Result: 我们对11个开源和闭源模型进行了基准测试，揭示了显著的性能差距，突出了关键挑战，并为未来的发展提供了见解。我们的跨模态框架提高了GPT-4o的通过率，并且自动化评估框架可以实现大规模评估。

Conclusion: 我们提出了Text2Vis，这是一个用于评估文本到可视化模型的基准，涵盖了20多种图表类型和多样的数据科学查询。我们还提出了一个跨模态的actor-critic代理框架，提高了GPT-4o的通过率，并引入了一个基于LLM的自动化评估框架，以实现大规模评估。

Abstract: Automated data visualization plays a crucial role in simplifying data
interpretation, enhancing decision-making, and improving efficiency. While
large language models (LLMs) have shown promise in generating visualizations
from natural language, the absence of comprehensive benchmarks limits the
rigorous evaluation of their capabilities. We introduce Text2Vis, a benchmark
designed to assess text-to-visualization models, covering 20+ chart types and
diverse data science queries, including trend analysis, correlation, outlier
detection, and predictive analytics. It comprises 1,985 samples, each with a
data table, natural language query, short answer, visualization code, and
annotated charts. The queries involve complex reasoning, conversational turns,
and dynamic data retrieval. We benchmark 11 open-source and closed-source
models, revealing significant performance gaps, highlighting key challenges,
and offering insights for future advancements. To close this gap, we propose
the first cross-modal actor-critic agentic framework that jointly refines the
textual answer and visualization code, increasing GPT-4o`s pass rate from 26%
to 42% over the direct approach and improving chart quality. We also introduce
an automated LLM-based evaluation framework that enables scalable assessment
across thousands of samples without human annotation, measuring answer
correctness, code execution success, visualization readability, and chart
accuracy. We release Text2Vis at https://github.com/vis-nlp/Text2Vis.

</details>


### [25] [Exploring LLM Autoscoring Reliability in Large-Scale Writing Assessments Using Generalizability Theory](https://arxiv.org/abs/2507.19980)
*Dan Song,Won-Chan Lee,Hong Jiao*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型在AP中文考试写作任务中的评分可靠性，并发现虽然人类评分者总体上更可靠，但LLMs在某些条件下表现良好，特别是故事叙述任务。结合人类和AI评分者的复合评分方法提高了可靠性，支持了混合评分模型在大规模写作评估中的潜在优势。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在评估大型语言模型（LLMs）在评分AP中文语言和文化考试写作任务中的可靠性，并比较人工和AI评分者之间的分数一致性。

Method: 研究使用一般化理论评估和比较了两种类型的AP中文自由回答写作任务（故事叙述和电子邮件回复）中人工和AI评分者之间的分数一致性。这些作文由两名受过培训的人类评分者和七名AI评分者独立评分。每篇作文获得了四个分数：一个整体分数和三个对应于任务完成、交付和语言使用的分析分数。

Result: 研究结果表明，尽管人类评分者总体上产生了更可靠的分数，但LLMs在某些条件下表现出合理的一致性，尤其是在故事叙述任务中。复合评分方法结合了人类和AI评分者，提高了可靠性。

Conclusion: 研究结果表明，虽然人类评分者总体上产生了更可靠的分数，但LLMs在某些条件下表现出合理的一致性，特别是在故事叙述任务中。结合人类和AI评分者的复合评分提高了可靠性，这支持了混合评分模型可能为大规模写作评估带来好处。

Abstract: This study investigates the estimation of reliability for large language
models (LLMs) in scoring writing tasks from the AP Chinese Language and Culture
Exam. Using generalizability theory, the research evaluates and compares score
consistency between human and AI raters across two types of AP Chinese
free-response writing tasks: story narration and email response. These essays
were independently scored by two trained human raters and seven AI raters. Each
essay received four scores: one holistic score and three analytic scores
corresponding to the domains of task completion, delivery, and language use.
Results indicate that although human raters produced more reliable scores
overall, LLMs demonstrated reasonable consistency under certain conditions,
particularly for story narration tasks. Composite scoring that incorporates
both human and AI raters improved reliability, which supports that hybrid
scoring models may offer benefits for large-scale writing assessments.

</details>


### [26] [VLQA: The First Comprehensive, Large, and High-Quality Vietnamese Dataset for Legal Question Answering](https://arxiv.org/abs/2507.19995)
*Tan-Minh Nguyen,Hoang-Trung Nguyen,Trong-Khoi Dao,Xuan-Hieu Phan,Ha-Thanh Nguyen,Thi-Hai-Yen Vuong*

Main category: cs.CL

TL;DR: 本文介绍了为越南法律领域设计的VLQA数据集，并通过实验验证了其有效性，以应对低资源语言中法律NLP的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于法律系统具有高度的专业性和地域差异，且低资源语言如越南语缺乏标注数据，因此需要构建针对不同自然语言的法律文本处理应用。

Method: 本文介绍了VLQA数据集，并对其进行了全面的统计分析，同时通过实验评估了其在法律信息检索和问答任务中的有效性。

Result: 本文介绍了VLQA数据集，并通过实验验证了其在法律信息检索和问答任务中的有效性。

Conclusion: 尽管在法律文本处理领域取得了进展，但仍然远未实现完全自动化法律任务的目标。本文介绍了VLQA数据集，这是一个为越南法律领域量身定制的全面且高质量的资源，并通过与最先进的模型进行实验评估了其有效性。

Abstract: The advent of large language models (LLMs) has led to significant
achievements in various domains, including legal text processing. Leveraging
LLMs for legal tasks is a natural evolution and an increasingly compelling
choice. However, their capabilities are often portrayed as greater than they
truly are. Despite the progress, we are still far from the ultimate goal of
fully automating legal tasks using artificial intelligence (AI) and natural
language processing (NLP). Moreover, legal systems are deeply domain-specific
and exhibit substantial variation across different countries and languages. The
need for building legal text processing applications for different natural
languages is, therefore, large and urgent. However, there is a big challenge
for legal NLP in low-resource languages such as Vietnamese due to the scarcity
of resources and annotated data. The need for labeled legal corpora for
supervised training, validation, and supervised fine-tuning is critical. In
this paper, we introduce the VLQA dataset, a comprehensive and high-quality
resource tailored for the Vietnamese legal domain. We also conduct a
comprehensive statistical analysis of the dataset and evaluate its
effectiveness through experiments with state-of-the-art models on legal
information retrieval and question-answering tasks.

</details>


### [27] [Anomaly Detection in Human Language via Meta-Learning: A Few-Shot Approach](https://arxiv.org/abs/2507.20019)
*Saurav Singla,Aarav Singla,Advik Gupta,Parnika Gupta*

Main category: cs.CL

TL;DR: 我们提出了一种元学习框架，用于在不同领域中检测人类语言中的异常，特别是在标记数据有限的情况下。


<details>
  <summary>Details</summary>
Motivation: 语言中的异常（如垃圾邮件、假新闻和仇恨言论）由于其稀疏性和变异性而是一个主要挑战。

Method: 我们结合了周期性训练和原型网络以及领域重采样来快速适应新的异常检测任务。

Result: 实证结果表明，我们的方法在F1和AUC分数上优于强基线。

Conclusion: 我们的方法在F1和AUC分数上优于强基线，我们还发布了代码和基准以促进少样本文本异常检测的进一步研究。

Abstract: We propose a meta learning framework for detecting anomalies in human
language across diverse domains with limited labeled data. Anomalies in
language ranging from spam and fake news to hate speech pose a major challenge
due to their sparsity and variability. We treat anomaly detection as a few shot
binary classification problem and leverage meta-learning to train models that
generalize across tasks. Using datasets from domains such as SMS spam, COVID-19
fake news, and hate speech, we evaluate model generalization on unseen tasks
with minimal labeled anomalies. Our method combines episodic training with
prototypical networks and domain resampling to adapt quickly to new anomaly
detection tasks. Empirical results show that our method outperforms strong
baselines in F1 and AUC scores. We also release the code and benchmarks to
facilitate further research in few-shot text anomaly detection.

</details>


### [28] [FAEDKV: Infinite-Window Fourier Transform for Unbiased KV Cache Compression](https://arxiv.org/abs/2507.20030)
*Runchao Li,Yao Fu,Mu Sheng,Xianxuan Long,Haotian Yu,Pan Li*

Main category: cs.CL

TL;DR: FAEDKV is a new training-free method for compressing KV cache in LLMs, which improves information retention and performance in long-context tasks.


<details>
  <summary>Details</summary>
Motivation: Current compression strategies for KV cache in LLMs often lead to biased representations and require costly retraining, which limits their effectiveness in long-context tasks.

Method: FAEDKV uses a novel training-free KV cache compression framework that transforms the KV cache into the frequency domain using the Infinite-Window Fourier Transform (IWDFT) to ensure unbiased information retention.

Result: Experiments on the LongBench benchmark show FAEDKV's superiority over existing methods by up to 22%, and it also shows superior position-agnostic retrieval accuracy on the Needle-In-A-Haystack task.

Conclusion: FAEDKV demonstrates superior performance in long-context tasks compared to existing methods, with significant improvements in information retention and retrieval accuracy.

Abstract: The efficacy of Large Language Models (LLMs) in long-context tasks is often
hampered by the substantial memory footprint and computational demands of the
Key-Value (KV) cache. Current compression strategies, including token eviction
and learned projections, frequently lead to biased representations -- either by
overemphasizing recent/high-attention tokens or by repeatedly degrading
information from earlier context -- and may require costly model retraining. We
present FAEDKV (Frequency-Adaptive Infinite-Window for KV cache), a novel,
training-free KV cache compression framework that ensures unbiased information
retention. FAEDKV operates by transforming the KV cache into the frequency
domain using a proposed Infinite-Window Fourier Transform (IWDFT). This
approach allows for the equalized contribution of all tokens to the compressed
representation, effectively preserving both early and recent contextual
information. A preliminary frequency ablation study identifies critical
spectral components for layer-wise, targeted compression. Experiments on
LongBench benchmark demonstrate FAEDKV's superiority over existing methods by
up to 22\%. In addition, our method shows superior, position-agnostic retrieval
accuracy on the Needle-In-A-Haystack task compared to compression based
approaches.

</details>


### [29] [Infogen: Generating Complex Statistical Infographics from Documents](https://arxiv.org/abs/2507.20046)
*Akash Ghosh,Aparna Garimella,Pritika Ramu,Sambaran Bandyopadhyay,Sriparna Saha*

Main category: cs.CL

TL;DR: 本文介绍了生成包含多个子图表的统计信息图的任务，并提出了一个两阶段框架Infogen，该框架在文本到统计信息图生成方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有工作仅限于生成简单的图表，没有先前的工作涉及从需要深入理解内容的文本密集型文档中创建复杂的图表。

Method: 提出了一种两阶段框架Infogen，其中微调的LLM首先生成元数据，然后将其转换为信息图代码。

Result: 在Infodat上进行的广泛评估表明，Infogen实现了最先进的性能。

Conclusion: Infogen在文本到统计信息图生成方面表现出色，优于封闭和开源的LLM。

Abstract: Statistical infographics are powerful tools that simplify complex data into
visually engaging and easy-to-understand formats. Despite advancements in AI,
particularly with LLMs, existing efforts have been limited to generating simple
charts, with no prior work addressing the creation of complex infographics from
text-heavy documents that demand a deep understanding of the content. We
address this gap by introducing the task of generating statistical infographics
composed of multiple sub-charts (e.g., line, bar, pie) that are contextually
accurate, insightful, and visually aligned. To achieve this, we define
infographic metadata that includes its title and textual insights, along with
sub-chart-specific details such as their corresponding data and alignment. We
also present Infodat, the first benchmark dataset for text-to-infographic
metadata generation, where each sample links a document to its metadata. We
propose Infogen, a two-stage framework where fine-tuned LLMs first generate
metadata, which is then converted into infographic code. Extensive evaluations
on Infodat demonstrate that Infogen achieves state-of-the-art performance,
outperforming both closed and open-source LLMs in text-to-statistical
infographic generation.

</details>


### [30] [A Tensor-Based Compiler and a Runtime for Neuron-Level DNN Certifier Specifications](https://arxiv.org/abs/2507.20055)
*Avaljot Singh,Yamin Chandini Sarita,Aditya Mishra,Ishaan Goyal,Gagandeep Singh,Charith Mendis*

Main category: cs.CL

TL;DR: 本文提出了一种编译器框架，将DNN验证器的神经元级规范自动转换为张量级实现，并引入了g-BCSR双压缩格式，以提高性能和灵活性。


<details>
  <summary>Details</summary>
Motivation: 当前的DNN验证器支持有限，开发新的或修改现有的验证器对于不同应用来说仍然困难。这是因为验证器的数学设计是在神经元级别表达的，而它们的实现是在张量级别优化和执行的。这种不匹配导致了设计和实现之间的语义差距，使得手动桥接既复杂又需要专业知识。

Method: 我们提出了一种编译器框架，该框架利用一种新颖的基于栈的中间表示（IR）和形状分析，将神经元级规范自动转换为张量级实现。此外，我们引入了g-BCSR，一种双压缩格式，用于表示张量。

Result: 我们的编译器能够自动将神经元级规范转换为张量级实现，并且通过g-BCSR格式优化了张量的存储和计算。结果表明，尽管具有灵活性，编译器的性能与手工优化的实现相当。

Conclusion: 我们提出了一种编译器框架，可以自动将DNN验证器的神经元级规范转换为基于张量的、层级的实现。此外，我们引入了g-BCSR，一种双压缩格式，用于表示张量。使用我们的编译器和g-BCSR，开发新的验证器并分析其在不同DNN中的效用变得容易。尽管具有灵活性，编译器的性能与手工优化的实现相当。

Abstract: The uninterpretability of DNNs has led to the adoption of abstract
interpretation-based certification as a practical means to establish trust in
real-world systems that rely on DNNs. However, the current landscape supports
only a limited set of certifiers, and developing new ones or modifying existing
ones for different applications remains difficult. This is because the
mathematical design of certifiers is expressed at the neuron level, while their
implementations are optimized and executed at the tensor level. This mismatch
creates a semantic gap between design and implementation, making manual
bridging both complex and expertise-intensive -- requiring deep knowledge in
formal methods, high-performance computing, etc.
  We propose a compiler framework that automatically translates neuron-level
specifications of DNN certifiers into tensor-based, layer-level
implementations. This is enabled by two key innovations: a novel stack-based
intermediate representation (IR) and a shape analysis that infers the implicit
tensor operations needed to simulate the neuron-level semantics. During
lifting, the shape analysis creates tensors in the minimal shape required to
perform the corresponding operations. The IR also enables domain-specific
optimizations as rewrites. At runtime, the resulting tensor computations
exhibit sparsity tied to the DNN architecture. This sparsity does not align
well with existing formats. To address this, we introduce g-BCSR, a
double-compression format that represents tensors as collections of blocks of
varying sizes, each possibly internally sparse.
  Using our compiler and g-BCSR, we make it easy to develop new certifiers and
analyze their utility across diverse DNNs. Despite its flexibility, the
compiler achieves performance comparable to hand-optimized implementations.

</details>


### [31] [RAG in the Wild: On the (In)effectiveness of LLMs with Mixture-of-Knowledge Retrieval Augmentation](https://arxiv.org/abs/2507.20059)
*Ran Xu,Yuchen Zhuang,Yue Yu,Haoyu Wang,Wenqi Shi,Carl Yang*

Main category: cs.CL

TL;DR: 本研究评估了RAG系统在现实世界场景中的表现，并发现了其局限性，强调了需要适应性检索策略的重要性。


<details>
  <summary>Details</summary>
Motivation: 虽然RAG在基于通用领域语料库的基准测试中表现出色，但其在现实、多样检索场景中的有效性仍需进一步探索。

Method: 我们使用MassiveDS评估了RAG系统，这是一个包含多种知识的大规模数据存储库。

Result: 我们发现检索主要对较小的模型有益，重排序器增加的价值很小，且没有单一的检索源始终表现优异。此外，当前的LLM难以在异构知识源之间路由查询。

Conclusion: 我们的研究结果表明，在将RAG部署到现实世界设置之前，需要适应性的检索策略。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
integrating external knowledge retrieved at inference time. While RAG
demonstrates strong performance on benchmarks largely derived from
general-domain corpora like Wikipedia, its effectiveness under realistic,
diverse retrieval scenarios remains underexplored. We evaluated RAG systems
using MassiveDS, a large-scale datastore with mixture of knowledge, and
identified critical limitations: retrieval mainly benefits smaller models,
rerankers add minimal value, and no single retrieval source consistently
excels. Moreover, current LLMs struggle to route queries across heterogeneous
knowledge sources. These findings highlight the need for adaptive retrieval
strategies before deploying RAG in real-world settings. Our code and data can
be found at https://github.com/ritaranx/RAG_in_the_Wild.

</details>


### [32] [ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models](https://arxiv.org/abs/2507.20091)
*Kaizhi Qian,Xulin Fan,Junrui Ni,Slava Shechtman,Mark Hasegawa-Johnson,Chuang Gan,Yang Zhang*

Main category: cs.CL

TL;DR: ProsodyLM 是一种新的语音语言模型，通过引入一种简单的分词方案来学习韵律信息。与传统的语音分词方案相比，该方案保留了更多的完整韵律信息，并且更容易被基于文本的 LLM 理解。我们发现，ProsodyLM 可以通过预训练学习到多样化的新兴韵律处理能力。


<details>
  <summary>Details</summary>
Motivation: The existing mainstream paradigm of training speech language models, which converts speech into discrete tokens before feeding them into LLMs, is sub-optimal in learning prosody information.

Method: ProsodyLM introduces a simple tokenization scheme amenable to learning prosody. Each speech utterance is first transcribed into text, followed by a sequence of word-level prosody tokens.

Result: We find that ProsodyLM can learn surprisingly diverse emerging prosody processing capabilities through pre-training alone, ranging from harnessing the prosody nuances in generated speech, such as contrastive focus, understanding emotion and stress in an utterance, to maintaining prosody consistency in long contexts.

Conclusion: ProsodyLM can learn surprisingly diverse emerging prosody processing capabilities through pre-training alone, ranging from harnessing the prosody nuances in generated speech, such as contrastive focus, understanding emotion and stress in an utterance, to maintaining prosody consistency in long contexts.

Abstract: Speech language models refer to language models with speech processing and
understanding capabilities. One key desirable capability for speech language
models is the ability to capture the intricate interdependency between content
and prosody. The existing mainstream paradigm of training speech language
models, which converts speech into discrete tokens before feeding them into
LLMs, is sub-optimal in learning prosody information -- we find that the
resulting LLMs do not exhibit obvious emerging prosody processing capabilities
via pre-training alone. To overcome this, we propose ProsodyLM, which
introduces a simple tokenization scheme amenable to learning prosody. Each
speech utterance is first transcribed into text, followed by a sequence of
word-level prosody tokens. Compared with conventional speech tokenization
schemes, the proposed tokenization scheme retains more complete prosody
information, and is more understandable to text-based LLMs. We find that
ProsodyLM can learn surprisingly diverse emerging prosody processing
capabilities through pre-training alone, ranging from harnessing the prosody
nuances in generated speech, such as contrastive focus, understanding emotion
and stress in an utterance, to maintaining prosody consistency in long
contexts.

</details>


### [33] [AI-Driven Generation of Old English: A Framework for Low-Resource Languages](https://arxiv.org/abs/2507.20111)
*Rodrigo Gabriel Salazar Alva,Matías Nuñez,Cristian López,Javier Martín Arista*

Main category: cs.CL

TL;DR: 本文提出了一种可扩展的框架，利用先进的大型语言模型（LLMs）生成高质量的古英语文本，以解决古英语资源不足的问题。方法包括参数高效微调、数据增强和双代理管道。评估结果显示显著改进，并且专家评估确认了生成文本的高语法准确性和风格忠实度。该方法为复兴其他濒危语言提供了实用的蓝图。


<details>
  <summary>Details</summary>
Motivation: 保护古代语言对于理解人类的文化和语言遗产至关重要，但古英语仍然资源不足，限制了其对现代自然语言处理（NLP）技术的可访问性。

Method: 我们提出了一种可扩展的框架，利用先进的大型语言模型（LLMs）生成高质量的古英语文本，该方法结合了参数高效微调（低秩适应，LoRA）、通过反向翻译的数据增强以及一个分离内容生成（用英语）和翻译（到古英语）任务的双代理管道。

Result: 使用自动度量标准（BLEU、METEOR 和 CHRF）进行的评估显示，与基线模型相比有显著改进，英语到古英语翻译的 BLEU 分数从 26 提高到 65 以上。专家的人类评估也证实了生成文本的高语法准确性和风格忠实度。

Conclusion: 我们的方法为复兴其他濒危语言提供了实用的蓝图，有效地将人工智能创新与文化保护目标结合起来。

Abstract: Preserving ancient languages is essential for understanding humanity's
cultural and linguistic heritage, yet Old English remains critically
under-resourced, limiting its accessibility to modern natural language
processing (NLP) techniques. We present a scalable framework that uses advanced
large language models (LLMs) to generate high-quality Old English texts,
addressing this gap. Our approach combines parameter-efficient fine-tuning
(Low-Rank Adaptation, LoRA), data augmentation via backtranslation, and a
dual-agent pipeline that separates the tasks of content generation (in English)
and translation (into Old English). Evaluation with automated metrics (BLEU,
METEOR, and CHRF) shows significant improvements over baseline models, with
BLEU scores increasing from 26 to over 65 for English-to-Old English
translation. Expert human assessment also confirms high grammatical accuracy
and stylistic fidelity in the generated texts. Beyond expanding the Old English
corpus, our method offers a practical blueprint for revitalizing other
endangered languages, effectively uniting AI innovation with the goals of
cultural preservation.

</details>


### [34] [Sem-DPO: Mitigating Semantic Inconsistency in Preference Optimization for Prompt Engineering](https://arxiv.org/abs/2507.20133)
*Anas Mohamed,Azal Ahmad Khan,Xinran Wang,Ahmad Faraz Khan,Shuwen Ge,Saman Bahzad Khan,Ayaan Ahmad,Ali Anwar*

Main category: cs.CL

TL;DR: Sem-DPO是一种改进的DPO方法，通过引入语义权重来保持提示的语义一致性，从而在多个任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: Direct Preference Optimization (DPO)虽然提供了一种轻量级、非策略的替代方法，但其令牌级别的正则化无法检查语义不一致，导致获得更高偏好分数的提示可能偏离用户的意图。

Method: Sem-DPO是一种DPO的变体，它通过将DPO损失乘以与原始提示和获胜候选者在嵌入空间中的余弦距离成比例的指数权重，来保留语义一致性。

Result: Sem-DPO在三个标准文本到图像提示优化基准和两个语言模型上实现了8-12%更高的CLIP相似度和5-9%更高的用户偏好分数，同时优于最先进的基线。

Conclusion: 这些发现表明，增强语义权重的强平基线应该成为提示优化研究的新标准，并为语言模型中的更广泛语义感知偏好优化奠定基础。

Abstract: Generative AI can now synthesize strikingly realistic images from text, yet
output quality remains highly sensitive to how prompts are phrased. Direct
Preference Optimization (DPO) offers a lightweight, off-policy alternative to
RL for automatic prompt engineering, but its token-level regularization leaves
semantic inconsistency unchecked as prompts that win higher preference scores
can still drift away from the user's intended meaning.
  We introduce Sem-DPO, a variant of DPO that preserves semantic consistency
yet retains its simplicity and efficiency. Sem-DPO scales the DPO loss by an
exponential weight proportional to the cosine distance between the original
prompt and winning candidate in embedding space, softly down-weighting training
signals that would otherwise reward semantically mismatched prompts. We provide
the first analytical bound on semantic drift for preference-tuned prompt
generators, showing that Sem-DPO keeps learned prompts within a provably
bounded neighborhood of the original text. On three standard text-to-image
prompt-optimization benchmarks and two language models, Sem-DPO achieves 8-12%
higher CLIP similarity and 5-9% higher human-preference scores (HPSv2.1,
PickScore) than DPO, while also outperforming state-of-the-art baselines. These
findings suggest that strong flat baselines augmented with semantic weighting
should become the new standard for prompt-optimization studies and lay the
groundwork for broader, semantics-aware preference optimization in language
models.

</details>


### [35] [Multi-Stage Verification-Centric Framework for Mitigating Hallucination in Multi-Modal RAG](https://arxiv.org/abs/2507.20136)
*Baiyu Chen,Wilson Wongso,Xiaoqian Hu,Yue Tan,Flora Salim*

Main category: cs.CL

TL;DR: 本文介绍了团队CRUISE为KDD Cup 2025 Meta Comprehensive RAG Benchmark for Multi-modal, Multi-turn (CRAG-MM)挑战开发的技术解决方案。该解决方案旨在解决现代视觉语言模型容易产生幻觉的问题，特别是在处理第一人称图像、长尾实体和复杂多跳问题时。我们的方法在任务1中获得了第三名，证明了优先考虑答案可靠性在复杂多模态RAG系统中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现代视觉语言模型（VLMs）容易产生幻觉，特别是在面对第一人称图像、长尾实体和复杂多跳问题时。这个问题在现实应用中尤为严重，因为用户提出的事实性查询需要跨多种模态的高事实准确性。

Method: 我们提出了一种多阶段框架，强调事实准确性和真实性，而不是完整性。该解决方案集成了一个轻量级查询路由器、一个查询感知的检索和摘要管道、双路径生成和事后验证。

Result: 我们的方法在任务1中获得了第三名，证明了优先考虑答案可靠性在复杂多模态RAG系统中的有效性。

Conclusion: 我们的方法在任务1中获得了第三名，证明了在复杂多模态RAG系统中优先考虑答案可靠性是有效的。

Abstract: This paper presents the technical solution developed by team CRUISE for the
KDD Cup 2025 Meta Comprehensive RAG Benchmark for Multi-modal, Multi-turn
(CRAG-MM) challenge. The challenge aims to address a critical limitation of
modern Vision Language Models (VLMs): their propensity to hallucinate,
especially when faced with egocentric imagery, long-tail entities, and complex,
multi-hop questions. This issue is particularly problematic in real-world
applications where users pose fact-seeking queries that demand high factual
accuracy across diverse modalities. To tackle this, we propose a robust,
multi-stage framework that prioritizes factual accuracy and truthfulness over
completeness. Our solution integrates a lightweight query router for
efficiency, a query-aware retrieval and summarization pipeline, a dual-pathways
generation and a post-hoc verification. This conservative strategy is designed
to minimize hallucinations, which incur a severe penalty in the competition's
scoring metric. Our approach achieved 3rd place in Task 1, demonstrating the
effectiveness of prioritizing answer reliability in complex multi-modal RAG
systems. Our implementation is available at
https://github.com/Breezelled/KDD-Cup-2025-Meta-CRAG-MM .

</details>


### [36] [Multi-Agent Interactive Question Generation Framework for Long Document Understanding](https://arxiv.org/abs/2507.20145)
*Kesen Wang,Daulet Toibazar,Abdulrahman Alfulayt,Abdulaziz S. Albadawi,Ranya A. Alkahtani,Asma A. Ibrahim,Haneen A. Alhomoud,Sherif Mohamed,Pedro J. Moreno*

Main category: cs.CL

TL;DR: 本文提出了一种自动化多智能体框架来生成长文档的问题，以提高LVLMs在长上下文理解方面的能力。


<details>
  <summary>Details</summary>
Motivation: 文档理解在长上下文场景中仍然是一个重大挑战，尤其是对于低资源语言如阿拉伯语来说，缺乏细粒度的训练数据。现有的最先进的技术依赖于人工标注，这既昂贵又低效。

Method: 我们提出了一种完全自动化的多智能体交互框架，以高效生成长上下文问题。

Result: 实验结果表明，我们生成的英语和阿拉伯语问题（AraEngLongBench）对主要的开源和闭源LVLMs来说是非常具有挑战性的。

Conclusion: 我们的方法能够生成高质量的单页和多页问题，有助于提升LVLMs在长上下文理解方面的能力。

Abstract: Document Understanding (DU) in long-contextual scenarios with complex layouts
remains a significant challenge in vision-language research. Although Large
Vision-Language Models (LVLMs) excel at short-context DU tasks, their
performance declines in long-context settings. A key limitation is the scarcity
of fine-grained training data, particularly for low-resource languages such as
Arabic. Existing state-of-the-art techniques rely heavily on human annotation,
which is costly and inefficient. We propose a fully automated, multi-agent
interactive framework to generate long-context questions efficiently. Our
approach efficiently generates high-quality single- and multi-page questions
for extensive English and Arabic documents, covering hundreds of pages across
diverse domains. This facilitates the development of LVLMs with enhanced
long-context understanding ability. Experimental results in this work have
shown that our generated English and Arabic questions
(\textbf{AraEngLongBench}) are quite challenging to major open- and
close-source LVLMs. The code and data proposed in this work can be found in
https://github.com/wangk0b/Multi_Agentic_QA_Long_Doc.git. Sample Question and
Answer (QA) pairs and structured system prompts can be found in the Appendix.

</details>


### [37] [Goal Alignment in LLM-Based User Simulators for Conversational AI](https://arxiv.org/abs/2507.20152)
*Shuhaib Mehri,Xiaocheng Yang,Takyoung Kim,Gokhan Tur,Shikib Mehri,Dilek Hakkani-Tür*

Main category: cs.CL

TL;DR: 本文提出了一种新的用户目标状态跟踪框架（UGST），以解决当前大型语言模型在多轮对话中难以保持目标导向行为的问题，并展示了该方法在两个基准测试中的显著改进。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在用户模拟方面的能力虽然有所进步，但它们在多轮对话中难以始终如一地表现出目标导向的行为，这是一个关键限制，会影响其在下游应用中的可靠性。

Method: 我们引入了用户目标状态跟踪（UGST），这是一种新的框架，用于跟踪对话过程中用户目标的进展。利用UGST，我们提出了一个三阶段的方法来开发可以自主跟踪目标进展并推理生成目标对齐响应的用户模拟器。

Result: 我们建立了全面的评估指标来衡量用户模拟器中的目标对齐度，并证明我们的方法在两个基准测试（MultiWOZ 2.4和{	au}-Bench）中取得了显著改进。

Conclusion: 我们的贡献填补了对话人工智能中的一个关键空白，并确立了UGST作为开发目标对齐用户模拟器的重要框架。

Abstract: User simulators are essential to conversational AI, enabling scalable agent
development and evaluation through simulated interactions. While current Large
Language Models (LLMs) have advanced user simulation capabilities, we reveal
that they struggle to consistently demonstrate goal-oriented behavior across
multi-turn conversations--a critical limitation that compromises their
reliability in downstream applications. We introduce User Goal State Tracking
(UGST), a novel framework that tracks user goal progression throughout
conversations. Leveraging UGST, we present a three-stage methodology for
developing user simulators that can autonomously track goal progression and
reason to generate goal-aligned responses. Moreover, we establish comprehensive
evaluation metrics for measuring goal alignment in user simulators, and
demonstrate that our approach yields substantial improvements across two
benchmarks (MultiWOZ 2.4 and {\tau}-Bench). Our contributions address a
critical gap in conversational AI and establish UGST as an essential framework
for developing goal-aligned user simulators.

</details>


### [38] [SGPO: Self-Generated Preference Optimization based on Self-Improver](https://arxiv.org/abs/2507.20181)
*Hyeonji Lee,Daejin Jo,Seohwan Yun,Sungwoong Kim*

Main category: cs.CL

TL;DR: 本文提出了一种名为SGPO的新型对齐框架，该框架利用在线策略的自我改进机制，通过自动生成偏好数据来优化策略模型。实验结果表明，SGPO在不使用外部偏好数据的情况下，显著提升了DPO和基线自我改进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的对齐方法通常依赖于离策略学习和人工标注的数据集，这限制了它们的广泛应用，并在训练过程中引入了分布偏移问题。因此，需要一种更有效的对齐方法。

Method: SGPO是一种基于自我改进者的自生成偏好优化框架，它利用了在线策略的自我改进机制。具体来说，改进者会优化策略模型的响应，以自动生成用于直接偏好优化（DPO）的偏好数据。改进者和策略模型被统一为一个模型，并通过参考监督微调输出来逐步改进当前响应。

Result: SGPO在AlpacaEval 2.0和Arena-Hard上的实验结果表明，它在不使用外部偏好数据的情况下，显著提升了DPO和基线自我改进方法的性能。

Conclusion: SGPO在AlpacaEval 2.0和Arena-Hard上的实验结果表明，它在不使用外部偏好数据的情况下，显著提升了DPO和基线自我改进方法的性能。

Abstract: Large language models (LLMs), despite their extensive pretraining on diverse
datasets, require effective alignment to human preferences for practical and
reliable deployment. Conventional alignment methods typically employ off-policy
learning and depend on human-annotated datasets, which limits their broad
applicability and introduces distribution shift issues during training. To
address these challenges, we propose Self-Generated Preference Optimization
based on Self-Improver (SGPO), an innovative alignment framework that leverages
an on-policy self-improving mechanism. Specifically, the improver refines
responses from a policy model to self-generate preference data for direct
preference optimization (DPO) of the policy model. Here, the improver and
policy are unified into a single model, and in order to generate higher-quality
preference data, this self-improver learns to make incremental yet discernible
improvements to the current responses by referencing supervised fine-tuning
outputs. Experimental results on AlpacaEval 2.0 and Arena-Hard show that the
proposed SGPO significantly improves performance over DPO and baseline
self-improving methods without using external preference data.

</details>


### [39] [SessionIntentBench: A Multi-task Inter-session Intention-shift Modeling Benchmark for E-commerce Customer Behavior Understanding](https://arxiv.org/abs/2507.20185)
*Yuqi Yang,Weiqi Wang,Baixuan Xu,Wei Fan,Qing Zong,Chunkit Chan,Zheye Deng,Xin Liu,Yifan Gao,Changlong Yu,Chen Luo,Yang Li,Zheng Li,Qingyu Yin,Bing Yin,Yangqiu Song*

Main category: cs.CL

TL;DR: 本文引入了意图树概念并构建了SessionIntentBench基准，用于评估L(V)LMs在理解跨会话意图变化方面的能力，发现当前模型未能有效捕捉意图，但注入意图可以提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能有效捕捉和建模客户意图，因为信息利用不足且仅使用显式信息如描述和标题。此外，缺乏明确建模电商产品购买会话中意图的数据和对应基准。

Method: 引入了意图树的概念并提出了一个数据集构建流程，构建了一个兄弟多模态基准SessionIntentBench，用于评估L(V)LMs在理解跨会话意图变化方面的能力。

Result: 构建了一个包含1,952,177个意图条目、1,132,145个会话意图轨迹和13,003,664个可用任务的数据集，提供了利用现有会话数据进行客户意图理解的可扩展方法。通过人工标注收集了一部分数据的地面真实标签以形成评估黄金集。

Conclusion: 当前的L(V)LMs在复杂会话设置中未能捕捉和利用意图，但注入意图可以提高LLMs的性能。

Abstract: Session history is a common way of recording user interacting behaviors
throughout a browsing activity with multiple products. For example, if an user
clicks a product webpage and then leaves, it might because there are certain
features that don't satisfy the user, which serve as an important indicator of
on-the-spot user preferences. However, all prior works fail to capture and
model customer intention effectively because insufficient information
exploitation and only apparent information like descriptions and titles are
used. There is also a lack of data and corresponding benchmark for explicitly
modeling intention in E-commerce product purchase sessions. To address these
issues, we introduce the concept of an intention tree and propose a dataset
curation pipeline. Together, we construct a sibling multimodal benchmark,
SessionIntentBench, that evaluates L(V)LMs' capability on understanding
inter-session intention shift with four subtasks. With 1,952,177 intention
entries, 1,132,145 session intention trajectories, and 13,003,664 available
tasks mined using 10,905 sessions, we provide a scalable way to exploit the
existing session data for customer intention understanding. We conduct human
annotations to collect ground-truth label for a subset of collected data to
form an evaluation gold set. Extensive experiments on the annotated data
further confirm that current L(V)LMs fail to capture and utilize the intention
across the complex session setting. Further analysis show injecting intention
enhances LLMs' performances.

</details>


### [40] [Diversity-Enhanced Reasoning for Subjective Questions](https://arxiv.org/abs/2507.20187)
*Yumeng Wang,Zhiyuan Fan,Jiayu Liu,Yi R. Fung*

Main category: cs.CL

TL;DR: 本文提出了一种名为MultiRole-R1的多样性增强框架，通过引入多个角色视角来提高主观推理任务的准确性和多样性。


<details>
  <summary>Details</summary>
Motivation: 由于在监督微调和可验证奖励的强化学习中依赖单一的地面真实，大型推理模型在主观问题上的效果受到同质推理倾向的限制。我们发现增加角色视角可以持续提高性能，因此提出了MultiRole-R1来解决这个问题。

Method: 我们提出了MultiRole-R1，这是一种增强多样性的框架，通过多个角色视角来改进主观推理任务的准确性和多样性。我们采用了无监督的数据构造流程，生成包含多样化角色视角的推理链，并使用基于组相对策略优化（GRPO）的强化学习方法，将多样性作为奖励信号之一。

Result: 我们的实验在六个基准测试中证明了MultiRole-R1的有效性，成功促进了视角多样性和词汇多样性，并揭示了推理多样性与准确性之间的正相关关系。

Conclusion: 我们的实验表明，MultiRole-R1在增强主观和客观推理方面具有有效性和泛化能力，展示了增强多样性训练在LRM中的潜力。

Abstract: Large reasoning models (LRM) with long chain-of-thought (CoT) capabilities
have shown strong performance on objective tasks, such as math reasoning and
coding. However, their effectiveness on subjective questions that may have
different responses from different perspectives is still limited by a tendency
towards homogeneous reasoning, introduced by the reliance on a single ground
truth in supervised fine-tuning and verifiable reward in reinforcement
learning. Motivated by the finding that increasing role perspectives
consistently improves performance, we propose MultiRole-R1, a
diversity-enhanced framework with multiple role perspectives, to improve the
accuracy and diversity in subjective reasoning tasks. MultiRole-R1 features an
unsupervised data construction pipeline that generates reasoning chains that
incorporate diverse role perspectives. We further employ reinforcement learning
via Group Relative Policy Optimization (GRPO) with reward shaping, by taking
diversity as a reward signal in addition to the verifiable reward. With
specially designed reward functions, we successfully promote perspective
diversity and lexical diversity, uncovering a positive relation between
reasoning diversity and accuracy. Our experiment on six benchmarks demonstrates
MultiRole-R1's effectiveness and generalizability in enhancing both subjective
and objective reasoning, showcasing the potential of diversity-enhanced
training in LRMs.

</details>


### [41] [IQ Test for LLMs: An Evaluation Framework for Uncovering Core Skills in LLMs](https://arxiv.org/abs/2507.20208)
*Aviya Maimon,Amir DN Cohen,Gal Vishne,Shauli Ravfogel,Reut Tsarfaty*

Main category: cs.CL

TL;DR: 本文提出了一种新的评估范式，通过因子分析识别驱动LLM性能的潜在技能，并将其应用于一个包含60个LLM和44个任务的排行榜，以识别冗余任务、辅助模型选择和分析模型在各个潜在技能上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型（LLMs）的评估依赖于基准分数，但难以解释这些分数揭示了模型的整体技能。我们缺乏对任务之间关系、它们共同测量的内容、差异以及哪些任务是冗余的理解。

Method: 我们使用因子分析来识别驱动跨基准性能的潜在技能，并将其应用于一个展示60个LLM在44个任务上的表现的新排行榜。

Result: 我们识别出一小部分潜在技能，这些技能大致解释了性能，并将这些见解转化为实用工具，以识别冗余任务、辅助模型选择和沿每个潜在技能对模型进行分析。

Conclusion: 我们提出了一个新评估范式，使用因子分析来识别驱动跨基准性能的潜在技能，并将这些见解转化为实用工具，以识别冗余任务、辅助模型选择和沿每个潜在技能对模型进行分析。

Abstract: Current evaluations of large language models (LLMs) rely on benchmark scores,
but it is difficult to interpret what these individual scores reveal about a
model's overall skills. Specifically, as a community we lack understanding of
how tasks relate to one another, what they measure in common, how they differ,
or which ones are redundant. As a result, models are often assessed via a
single score averaged across benchmarks, an approach that fails to capture the
models' wholistic strengths and limitations. Here, we propose a new evaluation
paradigm that uses factor analysis to identify latent skills driving
performance across benchmarks. We apply this method to a comprehensive new
leaderboard showcasing the performance of 60 LLMs on 44 tasks, and identify a
small set of latent skills that largely explain performance. Finally, we turn
these insights into practical tools that identify redundant tasks, aid in model
selection, and profile models along each latent skill.

</details>


### [42] [Co-NAML-LSTUR: A Combined Model with Attentive Multi-View Learning and Long- and Short-term User Representations for News Recommendation](https://arxiv.org/abs/2507.20210)
*Minh Hoang Nguyen,Thuat Thien Nguyen,Minh Nhat Ta*

Main category: cs.CL

TL;DR: 本文提出了一种混合新闻推荐框架Co-NAML-LSTUR，结合了多视图新闻建模和双尺度用户建模，取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常依赖于新闻文章的单视图特征（例如标题或类别）或未能全面捕捉跨时间尺度的用户偏好。

Method: 我们提出了Co-NAML-LSTUR，这是一种混合新闻推荐框架，结合了NAML用于关注的多视图新闻建模和LSTUR用于捕捉长短期用户表示。

Result: Co-NAML-LSTUR在MIND-small和MIND-large两个广泛使用的基准上分别实现了对大多数最先进的基线的显著改进。

Conclusion: 实验结果表明，将多视图新闻表示与双尺度用户建模相结合是有效的。

Abstract: News recommendation systems play a vital role in mitigating information
overload by delivering personalized news content. A central challenge is to
effectively model both multi-view news representations and the dynamic nature
of user interests, which often span both short- and long-term preferences.
Existing methods typically rely on single-view features of news articles (e.g.,
titles or categories) or fail to comprehensively capture user preferences
across time scales. In this work, we propose Co-NAML-LSTUR, a hybrid news
recommendation framework that integrates NAML for attentive multi-view news
modeling and LSTUR for capturing both long- and short-term user
representations. Our model also incorporates BERT-based word embeddings to
enhance semantic feature extraction. We evaluate Co-NAML-LSTUR on two widely
used benchmarks, MIND-small and MIND-large. Experimental results show that
Co-NAML-LSTUR achieves substantial improvements over most state-of-the-art
baselines on MIND-small and MIND-large, respectively. These results demonstrate
the effectiveness of combining multi-view news representations with dual-scale
user modeling. The implementation of our model is publicly available at
https://github.com/MinhNguyenDS/Co-NAML-LSTUR.

</details>


### [43] [Reframe Your Life Story: Interactive Narrative Therapist and Innovative Moment Assessment with Large Language Models](https://arxiv.org/abs/2507.20241)
*Yi Feng,Jiaqi Wang,Wenxuan Zhang,Zhuang Chen,Yutong Shen,Xiyao Xiao,Minlie Huang,Liping Jing,Jian Yu*

Main category: cs.CL

TL;DR: A framework called INT (Interactive Narrative Therapist) and IMA (Innovative Moment Assessment) is introduced to improve mental health support through realistic simulation of narrative therapy and tracking of therapeutic progress.


<details>
  <summary>Details</summary>
Motivation: Current approaches to mental health support using large language models lack realism in simulating specialized psychotherapy and fail to capture therapeutic progression over time. Narrative therapy remains underutilized due to limited access and social stigma.

Method: INT (Interactive Narrative Therapist) simulates expert narrative therapists by planning therapeutic stages, guiding reflection levels, and generating contextually appropriate expert-like responses. IMA (Innovative Moment Assessment) provides a therapy-centric evaluation method that quantifies effectiveness by tracking 'Innovative Moments' (IMs), critical narrative shifts in client speech signaling therapy progress.

Result: Experimental results on 260 simulated clients and 230 human participants reveal that INT consistently outperforms standard LLMs in therapeutic quality and depth. INT is also effective in synthesizing high-quality support conversations to facilitate social applications.

Conclusion: INT demonstrates superior therapeutic quality and depth compared to standard LLMs, and is effective in synthesizing high-quality support conversations for social applications.

Abstract: Recent progress in large language models (LLMs) has opened new possibilities
for mental health support, yet current approaches lack realism in simulating
specialized psychotherapy and fail to capture therapeutic progression over
time. Narrative therapy, which helps individuals transform problematic life
stories into empowering alternatives, remains underutilized due to limited
access and social stigma. We address these limitations through a comprehensive
framework with two core components. First, INT (Interactive Narrative
Therapist) simulates expert narrative therapists by planning therapeutic
stages, guiding reflection levels, and generating contextually appropriate
expert-like responses. Second, IMA (Innovative Moment Assessment) provides a
therapy-centric evaluation method that quantifies effectiveness by tracking
"Innovative Moments" (IMs), critical narrative shifts in client speech
signaling therapy progress. Experimental results on 260 simulated clients and
230 human participants reveal that INT consistently outperforms standard LLMs
in therapeutic quality and depth. We further demonstrate the effectiveness of
INT in synthesizing high-quality support conversations to facilitate social
applications.

</details>


### [44] [Modeling Professionalism in Expert Questioning through Linguistic Differentiation](https://arxiv.org/abs/2507.20249)
*Giulia D'Agostino,Chung-Chi Chen*

Main category: cs.CL

TL;DR: 本文研究了如何利用语言特征来建模和评估专家提问中的专业性，并展示了专业性是一个可以通过语言基础建模来捕捉的可学习的、领域通用的构造。


<details>
  <summary>Details</summary>
Motivation: 专业性是专家沟通的一个关键但研究不足的维度，特别是在高风险领域如金融中。本文旨在探讨如何利用语言特征来建模和评估专家提问中的专业性。

Method: 本文引入了一个新的注释框架，以量化金融分析师问题中的结构和语用元素，如话语调节器、前缀和请求类型。使用人工撰写和大型语言模型（LLM）生成的问题，构建了两个数据集：一个标注为感知专业性，另一个标注为问题来源。

Result: 相同的语言特征与人类判断和作者来源有很强的相关性，这表明存在共享的风格基础。此外，仅基于这些可解释特征训练的分类器在区分专家撰写的问题方面优于gemini-2.0和SVM基线。

Conclusion: 本文表明，专业性是一个可以通过语言基础建模来捕捉的可学习的、领域通用的构造。

Abstract: Professionalism is a crucial yet underexplored dimension of expert
communication, particularly in high-stakes domains like finance. This paper
investigates how linguistic features can be leveraged to model and evaluate
professionalism in expert questioning. We introduce a novel annotation
framework to quantify structural and pragmatic elements in financial analyst
questions, such as discourse regulators, prefaces, and request types. Using
both human-authored and large language model (LLM)-generated questions, we
construct two datasets: one annotated for perceived professionalism and one
labeled by question origin. We show that the same linguistic features correlate
strongly with both human judgments and authorship origin, suggesting a shared
stylistic foundation. Furthermore, a classifier trained solely on these
interpretable features outperforms gemini-2.0 and SVM baselines in
distinguishing expert-authored questions. Our findings demonstrate that
professionalism is a learnable, domain-general construct that can be captured
through linguistically grounded modeling.

</details>


### [45] [Post-Completion Learning for Language Models](https://arxiv.org/abs/2507.20252)
*Xiang Fei,Siqi Wang,Shu Wei,Yuxiang Nie,Wei Shi,Hao Feng,Can Huang*

Main category: cs.CL

TL;DR: 本文提出了Post-Completion Learning (PCL) 的训练框架，通过利用模型输出完成后的序列空间来提升模型的推理和自我评估能力。


<details>
  <summary>Details</summary>
Motivation: 当前的语言模型训练范式通常在达到结束序列（<eos>）标记时终止学习，忽略了完成后的空间中的潜在学习机会。我们提出了一种新的训练框架Post-Completion Learning (PCL)，系统地利用模型输出完成后的序列空间，以增强推理和自我评估能力。

Method: 我们设计了一种白盒强化学习方法，让模型根据奖励规则评估输出内容，然后计算并调整分数以与奖励函数对齐进行监督。我们实现了双轨SFT来优化推理和评估能力，并将其与RL训练混合以实现多目标混合优化。

Result: 在不同数据集和模型上的实验结果表明，我们的方法在传统SFT和RL方法上取得了持续的改进。

Conclusion: 我们的方法为语言模型训练提供了一种新的技术路径，能够在保持部署效率的同时提高输出质量。

Abstract: Current language model training paradigms typically terminate learning upon
reaching the end-of-sequence (<eos>}) token, overlooking the potential learning
opportunities in the post-completion space. We propose Post-Completion Learning
(PCL), a novel training framework that systematically utilizes the sequence
space after model output completion, to enhance both the reasoning and
self-evaluation abilities. PCL enables models to continue generating
self-assessments and reward predictions during training, while maintaining
efficient inference by stopping at the completion point.
  To fully utilize this post-completion space, we design a white-box
reinforcement learning method: let the model evaluate the output content
according to the reward rules, then calculate and align the score with the
reward functions for supervision. We implement dual-track SFT to optimize both
reasoning and evaluation capabilities, and mixed it with RL training to achieve
multi-objective hybrid optimization.
  Experimental results on different datasets and models demonstrate consistent
improvements over traditional SFT and RL methods. Our method provides a new
technical path for language model training that enhances output quality while
preserving deployment efficiency.

</details>


### [46] [EMBRACE: Shaping Inclusive Opinion Representation by Aligning Implicit Conversations with Social Norms](https://arxiv.org/abs/2507.20264)
*Abeer Aldayel,Areej Alokaili*

Main category: cs.CL

TL;DR: 本文介绍了一种评估框架，用于评估自然语言处理或计算模型中观点的表示方式，并通过隐含对话的分析，提供了一个更包容的模型行为路径。


<details>
  <summary>Details</summary>
Motivation: 现有的方法依赖于表面包含，忽略了对话中嵌入的细微、隐含的观点表达，这可能导致模型输出中的有害或刻板印象的表征。因此，本文旨在评估观点在NLP或计算模型中的表示方式，并引入一种强调隐含对话的对齐评估框架。

Method: 本文通过将响应的立场作为潜在观点的代理，建模了响应的立场，并使用正-未标记（PU）在线学习和指令调优的语言模型来评估后训练对齐。

Result: 本文提供了一种视角，以了解隐含观点是如何被（错误地）表示的，并提出了一个更包容的模型行为路径。

Conclusion: 本文提出了一种评估框架，用于评估自然语言处理或计算模型中如何表示观点，并提供了一种更包容的模型行为路径。

Abstract: Shaping inclusive representations that embrace diversity and ensure fair
participation and reflections of values is at the core of many
conversation-based models. However, many existing methods rely on surface
inclusion using mention of user demographics or behavioral attributes of social
groups. Such methods overlook the nuanced, implicit expression of opinion
embedded in conversations. Furthermore, the over-reliance on overt cues can
exacerbate misalignment and reinforce harmful or stereotypical representations
in model outputs. Thus, we took a step back and recognized that equitable
inclusion needs to account for the implicit expression of opinion and use the
stance of responses to validate the normative alignment. This study aims to
evaluate how opinions are represented in NLP or computational models by
introducing an alignment evaluation framework that foregrounds implicit, often
overlooked conversations and evaluates the normative social views and
discourse. Our approach models the stance of responses as a proxy for the
underlying opinion, enabling a considerate and reflective representation of
diverse social viewpoints. We evaluate the framework using both (i)
positive-unlabeled (PU) online learning with base classifiers, and (ii)
instruction-tuned language models to assess post-training alignment. Through
this, we provide a lens on how implicit opinions are (mis)represented and offer
a pathway toward more inclusive model behavior.

</details>


### [47] [MoL-RL: Distilling Multi-Step Environmental Feedback into LLMs for Feedback-Independent Reasoning](https://arxiv.org/abs/2507.20278)
*Kang Yang,Jingxue Chen,Qingkun Tang,Tianxiang Zhang,Qianchun Lu*

Main category: cs.CL

TL;DR: 本文提出了一种新的训练范式MoL-RL，通过结合多步EF信号和GRPO-based后训练，实现了在不依赖外部反馈循环的情况下进行鲁棒的反馈独立推理。实验结果表明，MoL-RL在多个基准测试中表现出色，展示了其在不同领域提升LLM推理能力的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的方法要么将EF转换为标量奖励，导致丰富的上下文信息丢失，要么使用细化数据集，未能充分利用EF交互的多步和离散特性。因此，需要一种新的方法来有效利用多步EF信号，以提高LLM的推理能力。

Method: 本文提出的方法结合了MoL（混合损失）持续训练和基于GRPO的后训练，以将多步EF信号整合到LLM中。MoL训练通过交叉熵损失优化特定领域的EF信号，同时通过Kullback-Leibler散度保持通用语言能力。GRPO-based后训练则用于将序列EF交互提炼为单步推理。

Result: 在数学推理（MATH-500, AIME24/AIME25）和代码生成（CodeAgent-Test）基准测试中，MoL-RL在Qwen3-8B模型上达到了最先进的性能，同时在模型规模（Qwen3-4B）上保持了强大的泛化能力。

Conclusion: 本文提出了一种新的训练范式MoL-RL，通过结合多步EF信号和GRPO-based后训练，实现了在不依赖外部反馈循环的情况下进行鲁棒的反馈独立推理。实验结果表明，MoL-RL在多个基准测试中表现出色，展示了其在不同领域提升LLM推理能力的潜力。

Abstract: Large language models (LLMs) face significant challenges in effectively
leveraging sequential environmental feedback (EF) signals, such as natural
language evaluations, for feedback-independent chain-of-thought (CoT)
reasoning. Existing approaches either convert EF into scalar rewards, losing
rich contextual information, or employ refinement datasets, failing to exploit
the multi-step and discrete nature of EF interactions. To address these
limitations, we propose MoL-RL, a novel training paradigm that integrates
multi-step EF signals into LLMs through a dual-objective optimization
framework. Our method combines MoL (Mixture-of-Losses) continual training,
which decouples domain-specific EF signals (optimized via cross-entropy loss)
and general language capabilities (preserved via Kullback-Leibler divergence),
with GRPO-based post-training to distill sequential EF interactions into
single-step inferences. This synergy enables robust feedback-independent
reasoning without relying on external feedback loops. Experimental results on
mathematical reasoning (MATH-500, AIME24/AIME25) and code generation
(CodeAgent-Test) benchmarks demonstrate that MoL-RL achieves state-of-the-art
performance with the Qwen3-8B model, while maintaining strong generalization
across model scales (Qwen3-4B). This work provides a promising approach for
leveraging multi-step textual feedback to enhance LLMs' reasoning capabilities
in diverse domains.

</details>


### [48] [What Language(s) Does Aya-23 Think In? How Multilinguality Affects Internal Language Representations](https://arxiv.org/abs/2507.20279)
*Katharina Trinley,Toshiki Nakai,Tatiana Anikina,Tanja Baeumel*

Main category: cs.CL

TL;DR: 本文通过分析Aya-23-8B和其他单语模型，揭示了多语言训练如何影响大型语言模型的内部结构，并为未来的跨语言迁移研究提供了见解。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在多语言任务中表现出色，但其内部语言处理机制仍不明确。本文旨在探索多语言训练对模型内部结构的影响。

Method: 使用logit lens和神经元专业化分析，比较了Aya-23-8B与其他单语模型在处理代码混合、填空和翻译任务时的表现。

Result: Aya-23在翻译任务中激活了类型相关的语言表示，而英语中心模型则依赖单一的中间语言；代码混合的神经元激活模式受混合率和基础语言的影响；Aya-23的语言特定神经元在最终层集中，与之前对解码器-only模型的研究结果不同。

Conclusion: 本文揭示了多语言训练如何影响大型语言模型的内部结构，并为未来的跨语言迁移研究提供了见解。

Abstract: Large language models (LLMs) excel at multilingual tasks, yet their internal
language processing remains poorly understood. We analyze how Aya-23-8B, a
decoder-only LLM trained on balanced multilingual data, handles code-mixed,
cloze, and translation tasks compared to predominantly monolingual models like
Llama 3 and Chinese-LLaMA-2. Using logit lens and neuron specialization
analyses, we find: (1) Aya-23 activates typologically related language
representations during translation, unlike English-centric models that rely on
a single pivot language; (2) code-mixed neuron activation patterns vary with
mixing rates and are shaped more by the base language than the mixed-in one;
and (3) Aya-23's languagespecific neurons for code-mixed inputs concentrate in
final layers, diverging from prior findings on decoder-only models. Neuron
overlap analysis further shows that script similarity and typological relations
impact processing across model types. These findings reveal how multilingual
training shapes LLM internals and inform future cross-lingual transfer
research.

</details>


### [49] [Advancing Dialectal Arabic to Modern Standard Arabic Machine Translation](https://arxiv.org/abs/2507.20301)
*Abdullah Alabdullah,Lifeng Han,Chenghua Lin*

Main category: cs.CL

TL;DR: 本研究针对阿拉伯语方言到标准阿拉伯语的机器翻译问题，提出了两种核心贡献：对无需训练提示技术的全面评估，以及开发了一个资源高效的微调流程。实验结果表明，在资源有限的情况下，高质量的DA-MSA机器翻译是可行的。


<details>
  <summary>Details</summary>
Motivation: Dialectal Arabic (DA) 对自然语言处理（NLP）构成了持续的挑战，因为阿拉伯世界日常交流大多使用与现代标准阿拉伯语（MSA）显著不同的方言。这种语言隔阂限制了数字服务和教育资源的获取，并阻碍了阿拉伯语机器翻译的进步。

Method: 本研究提出了两种核心贡献：对无需训练提示技术的全面评估，以及开发了一个资源高效的微调流程。评估了六种大型语言模型（LLMs）的提示策略，并开发了一个量化Gem2-9B模型的微调管道。

Result: 在提示策略的评估中，少样本提示始终优于零样本、思维链和我们提出的Ara-TEaR方法。GPT-4o在所有提示设置中表现最佳。对于微调，量化后的Gemma2-9B模型获得了49.88的CHrF++分数，超过了零样本GPT-4o（44.58）。联合多方言训练的模型比单方言模型高出10%以上的CHrF++，4位量化将内存使用量减少了60%，性能损失不到1%。

Conclusion: 本研究的结果和见解为提高阿拉伯语自然语言处理中的方言包容性提供了实用的蓝图，表明即使在资源有限的情况下，高质量的DA-MSA机器翻译也是可行的，并为更包容的语言技术铺平了道路。

Abstract: Dialectal Arabic (DA) poses a persistent challenge for natural language
processing (NLP), as most everyday communication in the Arab world occurs in
dialects that diverge significantly from Modern Standard Arabic (MSA). This
linguistic divide limits access to digital services and educational resources
and impedes progress in Arabic machine translation. This paper presents two
core contributions to advancing DA-MSA translation for the Levantine, Egyptian,
and Gulf dialects, particularly in low-resource and computationally constrained
settings: a comprehensive evaluation of training-free prompting techniques, and
the development of a resource-efficient fine-tuning pipeline. Our evaluation of
prompting strategies across six large language models (LLMs) found that
few-shot prompting consistently outperformed zero-shot, chain-of-thought, and
our proposed Ara-TEaR method. GPT-4o achieved the highest performance across
all prompting settings. For fine-tuning, a quantized Gemma2-9B model achieved a
CHrF++ score of 49.88, outperforming zero-shot GPT-4o (44.58). Joint
multi-dialect trained models outperformed single-dialect counterparts by over
10% CHrF++, and 4-bit quantization reduced memory usage by 60% with less than
1% performance loss. The results and insights of our experiments offer a
practical blueprint for improving dialectal inclusion in Arabic NLP, showing
that high-quality DA-MSA machine translation is achievable even with limited
resources and paving the way for more inclusive language technologies.

</details>


### [50] [DYNARTmo: A Dynamic Articulatory Model for Visualization of Speech Movement Patterns](https://arxiv.org/abs/2507.20343)
*Bernd J. Kröger*

Main category: cs.CL

TL;DR: DYNARTmo是一个动态的发音模型，用于在二维矢状平面上可视化语音发音过程。它基于UK-DYNAMO框架，并整合了发音不明确性、音段和手势控制以及共音化的原理。DYNARTmo模拟六个关键发音器，允许生成元音和辅音的发音配置。当前实现嵌入在一个基于网络的应用程序中，适用于语音学教育和言语治疗。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够可视化语音发音过程的动态模型，以支持语音学教育和言语治疗。

Method: 基于UK-DYNAMO框架，整合发音不明确性、音段和手势控制以及共音化的原理，构建一个动态的发音模型。

Result: DYNARTmo能够模拟六个关键发音器，生成元音和辅音的发音配置，并嵌入到一个基于网络的应用程序中。

Conclusion: DYNARTmo为语音学教育和言语治疗提供了一个有效的工具，未来将扩展其动态运动生成和与发音-声学模块的集成。

Abstract: We present DYNARTmo, a dynamic articulatory model designed to visualize
speech articulation processes in a two-dimensional midsagittal plane. The model
builds upon the UK-DYNAMO framework and integrates principles of articulatory
underspecification, segmental and gestural control, and coarticulation.
DYNARTmo simulates six key articulators based on ten continuous and six
discrete control parameters, allowing for the generation of both vocalic and
consonantal articulatory configurations. The current implementation is embedded
in a web-based application (SpeechArticulationTrainer) that includes sagittal,
glottal, and palatal views, making it suitable for use in phonetics education
and speech therapy. While this paper focuses on the static modeling aspects,
future work will address dynamic movement generation and integration with
articulatory-acoustic modules.

</details>


### [51] [RMTBench: Benchmarking LLMs Through Multi-Turn User-Centric Role-Playing](https://arxiv.org/abs/2507.20352)
*Hao Xiang,Tianyi Tang,Yang Su,Bowen Yu,An Yang,Fei Huang,Yichang Zhang,Yaojie Lu,Hongyu Lin,Xianpei Han,Jingren Zhou,Junyang Lin,Le Sun*

Main category: cs.CL

TL;DR: RMTBench is a user-centric role-playing benchmark that evaluates LLMs by focusing on user intentions rather than character backgrounds, providing a more practical assessment of role-playing capabilities.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks mostly adopt a character-centric approach, simplifying user-character interactions to isolated Q&A tasks, which fail to reflect real-world applications. Evaluating role-playing capabilities in LLMs is crucial yet challenging.

Method: RMTBench is a comprehensive user-centric bilingual role-playing benchmark featuring 80 diverse characters and over 8,000 dialogue rounds. It constructs dialogues based on explicit user motivations and includes an authentic multi-turn dialogue simulation mechanism with LLM-based scoring.

Result: RMTBench enables evaluation across various user scenarios by focusing on user intention fulfillment rather than character background. It provides a more effective framework for assessing role-playing capabilities in LLMs.

Conclusion: RMTBench bridges the gap between academic evaluation and practical deployment requirements, offering a more effective framework for assessing role-playing capabilities in LLMs.

Abstract: Recent advancements in Large Language Models (LLMs) have shown outstanding
potential for role-playing applications. Evaluating these capabilities is
becoming crucial yet remains challenging. Existing benchmarks mostly adopt a
\textbf{character-centric} approach, simplify user-character interactions to
isolated Q&A tasks, and fail to reflect real-world applications. To address
this limitation, we introduce RMTBench, a comprehensive \textbf{user-centric}
bilingual role-playing benchmark featuring 80 diverse characters and over 8,000
dialogue rounds. RMTBench includes custom characters with detailed backgrounds
and abstract characters defined by simple traits, enabling evaluation across
various user scenarios. Our benchmark constructs dialogues based on explicit
user motivations rather than character descriptions, ensuring alignment with
practical user applications. Furthermore, we construct an authentic multi-turn
dialogue simulation mechanism. With carefully selected evaluation dimensions
and LLM-based scoring, this mechanism captures the complex intention of
conversations between the user and the character. By shifting focus from
character background to user intention fulfillment, RMTBench bridges the gap
between academic evaluation and practical deployment requirements, offering a
more effective framework for assessing role-playing capabilities in LLMs. All
code and datasets will be released soon.

</details>


### [52] [Length Representations in Large Language Models](https://arxiv.org/abs/2507.20398)
*Sangjun Moon,Dasom Choi,Jingun Kwon,Hidetaka Kamigaito,Manabu Okumura*

Main category: cs.CL

TL;DR: 本研究揭示了大型语言模型如何通过多头注意力机制内部控制输出序列长度，证明长度信息部分与语义信息分离。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs可以控制输出序列长度，特别是在基于指令的设置中，但这种控制背后的内部机制尚未被探索。

Method: 我们通过实证研究分析了大型语言模型（LLMs）内部表示中如何编码输出序列长度信息，并探讨了多头注意力机制在确定输出序列长度中的关键作用。

Result: 我们的研究发现，多头注意力机制在确定输出序列长度中起着关键作用，可以通过调整特定的隐藏单元来控制输出序列长度，同时保持生成文本的信息量。此外，一些隐藏单元在提示变得更具体时变得更加活跃，反映了模型对这一属性的内部意识。

Conclusion: 我们的研究结果表明，LLMs已经学会了稳健且适应性强的内部机制来控制输出长度，而无需外部控制。

Abstract: Large language models (LLMs) have shown remarkable capabilities across
various tasks, that are learned from massive amounts of text-based data.
Although LLMs can control output sequence length, particularly in
instruction-based settings, the internal mechanisms behind this control have
been unexplored yet. In this study, we provide empirical evidence on how output
sequence length information is encoded within the internal representations in
LLMs. In particular, our findings show that multi-head attention mechanisms are
critical in determining output sequence length, which can be adjusted in a
disentangled manner. By scaling specific hidden units within the model, we can
control the output sequence length without losing the informativeness of the
generated text, thereby indicating that length information is partially
disentangled from semantic information. Moreover, some hidden units become
increasingly active as prompts become more length-specific, thus reflecting the
model's internal awareness of this attribute. Our findings suggest that LLMs
have learned robust and adaptable internal mechanisms for controlling output
length without any external control.

</details>


### [53] [Cognitive Chain-of-Thought: Structured Multimodal Reasoning about Social Situations](https://arxiv.org/abs/2507.20409)
*Eunkyu Park,Wesley Hanwen Deng,Gunhee Kim,Motahhare Eslami,Maarten Sap*

Main category: cs.CL

TL;DR: 本文介绍了CoCoT，一种通过三个认知阶段提升视觉语言模型推理能力的提示策略，并展示了其在多个任务中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 在基于社会背景的视觉任务中，将感知与以规范为基础的判断联系起来是至关重要的，但传统的CoT常常失效。

Method: 我们引入了认知链式思维（CoCoT），这是一种通过三个认知启发阶段（感知、情境和规范）来促进视觉语言模型推理的提示策略。

Result: 在多个多模态基准测试中（包括意图消歧、常识推理和安全性），CoCoT的表现优于CoT和直接提示（平均高出8%）。

Conclusion: 我们的研究结果表明，基于认知的推理阶段可以增强视觉语言模型的可解释性和社会意识，为更安全和可靠的多模态系统铺平道路。

Abstract: Chain-of-Thought (CoT) prompting helps models think step by step. But what
happens when they must see, understand, and judge-all at once? In visual tasks
grounded in social context, where bridging perception with norm-grounded
judgments is essential, flat CoT often breaks down. We introduce Cognitive
Chain-of-Thought (CoCoT), a prompting strategy that scaffolds VLM reasoning
through three cognitively inspired stages: perception, situation, and norm. Our
experiments show that, across multiple multimodal benchmarks (including intent
disambiguation, commonsense reasoning, and safety), CoCoT consistently
outperforms CoT and direct prompting (+8\% on average). Our findings
demonstrate that cognitively grounded reasoning stages enhance interpretability
and social awareness in VLMs, paving the way for safer and more reliable
multimodal systems.

</details>


### [54] [CONCAP: Seeing Beyond English with Concepts Retrieval-Augmented Captioning](https://arxiv.org/abs/2507.20411)
*George Ibrahim,Rita Ramos,Yova Kementchedjhieva*

Main category: cs.CL

TL;DR: 我们引入了CONCAP，这是一种多语言图像描述模型，它结合了检索到的描述和图像特定的概念，以增强输入图像的上下文并建立描述过程的基准。实验表明，CONCAP在低资源和中等资源语言上表现良好，数据需求大幅减少。


<details>
  <summary>Details</summary>
Motivation: 多语言视觉-语言模型在图像描述方面取得了显著进展，但仍落后于其英语同行，这是由于多语言训练数据有限和大规模模型参数化成本高昂。检索增强生成（RAG）提供了一种有前景的替代方案，通过在目标语言中检索示例来条件化描述生成，减少了对大量多语言训练的需求。然而，多语言RAG描述模型通常依赖于从英语翻译的检索描述，这相对于源语言可能会引入不匹配和语言偏差。

Method: 我们引入了CONCAP，这是一种多语言图像描述模型，它将检索到的描述与图像特定的概念相结合，增强了输入图像的上下文，并在不同语言中建立了描述过程的基准。

Result: 在XM3600数据集上的实验表明，CONCAP在低资源和中等资源语言上表现出色，数据需求大幅减少。

Conclusion: 我们的研究结果表明，概念感知的检索增强在弥合多语言性能差距方面是有效的。

Abstract: Multilingual vision-language models have made significant strides in image
captioning, yet they still lag behind their English counterparts due to limited
multilingual training data and costly large-scale model parameterization.
Retrieval-augmented generation (RAG) offers a promising alternative by
conditioning caption generation on retrieved examples in the target language,
reducing the need for extensive multilingual training. However, multilingual
RAG captioning models often depend on retrieved captions translated from
English, which can introduce mismatches and linguistic biases relative to the
source language. We introduce CONCAP, a multilingual image captioning model
that integrates retrieved captions with image-specific concepts, enhancing the
contextualization of the input image and grounding the captioning process
across different languages. Experiments on the XM3600 dataset indicate that
CONCAP enables strong performance on low- and mid-resource languages, with
highly reduced data requirements. Our findings highlight the effectiveness of
concept-aware retrieval augmentation in bridging multilingual performance gaps.

</details>


### [55] [Survey of NLU Benchmarks Diagnosing Linguistic Phenomena: Why not Standardize Diagnostics Benchmarks?](https://arxiv.org/abs/2507.20419)
*Khloud AL Jallad,Nada Ghneim,Ghaida Rebdawi*

Main category: cs.CL

TL;DR: 本文综述了现有的NLU评估基准，分析了其诊断数据集和语言现象覆盖情况，指出了当前缺乏统一评估标准的问题，并提出了未来建立全球语言现象层次结构和评估指标的建议。


<details>
  <summary>Details</summary>
Motivation: 由于当前NLU评估缺乏统一的标准，导致不同基准之间的比较困难，因此需要建立一个通用的评估框架。

Method: 本文对现有的英语、阿拉伯语和多语言NLU基准进行了全面回顾，特别关注其诊断数据集和所涵盖的语言现象，并进行了详细比较和分析。

Result: 本文发现了现有基准在语言现象覆盖上的不足，并提出了关于评估指标的研究问题，即为何没有类似工业中ISO标准的NLU评估诊断基准标准。

Conclusion: 本文指出，目前缺乏对NLU评估诊断基准的统一评价标准，建议未来研究建立全球语言现象层次结构，并开发诊断评估的评价指标以获得更深入的模型比较见解。

Abstract: Natural Language Understanding (NLU) is a basic task in Natural Language
Processing (NLP). The evaluation of NLU capabilities has become a trending
research topic that attracts researchers in the last few years, resulting in
the development of numerous benchmarks. These benchmarks include various tasks
and datasets in order to evaluate the results of pretrained models via public
leaderboards. Notably, several benchmarks contain diagnostics datasets designed
for investigation and fine-grained error analysis across a wide range of
linguistic phenomena. This survey provides a comprehensive review of available
English, Arabic, and Multilingual NLU benchmarks, with a particular emphasis on
their diagnostics datasets and the linguistic phenomena they covered. We
present a detailed comparison and analysis of these benchmarks, highlighting
their strengths and limitations in evaluating NLU tasks and providing in-depth
error analysis. When highlighting the gaps in the state-of-the-art, we noted
that there is no naming convention for macro and micro categories or even a
standard set of linguistic phenomena that should be covered. Consequently, we
formulated a research question regarding the evaluation metrics of the
evaluation diagnostics benchmarks: "Why do not we have an evaluation standard
for the NLU evaluation diagnostics benchmarks?" similar to ISO standard in
industry. We conducted a deep analysis and comparisons of the covered
linguistic phenomena in order to support experts in building a global hierarchy
for linguistic phenomena in future. We think that having evaluation metrics for
diagnostics evaluation could be valuable to gain more insights when comparing
the results of the studied models on different diagnostics benchmarks.

</details>


### [56] [CodeNER: Code Prompting for Named Entity Recognition](https://arxiv.org/abs/2507.20423)
*Sungwoo Han,Hyeyeon Kim,Jingun Kwon,Hidetaka Kamigaito,Manabu Okumura*

Main category: cs.CL

TL;DR: 本文提出了一种基于代码的提示方法，以提高大型语言模型在命名实体识别任务中的表现。实验结果表明，该方法在多个语言的数据集上优于传统文本提示方法，并且与思维链提示结合使用时效果更好。


<details>
  <summary>Details</summary>
Motivation: 尽管之前的方法已经成功生成了带有适当标签的候选命名实体跨度，但它们仅依赖于输入上下文信息来使用LLMs，特别是ChatGPT。然而，NER本质上需要捕捉详细的标记要求和输入上下文信息。

Method: 我们提出了一种新的方法，利用基于代码的提示来提高大型语言模型（LLMs）在理解和执行命名实体识别（NER）方面的能力。通过在提示中嵌入代码，我们提供了详细的BIO模式说明，从而利用LLMs理解编程语言中的长距离范围的能力。

Result: 实验结果表明，所提出的基于代码的提示方法在英语、阿拉伯语、芬兰语、丹麦语和德语数据集的十个基准测试中优于传统的文本提示方法，这表明明确构建NER指令的有效性。

Conclusion: 实验结果表明，基于代码的提示方法在十个基准测试中优于传统的文本提示方法，这表明明确构建NER指令的有效性。我们还验证了将所提出的基于代码的提示方法与思维链提示相结合可以进一步提高性能。

Abstract: Recent studies have explored various approaches for treating candidate named
entity spans as both source and target sequences in named entity recognition
(NER) by leveraging large language models (LLMs). Although previous approaches
have successfully generated candidate named entity spans with suitable labels,
they rely solely on input context information when using LLMs, particularly,
ChatGPT. However, NER inherently requires capturing detailed labeling
requirements with input context information. To address this issue, we propose
a novel method that leverages code-based prompting to improve the capabilities
of LLMs in understanding and performing NER. By embedding code within prompts,
we provide detailed BIO schema instructions for labeling, thereby exploiting
the ability of LLMs to comprehend long-range scopes in programming languages.
Experimental results demonstrate that the proposed code-based prompting method
outperforms conventional text-based prompting on ten benchmarks across English,
Arabic, Finnish, Danish, and German datasets, indicating the effectiveness of
explicitly structuring NER instructions. We also verify that combining the
proposed code-based prompting method with the chain-of-thought prompting
further improves performance.

</details>


### [57] [Speaking in Words, Thinking in Logic: A Dual-Process Framework in QA Systems](https://arxiv.org/abs/2507.20491)
*Tuan Bui,Trong Le,Phat Thai,Sang Nguyen,Minh Hua,Ngan Pham,Thang Bui,Tho Quan*

Main category: cs.CL

TL;DR: 本文介绍了Text-JEPA，一种轻量级的框架，用于将自然语言转换为一阶逻辑，通过双系统认知理论提高推理效率，并在特定领域数据集上验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 在封闭领域场景中，用户不仅需要准确的答案，还需要透明的推理和可解释的决策过程。现有的方法通常依赖于大规模模型，并在将自然语言转换为形式逻辑表示时表现出低效性。

Method: 我们引入了Text-JEPA，这是一种轻量级但有效的框架，用于将自然语言转换为一阶逻辑（NL2FOL）。Text-JEPA借鉴了双系统认知理论，模拟系统1以高效生成逻辑表示，而Z3求解器作为系统2，实现强大的逻辑推理。

Result: 在特定领域的数据集上进行的实证结果显示，Text-JEPA在计算开销显著降低的情况下，表现与基于大型语言模型的系统相当。

Conclusion: 我们的研究结果表明，结构化、可解释的推理框架在构建高效且可解释的问答系统方面具有潜力。

Abstract: Recent advances in large language models (LLMs) have significantly enhanced
question-answering (QA) capabilities, particularly in open-domain contexts.
However, in closed-domain scenarios such as education, healthcare, and law,
users demand not only accurate answers but also transparent reasoning and
explainable decision-making processes. While neural-symbolic (NeSy) frameworks
have emerged as a promising solution, leveraging LLMs for natural language
understanding and symbolic systems for formal reasoning, existing approaches
often rely on large-scale models and exhibit inefficiencies in translating
natural language into formal logic representations.
  To address these limitations, we introduce Text-JEPA (Text-based
Joint-Embedding Predictive Architecture), a lightweight yet effective framework
for converting natural language into first-order logic (NL2FOL). Drawing
inspiration from dual-system cognitive theory, Text-JEPA emulates System 1 by
efficiently generating logic representations, while the Z3 solver operates as
System 2, enabling robust logical inference. To rigorously evaluate the
NL2FOL-to-reasoning pipeline, we propose a comprehensive evaluation framework
comprising three custom metrics: conversion score, reasoning score, and
Spearman rho score, which collectively capture the quality of logical
translation and its downstream impact on reasoning accuracy.
  Empirical results on domain-specific datasets demonstrate that Text-JEPA
achieves competitive performance with significantly lower computational
overhead compared to larger LLM-based systems. Our findings highlight the
potential of structured, interpretable reasoning frameworks for building
efficient and explainable QA systems in specialized domains.

</details>


### [58] [AQUA: A Large Language Model for Aquaculture & Fisheries](https://arxiv.org/abs/2507.20520)
*Praneeth Narisetty,Uday Kumar Reddy Kattamanchi,Lohit Akshant Nimma,Sri Ram Kaushik Karnati,Shiva Nagendra Babu Kore,Mounika Golamari,Tejashree Nageshreddy*

Main category: cs.CL

TL;DR: 本文介绍了针对水产养殖的首个大型语言模型AQUA及其数据生成框架AQUADAPT，旨在解决行业面临的多种挑战。


<details>
  <summary>Details</summary>
Motivation: 水产养殖在保障全球食品安全和沿海经济中发挥着重要作用，但面临疾病爆发、低效饲养实践、劳动力成本上升、物流效率低下和孵化场问题等挑战。现有的机器学习方法无法解决水产养殖领域的特定复杂性。

Method: 引入了AQUA，这是第一个针对水产养殖的大型语言模型（LLM），并开发了AQUADAPT（数据采集、处理和调优），这是一个用于生成和精炼高质量合成数据的代理框架。

Result: AQUA和AQUADAPT的引入为水产养殖领域提供了新的解决方案，有助于提高生产效率和管理水平。

Conclusion: 我们的工作为水产养殖研究、咨询系统和决策工具中的LLM驱动创新奠定了基础。

Abstract: Aquaculture plays a vital role in global food security and coastal economies
by providing sustainable protein sources. As the industry expands to meet
rising demand, it faces growing challenges such as disease outbreaks,
inefficient feeding practices, rising labor costs, logistical inefficiencies,
and critical hatchery issues, including high mortality rates and poor water
quality control. Although artificial intelligence has made significant
progress, existing machine learning methods fall short of addressing the
domain-specific complexities of aquaculture. To bridge this gap, we introduce
AQUA, the first large language model (LLM) tailored for aquaculture, designed
to support farmers, researchers, and industry practitioners. Central to this
effort is AQUADAPT (Data Acquisition, Processing and Tuning), an Agentic
Framework for generating and refining high-quality synthetic data using a
combination of expert knowledge, largescale language models, and automated
evaluation techniques. Our work lays the foundation for LLM-driven innovations
in aquaculture research, advisory systems, and decision-making tools.

</details>


### [59] [SAND-Math: Using LLMs to Generate Novel, Difficult and Useful Mathematics Questions and Answers](https://arxiv.org/abs/2507.20527)
*Chaitanya Manem,Pratik Prabhanjan Brahma,Prakamya Mishra,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: SAND-Math是一个用于生成高质量、高难度数学问题和解答的数据集，通过难度提升步骤有效提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏困难且新颖的训练数据，开发高性能的数学大型语言模型面临瓶颈。

Method: SAND-Math方法包括从头生成高质量问题，然后通过新的难度提升步骤系统地提高问题的复杂性。

Result: 通过使用SAND-Math数据集，模型在AIME25基准测试中表现出色，比下一个最佳合成数据集高出17.85个百分点，并且通过难度提升步骤显著提高了性能。

Conclusion: SAND-Math数据集和相关工具包为构建更强大和高效的数学推理大型语言模型提供了实用且可扩展的解决方案。

Abstract: The demand for Large Language Models (LLMs) capable of sophisticated
mathematical reasoning is growing across industries. However, the development
of performant mathematical LLMs is critically bottlenecked by the scarcity of
difficult, novel training data. We introduce \textbf{SAND-Math} (Synthetic
Augmented Novel and Difficult Mathematics problems and solutions), a pipeline
that addresses this by first generating high-quality problems from scratch and
then systematically elevating their complexity via a new \textbf{Difficulty
Hiking} step. We demonstrate the effectiveness of our approach through two key
findings. First, augmenting a strong baseline with SAND-Math data significantly
boosts performance, outperforming the next-best synthetic dataset by
\textbf{$\uparrow$ 17.85 absolute points} on the AIME25 benchmark. Second, in a
dedicated ablation study, we show our Difficulty Hiking process is highly
effective: by increasing average problem difficulty from 5.02 to 5.98, this
step lifts AIME25 performance from 46.38\% to 49.23\%. The full generation
pipeline, final dataset, and a fine-tuned model form a practical and scalable
toolkit for building more capable and efficient mathematical reasoning LLMs.
SAND-Math dataset is released here:
\href{https://huggingface.co/datasets/amd/SAND-MATH}{https://huggingface.co/datasets/amd/SAND-MATH}

</details>


### [60] [Dialogues of Dissent: Thematic and Rhetorical Dimensions of Hate and Counter-Hate Speech in Social Media Conversations](https://arxiv.org/abs/2507.20528)
*Effi Levi,Gal Ron,Odelia Oshri,Shaul R. Shenhav*

Main category: cs.CL

TL;DR: 本文提出了一种新的多标签方案，用于标注社交媒体上的仇恨和反仇恨言论，并通过分析发现了一些关于这些言论的传播和影响的见解。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解社交媒体上仇恨和反仇恨言论的互动模式，以及它们如何影响在线行为，我们需要一种新的标注方法。

Method: 我们引入了一种新颖的多标签方案，用于联合标注社交媒体对话中的仇恨和反仇恨言论，将仇恨和反仇恨信息分为主题和修辞维度。

Result: 我们标注了一个包含92个对话（共720条推文）的样本，并进行了统计分析，结合公共指标，探索了主题和修辞维度之间的互动模式。

Conclusion: 我们的研究提供了关于仇恨言论在社交媒体上的传播、对抗策略及其对在线行为的潜在影响的见解。

Abstract: We introduce a novel multi-labeled scheme for joint annotation of hate and
counter-hate speech in social media conversations, categorizing hate and
counter-hate messages into thematic and rhetorical dimensions. The thematic
categories outline different discursive aspects of each type of speech, while
the rhetorical dimension captures how hate and counter messages are
communicated, drawing on Aristotle's Logos, Ethos and Pathos. We annotate a
sample of 92 conversations, consisting of 720 tweets, and conduct statistical
analyses, incorporating public metrics, to explore patterns of interaction
between the thematic and rhetorical dimensions within and between hate and
counter-hate speech. Our findings provide insights into the spread of hate
messages on social media, the strategies used to counter them, and their
potential impact on online behavior.

</details>


### [61] [Enhancing Hallucination Detection via Future Context](https://arxiv.org/abs/2507.20546)
*Joosung Lee,Cheonbok Park,Hwiyeol Jo,Jeonghoon Kim,Joonsuk Park,Kang Min Yoo*

Main category: cs.CL

TL;DR: 本文提出了一种用于检测黑箱生成器中幻觉的框架，通过采样未来上下文来提高检测效果。


<details>
  <summary>Details</summary>
Motivation: 由于幻觉一旦引入就会持续存在，因此需要一种有效的检测方法。

Method: 本文通过采样未来上下文，结合各种基于采样的方法，以检测幻觉。

Result: 本文提出的采样方法在多种方法中均表现出性能提升。

Conclusion: 本文提出了一种用于检测黑箱生成器中幻觉的框架，通过采样未来上下文来提高检测效果。

Abstract: Large Language Models (LLMs) are widely used to generate plausible text on
online platforms, without revealing the generation process. As users
increasingly encounter such black-box outputs, detecting hallucinations has
become a critical challenge. To address this challenge, we focus on developing
a hallucination detection framework for black-box generators. Motivated by the
observation that hallucinations, once introduced, tend to persist, we sample
future contexts. The sampled future contexts provide valuable clues for
hallucination detection and can be effectively integrated with various
sampling-based methods. We extensively demonstrate performance improvements
across multiple methods using our proposed sampling approach.

</details>


### [62] [ZSE-Cap: A Zero-Shot Ensemble for Image Retrieval and Prompt-Guided Captioning](https://arxiv.org/abs/2507.20564)
*Duc-Tai Dinh,Duc Anh Khoa Dinh*

Main category: cs.CL

TL;DR: 我们提出了ZSE-Cap（零样本集成用于描述），这是在EVENTA共享任务中获得第四名的系统。我们的零样本方法不需要对比赛数据进行微调。在检索方面，我们集成了CLIP、SigLIP和DINOv2的相似度分数。在描述方面，我们利用精心设计的提示引导Gemma 3模型，使其能够将文章中的高层次事件与图像中的视觉内容联系起来。我们的系统在私有测试集上获得了前四名的成绩，证明了通过集成和提示结合基础模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 我们希望提出一种零样本方法，无需对比赛数据进行微调，以实现文章支撑的图像检索和描述。

Method: 我们通过集成CLIP、SigLIP和DINOv2的相似度分数进行检索，并利用精心设计的提示引导Gemma 3模型，使其能够将文章中的高层次事件与图像中的视觉内容联系起来。

Result: 我们的系统最终得分为0.42002，在私有测试集上获得前四名的成绩。

Conclusion: 我们的系统在私有测试集上获得了前四名的成绩，证明了通过集成和提示结合基础模型的有效性。

Abstract: We present ZSE-Cap (Zero-Shot Ensemble for Captioning), our 4th place system
in Event-Enriched Image Analysis (EVENTA) shared task on article-grounded image
retrieval and captioning. Our zero-shot approach requires no finetuning on the
competition's data. For retrieval, we ensemble similarity scores from CLIP,
SigLIP, and DINOv2. For captioning, we leverage a carefully engineered prompt
to guide the Gemma 3 model, enabling it to link high-level events from the
article to the visual content in the image. Our system achieved a final score
of 0.42002, securing a top-4 position on the private test set, demonstrating
the effectiveness of combining foundation models through ensembling and
prompting. Our code is available at https://github.com/ductai05/ZSE-Cap.

</details>


### [63] [Before the Outrage: Challenges and Advances in Predicting Online Antisocial Behavior](https://arxiv.org/abs/2507.20614)
*Anaïs Ollagnier*

Main category: cs.CL

TL;DR: 本文对49项关于社会媒体上反社会行为预测的研究进行了系统综述，提出了一个结构化的分类法，并分析了不同任务的差异以及建模技术的趋势。


<details>
  <summary>Details</summary>
Motivation: 由于ASB预测领域缺乏统一的分类法或明确的方法综述，本文旨在提供一个系统的回顾，以帮助未来的研究工作。

Method: 本文对49项关于ASB预测的研究进行了系统综述，并提出了一个包含五种核心任务类型的结构化分类法。

Result: 本文分析了不同任务在时间框架、预测粒度和操作目标方面的差异，并探讨了建模技术的趋势以及数据集特征对任务可行性的影响。

Conclusion: 本文通过构建一个连贯的框架，旨在引导未来的研究朝着更稳健和具有社会责任感的ASB预测方向发展。

Abstract: Antisocial behavior (ASB) on social media-including hate speech, harassment,
and trolling-poses growing challenges for platform safety and societal
wellbeing. While prior work has primarily focused on detecting harmful content
after it appears, predictive approaches aim to forecast future harmful
behaviors-such as hate speech propagation, conversation derailment, or user
recidivism-before they fully unfold. Despite increasing interest, the field
remains fragmented, lacking a unified taxonomy or clear synthesis of existing
methods. This paper presents a systematic review of over 49 studies on ASB
prediction, offering a structured taxonomy of five core task types: early harm
detection, harm emergence prediction, harm propagation prediction, behavioral
risk prediction, and proactive moderation support. We analyze how these tasks
differ by temporal framing, prediction granularity, and operational goals. In
addition, we examine trends in modeling techniques-from classical machine
learning to pre-trained language models-and assess the influence of dataset
characteristics on task feasibility and generalization. Our review highlights
methodological challenges, such as dataset scarcity, temporal drift, and
limited benchmarks, while outlining emerging research directions including
multilingual modeling, cross-platform generalization, and human-in-the-loop
systems. By organizing the field around a coherent framework, this survey aims
to guide future work toward more robust and socially responsible ASB
prediction.

</details>


### [64] [Ontology-Enhanced Knowledge Graph Completion using Large Language Models](https://arxiv.org/abs/2507.20643)
*Wenbin Guo,Xin Wang,Jiaoyan Chen,Zhao Li,Zirui Chen*

Main category: cs.CL

TL;DR: 本文提出了一种基于LLM的本体增强KGC方法--OL-KGC，通过整合神经感知结构信息与本体知识，实现了更深入的理解和更好的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的KGC方法依赖于隐式知识表示，平行传播错误知识，从而阻碍了产生明确和决定性推理结果的能力。旨在整合神经感知结构信息与本体知识，利用LLM的强大能力以更深入地理解知识的内在逻辑。

Method: 提出了一种基于LLM的本体增强KGC方法--OL-KGC。首先利用神经感知机制将结构信息有效地嵌入到文本空间中，然后使用自动提取算法从需要完成的知识图谱（KGs）中提取本体知识，并将其转换为LLMs可理解的文本格式以提供逻辑指导。

Result: 在三个广泛使用的基准数据集FB15K-237、UMLS和WN18RR上进行了大量实验，实验结果表明OL-KGC在多个评估指标上显著优于现有主流KGC方法，达到最先进的性能。

Conclusion: OL-KGC在多个评估指标上显著优于现有的主流KGC方法，达到了最先进的性能。

Abstract: Large Language Models (LLMs) have been extensively adopted in Knowledge Graph
Completion (KGC), showcasing significant research advancements. However, as
black-box models driven by deep neural architectures, current LLM-based KGC
methods rely on implicit knowledge representation with parallel propagation of
erroneous knowledge, thereby hindering their ability to produce conclusive and
decisive reasoning outcomes. We aim to integrate neural-perceptual structural
information with ontological knowledge, leveraging the powerful capabilities of
LLMs to achieve a deeper understanding of the intrinsic logic of the knowledge.
We propose an ontology enhanced KGC method using LLMs -- OL-KGC. It first
leverages neural perceptual mechanisms to effectively embed structural
information into the textual space, and then uses an automated extraction
algorithm to retrieve ontological knowledge from the knowledge graphs (KGs)
that needs to be completed, which is further transformed into a textual format
comprehensible to LLMs for providing logic guidance. We conducted extensive
experiments on three widely-used benchmarks -- FB15K-237, UMLS and WN18RR. The
experimental results demonstrate that OL-KGC significantly outperforms existing
mainstream KGC methods across multiple evaluation metrics, achieving
state-of-the-art performance.

</details>


### [65] [Geometric-Mean Policy Optimization](https://arxiv.org/abs/2507.20673)
*Yuzhong Zhao,Yue Liu,Junpeng Liu,Jingye Chen,Xun Wu,Yaru Hao,Tengchao Lv,Shaohan Huang,Lei Cui,Qixiang Ye,Fang Wan,Furu Wei*

Main category: cs.CL

TL;DR: 本文提出了GMPO，一种改进的GRPO方法，通过最大化token级奖励的几何均值来提高稳定性，并在多个基准测试中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: GRPO在处理具有异常重要性加权奖励的tokens时存在不稳定策略更新的问题，表现为训练期间极端的重要性抽样比率。

Method: 提出了一种稳定版的GRPO，即几何均值策略优化（GMPO）。GMPO最大化token级奖励的几何均值，而不是算术均值。

Result: GMPO在理论和实验分析上都得到了验证，证明了其设计和稳定性优势。此外，GMPO-7B在多个数学和多模态推理基准测试中表现优于GRPO。

Conclusion: GMPO-7B在多个数学基准测试中平均优于GRPO 4.1%，在多模态推理基准测试中平均优于1.4%。

Abstract: Recent advancements, such as Group Relative Policy Optimization (GRPO), have
enhanced the reasoning capabilities of large language models by optimizing the
arithmetic mean of token-level rewards. However, GRPO suffers from unstable
policy updates when processing tokens with outlier importance-weighted rewards,
which manifests as extreme importance sampling ratios during training, i.e.,
the ratio between the sampling probabilities assigned to a token by the current
and old policies. In this work, we propose Geometric-Mean Policy Optimization
(GMPO), a stabilized variant of GRPO. Instead of optimizing the arithmetic
mean, GMPO maximizes the geometric mean of token-level rewards, which is
inherently less sensitive to outliers and maintains a more stable range of
importance sampling ratio. In addition, we provide comprehensive theoretical
and experimental analysis to justify the design and stability benefits of GMPO.
Beyond improved stability, GMPO-7B outperforms GRPO by an average of 4.1% on
multiple mathematical benchmarks and 1.4% on multimodal reasoning benchmark,
including AIME24, AMC, MATH500, OlympiadBench, Minerva, and Geometry3K. Code is
available at https://github.com/callsys/GMPO.

</details>


### [66] [When Scale Meets Diversity: Evaluating Language Models on Fine-Grained Multilingual Claim Verification](https://arxiv.org/abs/2507.20700)
*Hanna Shcharbakova,Tatiana Anikina,Natalia Skachkova,Josef van Genabith*

Main category: cs.CL

TL;DR: 本研究评估了五种最先进的语言模型在多语言事实验证任务中的表现，发现小型专业模型XLM-R在宏F1分数上显著优于大型语言模型，表明在细粒度多语言事实验证中，较小的模型可能更有效。


<details>
  <summary>Details</summary>
Motivation: 多语言虚假信息的快速传播需要强大的自动化事实验证系统，能够处理跨多种语言的细粒度真实性评估。虽然大型语言模型在许多自然语言处理任务中表现出色，但它们在多语言声明验证中的有效性，特别是对于细致分类方案的研究仍不足。

Method: 我们对五个最先进的语言模型在X-Fact数据集上进行了全面评估，该数据集覆盖25种语言，并有七个不同的真实性类别。实验比较了基于编码器的XLM-R和mT5等小型语言模型与最近的解码器-only LLMs（Llama 3.1、Qwen 2.5、Mistral Nemo）使用提示和微调方法的表现。

Result: XLM-R（270M参数）显著优于所有测试的LLMs（7-12B参数），在宏F1分数上达到了57.7%，而最佳LLM性能为16.9%。这比之前的最先进水平（41.9%）提高了15.8%，为多语言事实验证设定了新的性能基准。

Conclusion: 我们的研究发现，在细粒度多语言事实验证任务中，较小的专业模型可能比通用的大模型更有效，这对事实核查系统的实际部署具有重要意义。

Abstract: The rapid spread of multilingual misinformation requires robust automated
fact verification systems capable of handling fine-grained veracity assessments
across diverse languages. While large language models have shown remarkable
capabilities across many NLP tasks, their effectiveness for multilingual claim
verification with nuanced classification schemes remains understudied. We
conduct a comprehensive evaluation of five state-of-the-art language models on
the X-Fact dataset, which spans 25 languages with seven distinct veracity
categories. Our experiments compare small language models (encoder-based XLM-R
and mT5) with recent decoder-only LLMs (Llama 3.1, Qwen 2.5, Mistral Nemo)
using both prompting and fine-tuning approaches. Surprisingly, we find that
XLM-R (270M parameters) substantially outperforms all tested LLMs (7-12B
parameters), achieving 57.7% macro-F1 compared to the best LLM performance of
16.9%. This represents a 15.8% improvement over the previous state-of-the-art
(41.9%), establishing new performance benchmarks for multilingual fact
verification. Our analysis reveals problematic patterns in LLM behavior,
including systematic difficulties in leveraging evidence and pronounced biases
toward frequent categories in imbalanced data settings. These findings suggest
that for fine-grained multilingual fact verification, smaller specialized
models may be more effective than general-purpose large models, with important
implications for practical deployment of fact-checking systems.

</details>


### [67] [Text2VLM: Adapting Text-Only Datasets to Evaluate Alignment Training in Visual Language Models](https://arxiv.org/abs/2507.20704)
*Gabriel Downer,Sean Craven,Damian Ruck,Jake Thomas*

Main category: cs.CL

TL;DR: Text2VLM is a new method to evaluate the resilience of Visual Language Models (VLMs) against typographic prompt injection attacks by adapting text-only datasets into multimodal formats. It shows that open-source VLMs are more susceptible to such attacks and highlights the need for better safety mechanisms.


<details>
  <summary>Details</summary>
Motivation: The increasing integration of Visual Language Models (VLMs) into AI systems necessitates robust model alignment, especially when handling multimodal content that combines text and images. Existing evaluation datasets heavily lean towards text-only prompts, leaving visual vulnerabilities under evaluated.

Method: Text2VLM is a novel multi-stage pipeline that adapts text-only datasets into multimodal formats, specifically designed to evaluate the resilience of VLMs against typographic prompt injection attacks. It identifies harmful content in the original text and converts it into a typographic image, creating a multimodal prompt for VLMs.

Result: Our evaluation of open-source VLMs highlights their increased susceptibility to prompt injection when visual inputs are introduced, revealing critical weaknesses in the current models' alignment. This is in addition to a significant performance gap compared to closed-source frontier models. We validate Text2VLM through human evaluations, ensuring the alignment of extracted salient concepts; text summarization and output classification align with human expectations.

Conclusion: Text2VLM provides a scalable tool for comprehensive safety assessment, contributing to the development of more robust safety mechanisms for VLMs. By enhancing the evaluation of multimodal vulnerabilities, Text2VLM plays a role in advancing the safe deployment of VLMs in diverse, real-world applications.

Abstract: The increasing integration of Visual Language Models (VLMs) into AI systems
necessitates robust model alignment, especially when handling multimodal
content that combines text and images. Existing evaluation datasets heavily
lean towards text-only prompts, leaving visual vulnerabilities under evaluated.
To address this gap, we propose \textbf{Text2VLM}, a novel multi-stage pipeline
that adapts text-only datasets into multimodal formats, specifically designed
to evaluate the resilience of VLMs against typographic prompt injection
attacks. The Text2VLM pipeline identifies harmful content in the original text
and converts it into a typographic image, creating a multimodal prompt for
VLMs. Also, our evaluation of open-source VLMs highlights their increased
susceptibility to prompt injection when visual inputs are introduced, revealing
critical weaknesses in the current models' alignment. This is in addition to a
significant performance gap compared to closed-source frontier models. We
validate Text2VLM through human evaluations, ensuring the alignment of
extracted salient concepts; text summarization and output classification align
with human expectations. Text2VLM provides a scalable tool for comprehensive
safety assessment, contributing to the development of more robust safety
mechanisms for VLMs. By enhancing the evaluation of multimodal vulnerabilities,
Text2VLM plays a role in advancing the safe deployment of VLMs in diverse,
real-world applications.

</details>


### [68] [Investigating Structural Pruning and Recovery Techniques for Compressing Multimodal Large Language Models: An Empirical Study](https://arxiv.org/abs/2507.20749)
*Yiran Huang,Lukas Thede,Massimiliano Mancini,Wenjia Xu,Zeynep Akata*

Main category: cs.CL

TL;DR: 本文提出了一种直接压缩MLLMs的方法，通过结构剪枝和高效恢复训练，在计算资源有限的情况下仍能保持较高的性能。


<details>
  <summary>Details</summary>
Motivation: 当前参数减少技术主要涉及从小型语言模型（SLMs）训练MLLMs，但这些方法灵活性有限且计算密集。为了填补这一空白，我们提出直接压缩现有的MLLMs。

Method: 提出通过结构剪枝结合高效恢复训练直接压缩现有的MLLMs。研究了两种结构剪枝范式——逐层和宽度剪枝，并结合监督微调和知识蒸馏进行恢复训练。

Result: 宽度剪枝在计算资源有限或微调数据不足的低资源场景中通常保持更好的性能。在小压缩级别（<20%）下，仅微调多模态投影器就足以进行恢复训练。此外，结合监督微调和隐藏状态蒸馏在各种剪枝级别上都能实现最佳恢复。值得注意的是，只需原始训练数据的5%，就能保留超过95%的原始性能。

Conclusion: 通过在两个代表性MLLMs上的实证研究，本研究为希望在没有大量计算资源或足够数据的情况下有效压缩MLLMs的实践者提供了可行的见解。

Abstract: While Multimodal Large Language Models (MLLMs) demonstrate impressive
capabilities, their substantial computational and memory requirements pose
significant barriers to practical deployment. Current parameter reduction
techniques primarily involve training MLLMs from Small Language Models (SLMs),
but these methods offer limited flexibility and remain computationally
intensive. To address this gap, we propose to directly compress existing MLLMs
through structural pruning combined with efficient recovery training.
Specifically, we investigate two structural pruning paradigms--layerwise and
widthwise pruning--applied to the language model backbone of MLLMs, alongside
supervised finetuning and knowledge distillation. Additionally, we assess the
feasibility of conducting recovery training with only a small fraction of the
available data. Our results show that widthwise pruning generally maintains
better performance in low-resource scenarios with limited computational
resources or insufficient finetuning data. As for the recovery training,
finetuning only the multimodal projector is sufficient at small compression
levels (< 20%). Furthermore, a combination of supervised finetuning and
hidden-state distillation yields optimal recovery across various pruning
levels. Notably, effective recovery can be achieved with as little as 5% of the
original training data, while retaining over 95% of the original performance.
Through empirical study on two representative MLLMs, i.e., LLaVA-v1.5-7B and
Bunny-v1.0-3B, this study offers actionable insights for practitioners aiming
to compress MLLMs effectively without extensive computation resources or
sufficient data.

</details>


### [69] [Multilingual Self-Taught Faithfulness Evaluators](https://arxiv.org/abs/2507.20752)
*Carlo Alfano,Aymen Al Marjani,Zeno Jonke,Amin Mantrach,Saab Mansour,Marcello Federico*

Main category: cs.CL

TL;DR: 本文提出了一种多语言忠实性评估框架，该框架通过合成多语言摘要数据进行训练，并利用跨语言迁移学习来提高评估性能。实验表明，该框架在现有基线方法上有所改进。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的广泛应用，需要自动评估系统来解决信息幻觉问题。现有的忠实性评估方法主要集中在英语上，且通常需要昂贵的人工标注数据进行微调。因此，需要一种可以在多种语言中运行而无需大量标注数据的准确忠实性评估器。

Method: 本文提出了Self-Taught Evaluators for Multilingual Faithfulness框架，该框架通过合成多语言摘要数据进行训练，并利用跨语言迁移学习来提高评估性能。

Result: 实验表明，LLM的一般语言能力与其在特定语言评估任务中的表现之间存在一致的关系。本文提出的框架在现有基线方法上取得了改进，包括最先进的英语评估器和基于机器翻译的方法。

Conclusion: 本文提出了一种多语言忠实性评估框架，该框架仅从合成多语言摘要数据中学习，并利用跨语言迁移学习。实验表明，该框架在现有基线方法上有所改进，包括最先进的英语评估器和基于机器翻译的方法。

Abstract: The growing use of large language models (LLMs) has increased the need for
automatic evaluation systems, particularly to address the challenge of
information hallucination. Although existing faithfulness evaluation approaches
have shown promise, they are predominantly English-focused and often require
expensive human-labeled training data for fine-tuning specialized models. As
LLMs see increased adoption in multilingual contexts, there is a need for
accurate faithfulness evaluators that can operate across languages without
extensive labeled data. This paper presents Self-Taught Evaluators for
Multilingual Faithfulness, a framework that learns exclusively from synthetic
multilingual summarization data while leveraging cross-lingual transfer
learning. Through experiments comparing language-specific and mixed-language
fine-tuning approaches, we demonstrate a consistent relationship between an
LLM's general language capabilities and its performance in language-specific
evaluation tasks. Our framework shows improvements over existing baselines,
including state-of-the-art English evaluators and machine translation-based
approaches.

</details>


### [70] [On The Role of Pretrained Language Models in General-Purpose Text Embeddings: A Survey](https://arxiv.org/abs/2507.20783)
*Meishan Zhang,Xin Zhang,Xinping Zhao,Shouzheng Huang,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: 本文对通用文本嵌入（GPTE）进行了全面的概述，重点介绍了预训练语言模型（PLM）在其发展中的作用。我们讨论了PLMs在GPTE中的基本作用和高级作用，并提出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 文本嵌入由于在各种自然语言处理任务中的有效性而受到越来越多的关注，例如检索、分类、聚类、双语挖掘和摘要。随着预训练语言模型（PLM）的出现，通用文本嵌入（GPTE）因其能够生成丰富且可转移的表示而受到广泛关注。本文旨在提供一个全面的概述，以帮助研究人员了解GPTE的当前状态和未来潜力。

Method: 本文对GPTE进行了全面的概述，重点介绍了PLMs在其发展中的作用。首先，我们研究了基本架构并描述了PLMs在GPTE中的基本作用，即嵌入提取、表达增强、训练策略、学习目标和数据构建。然后，我们描述了由PLMs启用的高级作用，如多语言支持、多模态集成、代码理解以及场景特定适应。最后，我们强调了超越传统改进目标的潜在未来研究方向，包括排名整合、安全考虑、偏差缓解、结构信息整合和嵌入的认知扩展。

Result: 本文提供了关于GPTE的全面概述，重点介绍了PLMs在其发展中的作用。我们描述了PLMs在GPTE中的基本作用和高级作用，并强调了潜在的未来研究方向。

Conclusion: 本文旨在为新研究人员和资深研究人员提供关于GPTE当前状态和未来潜力的有价值参考。

Abstract: Text embeddings have attracted growing interest due to their effectiveness
across a wide range of natural language processing (NLP) tasks, such as
retrieval, classification, clustering, bitext mining, and summarization. With
the emergence of pretrained language models (PLMs), general-purpose text
embeddings (GPTE) have gained significant traction for their ability to produce
rich, transferable representations. The general architecture of GPTE typically
leverages PLMs to derive dense text representations, which are then optimized
through contrastive learning on large-scale pairwise datasets. In this survey,
we provide a comprehensive overview of GPTE in the era of PLMs, focusing on the
roles PLMs play in driving its development. We first examine the fundamental
architecture and describe the basic roles of PLMs in GPTE, i.e., embedding
extraction, expressivity enhancement, training strategies, learning objectives,
and data construction. Then, we describe advanced roles enabled by PLMs, such
as multilingual support, multimodal integration, code understanding, and
scenario-specific adaptation. Finally, we highlight potential future research
directions that move beyond traditional improvement goals, including ranking
integration, safety considerations, bias mitigation, structural information
incorporation, and the cognitive extension of embeddings. This survey aims to
serve as a valuable reference for both newcomers and established researchers
seeking to understand the current state and future potential of GPTE.

</details>


### [71] [Automating Thematic Review of Prevention of Future Deaths Reports: Replicating the ONS Child Suicide Study using Large Language Models](https://arxiv.org/abs/2507.20786)
*Sam Osian,Arpan Dutta,Sahil Bhandari,Iain E. Buchan,Dan W. Joyce*

Main category: cs.CL

TL;DR: 本文评估了 PFD Toolkit 是否能自动复制 ONS 对儿童自杀 PFD 报告的识别和主题分析，并验证了其在效率和可靠性方面的优势。结果表明，自动化 LLM 分析可以可靠且高效地完成手动主题审查，为公共卫生和安全提供可扩展、可重复和及时的见解。


<details>
  <summary>Details</summary>
Motivation: 之前对 PFD 报告的分析受到手动努力的限制，无法有效识别和编码相关案例。因此，需要一种自动化的方法来提高效率和可靠性。

Method: 使用 PFD Toolkit 的大型语言模型管道对 4,249 份 PFD 报告进行了处理，自动筛选出由自杀导致死亡且年龄在 18 岁或以下的案例，并对其进行了接收者类别和 23 个关注子主题的编码，以复制 ONS 的编码框架。

Result: PFD Toolkit 识别出了 72 份儿童自杀 PFD 报告，几乎是 ONS 数量的两倍。LLM 工作流与临床标注相比表现出显著到几乎完美的一致性（Cohen's κ = 0.82，95% CI: 0.66-0.98，原始一致性 = 91%）。整个脚本运行时间为 8 分 16 秒，将原本需要几个月的过程缩短到几分钟。

Conclusion: 自动化语言模型分析可以可靠且高效地复制法医数据的手动主题审查，为公共卫生和安全提供可扩展、可重复和及时的见解。PFD Toolkit 对未来研究是开放的。

Abstract: Prevention of Future Deaths (PFD) reports, issued by coroners in England and
Wales, flag systemic hazards that may lead to further loss of life. Analysis of
these reports has previously been constrained by the manual effort required to
identify and code relevant cases. In 2025, the Office for National Statistics
(ONS) published a national thematic review of child-suicide PFD reports ($\leq$
18 years), identifying 37 cases from January 2015 to November 2023 - a process
based entirely on manual curation and coding. We evaluated whether a fully
automated, open source "text-to-table" language-model pipeline (PFD Toolkit)
could reproduce the ONS's identification and thematic analysis of child-suicide
PFD reports, and assessed gains in efficiency and reliability. All 4,249 PFD
reports published from July 2013 to November 2023 were processed via PFD
Toolkit's large language model pipelines. Automated screening identified cases
where the coroner attributed death to suicide in individuals aged 18 or
younger, and eligible reports were coded for recipient category and 23 concern
sub-themes, replicating the ONS coding frame. PFD Toolkit identified 72
child-suicide PFD reports - almost twice the ONS count. Three blinded
clinicians adjudicated a stratified sample of 144 reports to validate the
child-suicide screening. Against the post-consensus clinical annotations, the
LLM-based workflow showed substantial to almost-perfect agreement (Cohen's
$\kappa$ = 0.82, 95% CI: 0.66-0.98, raw agreement = 91%). The end-to-end script
runtime was 8m 16s, transforming a process that previously took months into one
that can be completed in minutes. This demonstrates that automated LLM analysis
can reliably and efficiently replicate manual thematic reviews of coronial
data, enabling scalable, reproducible, and timely insights for public health
and safety. The PFD Toolkit is openly available for future research.

</details>


### [72] [Latent Inter-User Difference Modeling for LLM Personalization](https://arxiv.org/abs/2507.20849)
*Yilun Qiu,Tianhao Shi,Xiaoyan Zhao,Fengbin Zhu,Yang Zhang,Fuli Feng*

Main category: cs.CL

TL;DR: DEP is a framework that models inter-user differences in the latent space, leading to improved personalized outputs in review generation.


<details>
  <summary>Details</summary>
Motivation: Previous work focused on leveraging a user's own history, overlooking inter-user differences crucial for effective personalization. Recent attempts to model such differences relied on language-based prompts, which hindered the extraction of meaningful distinctions.

Method: DEP models inter-user differences in the latent space by constructing soft prompts through contrasting a user's embedding with those of peers, followed by filtering and compression using a sparse autoencoder before injecting into a frozen LLM.

Result: Experiments on personalized review generation show that DEP consistently outperforms baseline methods across multiple metrics.

Conclusion: DEP consistently outperforms baseline methods across multiple metrics in personalized review generation.

Abstract: Large language models (LLMs) are increasingly integrated into users' daily
lives, leading to a growing demand for personalized outputs. Previous work
focuses on leveraging a user's own history, overlooking inter-user differences
that are crucial for effective personalization. While recent work has attempted
to model such differences, the reliance on language-based prompts often hampers
the effective extraction of meaningful distinctions. To address these issues,
we propose Difference-aware Embedding-based Personalization (DEP), a framework
that models inter-user differences in the latent space instead of relying on
language prompts. DEP constructs soft prompts by contrasting a user's embedding
with those of peers who engaged with similar content, highlighting relative
behavioral signals. A sparse autoencoder then filters and compresses both
user-specific and difference-aware embeddings, preserving only task-relevant
features before injecting them into a frozen LLM. Experiments on personalized
review generation show that DEP consistently outperforms baseline methods
across multiple metrics. Our code is available at
https://github.com/SnowCharmQ/DEP.

</details>


### [73] [A survey of diversity quantification in natural language processing: The why, what, where and how](https://arxiv.org/abs/2507.20858)
*Louis Estève,Marie-Catherine de Marneffe,Nurit Melnik,Agata Savary,Olha Kanishcheva*

Main category: cs.CL

TL;DR: 本文调查了NLP中多样性概念的使用情况，并提出了一种统一的分类法，以更好地理解和比较不同的方法。


<details>
  <summary>Details</summary>
Motivation: 近年来，多样性在自然语言处理（NLP）中受到越来越多的关注，这是由于促进包容性、近似人类语言行为和提高系统性能等动机。然而，多样性在NLP中往往以一种随意的方式被处理，并且与其他领域中这一概念有较少的明确联系。

Method: 本文通过调查ACL Anthology过去6年中标题包含“diversity”或“diverse”的文章，提出了一个统一的分类法，用于解释NLP中多样性测量的原因、对象、地点和方法。

Result: 本文发现，在NLP中多样性被量化的方式多种多样，通常非常专门化，并使用不一致的术语。通过将多样性度量置于生态学和经济学的统一框架下，本文提出了一个统一的分类法。

Conclusion: 本文认为，这项研究为NLP中多样性概念的更好形式化铺平了道路，这将带来对该概念更好的理解以及各种方法之间的更好可比性。

Abstract: The concept of diversity has received increased consideration in Natural
Language Processing (NLP) in recent years. This is due to various motivations
like promoting and inclusion, approximating human linguistic behavior, and
increasing systems' performance. Diversity has however often been addressed in
an ad hoc manner in NLP, and with few explicit links to other domains where
this notion is better theorized. We survey articles in the ACL Anthology from
the past 6 years, with "diversity" or "diverse" in their title. We find a wide
range of settings in which diversity is quantified, often highly specialized
and using inconsistent terminology. We put forward a unified taxonomy of why,
what on, where, and how diversity is measured in NLP. Diversity measures are
cast upon a unified framework from ecology and economy (Stirling, 2007) with 3
dimensions of diversity: variety, balance and disparity. We discuss the trends
which emerge due to this systematized approach. We believe that this study
paves the way towards a better formalization of diversity in NLP, which should
bring a better understanding of this notion and a better comparability between
various approaches.

</details>


### [74] [Leveraging Open-Source Large Language Models for Clinical Information Extraction in Resource-Constrained Settings](https://arxiv.org/abs/2507.20859)
*Luc Builtjes,Joeran Bosma,Mathias Prokop,Bram van Ginneken,Alessa Hering*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Medical reports contain rich clinical information but are often unstructured
and written in domain-specific language, posing challenges for information
extraction. While proprietary large language models (LLMs) have shown promise
in clinical natural language processing, their lack of transparency and data
privacy concerns limit their utility in healthcare. This study therefore
evaluates nine open-source generative LLMs on the DRAGON benchmark, which
includes 28 clinical information extraction tasks in Dutch. We developed
\texttt{llm\_extractinator}, a publicly available framework for information
extraction using open-source generative LLMs, and used it to assess model
performance in a zero-shot setting. Several 14 billion parameter models,
Phi-4-14B, Qwen-2.5-14B, and DeepSeek-R1-14B, achieved competitive results,
while the bigger Llama-3.3-70B model achieved slightly higher performance at
greater computational cost. Translation to English prior to inference
consistently degraded performance, highlighting the need of native-language
processing. These findings demonstrate that open-source LLMs, when used with
our framework, offer effective, scalable, and privacy-conscious solutions for
clinical information extraction in low-resource settings.

</details>


### [75] [Soft Injection of Task Embeddings Outperforms Prompt-Based In-Context Learning](https://arxiv.org/abs/2507.20906)
*Jungwon Park,Wonjong Rhee*

Main category: cs.CL

TL;DR: 本文提出了一种新的任务嵌入软注入方法，该方法通过将任务条件从提示空间转移到激活空间，显著提高了任务性能并减少了计算成本。


<details>
  <summary>Details</summary>
Motivation: 尽管广泛采用，但不确定在提示中使用多个示例是否是最有效和高效的传达任务信息的方式。

Method: 我们提出了任务嵌入的软注入方法，该方法使用少量示例的ICL提示构造任务嵌入，并在推理过程中重复使用。通过预优化的混合参数（称为软头选择参数）将任务嵌入与注意力头激活进行软混合。

Result: 在57个任务和12个LLM上进行了广泛的评估，结果表明，我们的方法在平均57个任务中比10次示例ICL高出10.1%-13.9%。此外，我们的方法还揭示了注意力头在任务相关性中的角色，表明由我们的方法选择的任务相关头位置在相似任务中可以转移，但在不相似任务中不能转移。

Conclusion: 我们的方法通过将任务条件从提示空间转移到激活空间，开启了一种新的范式，以减少提示长度并提高任务性能。

Abstract: In-Context Learning (ICL) enables Large Language Models (LLMs) to perform
tasks by conditioning on input-output examples in the prompt, without requiring
any update in model parameters. While widely adopted, it remains unclear
whether prompting with multiple examples is the most effective and efficient
way to convey task information. In this work, we propose Soft Injection of task
embeddings. The task embeddings are constructed only once using few-shot ICL
prompts and repeatedly used during inference. Soft injection is performed by
softly mixing task embeddings with attention head activations using
pre-optimized mixing parameters, referred to as soft head-selection parameters.
This method not only allows a desired task to be performed without in-prompt
demonstrations but also significantly outperforms existing ICL approaches while
reducing memory usage and compute cost at inference time. An extensive
evaluation is performed across 57 tasks and 12 LLMs, spanning four model
families of sizes from 4B to 70B. Averaged across 57 tasks, our method
outperforms 10-shot ICL by 10.1%-13.9% across 12 LLMs. Additional analyses show
that our method also serves as an insightful tool for analyzing task-relevant
roles of attention heads, revealing that task-relevant head positions selected
by our method transfer across similar tasks but not across dissimilar ones --
underscoring the task-specific nature of head functionality. Our soft injection
method opens a new paradigm for reducing prompt length and improving task
performance by shifting task conditioning from the prompt space to the
activation space.

</details>


### [76] [MediQAl: A French Medical Question Answering Dataset for Knowledge and Reasoning Evaluation](https://arxiv.org/abs/2507.20917)
*Adrien Bazoge*

Main category: cs.CL

TL;DR: MediQAl是一个法语医学问答数据集，用于评估语言模型在事实性回忆和推理方面的能力，提供了重要的多语言医学资源基准。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言医学资源存在不足，因此需要一个专门针对法语医学问答的数据集来评估语言模型的能力。

Method: MediQAl数据集包含32,603个问题，来源于41个医学主题的法语医学考试，包括三种任务：单选题、多选题和开放性简答题，并对每个问题进行分类以分析模型的认知能力。

Result: 通过14个大型语言模型的广泛评估，发现事实性回忆和推理任务之间存在显著性能差距。

Conclusion: MediQAl数据集为评估语言模型在法语医学问答中的事实性回忆和推理能力提供了一个全面的基准，填补了医学领域多语言资源的重要空白。

Abstract: This work introduces MediQAl, a French medical question answering dataset
designed to evaluate the capabilities of language models in factual medical
recall and reasoning over real-world clinical scenarios. MediQAl contains
32,603 questions sourced from French medical examinations across 41 medical
subjects. The dataset includes three tasks: (i) Multiple-Choice Question with
Unique answer, (ii) Multiple-Choice Question with Multiple answer, and (iii)
Open-Ended Question with Short-Answer. Each question is labeled as
Understanding or Reasoning, enabling a detailed analysis of models' cognitive
capabilities. We validate the MediQAl dataset through extensive evaluation with
14 large language models, including recent reasoning-augmented models, and
observe a significant performance gap between factual recall and reasoning
tasks. Our evaluation provides a comprehensive benchmark for assessing language
models' performance on French medical question answering, addressing a crucial
gap in multilingual resources for the medical domain.

</details>


### [77] [FHSTP@EXIST 2025 Benchmark: Sexism Detection with Transparent Speech Concept Bottleneck Models](https://arxiv.org/abs/2507.20924)
*Roberto Labadie-Tamayo,Adrian Jaques Böck,Djordje Slijepčević,Xihui Chen,Andreas Babic,Matthias Zeppelzauer*

Main category: cs.CL

TL;DR: 本文介绍了三种用于识别和分类社交媒体文本中性别歧视的模型，并展示了它们在不同子任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 由于社交媒体和在线对话中的性别歧视现象日益严重，因此需要一种有效的方法来识别和分类这些内容。为此，本文旨在解决 EXIST 2025 挑战中的第一个任务，即识别和分类社交媒体文本中的性别歧视。

Method: 本文提出了三种模型：Speech Concept Bottleneck Model (SCBM)、Speech Concept Bottleneck Model with Transformer (SCBMT) 和微调的 XLM-RoBERTa 变体模型。SCBM 使用形容词作为可解释的瓶颈概念，SCBMT 在此基础上融合了基于形容词的表示和上下文嵌入，而 XLM-RoBERTa 则在提供的数据集上进行了微调。

Result: SCBMT 在英语和西班牙语的子任务 1.1 中分别获得第 7 名和第 6 名；XLM-RoBERTa 在英语和西班牙语的子任务 1.1 中分别获得第 6 名和第 4 名。此外，这些模型提供了细粒度的解释，包括实例级别和类别级别的解释。

Conclusion: 本文介绍了针对社交媒体文本中性别歧视识别的三种模型，并展示了它们在不同子任务上的表现。此外，还探讨了如何利用额外的元数据来提高分类效果。

Abstract: Sexism has become widespread on social media and in online conversation. To
help address this issue, the fifth Sexism Identification in Social Networks
(EXIST) challenge is initiated at CLEF 2025. Among this year's international
benchmarks, we concentrate on solving the first task aiming to identify and
classify sexism in social media textual posts. In this paper, we describe our
solutions and report results for three subtasks: Subtask 1.1 - Sexism
Identification in Tweets, Subtask 1.2 - Source Intention in Tweets, and Subtask
1.3 - Sexism Categorization in Tweets. We implement three models to address
each subtask which constitute three individual runs: Speech Concept Bottleneck
Model (SCBM), Speech Concept Bottleneck Model with Transformer (SCBMT), and a
fine-tuned XLM-RoBERTa transformer model. SCBM uses descriptive adjectives as
human-interpretable bottleneck concepts. SCBM leverages large language models
(LLMs) to encode input texts into a human-interpretable representation of
adjectives, then used to train a lightweight classifier for downstream tasks.
SCBMT extends SCBM by fusing adjective-based representation with contextual
embeddings from transformers to balance interpretability and classification
performance. Beyond competitive results, these two models offer fine-grained
explanations at both instance (local) and class (global) levels. We also
investigate how additional metadata, e.g., annotators' demographic profiles,
can be leveraged. For Subtask 1.1, XLM-RoBERTa, fine-tuned on provided data
augmented with prior datasets, ranks 6th for English and Spanish and 4th for
English in the Soft-Soft evaluation. Our SCBMT achieves 7th for English and
Spanish and 6th for Spanish.

</details>


### [78] [FRED: Financial Retrieval-Enhanced Detection and Editing of Hallucinations in Language Models](https://arxiv.org/abs/2507.20930)
*Likun Tan,Kuan-Wei Huang,Kevin Wu*

Main category: cs.CL

TL;DR: 本研究提出了一种检测和编辑大型语言模型中事实错误的方法，特别适用于金融领域。通过构建合成数据集并微调语言模型，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中的幻觉问题对需要事实可靠性的应用构成了重大挑战，特别是在高风险领域如金融中。

Method: 本研究基于提供的上下文，提出了一种检测和编辑模型生成响应中事实错误内容的有效方法。通过插入带有标记错误的财务问答语料库构建合成数据集，并微调四个语言模型（Phi-4、Phi-4-mini、Qwen3-4B 和 Qwen3-14B）以检测和编辑这些事实错误。

Result: 微调后的 Phi-4 模型在二元 F1 分数上比 OpenAI-o3 提高了 8%，整体检测性能提高了 30%。尽管只有 40 亿参数，微调后的 Phi-4-mini 模型在二元检测和整体检测方面仅比 OpenAI-o3 下降了 2% 和 0.1%。

Conclusion: 本研究提供了一种实用的解决方案，用于检测和编辑金融文本生成中的事实不一致之处，并引入了一个可推广的框架，可以增强大型语言模型在金融以外的多样化应用中的可信度和对齐性。

Abstract: Hallucinations in large language models pose a critical challenge for
applications requiring factual reliability, particularly in high-stakes domains
such as finance. This work presents an effective approach for detecting and
editing factually incorrect content in model-generated responses based on the
provided context. Given a user-defined domain-specific error taxonomy, we
construct a synthetic dataset by inserting tagged errors into financial
question-answering corpora and then fine-tune four language models, Phi-4,
Phi-4-mini, Qwen3-4B, and Qwen3-14B, to detect and edit these factual
inaccuracies. Our best-performing model, fine-tuned Phi-4, achieves an 8%
improvement in binary F1 score and a 30% gain in overall detection performance
compared to OpenAI-o3. Notably, our fine-tuned Phi-4-mini model, despite having
only 4 billion parameters, maintains competitive performance with just a 2%
drop in binary detection and a 0.1% decline in overall detection compared to
OpenAI-o3. Our work provides a practical solution for detecting and editing
factual inconsistencies in financial text generation while introducing a
generalizable framework that can enhance the trustworthiness and alignment of
large language models across diverse applications beyond finance. Our code and
data are available at https://github.com/pegasi-ai/fine-grained-editting.

</details>


### [79] [Mind the Gap: Conformative Decoding to Improve Output Diversity of Instruction-Tuned Large Language Models](https://arxiv.org/abs/2507.20956)
*Max Peeperkorn,Tom Kouwenhoven,Dan Brown,Anna Jordanous*

Main category: cs.CL

TL;DR: 本文研究了指令调优大型语言模型在叙事生成任务中的多样性差距，并提出了一种新的解码策略——符合解码，以恢复输出多样性。实验结果表明，该策略能有效增加多样性并保持或提高质量。


<details>
  <summary>Details</summary>
Motivation: 指令调优大型语言模型（LLMs）会降低输出的多样性，这对许多任务，尤其是创造性任务有影响。本文旨在研究这种“多样性差距”并探索如何恢复输出多样性。

Method: 本文研究了指令调优大型语言模型（LLMs）在写作提示叙事生成任务中的“多样性差距”，并探索了OLMo和OLMo 2模型在微调阶段的多样性损失。此外，还提出了一种新的解码策略——符合解码，以重新引入输出多样性。

Result: 实验结果表明，指令调优显著降低了多样性。DPO对多样性的影响最大。符合解码策略能够增加多样性，并且保持或提高质量。

Conclusion: 本文提出了一种新的解码策略——符合解码，可以引导指令模型使用其更丰富的基础模型来重新引入输出多样性。实验结果表明，符合解码通常会增加多样性，并且甚至可以保持或提高质量。

Abstract: Instruction-tuning large language models (LLMs) reduces the diversity of
their outputs, which has implications for many tasks, particularly for creative
tasks. This paper investigates the ``diversity gap'' for a writing prompt
narrative generation task. This gap emerges as measured by current diversity
metrics for various open-weight and open-source LLMs. The results show
significant decreases in diversity due to instruction-tuning. We explore the
diversity loss at each fine-tuning stage for the OLMo and OLMo 2 models to
further understand how output diversity is affected. The results indicate that
DPO has the most substantial impact on diversity. Motivated by these findings,
we present a new decoding strategy, conformative decoding, which guides an
instruct model using its more diverse base model to reintroduce output
diversity. We show that conformative decoding typically increases diversity and
even maintains or improves quality.

</details>


### [80] [Memorization in Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.21009)
*Danil Savine,Muni Sreenivas Pydi,Jamal Atif,Olivier Cappé*

Main category: cs.CL

TL;DR: 本研究探讨了微调大型语言模型中的记忆机制及其影响因素，特别是在医学领域。通过成员推断攻击和生成任务评估记忆情况，发现值和输出矩阵对记忆有更大影响，较低的困惑度与更多记忆相关，更高的LoRA排名会增加记忆但回报递减。这些发现有助于理解模型性能与隐私风险之间的权衡，并为开发更有效的适应策略提供指导。


<details>
  <summary>Details</summary>
Motivation: 本研究调查了微调大型语言模型（LLMs）中的记忆机制和影响因素，重点关注医学领域，因为该领域具有敏感的隐私性质。

Method: 本研究采用两种主要方法：一种是成员推断攻击，用于检测记忆数据，另一种是带有提示前缀的生成任务，用于评估逐字再现。我们分析了在变压器架构中适应不同权重矩阵的影响，困惑度与记忆之间的关系，以及增加低秩适应（LoRA）微调中的排名的影响。

Result: 关键发现包括：(1) 值和输出矩阵比查询和键矩阵对记忆的影响更大；(2) 微调模型的较低困惑度与增加的记忆相关；(3) 更高的LoRA排名会导致更多的记忆，但在更高的排名下回报会减少。

Conclusion: 这些结果提供了关于微调大型语言模型在性能和隐私风险之间权衡的见解。我们的发现对开发更有效和负责任的适应大型语言模型的策略具有重要意义，同时管理数据隐私问题。

Abstract: This study investigates the mechanisms and factors influencing memorization
in fine-tuned large language models (LLMs), with a focus on the medical domain
due to its privacy-sensitive nature. We examine how different aspects of the
fine-tuning process affect a model's propensity to memorize training data,
using the PHEE dataset of pharmacovigilance events.
  Our research employs two main approaches: a membership inference attack to
detect memorized data, and a generation task with prompted prefixes to assess
verbatim reproduction. We analyze the impact of adapting different weight
matrices in the transformer architecture, the relationship between perplexity
and memorization, and the effect of increasing the rank in low-rank adaptation
(LoRA) fine-tuning.
  Key findings include: (1) Value and Output matrices contribute more
significantly to memorization compared to Query and Key matrices; (2) Lower
perplexity in the fine-tuned model correlates with increased memorization; (3)
Higher LoRA ranks lead to increased memorization, but with diminishing returns
at higher ranks.
  These results provide insights into the trade-offs between model performance
and privacy risks in fine-tuned LLMs. Our findings have implications for
developing more effective and responsible strategies for adapting large
language models while managing data privacy concerns.

</details>


### [81] [Multi-Agent-as-Judge: Aligning LLM-Agent-Based Automated Evaluation with Multi-Dimensional Human Evaluation](https://arxiv.org/abs/2507.21028)
*Jiaju Chen,Yuxuan Lu,Xiaojie Wang,Huimin Zeng,Jing Huang,Jiri Gesi,Ying Xu,Bingsheng Yao,Dakuo Wang*

Main category: cs.CL

TL;DR: 本文提出了MAJ-EVAL框架，通过多代理辩论生成多维反馈，从而更好地模拟人类评估者。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-judge方法存在两个局限：代理的人格描述通常是任意设计的，框架不能推广到其他任务。

Method: 提出了一种多代理作为评估框架MAJ-EVAL，能够从相关文本文档中自动构建多个具有不同维度的评估者角色，实例化LLM代理，并进行小组辩论以生成多维反馈。

Result: 在教育和医学领域进行的评估实验表明，MAJ-EVAL生成的评估结果比传统自动化评估指标和现有的LLM-as-a-judge方法更符合人类专家的评分。

Conclusion: MAJ-EVAL能够生成与人类专家评分更一致的评估结果，相比传统的自动化评估指标和现有的LLM-as-a-judge方法具有优势。

Abstract: Nearly all human work is collaborative; thus, the evaluation of real-world
NLP applications often requires multiple dimensions that align with diverse
human perspectives. As real human evaluator resources are often scarce and
costly, the emerging "LLM-as-a-judge" paradigm sheds light on a promising
approach to leverage LLM agents to believably simulate human evaluators. Yet,
to date, existing LLM-as-a-judge approaches face two limitations: persona
descriptions of agents are often arbitrarily designed, and the frameworks are
not generalizable to other tasks. To address these challenges, we propose
MAJ-EVAL, a Multi-Agent-as-Judge evaluation framework that can automatically
construct multiple evaluator personas with distinct dimensions from relevant
text documents (e.g., research papers), instantiate LLM agents with the
personas, and engage in-group debates with multi-agents to Generate
multi-dimensional feedback. Our evaluation experiments in both the educational
and medical domains demonstrate that MAJ-EVAL can generate evaluation results
that better align with human experts' ratings compared with conventional
automated evaluation metrics and existing LLM-as-a-judge methods.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [82] [The Impact of Fine-tuning Large Language Models on Automated Program Repair](https://arxiv.org/abs/2507.19909)
*Roman Macháček,Anastasiia Grishina,Max Hort,Leon Moonen*

Main category: cs.SE

TL;DR: 本研究探讨了不同微调技术对用于自动化程序修复的大型语言模型性能的影响，并发现参数高效的微调方法可以取得更好的结果。


<details>
  <summary>Details</summary>
Motivation: 由于训练这些模型需要大量的资源，因此开发了微调技术来适应预训练LLM到特定任务，如APR，并以远低于从头开始训练的计算成本提高其性能。

Method: 本研究通过实验调查了各种微调技术对用于APR的LLM性能的影响。评估在三个流行的APR基准（即QuixBugs、Defects4J和HumanEval-Java）上进行，并考虑了六种不同参数大小的LLM。

Result: 全微调技术会由于不同的数据分布和过拟合而降低各种模型的基准测试性能。通过使用参数高效的微调方法，我们限制了模型的可训练参数数量并取得了更好的结果。

Conclusion: 通过使用参数高效的微调方法，我们限制了模型的可训练参数数量，并取得了更好的结果。

Abstract: Automated Program Repair (APR) uses various tools and techniques to help
developers achieve functional and error-free code faster. In recent years,
Large Language Models (LLMs) have gained popularity as components in APR tool
chains because of their performance and flexibility. However, training such
models requires a significant amount of resources. Fine-tuning techniques have
been developed to adapt pre-trained LLMs to specific tasks, such as APR, and
enhance their performance at far lower computational costs than training from
scratch. In this study, we empirically investigate the impact of various
fine-tuning techniques on the performance of LLMs used for APR. Our experiments
provide insights into the performance of a selection of state-of-the-art LLMs
pre-trained on code. The evaluation is done on three popular APR benchmarks
(i.e., QuixBugs, Defects4J and HumanEval-Java) and considers six different LLMs
with varying parameter sizes (resp. CodeGen, CodeT5, StarCoder, DeepSeekCoder,
Bloom, and CodeLlama-2). We consider three training regimens: no fine-tuning,
full fine-tuning, and parameter-efficient fine-tuning (PEFT) using LoRA and
IA3. We observe that full fine-tuning techniques decrease the benchmarking
performance of various models due to different data distributions and
overfitting. By using parameter-efficient fine-tuning methods, we restrict
models in the amount of trainable parameters and achieve better results.
  Keywords: large language models, automated program repair,
parameter-efficient fine-tuning, AI4Code, AI4SE, ML4SE.

</details>


### [83] [Enhancing Project-Specific Code Completion by Inferring Internal API Information](https://arxiv.org/abs/2507.20888)
*Le Deng,Xiaoxue Ren,Chao Ni,Ming Liang,David Lo,Zhongxin Liu*

Main category: cs.SE

TL;DR: 本文提出了一种无需依赖导入即可推断内部API信息的方法，并引入了一个新的基准ProjBench。实验结果表明，该方法在代码补全任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在处理内部API信息时存在困难，这影响了代码补全的准确性，尤其是在API未在文件中显式导入的情况下。

Method: 我们提出了一种方法来推断内部API信息，而无需依赖导入。我们的方法通过构建使用示例和语义描述来扩展API的表示，建立一个知识库，让LLMs生成相关的补全。我们还引入了ProjBench，这是一个避免泄露导入的大规模真实项目基准。

Result: 我们的方法在ProjBench和CrossCodeEval上显著优于现有方法，提升了代码精确匹配率和标识符精确匹配率。将我们的方法与现有基线结合，进一步提升了代码匹配率和标识符匹配率。

Conclusion: 我们的方法在ProjBench和CrossCodeEval上的实验表明，它显著优于现有方法，提高了代码精确匹配率22.72%，标识符精确匹配率18.31%。此外，将我们的方法与现有基线结合，可以提升代码匹配率47.80%和标识符匹配率35.55%。

Abstract: Project-specific code completion is a critical task that leverages context
from a project to generate accurate code. State-of-the-art methods use
retrieval-augmented generation (RAG) with large language models (LLMs) and
project information for code completion. However, they often struggle to
incorporate internal API information, which is crucial for accuracy, especially
when APIs are not explicitly imported in the file.
  To address this, we propose a method to infer internal API information
without relying on imports. Our method extends the representation of APIs by
constructing usage examples and semantic descriptions, building a knowledge
base for LLMs to generate relevant completions. We also introduce ProjBench, a
benchmark that avoids leaked imports and consists of large-scale real-world
projects.
  Experiments on ProjBench and CrossCodeEval show that our approach
significantly outperforms existing methods, improving code exact match by
22.72% and identifier exact match by 18.31%. Additionally, integrating our
method with existing baselines boosts code match by 47.80% and identifier match
by 35.55%.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [84] [Improving the Performance of Sequential Recommendation Systems with an Extended Large Language Model](https://arxiv.org/abs/2507.19990)
*Sinnyum Choi,Woong Kim*

Main category: cs.IR

TL;DR: 本文提出在LlamaRec框架中将Llama2替换为Llama3以改进基于LLM的推荐系统，并通过实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 最近人工智能领域的竞争加剧，导致不断推出新的大型语言模型（LLMs），这些模型表现出更好的语言理解和基于上下文的推理能力。预期这些进步将通过提高训练数据质量和架构设计来实现更高效的个性化推荐。然而，许多研究尚未考虑这些最新发展。

Method: 在LlamaRec框架中将Llama2替换为Llama3以改进基于LLM的推荐系统。

Result: 实验结果表明，在ML-100K、Beauty和Games数据集上，平均性能分别提高了38.65%、8.69%和8.19%。

Conclusion: 基于这些结果，我们认为所提出的方法是提高当前推荐系统性能的可行解决方案。

Abstract: Recently, competition in the field of artificial intelligence (AI) has
intensified among major technological companies, resulting in the continuous
release of new large-language models (LLMs) that exhibit improved language
understanding and context-based reasoning capabilities. It is expected that
these advances will enable more efficient personalized recommendations in
LLM-based recommendation systems through improved quality of training data and
architectural design. However, many studies have not considered these recent
developments. In this study, it was proposed to improve LLM-based
recommendation systems by replacing Llama2 with Llama3 in the LlamaRec
framework. To ensure a fair comparison, random seed values were set and
identical input data was provided during preprocessing and training. The
experimental results show average performance improvements of 38.65\%, 8.69\%,
and 8.19\% for the ML-100K, Beauty, and Games datasets, respectively, thus
confirming the practicality of this method. Notably, the significant
improvements achieved by model replacement indicate that the recommendation
quality can be improved cost-effectively without the need to make structural
changes to the system. Based on these results, it is our contention that the
proposed approach is a viable solution for improving the performance of current
recommendation systems.

</details>


<div id='q-fin.PM'></div>

# q-fin.PM [[Back]](#toc)

### [85] [Your AI, Not Your View: The Bias of LLMs in Investment Analysis](https://arxiv.org/abs/2507.20957)
*Hoyoung Lee,Junhyuk Seo,Suhwan Park,Junhyeong Lee,Wonbin Ahn,Chanyeol Choi,Alejandro Lopez-Lira,Yongjae Lee*

Main category: q-fin.PM

TL;DR: 本文提出了一个实验框架来研究大型语言模型（LLMs）在投资分析中的知识冲突，并首次定量分析了确认偏差。结果表明，LLMs在投资分析中表现出特定的偏好，如偏好大盘股和逆向策略，并且这些偏好往往演变为确认偏差。


<details>
  <summary>Details</summary>
Motivation: 在金融领域，由于预训练参数知识与实时市场数据之间的差异，大型语言模型（LLMs）经常面临知识冲突。当LLMs被部署在实际的投资服务中时，这种冲突尤其成问题，因为模型嵌入的偏好与金融机构的偏好不一致可能导致不可靠的建议。然而，很少有研究探讨LLMs实际上持有哪些投资观点。

Method: 我们提出了一个实验框架来研究这些冲突，并提供了对基于LLM的投资分析中确认偏差的第一个定量分析。通过假设情景，我们提取了模型的潜在偏好并测量了它们的持续性。

Result: 我们的分析揭示了在行业、规模和动量方面的不同且特定于模型的倾向。特别是，我们观察到大多数模型普遍偏好大盘股和逆向策略。这些偏好常常固化为确认偏差，模型坚持最初的判断，即使有反面证据。

Conclusion: 我们的分析揭示了LLM在投资分析中的明显且特定于模型的倾向，特别是在偏好大盘股和逆向策略方面。这些偏好往往演变为确认偏差，模型坚持最初的判断，即使有反面证据。

Abstract: In finance, Large Language Models (LLMs) face frequent knowledge conflicts
due to discrepancies between pre-trained parametric knowledge and real-time
market data. These conflicts become particularly problematic when LLMs are
deployed in real-world investment services, where misalignment between a
model's embedded preferences and those of the financial institution can lead to
unreliable recommendations. Yet little research has examined what investment
views LLMs actually hold. We propose an experimental framework to investigate
such conflicts, offering the first quantitative analysis of confirmation bias
in LLM-based investment analysis. Using hypothetical scenarios with balanced
and imbalanced arguments, we extract models' latent preferences and measure
their persistence. Focusing on sector, size, and momentum, our analysis reveals
distinct, model-specific tendencies. In particular, we observe a consistent
preference for large-cap stocks and contrarian strategies across most models.
These preferences often harden into confirmation bias, with models clinging to
initial judgments despite counter-evidence.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [86] [Does AI and Human Advice Mitigate Punishment for Selfish Behavior? An Experiment on AI ethics From a Psychological Perspective](https://arxiv.org/abs/2507.19487)
*Margarita Leib,Nils Köbis,Ivan Soraperra*

Main category: cs.CY

TL;DR: 研究显示，行为和建议内容影响惩罚，而建议来源不影响。


<details>
  <summary>Details</summary>
Motivation: 研究人们在遵循促进自私行为的AI建议时，如何被感知和惩罚。

Method: 结合社会心理学理论和机器行为及行为经济学方法，进行预注册的、有经济激励的实验。

Result: 亲社会行为受到的惩罚很少，而自私行为受到的惩罚更多。与没有建议相比，亲社会建议后自私行为受到更严厉的惩罚，而自私建议后则更宽松。此外，当决策者遵循AI建议时，他们被认为更负责任，但惩罚在两种建议来源之间没有差异。

Conclusion: 行为和建议内容影响惩罚，而建议来源不影响。

Abstract: People increasingly rely on AI-advice when making decisions. At times, such
advice can promote selfish behavior. When individuals abide by
selfishness-promoting AI advice, how are they perceived and punished? To study
this question, we build on theories from social psychology and combine
machine-behavior and behavioral economic approaches. In a pre-registered,
financially-incentivized experiment, evaluators could punish real
decision-makers who (i) received AI, human, or no advice. The advice (ii)
encouraged selfish or prosocial behavior, and decision-makers (iii) behaved
selfishly or, in a control condition, behaved prosocially. Evaluators further
assigned responsibility to decision-makers and their advisors. Results revealed
that (i) prosocial behavior was punished very little, whereas selfish behavior
was punished much more. Focusing on selfish behavior, (ii) compared to
receiving no advice, selfish behavior was penalized more harshly after
prosocial advice and more leniently after selfish advice. Lastly, (iii) whereas
selfish decision-makers were seen as more responsible when they followed AI
compared to human advice, punishment between the two advice sources did not
vary. Overall, behavior and advice content shape punishment, whereas the advice
source does not.

</details>


### [87] [The Carbon Cost of Conversation, Sustainability in the Age of Language Models](https://arxiv.org/abs/2507.20018)
*Sayed Mahbub Hasan Amiri,Prasun Goswami,Md. Mainul Islam,Mohammad Shakhawat Hossen,Sayed Majhab Hasan Amiri,Naznin Akter*

Main category: cs.CY

TL;DR: 文章分析了大型语言模型对环境的影响，包括碳足迹、用水量和电子垃圾，并提出了可持续发展的路径。


<details>
  <summary>Details</summary>
Motivation: 批判大型语言模型的可持续性，量化其对环境的影响，并提出解决方案以减少负面影响。

Method: 通过案例研究分析了GPT-4等大型语言模型以及像Mistral 7B这样的节能替代方案的碳足迹、用水量和电子垃圾贡献，并探讨了可持续自然语言处理的路径。

Result: 训练一个单一的大型语言模型可能排放相当于数百辆汽车每年行驶的二氧化碳，数据中心冷却加剧了脆弱地区的水资源短缺。

Conclusion: 文章最后呼吁将技术进步与地球边界相协调，倡导公平、透明和再生的人工智能系统，优先考虑人类和环境的福祉。

Abstract: Large language models (LLMs) like GPT-3 and BERT have revolutionized natural
language processing (NLP), yet their environmental costs remain dangerously
overlooked. This article critiques the sustainability of LLMs, quantifying
their carbon footprint, water usage, and contribution to e-waste through case
studies of models such as GPT-4 and energy-efficient alternatives like Mistral
7B. Training a single LLM can emit carbon dioxide equivalent to hundreds of
cars driven annually, while data centre cooling exacerbates water scarcity in
vulnerable regions. Systemic challenges corporate greenwashing, redundant model
development, and regulatory voids perpetuate harm, disproportionately burdening
marginalized communities in the Global South. However, pathways exist for
sustainable NLP: technical innovations (e.g., model pruning, quantum
computing), policy reforms (carbon taxes, mandatory emissions reporting), and
cultural shifts prioritizing necessity over novelty. By analysing industry
leaders (Google, Microsoft) and laggards (Amazon), this work underscores the
urgency of ethical accountability and global cooperation. Without immediate
action, AIs ecological toll risks outpacing its societal benefits. The article
concludes with a call to align technological progress with planetary
boundaries, advocating for equitable, transparent, and regenerative AI systems
that prioritize both human and environmental well-being.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [88] [Spatial Language Likelihood Grounding Network for Bayesian Fusion of Human-Robot Observations](https://arxiv.org/abs/2507.19947)
*Supawich Sitdhipol,Waritwong Sukprasongdee,Ekapol Chuangsuwanich,Rina Tse*

Main category: cs.RO

TL;DR: 本文提出了一种基于特征金字塔的似然接地网络（FP-LGN），用于实现不确定性感知的人机协作任务性能提升。


<details>
  <summary>Details</summary>
Motivation: 机器人在协作任务中需要克服感知限制，而不确定性感知的融合框架需要一个基于现实的似然函数来表示人类输入的不确定性。

Method: FP-LGN通过学习地图图像特征及其与空间关系语义的关系，来实现空间语言的接地，并使用三阶段课程学习来捕捉人类语言中的随机不确定性。

Result: FP-LGN在平均负对数似然（NLL）上与专家设计的规则相匹配，并表现出更高的鲁棒性和更低的标准差。协作感知结果表明，基于现实的似然成功地实现了异构人类语言观测和机器人传感器测量的不确定性感知融合。

Conclusion: FP-LGN成功地实现了不确定性感知的人机协作任务性能提升。

Abstract: Fusing information from human observations can help robots overcome sensing
limitations in collaborative tasks. However, an uncertainty-aware fusion
framework requires a grounded likelihood representing the uncertainty of human
inputs. This paper presents a Feature Pyramid Likelihood Grounding Network
(FP-LGN) that grounds spatial language by learning relevant map image features
and their relationships with spatial relation semantics. The model is trained
as a probability estimator to capture aleatoric uncertainty in human language
using three-stage curriculum learning. Results showed that FP-LGN matched
expert-designed rules in mean Negative Log-Likelihood (NLL) and demonstrated
greater robustness with lower standard deviation. Collaborative sensing results
demonstrated that the grounded likelihood successfully enabled
uncertainty-aware fusion of heterogeneous human language observations and robot
sensor measurements, achieving significant improvements in human-robot
collaborative task performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [89] [FedDPG: An Adaptive Yet Efficient Prompt-tuning Approach in Federated Learning Settings](https://arxiv.org/abs/2507.19534)
*Ali Shakeri,Wei Emma Zhang,Amin Beheshti,Weitong Chen,Jian Yang,Lishan Yang*

Main category: cs.LG

TL;DR: FedDPG是一种结合动态提示生成器的联邦学习方法，旨在提高模型灵活性和适应性，同时减少计算时间和参数传输量。


<details>
  <summary>Details</summary>
Motivation: 传统微调方法在利用预训练语言模型时存在显著的计算开销，而提示微调虽然效率较高，但提示对所有输入都是固定的，限制了模型的灵活性。此外，联邦学习在数据隐私方面受到关注，但客户端的通信和计算限制仍需解决。

Method: FedDPG结合了一个动态提示生成器网络，根据给定输入生成上下文感知提示，从而在保持数据隐私的同时提高模型的灵活性和适应性。

Result: FedDPG在三个NLP基准数据集上的实验表明，它在全局模型性能上优于最先进的参数高效微调方法，并显著减少了计算时间和需要通过FL网络发送的参数数量。

Conclusion: FedDPG在联邦学习环境中通过生成上下文感知提示，提高了模型的灵活性和适应性，并在全局模型性能上优于最先进的参数高效微调方法，同时显著减少了计算时间和需要通过FL网络发送的参数数量。

Abstract: Pre-trained Language Models (PLMs) have demonstrated impressive performance
in various NLP tasks. However, traditional fine-tuning methods for leveraging
PLMs for downstream tasks entail significant computational overhead.
Prompt-tuning has emerged as an efficient alternative that involves prepending
a limited number of parameters to the input sequence and only updating them
while the PLM's parameters are frozen. However, this technique's prompts remain
fixed for all inputs, reducing the model's flexibility. The Federated Learning
(FL) technique has gained attention in recent years to address the growing
concerns around data privacy. However, challenges such as communication and
computation limitations of clients still need to be addressed. To mitigate
these challenges, this paper introduces the Federated Dynamic Prompt Generator
(FedDPG), which incorporates a dynamic prompt generator network to generate
context-aware prompts based on the given input, ensuring flexibility and
adaptability while prioritising data privacy in federated learning settings.
Our experiments on three NLP benchmark datasets showcase that FedDPG
outperforms the state-of-the-art parameter-efficient fine-tuning methods in
terms of global model performance, and has significantly reduced the
calculation time and the number of parameters to be sent through the FL
network.

</details>


### [90] [Salsa as a Nonverbal Embodied Language -- The CoMPAS3D Dataset and Benchmarks](https://arxiv.org/abs/2507.19684)
*Bermet Burkanova,Payam Jome Yazdian,Chuxuan Zhang,Trinity Evans,Paige Tuttösí,Angelica Lim*

Main category: cs.LG

TL;DR: 本文提出了CoMPAS3D数据集，这是最大的和最多样化的即兴桑巴舞动作捕捉数据集，旨在作为交互式、富有表现力的人形AI的挑战性测试平台。同时，本文还发布了数据集、注释和代码，并提出了一种多任务SalsaAgent模型，能够执行所有基准任务，以鼓励研究社交互动的具身AI和创造性的、富有表现力的人形运动生成。


<details>
  <summary>Details</summary>
Motivation: 当前的AI系统在基于文本或语音的交互中表现出色，但人类交流远不止于文本，还包括身体动作、时间协调和物理协作。建模两个代理之间的耦合交互是一个巨大的挑战，因为它是连续的、双向反应的，并受到个体差异的影响。因此，本文旨在提供一个具有挑战性的测试平台，用于交互式、富有表现力的人形AI的研究。

Method: 本文提出了CoMPAS3D数据集，并将其与自然语言进行类比，评估了两个基准任务：领导或跟随生成（对应于口语和对话处理中的关键问题）以及二重奏生成。此外，本文还提出了一种多任务SalsaAgent模型，能够执行所有基准任务，并提供了其他基线以鼓励研究社交互动的具身AI和创造性、富有表现力的人形运动生成。

Result: 本文提出了CoMPAS3D数据集，包含18名不同技能水平的舞者进行的3小时即兴桑巴舞动作捕捉数据，并提供了精细的桑巴舞专家注释，覆盖了超过2,800个动作片段。此外，本文还提出了一种多任务SalsaAgent模型，能够执行所有基准任务，并提供了其他基线以鼓励研究社交互动的具身AI和创造性、富有表现力的人形运动生成。

Conclusion: 本文提出了CoMPAS3D数据集，这是最大的和最多样化的即兴桑巴舞动作捕捉数据集，旨在作为交互式、富有表现力的人形AI的挑战性测试平台。同时，本文还发布了数据集、注释和代码，并提出了一种能够执行所有基准任务的多任务SalsaAgent模型，以鼓励研究社交互动的具身AI和创造性的、富有表现力的人形运动生成。

Abstract: Imagine a humanoid that can safely and creatively dance with a human,
adapting to its partner's proficiency, using haptic signaling as a primary form
of communication. While today's AI systems excel at text or voice-based
interaction with large language models, human communication extends far beyond
text-it includes embodied movement, timing, and physical coordination. Modeling
coupled interaction between two agents poses a formidable challenge: it is
continuous, bidirectionally reactive, and shaped by individual variation. We
present CoMPAS3D, the largest and most diverse motion capture dataset of
improvised salsa dancing, designed as a challenging testbed for interactive,
expressive humanoid AI. The dataset includes 3 hours of leader-follower salsa
dances performed by 18 dancers spanning beginner, intermediate, and
professional skill levels. For the first time, we provide fine-grained salsa
expert annotations, covering over 2,800 move segments, including move types,
combinations, execution errors and stylistic elements. We draw analogies
between partner dance communication and natural language, evaluating CoMPAS3D
on two benchmark tasks for synthetic humans that parallel key problems in
spoken language and dialogue processing: leader or follower generation with
proficiency levels (speaker or listener synthesis), and duet (conversation)
generation. Towards a long-term goal of partner dance with humans, we release
the dataset, annotations, and code, along with a multitask SalsaAgent model
capable of performing all benchmark tasks, alongside additional baselines to
encourage research in socially interactive embodied AI and creative, expressive
humanoid motion generation.

</details>


### [91] [Agentic Reinforced Policy Optimization](https://arxiv.org/abs/2507.19849)
*Guanting Dong,Hangyu Mao,Kai Ma,Licheng Bao,Yifei Chen,Zhongyuan Wang,Zhongxia Chen,Jiazhen Du,Huiyang Wang,Fuzheng Zhang,Guorui Zhou,Yutao Zhu,Ji-Rong Wen,Zhicheng Dou*

Main category: cs.LG

TL;DR: ARPO is a new RL algorithm that improves the performance of LLM-based agents in multi-turn tool interactions by balancing exploration and stepwise advantage differences.


<details>
  <summary>Details</summary>
Motivation: Current RL algorithms inadequately balance the models' intrinsic long-horizon reasoning capabilities and their proficiency in multi-turn tool interactions.

Method: We propose Agentic Reinforced Policy Optimization (ARPO), a novel agentic RL algorithm tailored for training multi-turn LLM-based agents. ARPO incorporates an entropy-based adaptive rollout mechanism and integrates an advantage attribution estimation.

Result: Our experiments across 13 challenging benchmarks in computational reasoning, knowledge reasoning, and deep search domains demonstrate ARPO's superiority over trajectory-level RL algorithms.

Conclusion: ARPO achieves improved performance using only half of the tool-use budget required by existing methods, offering a scalable solution for aligning LLM-based agents with real-time dynamic environments.

Abstract: Large-scale reinforcement learning with verifiable rewards (RLVR) has
demonstrated its effectiveness in harnessing the potential of large language
models (LLMs) for single-turn reasoning tasks. In realistic reasoning
scenarios, LLMs can often utilize external tools to assist in task-solving
processes. However, current RL algorithms inadequately balance the models'
intrinsic long-horizon reasoning capabilities and their proficiency in
multi-turn tool interactions. To bridge this gap, we propose Agentic Reinforced
Policy Optimization (ARPO), a novel agentic RL algorithm tailored for training
multi-turn LLM-based agents. Through preliminary experiments, we observe that
LLMs tend to exhibit highly uncertain behavior, characterized by an increase in
the entropy distribution of generated tokens, immediately following
interactions with external tools. Motivated by this observation, ARPO
incorporates an entropy-based adaptive rollout mechanism, dynamically balancing
global trajectory sampling and step-level sampling, thereby promoting
exploration at steps with high uncertainty after tool usage. By integrating an
advantage attribution estimation, ARPO enables LLMs to internalize advantage
differences in stepwise tool-use interactions. Our experiments across 13
challenging benchmarks in computational reasoning, knowledge reasoning, and
deep search domains demonstrate ARPO's superiority over trajectory-level RL
algorithms. Remarkably, ARPO achieves improved performance using only half of
the tool-use budget required by existing methods, offering a scalable solution
for aligning LLM-based agents with real-time dynamic environments. Our code and
datasets are released at https://github.com/dongguanting/ARPO

</details>


### [92] [$K^4$: Online Log Anomaly Detection Via Unsupervised Typicality Learning](https://arxiv.org/abs/2507.20051)
*Weicong Chen,Vikash Singh,Zahra Rahmani,Debargha Ganguly,Mohsen Hariri,Vipin Chaudhary*

Main category: cs.LG

TL;DR: K^4 是一种无监督且与解析器无关的框架，用于高性能在线检测，通过四维描述符实现快速准确的异常检测。


<details>
  <summary>Details</summary>
Motivation: 现有的日志异常检测方法通常速度慢、依赖易出错的解析，并使用不现实的评估协议。

Method: K^4 使用高效的k近邻(k-NN)统计方法将任意日志嵌入转换为紧凑的四维描述符（精度、召回率、密度、覆盖率），从而实现轻量级异常检测器的准确评分。

Result: K^4 在AUROC指标上达到了0.995-0.999的新最先进的性能，比基线方法有显著提升，同时训练时间不到4秒，推理时间低至4微秒。

Conclusion: K^4 在在线评估协议中表现优异，具有高检测性能和快速的训练和推理速度。

Abstract: Existing Log Anomaly Detection (LogAD) methods are often slow, dependent on
error-prone parsing, and use unrealistic evaluation protocols. We introduce
$K^4$, an unsupervised and parser-independent framework for high-performance
online detection. $K^4$ transforms arbitrary log embeddings into compact
four-dimensional descriptors (Precision, Recall, Density, Coverage) using
efficient k-nearest neighbor (k-NN) statistics. These descriptors enable
lightweight detectors to accurately score anomalies without retraining. Using a
more realistic online evaluation protocol, $K^4$ sets a new state-of-the-art
(AUROC: 0.995-0.999), outperforming baselines by large margins while being
orders of magnitude faster, with training under 4 seconds and inference as low
as 4 $\mu$s.

</details>


### [93] [EcoTransformer: Attention without Multiplication](https://arxiv.org/abs/2507.20096)
*Xin Gao,Xingming Xu*

Main category: cs.LG

TL;DR: EcoTransformer是一种新的Transformer架构，通过使用拉普拉斯核和L1度量来构建输出上下文向量，从而减少了计算和能耗，同时保持了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer架构由于其缩放点积注意力机制而计算密集且能耗高，因此需要一种更节能的替代方案。

Method: 提出了一种新的Transformer架构EcoTransformer，其中输出上下文向量是通过使用拉普拉斯核对值进行卷积构建的，距离由查询和键之间的L1度量测量。

Result: EcoTransformer在NLP、生物信息学和视觉任务中表现与或优于基于点积的注意力机制，同时消耗显著更少的能量。

Conclusion: EcoTransformer在NLP、生物信息学和视觉任务中表现与或优于基于点积的注意力机制，同时消耗显著更少的能量。

Abstract: The Transformer, with its scaled dot-product attention mechanism, has become
a foundational architecture in modern AI. However, this mechanism is
computationally intensive and incurs substantial energy costs. We propose a new
Transformer architecture EcoTransformer, in which the output context vector is
constructed as the convolution of the values using a Laplacian kernel, where
the distances are measured by the L1 metric between the queries and keys.
Compared to dot-product based attention, the new attention score calculation is
free of matrix multiplication. It performs on par with, or even surpasses,
scaled dot-product attention in NLP, bioinformatics, and vision tasks, while
consuming significantly less energy.

</details>


### [94] [Customize Multi-modal RAI Guardrails with Precedent-based predictions](https://arxiv.org/abs/2507.20503)
*Cheng-Fu Yang,Thanh Tran,Christos Christodoulopoulos,Weitong Ruan,Rahul Gupta,Kai-Wei Chang*

Main category: cs.LG

TL;DR: 本文提出了一种基于先例的多模态护栏方法，以提高其灵活性和适应性，并通过实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的微调方法通常依赖于预定义的政策，限制了其对新政策的泛化能力或需要大量重新训练。而训练-free 方法则受限于有限的上下文长度，难以全面纳入所有政策。

Method: 我们提出了一种基于“先例”的方法，通过利用与给定输入类似的先前数据点的推理过程来判断模型。我们引入了一种批判-修正机制来收集高质量的先例，并提出了两种利用先例进行鲁棒预测的策略。

Result: 实验结果表明，我们的方法在少样本和全数据集场景中都优于之前的方法，并且在新政策的泛化方面表现出色。

Conclusion: 我们的方法在少样本和全数据集场景中都优于之前的方法，并且在新政策的泛化方面表现出色。

Abstract: A multi-modal guardrail must effectively filter image content based on
user-defined policies, identifying material that may be hateful, reinforce
harmful stereotypes, contain explicit material, or spread misinformation.
Deploying such guardrails in real-world applications, however, poses
significant challenges. Users often require varied and highly customizable
policies and typically cannot provide abundant examples for each custom policy.
Consequently, an ideal guardrail should be scalable to the multiple policies
and adaptable to evolving user standards with minimal retraining. Existing
fine-tuning methods typically condition predictions on pre-defined policies,
restricting their generalizability to new policies or necessitating extensive
retraining to adapt. Conversely, training-free methods struggle with limited
context lengths, making it difficult to incorporate all the policies
comprehensively. To overcome these limitations, we propose to condition model's
judgment on "precedents", which are the reasoning processes of prior data
points similar to the given input. By leveraging precedents instead of fixed
policies, our approach greatly enhances the flexibility and adaptability of the
guardrail. In this paper, we introduce a critique-revise mechanism for
collecting high-quality precedents and two strategies that utilize precedents
for robust prediction. Experimental results demonstrate that our approach
outperforms previous methods across both few-shot and full-dataset scenarios
and exhibits superior generalization to novel policies.

</details>


### [95] [Kimi K2: Open Agentic Intelligence](https://arxiv.org/abs/2507.20534)
*Kimi Team,Yifan Bai,Yiping Bao,Guanduo Chen,Jiahao Chen,Ningxin Chen,Ruijue Chen,Yanru Chen,Yuankun Chen,Yutian Chen,Zhuofu Chen,Jialei Cui,Hao Ding,Mengnan Dong,Angang Du,Chenzhuang Du,Dikang Du,Yulun Du,Yu Fan,Yichen Feng,Kelin Fu,Bofei Gao,Hongcheng Gao,Peizhong Gao,Tong Gao,Xinran Gu,Longyu Guan,Haiqing Guo,Jianhang Guo,Hao Hu,Xiaoru Hao,Tianhong He,Weiran He,Wenyang He,Chao Hong,Yangyang Hu,Zhenxing Hu,Weixiao Huang,Zhiqi Huang,Zihao Huang,Tao Jiang,Zhejun Jiang,Xinyi Jin,Yongsheng Kang,Guokun Lai,Cheng Li,Fang Li,Haoyang Li,Ming Li,Wentao Li,Yanhao Li,Yiwei Li,Zhaowei Li,Zheming Li,Hongzhan Lin,Xiaohan Lin,Zongyu Lin,Chengyin Liu,Chenyu Liu,Hongzhang Liu,Jingyuan Liu,Junqi Liu,Liang Liu,Shaowei Liu,T. Y. Liu,Tianwei Liu,Weizhou Liu,Yangyang Liu,Yibo Liu,Yiping Liu,Yue Liu,Zhengying Liu,Enzhe Lu,Lijun Lu,Shengling Ma,Xinyu Ma,Yingwei Ma,Shaoguang Mao,Jie Mei,Xin Men,Yibo Miao,Siyuan Pan,Yebo Peng,Ruoyu Qin,Bowen Qu,Zeyu Shang,Lidong Shi,Shengyuan Shi,Feifan Song,Jianlin Su,Zhengyuan Su,Xinjie Sun,Flood Sung,Heyi Tang,Jiawen Tao,Qifeng Teng,Chensi Wang,Dinglu Wang,Feng Wang,Haiming Wang,Jianzhou Wang,Jiaxing Wang,Jinhong Wang,Shengjie Wang,Shuyi Wang,Yao Wang,Yejie Wang,Yiqin Wang,Yuxin Wang,Yuzhi Wang,Zhaoji Wang,Zhengtao Wang,Zhexu Wang,Chu Wei,Qianqian Wei,Wenhao Wu,Xingzhe Wu,Yuxin Wu,Chenjun Xiao,Xiaotong Xie,Weimin Xiong,Boyu Xu,Jing Xu,Jinjing Xu,L. H. Xu,Lin Xu,Suting Xu,Weixin Xu,Xinran Xu,Yangchuan Xu,Ziyao Xu,Junjie Yan,Yuzi Yan,Xiaofei Yang,Ying Yang,Zhen Yang,Zhilin Yang,Zonghan Yang,Haotian Yao,Xingcheng Yao,Wenjie Ye,Zhuorui Ye,Bohong Yin,Longhui Yu,Enming Yuan,Hongbang Yuan,Mengjie Yuan,Haobing Zhan,Dehao Zhang,Hao Zhang,Wanlu Zhang,Xiaobin Zhang,Yangkun Zhang,Yizhi Zhang,Yongting Zhang,Yu Zhang,Yutao Zhang,Yutong Zhang,Zheng Zhang,Haotian Zhao,Yikai Zhao,Huabin Zheng,Shaojie Zheng,Jianren Zhou,Xinyu Zhou,Zaida Zhou,Zhen Zhu,Weiyu Zhuang,Xinxing Zu*

Main category: cs.LG

TL;DR: Kimi K2 是一个具有 320 亿激活参数和 1 万亿总参数的混合专家 (MoE) 大型语言模型。提出了 MuonClip 优化器，改进了 Muon 并采用了一种新颖的 QK-clip 技术来解决训练不稳定问题，同时享受 Muon 的先进标记效率。基于 MuonClip，K2 在 15.5 万亿个标记上进行了预训练，没有损失尖峰。在后训练过程中，K2 经历了一个多阶段的后训练过程，其中突出显示了一个大规模的代理数据合成管道和一个联合强化学习 (RL) 阶段，其中模型通过与真实和合成环境的互动来提高其能力。Kimi K2 在 Tau2-Bench 上获得 66.1，在 ACEBench (En) 上获得 76.5，在 SWE-Bench Verified 上获得 65.8，在 SWE-Bench Multilingual 上获得 47.3，超过了大多数开源和闭源基线。它在编程、数学和推理任务中也表现出色，在 LiveCodeBench v6 上获得 53.7，在 AIME 2025 上获得 49.5，在 GPQA-Diamond 上获得 75.1，在 OJBench 上获得 27.1，所有这些都没有扩展思维。


<details>
  <summary>Details</summary>
Motivation: Kimi K2 的目标是实现最先进的性能，在开源非思考模型中表现优异，并在代理能力方面表现出色。

Method: Kimi K2 是一个具有 320 亿激活参数和 1 万亿总参数的混合专家 (MoE) 大型语言模型。提出了 MuonClip 优化器，改进了 Muon 并采用了一种新颖的 QK-clip 技术来解决训练不稳定问题，同时享受 Muon 的先进标记效率。基于 MuonClip，K2 在 15.5 万亿个标记上进行了预训练，没有损失尖峰。在后训练过程中，K2 经历了一个多阶段的后训练过程，其中突出显示了一个大规模的代理数据合成管道和一个联合强化学习 (RL) 阶段，其中模型通过与真实和合成环境的互动来提高其能力。

Result: Kimi K2 在 Tau2-Bench 上获得 66.1，在 ACEBench (En) 上获得 76.5，在 SWE-Bench Verified 上获得 65.8，在 SWE-Bench Multilingual 上获得 47.3，超过了大多数开源和闭源基线。它在编程、数学和推理任务中也表现出色，在 LiveCodeBench v6 上获得 53.7，在 AIME 2025 上获得 49.5，在 GPQA-Diamond 上获得 75.1，在 OJBench 上获得 27.1，所有这些都没有扩展思维。

Conclusion: Kimi K2 是目前最强大的开源大型语言模型之一，尤其在软件工程和代理任务中表现出色。

Abstract: We introduce Kimi K2, a Mixture-of-Experts (MoE) large language model with 32
billion activated parameters and 1 trillion total parameters. We propose the
MuonClip optimizer, which improves upon Muon with a novel QK-clip technique to
address training instability while enjoying the advanced token efficiency of
Muon. Based on MuonClip, K2 was pre-trained on 15.5 trillion tokens with zero
loss spike. During post-training, K2 undergoes a multi-stage post-training
process, highlighted by a large-scale agentic data synthesis pipeline and a
joint reinforcement learning (RL) stage, where the model improves its
capabilities through interactions with real and synthetic environments.
  Kimi K2 achieves state-of-the-art performance among open-source non-thinking
models, with strengths in agentic capabilities. Notably, K2 obtains 66.1 on
Tau2-Bench, 76.5 on ACEBench (En), 65.8 on SWE-Bench Verified, and 47.3 on
SWE-Bench Multilingual -- surpassing most open and closed-sourced baselines in
non-thinking settings. It also exhibits strong capabilities in coding,
mathematics, and reasoning tasks, with a score of 53.7 on LiveCodeBench v6,
49.5 on AIME 2025, 75.1 on GPQA-Diamond, and 27.1 on OJBench, all without
extended thinking. These results position Kimi K2 as one of the most capable
open-source large language models to date, particularly in software engineering
and agentic tasks. We release our base and post-trained model checkpoints to
facilitate future research and applications of agentic intelligence.

</details>


### [96] [Dissecting Persona-Driven Reasoning in Language Models via Activation Patching](https://arxiv.org/abs/2507.20936)
*Ansh Poonia,Maeghal Jain*

Main category: cs.LG

TL;DR: 研究分析了角色分配如何影响大型语言模型在客观任务上的推理，并通过激活补丁技术揭示了模型中编码角色特定信息的关键组件。


<details>
  <summary>Details</summary>
Motivation: 研究角色分配如何影响模型在客观任务上的推理。

Method: 使用激活补丁，研究了角色如何影响模型在客观任务上的推理。

Result: 早期MLP层不仅关注输入的语法结构，还处理其语义内容。这些层将角色标记转换为更丰富的表示，然后由中间多头注意力（MHA）层用于塑造模型的输出。此外，研究还识别出特定的关注头，它们不成比例地关注种族和颜色身份。

Conclusion: 研究发现，早期MLP层不仅关注输入的语法结构，还处理其语义内容。这些层将角色标记转换为更丰富的表示，然后由中间多头注意力（MHA）层用于塑造模型的输出。此外，研究还识别出特定的关注头，它们不成比例地关注种族和颜色身份。

Abstract: Large language models (LLMs) exhibit remarkable versatility in adopting
diverse personas. In this study, we examine how assigning a persona influences
a model's reasoning on an objective task. Using activation patching, we take a
first step toward understanding how key components of the model encode
persona-specific information. Our findings reveal that the early Multi-Layer
Perceptron (MLP) layers attend not only to the syntactic structure of the input
but also process its semantic content. These layers transform persona tokens
into richer representations, which are then used by the middle Multi-Head
Attention (MHA) layers to shape the model's output. Additionally, we identify
specific attention heads that disproportionately attend to racial and
color-based identities.

</details>


### [97] [LoRA-PAR: A Flexible Dual-System LoRA Partitioning Approach to Efficient LLM Fine-Tuning](https://arxiv.org/abs/2507.20999)
*Yining Huang,Bin Li,Keke Tang,Meilian Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于双系统思维模式的LoRA-PAR框架，通过划分数据和参数并采用两阶段微调策略，在降低参数使用量的同时提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注领域适应或层分配，而不是明确地根据不同的响应需求调整数据和参数。受“思考，快与慢”中两种思维模式的启发，提出一种新的方法来优化参数分配。

Method: 提出了一种双系统LoRA框架LoRA-PAR，将数据和参数按System 1或System 2需求进行划分，并采用两阶段微调策略：用SFT训练System 1任务以增强知识和直觉，用RL训练System 2任务以强化更深层次的逻辑推理。

Result: 两阶段微调策略降低了活动参数使用量，同时在性能上达到或超过了最先进的PEFT基线。

Conclusion: 实验表明，两阶段微调策略（SFT和RL）在降低活动参数使用的同时，能够匹配或超越现有的PEFT基线。

Abstract: Large-scale generative models like DeepSeek-R1 and OpenAI-O1 benefit
substantially from chain-of-thought (CoT) reasoning, yet pushing their
performance typically requires vast data, large model sizes, and full-parameter
fine-tuning. While parameter-efficient fine-tuning (PEFT) helps reduce cost,
most existing approaches primarily address domain adaptation or layer-wise
allocation rather than explicitly tailoring data and parameters to different
response demands. Inspired by "Thinking, Fast and Slow," which characterizes
two distinct modes of thought-System 1 (fast, intuitive, often automatic) and
System 2 (slower, more deliberative and analytic)-we draw an analogy that
different "subregions" of an LLM's parameters might similarly specialize for
tasks that demand quick, intuitive responses versus those requiring multi-step
logical reasoning. Therefore, we propose LoRA-PAR, a dual-system LoRA framework
that partitions both data and parameters by System 1 or System 2 demands, using
fewer yet more focused parameters for each task. Specifically, we classify task
data via multi-model role-playing and voting, and partition parameters based on
importance scoring, then adopt a two-stage fine-tuning strategy of training
System 1 tasks with supervised fine-tuning (SFT) to enhance knowledge and
intuition and refine System 2 tasks with reinforcement learning (RL) to
reinforce deeper logical deliberation next. Extensive experiments show that the
two-stage fine-tuning strategy, SFT and RL, lowers active parameter usage while
matching or surpassing SOTA PEFT baselines.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [98] [AutoSign: Direct Pose-to-Text Translation for Continuous Sign Language Recognition](https://arxiv.org/abs/2507.19840)
*Samuel Ebimobowei Johnny,Blessed Guda,Andrew Blayama Stephen,Assane Gueye*

Main category: cs.CV

TL;DR: AutoSign是一种新的连续手语识别方法，通过使用自回归解码器和预训练模型，直接将姿态序列转换为自然语言文本，避免了传统对齐机制，并在数据集上取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的连续手语识别（CSLR）方法依赖于多阶段流水线，这导致了错误传播、过拟合和词汇可扩展性问题。因此，需要一种更有效的方法来解决这些问题。

Method: AutoSign是一种仅解码器的自回归Transformer，可以直接将姿态序列转换为自然语言文本，绕过传统的对齐机制。它结合了使用1D CNNs的时序压缩模块和预训练的阿拉伯语解码器AraGPT2来生成文本（glosses）。

Result: 通过全面的消融研究，我们证明了手部和身体动作提供了最具区分性的特征，用于独立于签名者的CSLR。AutoSign在Isharah-1000数据集上实现了显著的改进，WER分数提高了高达6.1%。

Conclusion: AutoSign通过消除多阶段管道，在Isharah-1000数据集上实现了显著的改进，与最佳现有方法相比，WER分数提高了高达6.1%。

Abstract: Continuously recognizing sign gestures and converting them to glosses plays a
key role in bridging the gap between the hearing and hearing-impaired
communities. This involves recognizing and interpreting the hands, face, and
body gestures of the signer, which pose a challenge as it involves a
combination of all these features. Continuous Sign Language Recognition (CSLR)
methods rely on multi-stage pipelines that first extract visual features, then
align variable-length sequences with target glosses using CTC or HMM-based
approaches. However, these alignment-based methods suffer from error
propagation across stages, overfitting, and struggle with vocabulary
scalability due to the intermediate gloss representation bottleneck. To address
these limitations, we propose AutoSign, an autoregressive decoder-only
transformer that directly translates pose sequences to natural language text,
bypassing traditional alignment mechanisms entirely. The use of this
decoder-only approach allows the model to directly map between the features and
the glosses without the need for CTC loss while also directly learning the
textual dependencies in the glosses. Our approach incorporates a temporal
compression module using 1D CNNs to efficiently process pose sequences,
followed by AraGPT2, a pre-trained Arabic decoder, to generate text (glosses).
Through comprehensive ablation studies, we demonstrate that hand and body
gestures provide the most discriminative features for signer-independent CSLR.
By eliminating the multi-stage pipeline, AutoSign achieves substantial
improvements on the Isharah-1000 dataset, achieving an improvement of up to
6.1\% in WER score compared to the best existing method.

</details>


### [99] [The Devil is in the EOS: Sequence Training for Detailed Image Captioning](https://arxiv.org/abs/2507.20077)
*Abdelrahman Mohamed,Yova Kementchedjhieva*

Main category: cs.CV

TL;DR: 本文提出了一种无监督方法，以减少视觉-语言模型在生成图像描述时过早预测结束序列标记的倾向，从而生成更长、更详细的描述。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言模型（VLMs）取得了重大进展，但图像描述仍然缺乏细节，基础模型生成的描述较短且通用。这种限制即使在VLMs配备了强大的视觉和语言骨干网络的情况下仍然存在。虽然已经提出了监督数据和复杂奖励函数来改进详细图像描述，但我们发现了一个更简单的根本问题：在交叉熵训练期间引入的对结束序列（EOS）标记的偏见。

Method: 我们提出了一种无监督的方法来消除模型过早预测结束序列（EOS）标记的倾向。通过减少这种偏差，我们鼓励生成更长、更详细的描述，而无需复杂的奖励函数或监督。

Result: 我们的实验表明，生成的描述长度和相关细节有显著增加，尽管预期会增加幻觉率。

Conclusion: 我们的方法简单有效，可以应用于任何预训练模型，并在三个VLM和三个详细描述基准测试中展示了其有效性。结果表明，生成的句子长度和相关细节有显著增加，尽管预期会增加幻觉率。

Abstract: Despite significant advances in vision-language models (VLMs), image
captioning often suffers from a lack of detail, with base models producing
short, generic captions. This limitation persists even though VLMs are equipped
with strong vision and language backbones. While supervised data and complex
reward functions have been proposed to improve detailed image captioning, we
identify a simpler underlying issue: a bias towards the end-of-sequence (EOS)
token, which is introduced during cross-entropy training. We propose an
unsupervised method to debias the model's tendency to predict the EOS token
prematurely. By reducing this bias, we encourage the generation of longer, more
detailed captions without the need for intricate reward functions or
supervision. Our approach is straightforward, effective, and easily applicable
to any pretrained model. We demonstrate its effectiveness through experiments
with three VLMs and on three detailed captioning benchmarks. Our results show a
substantial increase in caption length and relevant details, albeit with an
expected increase in the rate of hallucinations.

</details>


### [100] [The Importance of Facial Features in Vision-based Sign Language Recognition: Eyes, Mouth or Full Face?](https://arxiv.org/abs/2507.20884)
*Dinh Nam Pham,Eleftherios Avramidis*

Main category: cs.CV

TL;DR: 本研究系统地分析了非手动面部特征在自动手语识别中的作用，发现嘴巴是最重要的面部特征，能够显著提高识别准确率。


<details>
  <summary>Details</summary>
Motivation: 非手动面部特征在手语交流中起着至关重要的作用，但在自动手语识别（ASLR）中的重要性尚未得到充分探索。尽管以前的研究表明结合面部特征可以提高识别效果，但相关工作通常依赖于手工特征提取，并未能超越对手工特征与面部特征组合的比较。

Method: 我们使用两种不同的深度学习模型（基于CNN的模型和基于Transformer的模型）系统地研究了不同面部区域（眼睛、嘴巴和整个面部）的贡献，并在随机选择类别的孤立手势数据集上进行训练。

Result: 通过定量性能和定性显著性图评估，我们发现嘴巴是最重要的非手动面部特征，显著提高了准确率。

Conclusion: 我们的研究结果强调了在自动手语识别中纳入面部特征的必要性。

Abstract: Non-manual facial features play a crucial role in sign language
communication, yet their importance in automatic sign language recognition
(ASLR) remains underexplored. While prior studies have shown that incorporating
facial features can improve recognition, related work often relies on
hand-crafted feature extraction and fails to go beyond the comparison of manual
features versus the combination of manual and facial features. In this work, we
systematically investigate the contribution of distinct facial regionseyes,
mouth, and full faceusing two different deep learning models (a CNN-based model
and a transformer-based model) trained on an SLR dataset of isolated signs with
randomly selected classes. Through quantitative performance and qualitative
saliency map evaluation, we reveal that the mouth is the most important
non-manual facial feature, significantly improving accuracy. Our findings
highlight the necessity of incorporating facial features in ASLR.

</details>


### [101] [$A^2R^2$: Advancing Img2LaTeX Conversion via Visual Reasoning with Attention-Guided Refinement](https://arxiv.org/abs/2507.20890)
*Zhecheng Li,Guoxian Song,Yiwei Wang,Zhen Xiong,Junsong Yuan,Yujun Cai*

Main category: cs.CV

TL;DR: A^2R^2 是一种用于Img2LaTeX任务的框架，通过注意力引导的细化和视觉推理来提高LaTeX代码的准确性。


<details>
  <summary>Details</summary>
Motivation: 由于VLMs在处理细粒度视觉元素时表现不佳，导致LaTeX预测不准确，因此需要一种更有效的解决方案。

Method: A^2R^2 框架结合了注意力定位和迭代细化，使VLMs能够进行自我修正并逐步提高预测质量。

Result: A^2R^2 在六个评估指标上显著提升模型性能，并且增加推理轮次能进一步提高性能。

Conclusion: A^2R^2 显著提升了模型在Img2LaTeX任务上的性能，并通过实验验证了其有效性。

Abstract: Img2LaTeX is a practically significant task that involves converting
mathematical expressions or tabular data from images into LaTeX code. In recent
years, vision-language models (VLMs) have demonstrated strong performance
across a variety of visual understanding tasks, owing to their generalization
capabilities. While some studies have explored the use of VLMs for the
Img2LaTeX task, their performance often falls short of expectations.
Empirically, VLMs sometimes struggle with fine-grained visual elements, leading
to inaccurate LaTeX predictions. To address this challenge, we propose
$A^2R^2$: Advancing Img2LaTeX Conversion via Visual Reasoning with
Attention-Guided Refinement, a framework that effectively integrates attention
localization and iterative refinement within a visual reasoning framework,
enabling VLMs to perform self-correction and progressively improve prediction
quality. For effective evaluation, we introduce a new dataset,
Img2LaTex-Hard-1K, consisting of 1,100 carefully curated and challenging
examples designed to rigorously evaluate the capabilities of VLMs within this
task domain. Extensive experimental results demonstrate that: (1) $A^2R^2$
significantly improves model performance across six evaluation metrics spanning
both textual and visual levels, consistently outperforming other baseline
methods; (2) Increasing the number of inference rounds yields notable
performance gains, underscoring the potential of $A^2R^2$ in test-time scaling
scenarios; (3) Ablation studies and human evaluations validate the practical
effectiveness of our approach, as well as the strong synergy among its core
components during inference.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [102] [Leveraging Fine-Tuned Large Language Models for Interpretable Pancreatic Cystic Lesion Feature Extraction and Risk Categorization](https://arxiv.org/abs/2507.19973)
*Ebrahim Rasromani,Stella K. Kang,Yanqi Xu,Beisong Liu,Garvit Luhadia,Wan Fung Chui,Felicia L. Pasadyn,Yu Chih Hung,Julie Y. An,Edwin Mathieu,Zehui Gu,Carlos Fernandez-Granda,Ammar A. Javed,Greg D. Sacks,Tamas Gonda,Chenchan Huang,Yiqiu Shen*

Main category: cs.AI

TL;DR: 该研究开发并评估了能够自动从MRI/CT报告中提取胰腺囊性病变特征并根据指南分配风险类别的大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 手动从放射学报告中提取胰腺囊性病变特征是劳动密集型的，限制了大规模研究的进展。

Method: 我们使用QLoRA对两个开源大语言模型进行了微调，并利用GPT-4o生成的思维链数据进行训练。

Result: 思维链微调提高了LLaMA（80%到97%）和DeepSeek（79%到98%）的特征提取准确率，与GPT-4o（97%）相当。风险分类F1分数也有所提高（LLaMA：0.95；DeepSeek：0.94），接近GPT-4o（0.97）。

Conclusion: 微调的开源大语言模型结合思维链监督可以实现准确、可解释和高效的表型分析，其性能与GPT-4o相当。

Abstract: Background: Manual extraction of pancreatic cystic lesion (PCL) features from
radiology reports is labor-intensive, limiting large-scale studies needed to
advance PCL research. Purpose: To develop and evaluate large language models
(LLMs) that automatically extract PCL features from MRI/CT reports and assign
risk categories based on guidelines. Materials and Methods: We curated a
training dataset of 6,000 abdominal MRI/CT reports (2005-2024) from 5,134
patients that described PCLs. Labels were generated by GPT-4o using
chain-of-thought (CoT) prompting to extract PCL and main pancreatic duct
features. Two open-source LLMs were fine-tuned using QLoRA on GPT-4o-generated
CoT data. Features were mapped to risk categories per institutional guideline
based on the 2017 ACR White Paper. Evaluation was performed on 285 held-out
human-annotated reports. Model outputs for 100 cases were independently
reviewed by three radiologists. Feature extraction was evaluated using exact
match accuracy, risk categorization with macro-averaged F1 score, and
radiologist-model agreement with Fleiss' Kappa. Results: CoT fine-tuning
improved feature extraction accuracy for LLaMA (80% to 97%) and DeepSeek (79%
to 98%), matching GPT-4o (97%). Risk categorization F1 scores also improved
(LLaMA: 0.95; DeepSeek: 0.94), closely matching GPT-4o (0.97), with no
statistically significant differences. Radiologist inter-reader agreement was
high (Fleiss' Kappa = 0.888) and showed no statistically significant difference
with the addition of DeepSeek-FT-CoT (Fleiss' Kappa = 0.893) or GPT-CoT
(Fleiss' Kappa = 0.897), indicating that both models achieved agreement levels
on par with radiologists. Conclusion: Fine-tuned open-source LLMs with CoT
supervision enable accurate, interpretable, and efficient phenotyping for
large-scale PCL research, achieving performance comparable to GPT-4o.

</details>


### [103] [PITA: Preference-Guided Inference-Time Alignment for LLM Post-Training](https://arxiv.org/abs/2507.20067)
*Sarat Chandra Bobbili,Ujwal Dinesha,Dheeraj Narasimha,Srinivas Shakkottai*

Main category: cs.AI

TL;DR: PITA is a framework that aligns LLM outputs with user preferences during inference without requiring a reward model, using a preference-based guidance policy to modify token probabilities.


<details>
  <summary>Details</summary>
Motivation: Recent post-training methods for inference-time alignment depend on a pre-trained reward model, which requires fitting to human preference feedback—a potentially unstable process. PITA aims to eliminate this dependency by integrating preference feedback directly into the LLM's token generation.

Method: PITA integrates preference feedback directly into the LLM's token generation, learning a small preference-based guidance policy to modify token probabilities at inference time without LLM fine-tuning.

Result: PITA was evaluated across diverse tasks, including mathematical reasoning and sentiment classification, and demonstrated its effectiveness in aligning LLM outputs with user preferences.

Conclusion: PITA demonstrates effectiveness in aligning LLM outputs with user preferences across diverse tasks, offering a novel framework that eliminates the need for a reward model.

Abstract: Inference-time alignment enables large language models (LLMs) to generate
outputs aligned with end-user preferences without further training. Recent
post-training methods achieve this by using small guidance models to modify
token generation during inference. These methods typically optimize a reward
function KL-regularized by the original LLM taken as the reference policy. A
critical limitation, however, is their dependence on a pre-trained reward
model, which requires fitting to human preference feedback--a potentially
unstable process. In contrast, we introduce PITA, a novel framework that
integrates preference feedback directly into the LLM's token generation,
eliminating the need for a reward model. PITA learns a small preference-based
guidance policy to modify token probabilities at inference time without LLM
fine-tuning, reducing computational cost and bypassing the pre-trained reward
model dependency. The problem is framed as identifying an underlying preference
distribution, solved through stochastic search and iterative refinement of the
preference-based guidance model. We evaluate PITA across diverse tasks,
including mathematical reasoning and sentiment classification, demonstrating
its effectiveness in aligning LLM outputs with user preferences.

</details>


### [104] [The Policy Cliff: A Theoretical Analysis of Reward-Policy Maps in Large Language Models](https://arxiv.org/abs/2507.20150)
*Xingcheng Xu*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Reinforcement learning (RL) plays a crucial role in shaping the behavior of
large language and reasoning models (LLMs/LRMs). However, it often produces
brittle and unstable policies, leading to critical failures such as spurious
reasoning, deceptive alignment, and instruction disobedience that undermine the
trustworthiness and safety of LLMs/LRMs. Currently, these issues lack a unified
theoretical explanation and are typically addressed using ad-hoc heuristics.
This paper presents a rigorous mathematical framework for analyzing the
stability of the mapping from a reward function to the optimal policy. We show
that policy brittleness often stems from non-unique optimal actions, a common
occurrence when multiple valid traces exist in a reasoning task. This
theoretical lens provides a unified explanation for a range of seemingly
disparate failures, reframing them as rational outcomes of optimizing rewards
that may be incomplete or noisy, especially in the presence of action
degeneracy. We extend this analysis from the fundamental single-reward setting
to the more realistic multi-reward RL across diverse domains, showing how
stability is governed by an "effective reward" aggregation mechanism. We also
prove that entropy regularization restores policy stability at the cost of
increased stochasticity. Our framework provides a unified explanation for
recent empirical findings on deceptive reasoning, instruction-following
trade-offs, and RLHF-induced sophistry, and is further validated through
perturbation experiments in multi-reward RL. This work advances
policy-stability analysis from empirical heuristics towards a principled
theory, offering essential insights for designing safer and more trustworthy AI
systems.

</details>


### [105] [SciToolAgent: A Knowledge Graph-Driven Scientific Agent for Multi-Tool Integration](https://arxiv.org/abs/2507.20280)
*Keyan Ding,Jing Yu,Junjie Huang,Yuchen Yang,Qiang Zhang,Huajun Chen*

Main category: cs.AI

TL;DR: SciToolAgent是一种基于大型语言模型的代理，能够自动化生物、化学和材料科学中的数百个科学工具，通过知识图谱实现智能工具选择和执行，并具备安全检查模块，显著提升了复杂科学工作流的自动化水平。


<details>
  <summary>Details</summary>
Motivation: 科学研究所依赖的专用计算工具需要大量的领域专业知识，而现有的大型语言模型在整合和编排多个工具以进行复杂科学工作流方面存在困难。

Method: SciToolAgent利用科学工具知识图谱，通过基于图的检索增强生成实现智能工具选择和执行，并包含全面的安全检查模块以确保负责任和道德的工具使用。

Result: 在定制的基准测试中，SciToolAgent的表现显著优于现有方法。案例研究显示其在蛋白质工程、化学反应性预测、化学合成和金属有机框架筛选中的能力。

Conclusion: SciToolAgent能够显著提升复杂科学工作流的自动化水平，使高级研究工具对专家和非专家都更加易用。

Abstract: Scientific research increasingly relies on specialized computational tools,
yet effectively utilizing these tools demands substantial domain expertise.
While Large Language Models (LLMs) show promise in tool automation, they
struggle to seamlessly integrate and orchestrate multiple tools for complex
scientific workflows. Here, we present SciToolAgent, an LLM-powered agent that
automates hundreds of scientific tools across biology, chemistry, and materials
science. At its core, SciToolAgent leverages a scientific tool knowledge graph
that enables intelligent tool selection and execution through graph-based
retrieval-augmented generation. The agent also incorporates a comprehensive
safety-checking module to ensure responsible and ethical tool usage. Extensive
evaluations on a curated benchmark demonstrate that SciToolAgent significantly
outperforms existing approaches. Case studies in protein engineering, chemical
reactivity prediction, chemical synthesis, and metal-organic framework
screening further demonstrate SciToolAgent's capability to automate complex
scientific workflows, making advanced research tools accessible to both experts
and non-experts.

</details>


### [106] [Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition](https://arxiv.org/abs/2507.20526)
*Andy Zou,Maxwell Lin,Eliot Jones,Micha Nowak,Mateusz Dziemian,Nick Winter,Alexander Grattan,Valent Nathanael,Ayla Croft,Xander Davies,Jai Patel,Robert Kirk,Nate Burnikell,Yarin Gal,Dan Hendrycks,J. Zico Kolter,Matt Fredrikson*

Main category: cs.AI

TL;DR: 研究揭示了当前AI代理在面对攻击时存在严重漏洞，建议需要更强的防御措施。


<details>
  <summary>Details</summary>
Motivation: 研究目的是调查LLM驱动的AI代理在现实环境中是否可以被信任遵循部署政策，特别是在受到攻击的情况下。

Method: 我们进行了最大规模的公开红队竞赛，针对22个前沿AI代理进行了44种现实部署场景的测试。参与者提交了180万次提示注入攻击，并成功引发了政策违规行为。基于这些结果，我们构建了Agent Red Teaming (ART)基准，并在19个最先进的模型上进行了评估。

Result: 几乎所有代理在10-100次查询内都表现出政策违规行为，攻击在不同模型和任务之间具有高度可转移性。此外，我们发现代理的鲁棒性与模型大小、能力或推理时计算之间相关性有限。

Conclusion: 我们的研究揭示了当前AI代理中的关键且持续的漏洞，并表明需要额外的防御措施来对抗对抗性滥用。通过发布ART基准和配套的评估框架，我们旨在支持更严格的安全部署评估并推动更安全的代理部署进展。

Abstract: Recent advances have enabled LLM-powered AI agents to autonomously execute
complex tasks by combining language model reasoning with tools, memory, and web
access. But can these systems be trusted to follow deployment policies in
realistic environments, especially under attack? To investigate, we ran the
largest public red-teaming competition to date, targeting 22 frontier AI agents
across 44 realistic deployment scenarios. Participants submitted 1.8 million
prompt-injection attacks, with over 60,000 successfully eliciting policy
violations such as unauthorized data access, illicit financial actions, and
regulatory noncompliance. We use these results to build the Agent Red Teaming
(ART) benchmark - a curated set of high-impact attacks - and evaluate it across
19 state-of-the-art models. Nearly all agents exhibit policy violations for
most behaviors within 10-100 queries, with high attack transferability across
models and tasks. Importantly, we find limited correlation between agent
robustness and model size, capability, or inference-time compute, suggesting
that additional defenses are needed against adversarial misuse. Our findings
highlight critical and persistent vulnerabilities in today's AI agents. By
releasing the ART benchmark and accompanying evaluation framework, we aim to
support more rigorous security assessment and drive progress toward safer agent
deployment.

</details>


<div id='q-fin.TR'></div>

# q-fin.TR [[Back]](#toc)

### [107] [MountainLion: A Multi-Modal LLM-Based Agent System for Interpretable and Adaptive Financial Trading](https://arxiv.org/abs/2507.20474)
*Siyi Wu,Zhaoyang Guan,Leyi Zhao,Xinyuan Song,Xinyu Ying,Hanlin Zhang,Michele Pak,Yangfan He,Yi Xin,Jianhui Wang,Tianyu Shi*

Main category: q-fin.TR

TL;DR: MountainLion is a multi-modal, multi-agent system for financial trading that uses LLM-based agents to interpret financial data and generate investment strategies. It processes various types of financial data to produce high-quality reports and allows for user interaction and modification of recommendations. The system includes a reflection module that refines decision processes based on historical data and can adjust investment strategies in real-time. Empirical results show that MountainLion enhances investment frameworks by incorporating macroeconomic and capital flow signals, leading to improved returns and increased investor confidence.


<details>
  <summary>Details</summary>
Motivation: Cryptocurrency trading is a challenging task requiring the integration of heterogeneous data from multiple modalities. Traditional deep learning and reinforcement learning approaches typically demand large training datasets and encode diverse inputs into numerical representations, often at the cost of interpretability. Recent progress in large language model (LLM)-based agents has demonstrated the capacity to process multi-modal data and support complex investment decision-making.

Method: MountainLion is a multi-modal, multi-agent system for financial trading that coordinates specialized LLM-based agents to interpret financial data and generate investment strategies. It processes textual news, candlestick charts, and trading signal charts to produce high-quality financial reports, while also enabling modification of reports and investment recommendations through data-driven user interaction and question answering. A central reflection module analyzes historical trading signals and outcomes to continuously refine decision processes, and the system is capable of real-time report analysis, summarization, and dynamic adjustment of investment strategies.

Result: Empirical results confirm that MountainLion systematically enriches technical price triggers with contextual macroeconomic and capital flow signals, providing a more interpretable, robust, and actionable investment framework that improves returns and strengthens investor confidence.

Conclusion: MountainLion systematically enriches technical price triggers with contextual macroeconomic and capital flow signals, providing a more interpretable, robust, and actionable investment framework that improves returns and strengthens investor confidence.

Abstract: Cryptocurrency trading is a challenging task requiring the integration of
heterogeneous data from multiple modalities. Traditional deep learning and
reinforcement learning approaches typically demand large training datasets and
encode diverse inputs into numerical representations, often at the cost of
interpretability. Recent progress in large language model (LLM)-based agents
has demonstrated the capacity to process multi-modal data and support complex
investment decision-making. Building on these advances, we present
\textbf{MountainLion}, a multi-modal, multi-agent system for financial trading
that coordinates specialized LLM-based agents to interpret financial data and
generate investment strategies. MountainLion processes textual news,
candlestick charts, and trading signal charts to produce high-quality financial
reports, while also enabling modification of reports and investment
recommendations through data-driven user interaction and question answering. A
central reflection module analyzes historical trading signals and outcomes to
continuously refine decision processes, and the system is capable of real-time
report analysis, summarization, and dynamic adjustment of investment
strategies. Empirical results confirm that MountainLion systematically enriches
technical price triggers with contextual macroeconomic and capital flow
signals, providing a more interpretable, robust, and actionable investment
framework that improves returns and strengthens investor confidence.

</details>
