<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 44]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.GR](#cs.GR) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models](https://arxiv.org/abs/2507.13357)
*Atharva Bhargude,Ishan Gonehal,Chandler Haney,Dave Yoon,Kevin Zhu,Aaron Sandoval,Sean O'Brien,Kaustubh Vinnakota*

Main category: cs.CL

TL;DR: This paper introduces Adaptive Linguistic Prompting (ALP) to enhance phishing detection using multimodal large language models, achieving high accuracy and demonstrating the potential for more robust and interpretable detection systems.


<details>
  <summary>Details</summary>
Motivation: Phishing attacks are a significant cybersecurity threat, requiring adaptive detection techniques. Traditional approaches lack the capability to handle sophisticated phishing attempts effectively.

Method: The study explores few-shot Adaptive Linguistic Prompting (ALP) by leveraging the multimodal capabilities of state-of-the-art large language models (LLMs) such as GPT-4o and Gemini 1.5 Pro to detect phishing webpages.

Result: ALP significantly enhances phishing detection accuracy by guiding LLMs through structured reasoning and contextual analysis, achieving an F1-score of 0.93, surpassing traditional approaches.

Conclusion: ALP-integrated multimodal LLMs show great potential in advancing phishing detection frameworks, offering a more robust, interpretable, and adaptive solution.

Abstract: Phishing attacks represent a significant cybersecurity threat, necessitating
adaptive detection techniques. This study explores few-shot Adaptive Linguistic
Prompting (ALP) in detecting phishing webpages through the multimodal
capabilities of state-of-the-art large language models (LLMs) such as GPT-4o
and Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides
LLMs to analyze textual deception by breaking down linguistic patterns,
detecting urgency cues, and identifying manipulative diction commonly found in
phishing content. By integrating textual, visual, and URL-based analysis, we
propose a unified model capable of identifying sophisticated phishing attempts.
Our experiments demonstrate that ALP significantly enhances phishing detection
accuracy by guiding LLMs through structured reasoning and contextual analysis.
The findings highlight the potential of ALP-integrated multimodal LLMs to
advance phishing detection frameworks, achieving an F1-score of 0.93,
surpassing traditional approaches. These results establish a foundation for
more robust, interpretable, and adaptive linguistic-based phishing detection
systems using LLMs.

</details>


### [2] [Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition](https://arxiv.org/abs/2507.13380)
*Keito Inoshita,Rushia Harada*

Main category: cs.CL

TL;DR: PersonaGen is a framework for generating emotionally rich text using a Large Language Model through multi-stage persona-based conditioning. It constructs layered virtual personas to guide emotion expression generation and shows superior performance in generating diverse, coherent, and discriminative emotion expressions.


<details>
  <summary>Details</summary>
Motivation: The development of high-performance models in emotion recognition remains a challenge due to the scarcity of high-quality, diverse emotional datasets.

Method: PersonaGen is a novel framework for generating emotionally rich text using a Large Language Model (LLM) through multi-stage persona-based conditioning.

Result: Experimental results show that PersonaGen significantly outperforms baseline methods in generating diverse, coherent, and discriminative emotion expressions.

Conclusion: PersonaGen demonstrates potential as a robust alternative for augmenting or replacing real-world emotional datasets.

Abstract: In the field of emotion recognition, the development of high-performance
models remains a challenge due to the scarcity of high-quality, diverse
emotional datasets. Emotional expressions are inherently subjective, shaped by
individual personality traits, socio-cultural backgrounds, and contextual
factors, making large-scale, generalizable data collection both ethically and
practically difficult. To address this issue, we introduce PersonaGen, a novel
framework for generating emotionally rich text using a Large Language Model
(LLM) through multi-stage persona-based conditioning. PersonaGen constructs
layered virtual personas by combining demographic attributes, socio-cultural
backgrounds, and detailed situational contexts, which are then used to guide
emotion expression generation. We conduct comprehensive evaluations of the
generated synthetic data, assessing semantic diversity through clustering and
distributional metrics, human-likeness via LLM-based quality scoring, realism
through comparison with real-world emotion corpora, and practical utility in
downstream emotion classification tasks. Experimental results show that
PersonaGen significantly outperforms baseline methods in generating diverse,
coherent, and discriminative emotion expressions, demonstrating its potential
as a robust alternative for augmenting or replacing real-world emotional
datasets.

</details>


### [3] [SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation](https://arxiv.org/abs/2507.13381)
*Rafiq Kamel,Filippo Guerranti,Simon Geisler,Stephan Günnemann*

Main category: cs.CL

TL;DR: SAFT is a method that enhances LLMs by incorporating graph topology, leading to improved performance on AMR-to-text generation tasks.


<details>
  <summary>Details</summary>
Motivation: Current methods for handling structured inputs like AMRs often arbitrarily linearize them, discarding key structural cues, or rely on architectures incompatible with standard LLMs.

Method: SAFT is a structure-aware fine-tuning approach that injects graph topology into pretrained LLMs without architectural changes. It computes direction-sensitive positional encodings from the magnetic Laplacian of transformed AMRs and projects them into the embedding space of the LLM.

Result: SAFT sets a new state-of-the-art on AMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph complexity, highlighting the value of structure-aware representations in enhancing LLM performance.

Conclusion: SAFT offers a general and effective pathway for bridging structured data and language models.

Abstract: Large Language Models (LLMs) are increasingly applied to tasks involving
structured inputs such as graphs. Abstract Meaning Representations (AMRs),
which encode rich semantics as directed graphs, offer a rigorous testbed for
evaluating LLMs on text generation from such structures. Yet, current methods
often arbitrarily linearize AMRs, discarding key structural cues, or rely on
architectures incompatible with standard LLMs. We introduce SAFT, a
structure-aware fine-tuning approach that injects graph topology into
pretrained LLMs without architectural changes. We compute direction-sensitive
positional encodings from the magnetic Laplacian of transformed AMRs and
project them into the embedding space of the LLM. While possibly applicable to
any graph-structured inputs, we focus on AMR-to-text generation as a
representative and challenging benchmark. SAFT sets a new state-of-the-art on
AMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph
complexity, highlighting the value of structure-aware representations in
enhancing LLM performance. SAFT offers a general and effective pathway for
bridging structured data and language models.

</details>


### [4] [Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case](https://arxiv.org/abs/2507.13382)
*Chandrashekar Muniyappa,Sirisha Velampalli*

Main category: cs.CL

TL;DR: 本文提出了一种基于上下文图的方法来检测假新闻文章，通过将新闻文章转换为上下文图结构，并应用基于最小描述长度的基于图的异常检测算法进行图挖掘。


<details>
  <summary>Details</summary>
Motivation: 在当今数字世界中，假新闻传播速度极快，这是一个需要解决的重要问题。

Method: 我们提出了一种基于上下文图的方法来检测假新闻文章。我们利用自然语言处理（NLP）技术将新闻文章转换为上下文图结构，并应用基于最小描述长度（MDL）的基于图的异常检测（GBAD）算法进行图挖掘。

Result: 我们使用了来自Kaggle的数据集，其中包含真实和虚假的新闻文章。为了测试我们的方法，我们纳入了最近与新冠相关的新闻文章，这些文章包含真实和虚假的新闻，这进一步增强了数据集。

Conclusion: 我们的方法能够识别数据集中的规范模式，并随后发现偏离这些既定规范的异常模式。

Abstract: In today\'s digital world, fake news is spreading with immense speed. Its a
significant concern to address. In this work, we addressed that challenge using
novel graph based approach. We took dataset from Kaggle that contains real and
fake news articles. To test our approach we incorporated recent covid-19
related news articles that contains both genuine and fake news that are
relevant to this problem. This further enhances the dataset as well instead of
relying completely on the original dataset. We propose a contextual graph-based
approach to detect fake news articles. We need to convert news articles into
appropriate schema, so we leverage Natural Language Processing (NLP) techniques
to transform news articles into contextual graph structures. We then apply the
Minimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)
algorithm for graph mining. Graph-based methods are particularly effective for
handling rich contextual data, as they enable the discovery of complex patterns
that traditional query-based or statistical techniques might overlook. Our
proposed approach identifies normative patterns within the dataset and
subsequently uncovers anomalous patterns that deviate from these established
norms.

</details>


### [5] [PARAM-1 BharatGen 2.9B Model](https://arxiv.org/abs/2507.13390)
*Kundeshwar Pundalik,Piyush Sawarkar,Nihar Sahoo,Abhishek Shinde,Prateek Chanda,Vedant Goswami,Ajay Nagpal,Atul Singh,Viraj Thakur,Vijay Dewane,Aamod Thakur,Bhargav Patel,Smita Gautam,Bhagwan Panditi,Shyam Pawar,Madhav Kotcha,Suraj Racha,Saral Sureka,Pankaj Singh,Rishi Bal,Rohit Saluja,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: PARAM-1 is a language model trained with a focus on Indian diversity, aiming to address the under-representation of Indic languages in large language models.


<details>
  <summary>Details</summary>
Motivation: The exclusionary design of large language models results in structural under-representation of linguistically diverse regions such as India, where over 20 official languages and 100+ dialects coexist alongside phenomena like code-switching and diglossia.

Method: PARAM-1 is a 2.9B parameter decoder-only, text-only language model trained from scratch with an explicit architectural and linguistic focus on Indian diversity. It is trained on a bilingual dataset consisting of only Hindi and English, constructed with a strong focus on fact-rich, high-quality content. The model is guided by three core principles: equitable representation of Indic languages, tokenization fairness, and culturally aligned evaluation benchmarks.

Result: PARAM-1 demonstrates that it serves as both a competent general-purpose model and a robust baseline for India-centric applications.

Conclusion: PARAM-1 offers a design-first blueprint for equitable foundation modeling and serves as both a competent general-purpose model and a robust baseline for India-centric applications.

Abstract: Large Language Models (LLMs) have emerged as powerful general-purpose
reasoning systems, yet their development remains dominated by English-centric
data, architectures, and optimization paradigms. This exclusionary design
results in structural under-representation of linguistically diverse regions
such as India, where over 20 official languages and 100+ dialects coexist
alongside phenomena like code-switching and diglossia. We introduce PARAM-1, a
2.9B parameter decoder-only, text-only language model trained from scratch with
an explicit architectural and linguistic focus on Indian diversity. PARAM-1 is
trained on a bilingual dataset consisting of only Hindi and English,
constructed with a strong focus on fact-rich, high-quality content. It is
guided by three core principles: equitable representation of Indic languages
through a 25% corpus allocation; tokenization fairness via a SentencePiece
tokenizer adapted to Indian morphological structures; and culturally aligned
evaluation benchmarks across IndicQA, code-mixed reasoning, and
socio-linguistic robustness tasks. By embedding diversity at the pretraining
level-rather than deferring it to post-hoc alignment-PARAM-1 offers a
design-first blueprint for equitable foundation modeling. Our results
demonstrate that it serves as both a competent general-purpose model and a
robust baseline for India-centric applications.

</details>


### [6] [TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction](https://arxiv.org/abs/2507.13392)
*Emil Häglund,Johanna Björklund*

Main category: cs.CL

TL;DR: 本文提出了一种改进的客户评论分析方法，通过在意见单元上运行主题建模流程，提高了提取见解的效率，并能够捕捉与每个主题相关的情感。


<details>
  <summary>Details</summary>
Motivation: 现有的主题建模方法在处理客户评论时可能无法充分捕捉情感信息，从而限制了其在业务分析中的应用。因此，我们需要一种更有效的方法来提取和分析客户评论中的见解。

Method: 我们的方法涉及重新设计主题建模流程，使其在意见单元上运行，这些单元包括相关的文本摘录和关联的情感评分。我们使用大型语言模型可靠地提取这些单元，并评估了将主题和情感模态集成以进行准确的星级评分预测的方法。

Result: 我们的方法提高了后续主题建模的性能，生成了更连贯和可解释的主题，同时捕捉了每个主题的情感。通过将主题和情感与业务指标相关联，我们能够获得有关客户关注点如何影响业务结果的见解。

Conclusion: 通过将主题建模流程重新设计为在意见单元上运行，我们提高了从客户评论中提取见解的效率。这种方法能够更准确地捕捉与每个主题相关的情感，并通过将主题和情感与业务指标相关联，提供对客户关注点如何影响业务结果的洞察。

Abstract: We improve the extraction of insights from customer reviews by restructuring
the topic modelling pipeline to operate on opinion units - distinct statements
that include relevant text excerpts and associated sentiment scores. Prior work
has demonstrated that such units can be reliably extracted using large language
models. The result is a heightened performance of the subsequent topic
modeling, leading to coherent and interpretable topics while also capturing the
sentiment associated with each topic. By correlating the topics and sentiments
with business metrics, such as star ratings, we can gain insights on how
specific customer concerns impact business outcomes. We present our system's
implementation, use cases, and advantages over other topic modeling and
classification solutions. We also evaluate its effectiveness in creating
coherent topics and assess methods for integrating topic and sentiment
modalities for accurate star-rating prediction.

</details>


### [7] [Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only](https://arxiv.org/abs/2507.13395)
*Xuanqi Gao,Weipeng Jiang,Juan Zhai,Shiqing Ma,Siyi Xie,Xinyang Yin,Chao Shen*

Main category: cs.CL

TL;DR: Babel 是一种新的框架，用于在神经机器翻译中使用单语语料库提高风格保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常需要平行语料库来进行风格保留，而 Babel 仅使用单语语料库来增强风格保真度。

Method: Babel 使用了两个关键组件：基于上下文嵌入的风格检测器和基于扩散的风格应用器。

Result: 在五个不同的领域（法律、文学、科学写作、医学和教育内容）进行的大量实验表明，Babel 在识别风格不一致方面具有 88.21% 的精确度，并将风格保留提高了 150%，同时保持了 0.92 的高语义相似性分数。

Conclusion: Babel 是一种有效的框架，能够提高神经机器翻译中的风格保真度，同时保持语义完整性。

Abstract: The advent of neural machine translation (NMT) has revolutionized
cross-lingual communication, yet preserving stylistic nuances remains a
significant challenge. While existing approaches often require parallel corpora
for style preservation, we introduce Babel, a novel framework that enhances
stylistic fidelity in NMT using only monolingual corpora. Babel employs two key
components: (1) a style detector based on contextual embeddings that identifies
stylistic disparities between source and target texts, and (2) a
diffusion-based style applicator that rectifies stylistic inconsistencies while
maintaining semantic integrity. Our framework integrates with existing NMT
systems as a post-processing module, enabling style-aware translation without
requiring architectural modifications or parallel stylistic data. Extensive
experiments on five diverse domains (law, literature, scientific writing,
medicine, and educational content) demonstrate Babel's effectiveness: it
identifies stylistic inconsistencies with 88.21% precision and improves
stylistic preservation by 150% while maintaining a high semantic similarity
score of 0.92. Human evaluation confirms that translations refined by Babel
better preserve source text style while maintaining fluency and adequacy.

</details>


### [8] [Causal Language Control in Multilingual Transformers via Sparse Feature Steering](https://arxiv.org/abs/2507.13410)
*Cheng-Ting Chou,George Liu,Jessica Sun,Cole Blondin,Kevin Zhu,Vasu Sharma,Sean O'Brien*

Main category: cs.CL

TL;DR: 本文研究了是否可以利用稀疏自编码器（SAE）特征来在推理过程中引导大型多语言语言模型的生成语言。通过修改一个Transformer层的一个SAE特征，实现了高达90%的成功率的语言转换，同时保持了语义保真度。


<details>
  <summary>Details</summary>
Motivation: 确定性地控制大型多语言语言模型（LLMs）的目标生成语言仍然是一个基本挑战，特别是在没有显式语言提示或微调的零样本设置中。

Method: 我们利用预训练的稀疏自编码器（SAE）在Gemma-2B和Gemma-9B的残差流上，识别出在英语和四种目标语言（中文、日语、西班牙语和法语）之间激活差异最大的特征。通过仅修改一个Transformer层的一个SAE特征，我们实现了高达90%的成功率的语言转换。

Result: 通过仅修改一个Transformer层的一个SAE特征，我们实现了高达90%的成功率的语言转换，同时根据LaBSE（语言无关的BERT句子嵌入）相似性保持了语义保真度。分析表明，语言引导在中到晚期Transformer层中最有效，并且由与语言敏感SAE特征不成比例相关的特定注意力头放大。

Conclusion: 这些结果展示了稀疏特征控制作为一种轻量且可解释的机制，在可控多语言生成中的潜力。

Abstract: Deterministically controlling the target generation language of large
multilingual language models (LLMs) remains a fundamental challenge,
particularly in zero-shot settings where neither explicit language prompts nor
fine-tuning are available. In this work, we investigate whether sparse
autoencoder (SAE) features, previously shown to correlate with interpretable
model behaviors, can be leveraged to steer the generated language of LLMs
during inference. Leveraging pretrained SAEs on the residual streams of
Gemma-2B and Gemma-9B, we identify features whose activations differ most
significantly between English and four target languages: Chinese, Japanese,
Spanish, and French. By modifying just a single SAE feature at one transformer
layer, we achieve controlled language shifts with up to 90\% success, as
measured by FastText language classification, while preserving semantic
fidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding)
similarity. Our analysis reveals that language steering is most effective in
mid-to-late transformer layers and is amplified by specific attention heads
disproportionately associated with language-sensitive SAE features. These
results demonstrate the promise of sparse feature steering as a lightweight and
interpretable mechanism for controllable multilingual generation.

</details>


### [9] [Aligning Knowledge Graphs and Language Models for Factual Accuracy](https://arxiv.org/abs/2507.13411)
*Nur A Zarin Nishat,Andrea Coletta,Luigi Bellomarini,Kossi Amouzouvi,Jens Lehmann,Sahar Vahdati*

Main category: cs.CL

TL;DR: 本文提出了一种简单而有效的方法ALIGNed-LLM，通过将知识图谱注入语言模型的潜在空间来提高语言模型的事实准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言处理任务中表现出色，但容易产生幻觉。为了克服这一挑战，本文提出了将知识图谱注入语言模型的方法，以提供结构化、可靠、领域特定和最新的外部信息。

Method: 本文提出了一种基于知识图谱嵌入（KGE）模型的对齐方法，通过可训练的投影层将实体和文本嵌入对齐，从而提高语言模型的事实准确性。

Result: 本文的方法在三个流行的问答基准数据集和一个实际的金融用例中都取得了显著的改进。

Conclusion: 本文提出了一种简单而有效的方法ALIGNed-LLM，通过将知识图谱注入语言模型的潜在空间来提高语言模型的事实准确性。实验结果表明，该方法在多个问答基准数据集和一个实际的金融用例中都取得了显著的改进。

Abstract: Large language models like GPT-4, Gemini, and Claude have transformed natural
language processing (NLP) tasks such as question answering, dialogue
generation, summarization, and so forth; yet their susceptibility to
hallucination stands as one of the major challenges. Among numerous approaches
to overcome this challenge, integration of Knowledge Graphs (KGs) into language
models has emerged as a promising solution as it provides structured, reliable,
domain-specific, and up-to-date external information to the language models. In
this paper, we introduce ALIGNed-LLM, a simple yet effective approach to
improve language models' factuality via a lean strategy to infuse KGs into the
latent space of language models inspired by LLaVA where visual and textual
information is infused. We use embeddings from a pre-trained Knowledge Graph
Embedding (KGE) model, such as TransE, and a trainable projection layer to
align entity and text embeddings. This alignment enables the language model to
distinguish between similar entities improving factual grounding and reducing
hallucination. We tested our approach on three popular questions-answering
benchmark datasets alongside language models of varying sizes, showing
significant improvement. Furthermore, we applied our approach to a real-world
financial use case from a large central bank in Europe, which demands high
accuracy and precision, demonstrating a substantial improvement of the LLM
answers.

</details>


### [10] [Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers](https://arxiv.org/abs/2507.13474)
*Liang Lin,Zhihao Xu,Xuehai Tang,Shi Liu,Biyu Zhou,Fuqing Zhu,Jizhong Han,Songlin Hu*

Main category: cs.CL

TL;DR: 本文提出了一种新的越狱方法Paper Summary Attack (PSA)，并通过实验验证了其在多个大型语言模型上的高攻击成功率。研究还发现了不同基础模型在面对攻击型或防御型论文时表现出相反的漏洞偏倚，为未来的研究提供了新的线索。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）的安全性引起了广泛关注，本文旨在探讨LLMs是否倾向于信任权威来源的信息，从而发现潜在的新漏洞。

Method: 本文通过设计一个初步分析来验证LLMs对权威来源信息的信任倾向，并基于此提出了一种名为Paper Summary Attack (PSA)的新越狱方法。该方法系统地整合来自攻击型或防御型LLM安全论文的内容，构建对抗性提示模板，并在预定义的子部分中战略性地填充有害查询作为对抗性载荷。

Result: 实验结果表明，PSA不仅在基础LLMs上表现出显著的漏洞，而且在最先进的推理模型如Deepseek-R1上也表现良好。PSA在像Claude3.5-Sonnet这样的对齐良好的模型上实现了97%的攻击成功率（ASR），而在Deepseek-R1上甚至达到了98%的ASR。此外，研究还发现了不同基础模型以及同一模型的不同版本在面对攻击型或防御型论文时表现出相反的漏洞偏倚。

Conclusion: 本文提出了一个新颖的越狱方法Paper Summary Attack (PSA)，并展示了其在多个大型语言模型上的高攻击成功率。此外，研究还揭示了不同基础模型之间在面对攻击型或防御型论文时表现出相反的漏洞偏倚，这为未来的研究提供了新的方向。

Abstract: The safety of large language models (LLMs) has garnered significant research
attention. In this paper, we argue that previous empirical studies demonstrate
LLMs exhibit a propensity to trust information from authoritative sources, such
as academic papers, implying new possible vulnerabilities. To verify this
possibility, a preliminary analysis is designed to illustrate our two findings.
Based on this insight, a novel jailbreaking method, Paper Summary Attack
(\llmname{PSA}), is proposed. It systematically synthesizes content from either
attack-focused or defense-focused LLM safety paper to construct an adversarial
prompt template, while strategically infilling harmful query as adversarial
payloads within predefined subsections. Extensive experiments show significant
vulnerabilities not only in base LLMs, but also in state-of-the-art reasoning
model like Deepseek-R1. PSA achieves a 97\% attack success rate (ASR) on
well-aligned models like Claude3.5-Sonnet and an even higher 98\% ASR on
Deepseek-R1. More intriguingly, our work has further revealed diametrically
opposed vulnerability bias across different base models, and even between
different versions of the same model, when exposed to either attack-focused or
defense-focused papers. This phenomenon potentially indicates future research
clues for both adversarial methodologies and safety alignment.Code is available
at https://github.com/233liang/Paper-Summary-Attack

</details>


### [11] [Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?](https://arxiv.org/abs/2507.13490)
*Siqi Shen,Mehar Singh,Lajanugen Logeswaran,Moontae Lee,Honglak Lee,Rada Mihalcea*

Main category: cs.CL

TL;DR: 本文评估了三种广泛使用的探测策略在价值表示上的鲁棒性和表达能力，并引入了两个任务来研究价值是否对人口统计背景作出反应，以及它们与模型在相关价值场景中的行为对齐程度。结果表明，所有方法在输入扰动下都表现出较大的方差，且人口统计背景对自由文本生成的影响很小，模型的价值仅与它们对基于价值行动的偏好弱相关。


<details>
  <summary>Details</summary>
Motivation: 尽管已经有很多关于评估大型语言模型（LLMs）的价值取向的研究，但仍然存在几个挑战。首先，虽然多项选择题（MCQ）设置已被证明容易受到扰动的影响，但没有系统比较探测方法用于价值探测。其次，不清楚探测到的价值在多大程度上捕捉上下文信息并反映模型对现实世界行动的偏好。

Method: 我们评估了三种广泛使用的探测策略在价值表示上的鲁棒性和表达能力，并引入了两个任务来研究价值是否对人口统计背景作出反应，以及它们与模型在相关价值场景中的行为对齐程度。

Result: 我们通过提示和选项的变化显示，所有方法在输入扰动下都表现出较大的方差。我们还发现人口统计背景对自由文本生成的影响很小，模型的价值仅与它们对基于价值行动的偏好弱相关。

Conclusion: 我们的工作强调了对LLM价值探测进行更仔细检查的必要性，并意识到其局限性。

Abstract: There has been extensive research on assessing the value orientation of Large
Language Models (LLMs) as it can shape user experiences across demographic
groups. However, several challenges remain. First, while the Multiple Choice
Question (MCQ) setting has been shown to be vulnerable to perturbations, there
is no systematic comparison of probing methods for value probing. Second, it is
unclear to what extent the probed values capture in-context information and
reflect models' preferences for real-world actions. In this paper, we evaluate
the robustness and expressiveness of value representations across three widely
used probing strategies. We use variations in prompts and options, showing that
all methods exhibit large variances under input perturbations. We also
introduce two tasks studying whether the values are responsive to demographic
context, and how well they align with the models' behaviors in value-related
scenarios. We show that the demographic context has little effect on the
free-text generation, and the models' values only weakly correlate with their
preference for value-based actions. Our work highlights the need for a more
careful examination of LLM value probing and awareness of its limitations.

</details>


### [12] [Encoding syntactic objects and Merge operations in function spaces](https://arxiv.org/abs/2507.13501)
*Matilde Marcolli,Robert C. Berwick*

Main category: cs.CL

TL;DR: 本文提出了一种在函数空间中表示句法对象的方法，并展示了其与神经计算的理论可能性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨句法对象在函数空间中的表示方法，并展示其与神经计算的潜在联系。

Method: 本文使用第二瑞尼熵构建了一个交换非结合半环结构，并利用操作符代数和霍普夫代数马尔可夫链来实现合并操作。

Result: 本文证明了句法对象可以在函数空间中得到忠实表示，并展示了合并操作可以通过交叉频率相位同步实现。

Conclusion: 本文提供了数学论证，表明在某些函数空间中，可以构建任意句法对象的忠实表示。这种表示与代数结构兼容，并且可以实现神经计算的理论可能性。

Abstract: We provide a mathematical argument showing that, given a representation of
lexical items as functions (wavelets, for instance) in some function space, it
is possible to construct a faithful representation of arbitrary syntactic
objects in the same function space. This space can be endowed with a
commutative non-associative semiring structure built using the second Renyi
entropy. The resulting representation of syntactic objects is compatible with
the magma structure. The resulting set of functions is an algebra over an
operad, where the operations in the operad model circuits that transform the
input wave forms into a combined output that encodes the syntactic structure.
The action of Merge on workspaces is faithfully implemented as action on these
circuits, through a coproduct and a Hopf algebra Markov chain. The results
obtained here provide a constructive argument showing the theoretical
possibility of a neurocomputational realization of the core computational
structure of syntax. We also present a particular case of this general
construction where this type of realization of Merge is implemented as a cross
frequency phase synchronization on sinusoidal waves. This also shows that Merge
can be expressed in terms of the successor function of a semiring, thus
clarifying the well known observation of its similarities with the successor
function of arithmetic.

</details>


### [13] [A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows](https://arxiv.org/abs/2507.13544)
*Mohamed Achref Ben Ammar,Mohamed Taha Bennani*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The analysis of conversational dynamics has gained increasing importance with
the rise of large language model-based systems, which interact with users
across diverse contexts. In this work, we propose a novel computational
framework for constructing conversational graphs that capture the flow and
structure of loosely organized dialogues, referred to as quasi-patterned
conversations. We introduce the Filter & Reconnect method, a novel graph
simplification technique that minimizes noise while preserving semantic
coherence and structural integrity of conversational graphs. Through
comparative analysis, we demonstrate that the use of large language models
combined with our graph simplification technique has resulted in semantic
metric S increasing by a factor of 2.06 compared to previous approaches while
simultaneously enforcing a tree-like structure with 0 {\delta}-hyperbolicity,
ensuring optimal clarity in conversation modeling. This work provides a
computational method for analyzing large-scale dialogue datasets, with
practical applications related to monitoring automated systems such as
chatbots, dialogue management tools, and user behavior analytics.

</details>


### [14] [Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder](https://arxiv.org/abs/2507.13551)
*Feng Chen,Weizhe Xu,Changye Li,Serguei Pakhomov,Alex Cohen,Simran Bhola,Sandy Yin,Sunny X Tang,Michael Mackinley,Lena Palaniyappan,Dror Ben-Zeev,Trevor Cohen*

Main category: cs.CL

TL;DR: 本研究通过结合暂停特征和语义连贯性度量，评估了自动化语音分析在评估精神分裂症谱系障碍中的应用，结果表明这种结合方法能有效预测FTD的严重程度。


<details>
  <summary>Details</summary>
Motivation: 传统临床评分量表虽然经过验证，但资源密集且难以扩展。自动化语音分析可以客观量化语言和时间特征，提供可扩展的替代方案。然而，整合这些ASR派生特征用于评估FTD严重程度的效用需要进一步评估。

Method: 本研究将暂停特征与语义连贯性度量相结合，在三个数据集中评估了暂停相关特征以及已建立的连贯性度量，并使用支持向量回归（SVR）来预测临床FTD评分。

Result: 关键发现表明，单独的暂停特征可以稳健地预测FTD的严重程度。将暂停特征与语义连贯性度量结合提高了预测性能，独立模型的整合达到了高达ρ=0.649和AUC=83.71%的关联性，用于严重病例检测（TOPSY，最佳ρ=0.584和AUC=79.23%的语义-only模型）。

Conclusion: 这些发现表明，结合时间分析和语义分析的框架为改进混乱言语的评估提供了路线图，并推进了精神病学中的自动语音分析。

Abstract: Formal thought disorder (FTD), a hallmark of schizophrenia spectrum
disorders, manifests as incoherent speech and poses challenges for clinical
assessment. Traditional clinical rating scales, though validated, are
resource-intensive and lack scalability. Automated speech analysis with
automatic speech recognition (ASR) allows for objective quantification of
linguistic and temporal features of speech, offering scalable alternatives. The
use of utterance timestamps in ASR captures pause dynamics, which are thought
to reflect the cognitive processes underlying speech production. However, the
utility of integrating these ASR-derived features for assessing FTD severity
requires further evaluation. This study integrates pause features with semantic
coherence metrics across three datasets: naturalistic self-recorded diaries
(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream
narratives (PsyCL, n = 43). We evaluated pause related features alongside
established coherence measures, using support vector regression (SVR) to
predict clinical FTD scores. Key findings demonstrate that pause features alone
robustly predict the severity of FTD. Integrating pause features with semantic
coherence metrics enhanced predictive performance compared to semantic-only
models, with integration of independent models achieving correlations up to
\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best
\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance
gains from semantic and pause features integration held consistently across all
contexts, though the nature of pause patterns was dataset-dependent. These
findings suggest that frameworks combining temporal and semantic analyses
provide a roadmap for refining the assessment of disorganized speech and
advance automated speech analysis in psychosis.

</details>


### [15] [A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models](https://arxiv.org/abs/2507.13563)
*Kirill Borodin,Nikita Vasiliev,Vasiliy Kudryavtsev,Maxim Maslov,Mikhail Gorodnichev,Oleg Rogov,Grach Mkrtchian*

Main category: cs.CL

TL;DR: 本文介绍了一个名为Balalaika的新数据集，包含超过2000小时的高质量俄语音频，并展示了其在语音合成和增强任务中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 俄罗斯语音合成面临独特的挑战，包括元音弱化、辅音不送气、可变重音模式、同形异义词歧义和不自然的语调。

Method: 本文介绍了Balalaika数据集的构建流程、注释方法以及对比评估的结果。

Result: 实验结果表明，使用Balalaika训练的模型在语音合成和增强任务中表现更好。

Conclusion: 实验结果表明，使用Balalaika训练的模型在语音合成和增强任务中显著优于现有数据集。

Abstract: Russian speech synthesis presents distinctive challenges, including vowel
reduction, consonant devoicing, variable stress patterns, homograph ambiguity,
and unnatural intonation. This paper introduces Balalaika, a novel dataset
comprising more than 2,000 hours of studio-quality Russian speech with
comprehensive textual annotations, including punctuation and stress markings.
Experimental results show that models trained on Balalaika significantly
outperform those trained on existing datasets in both speech synthesis and
enhancement tasks. We detail the dataset construction pipeline, annotation
methodology, and results of comparative evaluations.

</details>


### [16] [Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models](https://arxiv.org/abs/2507.13614)
*Sergio E. Zanotto,Segun Aroyehun*

Main category: cs.CL

TL;DR: 本研究通过分析不同语言层次上的语言特征，探讨了人类写作和机器生成文本之间的差异。结果表明，人类写作的文本在句法结构上更简单，语义内容更丰富，并且在不同领域中表现出更大的变化。此外，较新的模型输出的文本具有相似的可变性，这表明机器生成文本正在趋于同质化。


<details>
  <summary>Details</summary>
Motivation: 尽管最近的研究主要集中在使用LLM来分类文本是人类写作还是机器生成的文本，但我们的研究重点是使用一组跨不同语言层次的语言特征来表征这些文本。

Method: 我们选择了一个包含8个领域和11种不同LLM生成的文本数据集。我们计算了不同的语言特征，如依赖长度和情绪性，并使用它们来表征人类写作和机器生成的文本，同时还考虑了不同的抽样策略、重复控制和模型发布日期。我们还计算了我们的特征在模型和领域之间的变异性，并应用了风格嵌入来进一步测试人类写作和机器生成文本之间的可变性。

Result: 我们的统计分析显示，人类写作的文本倾向于表现出更简单的句法结构和更多样的语义内容。此外，我们发现人类和机器文本在不同领域中都表现出风格多样性，但人类在我们的特征中表现出更大的变化。最后，我们应用风格嵌入进一步测试了人类写作和机器生成文本之间的可变性。值得注意的是，较新的模型输出的文本具有相似的可变性，这表明机器生成文本正在趋于同质化。

Conclusion: 我们的研究发现，人类写作的文本在句法结构上更简单，语义内容更丰富。此外，我们发现人类写作的文本在不同领域中表现出更大的特征变化。最后，我们应用风格嵌入进一步测试了人类写作和机器生成文本之间的可变性。值得注意的是，较新的模型输出的文本具有相似的可变性，这表明机器生成文本正在趋于同质化。

Abstract: The rapid advancements in large language models (LLMs) have significantly
improved their ability to generate natural language, making texts generated by
LLMs increasingly indistinguishable from human-written texts. While recent
research has primarily focused on using LLMs to classify text as either
human-written and machine-generated texts, our study focus on characterizing
these texts using a set of linguistic features across different linguistic
levels such as morphology, syntax, and semantics. We select a dataset of
human-written and machine-generated texts spanning 8 domains and produced by 11
different LLMs. We calculate different linguistic features such as dependency
length and emotionality and we use them for characterizing human-written and
machine-generated texts along with different sampling strategies, repetition
controls and model release date. Our statistical analysis reveals that
human-written texts tend to exhibit simpler syntactic structures and more
diverse semantic content. Furthermore, we calculate the variability of our set
of features across models and domains. Both human and machine texts show
stylistic diversity across domains, with humans displaying greater variation in
our features. Finally, we apply style embeddings to further test variability
among human-written and machine-generated texts. Notably, newer models output
text that is similarly variable, pointing to an homogenization of
machine-generated texts.

</details>


### [17] [Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters](https://arxiv.org/abs/2507.13618)
*Shanbo Cheng,Yu Bao,Qian Cao,Luyang Huang,Liyan Kang,Zhicheng Liu,Yu Lu,Wenhao Zhu,Zhichao Huang,Tao Li,Sitong Liu,Ningxin Peng,Shuaijie She,Lu Xu,Nuo Xu,Sen Yang,Runsheng Yu,Yiming Yu,Liehao Zou,Hang Li,Lu Lu,Yuxuan Wang,Yonghui Wu*

Main category: cs.CL

TL;DR: 本文介绍了Seed-X，这是一个由指令和推理模型组成的开源大型语言模型家族，通过7B参数规模推动翻译能力的极限。Seed-X在28种语言中实现了与领先闭源模型（包括Gemini-2.5和GPT-4o）相当的性能，并在自动指标和人工评估中显著优于更大的开源模型。


<details>
  <summary>Details</summary>
Motivation: Multilingual translation stands as a challenging task for large language models (LLMs) to handle intricate language patterns and stilted translations that arise in automated translations.

Method: The base model is pre-trained on a diverse, high-quality dataset encompassing both monolingual and bilingual content across 28 languages, harnessing the full potential of multilingual data. The instruct model is then finetuned to translate by Chain-of-Thought (CoT) reasoning and further enhanced through reinforcement learning (RL) to achieve better generalization across diverse language pairs.

Result: Seed-X achieves performance comparable to leading closed-source models, including Gemini-2.5 and GPT-4o, across 28 languages, and significantly outperforms larger open-source models in both automatic metrics and human evaluations.

Conclusion: Seed-X achieves performance comparable to leading closed-source models, including Gemini-2.5 and GPT-4o, across 28 languages, and significantly outperforms larger open-source models in both automatic metrics and human evaluations. We share the best practices through our optimization process, and make the parameter public available for advancing translation research and applications.

Abstract: Multilingual translation stands as a challenging task for large language
models (LLMs) to handle intricate language patterns and stilted translations
that arise in automated translations. In this paper, we introduce Seed-X, a
family of open-source LLMs comprising instruct and reasoning models, pushing
the limits of translation capability with 7B parameter size. The base model is
pre-trained on a diverse, high-quality dataset encompassing both monolingual
and bilingual content across 28 languages, harnessing the full potential of
multilingual data. The instruct model is then finetuned to translate by
Chain-of-Thought (CoT) reasoning and further enhanced through reinforcement
learning (RL) to achieve better generalization across diverse language pairs.
Seed-X achieves performance comparable to leading closed-source models,
including Gemini-2.5 and GPT-4o, across 28 languages, and significantly
outperforms larger open-source models in both automatic metrics and human
evaluations. We share the best practices through our optimization process, and
make the parameter public available for advancing translation research and
applications.

</details>


### [18] [CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer](https://arxiv.org/abs/2507.13655)
*Teerapong Panboonyuen*

Main category: cs.CL

TL;DR: 本文介绍了CU-ICU方法，通过稀疏微调和少量提示来提升大型语言模型在ICU环境中的表现，结果表明其在准确性和可解释性方面有显著提升。


<details>
  <summary>Details</summary>
Motivation: 将大型语言模型集成到医疗等专业领域面临独特的挑战，包括领域适应和有限的标记数据。

Method: CU-ICU方法利用Text-to-Text Transfer Transformer (T5)架构，采用稀疏微调方法，结合少量提示和选择性参数更新，以最小的监督实现高效适应。

Result: 在关键的ICU任务中，如早期败血症检测、死亡率预测和临床笔记生成，CU-ICU的表现优于标准微调方法，显著提高了预测准确性与可解释性。

Conclusion: CU-ICU作为一种可扩展、低开销的解决方案，能够提供准确且可解释的临床决策支持，在现实世界的ICU环境中具有应用价值。

Abstract: Integrating large language models into specialized domains like healthcare
presents unique challenges, including domain adaptation and limited labeled
data. We introduce CU-ICU, a method for customizing unsupervised
instruction-finetuned language models for ICU datasets by leveraging the
Text-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse
fine-tuning approach that combines few-shot prompting with selective parameter
updates, enabling efficient adaptation with minimal supervision. Our evaluation
across critical ICU tasks--early sepsis detection, mortality prediction, and
clinical note generation--demonstrates that CU-ICU consistently improves
predictive accuracy and interpretability over standard fine-tuning methods.
Notably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and
a 20% enhancement in generating clinically relevant explanations while updating
fewer than 1% of model parameters in its most efficient configuration. These
results establish CU-ICU as a scalable, low-overhead solution for delivering
accurate and interpretable clinical decision support in real-world ICU
environments.

</details>


### [19] [KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs](https://arxiv.org/abs/2507.13666)
*Woo-Chan Kim,Ji-Hoon Park,Seong-Whan Lee*

Main category: cs.CL

TL;DR: 提出了一种名为KiC的新框架，用于高效的成本自由形式文本生成。KiC通过识别弱模型输出中最具代表性的答案并评估其他响应与之的语义对齐度，决定是否接受弱模型的输出或升级到更强的模型。实验表明，KiC在保持高准确率的同时显著降低了API成本。


<details>
  <summary>Details</summary>
Motivation: Existing cascade approaches struggle to select a reliable representative response and assess the overall reliability of free-form outputs, as they rely on exact text matching.

Method: KiC identifies the most representative answer among multiple outputs from a weaker model and evaluates the semantic alignment of other responses with it. Based on the degree of alignment, KiC determines whether to accept the weaker model's output or escalate to a stronger model.

Result: Experiments on three free-form text generation benchmarks show that KiC achieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81 percent on average, and even outperforms GPT-4 in a specific benchmark.

Conclusion: KiC achieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81 percent on average, and even outperforms GPT-4 in a specific benchmark.

Abstract: Large language models (LLMs) have demonstrated state-of-the-art performance
across a wide range of natural language processing tasks. However,
high-performing models are typically accessible only via APIs, incurring
substantial inference costs. Cascade methods address this by initially
employing a cheaper model and escalating to a stronger one only when necessary.
Nevertheless, existing cascade approaches struggle to select a reliable
representative response and assess the overall reliability of free-form
outputs, as they rely on exact text matching. To overcome these limitations, we
propose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient
free-form text generation. KiC identifies the most representative answer among
multiple outputs from a weaker model and evaluates the semantic alignment of
other responses with it. Based on the degree of alignment, KiC determines
whether to accept the weaker model's output or escalate to a stronger model.
Experiments on three free-form text generation benchmarks show that KiC
achieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81
percent on average, and even outperforms GPT-4 in a specific benchmark.

</details>


### [20] [LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues](https://arxiv.org/abs/2507.13681)
*Haoyang Li,Zhanchao Xu,Yiming Li,Xuejia Chen,Darian Li,Anxin Tian,Qingfa Xiao,Cheng Deng,Jun Wang,Qing Li,Lei Chen,Mingxuan Yuan*

Main category: cs.CL

TL;DR: LoopServe是一种用于多轮对话中大型语言模型的自适应双阶段推理加速框架，通过在线稀疏化和渐进式键值压缩提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有的加速方法要么压缩上下文，要么优化键值缓存，但它们通常依赖于固定或基于位置的启发式方法，这些方法难以适应实际多轮对话中的动态和不可预测的模式。

Method: LoopServe引入了两种主要创新：在预填充阶段进行在线稀疏化，动态选择每个新输入中最重要的一部分注意力矩阵；在解码阶段使用渐进式键值压缩，根据最近生成的输出标记自适应地维护相关且高效的缓存。

Result: LoopServe在多个多轮数据集上进行了广泛的实验，结果表明其效果优于现有基线，并显著加速了LLM的推理。

Conclusion: LoopServe在多轮对话中显著提高了大型语言模型的推理速度，并在各种长上下文对话任务中表现出色。

Abstract: Multi-turn dialogues are essential in many real-world applications of large
language models, such as chatbots and virtual assistants. As conversation
histories become longer, existing large language models face increasing
computational and memory challenges, which hinder their ability to provide
efficient and responsive interactions. Most current acceleration methods either
compress the context or optimize key value caching, but they often rely on
fixed or position-based heuristics that do not adapt well to the dynamic and
unpredictable patterns found in actual multi-turn conversations. In this paper,
we present LoopServe, an adaptive dual-phase inference acceleration framework
for large language models in multi-turn dialogues. LoopServe introduces two
main innovations. First, it performs online sparsification during the
prefilling phase by dynamically selecting the most important parts of the
attention matrix for each new input. Second, it uses progressive key value
compression during decoding by adaptively maintaining a relevant and efficient
cache based on the most recently generated output tokens. We also propose a
\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new
benchmark} with eleven multi-turn datasets that reflect realistic query
positions and conversational dependencies. Extensive experiments demonstrate
that LoopServe consistently achieves superior effectiveness compared to
existing baselines and significantly accelerates LLM inference across a wide
range of long-context dialogue tasks.

</details>


### [21] [Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations](https://arxiv.org/abs/2507.13705)
*Cedric Waterschoot,Nava Tintarev,Francesco Barile*

Main category: cs.CL

TL;DR: This paper evaluates the use of Large Language Models (LLMs) in Group Recommender Systems (GRS) by comparing their recommendations and explanations to social choice-based aggregation strategies, revealing potential inefficiencies and issues with transparency.


<details>
  <summary>Details</summary>
Motivation: To evaluate the effectiveness of LLMs as decision-makers and explanation generators in Group Recommender Systems (GRS).

Method: Comparing LLM-generated recommendations and explanations to social choice-based aggregation strategies.

Result: LLM-generated recommendations resembled ADD aggregation, while explanations referred to averaging ratings. Group structure did not impact recommendations. LLMs used additional criteria like user similarity, diversity, or undefined popularity metrics.

Conclusion: LLMs in GRS pipeline have implications for standard aggregation strategies, and their explanations may lack transparency and explainability.

Abstract: Large Language Models (LLMs) are increasingly being implemented as joint
decision-makers and explanation generators for Group Recommender Systems (GRS).
In this paper, we evaluate these recommendations and explanations by comparing
them to social choice-based aggregation strategies. Our results indicate that
LLM-generated recommendations often resembled those produced by Additive
Utilitarian (ADD) aggregation. However, the explanations typically referred to
averaging ratings (resembling but not identical to ADD aggregation). Group
structure, uniform or divergent, did not impact the recommendations.
Furthermore, LLMs regularly claimed additional criteria such as user or item
similarity, diversity, or used undefined popularity metrics or thresholds. Our
findings have important implications for LLMs in the GRS pipeline as well as
standard aggregation strategies. Additional criteria in explanations were
dependent on the number of ratings in the group scenario, indicating potential
inefficiency of standard aggregation methods at larger item set sizes.
Additionally, inconsistent and ambiguous explanations undermine transparency
and explainability, which are key motivations behind the use of LLMs for GRS.

</details>


### [22] [The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction](https://arxiv.org/abs/2507.13732)
*Guillaume Zambrano*

Main category: cs.CL

TL;DR: 研究通过机器学习分析法国上诉法院的判决，发现法官的个人决策模式对案件结果有显著影响，支持法律现实主义观点。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨人类法官在法律决策中的作用，挑战法官是中立变量、统一适用法律的假设。

Method: 研究使用机器学习预测法国上诉法院儿童身体监护权的结果，比较了基于个别法官过去裁决的专门模型与基于聚合数据的通用模型。预测流程结合了大型语言模型（LLMs）和机器学习模型（RF、XGB 和 SVC）。

Result: 专门模型的预测准确性高于通用模型，最高F1得分为92.85%，而通用模型为82.63%。专门模型捕捉到稳定的个人模式，这些模式无法转移到其他法官。

Conclusion: 研究结果表明，法官的个人决策模式对案件结果有显著影响，这支持了法律现实主义的观点，即司法身份在法律结果中起着可衡量的作用。

Abstract: This study examines the role of human judges in legal decision-making by
using machine learning to predict child physical custody outcomes in French
appellate courts. Building on the legal realism-formalism debate, we test
whether individual judges' decision-making patterns significantly influence
case outcomes, challenging the assumption that judges are neutral variables
that apply the law uniformly. To ensure compliance with French privacy laws, we
implement a strict pseudonymization process. Our analysis uses 18,937 living
arrangements rulings extracted from 10,306 cases. We compare models trained on
individual judges' past rulings (specialist models) with a judge-agnostic model
trained on aggregated data (generalist models). The prediction pipeline is a
hybrid approach combining large language models (LLMs) for structured feature
extraction and ML models for outcome prediction (RF, XGB and SVC). Our results
show that specialist models consistently achieve higher predictive accuracy
than the general model, with top-performing models reaching F1 scores as high
as 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x
more samples. Specialist models capture stable individual patterns that are not
transferable to other judges. In-Domain and Cross-Domain validity tests provide
empirical support for legal realism, demonstrating that judicial identity plays
a measurable role in legal outcomes. All data and code used will be made
available.

</details>


### [23] [PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs](https://arxiv.org/abs/2507.13743)
*Maluna Menke,Thilo Hagendorff*

Main category: cs.CL

TL;DR: 研究评估了两种参数高效的微调技术（LoRA 和软提示微调）作为全模型微调的轻量级替代方案，以减轻大型语言模型中的偏见。使用 WinoQueer 基准测试，我们量化了三种开源 LLM 中的偏见，并观察到基准偏见分数高达 98（满分 100），其中 50 表示中立。在整理过的 QueerNews 语料库上使用 LoRA（<0.1% 的额外参数）可以将这些分数减少多达 50 分，并将中立性从几乎 0% 提高到最高 36%。软提示微调（10 个虚拟标记）只带来了微小的改进。这些发现表明，LoRA 可以在计算量最小的情况下带来有意义的公平性提升。作者提倡更广泛地采用社区指导的 PEFT，创建更大的由酷儿撰写的语料库，并超越 WinoQueer 的丰富评估套件，同时进行持续审计以保持 LLM 的包容性。


<details>
  <summary>Details</summary>
Motivation: Large Language Models (LLMs) frequently reproduce the gender- and sexual-identity prejudices embedded in their training corpora, leading to outputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of great importance.

Method: We evaluate two parameter-efficient fine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt tuning - as lightweight alternatives to full-model fine-tuning for mitigating biases in LLMs. Using the WinoQueer benchmark, we quantify bias in three open-source LLMs and observe baseline bias scores reaching up to 98 (out of 100) across a range of queer identities defined by gender and/or sexual orientation.

Result: Fine-tuning with LoRA (< 0.1% additional parameters) on a curated QueerNews corpus reduces those scores by up to 50 points and raises neutrality from virtually 0% to as much as 36%. Soft-prompt tuning (10 virtual tokens) delivers only marginal improvements.

Conclusion: LoRA can deliver meaningful fairness gains with minimal computation. We advocate broader adoption of community-informed PEFT, the creation of larger queer-authored corpora, and richer evaluation suites beyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.

Abstract: Large Language Models (LLMs) frequently reproduce the gender- and
sexual-identity prejudices embedded in their training corpora, leading to
outputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of
great importance. To achieve this, we evaluate two parameter-efficient
fine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt
tuning - as lightweight alternatives to full-model fine-tuning for mitigating
such biases. Using the WinoQueer benchmark, we quantify bias in three
open-source LLMs and observe baseline bias scores reaching up to 98 (out of
100) across a range of queer identities defined by gender and/or sexual
orientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%
additional parameters) on a curated QueerNews corpus reduces those scores by up
to 50 points and raises neutrality from virtually 0% to as much as 36%.
Soft-prompt tuning (10 virtual tokens) delivers only marginal improvements.
These findings show that LoRA can deliver meaningful fairness gains with
minimal computation. We advocate broader adoption of community-informed PEFT,
the creation of larger queer-authored corpora, and richer evaluation suites
beyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.

</details>


### [24] [Innocence in the Crossfire: Roles of Skip Connections in Jailbreaking Visual Language Models](https://arxiv.org/abs/2507.13761)
*Palash Nandi,Maithili Joshi,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文研究了视觉语言模型对提示设计的敏感性如何导致不当内容的生成，并提出了一个有效提高越狱成功率的框架。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨语言模型对提示设计的敏感性是否可以被用来生成不当内容，特别是在多模态环境下，以揭示VLMs的潜在漏洞。

Method: 本文通过分析三个关键因素（详细视觉信息、对抗样本和正面开头短语）对成功越狱的影响，研究了VLMs中不当内容生成的机制，并提出了一种利用VLM内部层间跳跃连接的框架来提高越狱成功率。

Result: 研究发现，虽然VLMs在单模态设置下可以可靠地区分良性与有害输入，但在多模态环境中这种能力显著下降。三个因素独立地能够触发越狱，且少量上下文示例（如三个）即可促使模型生成不当输出。此外，即使使用良性图像，提出的框架也能显著提高越狱成功率。

Conclusion: 本文结论表明，视觉语言模型（VLMs）在多模态环境下对提示设计的敏感性可能导致不当内容的生成，且这种漏洞具有复杂性和隐蔽性。

Abstract: Language models are highly sensitive to prompt formulations - small changes
in input can drastically alter their output. This raises a critical question:
To what extent can prompt sensitivity be exploited to generate inapt content?
In this paper, we investigate how discrete components of prompt design
influence the generation of inappropriate content in Visual Language Models
(VLMs). Specifically, we analyze the impact of three key factors on successful
jailbreaks: (a) the inclusion of detailed visual information, (b) the presence
of adversarial examples, and (c) the use of positively framed beginning
phrases. Our findings reveal that while a VLM can reliably distinguish between
benign and harmful inputs in unimodal settings (text-only or image-only), this
ability significantly degrades in multimodal contexts. Each of the three
factors is independently capable of triggering a jailbreak, and we show that
even a small number of in-context examples (as few as three) can push the model
toward generating inappropriate outputs. Furthermore, we propose a framework
that utilizes a skip-connection between two internal layers of the VLM, which
substantially increases jailbreak success rates, even when using benign images.
Finally, we demonstrate that memes, often perceived as humorous or harmless,
can be as effective as toxic visuals in eliciting harmful content, underscoring
the subtle and complex vulnerabilities of VLMs.

</details>


### [25] [An Enhanced Model-based Approach for Short Text Clustering](https://arxiv.org/abs/2507.13793)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Xuemeng Song,Tian Gan,Liqiang Nie*

Main category: cs.CL

TL;DR: 本文提出了一种改进的GSDMM+算法，用于解决短文本聚类中的稀疏性和高维度问题，并通过优化聚类粒度提升了聚类效果。


<details>
  <summary>Details</summary>
Motivation: 由于短文本数据具有稀疏性、大规模和高维度的特点，传统的文本聚类方法面临挑战。此外，表示学习的计算强度也增加了运行时间。因此，需要一种更高效的短文本聚类方法。

Method: 本文提出了GSDMM+算法，该算法基于GSDMM进行改进，通过减少初始化噪声、自适应调整词权重以及策略性聚类合并来优化性能。

Result: 实验结果表明，GSDMM+算法在处理短文本聚类任务中表现出更高的效率和更好的效果，能够揭示更多的主题相关信息。

Conclusion: 本文提出了一种改进的GSDMM+算法，能够有效处理短文本的稀疏性和高维度问题，并通过策略性聚类合并优化了聚类粒度。实验结果表明该方法在效率和效果上优于传统和最先进的方法。

Abstract: Short text clustering has become increasingly important with the popularity
of social media like Twitter, Google+, and Facebook. Existing methods can be
broadly categorized into two paradigms: topic model-based approaches and deep
representation learning-based approaches. This task is inherently challenging
due to the sparse, large-scale, and high-dimensional characteristics of the
short text data. Furthermore, the computational intensity required by
representation learning significantly increases the running time. To address
these issues, we propose a collapsed Gibbs Sampling algorithm for the Dirichlet
Multinomial Mixture model (GSDMM), which effectively handles the sparsity and
high dimensionality of short texts while identifying representative words for
each cluster. Based on several aspects of GSDMM that warrant further
refinement, we propose an improved approach, GSDMM+, designed to further
optimize its performance. GSDMM+ reduces initialization noise and adaptively
adjusts word weights based on entropy, achieving fine-grained clustering that
reveals more topic-related information. Additionally, strategic cluster merging
is employed to refine clustering granularity, better aligning the predicted
distribution with the true category distribution. We conduct extensive
experiments, comparing our methods with both classical and state-of-the-art
approaches. The experimental results demonstrate the efficiency and
effectiveness of our methods. The source code for our model is publicly
available at https://github.com/chehaoa/VEMC.

</details>


### [26] [Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models](https://arxiv.org/abs/2507.13827)
*Hosein Azarbonyad,Zi Long Zhu,Georgios Cheirmpos,Zubair Afzal,Vikrant Yadav,Georgios Tsatsaronis*

Main category: cs.CL

TL;DR: 本文提出两种方法从科学文章中提取关键概念和贡献，以问答对的形式呈现。一种方法依赖于文章内容，另一种方法利用知识图谱。评估结果显示基于知识图谱的方法效果更好，且在科学语料库上微调实体关系提取模型是关键。


<details>
  <summary>Details</summary>
Motivation: 学者在决定阅读一篇文章或将其纳入自己的研究时，常常需要快速识别和理解其主要思想。因此，我们旨在从科学文章中提取这些关键概念和贡献，以问答对的形式呈现。

Method: 我们提出了两种生成问答对的方法。第一种方法涉及选择显著段落，使用大型语言模型生成问题，根据获得有意义答案的可能性对这些问题进行排序，并随后生成答案。第二种方法利用知识图谱进行问答生成，通过在科学文章上微调实体关系提取模型来构建知识图谱，并采用显著三元组提取方法选择每个文章中最相关的实体关系。

Result: 我们的评估表明，基于知识图谱的方法能够有效捕捉文章中的主要思想。此外，我们的研究结果表明，在科学语料库上微调实体关系提取模型对于从这些文档中提取高质量的三元组至关重要。

Conclusion: 我们的评估表明，基于知识图谱的方法有效地捕捉了文章中讨论的主要思想。此外，我们的研究结果表明，在科学语料库上微调实体关系提取模型对于从这些文档中提取高质量的三元组至关重要。

Abstract: When deciding to read an article or incorporate it into their research,
scholars often seek to quickly identify and understand its main ideas. In this
paper, we aim to extract these key concepts and contributions from scientific
articles in the form of Question and Answer (QA) pairs. We propose two distinct
approaches for generating QAs. The first approach involves selecting salient
paragraphs, using a Large Language Model (LLM) to generate questions, ranking
these questions by the likelihood of obtaining meaningful answers, and
subsequently generating answers. This method relies exclusively on the content
of the articles. However, assessing an article's novelty typically requires
comparison with the existing literature. Therefore, our second approach
leverages a Knowledge Graph (KG) for QA generation. We construct a KG by
fine-tuning an Entity Relationship (ER) extraction model on scientific articles
and using it to build the graph. We then employ a salient triplet extraction
method to select the most pertinent ERs per article, utilizing metrics such as
the centrality of entities based on a triplet TF-IDF-like measure. This measure
assesses the saliency of a triplet based on its importance within the article
compared to its prevalence in the literature. For evaluation, we generate QAs
using both approaches and have them assessed by Subject Matter Experts (SMEs)
through a set of predefined metrics to evaluate the quality of both questions
and answers. Our evaluations demonstrate that the KG-based approach effectively
captures the main ideas discussed in the articles. Furthermore, our findings
indicate that fine-tuning the ER extraction model on our scientific corpus is
crucial for extracting high-quality triplets from such documents.

</details>


### [27] [The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words](https://arxiv.org/abs/2507.13839)
*Lizhi Ma,Tong Zhao,Shuai Zhang,Nirui Song,Hongliang He,Anqi Li,Ran Feng,Huachuan Qiu,Jingsong Ma,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 本研究分析了汉语心理辅导互动中语言表达与抑郁和焦虑的关系，发现负面情绪词汇的频率与心理状态严重程度有关，但第一人称单数代词的使用频率没有显著变化。研究结果强调了文化和对话背景对心理健康沟通中语言使用的影响。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨汉语心理辅导互动中语言表达与抑郁和焦虑心理状态之间的关系，特别是第一人称单数代词和负面情绪词汇的使用。

Method: 研究使用了一个包含735个在线心理咨询会话的语料库，并采用广义线性混合效应模型评估由LIWC软件量化的语言模式。

Result: 结果表明，负面情绪词汇的频率与客户抑郁和焦虑症状的严重程度之间存在显著正相关。然而，与之前主要来自英语语境的研究结果不同，第一人称单数代词的使用频率并未显著变化。

Conclusion: 研究结果强调了文化和社会对话背景对心理健康沟通中语言使用的影响，为中文语境下的心理治疗实践提供了相关的心理语言学标记。

Abstract: This study explores the relationship between linguistic expressions and
psychological states of depression and anxiety within Chinese psycho-counseling
interactions, focusing specifically on the usage of first-person singular
pronouns and negative emotional words. Utilizing a corpus derived from 735
online counseling sessions, the analysis employed a general linear mixed-effect
model to assess linguistic patterns quantified by the Linguistic Inquiry and
Word Count (LIWC) software. Results indicate a significant positive correlation
between the frequency of negative emotional words and the severity of both
depressive and anxious states among clients. However, contrary to prior
findings predominantly derived from English-language contexts, the usage
frequency of first-person singular pronouns did not vary significantly with the
clients' psychological conditions. These outcomes are discussed within the
framework of cultural distinctions between collectivist Chinese contexts and
individualistic Western settings, as well as the interactive dynamics unique to
psycho-counseling conversations. The findings highlight the nuanced influence
of cultural and conversational contexts on language use in mental health
communications, providing insights into psycholinguistic markers relevant to
therapeutic practices in Chinese-speaking populations.

</details>


### [28] [Modeling Fair Play in Detective Stories with Language Models](https://arxiv.org/abs/2507.13841)
*Eitan Wagner,Renana Keydar,Omri Abend*

Main category: cs.CL

TL;DR: 本文提出了一种概率框架，用于定义侦探小说中的期望品质，并正式定义了公平游戏，设计了适当的度量标准。通过将框架应用于LLM生成的侦探故事进行验证，结果表明LLM生成的故事可能不可预测，但通常无法在惊喜和公平游戏之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 有效的故事讲述需要在满足读者先验期望和引入意外发展之间取得微妙的平衡。在侦探小说领域，这种张力被称为公平游戏，它包括作者和读者之间关于神秘故事可能的解决范围的隐含协议。

Method: 我们提出了一种概率框架，用于定义侦探小说中的期望品质，并正式定义了公平游戏，设计了适当的度量标准。

Result: 通过将框架应用于LLM生成的侦探故事进行验证，结果表明LLM生成的故事可能不可预测，但通常无法在惊喜和公平游戏之间取得平衡。

Conclusion: 结果表明，尽管LLM生成的故事可能不可预测，但它们通常无法在惊喜和公平游戏之间取得平衡，这极大地影响了它们的质量。

Abstract: Effective storytelling relies on a delicate balance between meeting the
reader's prior expectations and introducing unexpected developments. In the
domain of detective fiction, this tension is known as fair play, which includes
the implicit agreement between the writer and the reader as to the range of
possible resolutions the mystery story may have. In this work, we present a
probabilistic framework for detective fiction that allows us to define desired
qualities. Using this framework, we formally define fair play and design
appropriate metrics for it. Stemming from these definitions is an inherent
tension between the coherence of the story, which measures how much it ``makes
sense'', and the surprise it induces. We validate the framework by applying it
to LLM-generated detective stories. This domain is appealing since we have an
abundance of data, we can sample from the distribution generating the story,
and the story-writing capabilities of LLMs are interesting in their own right.
Results show that while LLM-generated stories may be unpredictable, they
generally fail to balance the trade-off between surprise and fair play, which
greatly contributes to their poor quality.

</details>


### [29] [InTraVisTo: Inside Transformer Visualisation Tool](https://arxiv.org/abs/2507.13858)
*Nicolò Brunello,Davide Rigamonti,Andrea Sassella,Vincenzo Scotti,Mark James Carman*

Main category: cs.CL

TL;DR: 本文介绍了一个名为InTraVisTo的工具，用于可视化基于Transformer的大型语言模型的内部状态和信息流，以帮助研究人员更好地理解模型的计算过程。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）的推理能力在过去几年中有了显著提高，但它们在生产中的使用仍然具有挑战性，因为它们的不可预测性以及期望行为与实际模型输出之间的差异。

Method: 引入了一个名为InTraVisTo的新工具，用于研究和追踪基于Transformer的LLM生成每个标记的计算过程。该工具通过解码每个层的标记嵌入来可视化Transformer模型的内部状态，并使用Sankey图来显示不同层之间各个组件之间的信息流。

Result: InTraVisTo提供了一种可视化方法，使研究人员能够探索Transformer模型的内部状态和信息流，从而更好地理解LLM的计算过程。

Conclusion: InTraVisTo旨在帮助研究人员和实践者更好地理解Transformer模型中的计算，从而揭示LLM使用的内部模式和推理过程。

Abstract: The reasoning capabilities of Large Language Models (LLMs) have increased
greatly over the last few years, as have their size and complexity.
Nonetheless, the use of LLMs in production remains challenging due to their
unpredictable nature and discrepancies that can exist between their desired
behavior and their actual model output. In this paper, we introduce a new tool,
InTraVisTo (Inside Transformer Visualisation Tool), designed to enable
researchers to investigate and trace the computational process that generates
each token in a Transformer-based LLM. InTraVisTo provides a visualization of
both the internal state of the Transformer model (by decoding token embeddings
at each layer of the model) and the information flow between the various
components across the different layers of the model (using a Sankey diagram).
With InTraVisTo, we aim to help researchers and practitioners better understand
the computations being performed within the Transformer model and thus to shed
some light on internal patterns and reasoning processes employed by LLMs.

</details>


### [30] [Label Unification for Cross-Dataset Generalization in Cybersecurity NER](https://arxiv.org/abs/2507.13870)
*Maciej Jalocha,Johan Hausted Schmidt,William Michelseen*

Main category: cs.CL

TL;DR: 研究探讨了网络安全命名实体识别中标签统一的问题，尝试通过多种模型结构来提升跨数据集的泛化能力，但结果表明这些方法效果有限。


<details>
  <summary>Details</summary>
Motivation: 由于网络安全命名实体识别领域缺乏标准化标签，使得数据集难以合并，因此需要进行标签统一以提高数据资源的可用性。

Method: 研究进行了粗粒度标签统一，并使用BiLSTM模型进行了成对的跨数据集评估。此外，还提出了多头模型和基于图的迁移模型作为替代架构。

Result: 结果表明，训练于统一数据集的模型在跨数据集时泛化能力较差。多头模型在权重共享下仅带来微小改进，而基于图的迁移模型在BERT-base-NER上没有显著性能提升。

Conclusion: 研究发现，统一的数据集在跨数据集泛化方面表现不佳。虽然多头模型在权重共享下提供了微小的改进，但基于图的迁移模型在BERT-base-NER上的表现没有显著提升。

Abstract: The field of cybersecurity NER lacks standardized labels, making it
challenging to combine datasets. We investigate label unification across four
cybersecurity datasets to increase data resource usability. We perform a
coarse-grained label unification and conduct pairwise cross-dataset evaluations
using BiLSTM models. Qualitative analysis of predictions reveals errors,
limitations, and dataset differences. To address unification limitations, we
propose alternative architectures including a multihead model and a graph-based
transfer model. Results show that models trained on unified datasets generalize
poorly across datasets. The multihead model with weight sharing provides only
marginal improvements over unified training, while our graph-based transfer
model built on BERT-base-NER shows no significant performance gains compared
BERT-base-NER.

</details>


### [31] [Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies](https://arxiv.org/abs/2507.13875)
*Carlos Mena,Pol Serra,Jacobo Romero,Abir Messaoudi,Jose Giraldo,Carme Armentano-Oller,Rodolfo Zevallos,Ivan Meza,Javier Hernando*

Main category: cs.CL

TL;DR: 本文研究了如何通过生成合成数据和利用真实数据来提高Catalan-Spanish代码切换的自动语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏专门的CS数据集，ASR性能受到限制，因此需要改进ASR以适应实际的CS模式。

Method: 本文探索了三种策略：生成合成CS数据、连接单语音频以及利用带有语言标记的真实CS数据。

Result: 结果表明，将少量合成CS数据与主导语言标记结合可以取得最佳的转录性能。

Conclusion: 本文通过生成合成的CS数据并与主导语言标记结合，提高了Catalan-Spanish CS的ASR性能。

Abstract: Code-switching (CS), the alternating use of two or more languages, challenges
automatic speech recognition (ASR) due to scarce training data and linguistic
similarities. The lack of dedicated CS datasets limits ASR performance, as most
models rely on monolingual or mixed-language corpora that fail to reflect
real-world CS patterns. This issue is critical in multilingual societies where
CS occurs in informal and formal settings. A key example is Catalan-Spanish CS,
widely used in media and parliamentary speeches. In this work, we improve ASR
for Catalan-Spanish CS by exploring three strategies: (1) generating synthetic
CS data, (2) concatenating monolingual audio, and (3) leveraging real CS data
with language tokens. We extract CS data from Catalan speech corpora and
fine-tune OpenAI's Whisper models, making them available on Hugging Face.
Results show that combining a modest amount of synthetic CS data with the
dominant language token yields the best transcription performance.

</details>


### [32] [Using LLMs to identify features of personal and professional skills in an open-response situational judgment test](https://arxiv.org/abs/2507.13881)
*Cole Walsh,Rodica Ivan,Muhammad Zafar Iqbal,Colleen Robb*

Main category: cs.CL

TL;DR: 本文探讨了使用大型语言模型从情境判断测试（SJTs）回答中提取相关特征的新方法，并通过Casper SJT验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 学术项目越来越认识到个人和专业技能的重要性，并需要可扩展的系统来测量、评估和发展这些技能。

Method: 本文提出了一种新的方法，利用大型语言模型（LLMs）从SJTs回答中提取与构念相关的特征。

Result: 本文通过Casper SJT展示了这种方法的有效性。

Conclusion: 本文为个人和专业技能的自动化评分奠定了基础，并提出了使用大型语言模型提取相关特征的新方法。

Abstract: Academic programs are increasingly recognizing the importance of personal and
professional skills and their critical role alongside technical expertise in
preparing students for future success in diverse career paths. With this
growing demand comes the need for scalable systems to measure, evaluate, and
develop these skills. Situational Judgment Tests (SJTs) offer one potential
avenue for measuring these skills in a standardized and reliable way, but
open-response SJTs have traditionally relied on trained human raters for
evaluation, presenting operational challenges to delivering SJTs at scale. Past
attempts at developing NLP-based scoring systems for SJTs have fallen short due
to issues with construct validity of these systems. In this article, we explore
a novel approach to extracting construct-relevant features from SJT responses
using large language models (LLMs). We use the Casper SJT to demonstrate the
efficacy of this approach. This study sets the foundation for future
developments in automated scoring for personal and professional skills.

</details>


### [33] [Political Leaning and Politicalness Classification of Texts](https://arxiv.org/abs/2507.13913)
*Matous Volf,Jakub Simko*

Main category: cs.CL

TL;DR: 本文通过构建多样化数据集和训练新模型，提高了政治倾向和政治性分类任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法创建了孤立的解决方案，在分布外文本上表现不佳，因此需要一种更通用的方法来解决这个问题。

Method: 本文综合了现有的数据集和模型，构建了一个多样化数据集，并通过留一法和留一出法进行广泛的基准测试，评估现有模型并训练新模型。

Result: 本文构建了一个多样化数据集，并训练了具有增强泛化能力的新模型，以提高在分布外文本上的性能。

Conclusion: 本文通过构建多样化的数据集并训练具有增强泛化能力的新模型，解决了现有方法在分布外文本上表现不佳的问题。

Abstract: This paper addresses the challenge of automatically classifying text
according to political leaning and politicalness using transformer models. We
compose a comprehensive overview of existing datasets and models for these
tasks, finding that current approaches create siloed solutions that perform
poorly on out-of-distribution texts. To address this limitation, we compile a
diverse dataset by combining 12 datasets for political leaning classification
and creating a new dataset for politicalness by extending 18 existing datasets
with the appropriate label. Through extensive benchmarking with leave-one-in
and leave-one-out methodologies, we evaluate the performance of existing models
and train new ones with enhanced generalization capabilities.

</details>


### [34] [The Levers of Political Persuasion with Conversational AI](https://arxiv.org/abs/2507.13919)
*Kobi Hackenburg,Ben M. Tappin,Luke Hewitt,Ed Saunders,Sid Black,Hause Lin,Catherine Fist,Helen Margetts,David G. Rand,Christopher Summerfield*

Main category: cs.CL

TL;DR: 该研究通过三个大规模实验评估了19个大型语言模型在707个政治问题上的说服力，并检查了466,769条模型陈述的事实准确性。结果显示，当前和未来AI的说服力主要来自后训练和提示方法，而不是个性化或增加模型规模。此外，这些方法提高了说服力，但也降低了事实准确性。


<details>
  <summary>Details</summary>
Motivation: 评估当前和未来AI的说服力来源，并检查其对事实准确性的影响。

Method: 进行了三个大规模实验，部署了19个大型语言模型，并检查了它们的陈述的事实准确性。

Result: 后训练和提示方法显著提高了说服力，但同时降低了事实准确性。

Conclusion: 当前和未来AI的说服力主要来自后训练和提示方法，而不是个性化或增加模型规模。

Abstract: There are widespread fears that conversational AI could soon exert
unprecedented influence over human beliefs. Here, in three large-scale
experiments (N=76,977), we deployed 19 LLMs-including some post-trained
explicitly for persuasion-to evaluate their persuasiveness on 707 political
issues. We then checked the factual accuracy of 466,769 resulting LLM claims.
Contrary to popular concerns, we show that the persuasive power of current and
near-future AI is likely to stem more from post-training and prompting
methods-which boosted persuasiveness by as much as 51% and 27%
respectively-than from personalization or increasing model scale. We further
show that these methods increased persuasion by exploiting LLMs' unique ability
to rapidly access and strategically deploy information and that, strikingly,
where they increased AI persuasiveness they also systematically decreased
factual accuracy.

</details>


### [35] [Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support](https://arxiv.org/abs/2507.13937)
*Jan Trienes,Anastasiia Derzhanskaia,Roland Schwarzkopf,Markus Mühling,Jörg Schlötterer,Christin Seifert*

Main category: cs.CL

TL;DR: Marcel 是一个轻量级且开源的对话代理，旨在支持潜在学生处理入学相关问题，提供快速和个性化的回答，同时减轻大学工作人员的工作负担。


<details>
  <summary>Details</summary>
Motivation: 为了提供快速和个性化的回答，同时减轻大学工作人员的工作负担，需要一种高效的对话代理系统。

Method: 我们采用检索增强生成来将答案扎根于大学资源，并为用户提供可验证的、上下文相关的信息。为了提高检索质量，我们引入了一个 FAQ 检索器，将用户的问题映射到知识库条目，允许管理员引导检索，并改进了标准密集/混合检索策略。

Result: 系统设计用于在资源受限的学术环境中轻松部署。我们详细介绍了系统架构，提供了其组件的技术评估，并报告了实际部署中的见解。

Conclusion: Marcel 是一个轻量级且开源的对话代理，旨在支持潜在学生处理入学相关问题，提供快速和个性化的回答，同时减轻大学工作人员的工作负担。

Abstract: We present Marcel, a lightweight and open-source conversational agent
designed to support prospective students with admission-related inquiries. The
system aims to provide fast and personalized responses, while reducing workload
of university staff. We employ retrieval-augmented generation to ground answers
in university resources and to provide users with verifiable, contextually
relevant information. To improve retrieval quality, we introduce an FAQ
retriever that maps user questions to knowledge-base entries, allowing
administrators to steer retrieval, and improving over standard dense/hybrid
retrieval strategies. The system is engineered for easy deployment in
resource-constrained academic settings. We detail the system architecture,
provide a technical evaluation of its components, and report insights from a
real-world deployment.

</details>


### [36] [Exploiting Primacy Effect To Improve Large Language Models](https://arxiv.org/abs/2507.13949)
*Bianca Raimondi,Maurizio Gabbrielli*

Main category: cs.CL

TL;DR: 本研究探讨了微调大型语言模型中的首因偏见，并通过重新排列响应选项来利用这种效应，从而在多项选择题回答中提高了性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在许多自然语言处理（NLP）任务中变得不可或缺，但它们表现出偏见，特别是位置偏见，如首因和近因效应，这可能会影响答案的准确性。

Method: 我们首先展示了微调会增强这种偏见，这可能是因为接触到了类似人类的模式。因此，我们战略性地利用这种效应，根据与查询的语义相似性重新排序响应选项，而无需了解正确答案。

Result: 实验结果表明，这种方法在多项选择题回答（MCQA）中显著提高了性能。

Conclusion: 我们的研究结果强调了偏见的双重性质，既可以是挑战也可以是机会，为有意识的模型设计和自然语言处理应用提供了见解。

Abstract: Large Language Models (LLMs) have become essential in many Natural Language
Processing (NLP) tasks, leveraging extensive pre-training and fine-tuning to
achieve high accuracy. However, like humans, LLMs exhibit biases, particularly
positional biases such as primacy and recency effects, which can influence the
accuracy of the answers. The primacy effect-where items presented first are
more likely to be remembered or selected-plays a key role in Multiple Choice
Question Answering (MCQA), where the order of answer options can affect
prediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We
first show that fine-tuning amplifies this bias, probably due to exposure to
human-like patterns. Hence, we strategically leverage this effect by reordering
response options based on semantic similarity to the query, without requiring
knowledge of the correct answer. Our experimental results show that this
approach significantly improves performance in MCQA. More generally, our
findings underscore the dual nature of biases as both challenges and
opportunities, offering insights for bias-aware model design and NLP
applications.

</details>


### [37] [Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need](https://arxiv.org/abs/2507.13966)
*Bhishma Dedhia,Yuval Kansal,Niraj K. Jha*

Main category: cs.CL

TL;DR: 本文提出了一种基于知识图谱的任务生成方法，通过微调语言模型来获取和组合领域概念以进行推理。实验表明，该方法在医学领域表现出色，并有望推动领域特定超级智能的发展。


<details>
  <summary>Details</summary>
Motivation: 传统的语言模型在跨领域泛化方面表现良好，但在获取深度领域专业知识所需的抽象方面存在不足。因此，需要一种自底向上的方法，通过学习将简单的领域概念组合成更复杂的概念来获取专业知识。知识图谱提供了这种组合结构，可以用于生成任务并训练模型进行推理。

Method: 本文提出了一种任务生成管道，该管道直接从知识图谱（KG）原始概念合成任务，并利用这些任务对语言模型进行微调，以获得领域特定的超级智能。此外，还引入了ICD-Bench评估套件，用于量化15个医学领域的推理能力。

Result: 实验结果表明，QwQ-Med-3在ICD-Bench类别上显著优于最先进的推理模型。进一步分析表明，QwQ-Med-3利用获取的原始概念，在ICD-Bench最困难的任务上扩大了性能差距。此外，在医学问答基准测试中，QwQ-Med-3展示了其专业知识可以转移到基础模型中，从而提升其性能。

Conclusion: 本文提出了一种从知识图谱（KG）原始概念生成任务的管道，通过微调语言模型来获取和组合这些概念以进行推理。实验表明，QwQ-Med-3在医学领域表现出色，并且能够将专业知识转移到基础模型中。最后，作者认为未来的人工通用智能（AGI）可能来自于高效领域特定超级智能代理的可组合交互。

Abstract: Language models traditionally used for cross-domain generalization have
recently demonstrated task-specific reasoning. However, their top-down training
approach on general corpora is insufficient for acquiring abstractions needed
for deep domain expertise. This may require a bottom-up approach that acquires
expertise by learning to compose simple domain concepts into more complex ones.
A knowledge graph (KG) provides this compositional structure, where domain
primitives are represented as head-relation-tail edges and their paths encode
higher-level concepts. We present a task generation pipeline that synthesizes
tasks directly from KG primitives, enabling models to acquire and compose them
for reasoning. We fine-tune language models on the resultant KG-grounded
curriculum to demonstrate domain-specific superintelligence. While broadly
applicable, we validate our approach in medicine, where reliable KGs exist.
Using a medical KG, we curate 24,000 reasoning tasks paired with thinking
traces derived from diverse medical primitives. We fine-tune the QwQ-32B model
on this curriculum to obtain QwQ-Med-3 that takes a step towards medical
superintelligence. We also introduce ICD-Bench, an evaluation suite to quantify
reasoning abilities across 15 medical domains. Our experiments demonstrate that
QwQ-Med-3 significantly outperforms state-of-the-art reasoning models on
ICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired
primitives to widen the performance gap on the hardest tasks of ICD-Bench.
Finally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3
transfers acquired expertise to enhance the base model's performance. While the
industry's approach to artificial general intelligence (AGI) emphasizes broad
expertise, we envision a future in which AGI emerges from the composable
interaction of efficient domain-specific superintelligent agents.

</details>


### [38] [Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic](https://arxiv.org/abs/2507.13977)
*Lilit Grigoryan,Nikolay Karpov,Enas Albasiri,Vitaly Lavrukhin,Boris Ginsburg*

Main category: cs.CL

TL;DR: 本文提出了一种通用的方法论来处理阿拉伯语的语音和文本，并训练了两个基于FastConformer架构的新模型，一个专门用于MSA，另一个是第一个统一的公共模型，用于MSA和CA。MSA模型在相关数据集上设定了新的基准，而统一模型在CA的带符号准确性方面达到了SOTA，并保持了MSA的良好性能。为了促进可重复性，我们开源了模型和训练配方。


<details>
  <summary>Details</summary>
Motivation: 由于阿拉伯语的复杂性，阿拉伯语自动语音识别（ASR）系统的发展面临重大挑战，且仅有少量公开的阿拉伯语ASR模型存在。尽管大部分研究集中在现代标准阿拉伯语（MSA）上，但对语言内部的变化关注较少。因此，本文旨在提出一种通用的方法论来解决阿拉伯语的独特挑战。

Method: 本文提出了一种通用的方法论来处理阿拉伯语的语音和文本，并基于FastConformer架构训练了两个新模型，一个专门用于MSA，另一个是第一个统一的公共模型，用于MSA和CA。

Result: MSA模型在相关数据集上设定了新的基准，而统一模型在CA的带符号准确性方面达到了SOTA，并保持了MSA的良好性能。

Conclusion: 本文提出了一种通用的方法论来处理阿拉伯语的语音和文本，训练了两个基于FastConformer架构的新模型，一个专门用于MSA，另一个是第一个统一的公共模型，用于MSA和CA。MSA模型在相关数据集上设定了新的基准，而统一模型在CA的带符号准确性方面达到了SOTA，并保持了MSA的良好性能。为了促进可重复性，我们开源了模型和训练配方。

Abstract: Despite Arabic being one of the most widely spoken languages, the development
of Arabic Automatic Speech Recognition (ASR) systems faces significant
challenges due to the language's complexity, and only a limited number of
public Arabic ASR models exist. While much of the focus has been on Modern
Standard Arabic (MSA), there is considerably less attention given to the
variations within the language. This paper introduces a universal methodology
for Arabic speech and text processing designed to address unique challenges of
the language. Using this methodology, we train two novel models based on the
FastConformer architecture: one designed specifically for MSA and the other,
the first unified public model for both MSA and Classical Arabic (CA). The MSA
model sets a new benchmark with state-of-the-art (SOTA) performance on related
datasets, while the unified model achieves SOTA accuracy with diacritics for CA
while maintaining strong performance for MSA. To promote reproducibility, we
open-source the models and their training recipes.

</details>


### [39] [Efficient Temporal Tokenization for Mobility Prediction with Large Language Models](https://arxiv.org/abs/2507.14017)
*Haoyu He,Haozheng Luo,Yan Chen,Qi R. Wang*

Main category: cs.CL

TL;DR: RHYTHM is a framework that uses large language models to predict human mobility patterns efficiently and accurately by partitioning trajectories into daily segments and using hierarchical attention.


<details>
  <summary>Details</summary>
Motivation: To improve the efficiency and accuracy of spatio-temporal prediction for human mobility using large language models.

Method: RHYTHM partitions trajectories into daily segments encoded as discrete tokens with hierarchical attention, and enriches token representations with pre-computed prompt embeddings via a frozen LLM.

Result: Evaluation on three real-world datasets shows a 2.4% improvement in accuracy, 5.0% increase on weekends, and 24.6% reduction in training time compared to state-of-the-art methods.

Conclusion: RHYTHM achieves significant computational efficiency and improves accuracy in predicting human mobility patterns.

Abstract: We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for
Human Mobility), a framework that leverages large language models (LLMs) as
spatio-temporal predictors and trajectory reasoners. RHYTHM partitions
trajectories into daily segments encoded as discrete tokens with hierarchical
attention, capturing both daily and weekly dependencies while substantially
reducing the sequence length. Token representations are enriched with
pre-computed prompt embeddings via a frozen LLM, enhancing the model's ability
to capture interdependencies without extensive computational overhead. By
freezing the LLM backbone, RHYTHM achieves significant computational
efficiency. Evaluation on three real-world datasets demonstrates a 2.4%
improvement in accuracy, 5.0% increase on weekends, and 24.6% reduction in
training time compared to state-of-the-art methods.

</details>


### [40] [CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis](https://arxiv.org/abs/2507.14022)
*Jianfei Li,Kevin Kam Fung Yuen*

Main category: cs.CL

TL;DR: 本文提出了一种基于认知成对比较的分类模型选择框架 (CPC-CMS)，用于文档级情感分析。通过评估标准的权重计算和加权决策矩阵，选择了最佳分类模型。实验表明，在排除时间因素的情况下，ALBERT 表现最佳，但在考虑时间消耗时，没有单一模型始终优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 为了在文档级情感分析中选择最佳分类模型，提出了一种基于认知成对比较的分类模型选择框架 (CPC-CMS)。

Method: 基于专家知识判断的认知成对比较 (CPC) 用于计算评估标准的权重，包括准确率、精确率、召回率、F1 分数、特异性、马修斯相关系数 (MCC)、科恩的 Kappa (Kappa) 和效率。选择朴素贝叶斯、线性支持向量分类 (LSVC)、随机森林、逻辑回归、极端梯度提升 (XGBoost)、长短期记忆 (LSTM) 和 ALBERT 作为分类基线模型，并构建一个加权决策矩阵来选择最佳分类模型。

Result: 在排除时间因素的评估结果中，ALBERT 在三个数据集中表现最佳；如果包括时间消耗，则没有单一模型始终优于其他模型。

Conclusion: CPC-CMS 可以应用于不同领域的其他分类应用。

Abstract: This study proposes the Cognitive Pairwise Comparison Classification Model
Selection (CPC-CMS) framework for document-level sentiment analysis. The CPC,
based on expert knowledge judgment, is used to calculate the weights of
evaluation criteria, including accuracy, precision, recall, F1-score,
specificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and
efficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random
Forest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long
Short-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from
Transformers (ALBERT) are chosen as classification baseline models. A weighted
decision matrix consisting of classification evaluation scores with respect to
criteria weights, is formed to select the best classification model for a
classification problem. Three open datasets of social media are used to
demonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,
for evaluation results excluding the time factor, ALBERT is the best for the
three datasets; if time consumption is included, no single model always
performs better than the other models. The CPC-CMS can be applied to the other
classification applications in different areas.

</details>


### [41] [Evaluating the Effectiveness of Cost-Efficient Large Language Models in Benchmark Biomedical Tasks](https://arxiv.org/abs/2507.14045)
*Israt Jahan,Md Tahmid Rahman Laskar,Chun Peng,Jimmy Huang*

Main category: cs.CL

TL;DR: 本文评估了多种大型语言模型在生物医学任务中的表现，发现不同模型在不同任务中各有优势，开源模型在某些情况下表现更佳。


<details>
  <summary>Details</summary>
Motivation: 本文旨在全面评估成本效益高的大型语言模型（LLMs）在多种生物医学任务中的表现，包括文本和图像模态。

Method: 我们评估了多种封闭源代码和开源大型语言模型（LLMs）在生物医学文本分类和生成、问答以及多模态图像处理等任务上的表现。

Result: 实验结果表明，没有一个LLM能在所有任务中持续优于其他模型。相反，不同的LLM在不同的任务中表现出色。虽然一些封闭源代码的LLM在特定任务上表现出强大的性能，但它们的开源版本在某些情况下甚至能取得更好的结果，同时具有更快的推理速度和更高的隐私性。

Conclusion: 我们的实验结果为选择最适合特定生物医学应用的模型提供了有价值的见解。

Abstract: This paper presents a comprehensive evaluation of cost-efficient Large
Language Models (LLMs) for diverse biomedical tasks spanning both text and
image modalities. We evaluated a range of closed-source and open-source LLMs on
tasks such as biomedical text classification and generation, question
answering, and multimodal image processing. Our experimental findings indicate
that there is no single LLM that can consistently outperform others across all
tasks. Instead, different LLMs excel in different tasks. While some
closed-source LLMs demonstrate strong performance on specific tasks, their
open-source counterparts achieve comparable results (sometimes even better),
with additional benefits like faster inference and enhanced privacy. Our
experimental results offer valuable insights for selecting models that are
optimally suited for specific biomedical applications.

</details>


### [42] [Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog](https://arxiv.org/abs/2507.14063)
*Lautaro Estienne,Gabriel Ben Zenou,Nona Naderi,Jackie Cheung,Pablo Piantanida*

Main category: cs.CL

TL;DR: 本文介绍了Collaborative Rational Speech Act (CRSA)，这是一种基于信息理论的RSA扩展，用于建模多轮对话，并在参照游戏和医患对话中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的RSA扩展在扩展到多轮协作场景时面临挑战，需要一种能够处理对话中双方都有私有信息并根据对话生成话语的方法。

Method: 引入了Collaborative Rational Speech Act (CRSA)，这是基于信息理论的RSA扩展，通过优化从率失真理论中适应的增益函数来建模多轮对话。

Result: CRSA在参照游戏和基于模板的医患对话中表现出色，显示出更一致、可解释和协作的行为。

Conclusion: CRSA展示了比现有基线更一致、可解释和协作的行为，为更实用和社交意识的语言代理铺平了道路。

Abstract: As AI systems take on collaborative roles, they must reason about shared
goals and beliefs-not just generate fluent language. The Rational Speech Act
(RSA) framework offers a principled approach to pragmatic reasoning, but
existing extensions face challenges in scaling to multi-turn, collaborative
scenarios. In this paper, we introduce Collaborative Rational Speech Act
(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn
dialog by optimizing a gain function adapted from rate-distortion theory. This
gain is an extension of the gain model that is maximized in the original RSA
model but takes into account the scenario in which both agents in a
conversation have private information and produce utterances conditioned on the
dialog. We demonstrate the effectiveness of CRSA on referential games and
template-based doctor-patient dialogs in the medical domain. Empirical results
show that CRSA yields more consistent, interpretable, and collaborative
behavior than existing baselines-paving the way for more pragmatic and socially
aware language agents.

</details>


### [43] [DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits](https://arxiv.org/abs/2507.14079)
*Garapati Keerthana,Manik Gupta*

Main category: cs.CL

TL;DR: 本文介绍了DENSE系统，旨在通过模拟医生在撰写进展笔记时参考过去会诊的方式来与临床文档工作流程对齐。该系统利用细粒度的笔记分类和时间对齐机制，以及临床信息检索策略，从当前和之前的访问中识别相关的内容，并提示大型语言模型生成临床一致且时间意识的进展笔记。评估结果显示，生成的笔记表现出强大的纵向保真度，实现了较高的时间对齐比率，能够恢复碎片化文档中的叙述连贯性，从而支持改进的下游任务，如摘要、预测建模和临床决策支持，为现实世界医疗环境中的LLM驱动的笔记合成提供了一种可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 进展笔记是电子健康记录（EHR）中最具有临床意义的产物之一，提供了患者病情、治疗和护理决策的时空基础见解。然而，它们在大规模EHR数据集中严重不足。例如，在广泛使用的医疗信息集市重症监护III（MIMIC-III）数据集中，只有约8.56%的医院访问包含进展笔记，导致纵向患者叙述存在空白。相比之下，该数据集包含多种其他类型的笔记，每种都捕捉了护理的不同方面。

Method: DENSE（从分散证据中记录进展笔记）系统，该系统通过模拟医生在撰写进展笔记时参考过去的会诊来与临床文档工作流程对齐。该系统引入了细粒度的笔记分类和时间对齐机制，将跨访问的异构笔记组织成结构化的、按时间顺序的输入。DENSE利用临床信息检索策略，从当前和之前的访问中识别时间和语义相关的相关内容。这些检索到的证据用于提示大型语言模型（LLM）生成临床一致且时间意识的进展笔记。

Result: 我们在一个有多个访问和完整进展笔记文档的患者队列上评估了DENSE。生成的笔记表现出强大的纵向保真度，实现了1.089的时间对齐比率，超过了原始笔记中观察到的连续性。

Conclusion: 通过恢复碎片化文档中的叙述连贯性，我们的系统支持改进的下游任务，如摘要、预测建模和临床决策支持，为现实世界医疗环境中的LLM驱动的笔记合成提供了一种可扩展的解决方案。

Abstract: Progress notes are among the most clinically meaningful artifacts in an
Electronic Health Record (EHR), offering temporally grounded insights into a
patient's evolving condition, treatments, and care decisions. Despite their
importance, they are severely underrepresented in large-scale EHR datasets. For
instance, in the widely used Medical Information Mart for Intensive Care III
(MIMIC-III) dataset, only about $8.56\%$ of hospital visits include progress
notes, leaving gaps in longitudinal patient narratives. In contrast, the
dataset contains a diverse array of other note types, each capturing different
aspects of care.
  We present DENSE (Documenting Evolving Progress Notes from Scattered
Evidence), a system designed to align with clinical documentation workflows by
simulating how physicians reference past encounters while drafting progress
notes. The system introduces a fine-grained note categorization and a temporal
alignment mechanism that organizes heterogeneous notes across visits into
structured, chronological inputs. At its core, DENSE leverages a clinically
informed retrieval strategy to identify temporally and semantically relevant
content from both current and prior visits. This retrieved evidence is used to
prompt a large language model (LLM) to generate clinically coherent and
temporally aware progress notes.
  We evaluate DENSE on a curated cohort of patients with multiple visits and
complete progress note documentation. The generated notes demonstrate strong
longitudinal fidelity, achieving a temporal alignment ratio of $1.089$,
surpassing the continuity observed in original notes. By restoring narrative
coherence across fragmented documentation, our system supports improved
downstream tasks such as summarization, predictive modeling, and clinical
decision support, offering a scalable solution for LLM-driven note synthesis in
real-world healthcare settings.

</details>


### [44] [Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track](https://arxiv.org/abs/2507.14096)
*Brian Ondov,William Xia,Kush Attal,Ishita Unde,Jerry He,Hoa Dang,Ian Soboroff,Dina Demner-Fushman*

Main category: cs.CL

TL;DR: 研究展示了使用大型语言模型将生物医学文献转化为通俗语言的潜力，同时突显了其不足之处，并强调了改进自动基准测试工具的必要性。


<details>
  <summary>Details</summary>
Motivation: Recent advances in language models have shown potential to adapt professional-facing biomedical literature to plain language, making it accessible to patients and caregivers. However, their unpredictability, combined with the high potential for harm in this domain, means rigorous evaluation is necessary. Our goals with this track were to stimulate research and to provide high-quality evaluation of the most promising systems.

Method: We hosted the Plain Language Adaptation of Biomedical Abstracts (PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included complete, sentence-level, rewriting of abstracts (Task 1) as well as identifying and replacing difficult terms (Task 2). For automatic evaluation of Task 1, we developed a four-fold set of professionally-written references. Submissions for both Tasks 1 and 2 were provided extensive manual evaluation from biomedical experts.

Result: Twelve teams spanning twelve countries participated in the track, with models from multilayer perceptrons to large pretrained transformers. In manual judgments of Task 1, top-performing models rivaled human levels of factual accuracy and completeness, but not simplicity or brevity. Automatic, reference-based metrics generally did not correlate well with manual judgments. In Task 2, systems struggled with identifying difficult terms and classifying how to replace them. When generating replacements, however, LLM-based systems did well in manually judged accuracy, completeness, and simplicity, though not in brevity.

Conclusion: PLABA track showed promise for using Large Language Models to adapt biomedical literature for the general public, while also highlighting their deficiencies and the need for improved automatic benchmarking tools.

Abstract: Objective: Recent advances in language models have shown potential to adapt
professional-facing biomedical literature to plain language, making it
accessible to patients and caregivers. However, their unpredictability,
combined with the high potential for harm in this domain, means rigorous
evaluation is necessary. Our goals with this track were to stimulate research
and to provide high-quality evaluation of the most promising systems.
  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts
(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included
complete, sentence-level, rewriting of abstracts (Task 1) as well as
identifying and replacing difficult terms (Task 2). For automatic evaluation of
Task 1, we developed a four-fold set of professionally-written references.
Submissions for both Tasks 1 and 2 were provided extensive manual evaluation
from biomedical experts.
  Results: Twelve teams spanning twelve countries participated in the track,
with models from multilayer perceptrons to large pretrained transformers. In
manual judgments of Task 1, top-performing models rivaled human levels of
factual accuracy and completeness, but not simplicity or brevity. Automatic,
reference-based metrics generally did not correlate well with manual judgments.
In Task 2, systems struggled with identifying difficult terms and classifying
how to replace them. When generating replacements, however, LLM-based systems
did well in manually judged accuracy, completeness, and simplicity, though not
in brevity.
  Conclusion: The PLABA track showed promise for using Large Language Models to
adapt biomedical literature for the general public, while also highlighting
their deficiencies and the need for improved automatic benchmarking tools.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [45] [Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning](https://arxiv.org/abs/2507.13362)
*Binbin Ji,Siddharth Agrawal,Qiance Tang,Yvonne Wu*

Main category: cs.CV

TL;DR: 本研究探讨了如何通过强化学习和结构化提示来提高视觉-语言模型的空间推理能力和泛化行为。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨如何通过强化学习和结构化提示来提高视觉-语言模型的空间推理能力和泛化行为。

Method: 我们通过链式思维提示和强化学习来研究视觉-语言模型的空间推理能力。我们评估了不同的提示策略，并使用SAT数据集对模型进行了微调，以改进空间推理能力。

Result: 我们发现基于场景图的结构化多阶段提示（SceneGraph CoT）显著提高了空间推理的准确性。此外，与监督微调相比，GRPO在Pass@1评估中取得了更高的准确性，并在分布外条件下表现出更好的鲁棒性。

Conclusion: 我们的研究结果表明，强化学习和结构化提示可以提高现代视觉-语言模型的空间推理能力和泛化行为。

Abstract: This study investigates the spatial reasoning capabilities of vision-language
models (VLMs) through Chain-of-Thought (CoT) prompting and reinforcement
learning. We begin by evaluating the impact of different prompting strategies
and find that simple CoT formats, where the model generates a reasoning step
before the answer, not only fail to help, but can even harm the model's
original performance. In contrast, structured multi-stage prompting based on
scene graphs (SceneGraph CoT) significantly improves spatial reasoning
accuracy. Furthermore, to improve spatial reasoning ability, we fine-tune
models using Group Relative Policy Optimization (GRPO) on the SAT dataset and
evaluate their performance on CVBench. Compared to supervised fine-tuning
(SFT), GRPO achieves higher accuracy on Pass@1 evaluations and demonstrates
superior robustness under out-of-distribution (OOD) conditions. In particular,
we find that SFT overfits to surface-level linguistic patterns and may degrade
performance when test-time phrasing changes (e.g., from "closer to" to "farther
from"). GRPO, on the other hand, generalizes more reliably and maintains stable
performance under such shifts. Our findings provide insights into how
reinforcement learning and structured prompting improve the spatial reasoning
capabilities and generalization behavior of modern VLMs. All code is open
source at: https://github.com/Yvonne511/spatial-vlm-investigator

</details>


### [46] [CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks](https://arxiv.org/abs/2507.13609)
*Yanan Wang,Julio Vizcarra,Zhi Li,Hao Niu,Mori Kurokawa*

Main category: cs.CV

TL;DR: 本文提出 CoTasks 框架，通过分解视频问题为四个实体级别任务，提高视频模型的链式推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的指令调优模型在高层次视频-文本对上进行训练，缺乏用于组合性、逐步推理的结构化注释。

Method: 提出了一种新的框架 CoTasks，将复杂视频问题分解为四个实体级别的基础任务：帧定位、实体跟踪、空间和时间关系提取。

Result: 在 NeXT-QA 基准测试中，CoTasks 显著提高了推理性能：LLaVA-video-7B 的平均 GPT-4 评估分数提高了 +3.3 分，Qwen2.5-VL-3B 提高了 +17.4 分，在因果 (+14.6)、时间 (+10.9) 和描述性 (+48.1) 子类别中也有显著提升。

Conclusion: CoTasks 是一种有效的结构化 CoT 式监督框架，可以提高组合视频推理能力。

Abstract: Despite recent progress in video large language models (VideoLLMs), a key
open challenge remains: how to equip models with chain-of-thought (CoT)
reasoning abilities grounded in fine-grained object-level video understanding.
Existing instruction-tuned models, such as the Qwen and LLaVA series, are
trained on high-level video-text pairs, often lacking structured annotations
necessary for compositional, step-by-step reasoning. We propose CoTasks:
Chain-of-Thought based Video Instruction Tuning Tasks, a new framework that
decomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)
into four entity-level foundational tasks: frame localization, entity tracking,
spatial and temporal relation extraction. By embedding these intermediate
CoT-style reasoning steps into the input, CoTasks enables models to explicitly
perform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA
benchmark show that CoTasks significantly enhance inference performance:
LLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and
Qwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal
(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the
effectiveness of CoTasks as a structured CoT-style supervision framework for
improving compositional video reasoning.

</details>


### [47] [Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions](https://arxiv.org/abs/2507.13773)
*Pu Jian,Donglei Yu,Wen Yang,Shuo Ren,Jiajun Zhang*

Main category: cs.CV

TL;DR: 本文提出ClearVQA基准，用于评估视觉语言模型在解决模糊性方面的交互能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要通过重述问题来解决视觉问答中的模糊性，但忽略了用户与视觉语言模型之间的互动特性。

Method: 本文提出了ClearVQA基准，以解决现有研究中忽视用户与视觉语言模型互动的问题。

Result: 本文引入了ClearVQA基准，涵盖了三种常见的模糊性类别和各种视觉问答场景。

Conclusion: 本文介绍了ClearVQA基准，用于评估视觉语言模型在解决模糊性方面的交互能力。

Abstract: In visual question answering (VQA) context, users often pose ambiguous
questions to visual language models (VLMs) due to varying expression habits.
Existing research addresses such ambiguities primarily by rephrasing questions.
These approaches neglect the inherently interactive nature of user interactions
with VLMs, where ambiguities can be clarified through user feedback. However,
research on interactive clarification faces two major challenges: (1)
Benchmarks are absent to assess VLMs' capacity for resolving ambiguities
through interaction; (2) VLMs are trained to prefer answering rather than
asking, preventing them from seeking clarification. To overcome these
challenges, we introduce \textbf{ClearVQA} benchmark, which targets three
common categories of ambiguity in VQA context, and encompasses various VQA
scenarios.

</details>


### [48] [NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining](https://arxiv.org/abs/2507.14119)
*Maksim Kuprashevich,Grigorii Alekseenko,Irina Tolstykh,Georgii Fedorov,Bulat Suleimanov,Vladimir Dokholyan,Aleksandr Gordeev*

Main category: cs.CV

TL;DR: 本文提出了一种自动化、模块化的管道，用于挖掘高保真图像编辑三元组，并发布了NHR-Edit数据集和Bagel-NHR-Edit模型，取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图像编辑助手需要数百万个三元组进行监督训练，但挖掘像素精确的例子很困难。缺乏稳健的自动编辑质量度量指标阻碍了大规模可靠自动化。

Method: 本文提出了一种自动化、模块化的管道，利用任务调优的Gemini验证器直接评分指令遵循性和美学，无需分割或接地模型。通过反转和组合引导扩大了挖掘集，使大规模高保真训练数据成为可能。

Result: 本文提出的系统能够自动化挖掘高保真三元组，提高了训练数据的规模和质量。NHR-Edit数据集在跨数据集评估中超越了所有公共替代方案，Bagel-NHR-Edit模型在实验中取得了最先进的性能。

Conclusion: 本文提出了一种自动化、模块化的管道，可以跨领域、分辨率、指令复杂性和风格挖掘高保真三元组。通过自动化最重复的注释步骤，该方法允许在没有人工标注的情况下实现大规模训练。此外，还发布了NHR-Edit数据集和Bagel-NHR-Edit模型，取得了最先进的性能。

Abstract: Recent advances in generative modeling enable image editing assistants that
follow natural language instructions without additional user input. Their
supervised training requires millions of triplets: original image, instruction,
edited image. Yet mining pixel-accurate examples is hard. Each edit must affect
only prompt-specified regions, preserve stylistic coherence, respect physical
plausibility, and retain visual appeal. The lack of robust automated
edit-quality metrics hinders reliable automation at scale. We present an
automated, modular pipeline that mines high-fidelity triplets across domains,
resolutions, instruction complexities, and styles. Built on public generative
models and running without human intervention, our system uses a task-tuned
Gemini validator to score instruction adherence and aesthetics directly,
removing any need for segmentation or grounding models. Inversion and
compositional bootstrapping enlarge the mined set by approximately 2.2x,
enabling large-scale high-fidelity training data. By automating the most
repetitive annotation steps, the approach allows a new scale of training
without human labeling effort. To democratize research in this
resource-intensive area, we release NHR-Edit: an open dataset of 358k
high-quality triplets. In the largest cross-dataset evaluation, it surpasses
all public alternatives. We also release Bagel-NHR-Edit, an open-source
fine-tuned Bagel model, which achieves state-of-the-art metrics in our
experiments.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [49] [Preprint: Did I Just Browse A Website Written by LLMs?](https://arxiv.org/abs/2507.13933)
*Sichang "Steven" He,Ramesh Govindan,Harsha V. Madhyastha*

Main category: cs.NI

TL;DR: This paper addresses the challenge of detecting LLM-dominant web content, proposing a reliable pipeline that achieves high accuracy. It highlights the increasing prevalence of such content and its potential impact on the web ecosystem.


<details>
  <summary>Details</summary>
Motivation: The increasing use of LLMs to generate web content with minimal human input has led to issues like plagiarism and hallucination, making it unreliable and unethical. Current detectors are insufficient for complex web content, necessitating the development of more effective solutions.

Method: The paper proposes a reliable and scalable pipeline that classifies entire websites by analyzing the outputs of an LLM text detector on multiple prose-like pages. It also collects two ground truth datasets to train and evaluate the detector.

Result: The proposed detector achieves 100% accuracy on two ground truth datasets. It successfully identifies a significant portion of LLM-dominant sites in large-scale web data, showing their growing prevalence and high search rankings.

Conclusion: LLM-dominant content is becoming increasingly prevalent and poses ethical and reliability concerns. The proposed pipeline effectively detects such content, highlighting its growing impact on the web ecosystem.

Abstract: Increasingly, web content is automatically generated by large language models
(LLMs) with little human input. We call this "LLM-dominant" content. Since LLMs
plagiarize and hallucinate, LLM-dominant content can be unreliable and
unethical. Yet, websites rarely disclose such content, and human readers
struggle to distinguish it. Thus, we must develop reliable detectors for
LLM-dominant content. However, state-of-the-art LLM detectors are insufficient,
because they perform well mainly on clean, prose-like text, while web content
has complex markup and diverse genres.
  We propose a highly reliable, scalable pipeline that classifies entire
websites. Instead of naively classifying text extracted from each page, we
classify each site based on an LLM text detector's outputs of multiple
prose-like pages. We train and evaluate our detector by collecting 2 distinct
ground truth datasets totaling 120 sites, and obtain 100% accuracies testing
across them. In the wild, we detect a sizable portion of sites as LLM-dominant
among 10k sites in search engine results and 10k in Common Crawl archives. We
find LLM-dominant sites are growing in prevalence and rank highly in search
results, raising questions about their impact on end users and the overall Web
ecosystem.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [50] [DyG-RAG: Dynamic Graph Retrieval-Augmented Generation with Event-Centric Reasoning](https://arxiv.org/abs/2507.13396)
*Qingyun Sun,Jiaqi Yuan,Shan He,Xiao Guan,Haonan Yuan,Xingcheng Fu,Jianxin Li,Philip S. Yu*

Main category: cs.IR

TL;DR: DyG-RAG是一种新的事件中心动态图检索增强生成框架，旨在捕捉和推理嵌入在非结构化文本中的时间知识。


<details>
  <summary>Details</summary>
Motivation: 现有Graph RAG方法在时间推理方面存在不足，无法建模现实世界事件的演变结构和顺序。

Method: DyG-RAG引入了动态事件单元(DEUs)，构建事件图以捕捉事件间的时空和因果依赖，并提出了时间链式思维策略进行时间定位的答案生成。

Result: DyG-RAG在时间问答基准测试中表现出色，能够解决标准RAG系统无法处理的复杂时间敏感查询。

Conclusion: DyG-RAG显著提高了三种典型时间推理问题的准确率和召回率，为更忠实和时间感知的生成铺平了道路。

Abstract: Graph Retrieval-Augmented Generation has emerged as a powerful paradigm for
grounding large language models with external structured knowledge. However,
existing Graph RAG methods struggle with temporal reasoning, due to their
inability to model the evolving structure and order of real-world events. In
this work, we introduce DyG-RAG, a novel event-centric dynamic graph
retrieval-augmented generation framework designed to capture and reason over
temporal knowledge embedded in unstructured text. To eliminate temporal
ambiguity in traditional retrieval units, DyG-RAG proposes Dynamic Event Units
(DEUs) that explicitly encode both semantic content and precise temporal
anchors, enabling accurate and interpretable time-aware retrieval. To capture
temporal and causal dependencies across events, DyG-RAG constructs an event
graph by linking DEUs that share entities and occur close in time, supporting
efficient and meaningful multi-hop reasoning. To ensure temporally consistent
generation, DyG-RAG introduces an event timeline retrieval pipeline that
retrieves event sequences via time-aware traversal, and proposes a Time
Chain-of-Thought strategy for temporally grounded answer generation. This
unified pipeline enables DyG-RAG to retrieve coherent, temporally ordered event
sequences and to answer complex, time-sensitive queries that standard RAG
systems cannot resolve. Extensive experiments on temporal QA benchmarks
demonstrate that DyG-RAG significantly improves the accuracy and recall of
three typical types of temporal reasoning questions, paving the way for more
faithful and temporal-aware generation. DyG-RAG is available at
https://github.com/RingBDStack/DyG-RAG.

</details>


### [51] [RAG-based Architectures for Drug Side Effect Retrieval in LLMs](https://arxiv.org/abs/2507.13822)
*Shad Nygren,Pinar Avci,Andre Daniels,Reza Rassol,Afshin Beheshti,Diego Galeano*

Main category: cs.IR

TL;DR: 本文提出了一种基于大型语言模型的药物副作用检测方法，通过整合全面的药物副作用知识，提高了检测的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 药物副作用是全球主要的健康问题，需要先进的方法来准确检测和分析。虽然大型语言模型（LLMs）提供了有前途的对话界面，但其固有的限制，包括对黑箱训练数据的依赖、易受幻觉影响以及缺乏领域特定知识，阻碍了它们在药理学监测等专业领域的可靠性。

Method: 我们提出了两种架构：检索增强生成（RAG）和GraphRAG，它们将全面的药物副作用知识整合到Llama 3 8B语言模型中。

Result: 通过在19,520个药物副作用关联（涵盖976种药物和3,851个副作用术语）上的广泛评估，我们的结果表明，GraphRAG在药物副作用检索中实现了接近完美的准确性。

Conclusion: 该框架提供了一个高精度且可扩展的解决方案，标志着在利用大型语言模型进行关键药物警戒应用方面的重要进展。

Abstract: Drug side effects are a major global health concern, necessitating advanced
methods for their accurate detection and analysis. While Large Language Models
(LLMs) offer promising conversational interfaces, their inherent limitations,
including reliance on black-box training data, susceptibility to
hallucinations, and lack of domain-specific knowledge, hinder their reliability
in specialized fields like pharmacovigilance. To address this gap, we propose
two architectures: Retrieval-Augmented Generation (RAG) and GraphRAG, which
integrate comprehensive drug side effect knowledge into a Llama 3 8B language
model. Through extensive evaluations on 19,520 drug side effect associations
(covering 976 drugs and 3,851 side effect terms), our results demonstrate that
GraphRAG achieves near-perfect accuracy in drug side effect retrieval. This
framework offers a highly accurate and scalable solution, signifying a
significant advancement in leveraging LLMs for critical pharmacovigilance
applications.

</details>


### [52] [SPARQL Query Generation with LLMs: Measuring the Impact of Training Data Memorization and Knowledge Injection](https://arxiv.org/abs/2507.13859)
*Aleksandr Gashkov,Aleksandr Perevalov,Maria Eltsova,Andreas Both*

Main category: cs.IR

TL;DR: 本文提出了一种新方法，用于评估大型语言模型在生成SPARQL查询方面的质量，并分析了训练数据对其性能的影响。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）在问答功能上的改进仍有很大空间，因此需要一种方法来评估它们的质量，并估计训练数据对QA质量的影响。

Method: 本文引入了一种新方法，通过在不同条件下从自然语言问题生成SPARQL查询来评估LLMs的质量：(1) 零样本SPARQL生成，(2) 知识注入，以及(3) “匿名化”知识注入。

Result: 该方法首次能够估计训练数据对LLMs提升的QA质量的影响，有助于识别方法的可移植性或良好结果是否主要因为基准已被包含在训练数据中。

Conclusion: 本文提出的方法具有可移植性、鲁棒性，并支持任何知识图谱，因此可以轻松应用于任何KGQA或LLM，从而生成关于实际LLM能力的一致见解。

Abstract: Nowadays, the importance of software with natural-language user interfaces
cannot be underestimated. In particular, in Question Answering (QA) systems,
generating a SPARQL query for a given natural-language question (often named
Query Building) from the information retrieved from the same question is the
central task of QA systems working over Knowledge Graphs (KGQA). Due to the
rise of Large Language Models (LLMs), they are considered a well-suited method
to increase the quality of the question-answering functionality, as there is
still a lot of room for improvement, aiming for enhanced quality and
trustworthiness. However, LLMs are trained on web data, where researchers have
no control over whether the benchmark or the knowledge graph was already
included in the training data. In this paper, we introduce a novel method that
evaluates the quality of LLMs by generating a SPARQL query from a
natural-language question under various conditions: (1) zero-shot SPARQL
generation, (2) with knowledge injection, and (3) with "anonymized" knowledge
injection. This enables us, for the first time, to estimate the influence of
the training data on the QA quality improved by LLMs. Ultimately, this will
help to identify how portable a method is or whether good results might mostly
be achieved because a benchmark was already included in the training data (cf.
LLM memorization). The developed method is portable, robust, and supports any
knowledge graph; therefore, it could be easily applied to any KGQA or LLM,
s.t., generating consistent insights into the actual LLM capabilities is
possible.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [53] [GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models](https://arxiv.org/abs/2507.13550)
*Eduardo C. Garrido-Merchán,Cristina Puente*

Main category: cs.AI

TL;DR: 本文提出了一种使用大型语言模型（LLMs）开发专家系统的控制且透明的方法，通过限制领域并采用结构化的基于提示的提取方法，生成可由人类专家验证和纠正的符号知识表示。这种方法保证了所开发专家系统的可解释性、可扩展性和可靠性。实验表明，该方法在事实准确性方面表现出色，并结合了LLMs的召回能力和符号系统的精确性，为敏感领域的可靠AI应用奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在知识系统中取得了成功，但它们存在幻觉或自信地生成错误或不可验证的事实等缺点。因此，需要一种更可靠的方法来开发专家系统。

Method: 本文提出了一种使用大型语言模型（LLMs）开发专家系统的控制且透明的方法，通过限制领域并采用结构化的基于提示的提取方法，生成可由人类专家验证和纠正的符号知识表示。

Result: 通过与Claude Sonnet 3.7和GPT-4.1的定量和定性实验，本文展示了生成的知识库在事实准确性和语义连贯性方面的强一致性。

Conclusion: 本文提出了一种使用大型语言模型（LLMs）开发专家系统的控制且透明的方法，通过限制领域并采用结构化的基于提示的提取方法，生成可由人类专家验证和纠正的符号知识表示。这种方法保证了所开发专家系统的可解释性、可扩展性和可靠性。实验表明，该方法在事实准确性方面表现出色，并结合了LLMs的召回能力和符号系统的精确性，为敏感领域的可靠AI应用奠定了基础。

Abstract: The development of large language models (LLMs) has successfully transformed
knowledge-based systems such as open domain question nswering, which can
automatically produce vast amounts of seemingly coherent information. Yet,
those models have several disadvantages like hallucinations or confident
generation of incorrect or unverifiable facts. In this paper, we introduce a
new approach to the development of expert systems using LLMs in a controlled
and transparent way. By limiting the domain and employing a well-structured
prompt-based extraction approach, we produce a symbolic representation of
knowledge in Prolog, which can be validated and corrected by human experts.
This approach also guarantees interpretability, scalability and reliability of
the developed expert systems. Via quantitative and qualitative experiments with
Claude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic
coherence on our generated knowledge bases. We present a transparent hybrid
solution that combines the recall capacity of LLMs with the precision of
symbolic systems, thereby laying the foundation for dependable AI applications
in sensitive domains.

</details>


### [54] [DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs](https://arxiv.org/abs/2507.13737)
*Ye Tian,Xiaoyuan Ren,Zihao Wang,Onat Gungor,Xiaofan Yu,Tajana Rosing*

Main category: cs.AI

TL;DR: DailyLLM 是一种基于大语言模型的高效活动日志生成和总结系统，能够利用常见的智能手机和智能手表传感器，在四个维度上整合上下文信息，并在性能和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的活动日志生成方法在准确性、效率和语义丰富性方面存在显著限制，因此需要一种更有效的解决方案。

Method: DailyLLM 引入了一个轻量级基于大语言模型（LLM）的框架，结合结构化提示和高效的特征提取，以实现高层次的活动理解。

Result: 实验表明，DailyLLM 在日志生成的 BERTScore 精度上比最先进的基线方法提高了 17%，同时推理速度几乎快了 10 倍。

Conclusion: DailyLLM 是一种高效且准确的活动日志生成和总结系统，能够利用智能手机和智能手表上的常见传感器进行跨四个维度的上下文活动信息整合。

Abstract: Rich and context-aware activity logs facilitate user behavior analysis and
health monitoring, making them a key research focus in ubiquitous computing.
The remarkable semantic understanding and generation capabilities of Large
Language Models (LLMs) have recently created new opportunities for activity log
generation. However, existing methods continue to exhibit notable limitations
in terms of accuracy, efficiency, and semantic richness. To address these
challenges, we propose DailyLLM. To the best of our knowledge, this is the
first log generation and summarization system that comprehensively integrates
contextual activity information across four dimensions: location, motion,
environment, and physiology, using only sensors commonly available on
smartphones and smartwatches. To achieve this, DailyLLM introduces a
lightweight LLM-based framework that integrates structured prompting with
efficient feature extraction to enable high-level activity understanding.
Extensive experiments demonstrate that DailyLLM outperforms state-of-the-art
(SOTA) log generation methods and can be efficiently deployed on personal
computers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM
achieves a 17% improvement in log generation BERTScore precision compared to
the 70B-parameter SOTA baseline, while delivering nearly 10x faster inference
speed.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [55] [Physical models realizing the transformer architecture of large language models](https://arxiv.org/abs/2507.13354)
*Zeqian Chen*

Main category: cs.LG

TL;DR: 本文从物理角度构建了基于变换器架构的大语言模型的物理模型，这些模型作为开放量子系统存在于Fock空间中。


<details>
  <summary>Details</summary>
Motivation: 作者认为我们对变换器是什么以及为什么在物理上起作用的理解存在理论上的空白。

Method: 本文从现代芯片的物理角度出发，构建了在Hilbert空间上的token Fock空间中的物理模型，以实现基于变换器架构的大语言模型。

Result: 本文构建了基于变换器架构的大语言模型的物理模型，这些模型作为开放量子系统存在于Fock空间中。

Conclusion: 本文从物理角度构建了基于变换器架构的大语言模型的物理模型，这些模型作为开放量子系统存在于Fock空间中。

Abstract: The introduction of the transformer architecture in 2017 (cf.\cite{VSP2017})
marked the most striking advancement in natural language processing. The
transformer is a model architecture relying entirely on an attention mechanism
to draw global dependencies between input and output. However, we believe there
is a gap in our theoretical understanding of what the transformer is, and why
it works physically. In this paper, from a physical perspective on modern
chips, we construct physical models in the Fock space over the Hilbert space of
tokens realizing large language models based on a transformer architecture as
open quantum systems. Our physical models underlie the transformer architecture
for large language models.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [56] [EdgeVLA: Efficient Vision-Language-Action Models](https://arxiv.org/abs/2507.14049)
*Paweł Budzianowski,Wesley Maa,Matthew Freed,Jingxiang Mo,Winston Hsiao,Aaron Xie,Tomasz Młoduchowski,Viraj Tipnis,Benjamin Bolte*

Main category: cs.RO

TL;DR: 本文提出了一种名为Edge VLA (EVLA) 的新方法，以提高视觉-语言-动作（VLA）模型的推理速度，同时保持其表征能力，并在边缘设备上实现实时性能。


<details>
  <summary>Details</summary>
Motivation: 尽管像OpenVLA这样的模型展示了这一范式的潜力，但在资源受限的移动操作系统上部署大规模VLM仍然是一个重大障碍。本文旨在解决这一问题，提高VLA模型的推理速度和内存效率。

Method: 通过两个关键创新实现：1) 消除末端执行器位置预测的自回归要求，使推理速度提高了7倍；2) 利用小型语言模型（SLMs）的效率，在计算需求显著减少的情况下展示了与大型模型相当的训练性能。

Result: 早期结果表明，EVLA在训练特性上与OpenVLA相当，同时在推理速度和内存效率方面有显著提升。

Conclusion: 本文介绍了Edge VLA (EVLA)，这是一种新型方法，旨在显著提高视觉-语言-动作（VLA）模型的推理速度。EVLA在保持这些模型表征能力的同时，实现了边缘设备上的实时性能。

Abstract: Vision-Language Models (VLMs) have emerged as a promising approach to address
the data scarcity challenge in robotics, enabling the development of
generalizable visuomotor control policies. While models like OpenVLA showcase
the potential of this paradigm, deploying large-scale VLMs on
resource-constrained mobile manipulation systems remains a significant hurdle.
This paper introduces Edge VLA (EVLA), a novel approach designed to
significantly enhance the inference speed of Vision-Language-Action (VLA)
models. EVLA maintains the representational power of these models while
enabling real-time performance on edge devices. We achieve this through two key
innovations: 1) Eliminating the autoregressive requirement for end-effector
position prediction, leading to a 7x speedup in inference, and 2) Leveraging
the efficiency of Small Language Models (SLMs), demonstrating comparable
training performance to larger models with significantly reduced computational
demands. Our early results demonstrate that EVLA achieves comparable training
characteristics to OpenVLA while offering substantial gains in inference speed
and memory efficiency. We release our model checkpoints and training
\href{https://github.com/kscalelabs/evla }{codebase} to foster further
research.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [57] [TexGS-VolVis: Expressive Scene Editing for Volume Visualization via Textured Gaussian Splatting](https://arxiv.org/abs/2507.13586)
*Kaiyuan Tang,Kuangshi Ai,Jun Han,Chaoli Wang*

Main category: cs.GR

TL;DR: TexGS-VolVis是一种用于体积可视化的新框架，通过使用带有纹理和阴影属性的2D高斯基元，实现了高质量、几何一致的风格化和增强的光照控制，并支持图像和文本驱动的非写实场景编辑。


<details>
  <summary>Details</summary>
Motivation: 现有VolVis方法依赖于复杂的预定义规则，且仅能传递单一风格，限制了其灵活性。传统3D高斯基元将几何和外观紧密耦合，导致风格化结果不佳。

Method: TexGS-VolVis结合了可微分高斯基元和预训练大模型，采用2D高斯基元扩展每个高斯基元的纹理和阴影属性，实现高质量、几何一致的风格化和增强的光照控制。此外，还开发了图像和文本驱动的非写实场景编辑方法，以实现细粒度的局部编辑。

Result: TexGS-VolVis在各种体积渲染场景中进行了定性和定量评估，表现出优越的效率、视觉质量和编辑灵活性。

Conclusion: TexGS-VolVis展现出优于现有方法的效率、视觉质量和编辑灵活性。

Abstract: Advancements in volume visualization (VolVis) focus on extracting insights
from 3D volumetric data by generating visually compelling renderings that
reveal complex internal structures. Existing VolVis approaches have explored
non-photorealistic rendering techniques to enhance the clarity, expressiveness,
and informativeness of visual communication. While effective, these methods
often rely on complex predefined rules and are limited to transferring a single
style, restricting their flexibility. To overcome these limitations, we
advocate the representation of VolVis scenes using differentiable Gaussian
primitives combined with pretrained large models to enable arbitrary style
transfer and real-time rendering. However, conventional 3D Gaussian primitives
tightly couple geometry and appearance, leading to suboptimal stylization
results. To address this, we introduce TexGS-VolVis, a textured Gaussian
splatting framework for VolVis. TexGS-VolVis employs 2D Gaussian primitives,
extending each Gaussian with additional texture and shading attributes,
resulting in higher-quality, geometry-consistent stylization and enhanced
lighting control during inference. Despite these improvements, achieving
flexible and controllable scene editing remains challenging. To further enhance
stylization, we develop image- and text-driven non-photorealistic scene editing
tailored for TexGS-VolVis and 2D-lift-3D segmentation to enable partial editing
with fine-grained control. We evaluate TexGS-VolVis both qualitatively and
quantitatively across various volume rendering scenes, demonstrating its
superiority over existing methods in terms of efficiency, visual quality, and
editing flexibility.

</details>
