<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 42]
- [cs.LG](#cs.LG) [Total: 2]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.SE](#cs.SE) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [From Image Captioning to Visual Storytelling](https://arxiv.org/abs/2508.14045)
*Admitos Passadakis,Yingjin Song,Albert Gatt*

Main category: cs.CL

TL;DR: 本文提出了一种新的视觉叙事方法，通过整合图像描述和叙事生成，提高了故事质量，并提出了一个新度量工具ideality来评估结果与理想模型的距离。


<details>
  <summary>Details</summary>
Motivation: 视觉叙事是一项具有挑战性的多模态任务，需要生成既基于图像序列又具有叙事性和连贯性的故事。现有的方法难以平衡这些方面，因此本文提出了一种新的方法。

Method: 首先使用视觉到语言的模型获取输入图像的描述，然后利用语言到语言的方法将这些描述转化为连贯的叙述。

Result: 实验结果表明，将描述和叙事整合到统一框架中对生成故事的质量有积极影响。此外，该方法比以往的研究更加快速且易于重复使用。

Conclusion: 本文提出了一种将视觉叙事作为图像描述的超集的方法，通过在统一框架下整合描述和叙事，提高了生成故事的质量。此外，该方法加快了训练时间，并提出了一个新的度量工具ideality来模拟结果与理想模型的距离。

Abstract: Visual Storytelling is a challenging multimodal task between Vision &
Language, where the purpose is to generate a story for a stream of images. Its
difficulty lies on the fact that the story should be both grounded to the image
sequence but also narrative and coherent. The aim of this work is to balance
between these aspects, by treating Visual Storytelling as a superset of Image
Captioning, an approach quite different compared to most of prior relevant
studies. This means that we firstly employ a vision-to-language model for
obtaining captions of the input images, and then, these captions are
transformed into coherent narratives using language-to-language methods. Our
multifarious evaluation shows that integrating captioning and storytelling
under a unified framework, has a positive impact on the quality of the produced
stories. In addition, compared to numerous previous studies, this approach
accelerates training time and makes our framework readily reusable and
reproducible by anyone interested. Lastly, we propose a new metric/tool, named
ideality, that can be used to simulate how far some results are from an oracle
model, and we apply it to emulate human-likeness in visual storytelling.

</details>


### [2] [Benchmarking Sociolinguistic Diversity in Swahili NLP: A Taxonomy-Guided Approach](https://arxiv.org/abs/2508.14051)
*Kezia Oketch,John P. Lalor,Ahmed Abbasi*

Main category: cs.CL

TL;DR: 本文介绍了首个基于分类法的斯瓦希里语NLP评估，旨在填补社会语言多样性方面的空白。通过收集肯尼亚说话者的2,170个自由文本响应，研究揭示了社会语言变异对模型性能的影响，并提出了一个结构化的分类法来分析模型预测错误。


<details>
  <summary>Details</summary>
Motivation: 我们引入了第一个基于分类法的斯瓦希里语自然语言处理评估，解决了社会语言多样性方面的差距。

Method: 我们开发了一个结构化的分类法，并将其作为观察预训练和指令调优语言模型预测错误的透镜。

Result: 我们收集了一个包含2,170个自由文本响应的数据集，这些数据表现出部落影响、城市俚语、混合语言和借词。

Conclusion: 我们的研究推进了文化基础的评估框架，并突出了社会语言变异在塑造模型性能中的作用。

Abstract: We introduce the first taxonomy-guided evaluation of Swahili NLP, addressing
gaps in sociolinguistic diversity. Drawing on health-related psychometric
tasks, we collect a dataset of 2,170 free-text responses from Kenyan speakers.
The data exhibits tribal influences, urban vernacular, code-mixing, and
loanwords. We develop a structured taxonomy and use it as a lens for examining
model prediction errors across pre-trained and instruction-tuned language
models. Our findings advance culturally grounded evaluation frameworks and
highlight the role of sociolinguistic variation in shaping model performance.

</details>


### [3] [Contrastive Analysis of Constituent Order Preferences Within Adverbial Roles in English and Chinese News: A Large-Language-Model-Driven Approach](https://arxiv.org/abs/2508.14054)
*Yiran Rex Ma*

Main category: cs.CL

TL;DR: 本研究基于大型语言模型标注的可比英语-中文新闻语料库，从功能块的角度探讨了英语-中文新闻中成分顺序的差异，并分析了其典型的位置偏好和分布模式。研究发现英语新闻倾向于先呈现核心信息，功能块多为后置；而中文新闻倾向于先呈现背景信息，功能块多为前置。在SVO结构中，英语和中文新闻都表现出功能块分布的差异，但中文的前置倾向更为明显，而英语的后置倾向相对较弱。当功能块共现时，英语和中文新闻都表现出高度的灵活性，顺序调整由信息和语用目的驱动。研究揭示了语序既有系统性偏好又有动态适应性，为英汉信息结构的对比研究提供了新的实证支持。


<details>
  <summary>Details</summary>
Motivation: 探索英语-中文新闻中功能块的顺序差异及其分布模式，以提供对英汉信息结构对比研究的新实证支持。

Method: 基于大型语言模型标注的可比英语-中文新闻语料库，从功能块的角度探讨英语-中文新闻中成分顺序的差异，并分析其典型的位置偏好和分布模式。

Result: 发现英语新闻倾向于先呈现核心信息，功能块多为后置；而中文新闻倾向于先呈现背景信息，功能块多为前置。在SVO结构中，英语和中文新闻都表现出功能块分布的差异，但中文的前置倾向更为明显，而英语的后置倾向相对较弱。当功能块共现时，英语和中文新闻都表现出高度的灵活性，顺序调整由信息和语用目的驱动。

Conclusion: 研究揭示了语序既有系统性偏好又有动态适应性，为英汉信息结构的对比研究提供了新的实证支持。

Abstract: Based on comparable English-Chinese news corpora annotated by Large Language
Model (LLM), this paper attempts to explore the differences in constituent
order of English-Chinese news from the perspective of functional chunks with
adverbial roles, and analyze their typical positional preferences and
distribution patterns. It is found that: (1) English news prefers linear
narrative of core information first, and functional chunks are mostly
post-positioned, while Chinese news prefers overall presentation mode of
background first, and functional chunks are often pre-positioned; (2) In SVO
structure, both English and Chinese news show differences in the distribution
of functional chunks, but the tendency of Chinese pre-positioning is more
significant, while that of English post-positioning is relatively mild; (3)
When function blocks are co-occurring, both English and Chinese news show high
flexibility, and the order adjustment is driven by information and pragmatic
purposes. The study reveals that word order has both systematic preference and
dynamic adaptability, providing new empirical support for contrastive study of
English-Chinese information structure.

</details>


### [4] [T-REX: Table -- Refute or Entail eXplainer](https://arxiv.org/abs/2508.14055)
*Tim Luka Horstmann,Baptiste Geisenberger,Mehwish Alam*

Main category: cs.CL

TL;DR: T-REX 是一个基于大型语言模型的交互式工具，用于多模态、多语言表格中的声明验证，旨在提高事实核查的可访问性和透明度。


<details>
  <summary>Details</summary>
Motivation: 当前的解决方案对非专家来说仍然难以使用，因此需要一种更易访问且透明的事实核查工具。

Method: T-REX 使用最先进的指令调优推理大型语言模型来实现声明验证。

Result: T-REX 已经在线公开可用，能够为非专家提供先进的事实核查功能。

Conclusion: T-REX 是一个用于多模态、多语言表格中声明验证的首个实时交互工具，旨在为非专家提供先进的事实核查技术。

Abstract: Verifying textual claims against structured tabular data is a critical yet
challenging task in Natural Language Processing with broad real-world impact.
While recent advances in Large Language Models (LLMs) have enabled significant
progress in table fact-checking, current solutions remain inaccessible to
non-experts. We introduce T-REX (T-REX: Table -- Refute or Entail eXplainer),
the first live, interactive tool for claim verification over multimodal,
multilingual tables using state-of-the-art instruction-tuned reasoning LLMs.
Designed for accuracy and transparency, T-REX empowers non-experts by providing
access to advanced fact-checking technology. The system is openly available
online.

</details>


### [5] [Confidence Estimation for Text-to-SQL in Large Language Models](https://arxiv.org/abs/2508.14056)
*Sepideh Entezari Maleki,Mohammadreza Pourreza,Davood Rafiei*

Main category: cs.CL

TL;DR: 本文研究了在没有黄金答案的情况下对文本到SQL模型生成的SQL查询进行置信度估计的问题，并探讨了黑盒和白盒置信度估计策略的有效性。结果表明，基于一致性的方法在黑盒模型中表现更优，而基于SQL语法的方法在白盒设置中更具优势。此外，执行基础的查询验证为两种方法提供了有价值的补充信号。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）的模型权重和梯度通常受到限制，因此需要一种有效的置信度估计方法来评估模型生成的SQL查询的可靠性。

Method: 本文研究了在没有黄金答案的情况下对文本到SQL模型生成的SQL查询进行置信度估计的问题，并探讨了黑盒和白盒置信度估计策略的有效性。

Result: 基于一致性的方法在黑盒模型中表现更优，而基于SQL语法的方法在白盒设置中更具优势。此外，执行基础的查询验证为两种方法提供了有价值的补充信号。

Conclusion: 本文研究了在没有黄金答案的情况下对文本到SQL模型生成的SQL查询进行置信度估计的问题，并探讨了黑盒和白盒置信度估计策略的有效性。结果表明，基于一致性的方法在黑盒模型中表现更优，而基于SQL语法的方法在白盒设置中更具优势。此外，执行基础的查询验证为两种方法提供了有价值的补充信号。

Abstract: Confidence estimation for text-to-SQL aims to assess the reliability of
model-generated SQL queries without having access to gold answers. We study
this problem in the context of large language models (LLMs), where access to
model weights and gradients is often constrained. We explore both black-box and
white-box confidence estimation strategies, evaluating their effectiveness on
cross-domain text-to-SQL benchmarks. Our evaluation highlights the superior
performance of consistency-based methods among black-box models and the
advantage of SQL-syntax-aware approaches for interpreting LLM logits in
white-box settings. Furthermore, we show that execution-based grounding of
queries provides a valuable supplementary signal, improving the effectiveness
of both approaches.

</details>


### [6] [Assessing and Mitigating Data Memorization Risks in Fine-Tuned Large Language Models](https://arxiv.org/abs/2508.14062)
*Badrinath Ramakrishnan,Akshaya Balaji*

Main category: cs.CL

TL;DR: 本文分析了微调大型语言模型中的数据记忆问题，并提出了一种多层隐私保护框架，有效降低了数据泄露，同时保持了模型的效用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但它们倾向于记忆训练数据，这在微调过程中会带来显著的隐私风险。因此，需要一种有效的隐私保护框架来减少数据泄露。

Method: 本文进行了控制实验，分析了在现代LLM架构（如GPT-2、Phi-3和Gemma-2）上微调过程中数据记忆的现象，并提出了四种隐私保护方法：语义数据去重、生成过程中的差分隐私、基于熵的过滤和基于模式的内容过滤。

Result: 实验结果表明，使用重复的敏感数据进行微调会使隐私泄露率从基准水平的0-5%增加到60-75%，平均增加了64.2%。而提出的隐私保护方法可以将数据泄露降至0%，同时保持94.7%的原始模型效用。

Conclusion: 本文提出了一个多层次的隐私保护框架，并通过实验验证了四种互补的隐私保护方法，这些方法可以将数据泄露降至0%，同时保持94.7%的原始模型效用。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse natural language processing tasks, but their tendency to memorize
training data poses significant privacy risks, particularly during fine-tuning
processes. This paper presents a comprehensive empirical analysis of data
memorization in fine-tuned LLMs and introduces a novel multi-layered privacy
protection framework. Through controlled experiments on modern LLM
architectures including GPT-2, Phi-3, and Gemma-2, we demonstrate that
fine-tuning with repeated sensitive data increases privacy leakage rates from
baseline levels of 0-5% to 60-75%, representing a 64.2% average increase across
tested models. We propose and rigorously evaluate four complementary privacy
protection methods: semantic data deduplication, differential privacy during
generation, entropy-based filtering, and pattern-based content filtering. Our
experimental results show that these techniques can reduce data leakage to 0%
while maintaining 94.7% of original model utility.

</details>


### [7] [Punctuation and Predicates in Language Models](https://arxiv.org/abs/2508.14067)
*Sonakshi Chauhan,Maheep Chaudhary,Koby Choy,Samuel Nellessen,Nandi Schoots*

Main category: cs.CL

TL;DR: 本研究分析了标点符号在大型语言模型中的作用，并发现不同模型之间存在显著差异。同时，研究还揭示了LLMs处理不同推理规则的方式。


<details>
  <summary>Details</summary>
Motivation: 我们想了解信息在大型语言模型（LLMs）中是如何被收集和传播的，以及标点符号在其中的作用。

Method: 我们使用基于干预的技术评估了标点符号在GPT-2、DeepSeek和Gemma中的必要性和充分性。此外，我们通过交换实验和层交换实验研究了不同推理规则的处理方式。

Result: 我们的结果表明，对于GPT-2，标点符号在多个层中既是必要又是充分的，而在DeepSeek中则远不如GPT-2，而在Gemma中则完全不成立。此外，我们发现条件语句（if, then）和全称量词（for all）在LLMs中被处理得非常不同。

Conclusion: 我们的研究提供了关于标点符号使用和推理在LLMs中的内部机制的新见解，并对可解释性有影响。

Abstract: In this paper we explore where information is collected and how it is
propagated throughout layers in large language models (LLMs). We begin by
examining the surprising computational importance of punctuation tokens which
previous work has identified as attention sinks and memory aids. Using
intervention-based techniques, we evaluate the necessity and sufficiency (for
preserving model performance) of punctuation tokens across layers in GPT-2,
DeepSeek, and Gemma. Our results show stark model-specific differences: for
GPT-2, punctuation is both necessary and sufficient in multiple layers, while
this holds far less in DeepSeek and not at all in Gemma. Extending beyond
punctuation, we ask whether LLMs process different components of input (e.g.,
subjects, adjectives, punctuation, full sentences) by forming early static
summaries reused across the network, or if the model remains sensitive to
changes in these components across layers. Extending beyond punctuation, we
investigate whether different reasoning rules are processed differently by
LLMs. In particular, through interchange intervention and layer-swapping
experiments, we find that conditional statements (if, then), and universal
quantification (for all) are processed very differently. Our findings offer new
insight into the internal mechanisms of punctuation usage and reasoning in LLMs
and have implications for interpretability.

</details>


### [8] [DLLMQuant: Quantizing Diffusion-based Large Language Models](https://arxiv.org/abs/2508.14090)
*Chen Xu,Dawei Yang*

Main category: cs.CL

TL;DR: 本文研究了扩散型大语言模型（DLLMs）在量化过程中遇到的核心问题，并提出了一种专门针对DLLMs的后训练量化框架DLLMQuant，通过三种新技术有效解决了这些问题，实现了性能的显著提升和效率的增强。


<details>
  <summary>Details</summary>
Motivation: 扩散型大语言模型（DLLMs）在非自回归文本生成中展现出潜力，但其部署受到模型规模大和计算成本高的限制。现有的后训练量化（PTQ）方法在直接应用于DLLMs时会导致严重的精度下降和泛化性能降低。因此，需要一种专门针对DLLMs的量化框架。

Method: 本文提出了三种新技术：1) 时间-掩码自适应采样（TMAS），考虑时间和掩码因素，能够捕捉不同时间步的分布；2) 交互感知激活量化（IA-AQ），利用双向注意力的交互信号动态分配量化资源；3) 确定性引导量化（CGQ），将掩码状态和token得分作为关键权重标准，融入误差补偿中，使权重量化更适合DLLMs。

Result: 实验表明，DLLMQuant在保持高效的同时实现了显著的性能提升。

Conclusion: 本文提出了一种针对扩散型大语言模型（DLLMs）的后训练量化框架DLLMQuant，通过三种新技术有效解决了DLLMs在量化过程中遇到的核心问题，从而实现了性能的显著提升和效率的增强。

Abstract: Diffusion-based large language models (DLLMs) have shown promise for
non-autoregressive text generation, but their deployment is constrained by
large model sizes and heavy computational costs. Post-training quantization
(PTQ), a widely used method for compressing and accelerating Large Language
Models (LLMs), suffers from severe accuracy degradation and reduced
generalization performance when directly applied to DLLMs (e.g., AWQ suffers a
16% accuracy drop on LLADA under W4A4). This paper explores how DLLMs' key
mechanisms - dynamic masking, iterative generation, bidirectional attention -
clash with quantization. We identify three core issues: 1) Iterative generation
and dynamic masking ratios lead to distinct token distributions across decoding
steps, which are not adequately captured by existing PTQ calibration methods;
2) Quantization errors are accumulated and amplified progressively during
iteration in DLLMs, causing quantized models to perform worse as decoding steps
progress; 3) Unmasked tokens stabilize while masked remain probabilistic,
making overall feature distribution incompatible with existing PTQ methods. To
address these issues, we propose DLLMQuant, a PTQ framework tailored for DLLMs,
which incorporates three novel techniques: 1) Temporal-Mask Adaptive Sampling
(TMAS), a calibration method that accounts for both time and mask factors, with
the capacity to capture distributions across timesteps. 2) Interaction-Aware
Activation Quantization (IA-AQ), which utilizes bidirectional attention's
interaction signals to dynamically allocate quantization resources. 3)
Certainty-Guided Quantization (CGQ), which integrates mask status and token
scores as key weighting criteria into error compensation, making weight
quantization more suitable for DLLMs. Experiments show that DLLMQuant achieves
significant performance gains while enhancing efficiency.

</details>


### [9] [MMReview: A Multidisciplinary and Multimodal Benchmark for LLM-Based Peer Review Automation](https://arxiv.org/abs/2508.14146)
*Xian Gao,Jiacheng Ruan,Zongyun Zhang,Jingsheng Gao,Ting Liu,Yuzhuo Fu*

Main category: cs.CL

TL;DR: 本文提出了MMReview，这是一个涵盖多个学科和模态的全面基准，旨在评估大型语言模型和多模态大型语言模型在同行评审任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 随着学术出版物的快速增长，同行评审已成为研究界必不可少但耗时的责任。大型语言模型（LLMs）已被越来越多地用于辅助生成评审意见；然而，当前基于LLM的评审任务缺乏统一的评估基准，以严格评估模型生成全面、准确和符合人类偏好的评估的能力，特别是在涉及多模态内容（如图表）的场景中。

Method: 我们提出了MMReview，这是一个涵盖多个学科和模态的全面基准。MMReview包括240篇论文的多模态内容和专家撰写的评审意见，跨越四个主要学术领域：人工智能、自然科学、工程科学和社会科学。我们设计了13个任务，分为四个核心类别，旨在评估LLMs和MLLMs在逐步评审生成、结果制定、与人类偏好对齐以及对抗性输入操作的鲁棒性方面的性能。

Result: 在16个开源模型和5个先进的闭源模型上进行的广泛实验证明了该基准的彻底性。

Conclusion: 我们设想MMReview是建立自动化同行评审系统标准化基础的关键一步。

Abstract: With the rapid growth of academic publications, peer review has become an
essential yet time-consuming responsibility within the research community.
Large Language Models (LLMs) have increasingly been adopted to assist in the
generation of review comments; however, current LLM-based review tasks lack a
unified evaluation benchmark to rigorously assess the models' ability to
produce comprehensive, accurate, and human-aligned assessments, particularly in
scenarios involving multimodal content such as figures and tables. To address
this gap, we propose \textbf{MMReview}, a comprehensive benchmark that spans
multiple disciplines and modalities. MMReview includes multimodal content and
expert-written review comments for 240 papers across 17 research domains within
four major academic disciplines: Artificial Intelligence, Natural Sciences,
Engineering Sciences, and Social Sciences. We design a total of 13 tasks
grouped into four core categories, aimed at evaluating the performance of LLMs
and Multimodal LLMs (MLLMs) in step-wise review generation, outcome
formulation, alignment with human preferences, and robustness to adversarial
input manipulation. Extensive experiments conducted on 16 open-source models
and 5 advanced closed-source models demonstrate the thoroughness of the
benchmark. We envision MMReview as a critical step toward establishing a
standardized foundation for the development of automated peer review systems.

</details>


### [10] [DPad: Efficient Diffusion Language Models with Suffix Dropout](https://arxiv.org/abs/2508.14148)
*Xinhua Chen,Sitao Huang,Cong Guo,Chiyue Wei,Yintao He,Jianyi Zhang,Hai "Hellen" Li,Yiran Chen*

Main category: cs.CL

TL;DR: DPad是一种无需训练的方法，通过限制注意力到一小部分附近的后缀标记，提高了基于扩散的大型语言模型的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的大型语言模型（dLLMs）在每个步骤中预测所有未来的后缀标记，导致计算开销高。

Method: DPad通过两种策略：滑动窗口和距离衰减丢弃，限制注意力到一小部分附近的后缀标记。

Result: DPad在多个基准测试中实现了比原始dLLMs高达61.4倍的速度提升，同时保持了相当的准确性。

Conclusion: DPad展示了其在高效和可扩展的长序列推理中的潜力。

Abstract: Diffusion-based Large Language Models (dLLMs) parallelize text generation by
framing decoding as a denoising process, but suffer from high computational
overhead since they predict all future suffix tokens at each step while
retaining only a small fraction. We propose Diffusion Scratchpad (DPad), a
training-free method that restricts attention to a small set of nearby suffix
tokens, preserving fidelity while eliminating redundancy. DPad integrates two
strategies: (i) a sliding window, which maintains a fixed-length suffix window,
and (ii) distance-decay dropout, which deterministically removes distant suffix
tokens before attention computation. This simple design is compatible with
existing optimizations such as prefix caching and can be implemented with only
a few lines of code. Comprehensive evaluations across multiple benchmarks on
LLaDA-1.5 and Dream models demonstrate that DPad delivers up to
$\mathbf{61.4\times}$ speedup over vanilla dLLMs while maintaining comparable
accuracy, highlighting its potential for efficient and scalable long-sequence
inference. Our code is available at https://github.com/Crys-Chen/DPad.

</details>


### [11] [Comparing energy consumption and accuracy in text classification inference](https://arxiv.org/abs/2508.14170)
*Johannes Zschache,Tilman Hartwig*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型在文本分类推理中的能耗和准确性之间的权衡，发现最佳性能的模型也可以是节能的，而更大的LLM通常消耗更多能量且准确性较低。此外，研究发现推理能耗与模型运行时间有很强的相关性，这表明执行时间可以作为无法直接测量能耗时的实用代理。这些发现对可持续AI发展具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在自然语言处理任务中的广泛应用，能源效率和可持续性成为关注的焦点。尽管之前的研究主要集中在模型训练期间的能耗，但推理阶段受到的关注较少。因此，本研究旨在系统地评估文本分类推理中的能耗和准确性之间的权衡，以提供有关可持续AI发展的见解。

Method: 本研究系统地评估了在各种模型架构和硬件配置下，文本分类推理中的模型准确性和能耗之间的权衡。通过实证分析，研究了模型类型、模型大小和硬件规格对推理能耗的影响，并探讨了执行时间与能耗之间的关系。

Result: 研究结果表明，最佳性能的模型也可以是节能的，而更大的LLM通常消耗更多的能量且分类准确性较低。此外，推理能耗在不同模型类型、模型大小和硬件规格下表现出显著的差异。同时，研究发现推理能耗与模型运行时间有很强的相关性，这表明执行时间可以作为无法直接测量能耗时的实用代理。

Conclusion: 本研究的结论表明，在自然语言处理任务中，大型语言模型的推理阶段需要关注能源效率和可持续性。研究发现，最佳性能的模型也可以是节能的，而更大的LLM通常消耗更多的能量且分类准确性较低。此外，推理能耗与模型运行时间有很强的相关性，这表明执行时间可以作为无法直接测量能耗时的实用代理。这些发现对可持续AI发展具有重要意义，为研究人员、行业从业者和政策制定者提供了平衡性能和资源效率的可行见解。

Abstract: The increasing deployment of large language models (LLMs) in natural language
processing (NLP) tasks raises concerns about energy efficiency and
sustainability. While prior research has largely focused on energy consumption
during model training, the inference phase has received comparatively less
attention. This study systematically evaluates the trade-offs between model
accuracy and energy consumption in text classification inference across various
model architectures and hardware configurations. Our empirical analysis shows
that the best-performing model in terms of accuracy can also be
energy-efficient, while larger LLMs tend to consume significantly more energy
with lower classification accuracy. We observe substantial variability in
inference energy consumption ($<$mWh to $>$kWh), influenced by model type,
model size, and hardware specifications. Additionally, we find a strong
correlation between inference energy consumption and model runtime, indicating
that execution time can serve as a practical proxy for energy usage in settings
where direct measurement is not feasible. These findings have implications for
sustainable AI development, providing actionable insights for researchers,
industry practitioners, and policymakers seeking to balance performance and
resource efficiency in NLP applications.

</details>


### [12] [Let's Use ChatGPT To Write Our Paper! Benchmarking LLMs To Write the Introduction of a Research Paper](https://arxiv.org/abs/2508.14273)
*Krishna Garg,Firoz Shaikh,Sambaran Bandyopadhyay,Cornelia Caragea*

Main category: cs.CL

TL;DR: 本文介绍了SciIG任务，评估LLM生成研究论文引言的能力。通过从NAACL 2025和ICLR 2025论文中整理的新数据集，对五种最先进的模型进行了多维评估。结果显示LLaMA-4 Maverick在多数指标上表现最佳，三样本提示优于较少样本方法。研究提供了开发有效写作助手的见解，并计划公开所有代码和数据集以促进可重复性。


<details>
  <summary>Details</summary>
Motivation: 随着研究人员越来越多地采用LLM作为写作助手，生成高质量的研究论文引言仍然是一个挑战且至关重要。我们引入了科学引言生成（SciIG），这是一个任务，用于评估LLM从标题、摘要和相关作品中生成连贯引言的能力。

Method: 我们从NAACL 2025和ICLR 2025论文中整理了新的数据集，评估了五种最先进的模型，包括开源模型（DeepSeek-v3、Gemma-3-12B、LLaMA 4-Maverick、MistralAI Small 3.1）和闭源GPT-4o系统，从多个维度进行了评估：词汇重叠、语义相似性、内容覆盖、忠实性、一致性、引用正确性和叙述质量。我们的综合框架结合了自动化指标和LLM作为评判者的评估。

Result: 结果表明，LLaMA-4 Maverick在大多数指标上表现优于其他模型，特别是在语义相似性和忠实性方面。此外，三样本提示始终优于较少样本的方法。

Conclusion: 这些发现为开发有效的研究写作助手提供了实用的见解，并设定了LLM辅助学术写作的现实期望。为了促进可重复性和未来的研究，我们将公开所有代码和数据集。

Abstract: As researchers increasingly adopt LLMs as writing assistants, generating
high-quality research paper introductions remains both challenging and
essential. We introduce Scientific Introduction Generation (SciIG), a task that
evaluates LLMs' ability to produce coherent introductions from titles,
abstracts, and related works. Curating new datasets from NAACL 2025 and ICLR
2025 papers, we assess five state-of-the-art models, including both open-source
(DeepSeek-v3, Gemma-3-12B, LLaMA 4-Maverick, MistralAI Small 3.1) and
closed-source GPT-4o systems, across multiple dimensions: lexical overlap,
semantic similarity, content coverage, faithfulness, consistency, citation
correctness, and narrative quality. Our comprehensive framework combines
automated metrics with LLM-as-a-judge evaluations. Results demonstrate LLaMA-4
Maverick's superior performance on most metrics, particularly in semantic
similarity and faithfulness. Moreover, three-shot prompting consistently
outperforms fewer-shot approaches. These findings provide practical insights
into developing effective research writing assistants and set realistic
expectations for LLM-assisted academic writing. To foster reproducibility and
future research, we will publicly release all code and datasets.

</details>


### [13] [Disentangling concept semantics via multilingual averaging in Sparse Autoencoders](https://arxiv.org/abs/2508.14275)
*Cliff O'Reilly,Ernesto Jimenez-Ruiz,Tillman Weyde*

Main category: cs.CL

TL;DR: 本文提出了一种通过平均不同语言的激活来提取概念语义的方法，并展示了其在本体类之间关系建模中的有效性。


<details>
  <summary>Details</summary>
Motivation: 连接LLMs与形式化知识表示和推理是解决其不足的有前途的方法。现有的嵌入和稀疏自编码器在表示文本内容时，语义与句法和语言特定信息纠缠在一起。

Method: 通过使用稀疏自编码器获取每个类和语言版本的概念激活，并对不同语言的激活进行平均，以获得概念平均值。然后将概念平均值与本体类之间的地面真实映射进行相关性分析。

Result: 研究结果表明，概念平均值与本体类之间的地面真实映射具有强相关性，这表明该方法能够更准确地解释内部网络状态。

Conclusion: 研究结果表明，通过平均不同语言的激活可以得到与本体类之间真实关系对齐的概念平均值，这暗示了一种新的技术，可以更准确地解释内部网络状态。

Abstract: Connecting LLMs with formal knowledge representation and reasoning is a
promising approach to address their shortcomings. Embeddings and sparse
autoencoders are widely used to represent textual content, but the semantics
are entangled with syntactic and language-specific information. We propose a
method that isolates concept semantics in Large Langue Models by averaging
concept activations derived via Sparse Autoencoders. We create English text
representations from OWL ontology classes, translate the English into French
and Chinese and then pass these texts as prompts to the Gemma 2B LLM. Using the
open source Gemma Scope suite of Sparse Autoencoders, we obtain concept
activations for each class and language version. We average the different
language activations to derive a conceptual average. We then correlate the
conceptual averages with a ground truth mapping between ontology classes. Our
results give a strong indication that the conceptual average aligns to the true
relationship between classes when compared with a single language by itself.
The result hints at a new technique which enables mechanistic interpretation of
internal network states with higher accuracy.

</details>


### [14] [GRILE: A Benchmark for Grammar Reasoning and Explanation in Romanian LLMs](https://arxiv.org/abs/2508.14279)
*Adrian-Marius Dumitran,Alexandra-Mihaela Danila,Angela-Liliana Dumitran*

Main category: cs.CL

TL;DR: 本研究介绍了GRILE，这是一个针对罗马尼亚高风险考试的开放基准测试，用于评估大型语言模型在选择正确答案和生成语言准确解释方面的能力。结果显示，Gemini 2.5 Pro表现最佳，但大多数开源模型存在明显不足。研究还揭示了在低资源环境中可信教育NLP的挑战，并发布了所有数据、代码和公共网络演示以促进未来研究。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs（大型语言模型）已经革新了NLP（自然语言处理），但它们在低资源语言中的教学价值仍然不明确。

Method: 我们提出了GRILE，这是第一个开放的基准测试，包含从罗马尼亚高风险考试中收集的1,151个多项选择题。我们使用GRILE来探测七种最先进的多语言和罗马尼亚特定LLMs的两个互补能力：(i) 选择正确答案，以及(ii) 生成语言上准确的解释。

Result: Gemini 2.5 Pro达到了83%的准确率，而大多数开源模型则低于65%。48%的解释根据专家评审存在事实或教学缺陷。详细的错误分析指出了形态学和应用最新DOOM3正字法规范方面的系统性弱点。

Conclusion: 我们的研究揭示了在低资源环境中可信教育NLP的开放挑战，并将GRILE确立为可控解释生成和评估的新测试平台。

Abstract: LLMs (Large language models) have revolutionized NLP (Natural Language
Processing), yet their pedagogical value for low-resource languages remains
unclear. We present GRILE (Grammar Romanian Inference and Language
Explanations) , the first open benchmark of 1,151 multiple-choice questions
harvested from Romanian high-stakes exams (National Evaluation, Baccalaureate,
university admissions). GRILE enables us to probe two complementary abilities
of seven state-of-the-art multilingual and Romanian-specific LLMs: (i)
selecting the correct answer, and (ii) producing linguistically accurate
explanations. While Gemini 2.5 Pro reaches 83% accuracy, most open-weight
models stay below 65%, and 48% of their explanations contain factual or
pedagogical flaws according to expert review. A detailed error analysis
pinpoints systematic weaknesses in morphology and in applying the latest DOOM3
orthographic norms. All data, code and a public web demo are released to
catalyze future research. Our findings expose open challenges for trustworthy
educational NLP in low-resource settings and establish GRILE as a new test-bed
for controllable explanation generation and evaluation.

</details>


### [15] [Tokens with Meaning: A Hybrid Tokenization Approach for NLP](https://arxiv.org/abs/2508.14292)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Sercan Karakaş,Banu Diri,Savaş Yıldırım,Demircan Çelik*

Main category: cs.CL

TL;DR: 本文提出了一种混合分词框架，结合规则的形态分析和统计子词分割，提高了形态丰富语言的分词效果。


<details>
  <summary>Details</summary>
Motivation: 现有的子词方法如BPE和WordPiece在形态丰富的语言中表现不佳，因为它们依赖于频率而非语言结构。

Method: 该方法结合了基于规则的形态分析和统计子词分割，使用语音规范化、词根-词缀字典以及一种新的算法来平衡词素保留与词汇效率。

Result: 该分词器在TR-MMLU基准测试中实现了最高的土耳其语标记百分比（90.29%）和纯标记百分比（85.8%），并且与LLaMA、Gemma和GPT的分词器相比，生成的标记更具语言意义和连贯性。

Conclusion: 该方法展示了在土耳其语上的有效性，并且可以适应其他语言，为更可解释和有效的多语言NLP系统提供了一条实用的路径。

Abstract: Tokenization plays a pivotal role in natural language processing (NLP),
shaping how text is segmented and interpreted by language models. While subword
methods such as Byte Pair Encoding (BPE) and WordPiece have been effective,
they often struggle with morphologically rich and agglutinative languages
because they rely on frequency rather than linguistic structure. We introduce a
hybrid tokenization framework that combines rule-based morphological analysis
with statistical subword segmentation. The method uses phonological
normalization, root-affix dictionaries, and a novel algorithm that balances
morpheme preservation with vocabulary efficiency. It assigns shared identifiers
to phonologically variant affixes (e.g., -ler and -lar) and altered root forms
(e.g., kitap vs. kitab{\i}), reducing redundancy while maintaining semantic
integrity. Special tokens are added for whitespace and case, including an
UPPERCASE marker to avoid vocabulary inflation from capitalization. BPE is
integrated for out-of-vocabulary coverage without harming morphological
coherence. On the TR-MMLU benchmark, the tokenizer achieves the highest Turkish
Token Percentage (90.29\%) and Pure Token Percentage (85.8\%). Comparisons with
tokenizers from LLaMA, Gemma, and GPT show more linguistically meaningful and
coherent tokens. Although demonstrated on Turkish, the approach is
language-independent and adaptable to other languages, offering a practical
path toward more interpretable and effective multilingual NLP systems.

</details>


### [16] [A Joint Multitask Model for Morpho-Syntactic Parsing](https://arxiv.org/abs/2508.14307)
*Demian Inostroza,Mel Mistica,Ekaterina Vylomova,Chris Guest,Kemal Kurniawan*

Main category: cs.CL

TL;DR: 本文介绍了一个联合多任务模型，用于UniDive 2025形态句法解析共享任务，该模型在九种语言中表现优异。


<details>
  <summary>Details</summary>
Motivation: 我们提出了一个联合多任务模型，用于UniDive 2025形态句法解析共享任务，其中系统预测遵循新的UD注释方案的形态和句法分析。

Method: 我们的系统使用了一个共享的XLM-RoBERTa编码器，以及三个专门用于内容词识别、依存句法分析和形态句法特征预测的解码器。

Result: 我们的模型在共享任务的排行榜上取得了最佳的整体性能，覆盖了九种语言类型多样的语言，平均MSLAS得分为78.7%，LAS为80.1%，Feats F1为90.3%。

Conclusion: 我们的模型在共享任务的排行榜上取得了最佳的整体性能，覆盖了九种语言类型多样的语言，平均MSLAS得分为78.7%，LAS为80.1%，Feats F1为90.3%。

Abstract: We present a joint multitask model for the UniDive 2025 Morpho-Syntactic
Parsing shared task, where systems predict both morphological and syntactic
analyses following novel UD annotation scheme. Our system uses a shared
XLM-RoBERTa encoder with three specialized decoders for content word
identification, dependency parsing, and morphosyntactic feature prediction. Our
model achieves the best overall performance on the shared task's leaderboard
covering nine typologically diverse languages, with an average MSLAS score of
78.7 percent, LAS of 80.1 percent, and Feats F1 of 90.3 percent. Our ablation
studies show that matching the task's gold tokenization and content word
identification are crucial to model performance. Error analysis reveals that
our model struggles with core grammatical cases (particularly Nom-Acc) and
nominal features across languages.

</details>


### [17] [Zero-knowledge LLM hallucination detection and mitigation through fine-grained cross-model consistency](https://arxiv.org/abs/2508.14314)
*Aman Goel,Daniel Schwartz,Yanjun Qi*

Main category: cs.CL

TL;DR: Finch-Zk is a black-box framework that detects and mitigates hallucinations in LLM outputs without requiring external knowledge sources.


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) remain susceptible to hallucinations, which generate content that appears plausible but contains factual inaccuracies.

Method: Finch-Zk introduces two key innovations: a cross-model consistency checking strategy and a targeted mitigation technique.

Result: Experiments on the FELM dataset show Finch-Zk improves hallucination detection F1 scores by 6-39% compared to existing approaches. For mitigation, Finch-Zk achieves 7-8 absolute percentage points improvement in answer accuracy on the GPQA-diamond dataset when applied to state-of-the-art models like Llama 4 Maverick and Claude 4 Sonnet.

Conclusion: Finch-Zk provides a practical, deployment-ready safeguard for enhancing factual reliability in production LLM systems.

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across
diverse tasks, but they remain susceptible to hallucinations--generating
content that appears plausible but contains factual inaccuracies. We present
Finch-Zk, a black-box framework that leverages FINe-grained Cross-model
consistency to detect and mitigate Hallucinations in LLM outputs without
requiring external knowledge sources. Finch-Zk introduces two key innovations:
1) a cross-model consistency checking strategy that reveals fine-grained
inaccuracies by comparing responses generated by diverse models from
semantically-equivalent prompts, and 2) a targeted mitigation technique that
applies precise corrections to problematic segments while preserving accurate
content. Experiments on the FELM dataset show Finch-Zk improves hallucination
detection F1 scores by 6-39\% compared to existing approaches. For mitigation,
Finch-Zk achieves 7-8 absolute percentage points improvement in answer accuracy
on the GPQA-diamond dataset when applied to state-of-the-art models like Llama
4 Maverick and Claude 4 Sonnet. Extensive evaluation across multiple models
demonstrates that Finch-Zk provides a practical, deployment-ready safeguard for
enhancing factual reliability in production LLM systems.

</details>


### [18] [SurveyGen-I: Consistent Scientific Survey Generation with Evolving Plans and Memory-Guided Writing](https://arxiv.org/abs/2508.14317)
*Jing Chen,Zhiheng Yang,Yixian Shen,Jie Liu,Adam Belloum,Chrysa Papagainni,Paola Grosso*

Main category: cs.CL

TL;DR: 本文介绍了一种自动生成调查框架SurveyGen-I，该框架结合了粗到细的检索、自适应规划和记忆引导生成，以解决现有基于LLM的方法在保持长篇多章节调查的一致性和提供全面引用覆盖方面的不足。实验表明，SurveyGen-I在内容质量、一致性和引用覆盖方面优于之前的工作。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的方法在保持长篇多章节调查的一致性和提供全面的引用覆盖方面存在困难。

Method: SurveyGen-I结合了粗到细的检索、自适应规划和记忆引导生成。首先进行调查级别的检索以构建初始大纲和写作计划，然后通过存储先前编写的内容和术语的记忆机制动态地在生成过程中进行细化，确保各子部分的一致性。当系统检测到上下文不足时，会触发细粒度的子部分级检索。

Result: SurveyGen-I在四个科学领域中的实验表明，它在内容质量、一致性和引用覆盖方面优于之前的工作。

Conclusion: 实验表明，SurveyGen-I在内容质量、一致性以及引用覆盖方面始终优于之前的工作。

Abstract: Survey papers play a critical role in scientific communication by
consolidating progress across a field. Recent advances in Large Language Models
(LLMs) offer a promising solution by automating key steps in the
survey-generation pipeline, such as retrieval, structuring, and summarization.
However, existing LLM-based approaches often struggle with maintaining
coherence across long, multi-section surveys and providing comprehensive
citation coverage. To address these limitations, we introduce SurveyGen-I, an
automatic survey generation framework that combines coarse-to-fine retrieval,
adaptive planning, and memory-guided generation. SurveyGen-I first performs
survey-level retrieval to construct the initial outline and writing plan, and
then dynamically refines both during generation through a memory mechanism that
stores previously written content and terminology, ensuring coherence across
subsections. When the system detects insufficient context, it triggers
fine-grained subsection-level retrieval. During generation, SurveyGen-I
leverages this memory mechanism to maintain coherence across subsections.
Experiments across four scientific domains demonstrate that SurveyGen-I
consistently outperforms previous works in content quality, consistency, and
citation coverage.

</details>


### [19] [Beyond Semantic Similarity: Reducing Unnecessary API Calls via Behavior-Aligned Retriever](https://arxiv.org/abs/2508.14323)
*Yixin Chen,Ying Xiong,Shangyu Wu,Yufei Cui,Xue Liu,Nan Guan,Chun Jason Xue*

Main category: cs.CL

TL;DR: 本文提出了一种行为对齐检索器（BAR），通过提供行为一致的演示来帮助大型语言模型做出更准确的工具使用决策。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通过微调大型语言模型或使用基于演示的提示来解决这一挑战，但它们往往存在高训练开销，并且无法考虑不一致的演示样本，这会误导模型的调用行为。

Method: 我们构建了一个包含不同功能调用行为的语料库，即调用或不调用。我们使用对比学习框架，以定制的正/负对和双负对比损失来训练BAR，确保行为一致的示例的鲁棒检索。

Result: 实验表明，我们的方法显著减少了错误的功能调用，同时保持了高任务性能。

Conclusion: 我们的方法显著减少了错误的功能调用，同时保持了高任务性能，为工具增强的大型语言模型提供了一种成本效益高且高效解决方案。

Abstract: Tool-augmented large language models (LLMs) leverage external functions to
extend their capabilities, but inaccurate function calls can lead to
inefficiencies and increased costs.Existing methods address this challenge by
fine-tuning LLMs or using demonstration-based prompting, yet they often suffer
from high training overhead and fail to account for inconsistent demonstration
samples, which misguide the model's invocation behavior. In this paper, we
trained a behavior-aligned retriever (BAR), which provides behaviorally
consistent demonstrations to help LLMs make more accurate tool-using decisions.
To train the BAR, we construct a corpus including different function-calling
behaviors, i.e., calling or non-calling.We use the contrastive learning
framework to train the BAR with customized positive/negative pairs and a
dual-negative contrastive loss, ensuring robust retrieval of behaviorally
consistent examples.Experiments demonstrate that our approach significantly
reduces erroneous function calls while maintaining high task performance,
offering a cost-effective and efficient solution for tool-augmented LLMs.

</details>


### [20] [ISCA: A Framework for Interview-Style Conversational Agents](https://arxiv.org/abs/2508.14344)
*Charles Welch,Allison Lahnala,Vasudha Varadarajan,Lucie Flek,Rada Mihalcea,J. Lomax Boyd,João Sedoc*

Main category: cs.CL

TL;DR: 本文介绍了一种低计算量的非生成式系统，用于实现对话风格的对话代理，可方便地用于定性数据收集和定量分析，并通过在线管理面板轻松调整，代码开源。


<details>
  <summary>Details</summary>
Motivation: 在需要对对话流程进行控制或标准化的应用中，例如跟踪态度形成或行为变化，需要一种易于调整且无需编程的工具。

Method: 我们提出了一种低计算量的非生成式系统，用于实现对话风格的对话代理，可以通过受控交互和定量分析来促进定性数据收集。

Result: 我们展示了如何通过在线管理面板轻松调整系统以创建新的访谈，并提供了两个案例研究作为示例应用。

Conclusion: 我们的系统可以轻松调整，通过在线管理面板创建新的访谈，使工具无需编程即可使用。代码是开源的，允许其他人在此基础上构建并开发额外功能。

Abstract: We present a low-compute non-generative system for implementing
interview-style conversational agents which can be used to facilitate
qualitative data collection through controlled interactions and quantitative
analysis. Use cases include applications to tracking attitude formation or
behavior change, where control or standardization over the conversational flow
is desired. We show how our system can be easily adjusted through an online
administrative panel to create new interviews, making the tool accessible
without coding. Two case studies are presented as example applications, one
regarding the Expressive Interviewing system for COVID-19 and the other a
semi-structured interview to survey public opinion on emerging neurotechnology.
Our code is open-source, allowing others to build off of our work and develop
extensions for additional functionality.

</details>


### [21] [ZPD-SCA: Unveiling the Blind Spots of LLMs in Assessing Students' Cognitive Abilities](https://arxiv.org/abs/2508.14377)
*Wenhan Dong,Zhen Sun,Yuemeng Zhao,Zifan Peng,Jun Wu,Jingyi Zheng,Yule Liu,Xinlei He,Yu Wang,Ruiming Wang,Xinyi Huang,Lei Mo*

Main category: cs.CL

TL;DR: This paper introduces ZPD-SCA, a benchmark to assess Chinese reading comprehension difficulty. LLMs show improved performance with in-context examples but still have limitations in aligning material difficulty with students' cognitive abilities.


<details>
  <summary>Details</summary>
Motivation: To fill the gap in understanding LLMs' ability to evaluate reading comprehension difficulty across different student age groups, especially in the context of Chinese language education.

Method: Introduce ZPD-SCA, a novel benchmark specifically designed to assess stage-level Chinese reading comprehension difficulty, annotated by 60 Special Grade teachers.

Result: LLMs perform poorly in zero-shot learning scenarios, but their performance improves substantially with in-context examples. Some models achieve nearly double the accuracy of their zero-shot baselines. However, even the best-performing models display systematic directional biases.

Conclusion: LLMs possess emerging abilities to assess reading difficulty, while also exposing limitations in their current training for educationally aligned judgment. ZPD-SCA can provide a foundation for evaluating and improving LLMs in cognitively aligned educational applications.

Abstract: Large language models (LLMs) have demonstrated potential in educational
applications, yet their capacity to accurately assess the cognitive alignment
of reading materials with students' developmental stages remains insufficiently
explored. This gap is particularly critical given the foundational educational
principle of the Zone of Proximal Development (ZPD), which emphasizes the need
to match learning resources with Students' Cognitive Abilities (SCA). Despite
the importance of this alignment, there is a notable absence of comprehensive
studies investigating LLMs' ability to evaluate reading comprehension
difficulty across different student age groups, especially in the context of
Chinese language education. To fill this gap, we introduce ZPD-SCA, a novel
benchmark specifically designed to assess stage-level Chinese reading
comprehension difficulty. The benchmark is annotated by 60 Special Grade
teachers, a group that represents the top 0.15% of all in-service teachers
nationwide. Experimental results reveal that LLMs perform poorly in zero-shot
learning scenarios, with Qwen-max and GLM even falling below the probability of
random guessing. When provided with in-context examples, LLMs performance
improves substantially, with some models achieving nearly double the accuracy
of their zero-shot baselines. These results reveal that LLMs possess emerging
abilities to assess reading difficulty, while also exposing limitations in
their current training for educationally aligned judgment. Notably, even the
best-performing models display systematic directional biases, suggesting
difficulties in accurately aligning material difficulty with SCA. Furthermore,
significant variations in model performance across different genres underscore
the complexity of task. We envision that ZPD-SCA can provide a foundation for
evaluating and improving LLMs in cognitively aligned educational applications.

</details>


### [22] [Credence Calibration Game? Calibrating Large Language Models through Structured Play](https://arxiv.org/abs/2508.14390)
*Ke Fang,Tianyi Zhao,Lu Cheng*

Main category: cs.CL

TL;DR: 本文提出了一种基于提示的校准框架，受Credence Calibration Game的启发，通过反馈驱动的提示和先前性能的自然语言摘要，动态改进模型校准，并在多个模型和配置中展示了评估指标的持续改进。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）在决策关键领域越来越被部署，确保它们的置信度估计真实地对应于它们的实际正确性变得至关重要。现有的校准方法主要集中在事后调整或辅助模型训练上；然而，许多这些方法需要额外的监督或参数更新。

Method: 我们提出了一种基于提示的校准框架，受Credence Calibration Game的启发。我们的方法建立了一个结构化的交互循环，其中LLM根据其预测置信度与正确性的对齐程度接收反馈。通过反馈驱动的提示和先前性能的自然语言摘要，我们的框架动态地改进模型校准。

Result: 在不同模型和游戏配置上的广泛实验表明，评估指标有持续的改进。

Conclusion: 我们的结果突显了基于游戏的提示作为有效策略的潜力，用于LLM校准。

Abstract: As Large Language Models (LLMs) are increasingly deployed in
decision-critical domains, it becomes essential to ensure that their confidence
estimates faithfully correspond to their actual correctness. Existing
calibration methods have primarily focused on post-hoc adjustments or auxiliary
model training; however, many of these approaches necessitate additional
supervision or parameter updates. In this work, we propose a novel prompt-based
calibration framework inspired by the Credence Calibration Game. Our method
establishes a structured interaction loop wherein LLMs receive feedback based
on the alignment of their predicted confidence with correctness. Through
feedback-driven prompting and natural language summaries of prior performance,
our framework dynamically improves model calibration. Extensive experiments
across models and game configurations demonstrate consistent improvements in
evaluation metrics. Our results highlight the potential of game-based prompting
as an effective strategy for LLM calibration. Code and data are available at
https://anonymous.4open.science/r/LLM-Calibration/.

</details>


### [23] [DEPTH: Hallucination-Free Relation Extraction via Dependency-Aware Sentence Simplification and Two-tiered Hierarchical Refinement](https://arxiv.org/abs/2508.14391)
*Yupei Yang,Fan Feng,Lin Yang,Wanxi Deng,Lin Qu,Biwei Huang,Shikui Tu,Lei Xu*

Main category: cs.CL

TL;DR: 本文提出了一种名为DEPTH的框架，用于改进关系抽取任务，通过整合依赖感知的句子简化和两级分层细化来减少虚假预测，并在多个基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要集中在关系分类上，而LLMs在确定关系是否存在时常常遇到困难，尤其是在复杂句子结构或复杂语义的情况下，这会导致虚假预测。这些幻觉会引入知识图谱中的噪声边，影响结构化知识和下游任务的可靠性。

Method: DEPTH框架结合了依赖感知的句子简化和两级分层细化，分为两个阶段：(1) 基础模块通过利用最短依赖路径提取每个实体对的关系；(2) 优化模块汇总所有局部预测并基于对句子的整体理解进行修正。此外，还引入了一个因果驱动的奖励模型，以减少奖励黑客行为。

Result: DEPTH框架在六个基准测试中表现出色，平均幻觉率降低到7.0%，并且在平均F1分数上比最先进的基线提高了17.2%。

Conclusion: DEPTH框架在六个基准测试中表现出色，平均幻觉率降低到7.0%，并且在平均F1分数上比最先进的基线提高了17.2%。

Abstract: Relation extraction enables the construction of structured knowledge for many
downstream applications. While large language models (LLMs) have shown great
promise in this domain, most existing methods concentrate on relation
classification, which predicts the semantic relation type between a related
entity pair. However, we observe that LLMs often struggle to reliably determine
whether a relation exists, especially in cases involving complex sentence
structures or intricate semantics, which leads to spurious predictions. Such
hallucinations can introduce noisy edges in knowledge graphs, compromising the
integrity of structured knowledge and downstream reliability. To address these
challenges, we propose DEPTH, a framework that integrates Dependency-aware
sEntence simPlification and Two-tiered Hierarchical refinement into the
relation extraction pipeline. Given a sentence and its candidate entity pairs,
DEPTH operates in two stages: (1) the Grounding module extracts relations for
each pair by leveraging their shortest dependency path, distilling the sentence
into a minimal yet coherent relational context that reduces syntactic noise
while preserving key semantics; (2) the Refinement module aggregates all local
predictions and revises them based on a holistic understanding of the sentence,
correcting omissions and inconsistencies. We further introduce a
causality-driven reward model that mitigates reward hacking by disentangling
spurious correlations, enabling robust fine-tuning via reinforcement learning
with human feedback. Experiments on six benchmarks demonstrate that DEPTH
reduces the average hallucination rate to 7.0\% while achieving a 17.2\%
improvement in average F1 score over state-of-the-art baselines.

</details>


### [24] [Cognitive Surgery: The Awakening of Implicit Territorial Awareness in LLMs](https://arxiv.org/abs/2508.14408)
*Yinghan Zhou,Weifeng Zhu,Juan Wen,Wanli Peng,Zhengxian Wu,Yiming Xue*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型在个体展示范式下的自我识别能力，并提出了一种新框架Cognitive Surgery (CoSur)来提升其性能。实验结果显示该方法有效改善了LLMs在IPP场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管之前的研究已经观察到LLMs在个体展示范式下的性能下降现象，但其潜在原因尚未被系统分析。本文旨在探究这一现象的根本原因，并提出一种有效的方法来改善LLMs在IPP下的自我识别能力。

Method: 本文首先复制了现有研究以确认LLMs在IPP下难以区分自生成和他生成文本。然后，我们调查了这种失败的原因，并将其归因于隐式领土意识（ITA）现象。为了唤醒LLMs的ITA，我们提出了Cognitive Surgery (CoSur)，这是一个包含四个主要模块的框架：表示提取、领土构建、作者身份辨别和认知编辑。

Result: 实验结果表明，本文提出的CoSur方法显著提高了三种不同LLM在IPP场景下的性能，分别达到了83.25%、66.19%和88.01%的平均准确率。

Conclusion: 本文提出了一种名为Cognitive Surgery (CoSur)的新框架，旨在唤醒大型语言模型的隐式领土意识，从而提高它们在个体展示范式下的自我识别能力。实验结果表明，该方法显著提高了三种不同LLM在IPP场景下的性能。

Abstract: Large language models (LLMs) have been shown to possess a degree of
self-recognition capability-the ability to identify whether a given text was
generated by themselves. Prior work has demonstrated that this capability is
reliably expressed under the Pair Presentation Paradigm (PPP), where the model
is presented with two texts and asked to choose which one it authored. However,
performance deteriorates sharply under the Individual Presentation Paradigm
(IPP), where the model is given a single text to judge authorship. Although
this phenomenon has been observed, its underlying causes have not been
systematically analyzed. In this paper, we first replicate existing findings to
confirm that LLMs struggle to distinguish self- from other-generated text under
IPP. We then investigate the reasons for this failure and attribute it to a
phenomenon we term Implicit Territorial Awareness (ITA)-the model's latent
ability to distinguish self- and other-texts in representational space, which
remains unexpressed in its output behavior. To awaken the ITA of LLMs, we
propose Cognitive Surgery (CoSur), a novel framework comprising four main
modules: representation extraction, territory construction, authorship
discrimination and cognitive editing. Experimental results demonstrate that our
proposed method improves the performance of three different LLMs in the IPP
scenario, achieving average accuracies of 83.25%, 66.19%, and 88.01%,
respectively.

</details>


### [25] [Knowledge Graph-Infused Fine-Tuning for Structured Reasoning in Large Language Models](https://arxiv.org/abs/2508.14427)
*Wuyang Zhang,Yexin Tian,Xiandong Meng,Mengjie Wang,Junliang Du*

Main category: cs.CL

TL;DR: 本文提出一种基于知识图谱注入的微调算法框架，通过引入结构化图信息和融合机制，提升语言模型在结构化推理和实体提取任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在处理需要结构化知识的任务时存在的推理链缺失和实体级语义理解不足的问题。

Method: 该方法基于预训练语言模型，引入结构化图信息进行辅助学习，使用图神经网络编码实体及其关系，构建基于图的语义表示，并设计融合机制联合建模知识图谱嵌入与语言模型的上下文表示。同时引入门控机制以动态平衡语言语义和结构知识的贡献，提升知识整合的鲁棒性。

Result: 实验结果表明，所提出的结构感知微调框架显著增强了模型对复杂语义单元的表示能力，在实体识别、问答和语言生成等任务中表现出更好的语义一致性和上下文逻辑建模能力。

Conclusion: 该研究提出了一种基于知识图谱注入的微调算法框架，有效提升了模型在结构化推理和实体提取场景中的语义一致性和上下文逻辑建模能力。

Abstract: This paper addresses the problems of missing reasoning chains and
insufficient entity-level semantic understanding in large language models when
dealing with tasks that require structured knowledge. It proposes a fine-tuning
algorithm framework based on knowledge graph injection. The method builds on
pretrained language models and introduces structured graph information for
auxiliary learning. A graph neural network is used to encode entities and their
relations, constructing a graph-based semantic representation. A fusion
mechanism is then designed to jointly model the knowledge graph embeddings with
the contextual representations from the language model. To enhance the
robustness of knowledge integration, a gating mechanism is introduced to
dynamically balance the contributions of linguistic semantics and structural
knowledge. This effectively mitigates conflicts between different
representational spaces. During training, a joint loss function is constructed
to account for both task performance and structural alignment objectives. This
helps improve the accuracy of entity prediction and semantic reasoning. The
study also includes a series of systematic sensitivity experiments. It
evaluates the effects of learning rate, graph coverage, and structural
perturbations on model performance. The results further validate the
effectiveness and stability of the proposed method across tasks such as entity
recognition, question answering, and language generation. Experimental findings
show that the proposed structure-aware fine-tuning framework significantly
enhances the model's ability to represent complex semantic units. It
demonstrates better semantic consistency and contextual logic modeling in
scenarios involving structural reasoning and entity extraction.

</details>


### [26] [NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model](https://arxiv.org/abs/2508.14444)
*NVIDIA,:,Aarti Basant,Abhijit Khairnar,Abhijit Paithankar,Abhinav Khattar,Adi Renduchintala,Adithya Renduchintala,Aditya Malte,Akhiad Bercovich,Akshay Hazare,Alejandra Rico,Aleksander Ficek,Alex Kondratenko,Alex Shaposhnikov,Ali Taghibakhshi,Amelia Barton,Ameya Sunil Mahabaleshwarkar,Amy Shen,Andrew Tao,Ann Guan,Anna Shors,Anubhav Mandarwal,Arham Mehta,Arun Venkatesan,Ashton Sharabiani,Ashwath Aithal,Ashwin Poojary,Ayush Dattagupta,Balaram Buddharaju,Banghua Zhu,Barnaby Simkin,Bilal Kartal,Bita Darvish Rouhani,Bobby Chen,Boris Ginsburg,Brandon Norick,Brian Yu,Bryan Catanzaro,Charles Wang,Charlie Truong,Chetan Mungekar,Chintan Patel,Chris Alexiuk,Christian Munley,Christopher Parisien,Dan Su,Daniel Afrimi,Daniel Korzekwa,Daniel Rohrer,Daria Gitman,David Mosallanezhad,Deepak Narayanan,Dima Rekesh,Dina Yared,Dmytro Pykhtar,Dong Ahn,Duncan Riach,Eileen Long,Elliott Ning,Eric Chung,Erick Galinkin,Evelina Bakhturina,Gargi Prasad,Gerald Shen,Haim Elisha,Harsh Sharma,Hayley Ross,Helen Ngo,Herman Sahota,Hexin Wang,Hoo Chang Shin,Hua Huang,Iain Cunningham,Igor Gitman,Ivan Moshkov,Jaehun Jung,Jan Kautz,Jane Polak Scowcroft,Jared Casper,Jimmy Zhang,Jinze Xue,Jocelyn Huang,Joey Conway,John Kamalu,Jonathan Cohen,Joseph Jennings,Julien Veron Vialard,Junkeun Yi,Jupinder Parmar,Kari Briski,Katherine Cheung,Katherine Luna,Keith Wyss,Keshav Santhanam,Kezhi Kong,Krzysztof Pawelec,Kumar Anik,Kunlun Li,Kushan Ahmadian,Lawrence McAfee,Laya Sleiman,Leon Derczynski,Luis Vega,Maer Rodrigues de Melo,Makesh Narsimhan Sreedhar,Marcin Chochowski,Mark Cai,Markus Kliegl,Marta Stepniewska-Dziubinska,Matvei Novikov,Mehrzad Samadi,Meredith Price,Meriem Boubdir,Michael Boone,Michael Evans,Michal Bien,Michal Zawalski,Miguel Martinez,Mike Chrzanowski,Mohammad Shoeybi,Mostofa Patwary,Namit Dhameja,Nave Assaf,Negar Habibi,Nidhi Bhatia,Nikki Pope,Nima Tajbakhsh,Nirmal Kumar Juluru,Oleg Rybakov,Oleksii Hrinchuk,Oleksii Kuchaiev,Oluwatobi Olabiyi,Pablo Ribalta,Padmavathy Subramanian,Parth Chadha,Pavlo Molchanov,Peter Dykas,Peter Jin,Piotr Bialecki,Piotr Januszewski,Pradeep Thalasta,Prashant Gaikwad,Prasoon Varshney,Pritam Gundecha,Przemek Tredak,Rabeeh Karimi Mahabadi,Rajen Patel,Ran El-Yaniv,Ranjit Rajan,Ria Cheruvu,Rima Shahbazyan,Ritika Borkar,Ritu Gala,Roger Waleffe,Ruoxi Zhang,Russell J. Hewett,Ryan Prenger,Sahil Jain,Samuel Kriman,Sanjeev Satheesh,Saori Kaji,Sarah Yurick,Saurav Muralidharan,Sean Narenthiran,Seonmyeong Bak,Sepehr Sameni,Seungju Han,Shanmugam Ramasamy,Shaona Ghosh,Sharath Turuvekere Sreenivas,Shelby Thomas,Shizhe Diao,Shreya Gopal,Shrimai Prabhumoye,Shubham Toshniwal,Shuoyang Ding,Siddharth Singh,Siddhartha Jain,Somshubra Majumdar,Stefania Alborghetti,Syeda Nahida Akter,Terry Kong,Tim Moon,Tomasz Hliwiak,Tomer Asida,Tony Wang,Twinkle Vashishth,Tyler Poon,Udi Karpas,Vahid Noroozi,Venkat Srinivasan,Vijay Korthikanti,Vikram Fugro,Vineeth Kalluru,Vitaly Kurin,Vitaly Lavrukhin,Wasi Uddin Ahmad,Wei Du,Wonmin Byeon,Ximing Lu,Xin Dong,Yashaswi Karnati,Yejin Choi,Yian Zhang,Ying Lin,Yonggan Fu,Yoshi Suhara,Zhen Dong,Zhiyu Li,Zhongbo Zhu,Zijia Chen*

Main category: cs.CL

TL;DR: Nemotron-Nano-9B-v2是一种混合Mamba-Transformer语言模型，旨在提高推理任务的吞吐量，同时保持与类似大小模型相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了提高推理工作负载的吞吐量并实现与类似大小模型相当的准确性，研究者设计了Nemotron-Nano-9B-v2。

Method: Nemotron-Nano-9B-v2通过将Transformer架构中的大部分自注意力层替换为Mamba-2层，提高了推理速度，并采用Minitron策略进行压缩和蒸馏以实现大规模推理。

Result: Nemotron-Nano-9B-v2在推理基准测试中表现出与现有模型相当或更好的准确性，同时在8k输入和16k输出令牌的推理设置中实现了高达6倍的更高推理吞吐量。

Conclusion: Nemotron-Nano-9B-v2在推理任务中实现了比现有类似大小模型更高的推理吞吐量，同时保持了相当或更好的准确性。

Abstract: We introduce Nemotron-Nano-9B-v2, a hybrid Mamba-Transformer language model
designed to increase throughput for reasoning workloads while achieving
state-of-the-art accuracy compared to similarly-sized models.
Nemotron-Nano-9B-v2 builds on the Nemotron-H architecture, in which the
majority of the self-attention layers in the common Transformer architecture
are replaced with Mamba-2 layers, to achieve improved inference speed when
generating the long thinking traces needed for reasoning. We create
Nemotron-Nano-9B-v2 by first pre-training a 12-billion-parameter model
(Nemotron-Nano-12B-v2-Base) on 20 trillion tokens using an FP8 training recipe.
After aligning Nemotron-Nano-12B-v2-Base, we employ the Minitron strategy to
compress and distill the model with the goal of enabling inference on up to
128k tokens on a single NVIDIA A10G GPU (22GiB of memory, bfloat16 precision).
Compared to existing similarly-sized models (e.g., Qwen3-8B), we show that
Nemotron-Nano-9B-v2 achieves on-par or better accuracy on reasoning benchmarks
while achieving up to 6x higher inference throughput in reasoning settings like
8k input and 16k output tokens. We are releasing Nemotron-Nano-9B-v2,
Nemotron-Nano12B-v2-Base, and Nemotron-Nano-9B-v2-Base checkpoints along with
the majority of our pre- and post-training datasets on Hugging Face.

</details>


### [27] [In2x at WMT25 Translation Task](https://arxiv.org/abs/2508.14472)
*Lei Pang,Hanyi Mao,Quanjia Xiao,HaiXiao Liu,Xiangyi Li*

Main category: cs.CL

TL;DR: この論文では、大規模言語モデルを低資源言語に拡張するための新しいアプローチが提案されています。


<details>
  <summary>Details</summary>
Motivation: 大規模言語モデルシステムが低資源またはあまり使われていない言語で優れた性能を発揮できるようにすること。

Method: データ構築方法と報酬モデルの設計を含む、拡張可能なパラダイムの探求。

Result: 日本語関連の翻訳タスクに焦点を当てたオープンシステムの提出。

Conclusion: 本文の目的は、大規模言語モデルを低資源またはあまり使われていない言語に一般化するパラダイムを開発することです。

Abstract: This paper presents the open-system submission by the In2x research team for
the WMT25 General Machine Translation Shared Task. Our submission focuses on
Japanese-related translation tasks, aiming to explore a generalizable paradigm
for extending large language models (LLMs) to other languages. This paradigm
encompasses aspects such as data construction methods and reward model design.
The ultimate goal is to enable large language model systems to achieve
exceptional performance in low-resource or less commonly spoken languages.

</details>


### [28] [Reasoning is about giving reasons](https://arxiv.org/abs/2508.14488)
*Krunal Shah,Dan Roth*

Main category: cs.CL

TL;DR: 本文提出了一种新的中间表示（RLS）来捕捉自然语言论证的逻辑结构，从而支持各种推理形式并提高解释性和扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前的方法在解释性和扩展性方面存在不足，无法支持归纳或识别矛盾等任务。因此，需要一种更有效的中间表示来解决这些问题。

Method: 通过识别自然语言论证的逻辑结构（RLS），该方法能够确定论证中的逻辑原子及其规则，并利用这些信息进行推理。

Result: 本文在三个流行的推理数据集中验证了该方法的有效性，展示了其在高精度下识别和提取自然语言论证逻辑结构的能力，从而显著增强了推理能力。

Conclusion: 本文提出了一种中间表示（RLS），它可以理解自然语言论证的逻辑结构，从而支持各种推理形式，包括任意深度的推理、实时错误修正和与论证的互动讨论。

Abstract: Convincing someone of the truth value of a premise requires understanding and
articulating the core logical structure of the argument which proves or
disproves the premise. Understanding the logical structure of an argument
refers to understanding the underlying "reasons" which make up the proof or
disproof of the premise - as a function of the "logical atoms" in the argument.
While it has been shown that transformers can "chain" rules to derive simple
arguments, the challenge of articulating the "reasons" remains. Not only do
current approaches to chaining rules suffer in terms of their interpretability,
they are also quite constrained in their ability to accommodate extensions to
theoretically equivalent reasoning tasks - a model trained to chain rules
cannot support abduction or identify contradictions. In this work we suggest
addressing these shortcomings by identifying an intermediate representation
(which we call the Representation of the Logical Structure (RLS) of the
argument) that possesses an understanding of the logical structure of a natural
language argument - the logical atoms in the argument and the rules
incorporating them. Given the logical structure, reasoning is deterministic and
easy to compute. Therefore, our approach supports all forms of reasoning that
depend on the logical structure of the natural language argument, including
arbitrary depths of reasoning, on-the-fly mistake rectification and interactive
discussion with respect to an argument. We show that we can identify and
extract the logical structure of natural language arguments in three popular
reasoning datasets with high accuracies, thus supporting explanation generation
and extending the reasoning capabilities significantly.

</details>


### [29] [EmoTale: An Enacted Speech-emotion Dataset in Danish](https://arxiv.org/abs/2508.14548)
*Maja J. Hjuler,Harald V. Skat-Rørdam,Line H. Clemmensen,Sneha Das*

Main category: cs.CL

TL;DR: EmoTale是一个针对丹麦语和英语的情感语音语料库，通过SER模型验证了其有效性，结果与现有数据集相当。


<details>
  <summary>Details</summary>
Motivation: 由于较小语言（如丹麦语）缺乏功能性数据集，因此需要创建一个包含丹麦语和英语语音记录的语料库，并验证其有效性。

Method: 使用自监督语音模型（SSLM）嵌入和openSMILE特征提取器开发语音情感识别（SER）模型，并通过留一说话者交叉验证评估性能。

Result: EmoTale的最优模型在留一说话者交叉验证下实现了64.1%的未加权平均召回率，与DES的表现相当。

Conclusion: EmoTale是一个具有丹麦语和英语语音记录及其相关表现情感注释的语料库，其性能与DES相当，证明了其有效性。

Abstract: While multiple emotional speech corpora exist for commonly spoken languages,
there is a lack of functional datasets for smaller (spoken) languages, such as
Danish. To our knowledge, Danish Emotional Speech (DES), published in 1997, is
the only other database of Danish emotional speech. We present EmoTale; a
corpus comprising Danish and English speech recordings with their associated
enacted emotion annotations. We demonstrate the validity of the dataset by
investigating and presenting its predictive power using speech emotion
recognition (SER) models. We develop SER models for EmoTale and the reference
datasets using self-supervised speech model (SSLM) embeddings and the openSMILE
feature extractor. We find the embeddings superior to the hand-crafted
features. The best model achieves an unweighted average recall (UAR) of 64.1%
on the EmoTale corpus using leave-one-speaker-out cross-validation, comparable
to the performance on DES.

</details>


### [30] [Towards Skeletal and Signer Noise Reduction in Sign Language Production via Quaternion-Based Pose Encoding and Contrastive Learning](https://arxiv.org/abs/2508.14574)
*Guilhem Fauré,Mostafa Sadeghi,Sam Bigeard,Slim Ouni*

Main category: cs.CL

TL;DR: 本文提出两种改进方法以提高神经手语生成模型的鲁棒性：使用四元数空间中的骨旋转编码姿势并采用测地线损失，以及引入基于语义相似性的对比损失。实验结果显示，这些方法显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 神经手语生成（SLP）的主要挑战之一在于手势的高类内变异性，这源于签名者形态和训练数据中的风格多样性。为了提高对这些变化的鲁棒性，我们提出了两种改进标准渐进式变换器（PT）架构的方法。

Method: 首先，使用四元数空间中的骨旋转对姿势进行编码，并使用测地线损失进行训练，以提高角度关节运动的准确性和清晰度。其次，引入对比损失，通过语义相似性对解码器嵌入进行结构化，使用词素重叠或基于SBERT的句子相似性，旨在过滤掉不传达相关语义信息的解剖学和风格特征。

Result: 在Phoenix14T数据集上，仅使用对比损失就比PT基线提高了16%的正确关键点概率。当与基于四元数的姿势编码结合使用时，模型实现了骨角误差的6%减少。

Conclusion: 这些结果表明，在基于Transformer的SLP模型训练中，结合骨骼结构建模和语义引导的对比目标是有益的。

Abstract: One of the main challenges in neural sign language production (SLP) lies in
the high intra-class variability of signs, arising from signer morphology and
stylistic variety in the training data. To improve robustness to such
variations, we propose two enhancements to the standard Progressive
Transformers (PT) architecture (Saunders et al., 2020). First, we encode poses
using bone rotations in quaternion space and train with a geodesic loss to
improve the accuracy and clarity of angular joint movements. Second, we
introduce a contrastive loss to structure decoder embeddings by semantic
similarity, using either gloss overlap or SBERT-based sentence similarity,
aiming to filter out anatomical and stylistic features that do not convey
relevant semantic information. On the Phoenix14T dataset, the contrastive loss
alone yields a 16% improvement in Probability of Correct Keypoint over the PT
baseline. When combined with quaternion-based pose encoding, the model achieves
a 6% reduction in Mean Bone Angle Error. These results point to the benefit of
incorporating skeletal structure modeling and semantically guided contrastive
objectives on sign pose representations into the training of Transformer-based
SLP models.

</details>


### [31] [Filling the Gap for Uzbek: Creating Translation Resources for Southern Uzbek](https://arxiv.org/abs/2508.14586)
*Mukhammadsaid Mamasaidov,Azizullah Aral,Abror Shopulatov,Mironshoh Inomjonov*

Main category: cs.CL

TL;DR: 本文介绍了针对南方乌兹别克语的新资源，包括一个997句的FLORES+开发集、39,994句平行句子以及微调的NLLB-200模型，并提出了一种后处理方法来恢复阿拉伯文半空格字符，以提高形态边界的处理效果。所有数据集、模型和工具均已公开发布，以支持未来对南方乌兹别克语和其他低资源语言的研究。


<details>
  <summary>Details</summary>
Motivation: 南方乌兹别克语在自然语言处理中代表性不足，尽管有大约500万使用者。

Method: 提出了一种用于恢复阿拉伯文半空格字符的后处理方法，这有助于处理形态边界。还发布了新的资源，包括一个997句的FLORES+开发集、39,994句平行句子以及微调的NLLB-200模型。

Result: 发布了新的资源，包括一个997句的FLORES+开发集、39,994句平行句子以及微调的NLLB-200模型（lutfiy）。

Conclusion: 所有数据集、模型和工具都已公开发布，以支持未来对南方乌兹别克语和其他低资源语言的研究。

Abstract: Southern Uzbek (uzs) is a Turkic language variety spoken by around 5 million
people in Afghanistan and differs significantly from Northern Uzbek (uzn) in
phonology, lexicon, and orthography. Despite the large number of speakers,
Southern Uzbek is underrepresented in natural language processing. We present
new resources for Southern Uzbek machine translation, including a 997-sentence
FLORES+ dev set, 39,994 parallel sentences from dictionary, literary, and web
sources, and a fine-tuned NLLB-200 model (lutfiy). We also propose a
post-processing method for restoring Arabic-script half-space characters, which
improves handling of morphological boundaries. All datasets, models, and tools
are released publicly to support future work on Southern Uzbek and other
low-resource languages.

</details>


### [32] [Continuous sentiment scores for literary and multilingual contexts](https://arxiv.org/abs/2508.14620)
*Laurits Lyngbaek,Pascale Feldkamp,Yuri Bizzoni,Kristoffer Nielbo,Kenneth Enevoldsen*

Main category: cs.CL

TL;DR: 本文提出了一种基于概念向量投影的新型连续情感评分方法，在多语言文学数据上进行训练，能够更有效地捕捉跨类型、语言和历史时期的细微情感表达。该方法在英语和丹麦语文本上优于现有工具，产生的情感分数分布与人类评分非常接近，从而实现了文学中更准确的情感分析和情感弧建模。


<details>
  <summary>Details</summary>
Motivation: 情感分析广泛用于量化文本中的情感，但其在文学文本中的应用面临独特的挑战，如隐喻语言、风格歧义以及情感唤起策略。传统的基于字典的工具表现不佳，尤其是对于低资源语言，而变压器模型通常输出粗略的分类标签，限制了细粒度分析。

Method: 我们引入了一种基于概念向量投影的新型连续情感评分方法，在多语言文学数据上进行训练，能够更有效地捕捉跨类型、语言和历史时期的细微情感表达。

Result: 我们的方法在英语和丹麦语文本上优于现有工具，产生的情感分数分布与人类评分非常接近，从而实现了文学中更准确的情感分析和情感弧建模。

Conclusion: 我们的方法在英语和丹麦语文本上优于现有工具，产生的情感分数分布与人类评分非常接近，从而实现了文学中更准确的情感分析和情感弧建模。

Abstract: Sentiment Analysis is widely used to quantify sentiment in text, but its
application to literary texts poses unique challenges due to figurative
language, stylistic ambiguity, as well as sentiment evocation strategies.
Traditional dictionary-based tools often underperform, especially for
low-resource languages, and transformer models, while promising, typically
output coarse categorical labels that limit fine-grained analysis. We introduce
a novel continuous sentiment scoring method based on concept vector projection,
trained on multilingual literary data, which more effectively captures nuanced
sentiment expressions across genres, languages, and historical periods. Our
approach outperforms existing tools on English and Danish texts, producing
sentiment scores whose distribution closely matches human ratings, enabling
more accurate analysis and sentiment arc modeling in literature.

</details>


### [33] [Improving in-context learning with a better scoring function](https://arxiv.org/abs/2508.14685)
*Omar Naim,Swarnadeep Bhar,Jérôme Bolte,Nicholas Asher*

Main category: cs.CL

TL;DR: 本文研究了LLMs在ICL中的限制，并提出了SSA方法来改进性能。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在涉及一阶量词和线性函数的ICL中的限制，并寻找改进方法。

Method: 提出了一种名为SSA的新方法，作为Softmax的替代方案。

Result: 实验证明SSA在目标任务上显著提高了性能。

Conclusion: SSA可以显著提高性能，并且在各种语言探测任务中表现优于或等于基于Softmax的模型。

Abstract: Large language models (LLMs) exhibit a remarkable capacity to learn by
analogy, known as in-context learning (ICL). However, recent studies have
revealed limitations in this ability. In this paper, we examine these
limitations on tasks involving first-order quantifiers such as {\em all} and
{\em some}, as well as on ICL with linear functions. We identify Softmax, the
scoring function in attention mechanism, as a contributing factor to these
constraints. To address this, we propose \textbf{scaled signed averaging
(SSA)}, a novel alternative to Softmax. Empirical results show that SSA
dramatically improves performance on our target tasks. Furthermore, we evaluate
both encoder-only and decoder-only transformers models with SSA, demonstrating
that they match or exceed their Softmax-based counterparts across a variety of
linguistic probing tasks.

</details>


### [34] [ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Medicine](https://arxiv.org/abs/2508.14706)
*Junying Chen,Zhenyang Cai,Zhiheng Liu,Yunjin Yang,Rongsheng Wang,Qingying Xiao,Xiangyi Feng,Zhan Su,Jing Guo,Xiang Wan,Guangjun Yu,Haizhou Li,Benyou Wang*

Main category: cs.CL

TL;DR: 本文介绍了ShizhenGPT，这是第一个针对TCM的多模态语言模型，旨在克服数据稀缺和多模态诊断的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于高质量的TCM数据稀缺以及TCM诊断的多模态性质，LLM在TCM中的潜力尚未被充分探索。

Method: 我们提出了ShizhenGPT，这是第一个针对TCM的多模态LLM，并构建了最大的TCM数据集。

Result: 实验表明，ShizhenGPT优于可比较规模的LLM，并与更大的专有模型竞争。此外，它在现有的多模态LLM中领先于TCM视觉理解。

Conclusion: ShizhenGPT展示了在TCM领域中多模态感知和诊断的潜力，为未来的探索提供了基础。

Abstract: Despite the success of large language models (LLMs) in various domains, their
potential in Traditional Chinese Medicine (TCM) remains largely underexplored
due to two critical barriers: (1) the scarcity of high-quality TCM data and (2)
the inherently multimodal nature of TCM diagnostics, which involve looking,
listening, smelling, and pulse-taking. These sensory-rich modalities are beyond
the scope of conventional LLMs. To address these challenges, we present
ShizhenGPT, the first multimodal LLM tailored for TCM. To overcome data
scarcity, we curate the largest TCM dataset to date, comprising 100GB+ of text
and 200GB+ of multimodal data, including 1.2M images, 200 hours of audio, and
physiological signals. ShizhenGPT is pretrained and instruction-tuned to
achieve deep TCM knowledge and multimodal reasoning. For evaluation, we collect
recent national TCM qualification exams and build a visual benchmark for
Medicinal Recognition and Visual Diagnosis. Experiments demonstrate that
ShizhenGPT outperforms comparable-scale LLMs and competes with larger
proprietary models. Moreover, it leads in TCM visual understanding among
existing multimodal LLMs and demonstrates unified perception across modalities
like sound, pulse, smell, and vision, paving the way toward holistic multimodal
perception and diagnosis in TCM. Datasets, models, and code are publicly
available. We hope this work will inspire further exploration in this field.

</details>


### [35] [The Digital Sous Chef -- A Comparative Study on Fine-Tuning Language Models for Recipe Generation](https://arxiv.org/abs/2508.14718)
*Shubham Pundhir,Ganesh Bagler*

Main category: cs.CL

TL;DR: 本文建立了文本基础的食谱生成任务的基准，提出了一种改进的分词策略，并展示了基于Transformer的大模型在性能上的显著提升。


<details>
  <summary>Details</summary>
Motivation: 本文旨在建立一个严格基准，用于文本基础的食谱生成任务，解决通用分词器的局限性，以保持食谱结构和精确数值。

Method: 本文提出了一种针对标记化策略，通过在词汇表中添加23个常见分数标记和自定义结构标记来增强领域特定性。同时，对微调的GPT-2大模型（774M）与GPT-2小模型（124M）以及传统LSTM/RNN基线进行了全面比较。

Result: 实验结果表明，基于Transformer的大模型在BERTScore（F1）上比最佳循环基线提高了超过20%（0.92 vs 0.72），同时将困惑度降低了69.8%。

Conclusion: 本文讨论了文本基础的食谱生成任务中的剩余挑战，特别是事实准确性问题，并概述了这项基础研究如何为整合现实世界的约束和多模态输入的高级食谱生成研究铺平道路。

Abstract: We established a rigorous benchmark for text-based recipe generation, a
fundamental task in natural language generation. We present a comprehensive
comparative study contrasting a fine-tuned GPT-2 large (774M) model against the
GPT-2 small (124M) model and traditional LSTM/RNN baselines on the 5-cuisine
corpus from RecipeDB. Our key contribution is a targeted tokenization strategy
that augments the vocabulary with 23 common fraction tokens and custom
structural markers. This approach addresses a critical limitation of generic
tokenizers by preserving essential recipe structures and precise numerical
quantities, thereby enhancing domain specificity. Performance is evaluated
using a comprehensive suite of seven automatic metrics spanning fluency
(BLEU-4, METEOR), coherence (ROUGE-L), semantic relevance (BERTScore), and
diversity. Our experiments show that the large transformer-based approach
yields a >20% relative improvement in BERTScore (F1) (0.92 vs 0.72) over the
best recurrent baseline, while reducing perplexity by 69.8%. We conclude with a
discussion of remaining challenges, particularly regarding factual accuracy,
and outline how this foundational study paves the way for integrating
real-world constraints and multi-modal inputs in advanced recipe generation
research.

</details>


### [36] [Transplant Then Regenerate: A New Paradigm for Text Data Augmentation](https://arxiv.org/abs/2508.14723)
*Guangzhan Wang,Hongyu Zhang,Beijun Shen,Xiaodong Gu*

Main category: cs.CL

TL;DR: This paper introduces LMTransplant, a novel text augmentation method that leverages LLMs by transplanting seed text into an expanded context and regenerating variants, resulting in more diverse and creative content while preserving the original attributes.


<details>
  <summary>Details</summary>
Motivation: Traditional data augmentation methods like Back-translation focus on lexical-level rephrasing, which primarily produces variations with the same semantics. While LLMs have enhanced text augmentation through their 'knowledge emergence' capability, controlling the style and structure of these outputs remains challenging and requires meticulous prompt engineering.

Method: LMTransplant is a novel text augmentation paradigm that leverages LLMs. The core idea is transplant-then-regenerate: incorporating seed text into a context expanded by LLM, and asking the LLM to regenerate a variant based on the expanded context.

Result: LMTransplant was evaluated across various text-related tasks, demonstrating its superior performance over existing text augmentation methods. Moreover, it shows exceptional scalability as the size of augmented data grows.

Conclusion: LMTransplant demonstrates superior performance over existing text augmentation methods and shows exceptional scalability as the size of augmented data grows.

Abstract: Data augmentation is a critical technique in deep learning. Traditional
methods like Back-translation typically focus on lexical-level rephrasing,
which primarily produces variations with the same semantics. While large
language models (LLMs) have enhanced text augmentation by their "knowledge
emergence" capability, controlling the style and structure of these outputs
remains challenging and requires meticulous prompt engineering. In this paper,
we propose LMTransplant, a novel text augmentation paradigm leveraging LLMs.
The core idea of LMTransplant is transplant-then-regenerate: incorporating seed
text into a context expanded by LLM, and asking the LLM to regenerate a variant
based on the expanded context. This strategy allows the model to create more
diverse and creative content-level variants by fully leveraging the knowledge
embedded in LLMs, while preserving the core attributes of the original text. We
evaluate LMTransplant across various text-related tasks, demonstrating its
superior performance over existing text augmentation methods. Moreover,
LMTransplant demonstrates exceptional scalability as the size of augmented data
grows.

</details>


### [37] [Evaluating Multilingual and Code-Switched Alignment in LLMs via Synthetic Natural Language Inference](https://arxiv.org/abs/2508.14735)
*Samir Abdaljalil,Erchin Serpedin,Khalid Qaraqe,Hasan Kurban*

Main category: cs.CL

TL;DR: 本文提出了一种多语言自然语言推理的受控评估框架，通过生成合成的逻辑前提-假设对并将其翻译成多种语言来测试大型语言模型的跨语言推理能力。结果显示代码切换可以提高性能，并指出代码切换是提高多语言鲁棒性的有希望的方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）越来越多地应用于多语言环境，但它们在不同语言之间保持一致、逻辑基础对齐的能力仍然未被充分探索。

Method: 我们提出了一个受控的评估框架，用于多语言自然语言推理（NLI），该框架生成合成的基于逻辑的前提-假设对，并将它们翻译成一个类型学多样的语言集。

Result: 令人惊讶的是，代码切换不会降低性能，甚至可能提高性能，这表明翻译引起的词汇变化可能作为正则化信号。

Conclusion: 我们的研究揭示了当前大型语言模型在跨语言推理中的潜力和脆弱性，并将代码切换识别为提高多语言鲁棒性的有希望的杠杆。

Abstract: Large language models (LLMs) are increasingly applied in multilingual
contexts, yet their capacity for consistent, logically grounded alignment
across languages remains underexplored. We present a controlled evaluation
framework for multilingual natural language inference (NLI) that generates
synthetic, logic-based premise-hypothesis pairs and translates them into a
typologically diverse set of languages. This design enables precise control
over semantic relations and allows testing in both monolingual and
mixed-language (code-switched) conditions. Surprisingly, code-switching does
not degrade, and can even improve, performance, suggesting that
translation-induced lexical variation may serve as a regularization signal. We
validate semantic preservation through embedding-based similarity analyses and
cross-lingual alignment visualizations, confirming the fidelity of translated
pairs. Our findings expose both the potential and the brittleness of current
LLM cross-lingual reasoning, and identify code-switching as a promising lever
for improving multilingual robustness. Code available at:
https://github.com/KurbanIntelligenceLab/nli-stress-testing

</details>


### [38] [TransLLM: A Unified Multi-Task Foundation Framework for Urban Transportation via Learnable Prompting](https://arxiv.org/abs/2508.14782)
*Jiaming Leng,Yunying Bi,Chuan Qin,Bing Yin,Yanyong Zhang,Chao Wang*

Main category: cs.CL

TL;DR: 本文提出了一个统一的基础框架TransLLM，通过可学习的提示组合将时空建模与大型语言模型结合，以解决城市交通系统中的多个挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个关键限制：小规模深度学习模型是任务特定的且数据密集，而大型语言模型在交通领域处理结构化时空数据和数值推理时表现不佳。

Method: 提出了一种统一的基础框架TransLLM，通过可学习的提示组合将时空建模与大型语言模型结合。

Result: 在七个数据集和三个任务上的实验表明，TransLLM在监督和零样本设置中都表现出色。

Conclusion: TransLLM在多种任务中表现出色，具有强大的泛化能力和跨任务适应性。

Abstract: Urban transportation systems encounter diverse challenges across multiple
tasks, such as traffic forecasting, electric vehicle (EV) charging demand
prediction, and taxi dispatch. Existing approaches suffer from two key
limitations: small-scale deep learning models are task-specific and
data-hungry, limiting their generalizability across diverse scenarios, while
large language models (LLMs), despite offering flexibility through natural
language interfaces, struggle with structured spatiotemporal data and numerical
reasoning in transportation domains. To address these limitations, we propose
TransLLM, a unified foundation framework that integrates spatiotemporal
modeling with large language models through learnable prompt composition. Our
approach features a lightweight spatiotemporal encoder that captures complex
dependencies via dilated temporal convolutions and dual-adjacency graph
attention networks, seamlessly interfacing with LLMs through structured
embeddings. A novel instance-level prompt routing mechanism, trained via
reinforcement learning, dynamically personalizes prompts based on input
characteristics, moving beyond fixed task-specific templates. The framework
operates by encoding spatiotemporal patterns into contextual representations,
dynamically composing personalized prompts to guide LLM reasoning, and
projecting the resulting representations through specialized output layers to
generate task-specific predictions. Experiments across seven datasets and three
tasks demonstrate the exceptional effectiveness of TransLLM in both supervised
and zero-shot settings. Compared to ten baseline models, it delivers
competitive performance on both regression and planning problems, showing
strong generalization and cross-task adaptability. Our code is available at
https://github.com/BiYunying/TransLLM.

</details>


### [39] [Evaluating Retrieval-Augmented Generation vs. Long-Context Input for Clinical Reasoning over EHRs](https://arxiv.org/abs/2508.14817)
*Skatje Myers,Dmitriy Dligach,Timothy A. Miller,Samantha Barr,Yanjun Gao,Matthew Churpek,Anoop Mayampurath,Majid Afshar*

Main category: cs.CL

TL;DR: 本文研究了RAG在处理电子健康记录中的临床任务中的有效性，结果表明RAG在性能和效率方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHRs）是长的、嘈杂的和冗余的，这对必须在其中导航的临床医生构成了重大挑战。大型语言模型（LLMs）为从这些非结构化文本中提取和推理提供了有希望的解决方案，但临床笔记的长度往往超过了即使是最先进的模型的扩展上下文窗口。检索增强生成（RAG）提供了一种替代方法，通过从整个EHR中检索与任务相关的段落，可能减少所需的输入标记数量。

Method: 我们提出了三个临床任务，旨在跨医疗系统进行复制，只需最少的努力：1）提取影像学程序，2）生成抗生素使用的时间线，3）识别关键诊断。使用实际住院患者的EHR，我们测试了三种最先进的LLMs，提供不同数量的上下文，使用有针对性的文本检索或最近的临床笔记。

Result: 我们发现RAG与使用最近的笔记表现相当或更优，并且在需要极少的输入标记的情况下接近使用模型完整上下文的性能。

Conclusion: 我们的结果表明，即使新模型能够处理越来越长的文本，RAG仍然是一个有竞争力且高效的方法。

Abstract: Electronic health records (EHRs) are long, noisy, and often redundant, posing
a major challenge for the clinicians who must navigate them. Large language
models (LLMs) offer a promising solution for extracting and reasoning over this
unstructured text, but the length of clinical notes often exceeds even
state-of-the-art models' extended context windows. Retrieval-augmented
generation (RAG) offers an alternative by retrieving task-relevant passages
from across the entire EHR, potentially reducing the amount of required input
tokens. In this work, we propose three clinical tasks designed to be replicable
across health systems with minimal effort: 1) extracting imaging procedures, 2)
generating timelines of antibiotic use, and 3) identifying key diagnoses. Using
EHRs from actual hospitalized patients, we test three state-of-the-art LLMs
with varying amounts of provided context, using either targeted text retrieval
or the most recent clinical notes. We find that RAG closely matches or exceeds
the performance of using recent notes, and approaches the performance of using
the models' full context while requiring drastically fewer input tokens. Our
results suggest that RAG remains a competitive and efficient approach even as
newer models become capable of handling increasingly longer amounts of text.

</details>


### [40] [Long Chain-of-Thought Reasoning Across Languages](https://arxiv.org/abs/2508.14828)
*Josh Barua,Seun Eisape,Kayo Yin,Alane Suhr*

Main category: cs.CL

TL;DR: 本文研究了长链式思维在不同语言中的表现，并提供了翻译后的数据集以促进多语言推理研究。


<details>
  <summary>Details</summary>
Motivation: 尽管通过长链式思维（CoTs）进行推理在大型语言模型（LLMs）中展现出了惊人的能力，但推理过程几乎完全以英语为中心。本文旨在研究长链式思维在其他语言中的表现，并提供翻译后的数据集以促进多语言推理研究。

Method: 我们构建了两个流行的英文推理数据集的翻译版本，微调了Qwen 2.5 (7B) 和 Qwen 3 (8B) 模型，并对法语、日语、拉脱维亚语和斯瓦希里语中的长链式思维生成进行了系统研究。

Result: 实验揭示了三个关键发现：1）使用英语作为桥梁语言的效果因语言而异；2）Qwen 3 的广泛多语言预训练缩小了跨语言性能差距，但并未消除；3）数据质量和规模的权衡因语言而异。

Conclusion: 本文的结果阐明了长链式思维在不同语言间迁移的条件和原因，并提供了翻译后的数据集以促进公平的多语言推理研究。

Abstract: Scaling inference through long chains-of-thought (CoTs) has unlocked
impressive reasoning capabilities in large language models (LLMs), yet the
reasoning process remains almost exclusively English-centric. We construct
translated versions of two popular English reasoning datasets, fine-tune Qwen
2.5 (7B) and Qwen 3 (8B) models, and present a systematic study of long CoT
generation across French, Japanese, Latvian, and Swahili. Our experiments
reveal three key findings. First, the efficacy of using English as a pivot
language varies by language: it provides no benefit for French, improves
performance when used as the reasoning language for Japanese and Latvian, and
proves insufficient for Swahili where both task comprehension and reasoning
remain poor. Second, extensive multilingual pretraining in Qwen 3 narrows but
does not eliminate the cross-lingual performance gap. A lightweight fine-tune
using only 1k traces still improves performance by over 30\% in Swahili. Third,
data quality versus scale trade-offs are language dependent: small, carefully
curated datasets suffice for English and French, whereas larger but noisier
corpora prove more effective for Swahili and Latvian. Together, these results
clarify when and why long CoTs transfer across languages and provide translated
datasets to foster equitable multilingual reasoning research.

</details>


### [41] [MedReseacher-R1: Expert-Level Medical Deep Researcher via A Knowledge-Informed Trajectory Synthesis Framework](https://arxiv.org/abs/2508.14880)
*Ailing Yu,Lan Yao,Jingnan Liu,Zhe Chen,Jiajun Yin,Yuan Wang,Xinhao Liao,Zhiling Ye,Ji Li,Yun Yue,Hansong Xiao,Hualei Zhou,Chunxiao Guo,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: 本文介绍了一种医学深度研究代理，通过两个核心创新解决了医学领域中的挑战，展示了在专业领域中小型开源模型可以超越大型专有系统的潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管通用深度研究代理显示出令人印象深刻的性能，但在医学领域面临重大挑战，例如领先的专有系统在复杂医学基准上的准确性有限。

Method: 我们开发了一个使用医学知识图谱的新型数据合成框架，并集成了一个定制的私有医学检索引擎，结合监督微调和在线强化学习的两阶段训练范式。

Result: 我们的MedResearcher-R1-32B模型在医学基准上表现出色，建立了新的最先进结果，同时在一般的深度研究任务上保持竞争力。

Conclusion: 我们的工作表明，在架构、工具设计和训练数据构建方面的战略领域特定创新可以使较小的开源模型在专业领域中超越更大的专有系统。

Abstract: Recent developments in Large Language Model (LLM)-based agents have shown
impressive capabilities spanning multiple domains, exemplified by deep research
systems that demonstrate superior performance on complex information-seeking
and synthesis tasks. While general-purpose deep research agents have shown
impressive capabilities, they struggle significantly with medical domain
challenges, as evidenced by leading proprietary systems achieving limited
accuracy on complex medical benchmarks. The key limitations are: (1) the model
lacks sufficient dense medical knowledge for clinical reasoning, and (2) the
framework is constrained by the absence of specialized retrieval tools tailored
for medical contexts.We present a medical deep research agent that addresses
these challenges through two core innovations. First, we develop a novel data
synthesis framework using medical knowledge graphs, extracting the longest
chains from subgraphs around rare medical entities to generate complex
multi-hop question-answer pairs. Second, we integrate a custom-built private
medical retrieval engine alongside general-purpose tools, enabling accurate
medical information synthesis. Our approach generates 2100+ diverse
trajectories across 12 medical specialties, each averaging 4.2 tool
interactions.Through a two-stage training paradigm combining supervised
fine-tuning and online reinforcement learning with composite rewards, our
MedResearcher-R1-32B model demonstrates exceptional performance, establishing
new state-of-the-art results on medical benchmarks while maintaining
competitive performance on general deep research tasks. Our work demonstrates
that strategic domain-specific innovations in architecture, tool design, and
training data construction can enable smaller open-source models to outperform
much larger proprietary systems in specialized domains.

</details>


### [42] [Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs](https://arxiv.org/abs/2508.14896)
*Haokun Lin,Haobo Xu,Yichen Wu,Ziyu Guo,Renrui Zhang,Zhichao Lu,Ying Wei,Qingfu Zhang,Zhenan Sun*

Main category: cs.CL

TL;DR: 本文首次系统研究了基于扩散的语言模型的量化，发现了激活异常值的问题，并通过多种方法进行了评估，以提供高效的部署方案。


<details>
  <summary>Details</summary>
Motivation: 由于dLLMs在边缘设备上的部署面临挑战，因此需要探索其量化方法。

Method: 本文通过识别激活异常值并实现最先进的PTQ方法，对多个任务类型和模型变体进行了全面评估。

Result: 本文通过多角度评估，提供了关于不同配置下dLLM量化行为的实用见解。

Conclusion: 本文提出了对基于扩散的语言模型进行量化的第一项系统研究，并希望为未来高效部署dLLM的研究提供基础。

Abstract: Recent advances in diffusion large language models (dLLMs) have introduced a
promising alternative to autoregressive (AR) LLMs for natural language
generation tasks, leveraging full attention and denoising-based decoding
strategies. However, the deployment of these models on edge devices remains
challenging due to their massive parameter scale and high resource demands.
While post-training quantization (PTQ) has emerged as a widely adopted
technique for compressing AR LLMs, its applicability to dLLMs remains largely
unexplored. In this work, we present the first systematic study on quantizing
diffusion-based language models. We begin by identifying the presence of
activation outliers, characterized by abnormally large activation values that
dominate the dynamic range. These outliers pose a key challenge to low-bit
quantization, as they make it difficult to preserve precision for the majority
of values. More importantly, we implement state-of-the-art PTQ methods and
conduct a comprehensive evaluation across multiple task types and model
variants. Our analysis is structured along four key dimensions: bit-width,
quantization method, task category, and model type. Through this
multi-perspective evaluation, we offer practical insights into the quantization
behavior of dLLMs under different configurations. We hope our findings provide
a foundation for future research in efficient dLLM deployment. All codes and
experimental setups will be released to support the community.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [43] [GLASS: Test-Time Acceleration for LLMs via Global-Local Neural Importance Aggregation](https://arxiv.org/abs/2508.14302)
*Amirmohsen Sattarifard,Sepehr Lavasani,Ehsan Imani,Kunlin Zhang,Hanlin Xu,Fengyu Sun,Negar Hassanpour,Chao Gao*

Main category: cs.LG

TL;DR: 本文提出了A/I-GLASS，一种无需训练的动态剪枝方法，通过结合提示局部和模型内在的神经元统计信息，有效提升长文本生成性能，同时避免额外的推理开销。


<details>
  <summary>Details</summary>
Motivation: 在边缘硬件上部署大型语言模型（LLMs）需要激进的、与提示相关的动态剪枝，以减少计算而不降低质量。静态或预测器方法要么固定一个稀疏模式，要么增加额外的运行时开销，而最近的零样本方法依赖于单个提示的统计信息，在短提示和/或长生成场景中失败。

Method: A/I-GLASS：基于激活和影响的全局-局部神经重要性聚合，用于前馈网络的稀疏化，两种无需训练的方法，动态选择FFN单元，使用提示局部和模型内在全局神经元统计的排名聚合。

Result: 在多个LLM和基准测试中进行的实证结果表明，GLASS在挑战性的长文本生成场景中显著优于之前的无训练方法。

Conclusion: GLASS显著优于之前的无训练方法，特别是在长文本生成场景中，且无需依赖辅助预测器或增加任何推理开销。

Abstract: Deploying Large Language Models (LLMs) on edge hardware demands aggressive,
prompt-aware dynamic pruning to reduce computation without degrading quality.
Static or predictor-based schemes either lock in a single sparsity pattern or
incur extra runtime overhead, and recent zero-shot methods that rely on
statistics from a single prompt fail on short prompt and/or long generation
scenarios. We introduce A/I-GLASS: Activation- and Impact-based Global-Local
neural importance Aggregation for feed-forward network SparSification, two
training-free methods that dynamically select FFN units using a
rank-aggregation of prompt local and model-intrinsic global neuron statistics.
Empirical results across multiple LLMs and benchmarks demonstrate that GLASS
significantly outperforms prior training-free methods, particularly in
challenging long-form generation scenarios, without relying on auxiliary
predictors or adding any inference overhead.

</details>


### [44] [DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization](https://arxiv.org/abs/2508.14460)
*Shuaijie She,Yu Bao,Yu Lu,Lu Xu,Tao Li,Wenhao Zhu,Shujian Huang,Shanbo Cheng,Lu Lu,Yuxuan Wang*

Main category: cs.LG

TL;DR: DuPO 是一种基于双重学习的偏好优化框架，通过广义对偶性生成无注释反馈，解决了 RLVR 对昂贵标签的依赖和传统双重学习的限制。它在多种任务中表现出色，是一种可扩展、通用且无需注释的 LLM 优化范式。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习与可验证奖励（RLVR）对昂贵标签的依赖以及传统双重学习仅限于严格双重任务对的限制。

Method: DuPO 是一种基于双重学习的偏好优化框架，通过广义对偶性生成无注释反馈。它将原始任务的输入分解为已知和未知部分，然后构建其对偶任务以使用原始输出和已知信息重建未知部分。

Result: DuPO 在多种任务中取得了显著提升：在 756 个方向上平均翻译质量提高了 2.13 COMET，数学推理准确率平均提高了 6.4 分，在三个挑战基准上，作为推理时重排序器性能提高了 9.3 分。

Conclusion: DuPO 是一种可扩展、通用且无需注释的 LLM 优化范式。

Abstract: We present DuPO, a dual learning-based preference optimization framework that
generates annotation-free feedback via a generalized duality. DuPO addresses
two key limitations: Reinforcement Learning with Verifiable Rewards (RLVR)'s
reliance on costly labels and applicability restricted to verifiable tasks, and
traditional dual learning's restriction to strictly dual task pairs (e.g.,
translation and back-translation). Specifically, DuPO decomposes a primal
task's input into known and unknown components, then constructs its dual task
to reconstruct the unknown part using the primal output and known information
(e.g., reversing math solutions to recover hidden variables), broadening
applicability to non-invertible tasks. The quality of this reconstruction
serves as a self-supervised reward to optimize the primal task, synergizing
with LLMs' ability to instantiate both tasks via a single model. Empirically,
DuPO achieves substantial gains across diverse tasks: it enhances the average
translation quality by 2.13 COMET over 756 directions, boosts the mathematical
reasoning accuracy by an average of 6.4 points on three challenge benchmarks,
and enhances performance by 9.3 points as an inference-time reranker (trading
computation for accuracy). These results position DuPO as a scalable, general,
and annotation-free paradigm for LLM optimization.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [45] [The Prompting Brain: Neurocognitive Markers of Expertise in Guiding Large Language Models](https://arxiv.org/abs/2508.14869)
*Hend Al-Khalifa,Raneem Almansour,Layan Abdulrahman Alhuasini,Alanood Alsaleh,Mohamad-Hani Temsah,Mohamad-Hani_Temsah,Ashwag Rafea S Alruwaili*

Main category: q-bio.NC

TL;DR: 本研究通过fMRI探讨了专家和中级提示工程师在大脑功能连接和网络活动方面的差异，发现与更高提示工程素养相关的独特神经特征。


<details>
  <summary>Details</summary>
Motivation: Prompt engineering has rapidly emerged as a critical skill for effective interaction with large language models (LLMs), but the cognitive and neural underpinnings of this expertise remain largely unexplored.

Method: This paper presents findings from a cross-sectional pilot fMRI study investigating differences in brain functional connectivity and network activity between experts and intermediate prompt engineers.

Result: Our results reveal distinct neural signatures associated with higher prompt engineering literacy, including increased functional connectivity in brain regions such as the left middle temporal gyrus and the left frontal pole, as well as altered power-frequency dynamics in key cognitive networks.

Conclusion: Understanding the neural basis of human expertise in interacting with LLMs can inform the design of more intuitive human-AI interfaces, contribute to cognitive models of LLM interaction, and potentially guide the development of AI systems that better align with human cognitive workflows.

Abstract: Prompt engineering has rapidly emerged as a critical skill for effective
interaction with large language models (LLMs). However, the cognitive and
neural underpinnings of this expertise remain largely unexplored. This paper
presents findings from a cross-sectional pilot fMRI study investigating
differences in brain functional connectivity and network activity between
experts and intermediate prompt engineers. Our results reveal distinct neural
signatures associated with higher prompt engineering literacy, including
increased functional connectivity in brain regions such as the left middle
temporal gyrus and the left frontal pole, as well as altered power-frequency
dynamics in key cognitive networks. These findings offer initial insights into
the neurobiological basis of prompt engineering proficiency. We discuss the
implications of these neurocognitive markers in Natural Language Processing
(NLP). Understanding the neural basis of human expertise in interacting with
LLMs can inform the design of more intuitive human-AI interfaces, contribute to
cognitive models of LLM interaction, and potentially guide the development of
AI systems that better align with human cognitive workflows. This
interdisciplinary approach aims to bridge the gap between human cognition and
machine intelligence, fostering a deeper understanding of how humans learn and
adapt to complex AI systems.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [46] [Virtual Community: An Open World for Humans, Robots, and Society](https://arxiv.org/abs/2508.14893)
*Qinhong Zhou,Hongxin Zhang,Xiangye Lin,Zheyuan Zhang,Yutian Chen,Wenjun Liu,Zunzhe Zhang,Sunli Chen,Lixing Fang,Qiushi Lyu,Xinyu Sun,Jincheng Yang,Zeyuan Wang,Bao Chi Dang,Zhehuan Chen,Daksha Ladia,Jiageng Liu,Chuang Gan*

Main category: cs.CV

TL;DR: 本文介绍了一个名为 Virtual Community 的开放世界平台，用于研究人机共存中的具身社会智能，并提出了两个新的挑战来评估多智能体推理和规划能力以及多机器人协作能力。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能和机器人技术的快速发展，人类和机器人将在共享社区中共存，这带来了机遇和挑战。因此，需要一个平台来研究这一未来场景。

Method: 提出了一种名为 Virtual Community 的开放世界平台，用于研究人机共存中的具身社会智能。

Result: 提出了两个新的挑战：Community Planning Challenge 和 Community Robot Challenge，并评估了各种基线模型在这些任务上的表现。

Conclusion: Virtual Community 有望推动开放世界环境中人机共存的进一步研究。

Abstract: The rapid progress in AI and Robotics may lead to a profound societal
transformation, as humans and robots begin to coexist within shared
communities, introducing both opportunities and challenges. To explore this
future, we present Virtual Community-an open-world platform for humans, robots,
and society-built on a universal physics engine and grounded in real-world 3D
scenes. With Virtual Community, we aim to study embodied social intelligence at
scale: 1) How robots can intelligently cooperate or compete; 2) How humans
develop social relations and build community; 3) More importantly, how
intelligent robots and humans can co-exist in an open world. To support these,
Virtual Community features: 1) An open-source multi-agent physics simulator
that supports robots, humans, and their interactions within a society; 2) A
large-scale, real-world aligned community generation pipeline, including vast
outdoor space, diverse indoor scenes, and a community of grounded agents with
rich characters and appearances. Leveraging Virtual Community, we propose two
novel challenges. The Community Planning Challenge evaluates multi-agent
reasoning and planning ability in open-world settings, such as cooperating to
help agents with daily activities and efficiently connecting other agents. The
Community Robot Challenge requires multiple heterogeneous robots to collaborate
in solving complex open-world tasks. We evaluate various baselines on these
tasks and demonstrate the challenges in both high-level open-world task
planning and low-level cooperation controls. We hope that Virtual Community
will unlock further study of human-robot coexistence within open-world
environments.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [47] [RAG-Boost: Retrieval-Augmented Generation Enhanced LLM-based Speech Recognition](https://arxiv.org/abs/2508.14048)
*Pengcheng Wang,Sheng Li,Takahiro Shinozaki*

Main category: eess.AS

TL;DR: RAG-Boost 通过引入检索增强生成模块，在实时处理中提高了基于 LLM 的 ASR 系统的性能。


<details>
  <summary>Details</summary>
Motivation: 改进基于 LLM 的 ASR 系统，以提高语音识别的准确性。

Method: RAG-Boost 在实时处理中引入了检索增强生成（RAG）模块，每个部分 ASR 假设查询音频-文本对和领域术语的向量存储，并将检索结果与实时 ASR 假设融合以修复识别错误。

Result: 通过将检索结果与实时 ASR 假设融合，RAG-Boost 能够提高响应质量并修复识别错误。

Conclusion: RAG-Boost 提高了基于 LLM 的 ASR 系统的性能，通过在实时处理中引入检索增强生成模块来修复识别错误。

Abstract: In this paper, we propose RAG-Boost (ST-ShinozakiLab Task I system), which
enhances the baseline LLM-based ASR system of the MLC-SLM Challenge (task I)
with a retrieval-augmented generation (RAG) module on the fly. Each partial ASR
hypothesis queries a vector store of audio-text pairs and domain terms, and the
retrieved results are fused with the live ASR hypotheses to fix recognition
errors. The fused hypotheses are passed to the LLM, yielding improved
responses.

</details>


### [48] [MahaTTS: A Unified Framework for Multilingual Text-to-Speech Synthesis](https://arxiv.org/abs/2508.14049)
*Jaskaran Singh,Amartya Roy Chowdhury,Raghav Prabhakar,Varshul C. W*

Main category: eess.AS

TL;DR: 本文介绍了一种名为MahaTTS-v2的多语言多说话人文本到语音系统，该系统在印地语等语言中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前的文本到语音模型主要关注英语和欧洲语言，这限制了向更多人提供信息的机会。因此，需要一种能够处理印地语等语言的多语言多说话人文本到语音系统。

Method: 该方法利用Wav2Vec2.0标记进行语义提取，并使用语言模型（LM）进行文本到语义建模。此外，还使用了条件流模型（CFM）进行语义到梅尔频谱图生成。

Result: 实验结果表明，所提出的方法在其他框架上具有有效性。

Conclusion: 实验结果表明，所提出的方法在其他框架上具有有效性。

Abstract: Current Text-to-Speech models pose a multilingual challenge, where most of
the models traditionally focus on English and European languages, thereby
hurting the potential to provide access to information to many more people. To
address this gap, we introduce MahaTTS-v2 a Multilingual Multi-speaker
Text-To-Speech (TTS) system that has excellent multilingual expressive
capabilities in Indic languages. The model has been trained on around 20K hours
of data specifically focused on Indian languages. Our approach leverages
Wav2Vec2.0 tokens for semantic extraction, and a Language Model (LM) for
text-to-semantic modeling. Additionally, we have used a Conditional Flow Model
(CFM) for semantics to melspectogram generation. The experimental results
indicate the effectiveness of the proposed approach over other frameworks. Our
code is available at https://github.com/dubverse-ai/MahaTTSv2

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [49] [Who Sees What? Structured Thought-Action Sequences for Epistemic Reasoning in LLMs](https://arxiv.org/abs/2508.14564)
*Luca Annese,Sabrina Patania,Silvia Serino,Tom Foulsham,Silvia Rossi,Azzurra Ruggeri,Dimitri Ognibene*

Main category: cs.AI

TL;DR: 本研究探讨了使用结构化示例来提高基于LLM的代理在ReAct框架中的性能。虽然L型示例略有改善，但效果不一致。结果表明，仅靠结构化示例不足以实现稳健的视角采取，需要更多的信念跟踪、成本建模和更丰富的环境。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的系统在涉及主动感知、协作推理和视角采取的任务中仍然面临挑战。因此，本研究旨在探索结构化示例是否可以提高基于LLM的代理在ReAct框架中的性能。

Method: 研究提出了一个结构化的解决方案处理管道，生成三种不同类别的示例：最优目标路径（G型）、信息节点路径（E型）和逐步最优决策序列对比替代动作（L型）。这些解决方案通过提示LLM明确阐述每个决策背后的推理过程，转换为“思考-行动”示例。

Result: L型示例略微减少了澄清请求和总体操作步骤，但没有产生一致的改进。代理在需要基本注意过滤的任务中表现成功，但在需要关于遮挡空间的心理化或权衡认知行动成本的场景中遇到困难。

Conclusion: 研究表明，仅靠结构化示例不足以实现稳健的视角采取，需要显式的信念跟踪、成本建模和更丰富的环境来实现基于LLM的代理的社会基础协作。

Abstract: Recent advances in large language models (LLMs) and reasoning frameworks have
opened new possibilities for improving the perspective -taking capabilities of
autonomous agents. However, tasks that involve active perception, collaborative
reasoning, and perspective taking (understanding what another agent can see or
knows) pose persistent challenges for current LLM-based systems. This study
investigates the potential of structured examples derived from transformed
solution graphs generated by the Fast Downward planner to improve the
performance of LLM-based agents within a ReAct framework. We propose a
structured solution-processing pipeline that generates three distinct
categories of examples: optimal goal paths (G-type), informative node paths
(E-type), and step-by-step optimal decision sequences contrasting alternative
actions (L-type). These solutions are further converted into ``thought-action''
examples by prompting an LLM to explicitly articulate the reasoning behind each
decision. While L-type examples slightly reduce clarification requests and
overall action steps, they do not yield consistent improvements. Agents are
successful in tasks requiring basic attentional filtering but struggle in
scenarios that required mentalising about occluded spaces or weighing the costs
of epistemic actions. These findings suggest that structured examples alone are
insufficient for robust perspective-taking, underscoring the need for explicit
belief tracking, cost modelling, and richer environments to enable socially
grounded collaboration in LLM-based agents.

</details>


### [50] [MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers](https://arxiv.org/abs/2508.14704)
*Ziyang Luo,Zhiqi Shen,Wenzhuo Yang,Zirui Zhao,Prathyusha Jwalapuram,Amrita Saha,Doyen Sahoo,Silvio Savarese,Caiming Xiong,Junnan Li*

Main category: cs.AI

TL;DR: 我们介绍了MCP-Universe，这是第一个全面的基准，用于评估LLMs在真实和困难任务中的表现。我们的基准测试揭示了先进模型的性能限制，并提出了长期上下文和未知工具的挑战。我们还开源了评估框架以促进MCP生态系统的发展。


<details>
  <summary>Details</summary>
Motivation: 现有的基准过于简单，无法捕捉实际应用中的挑战，例如长周期推理和大型、不熟悉的工具空间。因此，我们需要一个更全面的基准来评估LLMs在真实场景中的表现。

Method: 我们引入了MCP-Universe，这是一个全面的基准，旨在通过与真实MCP服务器的交互来评估LLMs在现实和困难任务中的表现。我们实现了基于执行的评估器，包括格式评估器、静态评估器和动态评估器。

Result: 即使最先进的模型如GPT-5（43.72%）、Grok-4（33.33%）和Claude-4.0-Sonnet（29.44%）也表现出显著的性能限制。此外，我们的基准测试对LLM代理提出了长期上下文的挑战，并引入了未知工具的挑战。

Conclusion: 我们的基准测试揭示了即使是最先进的模型在处理现实世界任务时也存在显著的性能限制，并且提出了长期上下文和未知工具的挑战。此外，我们开源了可扩展的评估框架，以促进MCP生态系统的发展。

Abstract: The Model Context Protocol has emerged as a transformative standard for
connecting large language models to external data sources and tools, rapidly
gaining adoption across major AI providers and development platforms. However,
existing benchmarks are overly simplistic and fail to capture real application
challenges such as long-horizon reasoning and large, unfamiliar tool spaces. To
address this critical gap, we introduce MCP-Universe, the first comprehensive
benchmark specifically designed to evaluate LLMs in realistic and hard tasks
through interaction with real-world MCP servers. Our benchmark encompasses 6
core domains spanning 11 different MCP servers: Location Navigation, Repository
Management, Financial Analysis, 3D Design, Browser Automation, and Web
Searching. To ensure rigorous evaluation, we implement execution-based
evaluators, including format evaluators for agent format compliance, static
evaluators for time-invariant content matching, and dynamic evaluators that
automatically retrieve real-time ground truth for temporally sensitive tasks.
Through extensive evaluation of leading LLMs, we find that even SOTA models
such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit
significant performance limitations. In addition, our benchmark poses a
significant long-context challenge for LLM agents, as the number of input
tokens increases rapidly with the number of interaction steps. Moreover, it
introduces an unknown-tools challenge, as LLM agents often lack familiarity
with the precise usage of the MCP servers. Notably, enterprise-level agents
like Cursor cannot achieve better performance than standard ReAct frameworks.
Beyond evaluation, we open-source our extensible evaluation framework with UI
support, enabling researchers and practitioners to seamlessly integrate new
agents and MCP servers while fostering innovation in the rapidly evolving MCP
ecosystem.

</details>


### [51] [Privileged Self-Access Matters for Introspection in AI](https://arxiv.org/abs/2508.14802)
*Siyuan Song,Harvey Lederman,Jennifer Hu,Kyle Mahowald*

Main category: cs.AI

TL;DR: The paper argues for a more robust definition of introspection in AI and shows that LLMs may not truly introspect despite appearing to do so.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the lack of consensus on how to define introspection in AI models.

Method: The paper proposes a 'thicker' definition of introspection in AI and uses experiments with LLMs to test this definition.

Result: Experiments show that LLMs can appear to have lightweight introspection but fail to meet the proposed definition of meaningful introspection.

Conclusion: AI models may appear to have lightweight introspection but fail to meaningfully introspect according to a proposed definition.

Abstract: Whether AI models can introspect is an increasingly important practical
question. But there is no consensus on how introspection is to be defined.
Beginning from a recently proposed ''lightweight'' definition, we argue instead
for a thicker one. According to our proposal, introspection in AI is any
process which yields information about internal states through a process more
reliable than one with equal or lower computational cost available to a third
party. Using experiments where LLMs reason about their internal temperature
parameters, we show they can appear to have lightweight introspection while
failing to meaningfully introspect per our proposed definition.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [52] [FinAgentBench: A Benchmark Dataset for Agentic Retrieval in Financial Question Answering](https://arxiv.org/abs/2508.14052)
*Chanyeol Choi,Jihoon Kwon,Alejandro Lopez-Lira,Chaewoon Kim,Minjae Kim,Juneha Hwang,Jaeseon Ha,Hojun Choi,Suyeol Yun,Yongjin Kim,Yongjae Lee*

Main category: cs.IR

TL;DR: 本文介绍了FinAgentBench，这是第一个用于评估金融领域多步骤推理检索的大规模基准测试。通过该基准测试，我们可以更好地理解金融领域的检索中心语言模型行为，并通过针对性的微调提升其性能。


<details>
  <summary>Details</summary>
Motivation: 传统IR方法在金融领域中往往无法准确检索信息，因为需要捕捉语义相似性并进行细粒度的文档结构和领域知识推理。然而，目前尚无用于评估金融领域此类能力的基准测试。

Method: 我们引入了FinAgentBench，这是第一个用于评估金融领域多步骤推理检索的大规模基准测试。该基准包括3,429个专家标注的示例，评估LLM代理是否能够(1)在候选文档类型中识别最相关的文档类型，以及(2)精确定位所选文档中的关键段落。

Result: 我们评估了一系列最先进的模型，并进一步展示了有针对性的微调可以显著提高代理检索性能。

Conclusion: 我们的基准为研究金融领域复杂、特定领域的检索中心语言模型行为提供了基础。我们将在论文接受后公开数据集，并计划扩展并分享完整标普500及更多数据集。

Abstract: Accurate information retrieval (IR) is critical in the financial domain,
where investors must identify relevant information from large collections of
documents. Traditional IR methods-whether sparse or dense-often fall short in
retrieval accuracy, as it requires not only capturing semantic similarity but
also performing fine-grained reasoning over document structure and
domain-specific knowledge. Recent advances in large language models (LLMs) have
opened up new opportunities for retrieval with multi-step reasoning, where the
model ranks passages through iterative reasoning about which information is
most relevant to a given query. However, there exists no benchmark to evaluate
such capabilities in the financial domain. To address this gap, we introduce
FinAgentBench, the first large-scale benchmark for evaluating retrieval with
multi-step reasoning in finance -- a setting we term agentic retrieval. The
benchmark consists of 3,429 expert-annotated examples on S&P-100 listed firms
and assesses whether LLM agents can (1) identify the most relevant document
type among candidates, and (2) pinpoint the key passage within the selected
document. Our evaluation framework explicitly separates these two reasoning
steps to address context limitations. This design enables to provide a
quantitative basis for understanding retrieval-centric LLM behavior in finance.
We evaluate a suite of state-of-the-art models and further demonstrated how
targeted fine-tuning can significantly improve agentic retrieval performance.
Our benchmark provides a foundation for studying retrieval-centric LLM behavior
in complex, domain-specific tasks for finance. We will release the dataset
publicly upon acceptance of the paper and plan to expand and share dataset for
the full S&P 500 and beyond.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [53] [Two Birds with One Stone: Multi-Task Detection and Attribution of LLM-Generated Text](https://arxiv.org/abs/2508.14190)
*Zixin Rao,Youssef Mohamed,Shang Liu,Zeyan Liu*

Main category: cs.CR

TL;DR: 本文介绍了一种多任务学习框架DA-MTL，用于同时解决文本检测和作者身份归属问题，并在多个数据集和模型上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有对策主要集中在区分AI生成内容与人工撰写文本，而作者身份归属（确定特定LLM生成的文本）则较少受到关注，尽管它在法医分析中非常重要。因此，本文旨在开发一种能够同时解决这两个问题的框架。

Method: 本文提出了一种多任务学习框架DA-MTL，用于同时处理文本检测和作者身份归属问题。该框架在九个数据集和四个主干模型上进行了评估，并分析了跨模态和跨语言模式以及对抗性混淆技术的鲁棒性。

Result: DA-MTL在多个数据集和LLM来源上表现出色，能够捕捉每个任务的独特特征并共享见解，从而提高两个任务的性能。此外，研究还分析了跨模态和跨语言模式，并评估了框架对对抗性混淆技术的鲁棒性。

Conclusion: 本文提出了DA-MTL多任务学习框架，能够同时解决文本检测和作者身份归属问题，并在多个数据集和模型上表现出色。研究结果为LLM行为和检测及作者身份归属的泛化提供了有价值的见解。

Abstract: Large Language Models (LLMs), such as GPT-4 and Llama, have demonstrated
remarkable abilities in generating natural language. However, they also pose
security and integrity challenges. Existing countermeasures primarily focus on
distinguishing AI-generated content from human-written text, with most
solutions tailored for English. Meanwhile, authorship attribution--determining
which specific LLM produced a given text--has received comparatively little
attention despite its importance in forensic analysis. In this paper, we
present DA-MTL, a multi-task learning framework that simultaneously addresses
both text detection and authorship attribution. We evaluate DA-MTL on nine
datasets and four backbone models, demonstrating its strong performance across
multiple languages and LLM sources. Our framework captures each task's unique
characteristics and shares insights between them, which boosts performance in
both tasks. Additionally, we conduct a thorough analysis of cross-modal and
cross-lingual patterns and assess the framework's robustness against
adversarial obfuscation techniques. Our findings offer valuable insights into
LLM behavior and the generalization of both detection and authorship
attribution.

</details>


### [54] [MultiFuzz: A Dense Retrieval-based Multi-Agent System for Network Protocol Fuzzing](https://arxiv.org/abs/2508.14300)
*Youssef Maklad,Fares Wael,Ali Hamdi,Wael Elsersy,Khaled Shaban*

Main category: cs.CR

TL;DR: This paper introduces MultiFuzz, a novel dense retrieval-based multi-agent system designed to overcome limitations in protocol fuzzing by integrating semantic-aware context retrieval, specialized agents, and structured tool-assisted reasoning. MultiFuzz improves branch coverage and explores deeper protocol states compared to existing fuzzers.


<details>
  <summary>Details</summary>
Motivation: Traditional protocol fuzzing techniques often lack effectiveness due to a limited semantic understanding of complex protocol grammars and rigid seed mutation strategies. Recent works have integrated Large Language Models (LLMs) to guide protocol fuzzing but still face issues like unreliable output, LLM hallucinations, and assumptions of LLM knowledge about protocol specifications.

Method: MultiFuzz utilizes agentic chunks of protocol documentation (RFC Documents) to build embeddings in a vector database for a retrieval-augmented generation (RAG) pipeline, enabling agents to generate more reliable and structured outputs. The framework decomposes the fuzzing process into modular groups of agents that collaborate through chain-of-thought reasoning to dynamically adapt fuzzing strategies based on the retrieved contextual knowledge.

Result: Experimental evaluations on the Real-Time Streaming Protocol (RTSP) demonstrate that MultiFuzz significantly improves branch coverage and explores deeper protocol states and transitions over state-of-the-art (SOTA) fuzzers such as NSFuzz, AFLNet, and ChatAFL.

Conclusion: MultiFuzz establishes a new paradigm in autonomous protocol fuzzing, offering a scalable and extensible foundation for future research in intelligent agentic-based fuzzing systems.

Abstract: Traditional protocol fuzzing techniques, such as those employed by AFL-based
systems, often lack effectiveness due to a limited semantic understanding of
complex protocol grammars and rigid seed mutation strategies. Recent works,
such as ChatAFL, have integrated Large Language Models (LLMs) to guide protocol
fuzzing and address these limitations, pushing protocol fuzzers to wider
exploration of the protocol state space. But ChatAFL still faces issues like
unreliable output, LLM hallucinations, and assumptions of LLM knowledge about
protocol specifications. This paper introduces MultiFuzz, a novel dense
retrieval-based multi-agent system designed to overcome these limitations by
integrating semantic-aware context retrieval, specialized agents, and
structured tool-assisted reasoning. MultiFuzz utilizes agentic chunks of
protocol documentation (RFC Documents) to build embeddings in a vector database
for a retrieval-augmented generation (RAG) pipeline, enabling agents to
generate more reliable and structured outputs, enhancing the fuzzer in mutating
protocol messages with enhanced state coverage and adherence to syntactic
constraints. The framework decomposes the fuzzing process into modular groups
of agents that collaborate through chain-of-thought reasoning to dynamically
adapt fuzzing strategies based on the retrieved contextual knowledge.
Experimental evaluations on the Real-Time Streaming Protocol (RTSP) demonstrate
that MultiFuzz significantly improves branch coverage and explores deeper
protocol states and transitions over state-of-the-art (SOTA) fuzzers such as
NSFuzz, AFLNet, and ChatAFL. By combining dense retrieval, agentic
coordination, and language model reasoning, MultiFuzz establishes a new
paradigm in autonomous protocol fuzzing, offering a scalable and extensible
foundation for future research in intelligent agentic-based fuzzing systems.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [55] [Measuring LLM Code Generation Stability via Structural Entropy](https://arxiv.org/abs/2508.14288)
*Yewei Song,Tiezhu Sun,Xunzhu Tang,Prateek Rajput,Tegawende F. Bissyande,Jacques Klein*

Main category: cs.SE

TL;DR: 本文通过将结构熵概念扩展到程序领域，结合抽象语法树（AST）分析，提出了一种评估大型语言模型代码生成稳定性的方法。该方法利用Jensen-Shannon散度和结构交叉熵比率来衡量稳定性，并且无需参考、语言无关、与执行无关。实验表明，AST驱动的结构熵能够揭示模型的一致性和鲁棒性方面的细微差别。


<details>
  <summary>Details</summary>
Motivation: Assessing the stability of code generation from large language models (LLMs) is essential for judging their reliability in real-world development.

Method: Extending prior 'structural-entropy concepts' to the program domain by pairing entropy with abstract syntax tree (AST) analysis.

Result: The method runs in O(n,d) time with no external tests, providing a lightweight addition to the code-generation evaluation toolkit.

Conclusion: AST-driven structural entropy reveals nuances in model consistency and robustness.

Abstract: Assessing the stability of code generation from large language models (LLMs)
is essential for judging their reliability in real-world development. We extend
prior "structural-entropy concepts" to the program domain by pairing entropy
with abstract syntax tree (AST) analysis. For any fixed prompt, we collect the
multiset of depth-bounded subtrees of AST in each generated program and treat
their relative frequencies as a probability distribution. We then measure
stability in two complementary ways: (i) Jensen-Shannon divergence, a
symmetric, bounded indicator of structural overlap, and (ii) a Structural
Cross-Entropy ratio that highlights missing high-probability patterns. Both
metrics admit structural-only and token-aware variants, enabling separate views
on control-flow shape and identifier-level variability. Unlike pass@k, BLEU, or
CodeBLEU, our metrics are reference-free, language-agnostic, and
execution-independent. We benchmark several leading LLMs on standard code
generation tasks, demonstrating that AST-driven structural entropy reveals
nuances in model consistency and robustness. The method runs in O(n,d) time
with no external tests, providing a lightweight addition to the code-generation
evaluation toolkit.

</details>
