<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 60]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.CV](#cs.CV) [Total: 6]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.SD](#cs.SD) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs](https://arxiv.org/abs/2509.18113)
*Xin Hu,Yue Kang,Guanzi Yao,Tianze Kang,Mengjie Wang,Heyao Liu*

Main category: cs.CL

TL;DR: 本研究提出了一种动态提示调度机制，以提升大语言模型在多任务和跨领域设置下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法如SPoT依赖于固定的提示模板，在多任务和跨领域设置下存在泛化限制，因此需要一种更灵活的方法来提高模型的性能。

Method: 该研究引入了一个统一的多任务学习框架，包含动态提示调度机制，通过提示池和任务感知调度策略动态组合和对齐不同任务的提示，并利用任务嵌入和门控机制控制提示信号，以确保提示内容与任务需求的一致性。

Result: 实验结果表明，该方法在多个语言理解和知识推理任务中显著提升了性能，证明了其在统一多任务建模和跨领域适应中的有效性和适用性。

Conclusion: 该研究提出的动态提示调度方法在统一多任务建模和跨领域适应中表现出色，具有广泛的应用前景。

Abstract: This study addresses the generalization limitations commonly observed in
large language models under multi-task and cross-domain settings. Unlike prior
methods such as SPoT, which depends on fixed prompt templates, our study
introduces a unified multi-task learning framework with dynamic prompt
scheduling mechanism. By introducing a prompt pool and a task-aware scheduling
strategy, the method dynamically combines and aligns prompts for different
tasks. This enhances the model's ability to capture semantic differences across
tasks. During prompt fusion, the model uses task embeddings and a gating
mechanism to finely control the prompt signals. This ensures alignment between
prompt content and task-specific demands. At the same time, it builds flexible
sharing pathways across tasks. In addition, the proposed optimization objective
centers on joint multi-task learning. It incorporates an automatic learning
strategy for scheduling weights, which effectively mitigates task interference
and negative transfer. To evaluate the effectiveness of the method, a series of
sensitivity experiments were conducted. These experiments examined the impact
of prompt temperature parameters and task number variation. The results confirm
the advantages of the proposed mechanism in maintaining model stability and
enhancing transferability. Experimental findings show that the prompt
scheduling method significantly improves performance on a range of language
understanding and knowledge reasoning tasks. These results fully demonstrate
its applicability and effectiveness in unified multi-task modeling and
cross-domain adaptation.

</details>


### [2] [GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models](https://arxiv.org/abs/2509.18122)
*Yue Zhang,Jiaxin Zhang,Qiuyu Ren,Tahsin Saffat,Xiaoxuan Liu,Zitong Yang,Banghua Zhu,Yi Ma*

Main category: cs.CL

TL;DR: GAUSS是一个用于评估大语言模型数学能力的多维基准测试，能够详细描绘模型的数学技能，并揭示其优缺点。


<details>
  <summary>Details</summary>
Motivation: 为了评估大语言模型（LLMs）在数学方面的综合能力，需要一个能涵盖多个核心技能维度的基准测试。

Method: GAUSS通过将问题分类为认知技能并设计任务来隔离特定能力，从而构建模型数学能力的详细和可解释的轮廓。

Result: GAUSS可以生成模型的技能轮廓，例如GPT-5-thinking的技能轮廓展示了其优势和劣势以及与o4-mini-high的不同之处。

Conclusion: GAUSS是一个多维、基于技能的评估基准，能够全面、细致地描绘模型的数学能力，并展示其优缺点。

Abstract: We introduce \textbf{GAUSS} (\textbf{G}eneral \textbf{A}ssessment of
\textbf{U}nderlying \textbf{S}tructured \textbf{S}kills in Mathematics), a
benchmark that evaluates LLMs' mathematical abilities across twelve core skill
dimensions, grouped into three domains: knowledge and understanding, problem
solving and communication, and meta-skills and creativity. By categorizing
problems according to cognitive skills and designing tasks that isolate
specific abilities, GAUSS constructs comprehensive, fine-grained, and
interpretable profiles of models' mathematical abilities. These profiles
faithfully represent their underlying mathematical intelligence. To exemplify
how to use the \textsc{GAUSS} benchmark, we have derived the skill profile of
\textsc{GPT-5-thinking}, revealing its strengths and weaknesses as well as its
differences relative to \textsc{o4-mini-high}, thereby underscoring the value
of multidimensional, skill-based evaluation.

</details>


### [3] [Event Causality Identification with Synthetic Control](https://arxiv.org/abs/2509.18156)
*Haoyu Wang,Fengze Liu,Jiayao Zhang,Dan Roth,Kyle Richardson*

Main category: cs.CL

TL;DR: 本文提出了一种基于Rubin因果模型和合成控制方法的事件因果关系识别方法，能够在COPES-hard基准测试中取得更好的效果。


<details>
  <summary>Details</summary>
Motivation: 传统方法在事件因果关系识别中容易因非正式使用因果关系和错误的图推理而产生错误结果，因此需要一种更可靠的方法。

Method: 本文采用Rubin因果模型，将第一个事件视为处理，第二个事件视为结果，并通过合成控制方法生成对照组来识别因果关系。

Result: 本文的方法在COPES-hard基准测试中表现出优于GPT-4的效果，能够更稳健地识别因果关系。

Conclusion: 本文提出了一种基于Rubin因果模型的事件因果关系识别方法，通过合成控制方法生成对照组，从而更稳健地识别因果关系。

Abstract: Event causality identification (ECI), a process that extracts causal
relations between events from text, is crucial for distinguishing causation
from correlation. Traditional approaches to ECI have primarily utilized
linguistic patterns and multi-hop relational inference, risking false causality
identification due to informal usage of causality and specious graphical
inference. In this paper, we adopt the Rubin Causal Model to identify event
causality: given two temporally ordered events, we see the first event as the
treatment and the second one as the observed outcome. Determining their
causality involves manipulating the treatment and estimating the resultant
change in the likelihood of the outcome. Given that it is only possible to
implement manipulation conceptually in the text domain, as a work-around, we
try to find a twin for the protagonist from existing corpora. This twin should
have identical life experiences with the protagonist before the treatment but
undergoes an intervention of treatment. However, the practical difficulty of
locating such a match limits its feasibility. Addressing this issue, we use the
synthetic control method to generate such a twin' from relevant historical
data, leveraging text embedding synthesis and inversion techniques. This
approach allows us to identify causal relations more robustly than previous
methods, including GPT-4, which is demonstrated on a causality benchmark,
COPES-hard.

</details>


### [4] [ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization](https://arxiv.org/abs/2509.18158)
*Seungyoun Yi,Minsoo Khang,Sungrae Park*

Main category: cs.CL

TL;DR: ZERA 是一种新的框架，通过联合优化系统和用户提示，实现了高效的提示精炼，提高了大型语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 APO 方法通常只关注用户提示，依赖于非结构化的反馈，并且需要大量的样本和长的迭代周期，这使得它们成本高昂且脆弱。

Method: ZERA 通过使用八个可推广的标准对提示进行评分，并根据这些结构化的批评来修订提示，实现了低开销的精炼。

Result: 在五个 LLM 和九个不同的数据集上评估 ZERA，实验结果表明其相对于强基线有持续的改进。

Conclusion: ZERA 是一种有效的框架，可以联合优化系统和用户提示，从而提高大型语言模型的性能。

Abstract: Automatic Prompt Optimization (APO) improves large language model (LLM)
performance by refining prompts for specific tasks. However, prior APO methods
typically focus only on user prompts, rely on unstructured feedback, and
require large sample sizes and long iteration cycles-making them costly and
brittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a
novel framework that jointly optimizes both system and user prompts through
principled, low-overhead refinement. ZERA scores prompts using eight
generalizable criteria with automatically inferred weights, and revises prompts
based on these structured critiques. This enables fast convergence to
high-quality prompts using minimal examples and short iteration cycles. We
evaluate ZERA across five LLMs and nine diverse datasets spanning reasoning,
summarization, and code generation tasks. Experimental results demonstrate
consistent improvements over strong baselines. Further ablation studies
highlight the contribution of each component to more effective prompt
construction. Our implementation including all prompts is publicly available at
https://github.com/younatics/zera-agent.

</details>


### [5] [Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning](https://arxiv.org/abs/2509.18163)
*Haodong Zhao,Chenyan Zhao,Yansi Li,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.CL

TL;DR: 本文研究了辅助信息对大型语言模型推理过程的影响，发现模型的'思考模式'虽然有助于提高准确性，但误导性信息会导致性能大幅下降。这表明，挑战不仅仅是让模型'思考'，而是赋予它们评估其推理所依据的信息的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在复杂、知识密集型领域的应用需要其具备推理能力。在现实场景中，LLMs经常被增强外部信息，这些信息可能有帮助、无关或甚至具有误导性。本文旨在研究这种辅助信息对LLMs推理过程的因果影响。

Method: 本文引入了SciAux数据集，该数据集源自ScienceQA，用于系统测试模型对这些类型信息的鲁棒性。

Result: 研究结果揭示了一个关键漏洞：模型的'思考模式'是一把双刃剑。虽然有助于提高准确性，但误导性信息会导致性能大幅下降，这被思考过程放大了。

Conclusion: 研究发现，模型的'思考模式'是一把双刃剑。虽然有助于提高准确性，但误导性信息会导致性能大幅下降，这被思考过程放大了。这表明，挑战不仅仅是让模型'思考'，而是赋予它们评估其推理所依据的信息的能力。

Abstract: The capacity of Large Language Models (LLMs) to reason is fundamental to
their application in complex, knowledge-intensive domains. In real-world
scenarios, LLMs are often augmented with external information that can be
helpful, irrelevant, or even misleading. This paper investigates the causal
impact of such auxiliary information on the reasoning process of LLMs with
explicit step-by-step thinking capabilities. We introduce SciAux, a new dataset
derived from ScienceQA, to systematically test the robustness of the model
against these types of information. Our findings reveal a critical
vulnerability: the model's deliberative "thinking mode" is a double-edged
sword. While helpful context improves accuracy, misleading information causes a
catastrophic drop in performance, which is amplified by the thinking process.
Instead of conferring robustness, thinking reinforces the degree of error when
provided with misinformation. This highlights that the challenge is not merely
to make models "think", but to endow them with the critical faculty to evaluate
the information upon which their reasoning is based. The SciAux dataset is
available at https://huggingface.co/datasets/billhdzhao/SciAux.

</details>


### [6] [SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework](https://arxiv.org/abs/2509.18167)
*Junlin Wang,Zehao Wu,Shaowei Lu,Yanlan Li,Xinghao Huang*

Main category: cs.CL

TL;DR: 本文提出了一种过程监督的多智能体框架，以提高RAG中检索器和生成器之间的协调性，实现了更高的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: RAG的有效性依赖于检索器和生成器之间的协调，但由于这两个组件是独立开发的，它们的交互通常是次优的。

Method: 我们提出了一个过程监督的多智能体框架，引入了两个轻量级代理：决策者和知识选择器，并使用LLM作为裁判提供细粒度监督，采用树状结构的rollout策略，并通过PPO进行端到端训练。

Result: 在单跳和多跳问答基准测试中，我们的方法在准确性、稳定收敛性和可解释性推理轨迹方面优于标准RAG基线。

Conclusion: 该框架是模块化的且可即插即用，不需要对检索器或生成器进行修改，使其适用于实际的RAG应用。

Abstract: Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to
access external knowledge sources, but the effectiveness of RAG relies on the
coordination between the retriever and the generator. Since these components
are developed independently, their interaction is often suboptimal: the
retriever may return irrelevant or redundant documents, while the generator may
fail to fully leverage retrieved evidence. In this work, we propose a
process-supervised multi-agent framework to bridge the gap between retriever
and generator. The framework introduces two lightweight agents: a Decision
Maker, which determines when to continue retrieval or stop for answer
generation, and a Knowledge Selector, which filters retrieved documents to
retain only the most useful evidence. To provide fine-grained supervision, we
employ an LLM-as-a-Judge that evaluates each intermediate action with
process-level rewards, ensuring more accurate credit assignment than relying
solely on final answer correctness. We further adopt a tree-structured rollout
strategy to explore diverse reasoning paths, and train both agents with
Proximal Policy Optimization (PPO) in an end-to-end manner. Experiments on
single-hop and multi-hop question answering benchmarks show that our approach
achieves higher accuracy, more stable convergence, and produces more
interpretable reasoning trajectories compared with standard RAG baselines.
Importantly, the proposed framework is modular and plug-and-play, requiring no
modification to the retriever or generator, making it practical for real-world
RAG applications.

</details>


### [7] [ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers](https://arxiv.org/abs/2509.18175)
*Aditi Debsharma,Bhushan Jagyasi,Surajit Sen,Priyanka Pandey,Devicharith Dovari,Yuvaraj V. C,Rosalin Parida,Gopali Contractor*

Main category: cs.CL

TL;DR: 本文提出了一种新的对话情感识别和预测架构ERFC，该架构考虑了多模态、情感的不同属性、上下文以及对话中说话者话语的相互依赖性。实验表明该方法在呼叫中心等应用中具有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 在呼叫中心场景中，客服人员需要通过保持中性和积极情绪来安抚客户的不满或愤怒，从而提供良好的客户体验。预测未来话语的情感有助于提供正确的解决方案，从而提升客户体验。

Method: ERFC架构考虑了多模态、情感的不同属性、上下文以及对话中说话者话语的相互依赖性。

Result: 在IEMOCAP数据集上的大量实验表明，提出的ERFC架构是可行的。

Conclusion: 该研究提出了ERFC架构，可以为呼叫中心等应用提供巨大的商业价值，因为客户满意度至关重要。

Abstract: Emotion Recognition in Conversation has been seen to be widely applicable in
call center analytics, opinion mining, finance, retail, healthcare, and other
industries. In a call center scenario, the role of the call center agent is not
just confined to receiving calls but to also provide good customer experience
by pacifying the frustration or anger of the customers. This can be achieved by
maintaining neutral and positive emotion from the agent. As in any
conversation, the emotion of one speaker is usually dependent on the emotion of
other speaker. Hence the positive emotion of an agent, accompanied with the
right resolution will help in enhancing customer experience. This can change an
unhappy customer to a happy one. Imparting the right resolution at right time
becomes easier if the agent has the insight of the emotion of future
utterances. To predict the emotions of the future utterances we propose a novel
architecture, Emotion Recognition and Forecasting in Conversation. Our proposed
ERFC architecture considers multi modalities, different attributes of emotion,
context and the interdependencies of the utterances of the speakers in the
conversation. Our intensive experiments on the IEMOCAP dataset have shown the
feasibility of the proposed ERFC. This approach can provide a tremendous
business value for the applications like call center, where the happiness of
customer is utmost important.

</details>


### [8] [Evaluating Large Language Models for Detecting Antisemitism](https://arxiv.org/abs/2509.18293)
*Jay Patel,Hrudayangam Mehta,Jeremy Blackburn*

Main category: cs.CL

TL;DR: 本文评估了八种开源大型语言模型检测反犹太主义内容的能力，提出了一种新的提示方法Guided-CoT，提高了模型性能，并发现了不同模型在效用、可解释性和可靠性方面的差异。


<details>
  <summary>Details</summary>
Motivation: 检测仇恨内容是一个具有挑战性和重要性的问题，自动化工具如机器学习模型可以帮助解决这个问题，但需要持续训练以适应社交媒体不断变化的环境。

Method: 我们评估了八种开源大型语言模型检测反犹太主义内容的能力，探索了各种提示技术，并设计了一种新的类似思维链的提示方法Guided-CoT。

Result: Guided-CoT能够很好地处理上下文中的政策指南，提高所有评估模型的性能，无论解码配置、模型大小或推理能力如何。值得注意的是，Llama 3.1 70B的表现优于微调的GPT-3.5。此外，我们还研究了大型语言模型的错误，并引入了量化模型生成推理语义偏差的指标，揭示了大型语言模型之间的显著差异和矛盾行为。

Conclusion: 我们的实验展示了不同大型语言模型在检测反犹太主义内容方面的差异，包括其效用、可解释性和可靠性。

Abstract: Detecting hateful content is a challenging and important problem. Automated
tools, like machine-learning models, can help, but they require continuous
training to adapt to the ever-changing landscape of social media. In this work,
we evaluate eight open-source LLMs' capability to detect antisemitic content,
specifically leveraging in-context definition as a policy guideline. We explore
various prompting techniques and design a new CoT-like prompt, Guided-CoT.
Guided-CoT handles the in-context policy well, increasing performance across
all evaluated models, regardless of decoding configuration, model sizes, or
reasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.
Additionally, we examine LLM errors and introduce metrics to quantify semantic
divergence in model-generated rationales, revealing notable differences and
paradoxical behaviors among LLMs. Our experiments highlight the differences
observed across LLMs' utility, explainability, and reliability.

</details>


### [9] [Exploiting Tree Structure for Credit Assignment in RL Training of LLMs](https://arxiv.org/abs/2509.18314)
*Hieu Tran,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: TEMPO是一种基于树结构的强化学习算法，能够有效处理稀疏延迟奖励问题，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中由于稀疏延迟奖励而导致的token级信用分配问题，特别是在数学和医学问答任务中，只有少数决策token对结果有显著影响。

Method: 提出了一种名为Prefix-to-Tree (P2T)的简单过程，以及基于P2T的TEMPO算法，该算法利用树结构进行非参数前缀值计算，并通过分支门控的时间差分校正来增强组相对结果信号。

Result: TEMPO在Qwen3-1.7B/4B上优于PPO和GRPO，在分布内（MATH, MedQA）和分布外（GSM-HARD, AMC23, MedMCQA, MMLU-Medical）基准测试中表现更优。

Conclusion: TEMPO在多个基准测试中优于PPO和GRPO，并且在相似的运行时间内达到了更高的验证准确率。

Abstract: Reinforcement learning improves LLM reasoning, yet sparse delayed reward over
long sequences makes token-level credit assignment the key bottleneck. We study
the verifiable-reward setting, where the final answer is checkable and multiple
responses can be drawn per prompt. Reasoning tasks in math and medical QA align
with this setup, where only a few decision tokens significantly impact the
outcome. PPO offers token-level advantages with a learned value model, but it
is complex to train both the actor and critic models simultaneously, and it is
not easily generalizable, as the token-level values from the critic model can
make training prone to overfitting. GRPO is critic-free and supports verifiable
rewards, but spreads a single sequence-level return across tokens and ignores
branching. We introduce \textbf{Prefix-to-Tree (P2T)}, a simple procedure that
converts a group of responses into a prefix tree and computes
\emph{nonparametric} prefix values \(V(s)\) by aggregating descendant outcomes.
Built on P2T, we propose \textbf{TEMPO} (\emph{\textbf{T}ree-\textbf{E}stimated
\textbf{M}ean Prefix Value for \textbf{P}olicy \textbf{O}ptimization}), a
critic-free algorithm that augments the group-relative outcome signal of GRPO
with \emph{branch-gated} temporal-difference corrections derived from the tree.
At non-branch tokens, the temporal-difference (TD) term is zero, so TEMPO
reduces to GRPO; at branching tokens, it supplies precise token-level credit
without a learned value network or extra judges/teachers. On Qwen3-1.7B/4B,
TEMPO outperforms PPO and GRPO on in-distribution (MATH, MedQA) and
out-of-distribution (GSM-HARD, AMC23, MedMCQA, MMLU-Medical) benchmarks, and
reaches higher validation accuracy with roughly the same wall-clock time.

</details>


### [10] [Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning](https://arxiv.org/abs/2509.18316)
*Saksham Khatwani,He Cheng,Majid Afshar,Dmitriy Dligach,Yanjun Gao*

Main category: cs.CL

TL;DR: 本文研究了将大型语言模型作为知识图谱推理路径的奖励模型的方法，发现虽然路径判断性能较强，但向下游任务的迁移能力较弱。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在诊断推理方面展现出潜力，但往往缺乏可靠的、基于知识的推理。知识图谱可以支持可信的推理，但以往的方法通常通过检索增强生成或微调来整合知识图谱，而不是实现结构化推理。

Method: 本文探索了一种替代范式：将大型语言模型（LLMs）视为知识图谱（KG）推理路径的奖励模型，模型学习判断候选路径是否能导致正确的诊断。

Result: 实验表明，特定的奖励优化和蒸馏可以带来强大的路径判断性能，但向下游任务的迁移能力仍然较弱。

Conclusion: 本文提供了对临床知识图谱上“奖励模型风格”推理的首次系统评估，揭示了结构化、基于奖励的监督如何影响医疗保健中的生成式AI系统的诊断推理。

Abstract: Large language models (LLMs) show promise for diagnostic reasoning but often
lack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as
the Unified Medical Language System (UMLS), offer structured biomedical
knowledge that can support trustworthy reasoning. Prior approaches typically
integrate KGs via retrieval augmented generation or fine tuning, inserting KG
content into prompts rather than enabling structured reasoning. We explore an
alternative paradigm: treating the LLM as a reward model of KG reasoning paths,
where the model learns to judge whether a candidate path leads to correct
diagnosis for a given patient input. This approach is inspired by recent work
that leverages reward training to enhance model reasoning abilities, and
grounded in computational theory, which suggests that verifying a solution is
often easier than generating one from scratch. It also parallels physicians'
diagnostic assessment, where they judge which sequences of findings and
intermediate conditions most plausibly support a diagnosis. We first
systematically evaluate five task formulation for knowledge path judging and
eight training paradigm. Second, we test whether the path judging abilities
generalize to downstream diagnostic tasks, including diagnosis summarization
and medical question answering. Experiments with three open source
instruct-tuned LLMs reveal both promise and brittleness: while specific reward
optimization and distillation lead to strong path-judging performance, the
transferability to downstream tasks remain weak. Our finding provides the first
systematic assessment of "reward model style" reasoning over clinical KGs,
offering insights into how structured, reward-based supervision influences
diagnostic reasoning in GenAI systems for healthcare.

</details>


### [11] [Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding](https://arxiv.org/abs/2509.18344)
*Pei-Shuo Wang,Jian-Jia Chen,Chun-Che Yang,Chi-Chih Chang,Ning-Chi Huang,Mohamed S. Abdelfattah,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: 本文提出了一种名为SubSpec的方法，用于加速参数卸载，该方法无需训练且无损。通过从卸载的目标LLM部分生成低比特量化替代层来构建高度对齐的草稿模型，并共享剩余的GPU驻留层和KV缓存，进一步减少内存开销并增强对齐度。SubSpec在MT-Bench（8GB VRAM限制）上实现了Qwen2.5 7B的9.1倍加速，在流行生成基准测试中实现了Qwen2.5 32B的平均12.5倍加速。


<details>
  <summary>Details</summary>
Motivation: The immense model sizes of large language models (LLMs) challenge deployment on memory-limited consumer GPUs. Although model compression and parameter offloading are common strategies to address memory limitations, compression can degrade quality, and offloading maintains quality but suffers from slow inference. Speculative decoding presents a promising avenue to accelerate parameter offloading, utilizing a fast draft model to propose multiple draft tokens, which are then verified by the target LLM in parallel with a single forward pass.

Method: SubSpec constructs a highly aligned draft model by generating low-bit quantized substitute layers from offloaded target LLM portions. Additionally, our method shares the remaining GPU-resident layers and the KV-Cache, further reducing memory overhead and enhance alignment.

Result: SubSpec achieves a high average acceptance length, delivering 9.1x speedup for Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

Conclusion: SubSpec achieves a high average acceptance length, delivering 9.1x speedup for Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

Abstract: The immense model sizes of large language models (LLMs) challenge deployment
on memory-limited consumer GPUs. Although model compression and parameter
offloading are common strategies to address memory limitations, compression can
degrade quality, and offloading maintains quality but suffers from slow
inference. Speculative decoding presents a promising avenue to accelerate
parameter offloading, utilizing a fast draft model to propose multiple draft
tokens, which are then verified by the target LLM in parallel with a single
forward pass. This method reduces the time-consuming data transfers in forward
passes that involve offloaded weight transfers. Existing methods often rely on
pretrained weights of the same family, but require additional training to align
with custom-trained models. Moreover, approaches that involve draft model
training usually yield only modest speedups. This limitation arises from
insufficient alignment with the target model, preventing higher token
acceptance lengths. To address these challenges and achieve greater speedups,
we propose SubSpec, a plug-and-play method to accelerate parameter offloading
that is lossless and training-free. SubSpec constructs a highly aligned draft
model by generating low-bit quantized substitute layers from offloaded target
LLM portions. Additionally, our method shares the remaining GPU-resident layers
and the KV-Cache, further reducing memory overhead and enhance alignment.
SubSpec achieves a high average acceptance length, delivering 9.1x speedup for
Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for
Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

</details>


### [12] [Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents](https://arxiv.org/abs/2509.18360)
*Chutong Meng,Philipp Koehn*

Main category: cs.CL

TL;DR: Speech Vecalign 是一种不依赖文本转录的语音对齐方法，能够生成更长且更鲁棒的对齐结果，并在语音到语音翻译任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的语音对齐方法如 Global Mining 和 Local Mining 存在对齐长度不足和噪声较多的问题，需要一种更鲁棒且能产生更长对齐的方法。

Method: Speech Vecalign 是一种并行语音文档对齐方法，它单调对齐语音段嵌入而不依赖文本转录。

Result: Speech Vecalign 在 3,000 小时的未标记平行英语-德语语音文档上产生了约 1,000 小时的高质量对齐，并在语音到语音翻译任务中提升了性能。

Conclusion: Speech Vecalign 提高了语音到语音翻译的性能，并且在使用更少原始语音文档的情况下表现与 SpeechMatrix 模型相当或更好。

Abstract: We present Speech Vecalign, a parallel speech document alignment method that
monotonically aligns speech segment embeddings and does not depend on text
transcriptions. Compared to the baseline method Global Mining, a variant of
speech mining, Speech Vecalign produces longer speech-to-speech alignments. It
also demonstrates greater robustness than Local Mining, another speech mining
variant, as it produces less noise. We applied Speech Vecalign to 3,000 hours
of unlabeled parallel English-German (En-De) speech documents from VoxPopuli,
yielding about 1,000 hours of high-quality alignments. We then trained En-De
speech-to-speech translation models on the aligned data. Speech Vecalign
improves the En-to-De and De-to-En performance over Global Mining by 0.37 and
0.18 ASR-BLEU, respectively. Moreover, our models match or outperform
SpeechMatrix model performance, despite using 8 times fewer raw speech
documents.

</details>


### [13] [Interactive Real-Time Speaker Diarization Correction with Human Feedback](https://arxiv.org/abs/2509.18377)
*Xinlu He,Yiwen Guan,Badrivishal Paurana,Zilin Dai,Jacob Whitehill*

Main category: cs.CL

TL;DR: 本文提出了一种LLM辅助的说话人回声校正系统，通过实时用户反馈和改进的工作流技术显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 大多数自动语音处理系统在“开环”模式下运行，没有用户反馈关于谁说了什么；然而，人机交互工作流程可以潜在地提高准确性。

Method: 我们提出了一个LLM辅助的说话人回声校正系统，允许用户实时修复说话人归因错误。该流程执行流式ASR和回声校正，使用LLM提供简洁的摘要，并接受简短的口头反馈，立即整合而不干扰交互。此外，我们开发了技术使工作流更有效：首先，一种合并时分割（SWM）技术检测并分割ASR错误地归因于单一说话人的多说话人段。其次，基于用户回声校正收集在线说话人注册，从而帮助防止未来发生说话人回声错误。

Result: LLM驱动的模拟显示，我们的系统显著减少了DER（9.92%）和说话人混淆错误（44.23%）。

Conclusion: 我们的系统在AMI测试集上的LLM驱动模拟表明，它显著减少了DER（9.92%）和说话人混淆错误（44.23%）。

Abstract: Most automatic speech processing systems operate in "open loop" mode without
user feedback about who said what; yet, human-in-the-loop workflows can
potentially enable higher accuracy. We propose an LLM-assisted speaker
diarization correction system that lets users fix speaker attribution errors in
real time. The pipeline performs streaming ASR and diarization, uses an LLM to
deliver concise summaries to the users, and accepts brief verbal feedback that
is immediately incorporated without disrupting interactions. Moreover, we
develop techniques to make the workflow more effective: First, a
split-when-merged (SWM) technique detects and splits multi-speaker segments
that the ASR erroneously attributes to just a single speaker. Second, online
speaker enrollments are collected based on users' diarization corrections, thus
helping to prevent speaker diarization errors from occurring in the future.
LLM-driven simulations on the AMI test set indicate that our system
substantially reduces DER by 9.92% and speaker confusion error by 44.23%. We
further analyze correction efficacy under different settings, including summary
vs full transcript display, the number of online enrollments limitation, and
correction frequency.

</details>


### [14] [NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery](https://arxiv.org/abs/2509.18395)
*Minki Hong,Jangho Choi,Jihie Kim*

Main category: cs.CL

TL;DR: 本文介绍了NormGenesis，一个用于生成和注释跨多种语言的社会基础对话的多文化框架。通过引入Violation-to-Resolution（V2R）对话类型和基于实例的迭代细化方法，提高了语用一致性。实验结果表明，该框架在多个方面优于现有数据集。


<details>
  <summary>Details</summary>
Motivation: 为了使对话系统生成不仅连贯而且社会可接受的响应，需要对社会规范进行建模。此外，需要改进在资源不足的语言中的语用一致性。

Method: 我们提出了NormGenesis，这是一个多文化框架，用于生成和注释跨英语、中文和韩语的社会基础对话。我们提出了一种新的对话类型Violation-to-Resolution (V2R)，以建模规范违反后的对话进展。我们还实施了一个基于实例的迭代细化，在对话合成早期阶段提高语用一致性。

Result: 使用这个框架，我们构建了一个包含10,800个多轮对话的数据集，这些对话在回合级别上进行了规范遵守、说话人意图和情感反应的标注。人类和LLM评估表明，NormGenesis在细化质量、对话自然度和泛化性能方面显著优于现有数据集。

Conclusion: 我们的工作为文化适应性对话建模建立了新的基准，并提供了一种可在语言和文化多样化的语言中进行规范意识生成的可扩展方法。

Abstract: Social norms govern culturally appropriate behavior in communication,
enabling dialogue systems to produce responses that are not only coherent but
also socially acceptable. We present NormGenesis, a multicultural framework for
generating and annotating socially grounded dialogues across English, Chinese,
and Korean. To model the dynamics of social interaction beyond static norm
classification, we propose a novel dialogue type, Violation-to-Resolution
(V2R), which models the progression of conversations following norm violations
through recognition and socially appropriate repair. To improve pragmatic
consistency in underrepresented languages, we implement an exemplar-based
iterative refinement early in the dialogue synthesis process. This design
introduces alignment with linguistic, emotional, and sociocultural expectations
before full dialogue generation begins. Using this framework, we construct a
dataset of 10,800 multi-turn dialogues annotated at the turn level for norm
adherence, speaker intent, and emotional response. Human and LLM-based
evaluations demonstrate that NormGenesis significantly outperforms existing
datasets in refinement quality, dialogue naturalness, and generalization
performance. We show that models trained on our V2R-augmented data exhibit
improved pragmatic competence in ethically sensitive contexts. Our work
establishes a new benchmark for culturally adaptive dialogue modeling and
provides a scalable methodology for norm-aware generation across linguistically
and culturally diverse languages.

</details>


### [15] [Evaluating the Creativity of LLMs in Persian Literary Text Generation](https://arxiv.org/abs/2509.18401)
*Armin Tourajmehr,Mohammad Reza Modarres,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型在生成波斯文学文本方面的创造力，并探讨了其在理解和运用文学手法上的优缺点。


<details>
  <summary>Details</summary>
Motivation: 先前的研究主要集中在英语上，对非英语文学传统探索有限，且缺乏评估创造力的标准方法。本文旨在评估大型语言模型生成富含文化相关表达的波斯文学文本的能力。

Method: 构建了一个包含20个不同主题的用户生成波斯文学数据集，并通过改编Torrance创造力测试来评估模型输出的四个创造力维度（原创性、流畅性、灵活性和详尽性）。此外，采用大型语言模型作为评委进行自动化评分，并通过组内相关系数验证其可靠性。

Result: 研究结果表明，大型语言模型在波斯文学文本生成方面表现出一定的创造力，但在理解与运用四种核心文学手法（明喻、隐喻、夸张和对照）方面存在局限性。

Conclusion: 研究结果突显了大型语言模型在波斯文学文本生成中的优势和局限性，强调了进一步改进的必要性。

Abstract: Large language models (LLMs) have demonstrated notable creative abilities in
generating literary texts, including poetry and short stories. However, prior
research has primarily centered on English, with limited exploration of
non-English literary traditions and without standardized methods for assessing
creativity. In this paper, we evaluate the capacity of LLMs to generate Persian
literary text enriched with culturally relevant expressions. We build a dataset
of user-generated Persian literary spanning 20 diverse topics and assess model
outputs along four creativity dimensions-originality, fluency, flexibility, and
elaboration-by adapting the Torrance Tests of Creative Thinking. To reduce
evaluation costs, we adopt an LLM as a judge for automated scoring and validate
its reliability against human judgments using intraclass correlation
coefficients, observing strong agreement. In addition, we analyze the models'
ability to understand and employ four core literary devices: simile, metaphor,
hyperbole, and antithesis. Our results highlight both the strengths and
limitations of LLMs in Persian literary text generation, underscoring the need
for further refinement.

</details>


### [16] [Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations](https://arxiv.org/abs/2509.18439)
*Oscar J. Ponce-Ponte,David Toro-Tobon,Luis F. Figueroa,Michael Gionfriddo,Megan Branda,Victor M. Montori,Saturnino Luz,Juan P. Brito*

Main category: cs.CL

TL;DR: 本研究旨在开发一种自动化方法来测量SDM，通过语言建模和对话对齐（CA）分数。使用深度学习和微调的BERT模型进行训练，并评估CA分数与SDM结果之间的关联。结果表明，这种方法可以大规模评估SDM策略。


<details>
  <summary>Details</summary>
Motivation: 目前尚无方法可以大规模自动测量SDM，而SDM对于实现以患者为中心的护理是必要的。

Method: 本研究使用语言建模和对话对齐（CA）分数开发了一种自动化方法来测量SDM。通过使用深度学习（DL）模型和微调的BERT模型进行下一步句子预测（NSP）任务，训练了上下文-响应对和负采样。

Result: DL模型没有使用风格书策略达到了0.227的召回率@1，而微调的BERTbase（110M）达到了最高的0.640召回率@1。没有使用风格书策略的DL生成的AbsMax（18.36 SE7.74 p=0.025）和Max CA（21.02 SE7.63 p=0.012）分数与OPTION12相关。微调的BERTbase（110M）生成的Max CA分数与DCS分数相关（-27.61 SE12.63 p=0.037）。

Conclusion: 本研究引入了一种自动化、可扩展的方法，通过可解释的CA分数来测量患者-医生对话中的SDM，具有在大规模评估SDM策略的潜力。

Abstract: Shared decision-making (SDM) is necessary to achieve patient-centred care.
Currently no methodology exists to automatically measure SDM at scale. This
study aimed to develop an automated approach to measure SDM by using language
modelling and the conversational alignment (CA) score. A total of 157
video-recorded patient-doctor conversations from a randomized multi-centre
trial evaluating SDM decision aids for anticoagulation in atrial fibrillations
were transcribed and segmented into 42,559 sentences. Context-response pairs
and negative sampling were employed to train deep learning (DL) models and
fine-tuned BERT models via the next sentence prediction (NSP) task. Each
top-performing model was used to calculate four types of CA scores. A
random-effects analysis by clinician, adjusting for age, sex, race, and trial
arm, assessed the association between CA scores and SDM outcomes: the
Decisional Conflict Scale (DCS) and the Observing Patient Involvement in
Decision-Making 12 (OPTION12) scores. p-values were corrected for multiple
comparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,
mean age 70 SD 10.8), clinicians on average spoke more words than patients
(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1
of 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1
with 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)
scores generated with the DL without stylebook were associated with OPTION12.
The Max CA score generated with the fine-tuned BERTbase (110M) was associated
with the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an
impact the association between CA scores and SDM. This study introduces an
automated, scalable methodology to measure SDM in patient-doctor conversations
through explainable CA scores, with potential to evaluate SDM strategies at
scale.

</details>


### [17] [CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density](https://arxiv.org/abs/2509.18458)
*Daniel Kaiser,Arnoldo Frigessi,Ali Ramezani-Kebrya,Benjamin Ricaud*

Main category: cs.CL

TL;DR: CogniLoad is a new benchmark for evaluating long-context reasoning in LLMs, based on Cognitive Load Theory. It allows for systematic control over factors like task length, intrinsic difficulty, and distractor interference, revealing how different models perform under varying conditions.


<details>
  <summary>Details</summary>
Motivation: Current benchmarks for long-context reasoning in Large Language Models (LLMs) often blur critical factors like intrinsic task complexity, distractor interference, and task length, making it difficult to perform precise failure analysis.

Method: CogniLoad is a synthetic benchmark grounded in Cognitive Load Theory (CLT) that generates natural-language logic puzzles with independently tunable parameters reflecting CLT's core dimensions: intrinsic difficulty, distractor-to-signal ratio, and task length.

Result: Evaluating 22 SotA reasoning LLMs, CogniLoad reveals distinct performance sensitivities, identifying task length as a dominant constraint and uncovering varied tolerances to intrinsic complexity and U-shaped responses to distractor ratios.

Conclusion: CogniLoad provides a reproducible, scalable, and diagnostically rich tool for dissecting LLM reasoning limitations and guiding future model development.

Abstract: Current benchmarks for long-context reasoning in Large Language Models (LLMs)
often blur critical factors like intrinsic task complexity, distractor
interference, and task length. To enable more precise failure analysis, we
introduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load
Theory (CLT). CogniLoad generates natural-language logic puzzles with
independently tunable parameters that reflect CLT's core dimensions: intrinsic
difficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\rho$)
regulates extraneous load; and task length ($N$) serves as an operational proxy
for conditions demanding germane load. Evaluating 22 SotA reasoning LLMs,
CogniLoad reveals distinct performance sensitivities, identifying task length
as a dominant constraint and uncovering varied tolerances to intrinsic
complexity and U-shaped responses to distractor ratios. By offering systematic,
factorial control over these cognitive load dimensions, CogniLoad provides a
reproducible, scalable, and diagnostically rich tool for dissecting LLM
reasoning limitations and guiding future model development.

</details>


### [18] [LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling](https://arxiv.org/abs/2509.18467)
*Zeyu Liu,Souvik Kundu,Lianghao Jiang,Anni Li,Srikanth Ronanki,Sravan Bodapati,Gourav Datta,Peter A. Beerel*

Main category: cs.CL

TL;DR: LAWCAT is a novel linearization framework that efficiently transfers the capabilities of pre-trained transformers into a performant linear attention architecture, achieving high performance on long-context tasks with reduced computational resources.


<details>
  <summary>Details</summary>
Motivation: Transformer architectures have achieved state-of-the-art performance across diverse domains, but their quadratic computational complexity with respect to sequence length remains a significant bottleneck, particularly for latency-sensitive long-context applications. While recent linear-complexity alternatives are increasingly powerful, effectively training them from scratch is still resource-intensive.

Method: LAWCAT integrates causal Conv1D layers to enhance local dependency modeling and employs normalized gated linear attention to improve generalization across varying context lengths.

Result: Distilling Mistral-7B with only 1K-length sequences yields over 90% passkey retrieval accuracy up to 22K tokens, significantly extending its effective context window. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance on S-NIAH 1&2&3 tasks (1K-8K context length) and BABILong benchmark (QA2&QA3, 0K-16K context length), requiring less than 0.1% pre-training tokens compared with pre-training models. Furthermore, LAWCAT exhibits faster prefill speeds than FlashAttention-2 for sequences exceeding 8K tokens.

Conclusion: LAWCAT provides an efficient pathway to high-performance, long-context linear models suitable for edge deployment, reducing reliance on extensive long-sequence training data and computational resources.

Abstract: Although transformer architectures have achieved state-of-the-art performance
across diverse domains, their quadratic computational complexity with respect
to sequence length remains a significant bottleneck, particularly for
latency-sensitive long-context applications. While recent linear-complexity
alternatives are increasingly powerful, effectively training them from scratch
is still resource-intensive. To overcome these limitations, we propose LAWCAT
(Linear Attention with Convolution Across Time), a novel linearization
framework designed to efficiently transfer the capabilities of pre-trained
transformers into a performant linear attention architecture. LAWCAT integrates
causal Conv1D layers to enhance local dependency modeling and employs
normalized gated linear attention to improve generalization across varying
context lengths. Our comprehensive evaluations demonstrate that, distilling
Mistral-7B with only 1K-length sequences yields over 90\% passkey retrieval
accuracy up to 22K tokens, significantly extending its effective context
window. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance
on S-NIAH 1\&2\&3 tasks (1K-8K context length) and BABILong benchmark
(QA2\&QA3, 0K-16K context length), requiring less than 0.1\% pre-training
tokens compared with pre-training models. Furthermore, LAWCAT exhibits faster
prefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT
thus provides an efficient pathway to high-performance, long-context linear
models suitable for edge deployment, reducing reliance on extensive
long-sequence training data and computational resources.

</details>


### [19] [Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference](https://arxiv.org/abs/2509.18487)
*Ben Finkelshtein,Silviu Cucerzan,Sujay Kumar Jauhar,Ryen White*

Main category: cs.CL

TL;DR: 本文评估了LLM在图数据中的表现，发现代码生成是最有效的交互方式，并在异质图中表现良好。


<details>
  <summary>Details</summary>
Motivation: 尽管对LLM在图数据中的应用兴趣激增，但该领域缺乏对其能力的系统理解。

Method: 本文进行了大规模、受控的评估，涵盖了多个变量轴，以系统地评估基于LLM的图推理方法在文本应用中的优缺点。

Result: LLM作为代码生成器在图数据上表现出最强的整体性能，特别是在长文本或高阶图中，提示方法很快超出token预算。所有交互策略在异质图上仍然有效，挑战了LLM方法在低同质性下崩溃的假设。代码生成能够灵活地在结构、特征或标签之间调整依赖关系，以利用最有信息量的输入类型。

Conclusion: 本文提供了对当前LLM-图交互模式的优势和局限性的全面看法，并强调了未来方法的关键设计原则。

Abstract: Large language models (LLMs) are increasingly used for text-rich graph
machine learning tasks such as node classification in high-impact domains like
fraud detection and recommendation systems. Yet, despite a surge of interest,
the field lacks a principled understanding of the capabilities of LLMs in their
interaction with graph data. In this work, we conduct a large-scale, controlled
evaluation across several key axes of variability to systematically assess the
strengths and weaknesses of LLM-based graph reasoning methods in text-based
applications. The axes include the LLM-graph interaction mode, comparing
prompting, tool-use, and code generation; dataset domains, spanning citation,
web-link, e-commerce, and social networks; structural regimes contrasting
homophilic and heterophilic graphs; feature characteristics involving both
short- and long-text node attributes; and model configurations with varying LLM
sizes and reasoning capabilities. We further analyze dependencies by
methodically truncating features, deleting edges, and removing labels to
quantify reliance on input types. Our findings provide practical and actionable
guidance. (1) LLMs as code generators achieve the strongest overall performance
on graph data, with especially large gains on long-text or high-degree graphs
where prompting quickly exceeds the token budget. (2) All interaction
strategies remain effective on heterophilic graphs, challenging the assumption
that LLM-based methods collapse under low homophily. (3) Code generation is
able to flexibly adapt its reliance between structure, features, or labels to
leverage the most informative input type. Together, these findings provide a
comprehensive view of the strengths and limitations of current LLM-graph
interaction modes and highlight key design principles for future approaches.

</details>


### [20] [A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition](https://arxiv.org/abs/2509.18514)
*Mohamad Elzohbi,Richard Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种使用ByT5模型将短语插入阿拉伯诗歌以符合特定节奏的方法。


<details>
  <summary>Details</summary>
Motivation: 提出一种方法，将短语插入阿拉伯诗歌中，以符合特定节奏。

Method: 使用ByT5模型进行条件去噪目标微调，以重建被遮蔽的单词以匹配目标节奏。采用课程学习策略，在一般阿拉伯语数据集上预训练，然后在诗歌数据集上微调，并探索从英语到阿拉伯语的跨语言迁移。

Result: 实验结果表明，我们的模型在保持语义连贯性的同时实现了高度的节奏对齐。

Conclusion: 该模型有望用于古典阿拉伯诗歌创作过程中的协作应用。

Abstract: This paper presents a methodology for inserting phrases in Arabic poems to
conform to a specific rhythm using ByT5, a byte-level multilingual
transformer-based model. Our work discusses a rule-based grapheme-to-beat
transformation tailored for extracting the rhythm from fully diacritized Arabic
script. Our approach employs a conditional denoising objective to fine-tune
ByT5, where the model reconstructs masked words to match a target rhythm. We
adopt a curriculum learning strategy, pre-training on a general Arabic dataset
before fine-tuning on poetic dataset, and explore cross-lingual transfer from
English to Arabic. Experimental results demonstrate that our models achieve
high rhythmic alignment while maintaining semantic coherence. The proposed
model has the potential to be used in co-creative applications in the process
of composing classical Arabic poems.

</details>


### [21] [Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector](https://arxiv.org/abs/2509.18535)
*Mo Mu,Dianqiao Lei,Chang Li*

Main category: cs.CL

TL;DR: 本文提出了一种新的任务和轻量级框架，用于检测原始和PSP修改的AI生成文本，通过基于内部结构的分类方法来克服现有检测器的局限性。


<details>
  <summary>Details</summary>
Motivation: ChatGPT的广泛采用引发了对其滥用的担忧，这凸显了检测AI生成文本的必要性。当前的词级检测器容易受到改写或简单提示（PSP）的影响，受到ChatGPT的词级模式（CWP）和训练数据内容引起的偏见影响，在修改后的文本上表现下降，并且通常需要大型模型或在线LLM交互。

Method: 我们引入了一个新任务来检测原始和PSP修改的AI生成文本，并提出了一种轻量级框架，该框架基于文本的内部结构进行分类，这种结构在词级变化下保持不变。我们的方法从预训练语言模型中编码句子嵌入，并通过注意力机制建模它们之间的关系。我们采用对比学习来减轻自回归生成的嵌入偏差，并结合因果图和反事实方法来隔离结构特征与主题相关偏差。

Result: 我们的方法在两个精心整理的数据集上验证了其有效性，包括摘要比较和修订的生活常见问题。

Conclusion: 我们的方法在两个精心整理的数据集上验证了其有效性。

Abstract: The widespread adoption of ChatGPT has raised concerns about its misuse,
highlighting the need for robust detection of AI-generated text. Current
word-level detectors are vulnerable to paraphrasing or simple prompts (PSP),
suffer from biases induced by ChatGPT's word-level patterns (CWP) and training
data content, degrade on modified text, and often require large models or
online LLM interaction. To tackle these issues, we introduce a novel task to
detect both original and PSP-modified AI-generated texts, and propose a
lightweight framework that classifies texts based on their internal structure,
which remains invariant under word-level changes. Our approach encodes sentence
embeddings from pre-trained language models and models their relationships via
attention. We employ contrastive learning to mitigate embedding biases from
autoregressive generation and incorporate a causal graph with counterfactual
methods to isolate structural features from topic-related biases. Experiments
on two curated datasets, including abstract comparisons and revised life FAQs,
validate the effectiveness of our method.

</details>


### [22] [CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs](https://arxiv.org/abs/2509.18536)
*Jin Young Kim,Ji Won Yoon*

Main category: cs.CL

TL;DR: CCQA是一种基于循环一致性的新型推理方法，适用于小型语言模型，能够有效提升其在数学和常识推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统方法在小型语言模型（SLMs）上的效果不明确，且通常无法提高性能。因此，需要一种更有效的推理方法来提升SLMs的表现。

Method: CCQA是一种基于循环一致性的新型推理方法，它从每个推理路径和答案生成问题，并通过与原始问题的相似性评估来选择最佳候选解决方案。为了提高效率，使用了一个轻量级的Flan-T5模型专门用于问题生成。

Result: 实验结果表明，CCQA在八个模型上 consistently 超过现有的最先进的方法，并为SLMs的高效推理建立了新的实用基线。

Conclusion: CCQA在数学和常识推理基准测试中 consistently 超过现有的最先进的方法，并为SLMs的高效推理建立了新的实用基线。

Abstract: Recently, inference-time reasoning strategies have further improved the
accuracy of large language models (LLMs), but their effectiveness on smaller
models remains unclear. Based on the observation that conventional approaches
often fail to improve performance in this context, we propose
\textbf{C}ycle-\textbf{C}onsistency in \textbf{Q}uestion \textbf{A}nswering
(CCQA), a novel reasoning method that can be effectively applied to SLMs.
Inspired by cycle consistency, CCQA generates a question from each reasoning
path and answer, evaluates each by its similarity to the original question, and
then selects the candidate solution with the highest similarity score as the
final response. Since conventional SLMs struggle to generate accurate questions
from their own reasoning paths and answers, we employ a lightweight Flan-T5
model specialized for question generation to support this process efficiently.
From the experimental results, it is verified that CCQA consistently
outperforms existing state-of-the-art (SOTA) methods across eight models on
mathematical and commonsense reasoning benchmarks. Furthermore, our method
establishes a new practical baseline for efficient reasoning in SLMs. Source
code can be found at https://github.com/scai-research/ccqa_official.

</details>


### [23] [Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity](https://arxiv.org/abs/2509.18577)
*Yeongbin Seo,Gayoung Kim,Jaehyung Kim,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 本文提出了一种基于先验的数据过滤方法，该方法使用语料库级别的词频统计来估计标记先验，从而作为PPL的快速替代品，无需模型推理。这种方法在多个基准测试中表现优异，并且在处理符号语言和多语言语料库时具有良好的适应性。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）在大规模网络语料库上进行预训练，因此仔细选择数据变得至关重要，以确保有效的学习。虽然基于困惑度（PPL）的过滤表现出色，但它存在缺点：大量的时间成本以及在处理噪声或分布外样本时模型的固有不可靠性。

Method: 我们提出了一种基于先验的数据过滤方法，该方法使用语料库级别的词频统计来估计标记先验，受到关于词角色和词汇密度的语言学见解的启发。我们的方法基于标记先验的均值和标准差过滤文档，作为PPL的快速替代品，而无需模型推理。

Result: 基于先验的过滤方法在20个下游基准测试中实现了最高的平均性能，同时相比基于PPL的过滤减少了超过1000倍的时间成本。

Conclusion: 我们的方法在20个下游基准测试中实现了最高的平均性能，同时相比基于PPL的过滤减少了超过1000倍的时间成本。我们进一步证明了其在符号语言（如代码和数学）中的适用性，并且无需监督就能动态适应多语言语料库。

Abstract: As large language models (LLMs) are pretrained on massive web corpora,
careful selection of data becomes essential to ensure effective and efficient
learning. While perplexity (PPL)-based filtering has shown strong performance,
it suffers from drawbacks: substantial time costs and inherent unreliability of
the model when handling noisy or out-of-distribution samples. In this work, we
propose a simple yet powerful alternative: a prior-based data filtering method
that estimates token priors using corpus-level term frequency statistics,
inspired by linguistic insights on word roles and lexical density. Our approach
filters documents based on the mean and standard deviation of token priors,
serving as a fast proxy to PPL while requiring no model inference. Despite its
simplicity, the prior-based filter achieves the highest average performance
across 20 downstream benchmarks, while reducing time cost by over 1000x
compared to PPL-based filtering. We further demonstrate its applicability to
symbolic languages such as code and math, and its dynamic adaptability to
multilingual corpora without supervision

</details>


### [24] [TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning](https://arxiv.org/abs/2509.18585)
*Yu Chen,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: TsqLoRA是一种新的方法，结合了数据质量驱动的选择和敏感性感知的低秩适应，以提高微调效率并保持或提升性能。


<details>
  <summary>Details</summary>
Motivation: 全微调所有模型参数在计算上昂贵且内存密集，特别是在资源受限的环境中。现有的参数高效微调方法减少了可训练参数的数量，但通常忽略了不同模型层的不同敏感性和训练数据的重要性。

Method: TsqLoRA结合了数据质量驱动的选择和敏感性感知的低秩适应，包括两个主要组件：一个用于选择最有信息量的训练数据的质量感知采样机制，以及一个根据每层对参数更新的敏感性调整等级的动态等级分配模块。

Result: 实验结果表明，TsqLoRA在提高微调效率的同时，保持或甚至提高了在各种NLP任务上的性能。

Conclusion: 实验结果表明，TsqLoRA在提高微调效率的同时，保持或甚至提高了在各种NLP任务上的性能。

Abstract: Fine-tuning large pre-trained models for downstream tasks has become a
fundamental approach in natural language processing. Fully fine-tuning all
model parameters is computationally expensive and memory-intensive, especially
in resource-constrained environments. Existing parameter-efficient fine-tuning
methods reduce the number of trainable parameters but typically overlook the
varying sensitivity of different model layers and the importance of training
data. In this work, we propose TsqLoRA, a novel method that integrates
data-quality-driven selection with sensitivity-aware low-rank adaptation,
consisted of two main components: a quality-aware sampling mechanism for
selecting the most informative training data, and a dynamic rank allocation
module that adjusts the rank of each layer based on its sensitivity to
parameter updates. The experimental results demonstrate that TsqLoRA improves
fine-tuning efficiency while maintaining or even improving performance on a
variety of NLP tasks. Our code will be available at
https://github.com/Benjamin-Ricky/TsqLoRA.

</details>


### [25] [UniECG: Understanding and Generating ECG in One Unified Model](https://arxiv.org/abs/2509.18588)
*Jiarui Jin,Haoyu Wang,Xiang Lan,Jun Li,Gaofeng Cheng,Hongyan Li,Shenda Hong*

Main category: cs.CL

TL;DR: UniECG是第一个能够同时执行基于证据的心电图解释和文本条件心电图生成任务的统一模型，通过解耦的两阶段训练方法实现。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型在理解和生成心电图信号方面存在局限，无法提供准确的医学诊断。

Method: 采用解耦的两阶段训练方法，首先学习基于证据的解释技能（心电图到文本），然后通过潜在空间对齐注入心电图生成能力（文本到心电图）。

Result: UniECG可以根据用户输入自主选择解释或生成心电图，显著扩展了当前心电图模型的能力边界。

Conclusion: UniECG是首个统一的心电图模型，具有重要的应用价值。

Abstract: Recent unified models such as GPT-5 have achieved encouraging progress on
vision-language tasks. However, these unified models typically fail to
correctly understand ECG signals and provide accurate medical diagnoses, nor
can they correctly generate ECG signals. To address these limitations, we
propose UniECG, the first unified model for ECG capable of concurrently
performing evidence-based ECG interpretation and text-conditioned ECG
generation tasks. Through a decoupled two-stage training approach, the model
first learns evidence-based interpretation skills (ECG-to-Text), and then
injects ECG generation capabilities (Text-to-ECG) via latent space alignment.
UniECG can autonomously choose to interpret or generate an ECG based on user
input, significantly extending the capability boundaries of current ECG models.
Our code and checkpoints will be made publicly available at
https://github.com/PKUDigitalHealth/UniECG upon acceptance.

</details>


### [26] [A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users](https://arxiv.org/abs/2509.18632)
*Nishant Balepur,Matthew Shu,Yoo Yeon Sung,Seraphina Goldfarb-Tarrant,Shi Feng,Fumeng Yang,Rachel Rudinger,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 研究发现，基于用户偏好的对齐方法可能无法准确反映LLM计划的实际帮助性，建议通过真实用户交互来改进对齐。


<details>
  <summary>Details</summary>
Motivation: 为了确保LLM生成的计划是有帮助的，通常依赖于用户偏好，但这种方法可能无法准确反映实际帮助性。

Method: 通过Planorama接口收集用户对LLM计划的反馈，并在代理和奖励模型中重现设置以评估计划的帮助性。

Result: 发现用户/模型偏好和代理成功率不能准确预测哪些计划对用户有帮助，且表面线索如简洁性和问题相似性与偏好有关，但无法预测帮助性。

Conclusion: 我们主张对有用的LLM进行对齐需要来自真实用户交互的反馈，而不仅仅是对看起来有用的东西的偏好。

Abstract: To assist users in complex tasks, LLMs generate plans: step-by-step
instructions towards a goal. While alignment methods aim to ensure LLM plans
are helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer,
assuming this reflects what helps them. We test this with Planorama: an
interface where 126 users answer 300 multi-step questions with LLM plans. We
get 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA
success) and user preferences on plans, and recreate the setup in agents and
reward models to see if they simulate or prefer what helps users. We expose: 1)
user/model preferences and agent success do not accurately predict which plans
help users, so common alignment feedback can misalign with helpfulness; 2) this
gap is not due to user-specific preferences, as users are similarly successful
when using plans they prefer/disprefer; 3) surface-level cues like brevity and
question similarity strongly link to preferences, but such biases fail to
predict helpfulness. In all, we argue aligning helpful LLMs needs feedback from
real user interactions, not just preferences of what looks helpful, so we
discuss the plan NLP researchers can execute to solve this problem.

</details>


### [27] [Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering](https://arxiv.org/abs/2509.18655)
*Lingwen Deng,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为CAPE-KG的一致性感知框架，用于参数保留知识编辑（PPKE）在多跳问答（MHQA）任务中，实验表明该方法在PPKE性能上有所提升，证明了解决一致性问题的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图谱的参数保留知识编辑方法在多跳问答任务中存在不一致的问题，导致知识污染、更新不稳定以及检索行为无法反映预期的编辑。因此，需要一种新的方法来解决这些问题，提高PPKE在多跳推理中的可靠性。

Method: 本文提出了一种名为CAPE-KG的一致性感知框架，用于参数保留知识编辑（PPKE）在多跳问答（MHQA）任务中。该框架确保知识图谱的构建、更新和检索始终符合MHQA任务的要求，从而保持未编辑和编辑知识的连贯推理。

Result: 在MQuAKE基准测试上的广泛实验表明，PPKE在多跳问答任务中的性能得到了提升，证明了解决一致性问题的有效性。

Conclusion: 本文提出了CAPE-KG，一种用于多跳问答任务的参数保留知识编辑的一致性感知框架，实验表明该方法在PPKE性能上有所提升，证明了解决一致性问题的有效性。

Abstract: Parameter-Preserving Knowledge Editing (PPKE) enables updating models with
new or corrected information without retraining or parameter adjustment. Recent
PPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)
capabilities to multi-hop question answering (MHQA). However, these methods
often lack consistency, leading to knowledge contamination, unstable updates,
and retrieval behaviors that fail to reflect the intended edits. Such
inconsistencies undermine the reliability of PPKE in multi- hop reasoning. We
present CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge
Graphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures
KG construction, update, and retrieval are always aligned with the requirements
of the MHQA task, maintaining coherent reasoning over both unedited and edited
knowledge. Extensive experiments on the MQuAKE benchmark show accuracy
improvements in PPKE performance for MHQA, demonstrating the effectiveness of
addressing consistency in PPKE.

</details>


### [28] [Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction](https://arxiv.org/abs/2509.18658)
*Huanxin Sheng,Xinyi Liu,Hangfeng He,Jieyu Zhao,Jian Kang*

Main category: cs.CL

TL;DR: 本研究首次提出一种框架，利用共形预测分析LLM-as-a-judge中的不确定性，并提供预测区间。实验表明该方法有效，且区间中点和法官重新提示有助于提高判断质量。


<details>
  <summary>Details</summary>
Motivation: LLM-as-a-judge在自然语言生成评估中展现出潜力，但其评估的不确定性尚未得到充分研究。这种不可靠性可能限制其在许多应用中的部署。因此，需要一种方法来分析和解决这一问题。

Method: 本研究使用共形预测方法构建连续预测区间，并设计了一个用于离散评分任务的有序边界调整。此外，还提出了一种基于区间的中点得分作为原始模型得分和加权平均的低偏差替代方案。

Result: 实验结果表明，共形预测可以提供具有覆盖保证的有效预测区间。同时，区间中点和法官重新提示在改善判断方面表现出一定的有用性。

Conclusion: 本研究提出了一个框架，通过共形预测提供基于LLM的评分预测区间，从而分析LLM-as-a-judge中的不确定性。实验表明，共形预测可以提供具有覆盖保证的有效预测区间，并探索了区间中点和法官重新提示在更好判断中的有用性。

Abstract: LLM-as-a-judge has become a promising paradigm for using large language
models (LLMs) to evaluate natural language generation (NLG), but the
uncertainty of its evaluation remains underexplored. This lack of reliability
may limit its deployment in many applications. This work presents the first
framework to analyze the uncertainty by offering a prediction interval of
LLM-based scoring via conformal prediction. Conformal prediction constructs
continuous prediction intervals from a single evaluation run, and we design an
ordinal boundary adjustment for discrete rating tasks. We also suggest a
midpoint-based score within the interval as a low-bias alternative to raw model
score and weighted average. We perform extensive experiments and analysis,
which show that conformal prediction can provide valid prediction interval with
coverage guarantees. We also explore the usefulness of interval midpoint and
judge reprompting for better judgment.

</details>


### [29] [MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service](https://arxiv.org/abs/2509.18713)
*Yizhe Huang,Yang Liu,Ruiyu Zhao,Xiaolong Zhong,Xingming Yue,Ling Jiang*

Main category: cs.CL

TL;DR: 本文提出了一种名为MemOrb的轻量级记忆层，用于提高大型语言模型代理在客户服务场景中的长期可靠性。通过结构化反思，MemOrb在不进行微调的情况下显著提升了任务成功率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型代理（LLM-based agents）越来越多地部署在客户服务中，但它们常常在会话之间遗忘、重复错误，并且缺乏持续自我改进的机制。这使得它们在需要稳定性和一致性的动态环境中不可靠。为了更好地评估这些特性，我们强调两个指标：任务成功率作为整体效果的衡量标准，以及一致性指标如Pass$^k$来捕捉多次试验中的可靠性。

Method: 我们提出了MemOrb，这是一种轻量级且即插即用的口头强化记忆层，能够将多轮交互浓缩为紧凑的策略反思。这些反思被存储在一个共享的记忆库中，并被检索以指导决策，而无需任何微调。

Result: 实验表明，MemOrb显著提高了成功率和稳定性，多轮成功率最高提升了63个百分点，并在重复试验中提供了更一致的性能。

Conclusion: 我们的结果表明，结构化反思是提高冻结的LLM代理在客户服务场景中长期可靠性的强大机制。

Abstract: Large Language Model-based agents(LLM-based agents) are increasingly deployed
in customer service, yet they often forget across sessions, repeat errors, and
lack mechanisms for continual self-improvement. This makes them unreliable in
dynamic settings where stability and consistency are critical. To better
evaluate these properties, we emphasize two indicators: task success rate as a
measure of overall effectiveness, and consistency metrics such as Pass$^k$ to
capture reliability across multiple trials. To address the limitations of
existing approaches, we propose MemOrb, a lightweight and plug-and-play verbal
reinforcement memory layer that distills multi-turn interactions into compact
strategy reflections. These reflections are stored in a shared memory bank and
retrieved to guide decision-making, without requiring any fine-tuning.
Experiments show that MemOrb significantly improves both success rate and
stability, achieving up to a 63 percentage-point gain in multi-turn success
rate and delivering more consistent performance across repeated trials. Our
results demonstrate that structured reflection is a powerful mechanism for
enhancing long-term reliability of frozen LLM agents in customer service
scenarios.

</details>


### [30] [LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR](https://arxiv.org/abs/2509.18722)
*Pattara Tipaksorn,Sumonmas Thatphithakkul,Vataya Chunwijitra,Kwanchiva Thangthai*

Main category: cs.CL

TL;DR: 本文介绍了一个名为LOTUSDIS的公开泰语会议语料库，用于推进远场对话语音识别。通过微调，显著提高了语音识别的鲁棒性，特别是在远场情况下。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练数据与泰语远场语音之间存在不匹配，导致离线模型性能下降。因此，需要一个包含远场语音的数据集来提高语音识别的鲁棒性。

Method: 本文介绍了LOTUSDIS，一个公开可用的泰语会议语料库，用于推进远场对话语音识别。语料库包含114小时的自发、未脚本的对话，通过九个独立的单通道设备在不同距离下录制，以保留混响、噪声和设备色散的效果。同时提供了标准的训练、开发和测试分割，并发布了可重复的基线系统。

Result: 在零样本和微调条件下对多个Whisper变体进行了基准测试。离线模型在距离上表现出明显的退化，而微调后的泰国Whisper基线显著降低了整体WER和远场WER，特别是在最远的麦克风上取得了显著提升。

Conclusion: 实验结果表明，使用LOTUSDIS数据集进行微调可以显著提高语音识别的鲁棒性，尤其是在远场情况下。该语料库对于推动远场对话语音识别研究具有重要意义。

Abstract: We present LOTUSDIS, a publicly available Thai meeting corpus designed to
advance far-field conversational ASR. The dataset comprises 114 hours of
spontaneous, unscripted dialogue collected in 15-20 minute sessions with three
participants, where overlapping speech is frequent and natural. Speech was
recorded simultaneously by nine independent single-channel devices spanning six
microphone types at distances from 0.12 m to 10 m, preserving the authentic
effects of reverberation, noise, and device coloration without relying on
microphone arrays. We provide standard train, dev, test splits and release a
reproducible baseline system. We benchmarked several Whisper variants under
zero-shot and fine-tuned conditions. Off-the-shelf models showed strong
degradation with distance, confirming a mismatch between pre-training data and
Thai far-field speech. Fine-tuning on LOTUSDIS dramatically improved
robustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and
far-field WER from 81.6 to 49.5, with especially large gains on the most
distant microphones. These results underscore the importance of
distance-diverse training data for robust ASR. The corpus is available under
CC-BY-SA 4.0. We also release training and evaluation scripts as a baseline
system to promote reproducible research in this field.

</details>


### [31] [Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models](https://arxiv.org/abs/2509.18742)
*Yunan Wang,Jianxin Li,Ziwei Zhang*

Main category: cs.CL

TL;DR: DyGRASP is a novel method that efficiently and effectively processes DyTAGs by capturing both recent and global temporal semantics, leading to significant improvements in node retrieval tasks.


<details>
  <summary>Details</summary>
Motivation: Existing methods for static TAGs are insufficient for DyTAGs due to their inability to capture recent-global temporal semantics and efficiency issues when applied to the abundant and evolving text in DyTAGs.

Method: DyGRASP combines LLMs and temporal GNNs, using a node-centric implicit reasoning method with a sliding window mechanism to capture recent temporal semantics, and explicit reasoning with tailored prompts and an RNN-like chain structure to infer long-term semantics. It integrates recent and global temporal semantics along with dynamic graph structural information through updating and merging layers.

Result: DyGRASP achieves up to 34% improvement in Hit@10 for destination node retrieval tasks on DyTAG benchmarks and exhibits strong generalization across different temporal GNNs and LLMs.

Conclusion: DyGRASP demonstrates superior performance in handling DyTAGs and shows strong generalization across different temporal GNNs and LLMs.

Abstract: Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph
interactions and associated text attributes, are prevalent in real-world
applications. Existing methods, such as Graph Neural Networks (GNNs) and Large
Language Models (LLMs), mostly focus on static TAGs. Extending these existing
methods to DyTAGs is challenging as they largely neglect the recent-global
temporal semantics: the recent semantic dependencies among interaction texts
and the global semantic evolution of nodes over time. Furthermore, applying
LLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To
tackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic
Processing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to
efficiently and effectively reason on DyTAGs. Specifically, we first design a
node-centric implicit reasoning method together with a sliding window mechanism
to efficiently capture recent temporal semantics. In addition, to capture
global semantic dynamics of nodes, we leverage explicit reasoning with tailored
prompts and an RNN-like chain structure to infer long-term semantics. Lastly,
we intricately integrate the recent and global temporal semantics as well as
the dynamic graph structural information using updating and merging layers.
Extensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,
achieving up to 34% improvement in Hit@10 for destination node retrieval task.
Besides, DyGRASP exhibits strong generalization across different temporal GNNs
and LLMs.

</details>


### [32] [False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models](https://arxiv.org/abs/2509.18750)
*Julie Kallini,Dan Jurafsky,Christopher Potts,Martijn Bartelds*

Main category: cs.CL

TL;DR: 研究分析了多语言模型中令牌重叠的影响，发现重叠有助于跨语言迁移，并且随着重叠增加，性能提升。


<details>
  <summary>Details</summary>
Motivation: 先前的工作提供了混合的证据，部分原因是不同的设置和混杂因素，如令牌频率或子词分割粒度。我们旨在通过一个受控实验来解决这个问题。

Method: 我们设计了一个受控实验，其中在系统变化的词汇重叠设置下，对多种语言对进行双语自回归模型的训练。

Result: 我们发现具有重叠的模型在XNLI和XQuAD上表现优于具有不相交词汇的模型，并且随着重叠的增加，转移性能通常会提高。

Conclusion: 我们的研究结果突出了多语言模型中令牌重叠的优势，并表明大量的共享词汇仍然是多语言分词器的有益设计选择。

Abstract: Subword tokenizers trained on multilingual corpora naturally produce
overlapping tokens across languages. Does token overlap facilitate
cross-lingual transfer or instead introduce interference between languages?
Prior work offers mixed evidence, partly due to varied setups and confounders,
such as token frequency or subword segmentation granularity. To address this
question, we devise a controlled experiment where we train bilingual
autoregressive models on multiple language pairs under systematically varied
vocabulary overlap settings. Crucially, we explore a new dimension to
understanding how overlap affects transfer: the semantic similarity of tokens
shared across languages. We first analyze our models' hidden representations
and find that overlap of any kind creates embedding spaces that capture
cross-lingual semantic relationships, while this effect is much weaker in
models with disjoint vocabularies. On XNLI and XQuAD, we find that models with
overlap outperform models with disjoint vocabularies, and that transfer
performance generally improves as overlap increases. Overall, our findings
highlight the advantages of token overlap in multilingual models and show that
substantial shared vocabulary remains a beneficial design choice for
multilingual tokenizers.

</details>


### [33] [When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models](https://arxiv.org/abs/2509.18762)
*Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen*

Main category: cs.CL

TL;DR: 本文研究了长上下文微调对短上下文任务性能的影响，发现长上下文微调可以提高短上下文任务的性能，并揭示了其背后的机制。


<details>
  <summary>Details</summary>
Motivation: 本文动机是研究长上下文微调对短上下文任务性能的影响，以及探索其背后的机制。

Method: 本文方法是对多头注意力（MHA）和前馈网络（FFN）进行解耦分析，并研究它们的相互作用，以揭示长上下文微调对短上下文任务的影响机制。

Result: 本文结果表明，长上下文微调可以提高短上下文任务的性能，而不仅仅是由于长上下文预训练带来的退化。

Conclusion: 本文结论是，混合训练可以缓解这种偏差，为微调大型语言模型提供了可解释的指导。

Abstract: Large language models (LLMs) have achieved impressive performance across
natural language processing (NLP) tasks. As real-world applications
increasingly demand longer context windows, continued pretraining and
supervised fine-tuning (SFT) on long-context data has become a common approach.
While the effects of data length in continued pretraining have been extensively
studied, their implications for SFT remain unclear. In this work, we
systematically investigate how SFT data length influences LLM behavior on
short-context tasks. Counterintuitively, we find that long-context SFT improves
short-context performance, contrary to the commonly observed degradation from
long-context pretraining. To uncover the underlying mechanisms of this
phenomenon, we first decouple and analyze two key components, Multi-Head
Attention (MHA) and Feed-Forward Network (FFN), and show that both
independently benefit from long-context SFT. We further study their interaction
and reveal a knowledge preference bias: long-context SFT promotes contextual
knowledge, while short-context SFT favors parametric knowledge, making
exclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that
hybrid training mitigates this bias, offering explainable guidance for
fine-tuning LLMs.

</details>


### [34] [Financial Risk Relation Identification through Dual-view Adaptation](https://arxiv.org/abs/2509.18775)
*Wei-Ning Chiu,Yu-Hsiang Wang,Andy Hsiao,Yu-Shiang Huang,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 本文提出了一种基于10-K文件和自然语言处理技术的系统方法，用于提取企业间的风险关系，并展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 识别企业间的风险关系对于投资组合管理和投资策略至关重要，但传统方法依赖于主观的专家判断和手动分析，难以扩展。

Method: 我们提出了一种系统的方法，利用10-K文件作为数据源，通过自然语言处理技术提取企业间的风险关系。

Result: 实验表明，我们的方法在多个评估设置中表现优于强基线。

Conclusion: 我们的方法在多个评估设置中优于强基线，展示了其有效性。

Abstract: A multitude of interconnected risk events -- ranging from regulatory changes
to geopolitical tensions -- can trigger ripple effects across firms.
Identifying inter-firm risk relations is thus crucial for applications like
portfolio management and investment strategy. Traditionally, such assessments
rely on expert judgment and manual analysis, which are, however, subjective,
labor-intensive, and difficult to scale. To address this, we propose a
systematic method for extracting inter-firm risk relations using Form 10-K
filings -- authoritative, standardized financial documents -- as our data
source. Leveraging recent advances in natural language processing, our approach
captures implicit and abstract risk connections through unsupervised
fine-tuning based on chronological and lexical patterns in the filings. This
enables the development of a domain-specific financial encoder with a deeper
contextual understanding and introduces a quantitative risk relation score for
transparency, interpretable analysis. Extensive experiments demonstrate that
our method outperforms strong baselines across multiple evaluation settings.

</details>


### [35] [AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field](https://arxiv.org/abs/2509.18776)
*Chen Liang,Zhaoqi Huang,Haofen Wang,Fu Chai,Chunying Yu,Huanhuan Wei,Zhengjie Liu,Yanpeng Li,Hongjun Wang,Ruifeng Luo,Xianzhong Zhao*

Main category: cs.CL

TL;DR: 本文建立了AECBench基准，评估了大型语言模型在建筑、工程和施工领域的表现，并揭示了它们在多个认知水平上的性能下降。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在建筑、工程和施工（AEC）领域越来越受到关注，但它们在这样一个专业且安全关键的领域中的稳健性和可靠性仍有待评估。因此，本文旨在建立一个全面的基准，以评估LLMs在AEC领域的表现。

Method: 本文建立了AECBench，这是一个全面的基准，旨在量化当前LLMs在建筑、工程和施工（AEC）领域的优缺点。该基准定义了23个代表性任务，这些任务位于一个五级认知导向评估框架中，包括知识记忆、理解、推理、计算和应用。此外，还引入了一种LLM-as-a-Judge方法，以提供一种可扩展且一致的方法来评估复杂、长格式的回答。

Result: 通过对九个LLMs的评估，发现它们在五个认知水平上表现出性能下降。尽管在基础任务上表现出色，但在解释来自建筑规范表格的知识、执行复杂推理和计算以及生成领域特定文档方面存在显著缺陷。

Conclusion: 本研究为未来在安全关键工程实践中稳健可靠地集成大型语言模型（LLMs）奠定了基础。

Abstract: Large language models (LLMs), as a novel information technology, are seeing
increasing adoption in the Architecture, Engineering, and Construction (AEC)
field. They have shown their potential to streamline processes throughout the
building lifecycle. However, the robustness and reliability of LLMs in such a
specialized and safety-critical domain remain to be evaluated. To address this
challenge, this paper establishes AECBench, a comprehensive benchmark designed
to quantify the strengths and limitations of current LLMs in the AEC domain.
The benchmark defines 23 representative tasks within a five-level
cognition-oriented evaluation framework encompassing Knowledge Memorization,
Understanding, Reasoning, Calculation, and Application. These tasks were
derived from authentic AEC practice, with scope ranging from codes retrieval to
specialized documents generation. Subsequently, a 4,800-question dataset
encompassing diverse formats, including open-ended questions, was crafted
primarily by engineers and validated through a two-round expert review.
Furthermore, an LLM-as-a-Judge approach was introduced to provide a scalable
and consistent methodology for evaluating complex, long-form responses
leveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear
performance decline across five cognitive levels was revealed. Despite
demonstrating proficiency in foundational tasks at the Knowledge Memorization
and Understanding levels, the models showed significant performance deficits,
particularly in interpreting knowledge from tables in building codes, executing
complex reasoning and calculation, and generating domain-specific documents.
Consequently, this study lays the groundwork for future research and
development aimed at the robust and reliable integration of LLMs into
safety-critical engineering practices.

</details>


### [36] [Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing](https://arxiv.org/abs/2509.18792)
*Sabri Boughorbel,Fahim Dalvi,Nadir Durrani,Majd Hawasly*

Main category: cs.CL

TL;DR: 本文使用模型差异分析方法，研究了Gemma-2-9b-it和SimPO增强变体之间的能力差异，发现SimPO在多个方面有显著提升，并揭示了性能差距背后的机制原因。


<details>
  <summary>Details</summary>
Motivation: 随着微调成为改进大型语言模型的主要范式，了解这一过程中的变化变得越来越重要。传统基准测试往往无法解释为什么一个模型比另一个模型表现更好。

Method: 使用模型差异分析（一种机制可解释性方法）来分析Gemma-2-9b-it和一个SimPO增强变体之间的特定能力差异。通过crosscoders，识别并分类区分两个模型的潜在表示。

Result: SimPO获得了主要增强安全机制（+32.8%）、多语言能力（+43.8%）和指令遵循能力（+151.7%），而其额外训练也减少了对模型自我参考（-44.1%）和幻觉管理（-68.5%）的强调。

Conclusion: 模型差异分析可以提供超越排行榜指标的细粒度见解，将性能差距归因于具体的机制能力。这种方法为比较大型语言模型提供了一个透明且有针对性的框架。

Abstract: As fine-tuning becomes the dominant paradigm for improving large language
models (LLMs), understanding what changes during this process is increasingly
important. Traditional benchmarking often fails to explain why one model
outperforms another. In this work, we use model diffing, a mechanistic
interpretability approach, to analyze the specific capability differences
between Gemma-2-9b-it and a SimPO-enhanced variant. Using crosscoders, we
identify and categorize latent representations that differentiate the two
models. We find that SimPO acquired latent concepts predominantly enhance
safety mechanisms (+32.8%), multilingual capabilities (+43.8%), and
instruction-following (+151.7%), while its additional training also reduces
emphasis on model self-reference (-44.1%) and hallucination management
(-68.5%). Our analysis shows that model diffing can yield fine-grained insights
beyond leaderboard metrics, attributing performance gaps to concrete
mechanistic capabilities. This approach offers a transparent and targeted
framework for comparing LLMs.

</details>


### [37] [MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction](https://arxiv.org/abs/2509.18813)
*Liting Zhang,Shiwan Zhao,Aobo Kong,Qicheng Li*

Main category: cs.CL

TL;DR: MAPEX是第一个将多智能体协作引入关键短语提取的框架，通过双路径策略动态适应文档长度，表现出强大的泛化能力和性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督提示方法在大型语言模型上往往依赖于统一的单阶段推理管道，这限制了对大型语言模型推理和生成能力的充分利用，特别是在不同场景下的关键短语提取复杂性方面。

Method: MAPEX引入了多智能体协作到关键短语提取中，通过专家招聘、候选提取、主题引导、知识增强和后处理模块协调基于LLM的智能体。采用双路径策略动态适应文档长度：知识驱动提取用于短文本，主题引导提取用于长文本。

Result: 在三个不同的大型语言模型上的六个基准数据集上进行的广泛实验表明，MAPEX在F1@5上平均优于最先进的无监督方法2.44%和标准大型语言模型基线4.01%。

Conclusion: MAPEX在六个基准数据集上的实验表明其具有强大的泛化能力和通用性，优于最先进的无监督方法和标准LLM基线。

Abstract: Keyphrase extraction is a fundamental task in natural language processing.
However, existing unsupervised prompt-based methods for Large Language Models
(LLMs) often rely on single-stage inference pipelines with uniform prompting,
regardless of document length or LLM backbone. Such one-size-fits-all designs
hinder the full exploitation of LLMs' reasoning and generation capabilities,
especially given the complexity of keyphrase extraction across diverse
scenarios. To address these challenges, we propose MAPEX, the first framework
that introduces multi-agent collaboration into keyphrase extraction. MAPEX
coordinates LLM-based agents through modules for expert recruitment, candidate
extraction, topic guidance, knowledge augmentation, and post-processing. A
dual-path strategy dynamically adapts to document length: knowledge-driven
extraction for short texts and topic-guided extraction for long texts.
Extensive experiments on six benchmark datasets across three different LLMs
demonstrate its strong generalization and universality, outperforming the
state-of-the-art unsupervised method by 2.44\% and standard LLM baselines by
4.01\% in F1@5 on average. Code is available at
https://github.com/NKU-LITI/MAPEX.

</details>


### [38] [Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?](https://arxiv.org/abs/2509.18843)
*Damian Stachura,Joanna Konieczna,Artur Nowak*

Main category: cs.CL

TL;DR: 研究显示，开放权重的大语言模型在生物医学问答任务中能够与专有模型相媲美，甚至在某些情况下表现更优，尤其是在使用集成策略时。


<details>
  <summary>Details</summary>
Motivation: 探索开放权重的小型LLMs是否能够有效替代大型专有模型，特别是在生物医学问答领域。

Method: 通过检索基于嵌入距离的相关片段、上下文学习和结构化输出等技术来增强问答能力，并使用集成方法来利用不同模型的输出。

Result: 开放权重的LLMs在生物医学问答任务中表现与专有模型相当，有时甚至更好。

Conclusion: 开放权重的大语言模型（LLMs）在性能上已经可以与专有模型相媲美，甚至在某些情况下超过了它们，特别是在使用集成策略时。

Abstract: Open-weight versions of large language models (LLMs) are rapidly advancing,
with state-of-the-art models like DeepSeek-V3 now performing comparably to
proprietary LLMs. This progression raises the question of whether small
open-weight LLMs are capable of effectively replacing larger closed-source
models. We are particularly interested in the context of biomedical
question-answering, a domain we explored by participating in Task 13B Phase B
of the BioASQ challenge. In this work, we compare several open-weight models
against top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and
Claude 3.7 Sonnet. To enhance question answering capabilities, we use various
techniques including retrieving the most relevant snippets based on embedding
distance, in-context learning, and structured outputs. For certain submissions,
we utilize ensemble approaches to leverage the diverse outputs generated by
different models for exact-answer questions. Our results demonstrate that
open-weight LLMs are comparable to proprietary ones. In some instances,
open-weight LLMs even surpassed their closed counterparts, particularly when
ensembling strategies were applied. All code is publicly available at
https://github.com/evidenceprime/BioASQ-13b.

</details>


### [39] [Multi-Hierarchical Feature Detection for Large Language Model Generated Text](https://arxiv.org/abs/2509.18862)
*Luyan Zhang,Xinyu Xie*

Main category: cs.CL

TL;DR: 本文研究了多层级特征集成在AI文本检测中的应用，发现虽然理论上有潜力，但实际性能提升有限且计算成本高，表明现代神经语言模型可能已高效捕捉了主要检测信号。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型技术的快速发展，人们越来越关注多特征方法是否能显著提高AI文本检测效果，超越单一神经网络模型的表现。虽然直觉上认为结合语义、句法和统计特征可以提供互补信号，但这一假设尚未在现代LLM生成的文本中得到严格测试。

Method: 本文提出了MHFD（多层级特征检测）方法，通过自适应融合结合DeBERTa-based语义分析、句法解析和统计概率特征，对多层级特征集成进行系统实证研究。

Result: 实验结果表明，尽管理论上预期多特征集成能带来提升，但实际上其性能提升非常有限（0.4-0.5%），而计算开销却显著增加（4.2倍）。MHFD方法在多个基准数据集上的实验结果显示，它在领域内检测中达到89.7%的准确率，并在跨领域检测中保持84.2%的稳定性能，比现有方法有0.4-2.6%的适度改进。

Conclusion: 实验结果表明，MHFD方法在领域内检测中达到了89.7%的准确率，并在跨领域检测中保持了84.2%的稳定性能，显示出比现有方法0.4-2.6%的适度改进。然而，多特征集成带来的性能提升有限（0.4-0.5%），而计算开销却显著增加（4.2倍）。这表明现代神经语言模型可能已经高效地捕捉了大多数相关的检测信号。

Abstract: With the rapid advancement of large language model technology, there is
growing interest in whether multi-feature approaches can significantly improve
AI text detection beyond what single neural models achieve. While intuition
suggests that combining semantic, syntactic, and statistical features should
provide complementary signals, this assumption has not been rigorously tested
with modern LLM-generated text. This paper provides a systematic empirical
investigation of multi-hierarchical feature integration for AI text detection,
specifically testing whether the computational overhead of combining multiple
feature types is justified by performance gains. We implement MHFD
(Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic
analysis, syntactic parsing, and statistical probability features through
adaptive fusion. Our investigation reveals important negative results: despite
theoretical expectations, multi-feature integration provides minimal benefits
(0.4-0.5% improvement) while incurring substantial computational costs (4.2x
overhead), suggesting that modern neural language models may already capture
most relevant detection signals efficiently. Experimental results on multiple
benchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in
in-domain detection and maintains 84.2% stable performance in cross-domain
detection, showing modest improvements of 0.4-2.6% over existing methods.

</details>


### [40] [Diversity Boosts AI-Generated Text Detection](https://arxiv.org/abs/2509.18880)
*Advik Raj Basani,Pin-Yu Chen*

Main category: cs.CL

TL;DR: DivEye is a novel detection framework that uses surprisal-based features to capture unpredictability in text, offering improved performance and interpretability over existing methods.


<details>
  <summary>Details</summary>
Motivation: Prior detectors often rely on token-level likelihoods or opaque black-box classifiers, which struggle against high-quality generations and offer little interpretability. The need for a more robust and interpretable detection method has become increasingly important due to the misuse of LLMs in various fields.

Method: DivEye captures how unpredictability fluctuates across a text using surprisal-based features. It uses a set of interpretable statistical features to capture the variability in lexical and structural unpredictability between human-authored text and LLM outputs.

Result: DivEye outperforms existing zero-shot detectors by up to 33.2% and achieves competitive performance with fine-tuned baselines across multiple benchmarks. It is robust to paraphrasing and adversarial attacks, generalizes well across domains and models, and improves the performance of existing detectors by up to 18.7% when used as an auxiliary signal.

Conclusion: DivEye is a robust and interpretable detection framework that outperforms existing zero-shot detectors and improves the performance of existing detectors by up to 18.7% when used as an auxiliary signal. It provides insights into why a text is flagged, highlighting rhythmic unpredictability as a powerful signal for LLM detection.

Abstract: Detecting AI-generated text is an increasing necessity to combat misuse of
LLMs in education, business compliance, journalism, and social media, where
synthetic fluency can mask misinformation or deception. While prior detectors
often rely on token-level likelihoods or opaque black-box classifiers, these
approaches struggle against high-quality generations and offer little
interpretability. In this work, we propose DivEye, a novel detection framework
that captures how unpredictability fluctuates across a text using
surprisal-based features. Motivated by the observation that human-authored text
exhibits richer variability in lexical and structural unpredictability than LLM
outputs, DivEye captures this signal through a set of interpretable statistical
features. Our method outperforms existing zero-shot detectors by up to 33.2%
and achieves competitive performance with fine-tuned baselines across multiple
benchmarks. DivEye is robust to paraphrasing and adversarial attacks,
generalizes well across domains and models, and improves the performance of
existing detectors by up to 18.7% when used as an auxiliary signal. Beyond
detection, DivEye provides interpretable insights into why a text is flagged,
pointing to rhythmic unpredictability as a powerful and underexplored signal
for LLM detection.

</details>


### [41] [Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass](https://arxiv.org/abs/2509.18901)
*Nicholas Popovič,Michael Färber*

Main category: cs.CL

TL;DR: JEDI是一种仅编码器的架构，能够在不使用生成模型的情况下进行提取性原子事实分解和可解释的推理。通过使用合成推理语料库，JEDI在准确性和鲁棒性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的方法依赖于资源密集型的生成大型语言模型（LLMs）来进行分解。我们希望提出一种更高效的方法，以提高可解释性和鲁棒性。

Method: 我们提出了JEDI，这是一种仅编码器的架构，能够联合执行提取性原子事实分解和可解释的推理，而无需在推理过程中使用生成模型。为了促进训练，我们生成了一个覆盖多个NLI基准的大规模合成推理语料库。

Result: 实验结果表明，JEDI在分布内的准确性具有竞争力，并且在分布外和对抗设置中显著提高了鲁棒性。

Conclusion: 我们的研究表明，通过使用编码器-only架构和合成推理，可以在NLI中实现可解释性和鲁棒的泛化。

Abstract: Recent works in Natural Language Inference (NLI) and related tasks, such as
automated fact-checking, employ atomic fact decomposition to enhance
interpretability and robustness. For this, existing methods rely on
resource-intensive generative large language models (LLMs) to perform
decomposition. We propose JEDI, an encoder-only architecture that jointly
performs extractive atomic fact decomposition and interpretable inference
without requiring generative models during inference. To facilitate training,
we produce a large corpus of synthetic rationales covering multiple NLI
benchmarks. Experimental results demonstrate that JEDI achieves competitive
accuracy in distribution and significantly improves robustness out of
distribution and in adversarial settings over models based solely on extractive
rationale supervision. Our findings show that interpretability and robust
generalization in NLI can be realized using encoder-only architectures and
synthetic rationales. Code and data available at https://jedi.nicpopovic.com

</details>


### [42] [DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment](https://arxiv.org/abs/2509.18987)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本文提出了一种使用DTW进行语音和文本嵌入对齐的方法，以改进E2E-ST，该方法在准确性、速度和低资源设置中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决语音和文本模态之间的表示差异问题，以改进端到端语音翻译(E2E-ST)。

Method: 我们适应了动态时间规整(DTW)来在训练期间对齐语音和文本嵌入。

Result: 我们的方法产生了更准确的对齐，并在E2E-ST中取得了可比的结果，同时显著更快。此外，在5/6的语言方向上，我们的方法在低资源设置中表现更好。

Conclusion: 我们的方法在E2E-ST中有效地弥合了模态差距，并在低资源设置中表现优于之前的工作。

Abstract: End-to-End Speech Translation (E2E-ST) is the task of translating source
speech directly into target text bypassing the intermediate transcription step.
The representation discrepancy between the speech and text modalities has
motivated research on what is known as bridging the modality gap.
State-of-the-art methods addressed this by aligning speech and text
representations on the word or token level. Unfortunately, this requires an
alignment tool that is not available for all languages. Although this issue has
been addressed by aligning speech and text embeddings using nearest-neighbor
similarity search, it does not lead to accurate alignments. In this work, we
adapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during
training. Our experiments demonstrate the effectiveness of our method in
bridging the modality gap in E2E-ST. Compared to previous work, our method
produces more accurate alignments and achieves comparable E2E-ST results while
being significantly faster. Furthermore, our method outperforms previous work
in low resource settings on 5 out of 6 language directions.

</details>


### [43] [Investigating Test-Time Scaling with Reranking for Machine Translation](https://arxiv.org/abs/2509.19020)
*Shaomu Tan,Ryosuke Mitani,Ritvik Choudhary,Toshiyuki Sekiya*

Main category: cs.CL

TL;DR: This paper presents the first systematic study of Test-Time Scaling (TTS) for machine translation, showing that TTS can improve translation quality for high-resource languages and match or surpass larger models with more compute cost, but may degrade quality in low-resource cases under fixed compute budgets.


<details>
  <summary>Details</summary>
Motivation: Scaling model parameters is costly, and TTS offers an alternative by allocating more computation at inference. However, TTS has not been systematically explored for machine translation.

Method: We present the first systematic study of TTS for machine translation, investigating a best-of-N framework on WMT24 benchmarks.

Result: For high-resource languages, TTS generally improves translation quality according to multiple metrics, and human evaluation confirms these gains. Smaller models with large N can match or surpass larger models at N=1 with more compute cost. Under fixed compute budgets, larger models are typically more efficient, and TTS can degrade quality in low-resource cases.

Conclusion: TTS can improve translation quality for high-resource languages and can match or surpass larger models with more compute cost, but may degrade quality in low-resource cases under fixed compute budgets.

Abstract: Scaling model parameters has become the de facto strategy for improving NLP
systems, but it comes with substantial computational costs. Test-Time Scaling
(TTS) offers an alternative by allocating more computation at inference:
generating multiple candidates and selecting the best. While effective in tasks
such as mathematical reasoning, TTS has not been systematically explored for
machine translation (MT). In this paper, we present the first systematic study
of TTS for MT, investigating a simple but practical best-of-N framework on
WMT24 benchmarks. Our experiments cover six high-resource and one low-resource
language pairs, five model sizes (3B-72B), and various TTS compute budget (N up
to 1024). Our results show that a) For high-resource languages, TTS generally
improves translation quality according to multiple neural MT evaluation
metrics, and our human evaluation confirms these gains; b) Augmenting smaller
models with large $N$ can match or surpass larger models at $N{=}1$ with more
compute cost; c) Under fixed compute budgets, larger models are typically more
efficient, and TTS can degrade quality due to metric blind spots in
low-resource cases.

</details>


### [44] [Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus](https://arxiv.org/abs/2509.19033)
*Chiara Alzetta,Serena Auriemma,Alessandro Bondielli,Luca Dini,Chiara Fazzone,Alessio Miaschi,Martina Miliani,Marta Sartor*

Main category: cs.CL

TL;DR: 本文分析了意大利计算语言学和自然语言处理社区的研究趋势，通过CLiC-it会议的论文集提供了该领域的新兴趋势和关键发展的见解。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为意大利和国际研究社区提供有关计算语言学和自然语言处理领域新兴趋势和关键发展的有价值见解，以支持未来的决策和研究方向。

Method: 本文收集了CLiC-it会议前10届的论文集（从2014年到2024年），并进行了元数据和论文内容的全面分析，包括作者背景、性别、隶属关系等信息。

Result: 本文提供了CLiC-it会议前10届的论文集，并对其元数据和论文内容进行了全面分析，揭示了该领域的研究趋势和关键发展。

Conclusion: 本文通过分析CLiC-it会议的贡献，追踪了意大利计算语言学和自然语言处理社区的研究趋势，并提供了关于该领域新兴趋势和关键发展的见解，以支持未来的决策和研究方向。

Abstract: Over the past decade, Computational Linguistics (CL) and Natural Language
Processing (NLP) have evolved rapidly, especially with the advent of
Transformer-based Large Language Models (LLMs). This shift has transformed
research goals and priorities, from Lexical and Semantic Resources to Language
Modelling and Multimodality. In this study, we track the research trends of the
Italian CL and NLP community through an analysis of the contributions to
CLiC-it, arguably the leading Italian conference in the field. We compile the
proceedings from the first 10 editions of the CLiC-it conference (from 2014 to
2024) into the CLiC-it Corpus, providing a comprehensive analysis of both its
metadata, including author provenance, gender, affiliations, and more, as well
as the content of the papers themselves, which address various topics. Our goal
is to provide the Italian and international research communities with valuable
insights into emerging trends and key developments over time, supporting
informed decisions and future directions in the field.

</details>


### [45] [Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering](https://arxiv.org/abs/2509.19094)
*Alireza Salemi,Cheng Li,Mingyang Zhang,Qiaozhu Mei,Zhuowan Li,Spurthi Amba Hombaiah,Weize Kong,Tao Chen,Hamed Zamani,Michael Bendersky*

Main category: cs.CL

TL;DR: 本文提出了一种名为Pathways of Thoughts (PoT)的方法，用于个性化问答系统，通过探索多种推理轨迹并根据推断的用户偏好聚合和重新加权候选响应，从而提高准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 个性化QA系统需要适应用户特定的信息需求，但存在从长而嘈杂的上下文中推断偏好以及生成正确、上下文合适且与用户期望和背景知识一致的响应的挑战。

Method: 提出了一种名为Pathways of Thoughts (PoT)的方法，该方法在推理阶段适用于任何大型语言模型，无需任务特定的微调。

Result: 在LaMP-QA基准测试中，PoT始终优于竞争基线，相对改进高达13.1%。人工评估也证实了这些结果，66%的情况下标注者更喜欢PoT的输出。

Conclusion: PoT在个性化QA任务中表现出色，能够生成更符合用户需求的响应。

Abstract: Personalization is essential for adapting question answering (QA) systems to
user-specific information needs, thereby improving both accuracy and user
satisfaction. However, personalized QA remains relatively underexplored due to
challenges such as inferring preferences from long, noisy, and implicit
contexts, and generating responses that are simultaneously correct,
contextually appropriate, and aligned with user expectations and background
knowledge. To address these challenges, we propose Pathways of Thoughts (PoT),
an inference-stage method that applies to any large language model (LLM)
without requiring task-specific fine-tuning. The approach models the reasoning
of an LLM as an iterative decision process, where the model dynamically selects
among cognitive operations such as reasoning, revision, personalization, and
clarification. This enables exploration of multiple reasoning trajectories,
producing diverse candidate responses that capture different perspectives. PoT
then aggregates and reweights these candidates according to inferred user
preferences, yielding a final personalized response that benefits from the
complementary strengths of diverse reasoning paths. Experiments on the LaMP-QA
benchmark for personalized QA show that PoT consistently outperforms
competitive baselines, achieving up to a 13.1% relative improvement. Human
evaluation corroborates these results, with annotators preferring outputs from
PoT in 66% of cases and reporting ties in only 15% of cases.

</details>


### [46] [Are most sentences unique? An empirical examination of Chomskyan claims](https://arxiv.org/abs/2509.19108)
*Hiram Ring*

Main category: cs.CL

TL;DR: 该研究利用NLTK库分析不同类型的语料库，发现尽管大多数句子是独特的，但重复的句子在语料库中仍占有一席之地。


<details>
  <summary>Details</summary>
Motivation: 语言学中一个常见的说法是大多数语言表达都是独特的，但随着大规模语料库的可用性增加，这一说法可以被实证研究。

Method: 使用NLTK Python库解析不同类型的语料库，并统计每个语料库中的精确字符串匹配次数。

Result: 结果表明，虽然完全独特的句子通常是语料库中的大多数，但这一现象高度受类型限制，重复的句子在任何单个语料库中都不是微不足道的部分。

Conclusion: 重复的句子在任何单个语料库中都不是微不足道的部分，这表明语言使用中的重复现象值得进一步研究。

Abstract: A repeated claim in linguistics is that the majority of linguistic utterances
are unique. For example, Pinker (1994: 10), summarizing an argument by Noam
Chomsky, states that "virtually every sentence that a person utters or
understands is a brand-new combination of words, appearing for the first time
in the history of the universe." With the increased availability of large
corpora, this is a claim that can be empirically investigated. The current
paper addresses the question by using the NLTK Python library to parse corpora
of different genres, providing counts of exact string matches in each. Results
show that while completely unique sentences are often the majority of corpora,
this is highly constrained by genre, and that duplicate sentences are not an
insignificant part of any individual corpus.

</details>


### [47] [Human-Annotated NER Dataset for the Kyrgyz Language](https://arxiv.org/abs/2509.19109)
*Timur Turatali,Anton Alekseev,Gulira Jumalieva,Gulnara Kabaeva,Sergey Nikolenko*

Main category: cs.CL

TL;DR: 本文介绍了KyrgyzNER，这是第一个手动注释的吉尔吉斯语命名实体识别数据集，并评估了多种模型在该任务上的表现。结果表明，多语言预训练模型在处理资源有限语言时具有挑战性和机会。


<details>
  <summary>Details</summary>
Motivation: 本文旨在创建一个用于吉尔吉斯语命名实体识别的首个手动注释数据集，并评估不同模型在该任务上的表现，以探索多语言预训练模型在资源有限语言中的应用潜力。

Method: 我们引入了KyrgyzNER，这是第一个手动注释的吉尔吉斯语命名实体识别数据集。该数据集包含来自24.KG新闻门户的1,499篇新闻文章，包含10,900个句子和39,075个实体提及，涵盖了27个命名实体类别。我们展示了我们的注释方案，讨论了注释过程中遇到的挑战，并提供了描述性统计信息。我们还评估了几种命名实体识别模型，包括基于条件随机场的传统序列标记方法和在我们的数据集上微调的最先进的多语言变压器模型。

Result: 所有模型在罕见实体类别上都表现出困难，但基于多语言RoBERTa的模型在精确率和召回率之间取得了有希望的平衡。这些结果表明，多语言预训练模型在处理资源有限的语言时具有挑战性和机会。虽然多语言RoBERTa模型表现最佳，但其他多语言模型也取得了相当的结果。

Conclusion: 这些发现强调了使用多语言预训练模型处理资源有限语言的挑战和机遇。虽然多语言RoBERTa模型表现最佳，但其他多语言模型也取得了相当的结果。这表明，未来研究更细粒度的注释方案可能会为吉尔吉斯语处理管道评估提供更深入的见解。

Abstract: We introduce KyrgyzNER, the first manually annotated named entity recognition
dataset for the Kyrgyz language. Comprising 1,499 news articles from the 24.KG
news portal, the dataset contains 10,900 sentences and 39,075 entity mentions
across 27 named entity classes. We show our annotation scheme, discuss the
challenges encountered in the annotation process, and present the descriptive
statistics. We also evaluate several named entity recognition models, including
traditional sequence labeling approaches based on conditional random fields and
state-of-the-art multilingual transformer-based models fine-tuned on our
dataset. While all models show difficulties with rare entity categories, models
such as the multilingual RoBERTa variant pretrained on a large corpus across
many languages achieve a promising balance between precision and recall. These
findings emphasize both the challenges and opportunities of using multilingual
pretrained models for processing languages with limited resources. Although the
multilingual RoBERTa model performed best, other multilingual models yielded
comparable results. This suggests that future work exploring more granular
annotation schemes may offer deeper insights for Kyrgyz language processing
pipelines evaluation.

</details>


### [48] [Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering](https://arxiv.org/abs/2509.19125)
*Kun Zhu,Lizi Liao,Yuxuan Gu,Lei Huang,Xiaocheng Feng,Bing Qin*

Main category: cs.CL

TL;DR: 本文提出了一种新的上下文感知层次分类法生成框架，通过整合LLM引导的多方面编码和动态聚类，提高了分类法的连贯性、粒度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长需要高效的方法来组织和综合研究结果。现有的分类法构建方法，利用无监督聚类或直接提示大型语言模型（LLMs），通常缺乏连贯性和粒度。

Method: 我们提出了一种新颖的上下文感知层次分类法生成框架，该框架结合了LLM引导的多方面编码和动态聚类。我们的方法利用LLMs识别每篇论文的关键方面（例如，方法、数据集、评估），并生成特定于方面的论文摘要，然后在每个方面上进行编码和聚类，以形成连贯的层次结构。

Result: 实验结果表明，我们的方法显著优于之前的方法，在分类法的连贯性、粒度和可解释性方面取得了最先进的性能。

Conclusion: 我们的方法在分类法的连贯性、粒度和可解释性方面显著优于之前的方法，达到了最先进的性能。

Abstract: The rapid growth of scientific literature demands efficient methods to
organize and synthesize research findings. Existing taxonomy construction
methods, leveraging unsupervised clustering or direct prompting of large
language models (LLMs), often lack coherence and granularity. We propose a
novel context-aware hierarchical taxonomy generation framework that integrates
LLM-guided multi-aspect encoding with dynamic clustering. Our method leverages
LLMs to identify key aspects of each paper (e.g., methodology, dataset,
evaluation) and generates aspect-specific paper summaries, which are then
encoded and clustered along each aspect to form a coherent hierarchy. In
addition, we introduce a new evaluation benchmark of 156 expert-crafted
taxonomies encompassing 11.6k papers, providing the first naturally annotated
dataset for this task. Experimental results demonstrate that our method
significantly outperforms prior approaches, achieving state-of-the-art
performance in taxonomy coherence, granularity, and interpretability.

</details>


### [49] [Anecdoctoring: Automated Red-Teaming Across Language and Place](https://arxiv.org/abs/2509.19143)
*Alejandro Cuevas,Saloni Dash,Bharat Kumar Nayak,Dan Vann,Madeleine I. G. Daepp*

Main category: cs.CL

TL;DR: 本文提出了一种新的红队评估方法'anecdoctoring'，用于生成跨语言和文化的对抗性提示，以提高攻击成功率并提供可解释性优势。研究结果强调了需要在全球范围内实施基于现实世界对抗性滥用的虚假信息缓解措施。


<details>
  <summary>Details</summary>
Motivation: 由于红队评估数据集通常以美国和英语为中心，而生成式AI的全球采用需要在不同语言和文化中具有鲁棒性的红队评估，因此需要解决这一差距。

Method: 提出了一种名为'anecdoctoring'的新红队评估方法，该方法可以跨语言和文化自动生成对抗性提示。从三个语言（英语、西班牙语和印地语）和两个地理区域（美国和印度）的事实核查网站收集了错误信息声明，并将这些声明聚类为更广泛的故事，然后用知识图谱对这些聚类进行表征，以增强攻击者使用的大型语言模型。

Result: 与少样本提示相比，该方法产生了更高的攻击成功率，并提供了可解释性的优势。

Conclusion: 研究结果强调了需要在全球范围内实施基于现实世界对抗性滥用的虚假信息缓解措施。

Abstract: Disinformation is among the top risks of generative artificial intelligence
(AI) misuse. Global adoption of generative AI necessitates red-teaming
evaluations (i.e., systematic adversarial probing) that are robust across
diverse languages and cultures, but red-teaming datasets are commonly US- and
English-centric. To address this gap, we propose "anecdoctoring", a novel
red-teaming approach that automatically generates adversarial prompts across
languages and cultures. We collect misinformation claims from fact-checking
websites in three languages (English, Spanish, and Hindi) and two geographies
(US and India). We then cluster individual claims into broader narratives and
characterize the resulting clusters with knowledge graphs, with which we
augment an attacker LLM. Our method produces higher attack success rates and
offers interpretability benefits relative to few-shot prompting. Results
underscore the need for disinformation mitigations that scale globally and are
grounded in real-world adversarial misuse.

</details>


### [50] [Measuring AI "Slop" in Text](https://arxiv.org/abs/2509.19163)
*Chantal Shaib,Tuhin Chakrabarty,Diego Garcia-Olano,Byron C. Wallace*

Main category: cs.CL

TL;DR: 本文通过访谈专家开发了AI生成文本中低质量内容（即slop）的分类法，并提出了一套可解释的评估维度。研究发现二元slop判断虽然主观，但与连贯性和相关性等潜在维度有关。该框架可用于评估AI生成文本的质量，并可能揭示影响质量判断的语言和风格因素。


<details>
  <summary>Details</summary>
Motivation: 目前没有对AI“slop”这一术语的共识定义或衡量方法，因此需要一种系统的方式来评估AI生成文本的质量。

Method: 通过与NLP、写作和哲学领域的专家进行访谈，我们开发了“slop”的分类法，并提出了可解释的维度来评估文本中的slop。通过跨度级注释，我们发现二元slop判断是（某种程度上）主观的，但这些决定仍然与潜在的维度如连贯性和相关性相关。

Result: 通过跨度级注释，我们发现二元slop判断是（某种程度上）主观的，但这些决定仍然与潜在的维度如连贯性和相关性相关。

Conclusion: 我们的框架可以用于在检测和二元偏好任务中评估AI生成的文本，可能为导致质量判断的语言和风格因素提供新的见解。

Abstract: AI "slop" is an increasingly popular term used to describe low-quality
AI-generated text, but there is currently no agreed upon definition of this
term nor a means to measure its occurrence. In this work, we develop a taxonomy
of "slop" through interviews with experts in NLP, writing, and philosophy, and
propose a set of interpretable dimensions for its assessment in text. Through
span-level annotation, we find that binary "slop" judgments are (somewhat)
subjective, but such determinations nonetheless correlate with latent
dimensions such as coherence and relevance. Our framework can be used to
evaluate AI-generated text in both detection and binary preference tasks,
potentially offering new insights into the linguistic and stylistic factors
that contribute to quality judgments.

</details>


### [51] [Soft Tokens, Hard Truths](https://arxiv.org/abs/2509.19170)
*Natasha Butt,Ariel Kwiatkowski,Ismail Labiad,Julia Kempe,Yann Ollivier*

Main category: cs.CL

TL;DR: 本文首次提出一种通过强化学习学习连续Chain-of-Thought（CoT）的方法，无需从参考离散CoT中蒸馏。实验表明，连续CoT在数学推理任务中表现优异，且能更好地保留基础模型在域外任务上的预测能力。


<details>
  <summary>Details</summary>
Motivation: 尽管理论研究表明连续token具有更高的表达能力和效率，但实际应用中由于训练困难，之前的文献要么仅在预训练离散token模型上使用连续token进行推理，要么必须从真实离散CoT中蒸馏连续CoT，导致计算成本高且CoT长度受限。

Method: 本文采用强化学习（RL）方法，引入“软”token：将多个token混合并加入输入嵌入的噪声以提供RL探索。这种方法计算开销小，可以学习数百个token的连续CoT。

Result: 在Llama和Qwen模型（最大8B参数）的数学推理基准测试中，使用连续CoT的训练在pass@1指标上与离散token CoT相当，并在pass@32指标上超越了它们，显示出更大的CoT多样性。此外，最佳性能场景是使用连续CoT进行训练，然后在推理时使用离散token，这意味着“软”模型可以以标准方式部署。

Conclusion: 本文提出了一种可扩展的方法，通过强化学习（RL）学习连续的CoT，而无需从参考离散CoT中蒸馏。实验结果表明，使用连续CoT在数学推理基准测试中与离散token CoT相当，甚至在某些情况下表现更好，同时能够更好地保留基础模型在域外任务上的预测能力。

Abstract: The use of continuous instead of discrete tokens during the Chain-of-Thought
(CoT) phase of reasoning LLMs has garnered attention recently, based on the
intuition that a continuous mixture of discrete tokens could simulate a
superposition of several reasoning paths simultaneously. Theoretical results
have formally proven that continuous tokens have much greater expressivity and
can solve specific problems more efficiently. However, practical use of
continuous tokens has been limited by strong training difficulties: previous
works either just use continuous tokens at inference time on a pre-trained
discrete-token model, or must distill the continuous CoT from ground-truth
discrete CoTs and face computational costs that limit the CoT to very few
tokens.
  This is the first work introducing a scalable method to learn continuous CoTs
via reinforcement learning (RL), without distilling from reference discrete
CoTs. We use "soft" tokens: mixtures of tokens together with noise on the input
embedding to provide RL exploration. Computational overhead is minimal,
enabling us to learn continuous CoTs with hundreds of tokens. On math reasoning
benchmarks with Llama and Qwen models up to 8B, training with continuous CoTs
match discrete-token CoTs for pass@1 and surpass them for pass@32, showing
greater CoT diversity. In systematic comparisons, the best-performing scenario
is to train with continuous CoT tokens then use discrete tokens for inference,
meaning the "soft" models can be deployed in a standard way. Finally, we show
continuous CoT RL training better preserves the predictions of the base model
on out-of-domain tasks, thus providing a softer touch to the base model.

</details>


### [52] [Online Process Reward Leanring for Agentic Reinforcement Learning](https://arxiv.org/abs/2509.19199)
*Xiaoqian Liu,Ke Wang,Yuchuan Wu,Fei Huang,Yongbin Li,Junge Zhang,Jianbin Jiao*

Main category: cs.CL

TL;DR: OPRL is a credit-assignment strategy for agentic RL that integrates seamlessly with standard on-policy algorithms. It optimizes an implicit process reward model (PRM) to transform trajectory preferences into implicit step rewards, which are used to compute step-level advantages. OPRL shows superior performance over frontier LLMs and strong RL baselines across domains, achieving state-of-the-art results with higher sample-efficiency and lower variance during training.


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) are increasingly trained with reinforcement learning (RL) as autonomous agents that reason and act over long horizons in interactive environments. However, sparse and sometimes unverifiable rewards make temporal credit assignment extremely challenging. Recent work attempts to integrate process supervision into agent learning but suffers from biased annotation, reward hacking, high-variance from overly fine-grained signals or failtures when state overlap is rare.

Method: We introduce Online Process Reward Learning (OPRL), a general credit-assignment strategy for agentic RL that integrates seamlessly with standard on-policy algorithms without relying on additional rollouts or explicit step labels. In OPRL, we optimize an implicit process reward model (PRM) alternately with the agent's policy to transform trajectory preferences into implicit step rewards through a trajectory-based DPO objective.

Result: Empirically, we evaluate OPRL on three distinct agent benchmarks, including WebShop and VisualSokoban, as well as open-ended social interactions with unverifiable rewards in SOTOPIA. Crucially, OPRL shows superior performance over frontier LLMs and strong RL baselines across domains, achieving state-of-the-art results with higher sample-efficiency and lower variance during training.

Conclusion: OPRL shows superior performance over frontier LLMs and strong RL baselines across domains, achieving state-of-the-art results with higher sample-efficiency and lower variance during training. Further analysis also demonstrates the efficient exploration by OPRL using fewer actions, underscoring its potential for agentic learning in real-world scenarios.

Abstract: Large language models (LLMs) are increasingly trained with reinforcement
learning (RL) as autonomous agents that reason and act over long horizons in
interactive environments.
  However, sparse and sometimes unverifiable rewards make temporal credit
assignment extremely challenging.
  Recent work attempts to integrate process supervision into agent learning but
suffers from biased annotation, reward hacking, high-variance from overly
fine-grained signals or failtures when state overlap is rare.
  We therefore introduce Online Process Reward Learning (OPRL), a general
credit-assignment strategy for agentic RL that integrates seamlessly with
standard on-policy algorithms without relying on additional rollouts or
explicit step labels.
  In OPRL, we optimize an implicit process reward model (PRM) alternately with
the agent's policy to transform trajectory preferences into implicit step
rewards through a trajectory-based DPO objective.
  These step rewards are then used to compute step-level advantages, which are
combined with episode-level advantages from outcome rewards for policy update,
creating a self-reinforcing loop.
  Theoretical findings guarantee that the learned step rewards are consistent
with trajectory preferences and act as potential-based shaping rewards,
providing bounded gradients to stabilize training.
  Empirically, we evaluate OPRL on three distinct agent benmarks, including
WebShop and VisualSokoban, as well as open-ended social interactions with
unverfiable rewards in SOTOPIA.
  Crucially, OPRL shows superior performance over frontier LLMs and strong RL
baselines across domains, achieving state-of-the-art results with higher
sample-efficiency and lower variance during training.
  Further analysis also demonstrates the efficient exploration by OPRL using
fewer actions, underscoring its potential for agentic learning in real-world
scenarios.

</details>


### [53] [Steering Multimodal Large Language Models Decoding for Context-Aware Safety](https://arxiv.org/abs/2509.19212)
*Zheyuan Liu,Zhangchen Xu,Guangyao Dou,Xiangchi Yuan,Zhaoxuan Tan,Radha Poovendran,Meng Jiang*

Main category: cs.CL

TL;DR: SafeCoDe is a new decoding framework that improves the safety of multimodal large language models by dynamically adjusting token generation based on multimodal context.


<details>
  <summary>Details</summary>
Motivation: Existing methods often fail to balance oversensitivity and undersensitivity, leaving a persistent gap in safety alignment.

Method: Safety-aware Contrastive Decoding (SafeCoDe), a lightweight and model-agnostic decoding framework that dynamically adjusts token generation based on multimodal context.

Result: Extensive experiments across diverse MLLM architectures and safety benchmarks show that SafeCoDe consistently improves context-sensitive refusal behaviors while preserving model helpfulness.

Conclusion: SafeCoDe consistently improves context-sensitive refusal behaviors while preserving model helpfulness.

Abstract: Multimodal Large Language Models (MLLMs) are increasingly deployed in
real-world applications, yet their ability to make context-aware safety
decisions remains limited. Existing methods often fail to balance
oversensitivity (unjustified refusals of benign queries) and undersensitivity
(missed detection of visually grounded risks), leaving a persistent gap in
safety alignment. To address this issue, we introduce Safety-aware Contrastive
Decoding (SafeCoDe), a lightweight and model-agnostic decoding framework that
dynamically adjusts token generation based on multimodal context. SafeCoDe
operates in two stages: (1) a contrastive decoding mechanism that highlights
tokens sensitive to visual context by contrasting real and Gaussian-noised
images, and (2) a global-aware token modulation strategy that integrates
scene-level reasoning with token-level adjustment to adapt refusals according
to the predicted safety verdict. Extensive experiments across diverse MLLM
architectures and safety benchmarks, covering undersensitivity,
oversensitivity, and general safety evaluations, show that SafeCoDe
consistently improves context-sensitive refusal behaviors while preserving
model helpfulness.

</details>


### [54] [Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction](https://arxiv.org/abs/2509.19224)
*Tariq Abdul-Quddoos,Xishuang Dong,Lijun Qian*

Main category: cs.CL

TL;DR: 本研究比较了多个预训练的基于注意力的模型在EHR信息提取任务中的表现，发现基于临床数据的模型在检测药物事件方面更有效，但Bert Base在分类药物事件上下文方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 为了开发有效的解决方案，从电子健康记录（EHR）中提取与患者药物事件相关的上下文信息，本研究对多个预训练模型进行了比较分析。

Method: 对预训练的基于注意力的模型（如Bert Base、BioBert、两种变体的Bio+Clinical Bert、RoBerta和Clinical Long- former）进行了比较分析，并在CMED数据集上进行了微调和应用，以执行药物提取、医疗事件检测和多维药物事件上下文分类。

Result: 基于临床数据预训练的模型在检测药物和药物事件方面表现更优，而Bert Base在分类药物相关事件的上下文方面效果最好。

Conclusion: 研究结果表明，基于临床数据预训练的模型在检测药物和药物事件方面更有效，但Bert Base在分类与药物相关的事件上下文方面表现最佳。

Abstract: Attention-based models have become the leading approach in modeling medical
language for Natural Language Processing (NLP) in clinical notes. These models
outperform traditional techniques by effectively capturing contextual rep-
resentations of language. In this research a comparative analysis is done
amongst pre- trained attention based models namely Bert Base, BioBert, two
variations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task
related to Electronic Health Record (EHR) information extraction. The tasks
from Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges
(n2c2) are considered for this comparison, with the Contextualized Medication
Event Dataset (CMED) given for these task. CMED is a dataset of unstructured
EHRs and annotated notes that contain task relevant information about the EHRs.
The goal of the challenge is to develop effective solutions for extracting
contextual information related to patient medication events from EHRs using
data driven methods. Each pre-trained model is fine-tuned and applied on CMED
to perform medication extraction, medical event detection, and
multi-dimensional medication event context classification. Pro- cessing methods
are also detailed for breaking down EHRs for compatibility with the applied
models. Performance analysis has been carried out using a script based on
constructing medical terms from the evaluation portion of CMED with metrics
including recall, precision, and F1-Score. The results demonstrate that models
pre-trained on clinical data are more effective in detecting medication and
medication events, but Bert Base, pre- trained on general domain data showed to
be the most effective for classifying the context of events related to
medications.

</details>


### [55] [CompLLM: Compression for Long Context Q&A](https://arxiv.org/abs/2509.19228)
*Gabriele Berton,Jayakrishnan Unnikrishnan,Son Tran,Mubarak Shah*

Main category: cs.CL

TL;DR: CompLLM is a soft compression technique that divides context into segments for efficient, scalable, and reusable compression, improving performance and reducing resource usage.


<details>
  <summary>Details</summary>
Motivation: Existing techniques for soft context compression have limitations in terms of compression complexity and reusability across queries with overlapping contexts.

Method: CompLLM divides the context into segments and compresses each one independently, which yields efficiency, scalability, and reusability.

Result: With a 2x compression rate, CompLLM speeds up Time To First Token (TTFT) by up to 4x and reduces the KV cache size by 50%, while achieving performance comparable to that obtained with the uncompressed context.

Conclusion: CompLLM achieves performance comparable to that obtained with the uncompressed context, and even surpasses it on very long sequences, demonstrating its effectiveness and practical utility.

Abstract: Large Language Models (LLMs) face significant computational challenges when
processing long contexts due to the quadratic complexity of self-attention.
While soft context compression methods, which map input text to smaller latent
representations, have shown promise, their real-world adoption is limited.
Existing techniques typically compress the context as a single unit, which
leads to quadratic compression complexity and an inability to reuse
computations across queries with overlapping contexts. In this work, we
introduce CompLLM, a soft compression technique designed for practical
deployment. Instead of processing the context holistically, CompLLM divides it
into segments and compresses each one independently. This simple design choice
yields three critical properties: efficiency, as the compression step scales
linearly with the context length; scalability, enabling models trained on short
sequences (e.g., 1k tokens) to generalize to contexts of 100k tokens; and
reusability, allowing compressed segments to be cached and reused across
different queries. Our experiments show that with a 2x compression rate, at
high context lengths CompLLM speeds up Time To First Token (TTFT) by up to 4x
and reduces the KV cache size by 50%. Furthermore, CompLLM achieves performance
comparable to that obtained with the uncompressed context, and even surpasses
it on very long sequences, demonstrating its effectiveness and practical
utility.

</details>


### [56] [Reinforcement Learning on Pre-Training Data](https://arxiv.org/abs/2509.19249)
*Siheng Li,Kejiao Li,Zenan Xu,Guanhua Huang,Evander Yang,Kun Li,Haoyuan Wu,Jiajia Wu,Zihao Zheng,Chenchen Zhang,Kun Shi,Kyrierl Deng,Qi Yi,Ruibin Xiong,Tingqiang Xu,Yuhao Jiang,Jianfeng Yan,Yuyuan Zeng,Guanghui Xu,Jinbao Xue,Zhijiang Xu,Zheng Fang,Shuai Li,Qibin Liu,Xiaoxue Li,Zhuoyu Li,Yangyu Tao,Fei Gao,Cheng Jiang,Bo Chao Wang,Kai Liu,Jianchen Zhu,Wai Lam,Wayyt Wang,Bo Zhou,Di Wang*

Main category: cs.CL

TL;DR: This paper introduces RLPT, a new training-time scaling paradigm for optimizing large language models (LLMs) by enabling the policy to autonomously explore meaningful trajectories to learn from pre-training data and improve its capability through reinforcement learning (RL).


<details>
  <summary>Details</summary>
Motivation: The growing disparity between the exponential scaling of computational resources and the finite growth of high-quality text data now constrains conventional scaling approaches for large language models (LLMs).

Method: RLPT is a new training-time scaling paradigm for optimizing LLMs. It enables the policy to autonomously explore meaningful trajectories to learn from pre-training data and improve its capability through reinforcement learning (RL).

Result: Extensive experiments on both general-domain and mathematical reasoning benchmarks across multiple models validate the effectiveness of RLPT. For example, when applied to Qwen3-4B-Base, RLPT yields absolute improvements of 3.0, 5.1, 8.1, 6.0, 6.6, and 5.3 on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and AIME25, respectively.

Conclusion: RLPT provides a solid foundation, extending the reasoning boundaries of LLMs and enhancing RLVR performance.

Abstract: The growing disparity between the exponential scaling of computational
resources and the finite growth of high-quality text data now constrains
conventional scaling approaches for large language models (LLMs). To address
this challenge, we introduce Reinforcement Learning on Pre-Training data
(RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast
to prior approaches that scale training primarily through supervised learning,
RLPT enables the policy to autonomously explore meaningful trajectories to
learn from pre-training data and improve its capability through reinforcement
learning (RL). While existing RL strategies such as reinforcement learning from
human feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR)
rely on human annotation for reward construction, RLPT eliminates this
dependency by deriving reward signals directly from pre-training data.
Specifically, it adopts a next-segment reasoning objective, rewarding the
policy for accurately predicting subsequent text segments conditioned on the
preceding context. This formulation allows RL to be scaled on pre-training
data, encouraging the exploration of richer trajectories across broader
contexts and thereby fostering more generalizable reasoning skills. Extensive
experiments on both general-domain and mathematical reasoning benchmarks across
multiple models validate the effectiveness of RLPT. For example, when applied
to Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$,
$6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and
AIME25, respectively. The results further demonstrate favorable scaling
behavior, suggesting strong potential for continued gains with more compute. In
addition, RLPT provides a solid foundation, extending the reasoning boundaries
of LLMs and enhancing RLVR performance.

</details>


### [57] [Extracting Conceptual Spaces from LLMs Using Prototype Embeddings](https://arxiv.org/abs/2509.19269)
*Nitesh Kumar,Usashi Chatterjee,Steven Schockaert*

Main category: cs.CL

TL;DR: 本文提出一种从大型语言模型中提取概念空间的策略，通过嵌入原型描述并微调模型以对齐概念空间维度，结果表明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 尽管最近的大型语言模型在捕捉感知特征方面表现出色，但目前缺乏有效的实用方法来提取对应的的概念空间。

Method: 本文提出通过嵌入对应原型的描述来编码特征（如甜度），并微调大型语言模型以对齐原型嵌入与概念空间维度。

Result: 实证分析表明，该方法非常有效。

Conclusion: 本文提出了一种从大型语言模型中提取概念空间的有效策略，通过微调模型使原型嵌入与概念空间维度对齐，从而更好地捕捉感知特征。

Abstract: Conceptual spaces represent entities and concepts using cognitively
meaningful dimensions, typically referring to perceptual features. Such
representations are widely used in cognitive science and have the potential to
serve as a cornerstone for explainable AI. Unfortunately, they have proven
notoriously difficult to learn, although recent LLMs appear to capture the
required perceptual features to a remarkable extent. Nonetheless, practical
methods for extracting the corresponding conceptual spaces are currently still
lacking. While various methods exist for extracting embeddings from LLMs,
extracting conceptual spaces also requires us to encode the underlying
features. In this paper, we propose a strategy in which features (e.g.
sweetness) are encoded by embedding the description of a corresponding
prototype (e.g. a very sweet food). To improve this strategy, we fine-tune the
LLM to align the prototype embeddings with the corresponding conceptual space
dimensions. Our empirical analysis finds this approach to be highly effective.

</details>


### [58] [SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data](https://arxiv.org/abs/2509.19270)
*Erik Božík,Marek Šuppa*

Main category: cs.CL

TL;DR: 本文介绍了SloPalSpeech数据集，用于改善低资源语言如斯洛伐克的自动语音识别，并通过微调模型显著降低了词错误率。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别（ASR）对于像斯洛伐克这样的低资源语言受到训练数据稀缺的阻碍。

Method: 开发了一个强大的处理管道，将长格式录音对齐和分割成适合模型训练的干净30秒音频-文本对。使用该数据集微调了多个OpenAI Whisper模型，并在标准斯洛伐克基准测试中取得了显著的词错误率（WER）降低。

Result: 微调后的Whisper-small模型的WER降低了高达70%，接近更大规模的Whisper-large-v3模型的基线性能。

Conclusion: SloPalSpeech数据集和微调模型的发布将促进低资源语音识别领域的未来研究。

Abstract: Automatic Speech Recognition (ASR) for low-resource languages like Slovak is
hindered by the scarcity of training data. To address this, we introduce
SloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of
speech from parliamentary proceedings. We developed a robust processing
pipeline to align and segment long-form recordings into clean, 30-second
audio-transcript pairs suitable for model training. We use this dataset to
fine-tune several OpenAI Whisper models (small, medium, large-v3, and
large-v3-turbo), achieving significant Word Error Rate (WER) reductions on
standard Slovak benchmarks like Common Voice and FLEURS. For instance, the
fine-tuned Whisper-small model's WER dropped by up to 70\%, approaching the
baseline performance of the much larger Whisper-large-v3 model. To foster
future research in low-resource speech recognition, we publicly release the
complete SloPalSpeech dataset, the fully segmented transcripts (60 million
words), and all our fine-tuned models.

</details>


### [59] [WolBanking77: Wolof Banking Speech Intent Classification Dataset](https://arxiv.org/abs/2509.19271)
*Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione*

Main category: cs.CL

TL;DR: 本文提出并介绍了用于学术研究的沃洛夫语意图分类数据集（WolBanking77），并在该数据集上进行了实验，结果表明其具有良好的前景。


<details>
  <summary>Details</summary>
Motivation: 由于之前的研究主要集中在高资源语言数据集上，导致低资源语言和识字率高的地区语言的意图分类模型存在差距。例如，在塞内加尔，沃洛夫语是90%人口使用的语言，但该国的识字率仅为42%。因此，需要一个专门针对沃洛夫语的意图分类数据集。

Method: 本文介绍了WolBanking77数据集的构建过程，包括文本句子和语音句子的收集，并对各种基线模型进行了实验，包括文本和语音的最先进模型。

Result: 在WolBanking77数据集上进行的实验结果非常有前景，本文还提供了对数据集内容的详细分析，并报告了NLP和ASR模型的基线F1分数和词错误率指标。

Conclusion: 本文提出了一个用于学术研究的沃洛夫语意图分类数据集（WolBanking77），并展示了在该数据集上的实验结果。同时，作者计划分享和维护该数据集，并发布开源代码。

Abstract: Intent classification models have made a lot of progress in recent years.
However, previous studies primarily focus on high-resource languages datasets,
which results in a gap for low-resource languages and for regions with a high
rate of illiterate people where languages are more spoken than read or written.
This is the case in Senegal, for example, where Wolof is spoken by around 90\%
of the population, with an illiteracy rate of 42\% for the country. Wolof is
actually spoken by more than 10 million people in West African region. To
tackle such limitations, we release a Wolof Intent Classification Dataset
(WolBanking77), for academic research in intent classification. WolBanking77
currently contains 9,791 text sentences in the banking domain and more than 4
hours of spoken sentences. Experiments on various baselines are conducted in
this work, including text and voice state-of-the-art models. The results are
very promising on this current dataset. This paper also provides detailed
analyses of the contents of the data. We report baseline f1-score and word
error rate metrics respectively on NLP and ASR models trained on WolBanking77
dataset and also comparisons between models. We plan to share and conduct
dataset maintenance, updates and to release open-source code.

</details>


### [60] [DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture](https://arxiv.org/abs/2509.19274)
*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Nemil Shah,Abhilekh Borah,Vanshika Shah,Nishant Mishra,Sriparna Saha*

Main category: cs.CL

TL;DR: DRISHTIKON is a new benchmark for evaluating the cultural understanding of AI systems, focusing on Indian culture with a multilingual and multimodal dataset.


<details>
  <summary>Details</summary>
Motivation: To evaluate the cultural understanding of generative AI systems, especially for Indian culture, which has been underrepresented in existing benchmarks.

Method: We evaluate a wide range of vision-language models (VLMs), including open-source small and large models, proprietary systems, reasoning-specialized VLMs, and Indic-focused models, across zero-shot and chain-of-thought settings.

Result: Our results expose key limitations in current models' ability to reason over culturally grounded, multimodal inputs, particularly for low-resource languages and less-documented traditions.

Conclusion: DRISHTIKON fills a vital gap in inclusive AI research, offering a robust testbed to advance culturally aware, multimodally competent language technologies.

Abstract: We introduce DRISHTIKON, a first-of-its-kind multimodal and multilingual
benchmark centered exclusively on Indian culture, designed to evaluate the
cultural understanding of generative AI systems. Unlike existing benchmarks
with a generic or global scope, DRISHTIKON offers deep, fine-grained coverage
across India's diverse regions, spanning 15 languages, covering all states and
union territories, and incorporating over 64,000 aligned text-image pairs. The
dataset captures rich cultural themes including festivals, attire, cuisines,
art forms, and historical heritage amongst many more. We evaluate a wide range
of vision-language models (VLMs), including open-source small and large models,
proprietary systems, reasoning-specialized VLMs, and Indic-focused models,
across zero-shot and chain-of-thought settings. Our results expose key
limitations in current models' ability to reason over culturally grounded,
multimodal inputs, particularly for low-resource languages and less-documented
traditions. DRISHTIKON fills a vital gap in inclusive AI research, offering a
robust testbed to advance culturally aware, multimodally competent language
technologies.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [61] [No Verifiable Reward for Prosody: Toward Preference-Guided Prosody Learning in TTS](https://arxiv.org/abs/2509.18531)
*Seungyoun Shin,Dongha Ahn,Jiwoo Kim,Sungwook Jeon*

Main category: eess.AS

TL;DR: 本文提出了一种迭代直接偏好优化（DPO）方案，用于优化文本转语音的韵律自然度，结果表明在无法自动奖励韵律的情况下，人类偏好优化是一种实用且数据高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有工作在神经文本转语音（TTS）中报告了组相对策略优化（GRPO）的进展。然而，在缺乏可验证的韵律奖励的情况下，GRPO在以转录为导向的信号（CER/NLL）上训练会降低错误率，但将韵律压缩成单调、不自然的语音；添加说话人相似性进一步使训练不稳定并降低CER。

Method: 提出了一种迭代直接偏好优化（DPO）方案，仅需每轮几百个人工标注的偏好对来直接优化韵律自然度，同时对当前模型进行正则化。

Result: 在KoCC-TTS数据集上，我们的方法在人类偏好（ELO）方面达到了最高水平，同时保持了竞争性的CER，优于GRPO和强大的商业基线。

Conclusion: 当无法自动奖励韵律时，人类偏好优化为自然且稳健的文本转语音提供了一条实用且数据高效的路径。

Abstract: Recent work reports gains in neural text-to-speech (TTS) with Group Relative
Policy Optimization (GRPO). However, in the absence of a verifiable reward for
\textit{prosody}, GRPO trained on transcription-oriented signals (CER/NLL)
lowers error rates yet collapses prosody into monotone, unnatural speech;
adding speaker-similarity further destabilizes training and degrades CER. We
address this with an \textit{iterative Direct Preference Optimization (DPO)}
scheme that uses only a few hundred human-labeled preference pairs per round to
directly optimize prosodic naturalness while regularizing to the current model.
On \textbf{KoCC-TTS}, a curated dataset of authentic Korean call center
interactions capturing task-oriented dialogues, our method attains the highest
human preference (ELO) with competitive CER, outperforming GRPO and strong
commercial baselines. These results suggest that when prosody cannot be
rewarded automatically, \textit{human preference optimization} offers a
practical and data-efficient path to natural and robust TTS. The demo page is
available at \href{https://tts.ch.dev}

</details>


### [62] [HarmoniFuse: A Component-Selective and Prompt-Adaptive Framework for Multi-Task Speech Language Modeling](https://arxiv.org/abs/2509.18570)
*Yuke Si,Runyan Yang,Yingying Gao,Junlan Feng,Chao Deng,Shilei Zhang*

Main category: eess.AS

TL;DR: 本文提出了一种名为HarmoniFuse的多任务语音语言建模框架，通过选择和融合语音表示中的任务相关组件来协调异构任务需求。该方法在自动语音识别（ASR）和语音情感识别（SER）任务中均表现出色，提供了一个在现实数据限制下可扩展且稳健的多任务语音理解解决方案。


<details>
  <summary>Details</summary>
Motivation: Existing multitask SLMs typically adopt naive parameter sharing or prompt-based conditioning without explicitly modeling the differences in information composition required by each task. Such designs risk task interference and performance degradation, especially under limited data conditions.

Method: HarmoniFuse is a component-selective and prompt-adaptive framework for multi-task speech language modeling. It harmonizes heterogeneous task demands by selecting and fusing task-relevant components of speech representations. It integrates a gated speech encoder to extract task-specific acoustic features and a prompt-adaptive dynamic fusion module to aggregate transformer layers based on task characteristics. Additionally, a batch-interleaved training strategy enables leveraging separate ASR and SER datasets without requiring joint annotation.

Result: Experimental results demonstrate that HarmoniFuse improves both ASR and SER performance, offering a scalable and robust solution for multitask speech understanding under realistic data constraints.

Conclusion: HarmoniFuse improves both ASR and SER performance, offering a scalable and robust solution for multitask speech understanding under realistic data constraints.

Abstract: Recent advances in large language models have facilitated the development of
unified speech language models (SLMs) capable of supporting multiple speech
tasks within a shared architecture. However, tasks such as automatic speech
recognition (ASR) and speech emotion recognition (SER) rely on distinct types
of information: ASR primarily depends on linguistic content, whereas SER
requires the integration of both linguistic and paralinguistic cues. Existing
multitask SLMs typically adopt naive parameter sharing or prompt-based
conditioning without explicitly modeling the differences in information
composition required by each task. Such designs risk task interference and
performance degradation, especially under limited data conditions. To address
these limitations, we propose HarmoniFuse, a component-selective and
prompt-adaptive framework for multi-task speech language modeling. HarmoniFuse
is designed to harmonize heterogeneous task demands by selecting and fusing
task-relevant components of speech representations. Specifically, it integrates
a gated speech encoder to extract task-specific acoustic features and a
prompt-adaptive dynamic fusion module to aggregate transformer layers based on
task characteristics. In addition, a batch-interleaved training strategy
enables leveraging separate ASR and SER datasets without requiring joint
annotation. Experimental results demonstrate that HarmoniFuse improves both ASR
and SER performance, offering a scalable and robust solution for multitask
speech understanding under realistic data constraints.

</details>


### [63] [Teaching Audio Models to Reason: A Unified Framework for Source- and Layer-wise Distillation](https://arxiv.org/abs/2509.18579)
*Runyan Yang,Yuke Si,Yingying Gao,Junlan Feng,Chao Deng,Shilei Zhang*

Main category: eess.AS

TL;DR: 本文提出了一种统一的知识蒸馏框架，用于将推理能力从文本教师模型转移到音频学生模型，以解决音频模型在复杂推理方面的不足。


<details>
  <summary>Details</summary>
Motivation: 大型音频语言模型在ASR和情感识别等任务中表现出色，但由于音频和文本之间的模态差距以及缺乏结构化的中间监督，它们在复杂推理方面仍然存在困难。

Method: 我们提出了一种统一的知识蒸馏框架，将推理能力从高容量的文本教师模型转移到学生音频模型，同时保留其声学能力。方法引入了两个关键维度：源级蒸馏，利用文本和声学教师提供互补的模态特定监督；层级蒸馏，将教师信号与适当的学生层对齐以提高传输效率。

Result: 实验结果表明，音频推理性能有显著提升，证明了框架作为音频建模推理传输解决方案的有效性。

Conclusion: 实验结果表明，我们的框架在音频推理性能上有了显著提升，证明了其作为音频建模推理传输解决方案的有效性。

Abstract: While large audio language models excel at tasks like ASR and emotion
recognition, they still struggle with complex reasoning due to the modality gap
between audio and text as well as the lack of structured intermediate
supervision. To address this, we propose a unified knowledge distillation
framework to transfer reasoning capabilities from a high-capacity textual
teacher model to a student audio models while preserving its acoustic
competence. Our method introduces two key dimensions: source-wise distillation,
which leverages both textual and acoustic teachers to provide complementary
modality-specific supervision; and layer-wise distillation, which aligns
teacher signals with appropriate student layers to improve transfer efficiency.
This dual-dimensional strategy enables fine-grained control over the
distillation process, effectively bridging the gap between symbolic reasoning
and speech representations. Experimental results show significant improvements
in audio reasoning performance, demonstrating the effectiveness of our
framework as a reasoning transfer solution for audio modeling.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [64] [Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR](https://arxiv.org/abs/2509.18174)
*Khalil Hennara,Muhammad Hreden,Mohamed Motasim Hamed,Ahmad Bastati,Zeina Aldallal,Sara Chrouf,Safwan AlModhayan*

Main category: cs.CV

TL;DR: 本文介绍了Baseer，一个专门针对阿拉伯文档OCR进行微调的视觉-语言模型。通过结合合成和现实世界文档的大规模数据集，Baseer使用解码器-only微调策略来适应预训练的MLLM。我们还提出了Misraj-DocOCR，一个高质量、专家验证的基准，用于严格评估阿拉伯OCR系统。实验结果表明，Baseer显著优于现有解决方案，实现了0.25的WER，并在该领域建立了新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯文档OCR仍然是一个具有挑战性的任务，由于该语言的连笔字、多样的字体、变音符号和从右到左的方向。虽然现代多模态大语言模型（MLLMs）已经提高了高资源语言的文档理解，但它们在阿拉伯语上的表现仍然有限。

Method: 我们引入了Baseer，这是一个专门针对阿拉伯文档OCR进行微调的视觉-语言模型。利用结合合成和现实世界文档的大规模数据集，Baseer使用解码器-only微调策略来适应预训练的MLLM，同时保留通用视觉特征。

Result: 我们的实验表明，Baseer显著优于现有的开源和商业解决方案，实现了0.25的WER，并在阿拉伯文档OCR领域建立了新的最先进水平。

Conclusion: 我们的结果突显了通用MLLM在特定领域适应的优势，并为像阿拉伯语这样形态丰富的语言的高精度OCR建立了强大的基准。

Abstract: Arabic document OCR remains a challenging task due to the language's cursive
script, diverse fonts, diacritics, and right-to-left orientation. While modern
Multimodal Large Language Models (MLLMs) have advanced document understanding
for high-resource languages, their performance on Arabic remains limited. In
this work, we introduce Baseer, a vision-language model fine- tuned
specifically for Arabic document OCR. Leveraging a large-scale dataset
combining synthetic and real-world documents, Baseer is trained using a
decoder-only fine-tuning strategy to adapt a pre-trained MLLM while preserving
general visual features. We also present Misraj-DocOCR, a high-quality,
expert-verified benchmark designed for rigorous evaluation of Arabic OCR
systems. Our experiments show that Baseer significantly outperforms existing
open-source and commercial solutions, achieving a WER of 0.25 and establishing
a new state-of-the-art in the domain of Arabic document OCR. Our results
highlight the benefits of domain-specific adaptation of general-purpose MLLMs
and establish a strong baseline for high-accuracy OCR on morphologically rich
languages like Arabic.

</details>


### [65] [OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation](https://arxiv.org/abs/2509.18600)
*Zhuoxiao Chen,Hongyang Yu,Ying Xu,Yadan Luo,Long Duong,Yuan-Fang Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为OraPO的框架，结合了基于FactScore的奖励机制FactS，以在有限预算下解决放射学报告生成任务。OraPO通过将失败的探索转换为直接偏好监督，实现了单阶段、仅RL的训练。FactS通过提取原子临床事实并检查与真实标签的蕴含关系，使学习基于诊断证据，产生密集且可解释的句子级奖励。该框架显著提高了学习效率，并在CheXpert Plus数据集上取得了新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的工作通常遵循规模驱动的范式，通过大规模配对语料库和大型骨干网络进行多阶段训练，使得管道高度依赖数据和计算资源。本文旨在在有限预算下解决RRG任务。

Method: OraPO通过将失败的GRPO探索转换为直接偏好监督，实现了单阶段、仅RL的训练。FactS通过提取原子临床事实并检查与真实标签的蕴含关系，使学习基于诊断证据，产生密集且可解释的句子级奖励。

Result: OraPO和FactS创建了一个紧凑且强大的框架，显著提高了学习效率，在临床挑战性病例中表现优异，并在CheXpert Plus数据集上取得了新的SOTA性能（F1为0.341），使用2-3个数量级更少的训练数据和小型基础VLM在普通硬件上实现。

Conclusion: OraPO和FactS共同创建了一个紧凑且强大的框架，显著提高了在临床挑战性病例中的学习效率，在CheXpert Plus数据集上取得了新的SOTA性能（F1为0.341），并且使用少量训练数据和小型基础VLM在普通硬件上实现了这一点。

Abstract: Radiology report generation (RRG) aims to automatically produce clinically
faithful reports from chest X-ray images. Prevailing work typically follows a
scale-driven paradigm, by multi-stage training over large paired corpora and
oversized backbones, making pipelines highly data- and compute-intensive. In
this paper, we propose Oracle-educated GRPO {OraPO) with a FactScore-based
reward (FactS) to tackle the RRG task under constrained budgets. OraPO enables
single-stage, RL-only training by converting failed GRPO explorations on rare
or difficult studies into direct preference supervision via a lightweight
oracle step. FactS grounds learning in diagnostic evidence by extracting atomic
clinical facts and checking entailment against ground-truth labels, yielding
dense, interpretable sentence-level rewards. Together, OraPO and FactS create a
compact and powerful framework that significantly improves learning efficiency
on clinically challenging cases, setting the new SOTA performance on the
CheXpert Plus dataset (0.341 in F1) with 2--3 orders of magnitude less training
data using a small base VLM on modest hardware.

</details>


### [66] [Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions](https://arxiv.org/abs/2509.18847)
*Junhao Su,Yuanliang Wan,Junwei Yang,Hengyu Shi,Tianyang Han,Junfeng Luo,Yurui Qiu*

Main category: cs.CV

TL;DR: 本文提出结构化反思方法，通过显式诊断和修复错误来提高工具调用的可靠性，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前自我反思实践依赖于启发式提示或单向推理，这在多轮交互中容易重复错误。需要一种更可靠的方法来诊断和修复错误。

Method: 提出结构化反思，将从错误到修复的路径转化为显式、可控和可训练的动作。结合DAPO和GSPO目标与针对工具使用的奖励方案，优化逐步策略：反思、调用、最终结果。

Result: 在BFCL v3和Tool-Reflection-Bench上的实验显示，多轮工具调用的成功率和错误恢复能力显著提高，冗余调用减少。

Conclusion: 使反思显式化并直接优化可以提高工具交互的可靠性，并为代理提供从失败中学习的可重复路径。

Abstract: Tool-augmented large language models (LLMs) are usually trained with
supervised imitation or coarse-grained reinforcement learning that optimizes
single tool calls. Current self-reflection practices rely on heuristic prompts
or one-way reasoning: the model is urged to 'think more' instead of learning
error diagnosis and repair. This is fragile in multi-turn interactions; after a
failure the model often repeats the same mistake. We propose structured
reflection, which turns the path from error to repair into an explicit,
controllable, and trainable action. The agent produces a short yet precise
reflection: it diagnoses the failure using evidence from the previous step and
then proposes a correct, executable follow-up call. For training we combine
DAPO and GSPO objectives with a reward scheme tailored to tool use, optimizing
the stepwise strategy Reflect, then Call, then Final. To evaluate, we introduce
Tool-Reflection-Bench, a lightweight benchmark that programmatically checks
structural validity, executability, parameter correctness, and result
consistency. Tasks are built as mini trajectories of erroneous call,
reflection, and corrected call, with disjoint train and test splits.
Experiments on BFCL v3 and Tool-Reflection-Bench show large gains in multi-turn
tool-call success and error recovery, and a reduction of redundant calls. These
results indicate that making reflection explicit and optimizing it directly
improves the reliability of tool interaction and offers a reproducible path for
agents to learn from failure.

</details>


### [67] [VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction](https://arxiv.org/abs/2509.19002)
*Hao Wang,Eiki Murata,Lingfang Zhang,Ayako Sato,So Fukuda,Ziqi Yin,Wentao Hu,Keisuke Nakao,Yusuke Nakamura,Sebastian Zwirner,Yi-Chia Chen,Hiroyuki Otomo,Hiroki Ouchi,Daisuke Kawahara*

Main category: cs.CV

TL;DR: The paper introduces VIR-Bench, a new benchmark for evaluating MLLMs' geospatial-temporal intelligence through travel videos, highlighting the challenges of long-distance travel and demonstrating the effectiveness of the benchmark in improving real-world applications.


<details>
  <summary>Details</summary>
Motivation: Current video benchmarks focus largely on indoor scenes or short-range outdoor activities, leaving the challenges associated with long-distance travel largely unexplored. Mastering extended geospatial-temporal trajectories is critical for next-generation MLLMs.

Method: The paper presents VIR-Bench, a novel benchmark consisting of 200 travel videos that frames itinerary reconstruction as a challenging task to evaluate and push forward MLLMs' geospatial-temporal intelligence.

Result: Experimental results reveal that state-of-the-art MLLMs, including proprietary ones, struggle to achieve high scores, underscoring the difficulty of handling videos that span extended spatial and temporal scales. Moreover, a prototype travel-planning agent leveraging insights from VIR-Bench shows markedly improved itinerary recommendations.

Conclusion: VIR-Bench not only effectively benchmarks models but also translates into concrete performance gains in user-facing applications.

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly enhanced video understanding capabilities, opening new
possibilities for practical applications. Yet current video benchmarks focus
largely on indoor scenes or short-range outdoor activities, leaving the
challenges associated with long-distance travel largely unexplored. Mastering
extended geospatial-temporal trajectories is critical for next-generation
MLLMs, underpinning real-world tasks such as embodied-AI planning and
navigation. To bridge this gap, we present VIR-Bench, a novel benchmark
consisting of 200 travel videos that frames itinerary reconstruction as a
challenging task designed to evaluate and push forward MLLMs'
geospatial-temporal intelligence. Experimental results reveal that
state-of-the-art MLLMs, including proprietary ones, struggle to achieve high
scores, underscoring the difficulty of handling videos that span extended
spatial and temporal scales. Moreover, we conduct an in-depth case study in
which we develop a prototype travel-planning agent that leverages the insights
gained from VIR-Bench. The agent's markedly improved itinerary recommendations
verify that our evaluation protocol not only benchmarks models effectively but
also translates into concrete performance gains in user-facing applications.

</details>


### [68] [ColorBlindnessEval: Can Vision-Language Models Pass Color Blindness Tests?](https://arxiv.org/abs/2509.19070)
*Zijian Ling,Han Zhang,Yazhuo Zhou,Jiahao Cui*

Main category: cs.CV

TL;DR: 本文提出了ColorBlindnessEval，这是一个新的基准，用于评估视觉-语言模型（VLMs）在视觉对抗场景中的鲁棒性。实验结果揭示了模型在对抗性上下文中解释数字的能力有限，突显了普遍的幻觉问题。这些发现强调了提高VLMs在复杂视觉环境中的鲁棒性的必要性。ColorBlindnessEval作为评估和提高VLMs在实际应用中可靠性的工具具有重要价值。


<details>
  <summary>Details</summary>
Motivation: 本文旨在评估视觉-语言模型（VLMs）在视觉对抗场景中的鲁棒性，特别是在类似Ishihara色盲测试的场景中。通过提出一个新的基准ColorBlindnessEval，本文希望揭示模型在对抗性上下文中解释数字的能力有限，并强调提高VLMs在复杂视觉环境中的鲁棒性的必要性。

Method: 本文提出了ColorBlindnessEval，这是一个新的基准，用于评估视觉-语言模型（VLMs）在视觉对抗场景中的鲁棒性。我们的数据集包含500张类似Ishihara的图像，其中包含从0到99的数字，颜色组合各不相同，挑战VLMs准确识别嵌入在复杂视觉模式中的数字信息。我们使用是/否提示和开放式提示评估9个VLMs，并与人类参与者进行比较。

Result: 我们的实验揭示了模型在对抗性上下文中解释数字的能力有限，突显了普遍的幻觉问题。这些发现强调了提高VLMs在复杂视觉环境中的鲁棒性的必要性。ColorBlindnessEval作为评估和提高VLMs在实际应用中可靠性的工具具有重要价值。

Conclusion: 本文提出了ColorBlindnessEval，这是一个新的基准，用于评估视觉-语言模型（VLMs）在视觉对抗场景中的鲁棒性。实验结果揭示了模型在对抗性上下文中解释数字的能力有限，突显了普遍的幻觉问题。这些发现强调了提高VLMs在复杂视觉环境中的鲁棒性的必要性。ColorBlindnessEval作为评估和提高VLMs在实际应用中可靠性的工具具有重要价值。

Abstract: This paper presents ColorBlindnessEval, a novel benchmark designed to
evaluate the robustness of Vision-Language Models (VLMs) in visually
adversarial scenarios inspired by the Ishihara color blindness test. Our
dataset comprises 500 Ishihara-like images featuring numbers from 0 to 99 with
varying color combinations, challenging VLMs to accurately recognize numerical
information embedded in complex visual patterns. We assess 9 VLMs using Yes/No
and open-ended prompts and compare their performance with human participants.
Our experiments reveal limitations in the models' ability to interpret numbers
in adversarial contexts, highlighting prevalent hallucination issues. These
findings underscore the need to improve the robustness of VLMs in complex
visual environments. ColorBlindnessEval serves as a valuable tool for
benchmarking and improving the reliability of VLMs in real-world applications
where accuracy is critical.

</details>


### [69] [Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning](https://arxiv.org/abs/2509.19090)
*Guoxin Wang,Jun Zhao,Xinyi Liu,Yanbo Liu,Xuyang Cao,Chao Li,Zhuoyun Liu,Qintian Sun,Fangru Zhou,Haoqiang Xing,Zhenhong Yang*

Main category: cs.CV

TL;DR: Citrus-V是一个多模态医学基础模型，结合了图像分析和文本推理，实现了像素级病变定位、结构化报告生成和类似医生的诊断推理，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有成像模型过于狭窄，需要多个专门的网络，限制了它们的泛化能力。而现实世界的临床应用需要精确的视觉定位、多模态集成和链式思维推理。

Method: 提出了一种新颖的多模态训练方法，并发布了一个经过筛选的开源数据集，涵盖推理、检测、分割和文档理解任务。

Result: Citrus-V结合了图像分析和文本推理，实现了像素级病变定位、结构化报告生成和类似医生的诊断推理。

Conclusion: Citrus-V在多个基准测试中表现出色，超越了现有的开源医学模型和专家级成像系统，提供了一个从视觉定位到临床推理的统一流程，并支持精确的病变量化、自动报告和可靠的第二意见。

Abstract: Medical imaging provides critical evidence for clinical diagnosis, treatment
planning, and surgical decisions, yet most existing imaging models are narrowly
focused and require multiple specialized networks, limiting their
generalization. Although large-scale language and multimodal models exhibit
strong reasoning and multi-task capabilities, real-world clinical applications
demand precise visual grounding, multimodal integration, and chain-of-thought
reasoning. We introduce Citrus-V, a multimodal medical foundation model that
combines image analysis with textual reasoning. The model integrates detection,
segmentation, and multimodal chain-of-thought reasoning, enabling pixel-level
lesion localization, structured report generation, and physician-like
diagnostic inference in a single framework. We propose a novel multimodal
training approach and release a curated open-source data suite covering
reasoning, detection, segmentation, and document understanding tasks.
Evaluations demonstrate that Citrus-V outperforms existing open-source medical
models and expert-level imaging systems across multiple benchmarks, delivering
a unified pipeline from visual grounding to clinical reasoning and supporting
precise lesion quantification, automated reporting, and reliable second
opinions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [70] [The Illusion of Readiness: Stress Testing Large Frontier Models on Multimodal Medical Benchmarks](https://arxiv.org/abs/2509.18234)
*Yu Gu,Jingjing Fu,Xiaodong Liu,Jeya Maria Jose Valanarasu,Noel Codella,Reuben Tan,Qianchu Liu,Ying Jin,Sheng Zhang,Jinyu Wang,Rui Wang,Lei Song,Guanghui Qin,Naoto Usuyama,Cliff Wong,Cheng Hao,Hohin Lee,Praneeth Sanapathi,Sarah Hilado,Bian Jiang,Javier Alvarez-Valle,Mu Wei,Jianfeng Gao,Eric Horvitz,Matt Lungren,Hoifung Poon,Paul Vozila*

Main category: cs.AI

TL;DR: 大型前沿模型在医疗基准测试中表现优异，但它们在面对输入变化时表现出脆弱性，且可能依赖应试技巧而非真正的医学理解。


<details>
  <summary>Details</summary>
Motivation: 当前的医疗基准测试可能奖励应试技巧而非真正的医学理解，这可能导致人工智能系统在现实世界中的表现不佳。

Method: 评估六种旗舰模型在六个广泛使用的基准测试中的表现，并通过临床医生指导的评分标准评估这些基准测试真正衡量的内容。

Result: 高排行榜分数隐藏了脆弱性和捷径学习，基准测试在衡量内容上存在很大差异，但被当作可互换的工具使用，掩盖了失败模式。

Conclusion: 医疗基准测试分数并不能直接反映现实世界的准备情况。如果希望人工智能在医疗保健中获得信任，我们需要的不仅仅是排行榜上的胜利，还需要对系统的鲁棒性、合理的推理和与真实医疗需求的一致性进行问责。

Abstract: Large frontier models like GPT-5 now achieve top scores on medical
benchmarks. But our stress tests tell a different story. Leading systems often
guess correctly even when key inputs like images are removed, flip answers
under trivial prompt changes, and fabricate convincing yet flawed reasoning.
These aren't glitches; they expose how today's benchmarks reward test-taking
tricks over medical understanding. We evaluate six flagship models across six
widely used benchmarks and find that high leaderboard scores hide brittleness
and shortcut learning. Through clinician-guided rubric evaluation, we show that
benchmarks vary widely in what they truly measure yet are treated
interchangeably, masking failure modes. We caution that medical benchmark
scores do not directly reflect real-world readiness. If we want AI to earn
trust in healthcare, we must demand more than leaderboard wins and must hold
systems accountable for robustness, sound reasoning, and alignment with real
medical demands.

</details>


### [71] [Memory-QA: Answering Recall Questions Based on Multimodal Memories](https://arxiv.org/abs/2509.18436)
*Hongda Jiang,Xinyuan Zhang,Siddhant Garg,Rishab Arora,Shiun-Zu Kuo,Jiayang Xu,Christopher Brossman,Yue Liu,Aaron Colak,Ahmed Aly,Anuj Kumar,Xin Luna Dong*

Main category: cs.AI

TL;DR: The paper introduces Memory-QA, a real-world task for answering recall questions about visual content from multimodal memories. It proposes Pensieve, a pipeline that addresses the challenges of this task and demonstrates superior performance over existing methods.


<details>
  <summary>Details</summary>
Motivation: The Memory-QA task poses unique challenges in creating task-oriented memories, utilizing temporal and location information, and drawing upon multiple memories to answer recall questions.

Method: Pensieve integrates memory-specific augmentation, time- and location-aware multi-signal retrieval, and multi-memory QA fine-tuning.

Result: Pensieve shows superior performance over state-of-the-art solutions, with up to 14% improvement in QA accuracy.

Conclusion: Pensieve outperforms state-of-the-art solutions in the Memory-QA task.

Abstract: We introduce Memory-QA, a novel real-world task that involves answering
recall questions about visual content from previously stored multimodal
memories. This task poses unique challenges, including the creation of
task-oriented memories, the effective utilization of temporal and location
information within memories, and the ability to draw upon multiple memories to
answer a recall question. To address these challenges, we propose a
comprehensive pipeline, Pensieve, integrating memory-specific augmentation,
time- and location-aware multi-signal retrieval, and multi-memory QA
fine-tuning. We created a multimodal benchmark to illustrate various real
challenges in this task, and show the superior performance of Pensieve over
state-of-the-art solutions (up to 14% on QA accuracy).

</details>


### [72] [Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World](https://arxiv.org/abs/2509.19265)
*Saeed Almheiri,Rania Hossam,Mena Attia,Chenxi Wang,Preslav Nakov,Timothy Baldwin,Fajri Koto*

Main category: cs.AI

TL;DR: 本文研究了阿拉伯世界中的常识推理跨文化转移，发现通过少量文化特定示例可以显著提高多语言模型在其他地区的性能，并且跨文化演示在某些情况下可以与同文化对齐相媲美。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）通常反映西方中心的偏见，限制了它们在多样化文化背景中的有效性。虽然一些工作已经探索了文化对齐，但利用一种文化的对齐来提高其他文化性能的跨文化转移潜力仍然研究不足。

Method: 本文使用了一个涵盖13个阿拉伯国家的文化基础常识推理数据集，评估了轻量级对齐方法，如上下文学习和基于演示的强化（DITTO），以及监督微调和直接偏好优化等基线方法。

Result: 结果表明，仅需一个国家的12个文化特定示例，就可以在多语言模型中平均提高其他地区的性能10%。此外，我们证明了来自印尼和美国背景的跨文化演示可以与同文化对齐相媲美或超越，突显了超出阿拉伯世界的文化常识可迁移性。

Conclusion: 本文表明，高效的跨文化对齐是可能的，并为适应低资源文化环境中的大型语言模型提供了一种有前景的方法。

Abstract: Large language models (LLMs) often reflect Western-centric biases, limiting
their effectiveness in diverse cultural contexts. Although some work has
explored cultural alignment, the potential for cross-cultural transfer, using
alignment in one culture to improve performance in others, remains
underexplored. This paper investigates cross-cultural transfer of commonsense
reasoning in the Arab world, where linguistic and historical similarities
coexist with local cultural differences. Using a culturally grounded
commonsense reasoning dataset covering 13 Arab countries, we evaluate
lightweight alignment methods such as in-context learning and
demonstration-based reinforcement (DITTO), alongside baselines like supervised
fine-tuning and direct preference optimization. Our results show that merely 12
culture-specific examples from one country can improve performance in others by
10\% on average, within multilingual models. In addition, we demonstrate that
out-of-culture demonstrations from Indonesia and US contexts can match or
surpass in-culture alignment for MCQ reasoning, highlighting cultural
commonsense transferability beyond the Arab world. These findings demonstrate
that efficient cross-cultural alignment is possible and offer a promising
approach to adapt LLMs to low-resource cultural settings.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [73] [Agentic AutoSurvey: Let LLMs Survey LLMs](https://arxiv.org/abs/2509.18661)
*Yixin Liu,Yonghui Wu,Denghui Zhang,Lichao Sun*

Main category: cs.IR

TL;DR: 本文提出了一种多智能体框架Agentic AutoSurvey，用于自动化文献综述生成，通过四个专业代理协同工作，提高了文献综述的质量和覆盖范围。实验结果表明，该方法在多个研究主题上优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 科学文献的指数级增长给研究人员在快速发展的领域中综合知识带来了前所未有的挑战。现有的方法存在根本性的局限性，因此需要一种更有效的自动化文献综述生成方法。

Method: 我们提出了Agentic AutoSurvey，这是一个多智能体框架，用于自动化调查生成，通过四个专业代理（论文搜索专家、主题挖掘与聚类、学术调查撰写者和质量评估者）协同工作，生成全面的文献调查。

Result: 在COLM 2024类别中的六个代表性LLM研究主题上进行的实验表明，我们的多智能体方法相比现有基线有显著改进，得分8.18/10，而AutoSurvey得分为4.77/10。多智能体架构每主题处理75-443篇论文（六个主题共847篇），通过专门的代理协调实现高引用覆盖率（通常在75-100篇论文集上≥80%；在非常大的集合如RLHF上较低）。

Conclusion: 这些发现表明，多智能体架构在快速发展的科学领域中自动文献综述生成方面代表了重要的进步。

Abstract: The exponential growth of scientific literature poses unprecedented
challenges for researchers attempting to synthesize knowledge across rapidly
evolving fields. We present \textbf{Agentic AutoSurvey}, a multi-agent
framework for automated survey generation that addresses fundamental
limitations in existing approaches. Our system employs four specialized agents
(Paper Search Specialist, Topic Mining \& Clustering, Academic Survey Writer,
and Quality Evaluator) working in concert to generate comprehensive literature
surveys with superior synthesis quality. Through experiments on six
representative LLM research topics from COLM 2024 categories, we demonstrate
that our multi-agent approach achieves significant improvements over existing
baselines, scoring 8.18/10 compared to AutoSurvey's 4.77/10. The multi-agent
architecture processes 75--443 papers per topic (847 total across six topics)
while targeting high citation coverage (often $\geq$80\% on 75--100-paper sets;
lower on very large sets such as RLHF) through specialized agent orchestration.
Our 12-dimension evaluation captures organization, synthesis integration, and
critical analysis beyond basic metrics. These findings demonstrate that
multi-agent architectures represent a meaningful advancement for automated
literature survey generation in rapidly evolving scientific domains.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [74] [Safe-SAIL: Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework](https://arxiv.org/abs/2509.18127)
*Jiaqi Weng,Han Zheng,Hanyu Zhang,Qinqin He,Jialing Tao,Hui Xue,Zhixuan Chu,Xiting Wang*

Main category: cs.LG

TL;DR: 本文提出了一种名为Safe-SAIL的框架，用于在大型语言模型中解释稀疏自编码器（SAE）特征，以推进安全领域中的机制理解。该方法系统地识别具有最佳概念特定可解释性的SAE，解释与安全相关的神经元，并引入高效的策略来扩大解释过程。我们还将发布一个全面的工具包，包括SAE检查点和人类可读的神经元解释，以支持对安全风险的实证分析。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在现实世界应用中的部署增加，安全问题变得越来越重要。然而，现有的安全研究主要集中在评估LLM输出或特定的安全任务上，这限制了它们处理更广泛、未定义的风险的能力。因此，需要一种能够提取丰富且多样的与安全相关的特征的方法，以有效捕捉这些高风险行为。

Method: 本文提出了一种名为Safe-SAIL的框架，用于在大型语言模型中解释稀疏自编码器（SAE）特征，以推进安全领域中的机制理解。该方法系统地识别具有最佳概念特定可解释性的SAE，解释与安全相关的神经元，并引入高效的策略来扩大解释过程。

Result: 本文提出了Safe-SAIL框架，能够系统地识别具有最佳概念特定可解释性的SAE，并解释与安全相关的神经元。此外，还引入了高效的策略来扩大解释过程。我们还将发布一个全面的工具包，包括SAE检查点和人类可读的神经元解释，以支持对安全风险的实证分析。

Conclusion: 本文提出了Safe-SAIL框架，以提高大型语言模型在安全领域的机制理解。同时，我们将发布一个全面的工具包，以促进对LLM安全的研究。

Abstract: Increasing deployment of large language models (LLMs) in real-world
applications raises significant safety concerns. Most existing safety research
focuses on evaluating LLM outputs or specific safety tasks, limiting their
ability to ad- dress broader, undefined risks. Sparse Autoencoders (SAEs)
facilitate interpretability research to clarify model behavior by explaining
single-meaning atomic features decomposed from entangled signals. jHowever,
prior applications on SAEs do not interpret features with fine-grained
safety-related con- cepts, thus inadequately addressing safety-critical
behaviors, such as generating toxic responses and violating safety regu-
lations. For rigorous safety analysis, we must extract a rich and diverse set
of safety-relevant features that effectively capture these high-risk behaviors,
yet face two challenges: identifying SAEs with the greatest potential for
generating safety concept-specific neurons, and the prohibitively high cost of
detailed feature explanation. In this paper, we pro- pose Safe-SAIL, a
framework for interpreting SAE features within LLMs to advance mechanistic
understanding in safety domains. Our approach systematically identifies SAE
with best concept-specific interpretability, explains safety-related neurons,
and introduces efficient strategies to scale up the in- terpretation process.
We will release a comprehensive toolkit including SAE checkpoints and
human-readable neuron ex- planations, which supports empirical analysis of
safety risks to promote research on LLM safety.

</details>


### [75] [PiMoE: Token-Level Routing for Integrating High-Precision Computation and Reasoning](https://arxiv.org/abs/2509.18169)
*Hengbo Xiao,Jingyuan Fan,Xin Tong,Jingzhao Zhang,Chao Lu,Guannan He*

Main category: cs.LG

TL;DR: PiMoE is a new architecture that integrates computation and reasoning into LLMs, offering improved efficiency, interpretability, and scalability for complex systems.


<details>
  <summary>Details</summary>
Motivation: Current large language models (LLMs) cannot incorporate high-precision numerical computation as an intrinsic and interpretable capability. Mainstream multi-agent approaches introduce communication overhead and suffer from inefficiency and limited scalability.

Method: PiMoE (Physically-isolated Mixture of Experts) is a training and inference architecture that integrates computation and reasoning by endogenously incorporating computational capabilities into neural networks after separately training experts, a text-to-computation module, and a router.

Result: PiMoE achieves higher accuracy than directly fine-tuning LLMs and shows significant improvements in response latency, token usage, and GPU energy consumption compared to mainstream multi-agent approaches.

Conclusion: PiMoE offers an efficient, interpretable, and scalable paradigm for next-generation scientific or industrial intelligent systems.

Abstract: Complex systems typically rely on high-precision numerical computation to
support decisions, but current large language models (LLMs) cannot yet
incorporate such computations as an intrinsic and interpretable capability with
existing architectures. Mainstream multi-agent approaches can leverage external
experts, but inevitably introduce communication overhead and suffer from
inefficient multimodal emergent capability and limited scalability. To this
end, we propose PiMoE (Physically-isolated Mixture of Experts), a training and
inference architecture for integrating computation and reasoning. Instead of
the workflow paradigm of tool invocation, PiMoE endogenously integrates
computational capabilities into neural networks after separately training
experts, a text-to-computation module, and a router. At inference, the router
directs computation and reasoning at the token level, thereby enabling
iterative alternation within a single chain of thought. We evaluate PiMoE on
two reasoning-computation tasks against LLM finetuning and the multi-agent
system approaches. Results show that the PiMoE architecture achieves not only
higher accuracy than directly finetuning LLMs but also significant improvements
in response latency, token usage, and GPU energy consumption compared with
mainstream multi-agent approaches. PiMoE offers an efficient, interpretable,
and scalable paradigm for next-generation scientific or industrial intelligent
systems.

</details>


### [76] [TurnBack: A Geospatial Route Cognition Benchmark for Large Language Models through Reverse Route](https://arxiv.org/abs/2509.18173)
*Hongyi Luo,Qing Cheng,Daniel Matos,Hari Krishna Gadi,Yanfeng Zhang,Lu Liu,Yongliang Wang,Niclas Zeller,Daniel Cremers,Liqiu Meng*

Main category: cs.LG

TL;DR: This paper proposes a large-scale benchmark and conducts a comprehensive evaluation of the geospatial route cognition of Large Language Models (LLMs). It introduces a novel tool called PathBuilder for converting natural language instructions into navigation routes and vice versa, along with a new evaluation framework and metrics to assess 11 state-of-the-art LLMs on the task of route reversal.


<details>
  <summary>Details</summary>
Motivation: Prior research in this domain has been constrained by non-quantifiable metrics, limited evaluation datasets and unclear research hierarchies.

Method: We create a large-scale evaluation dataset comprised of 36000 routes from 12 metropolises worldwide. Then, we introduce PathBuilder, a novel tool for converting natural language instructions into navigation routes, and vice versa. Finally, we propose a new evaluation framework and metrics to rigorously assess 11 state-of-the-art (SOTA) LLMs on the task of route reversal.

Result: The benchmark reveals that LLMs exhibit limitation to reverse routes: most reverse routes neither return to the starting point nor are similar to the optimal route.

Conclusion: LLMs exhibit limitations in reversing routes and face challenges such as low robustness in route generation and high confidence for their incorrect answers.

Abstract: Humans can interpret geospatial information through natural language, while
the geospatial cognition capabilities of Large Language Models (LLMs) remain
underexplored. Prior research in this domain has been constrained by
non-quantifiable metrics, limited evaluation datasets and unclear research
hierarchies. Therefore, we propose a large-scale benchmark and conduct a
comprehensive evaluation of the geospatial route cognition of LLMs. We create a
large-scale evaluation dataset comprised of 36000 routes from 12 metropolises
worldwide. Then, we introduce PathBuilder, a novel tool for converting natural
language instructions into navigation routes, and vice versa, bridging the gap
between geospatial information and natural language. Finally, we propose a new
evaluation framework and metrics to rigorously assess 11 state-of-the-art
(SOTA) LLMs on the task of route reversal. The benchmark reveals that LLMs
exhibit limitation to reverse routes: most reverse routes neither return to the
starting point nor are similar to the optimal route. Additionally, LLMs face
challenges such as low robustness in route generation and high confidence for
their incorrect answers. Code\ \&\ Data available here:
\href{https://github.com/bghjmn32/EMNLP2025_Turnback}{TurnBack.}

</details>


### [77] [Conversational Orientation Reasoning: Egocentric-to-Allocentric Navigation with Multimodal Chain-of-Thought](https://arxiv.org/abs/2509.18200)
*Yu Ti Huang*

Main category: cs.LG

TL;DR: 本文介绍了用于传统中文对话导航的新基准COR，以及一个结合ASR转录语音与地标坐标的多模态链式思维框架MCoT。MCoT在各种条件下表现出色，展示了结构化多模态推理在资源高效具身导航中的潜力。


<details>
  <summary>Details</summary>
Motivation: 对话代理必须将自我中心的陈述（如“在我的右边”）转换为分配中心的方向（北/东/南/西）。这一挑战在室内或复杂设施中尤其关键，因为GPS信号弱且缺乏详细地图。虽然链式思维（CoT）提示已在语言和视觉任务中推进了推理，但其在多模态空间方向中的应用仍研究不足。

Method: 我们提出了一个多模态链式思维（MCoT）框架，该框架通过结构化的三步推理过程整合ASR转录语音与地标坐标：(1) 提取空间关系，(2) 将坐标映射到绝对方向，(3) 推断用户方向。此外，还采用了课程学习策略，在资源受限的设置中逐步构建这些能力。

Result: 实验表明，MCoT在干净的转录文本上实现了100%的方向准确性，在ASR转录文本上实现了98.1%，显著优于单模态和非结构基线。此外，MCoT在嘈杂的对话条件下表现出稳健性，包括ASR识别错误和多语言代码切换。模型还在跨领域评估中保持高准确性，并对语言变化、领域转移和参照歧义具有韧性。

Conclusion: 这些发现突显了结构化多模态链式思维空间推理在可解释和资源高效具身导航方面的潜力。

Abstract: Conversational agents must translate egocentric utterances (e.g., "on my
right") into allocentric orientations (N/E/S/W). This challenge is particularly
critical in indoor or complex facilities where GPS signals are weak and
detailed maps are unavailable. While chain-of-thought (CoT) prompting has
advanced reasoning in language and vision tasks, its application to multimodal
spatial orientation remains underexplored. We introduce Conversational
Orientation Reasoning (COR), a new benchmark designed for Traditional Chinese
conversational navigation projected from real-world environments, addressing
egocentric-to-allocentric reasoning in non-English and ASR-transcribed
scenarios. We propose a multimodal chain-of-thought (MCoT) framework, which
integrates ASR-transcribed speech with landmark coordinates through a
structured three-step reasoning process: (1) extracting spatial relations, (2)
mapping coordinates to absolute directions, and (3) inferring user orientation.
A curriculum learning strategy progressively builds these capabilities on
Taiwan-LLM-13B-v2.0-Chat, a mid-sized model representative of
resource-constrained settings. Experiments show that MCoT achieves 100%
orientation accuracy on clean transcripts and 98.1% with ASR transcripts,
substantially outperforming unimodal and non-structured baselines. Moreover,
MCoT demonstrates robustness under noisy conversational conditions, including
ASR recognition errors and multilingual code-switching. The model also
maintains high accuracy in cross-domain evaluation and resilience to linguistic
variation, domain shift, and referential ambiguity. These findings highlight
the potential of structured MCoT spatial reasoning as a path toward
interpretable and resource-efficient embodied navigation.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [78] [Pay More Attention To Audio: Mitigating Imbalance of Cross-Modal Attention in Large Audio Language Models](https://arxiv.org/abs/2509.18816)
*Junyu Wang,Ziyang Ma,Zhengding Luo,Tianrui Wang,Meng Ge,Xiaobao Wang,Longbiao Wang*

Main category: cs.SD

TL;DR: 本文提出了一种名为MATA的新方法，用于解决大型音频语言模型中的音频-文本注意力不平衡问题，通过在自注意力机制中动态地增加对音频标记的关注度，从而提高模型在音频推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 大型音频语言模型（LALMs）常常受到音频-文本注意力不平衡的影响，优先考虑文本而不是声学信息，这阻碍了它们充分利用声学线索，导致在音频推理任务上的表现不佳。

Method: 我们提出了MATA，这是一种无需训练的方法，在自注意力机制中动态地让大型音频语言模型更多地关注音频标记。

Result: 在MMAU和MMAR基准测试上的实验确认了MATA的有效性，表现出一致的性能提升。值得注意的是，在MMAR上，MATA使一个开源模型首次超越了专有的Gemini 2.0 Flash。

Conclusion: 我们的工作提供了一种有效的解决方案来减轻注意力偏差，并为增强多模态模型的音频处理能力开辟了一个新的研究方向。

Abstract: Large Audio-Language Models (LALMs) often suffer from audio-textual attention
imbalance, prioritizing text over acoustic information, particularly in the
multi-modal fusion layers of the Transformer architecture. This bias hinders
their ability to fully utilize acoustic cues, causing suboptimal performance on
audio reasoning tasks. To mitigate this, we propose \textbf{MATA}, a novel
training-free method that dynamically pushes LALMs to pay \textbf{M}ore
\textbf{A}ttention \textbf{T}o \textbf{A}udio tokens within the self-attention
mechanism. Specifically, MATA intervenes post raw attention scoring, targeting
only the last token in intermediate layers without introducing additional
parameters or computational overhead. Experiments on the MMAU and MMAR
benchmarks confirm MATA's effectiveness, with consistent performance gains.
Notably, on MMAR, MATA enables an open-source model to surpass the proprietary
Gemini 2.0 Flash for the first time. Our work provides an efficient solution to
mitigate attention bias and opens a new research direction for enhancing the
audio-processing capabilities of multi-modal models.

</details>


### [79] [Finding My Voice: Generative Reconstruction of Disordered Speech for Automated Clinical Evaluation](https://arxiv.org/abs/2509.19231)
*Karen Rosero,Eunjung Yeo,David R. Mortensen,Cortney Van't Slot,Rami R. Hallac,Carlos Busso*

Main category: cs.SD

TL;DR: 我们提出了ChiReSSD，这是一种语音重建框架，可以在保留儿童说话者身份的同时抑制发音错误。我们的结果表明，解耦的、基于风格的TTS重建可以为不同临床人群提供保留身份的语音。


<details>
  <summary>Details</summary>
Motivation: 为了在保留儿童说话者身份的同时抑制发音错误，我们需要一种能够适应有语音障碍的儿童声音的语音重建框架。

Method: 我们提出了ChiReSSD，这是一种语音重建框架，可以在抑制发音错误的同时保留儿童说话者的身份。与之前在健康成人语音上训练的方法不同，ChiReSSD适应有语音障碍（SSD）的儿童的声音，特别关注音高和语调。

Result: 我们在STAR数据集上评估了我们的方法，并报告了在词汇准确性和说话者身份保留方面的显著改进。此外，我们自动预测原始和重建对中的语音内容，其中纠正辅音的比例与正确辅音的比例（PCC）相当，这是一个临床语音评估指标。实验显示自动标注和人工专家标注之间的皮尔逊相关系数为0.63，突显了减少手动转录负担的潜力。此外，在TORGO数据集上的实验展示了在重建成人构音障碍语音方面的有效性。

Conclusion: 我们的结果表明，解耦的、基于风格的TTS重建可以为不同临床人群提供保留身份的语音。

Abstract: We present ChiReSSD, a speech reconstruction framework that preserves
children speaker's identity while suppressing mispronunciations. Unlike prior
approaches trained on healthy adult speech, ChiReSSD adapts to the voices of
children with speech sound disorders (SSD), with particular emphasis on pitch
and prosody. We evaluate our method on the STAR dataset and report substantial
improvements in lexical accuracy and speaker identity preservation.
Furthermore, we automatically predict the phonetic content in the original and
reconstructed pairs, where the proportion of corrected consonants is comparable
to the percentage of correct consonants (PCC), a clinical speech assessment
metric. Our experiments show Pearson correlation of 0.63 between automatic and
human expert annotations, highlighting the potential to reduce the manual
transcription burden. In addition, experiments on the TORGO dataset demonstrate
effective generalization for reconstructing adult dysarthric speech. Our
results indicate that disentangled, style-based TTS reconstruction can provide
identity-preserving speech across diverse clinical populations.

</details>
