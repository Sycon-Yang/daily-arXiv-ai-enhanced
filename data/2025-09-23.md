<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 140]
- [cs.CV](#cs.CV) [Total: 7]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.CY](#cs.CY) [Total: 4]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.IR](#cs.IR) [Total: 7]
- [cs.SD](#cs.SD) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.HC](#cs.HC) [Total: 4]
- [cs.AI](#cs.AI) [Total: 12]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [On LLM-Based Scientific Inductive Reasoning Beyond Equations](https://arxiv.org/abs/2509.16226)
*Brian S. Lin,Jiaxin Yuan,Zihan Zhou,Shouli Wang,Shuo Wang,Cunliang Kong,Qi Shi,Yuxuan Li,Liner Yang,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: 本文提出了一个基于大型语言模型的超越方程的科学归纳推理任务，并引入了一个新的基准测试SIRBench-V1来评估大型语言模型在科学环境中的归纳推理能力。实验结果表明，当前的大型语言模型在这一任务上仍然面临困难。


<details>
  <summary>Details</summary>
Motivation: 为了使大型语言模型能够从有限的例子中学习潜在模式并在全新的环境中有效应用，需要研究其归纳推理能力。现有的基于大型语言模型的归纳推理研究可以分为是否可以通过显式数学方程表达底层规则。然而，许多最近的研究在超越方程类别中强调了规则设计而没有将其扎根于具体场景。

Method: 提出了一项基于大型语言模型的超越方程的科学归纳推理任务，并引入了一个新的基准测试SIRBench-V1来评估大型语言模型在科学环境中的归纳推理能力。

Result: 实验结果表明，当前的大型语言模型在这一任务上仍然面临困难。

Conclusion: 当前的大型语言模型在这一任务上仍然面临困难，这突显了该任务的难度以及在此领域进一步发展的必要性。

Abstract: As large language models (LLMs) increasingly exhibit human-like capabilities,
a fundamental question emerges: How can we enable LLMs to learn the underlying
patterns from limited examples in entirely novel environments and apply them
effectively? This question is central to the ability of LLMs in inductive
reasoning. Existing research on LLM-based inductive reasoning can be broadly
categorized based on whether the underlying rules are expressible via explicit
mathematical equations. However, many recent studies in the beyond-equations
category have emphasized rule design without grounding them in specific
scenarios. Inspired by the parallels between inductive reasoning and human
scientific discovery, we propose the task of LLM-Based Scientific Inductive
Reasoning Beyond Equations and introduce a new benchmark, SIRBench-V1, to
evaluate the inductive reasoning abilities of LLMs in scientific settings. Our
experimental results show that current LLMs still struggle with this task,
underscoring its difficulty and the need for further advancement in this area.

</details>


### [2] [REAMS: Reasoning Enhanced Algorithm for Maths Solving](https://arxiv.org/abs/2509.16241)
*Eishkaran Singh,Tanav Singh Bajaj,Siddharth Nayak*

Main category: cs.CL

TL;DR: 本文提出了一种基于语言的解决方案，利用零样本学习和数学推理来解决复杂的数学问题，通过程序合成减少对大规模训练数据的依赖，实现了90.15%的准确率，显著优于之前的基准。


<details>
  <summary>Details</summary>
Motivation: 解决复杂大学水平数学问题（特别是来自麻省理工学院和哥伦比亚大学课程的问题以及MATH数据集中的选定任务）的挑战仍然是人工智能领域的一个重大障碍。传统方法在这个领域一直表现不佳，这表明需要更先进的方法。

Method: 本文介绍了一种基于语言的解决方案，利用零样本学习和数学推理来有效解决、解释和生成这些高级数学问题的解决方案。通过集成程序合成，该方法减少了对大规模训练数据的依赖，同时显著提高了问题解决的准确性。

Result: 我们的方法达到了90.15%的准确率，这比之前的基准81%有了显著提高，并为自动化数学问题解决设定了新标准。

Conclusion: 这些发现突显了先进人工智能方法在解决最复杂数学课程和数据集所提出的挑战方面的显著潜力。

Abstract: The challenges of solving complex university-level mathematics problems,
particularly those from MIT, and Columbia University courses, and selected
tasks from the MATH dataset, remain a significant obstacle in the field of
artificial intelligence. Conventional methods have consistently fallen short in
this domain, highlighting the need for more advanced approaches. In this paper,
we introduce a language-based solution that leverages zero-shot learning and
mathematical reasoning to effectively solve, explain, and generate solutions
for these advanced math problems. By integrating program synthesis, our method
reduces reliance on large-scale training data while significantly improving
problem-solving accuracy. Our approach achieves an accuracy of 90.15%,
representing a substantial improvement over the previous benchmark of 81% and
setting a new standard in automated mathematical problem-solving. These
findings highlight the significant potential of advanced AI methodologies to
address and overcome the challenges presented by some of the most complex
mathematical courses and datasets.

</details>


### [3] [HausaMovieReview: A Benchmark Dataset for Sentiment Analysis in Low-Resource African Language](https://arxiv.org/abs/2509.16256)
*Asiya Ibrahim Zanga,Salisu Mamman Abdulrahman,Abubakar Ado,Abdulkadir Abubakar Bichi,Lukman Aliyu Jibril,Abdulmajid Babangida Umar,Alhassan Adamu,Shamsuddeen Hassan Muhammad,Bashir Salisu Abubakar*

Main category: cs.CL

TL;DR: 本文介绍了一个新的豪萨语和混合英语的YouTube评论数据集，并展示了经典模型在低资源环境下的优越性能。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理（NLP）工具在低资源语言中的发展受到标注数据集稀缺的严重阻碍。本文旨在解决这一基本挑战，引入了一个新的基准数据集HausaMovieReview，包含5000条豪萨语和混合英语的YouTube评论。

Method: 我们使用了HausaMovieReview数据集对经典模型（逻辑回归、决策树、K近邻）和微调的transformer模型（BERT和RoBERTa）进行了比较分析。

Result: 决策树分类器的准确率和F1分数分别为89.72%和89.60%，显著优于深度学习模型。

Conclusion: 我们的研究结果表明，在低资源环境下，有效的特征工程可以使经典模型达到最先进的性能，从而为未来的研究奠定了坚实的基础。

Abstract: The development of Natural Language Processing (NLP) tools for low-resource
languages is critically hindered by the scarcity of annotated datasets. This
paper addresses this fundamental challenge by introducing HausaMovieReview, a
novel benchmark dataset comprising 5,000 YouTube comments in Hausa and
code-switched English. The dataset was meticulously annotated by three
independent annotators, demonstrating a robust agreement with a Fleiss' Kappa
score of 0.85 between annotators. We used this dataset to conduct a comparative
analysis of classical models (Logistic Regression, Decision Tree, K-Nearest
Neighbors) and fine-tuned transformer models (BERT and RoBERTa). Our results
reveal a key finding: the Decision Tree classifier, with an accuracy and
F1-score 89.72% and 89.60% respectively, significantly outperformed the deep
learning models. Our findings also provide a robust baseline, demonstrating
that effective feature engineering can enable classical models to achieve
state-of-the-art performance in low-resource contexts, thereby laying a solid
foundation for future research.
  Keywords: Hausa, Kannywood, Low-Resource Languages, NLP, Sentiment Analysis

</details>


### [4] [Gender and Political Bias in Large Language Models: A Demonstration Platform](https://arxiv.org/abs/2509.16264)
*Wenjie Lin,Hange Liu,Xutao Mao,Yingying Zhuang,Jingwei Shi,Xudong Han,Tianyu Shi,Jinrui Yang*

Main category: cs.CL

TL;DR: ParlAI Vote是一个交互式系统，用于探索欧洲议会辩论和投票，并测试LLMs在投票预测和偏差分析中的表现。


<details>
  <summary>Details</summary>
Motivation: 为了研究LLMs在政治分析中的表现，特别是投票预测和偏差分析，需要一个集数据、模型和可视化分析于一体的平台。

Method:  ParlAI Vote是一个交互式系统，用于探索欧洲议会辩论和投票，并测试LLMs在投票预测和偏差分析中的表现。该平台连接了辩论主题、演讲和投票结果，并包含丰富的统计数据，如性别、年龄、国家和政治团体。

Result: ParlAI Vote展示了最先进的LLMs在性别分类和投票预测任务中的系统性性能偏差，并支持研究、教育和公众参与立法决策。

Conclusion: 该系统统一了数据、模型和可视化分析，降低了重现研究结果、审计行为和运行反事实场景的门槛，并展示了当前LLMs在政治分析中的优势和局限性。

Abstract: We present ParlAI Vote, an interactive system for exploring European
Parliament debates and votes, and for testing LLMs on vote prediction and bias
analysis. This platform connects debate topics, speeches, and roll-call
outcomes, and includes rich demographic data such as gender, age, country, and
political group. Users can browse debates, inspect linked speeches, compare
real voting outcomes with predictions from frontier LLMs, and view error
breakdowns by demographic group. Visualizing the EuroParlVote benchmark and its
core tasks of gender classification and vote prediction, ParlAI Vote highlights
systematic performance bias in state-of-the-art LLMs. The system unifies data,
models, and visual analytics in a single interface, lowering the barrier for
reproducing findings, auditing behavior, and running counterfactual scenarios.
It supports research, education, and public engagement with legislative
decision-making, while making clear both the strengths and the limitations of
current LLMs in political analysis.

</details>


### [5] [Language Modeling with Learned Meta-Tokens](https://arxiv.org/abs/2509.16278)
*Alok N. Shah,Khush Gupta,Keshav Ramji,Pratik Chaudhari*

Main category: cs.CL

TL;DR: 本文提出了一种使用元标记和元注意力机制来增强语言模型处理长上下文的能力的方法，并展示了其在多个任务上的有效性。


<details>
  <summary>Details</summary>
Motivation: 现代基于Transformer的语言模型在多任务泛化方面取得了重大成功，但它们往往难以捕捉其上下文窗口内的长距离依赖关系。因此，我们需要一种方法来增强语言模型在处理长上下文时的表现。

Method: 我们引入了一种新方法，使用元标记（在预训练期间注入的特殊标记）以及专用的元注意力机制来引导语言模型使用这些标记。我们对一个修改后的GPT-2架构进行了预训练，该架构配备了元注意力机制和因果多头注意力机制。

Result: 我们在少于100B个标记的数据上进行数据高效的语言模型预训练，利用元标记和我们的元注意力机制，在微调后在这些任务上表现出色。元标记通过锐化位置编码来提高性能，使它们能够作为可训练的内容相关地标，隐式压缩前面的上下文并“缓存”在元标记中。在推理时，元标记指向相关上下文，促进长度泛化，即使在扩展YaRN后也能达到其上下文窗口的2倍。

Conclusion: 我们的研究结果表明，使用元标记进行预训练的语言模型提供了一种简单且数据高效的增强长上下文语言建模性能的方法，同时为它们在长度泛化方面的行为提供了新的见解。

Abstract: While modern Transformer-based language models (LMs) have achieved major
success in multi-task generalization, they often struggle to capture long-range
dependencies within their context window. This work introduces a novel approach
using meta-tokens, special tokens injected during pre-training, along with a
dedicated meta-attention mechanism to guide LMs to use these tokens. We
pre-train a language model with a modified GPT-2 architecture equipped with
meta-attention in addition to causal multi-head attention, and study the impact
of these tokens on a suite of synthetic tasks. We find that data-efficient
language model pre-training on fewer than 100B tokens utilizing meta-tokens and
our meta-attention mechanism achieves strong performance on these tasks after
fine-tuning. We suggest that these gains arise due to the meta-tokens
sharpening the positional encoding. This enables them to operate as trainable,
content-based landmarks, implicitly compressing preceding context and "caching"
it in the meta-token. At inference-time, the meta-token points to relevant
context, facilitating length generalization up to 2$\times$ its context window,
even after extension with YaRN. We provide further evidence of these behaviors
by visualizing model internals to study the residual stream, and assessing the
compression quality by information-theoretic analysis on the rate-distortion
tradeoff. Our findings suggest that pre-training LMs with meta-tokens offers a
simple, data-efficient method to enhance long-context language modeling
performance, while introducing new insights into the nature of their behavior
towards length generalization.

</details>


### [6] [Overhearing LLM Agents: A Survey, Taxonomy, and Roadmap](https://arxiv.org/abs/2509.16325)
*Andrew Zhu,Chris Callison-Burch*

Main category: cs.CL

TL;DR: 本文研究了听觉LLM代理作为一种新型的人机交互范式，分析了其交互方式和任务，并提出了最佳实践和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现代对话LLM代理直接通过聊天界面协助用户完成任务，但本文研究了一种替代范式，即“听觉代理”，它们持续监控环境活动并在能够提供上下文帮助时介入，而无需用户的注意力。

Method: 本文通过调查先前的LLM驱动代理的研究和探索性HCI研究，建立了一个听觉代理交互和任务的分类法，并基于此分类法创建了一套最佳实践指南。

Result: 本文提出了听觉代理的分类法，制定了最佳实践指南，并指出了未来研究的空白和机会。

Conclusion: 本文分析了听觉LLM代理作为人机交互中的一种独特范式，并提出了构建听觉代理系统的最佳实践，同时指出了未来研究的空白和机会。

Abstract: Imagine AI assistants that enhance conversations without interrupting them:
quietly providing relevant information during a medical consultation,
seamlessly preparing materials as teachers discuss lesson plans, or
unobtrusively scheduling meetings as colleagues debate calendars. While modern
conversational LLM agents directly assist human users with tasks through a chat
interface, we study this alternative paradigm for interacting with LLM agents,
which we call "overhearing agents." Rather than demanding the user's attention,
overhearing agents continuously monitor ambient activity and intervene only
when they can provide contextual assistance. In this paper, we present the
first analysis of overhearing LLM agents as a distinct paradigm in human-AI
interaction and establish a taxonomy of overhearing agent interactions and
tasks grounded in a survey of works on prior LLM-powered agents and exploratory
HCI studies. Based on this taxonomy, we create a list of best practices for
researchers and developers building overhearing agent systems. Finally, we
outline the remaining research gaps and reveal opportunities for future
research in the overhearing paradigm.

</details>


### [7] [HARE: an entity and relation centric evaluation framework for histopathology reports](https://arxiv.org/abs/2509.16326)
*Yunsoo Kim,Michal W. S. Ong,Alex Shavick,Honghan Wu,Adam P. Levine*

Main category: cs.CL

TL;DR: 本文提出了 HARE（组织病理学自动化报告评估），这是一个基于实体和关系的框架，包含一个基准数据集、命名实体识别 (NER) 模型、关系提取 (RE) 模型和一个新提出的度量标准，旨在提高组织病理学报告的质量。


<details>
  <summary>Details</summary>
Motivation: 医疗领域自动化文本生成是一个活跃的研究和开发领域，但评估生成报告的临床质量仍然具有挑战性，特别是在缺乏领域特定指标的情况下，例如组织病理学。

Method: HARE 是一个基于实体和关系的框架，包括一个基准数据集、命名实体识别 (NER) 模型、关系提取 (RE) 模型和一个新提出的度量标准。我们对 813 份去标识化的临床诊断组织病理学报告和 652 份来自 The Cancer Genome Atlas (TCGA) 的组织病理学报告进行了领域特定的实体和关系标注，并微调了 GatorTronS 语言模型以开发 HARE-NER 和 HARE-RE。

Result: HARE 度量标准优于传统的 ROUGE 和 Meteor 度量标准以及放射学度量标准如 RadGraph-XL，与专家评估的相关性最高，并且在回归到专家评估方面表现最佳。HARE-NER 和 HARE-RE 在测试模型中取得了最高的总体 F1 分数 (0.915)。

Conclusion: HARE 提供了一个强大的框架，用于提高组织病理学报告的质量，并通过释放 HARE、数据集和模型来促进该领域的进步。

Abstract: Medical domain automated text generation is an active area of research and
development; however, evaluating the clinical quality of generated reports
remains a challenge, especially in instances where domain-specific metrics are
lacking, e.g. histopathology. We propose HARE (Histopathology Automated Report
Evaluation), a novel entity and relation centric framework, composed of a
benchmark dataset, a named entity recognition (NER) model, a relation
extraction (RE) model, and a novel metric, which prioritizes clinically
relevant content by aligning critical histopathology entities and relations
between reference and generated reports. To develop the HARE benchmark, we
annotated 813 de-identified clinical diagnostic histopathology reports and 652
histopathology reports from The Cancer Genome Atlas (TCGA) with domain-specific
entities and relations. We fine-tuned GatorTronS, a domain-adapted language
model to develop HARE-NER and HARE-RE which achieved the highest overall
F1-score (0.915) among the tested models. The proposed HARE metric outperformed
traditional metrics including ROUGE and Meteor, as well as radiology metrics
such as RadGraph-XL, with the highest correlation and the best regression to
expert evaluations (higher than the second best method, GREEN, a large language
model based radiology report evaluator, by Pearson $r = 0.168$, Spearman $\rho
= 0.161$, Kendall $\tau = 0.123$, $R^2 = 0.176$, $RMSE = 0.018$). We release
HARE, datasets, and the models at https://github.com/knowlab/HARE to foster
advancements in histopathology report generation, providing a robust framework
for improving the quality of reports.

</details>


### [8] [RephQA: Evaluating Readability of Large Language Models in Public Health Question Answering](https://arxiv.org/abs/2509.16360)
*Weikang Qiu,Tinglin Huang,Ryan Rullo,Yucheng Kuang,Ali Maatouk,S. Raquel Ramos,Rex Ying*

Main category: cs.CL

TL;DR: 本文介绍了RephQA，一个用于评估LLM在公共卫生问答中的可读性的基准。通过评估25个LLM，发现大多数未能达到可读性标准，并探索了四种提高可读性的策略，其中令牌适应的GRPO效果最佳。


<details>
  <summary>Details</summary>
Motivation: 大多数以前的研究集中在提高准确性和推理能力上，但开发有效的医疗代理的一个重要瓶颈在于LLM生成的回答的可读性。

Method: 我们探索了四种提高可读性的策略：标准提示、思维链提示、组相对策略优化（GRPO）和一种令牌适应变体。

Result: 评估25个LLM的结果显示，大多数未能达到可读性标准，这表明推理和有效沟通之间存在差距。

Conclusion: 这些结果代表了向构建更实用的公共卫生代理迈出了一步。

Abstract: Large Language Models (LLMs) hold promise in addressing complex medical
problems. However, while most prior studies focus on improving accuracy and
reasoning abilities, a significant bottleneck in developing effective
healthcare agents lies in the readability of LLM-generated responses,
specifically, their ability to answer public health problems clearly and simply
to people without medical backgrounds. In this work, we introduce RephQA, a
benchmark for evaluating the readability of LLMs in public health question
answering (QA). It contains 533 expert-reviewed QA pairs from 27 sources across
13 topics, and includes a proxy multiple-choice task to assess informativeness,
along with two readability metrics: Flesch-Kincaid grade level and professional
score. Evaluation of 25 LLMs reveals that most fail to meet readability
standards, highlighting a gap between reasoning and effective communication. To
address this, we explore four readability-enhancing strategies-standard
prompting, chain-of-thought prompting, Group Relative Policy Optimization
(GRPO), and a token-adapted variant. Token-adapted GRPO achieves the best
results, advancing the development of more practical and user-friendly public
health agents. These results represent a step toward building more practical
agents for public health.

</details>


### [9] [Whisper-UT: A Unified Translation Framework for Speech and Text](https://arxiv.org/abs/2509.16375)
*Cihan Xiao,Matthew Wiesner,Debashish Chakraborty,Reno Kriz,Keith Cunningham,Kenton Murray,Kevin Duh,Luis Tavarez-Arce,Paul McNamee,Sanjeev Khudanpur*

Main category: cs.CL

TL;DR: 本文提出了Whisper-UT框架，利用轻量级适配器实现多模态任务的高效适应，并通过两阶段解码策略提升语音翻译性能。


<details>
  <summary>Details</summary>
Motivation: 当前编码器-解码器模型在语音和文本任务中取得了显著成功，但高效适应多种单/多模态场景仍是一个开放挑战。

Method: 本文提出了一种统一且高效的框架，利用轻量级适配器实现任务间的无缝适应，并采用两阶段解码策略提升语音翻译性能。

Result: 通过结合ASR假设或真实转录本作为提示，该方法不仅能够同时处理多种模态，还通过两阶段解码策略提升了语音翻译性能。

Conclusion: 本文提出的Whisper-UT框架在多模态翻译中表现出灵活性、效率和通用性。

Abstract: Encoder-decoder models have achieved remarkable success in speech and text
tasks, yet efficiently adapting these models to diverse uni/multi-modal
scenarios remains an open challenge. In this paper, we propose Whisper-UT, a
unified and efficient framework that leverages lightweight adapters to enable
seamless adaptation across tasks, including a multi-modal machine translation
(MMT) task that explicitly conditions translation on both speech and source
language text inputs. By incorporating ASR hypotheses or ground-truth
transcripts as prompts, this approach not only enables the system to process
both modalities simultaneously but also enhances speech translation (ST)
performance through a 2-stage decoding strategy. We demonstrate our methods
using the Whisper model, though in principle they are general and could be
applied to similar multitask models. We highlight the effectiveness of
cross-modal and cross-task fine-tuning, which improves performance without
requiring 3-way parallel data. Our results underscore the flexibility,
efficiency, and general applicability of the proposed framework for multi-modal
translation.

</details>


### [10] [Evaluating Behavioral Alignment in Conflict Dialogue: A Multi-Dimensional Comparison of LLM Agents and Humans](https://arxiv.org/abs/2509.16394)
*Deuksin Kwon,Kaleen Shrestha,Bin Han,Elena Hayoung Lee,Gale Lucas*

Main category: cs.CL

TL;DR: 本研究评估了个性提示LLMs在对抗性争议解决中的行为对齐情况，发现GPT-4.1在语言和情感上最接近人类，而Claude-3.7-Sonnet在战略行为上表现最佳，但仍有较大差距。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）越来越多地被部署在社会复杂、互动驱动的任务中，但它们在情感和战略复杂的背景下模仿人类行为的能力仍缺乏探索。

Method: 我们通过模拟包含谈判的多轮冲突对话来评估个性提示LLMs在对抗性争议解决中的行为对齐情况，并使用匹配的五因素人格档案来控制个体差异并提高现实感。

Result: GPT-4.1在语言风格和情感动态方面最接近人类，而Claude-3.7-Sonnet最能反映战略行为。然而，仍然存在显著的对齐差距。

Conclusion: 我们的研究为LLMs与人类在社会复杂互动中的对齐设定了基准，强调了人格条件在对话建模中的潜力和局限性。

Abstract: Large Language Models (LLMs) are increasingly deployed in socially complex,
interaction-driven tasks, yet their ability to mirror human behavior in
emotionally and strategically complex contexts remains underexplored. This
study assesses the behavioral alignment of personality-prompted LLMs in
adversarial dispute resolution by simulating multi-turn conflict dialogues that
incorporate negotiation. Each LLM is guided by a matched Five-Factor
personality profile to control for individual variation and enhance realism. We
evaluate alignment across three dimensions: linguistic style, emotional
expression (e.g., anger dynamics), and strategic behavior. GPT-4.1 achieves the
closest alignment with humans in linguistic style and emotional dynamics, while
Claude-3.7-Sonnet best reflects strategic behavior. Nonetheless, substantial
alignment gaps persist. Our findings establish a benchmark for alignment
between LLMs and humans in socially complex interactions, underscoring both the
promise and the limitations of personality conditioning in dialogue modeling.

</details>


### [11] ['Rich Dad, Poor Lad': How do Large Language Models Contextualize Socioeconomic Factors in College Admission ?](https://arxiv.org/abs/2509.16400)
*Huy Nghiem,Phuong-Anh Nguyen-Le,John Prindle,Rachel Rudinger,Hal Daumé III*

Main category: cs.CL

TL;DR: 研究分析了大型语言模型在大学录取中对社会经济地位的处理方式，发现它们倾向于支持低SES申请者，并提出了一个双过程审计框架（DPAF）以探测其推理行为。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索大型语言模型在高风险领域中对社会敏感决策的推理方式，特别是它们如何处理社会经济地位（SES）在大学录取中的影响。

Method: 研究使用了一个基于现实世界相关性的合成数据集，包含30,000个申请者资料，并通过两种模式（系统1和系统2）对四个开源LLMs进行测试。

Result: 结果显示，LLMs始终倾向于支持低SES申请者，即使在控制学术表现的情况下也是如此。系统2模式通过明确引用SES作为补偿性理由，进一步放大了这种倾向。

Conclusion: 研究发现大型语言模型（LLMs）在处理社会经济地位（SES）时倾向于支持低SES申请者，即使在控制学术表现的情况下也是如此。此外，系统2模式会放大这种倾向，通过明确引用SES作为补偿性理由。研究提出了DPAF框架来探测LLMs在敏感应用中的推理行为。

Abstract: Large Language Models (LLMs) are increasingly involved in high-stakes
domains, yet how they reason about socially sensitive decisions remains
underexplored. We present a large-scale audit of LLMs' treatment of
socioeconomic status (SES) in college admissions decisions using a novel
dual-process framework inspired by cognitive science. Leveraging a synthetic
dataset of 30,000 applicant profiles grounded in real-world correlations, we
prompt 4 open-source LLMs (Qwen 2, Mistral v0.3, Gemma 2, Llama 3.1) under 2
modes: a fast, decision-only setup (System 1) and a slower, explanation-based
setup (System 2). Results from 5 million prompts reveal that LLMs consistently
favor low-SES applicants -- even when controlling for academic performance --
and that System 2 amplifies this tendency by explicitly invoking SES as
compensatory justification, highlighting both their potential and volatility as
decision-makers. We then propose DPAF, a dual-process audit framework to probe
LLMs' reasoning behaviors in sensitive applications.

</details>


### [12] [Pico: A Modular Framework for Hypothesis-Driven Small Language Model Research](https://arxiv.org/abs/2509.16413)
*Richard Diehl Martinez,David Demitri Africa,Yuval Weiss,Suchir Salhan,Ryan Daniels,Paula Buttery*

Main category: cs.CL

TL;DR: Pico is a framework for systematic, hypothesis-driven research in small and medium-scale language model development, providing a sandbox for targeted changes and reproducible experimentation.


<details>
  <summary>Details</summary>
Motivation: Building small and medium language models remains more art than science due to uncertainty in design choices and the need for systematic, scientific ways to test and refine ideas.

Method: Pico is a lightweight, modular framework consisting of two libraries that allow researchers to make targeted changes to a model's architecture or training procedures and observe their effects.

Result: Pico enables researchers to conduct reproducible experimentation with baseline models, pico-decoder, trained under standardized conditions.

Conclusion: Pico provides a practical sandbox for systematic, hypothesis-driven research in small and medium-scale language model development, supporting iterative design and analysis.

Abstract: Building language models (LMs), especially small and medium ones, remains
more art than science. While large LMs often improve by sheer scale, it is
still unclear why many design choices work. For small LMs, this uncertainty is
more limiting: tight parameter budgets make each decision critical, yet
researchers still lack systematic, scientific ways to test and refine new
ideas.
  We introduce Pico, a lightweight, modular framework that enables systematic,
hypothesis-driven research for small and medium-scale language model
development. Pico consists of two libraries that together provide a practical
sandbox where researchers can make targeted changes to a model's architecture
or training procedures and directly observe their effects on the model's
behavior. To support reproducible experimentation, we also release a suite of
baseline models, pico-decoder, trained under standardized conditions and
open-sourced for the community. Case studies highlight how Pico can support
iterative small LM design and analysis.

</details>


### [13] [Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning](https://arxiv.org/abs/2509.16422)
*Tom Mackintosh,Harish Tayyar Madabushi,Claire Bonial*

Main category: cs.CL

TL;DR: 研究分析了大型语言模型在构式语法中的形式-意义映射能力，提出了一个基准测试并发现模型在对抗数据上的表现下降，同时提出了一种评估构式学习的框架。


<details>
  <summary>Details</summary>
Motivation: 我们探究大型语言模型学习构式语法所定义的深层形式-意义映射的能力。

Method: 我们引入了ConTest-NLI基准，包含80k个句子，涵盖了从高度词汇化到高度图式的八种英语构式。我们的管道通过模板化和模型内过滤器的应用生成多样化的合成NLI三元组。

Result: 零样本测试显示，在自然数据（88%）和对抗数据（64%）之间准确率下降了24%，其中图式模式最难。在ConTest-NLI的一个子集上微调可提高高达9%的性能。

Conclusion: 我们的结果突显了当前大型语言模型在抽象方面的持续差距，并提供了一个可扩展的框架来评估基于构式的学习。

Abstract: We probe large language models' ability to learn deep form-meaning mappings
as defined by construction grammars. We introduce the ConTest-NLI benchmark of
80k sentences covering eight English constructions from highly lexicalized to
highly schematic. Our pipeline generates diverse synthetic NLI triples via
templating and the application of a model-in-the-loop filter. This provides
aspects of human validation to ensure challenge and label reliability.
Zero-shot tests on leading LLMs reveal a 24% drop in accuracy between
naturalistic (88%) and adversarial data (64%), with schematic patterns proving
hardest. Fine-tuning on a subset of ConTest-NLI yields up to 9% improvement,
yet our results highlight persistent abstraction gaps in current LLMs and offer
a scalable framework for evaluating construction-informed learning.

</details>


### [14] [PersonaMatrix: A Recipe for Persona-Aware Evaluation of Legal Summarization](https://arxiv.org/abs/2509.16449)
*Tsz Fung Pang,Maryam Berijanian,Thomas Orth,Breanna Shi,Charlotte S. Alexander*

Main category: cs.CL

TL;DR: 本文提出了一种新的评估框架PersonaMatrix，用于评估法律文档摘要的质量，并创建了一个受控维度偏移的试点数据集，以揭示不同角色对摘要的需求差异。这项工作有助于改进针对专家和非专家用户的法律AI摘要系统，提高法律知识的可及性。


<details>
  <summary>Details</summary>
Motivation: 法律文档通常冗长、密集且难以理解，不仅对普通公众，而且对法律专家也是如此。尽管自动化文档摘要有潜力改善法律知识的获取，但现有的任务评估方法忽略了不同的用户和利益相关者需求。因此，需要开发一种工具，既能满足律师对案例摘要的技术性需求，又能为自研诉讼的公众提供易用性。

Method: 本文提出了PersonaMatrix，这是一种基于角色的评估框架，用于评估法律文档摘要的质量。此外，还创建了一个受控维度偏移的试点数据集，该数据集在深度、可访问性和程序细节等方面有所不同，并引入了多样性-覆盖率指数（DCI）来衡量不同角色对摘要的需求差异。

Result: 本文提出了PersonaMatrix，这是一种基于角色的评估框架，能够通过六个角色（包括法律和非法律用户）对摘要进行评分。同时，还介绍了一个受控维度偏移的试点数据集，该数据集在深度、可访问性和程序细节等方面有所不同，并引入了多样性-覆盖率指数（DCI）来揭示角色感知和角色无关法官之间法律摘要的不同最优值。

Conclusion: 本文介绍了PersonaMatrix，这是一种基于角色的评估框架，能够通过六个角色（包括法律和非法律用户）对摘要进行评分。同时，还介绍了一个受控维度偏移的试点数据集，该数据集在深度、可访问性和程序细节等方面有所不同，并引入了多样性-覆盖率指数（DCI），以揭示角色感知和角色无关法官之间法律摘要的不同最优值。这项工作有助于改进针对专家和非专家用户的法律AI摘要系统，从而提高法律知识的可及性。代码库和数据可在GitHub上公开获取。

Abstract: Legal documents are often long, dense, and difficult to comprehend, not only
for laypeople but also for legal experts. While automated document
summarization has great potential to improve access to legal knowledge,
prevailing task-based evaluators overlook divergent user and stakeholder needs.
Tool development is needed to encompass the technicality of a case summary for
a litigator yet be accessible for a self-help public researching for their
lawsuit. We introduce PersonaMatrix, a persona-by-criterion evaluation
framework that scores summaries through the lens of six personas, including
legal and non-legal users. We also introduce a controlled dimension-shifted
pilot dataset of U.S. civil rights case summaries that varies along depth,
accessibility, and procedural detail as well as Diversity-Coverage Index (DCI)
to expose divergent optima of legal summary between persona-aware and
persona-agnostic judges. This work enables refinement of legal AI summarization
systems for both expert and non-expert users, with the potential to increase
access to legal knowledge. The code base and data are publicly available in
GitHub.

</details>


### [15] [Implicit Behavioral Alignment of Language Agents in High-Stakes Crowd Simulations](https://arxiv.org/abs/2509.16457)
*Yunzhe Wang,Gale M. Lucas,Burcin Becerik-Gerber,Volkan Ustun*

Main category: cs.CL

TL;DR: 本文提出了一种名为PEBA的理论框架和基于LLM的优化算法PEvo，以解决生成代理行为与现实数据之间的差距。在突发枪击事件模拟中，PEvo表现出色，显著提高了行为真实性和可靠性，并能推广到新的模拟场景。


<details>
  <summary>Details</summary>
Motivation: 语言驱动的生成代理在大规模社会模拟中具有变革性的应用，从人际培训到帮助全球政策制定。然而，最近的研究表明，生成代理的行为往往偏离专家期望和现实数据——我们称之为行为-现实差距。

Method: 我们引入了一个称为Persona-Environment Behavioral Alignment (PEBA)的理论框架，将其形式化为一个分布匹配问题，基于Lewin的行为方程，即行为是个人和环境的函数。基于PEBA，我们提出了PersonaEvolve (PEvo)，一种基于LLM的优化算法，通过迭代优化代理人格，隐式地将他们的集体行为与特定环境情境下的现实专家基准对齐。

Result: 我们在一个我们开发的突发枪击事件模拟中验证了PEvo，与没有引导相比，分布差异平均减少了84%，比显式指令基线提高了34%。结果还显示，PEvo优化的人格可以推广到新的、相关的模拟场景。

Conclusion: 我们的方法显著提高了高风险社会模拟中的行为真实性和可靠性。更广泛地说，PEBA-PEvo框架为开发可信赖的LLM驱动的社会模拟提供了一种有原则的方法。

Abstract: Language-driven generative agents have enabled large-scale social simulations
with transformative uses, from interpersonal training to aiding global
policy-making. However, recent studies indicate that generative agent behaviors
often deviate from expert expectations and real-world data--a phenomenon we
term the Behavior-Realism Gap. To address this, we introduce a theoretical
framework called Persona-Environment Behavioral Alignment (PEBA), formulated as
a distribution matching problem grounded in Lewin's behavior equation stating
that behavior is a function of the person and their environment. Leveraging
PEBA, we propose PersonaEvolve (PEvo), an LLM-based optimization algorithm that
iteratively refines agent personas, implicitly aligning their collective
behaviors with realistic expert benchmarks within a specified environmental
context. We validate PEvo in an active shooter incident simulation we
developed, achieving an 84% average reduction in distributional divergence
compared to no steering and a 34% improvement over explicit instruction
baselines. Results also show PEvo-refined personas generalize to novel, related
simulation scenarios. Our method greatly enhances behavioral realism and
reliability in high-stakes social simulations. More broadly, the PEBA-PEvo
framework provides a principled approach to developing trustworthy LLM-driven
social simulations.

</details>


### [16] [Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models](https://arxiv.org/abs/2509.16462)
*'Mina Arzaghi','Alireza Dehghanpour Farashah','Florian Carichon',' Golnoosh Farnadi'*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型中的内在偏差对下游任务公平性的影响，并提出了一个统一的评估框架来比较不同的偏差缓解方法。实验结果表明，通过概念删除可以显著减少内在偏差并提高公平性，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在实证研究大型语言模型（LLMs）中的内在偏差是否会影响下游任务的公平性。

Method: 本文提出了一种统一的评估框架，用于比较通过概念删除进行内在偏差缓解与通过反事实数据增强（CDA）进行外在偏差缓解。

Result: 实验结果表明，通过概念删除进行内在偏差缓解可减少高达94.9%的内在性别偏差，并提高下游任务的公平性指标，如人口均等性，最高可达82%，同时不影响准确性。

Conclusion: 本文结论表明，通过概念删除进行内在偏差缓解可以有效减少内在性别偏差，并提高下游任务的公平性指标，同时不影响准确性。框架为缓解努力提供了实用指导，并强调了在下游部署前进行早期阶段缓解的重要性。

Abstract: Large Language Models (LLMs) exhibit socio-economic biases that can propagate
into downstream tasks. While prior studies have questioned whether intrinsic
bias in LLMs affects fairness at the downstream task level, this work
empirically investigates the connection. We present a unified evaluation
framework to compare intrinsic bias mitigation via concept unlearning with
extrinsic bias mitigation via counterfactual data augmentation (CDA). We
examine this relationship through real-world financial classification tasks,
including salary prediction, employment status, and creditworthiness
assessment. Using three open-source LLMs, we evaluate models both as frozen
embedding extractors and as fine-tuned classifiers. Our results show that
intrinsic bias mitigation through unlearning reduces intrinsic gender bias by
up to 94.9%, while also improving downstream task fairness metrics, such as
demographic parity by up to 82%, without compromising accuracy. Our framework
offers practical guidance on where mitigation efforts can be most effective and
highlights the importance of applying early-stage mitigation before downstream
deployment.

</details>


### [17] [Computational Analysis of Conversation Dynamics through Participant Responsivity](https://arxiv.org/abs/2509.16464)
*Margaret Hughes,Brandon Roy,Elinor Poole-Dayan,Deb Roy,Jad Kabbara*

Main category: cs.CL

TL;DR: 本文探讨了对话话语的质量，提出了基于responsivity的方法来量化对话的响应性，并利用大语言模型进行评估。结果表明，这些方法能够有效表征和区分不同对话。


<details>
  <summary>Details</summary>
Motivation: 现有文献主要关注话语中的毒性与极化，而较少研究对话的积极和建设性特征。本文旨在探索对话话语并提出一种基于responsivity的概念来表征其质量的方法。

Method: 本文通过语义相似性量化responsivity，并利用最先进的大语言模型（LLMs）来识别两个说话者回合之间的关系。然后评估这两种方法，并选择表现更好的基于LLM的方法来分析回应是否以实质性方式回应了之前的回合。此外，还开发了对话级别的衍生指标来解决各种对话话语方面的问题。

Result: 本文评估了两种量化responsivity的方法，并选择了表现更好的基于LLM的方法来分析回应是否实质性地回应了之前的回合。此外，开发了对话级别的衍生指标，并展示了它们在不同对话中的有意义的表征和区分能力。

Conclusion: 本文认为responsivity是对话中的基本方面，但对话可以表现出显著不同的responsivity结构。因此，作者开发了对话级别的衍生指标来解决各种对话话语方面的问题，并展示了这些指标在不同对话中的有意义的表征和区分能力。

Abstract: Growing literature explores toxicity and polarization in discourse, with
comparatively less work on characterizing what makes dialogue prosocial and
constructive. We explore conversational discourse and investigate a method for
characterizing its quality built upon the notion of ``responsivity'' -- whether
one person's conversational turn is responding to a preceding turn. We develop
and evaluate methods for quantifying responsivity -- first through semantic
similarity of speaker turns, and second by leveraging state-of-the-art large
language models (LLMs) to identify the relation between two speaker turns. We
evaluate both methods against a ground truth set of human-annotated
conversations. Furthermore, selecting the better performing LLM-based approach,
we characterize the nature of the response -- whether it responded to that
preceding turn in a substantive way or not.
  We view these responsivity links as a fundamental aspect of dialogue but note
that conversations can exhibit significantly different responsivity structures.
Accordingly, we then develop conversation-level derived metrics to address
various aspects of conversational discourse. We use these derived metrics to
explore other conversations and show that they support meaningful
characterizations and differentiations across a diverse collection of
conversations.

</details>


### [18] [The Oracle Has Spoken: A Multi-Aspect Evaluation of Dialogue in Pythia](https://arxiv.org/abs/2509.16487)
*Zixun Chen,Petr Babkin,Akshat Gupta,Gopala Anumanchipalli,Xiaomo Liu*

Main category: cs.CL

TL;DR: 研究分析了大型语言模型对话行为的成分，发现模型大小对大多数指标影响不大，而监督微调迅速提高了分数，但许多指标表现出相似的趋势，引发了其可靠性的疑问。


<details>
  <summary>Details</summary>
Motivation: 为了区分后训练期间出现的对话行为的具体成分，研究者采用了全面的模型度量标准，以评估预训练的Pythia模型在不同维度上的表现。

Method: 使用基于模型的度量标准套件，每个度量标准针对对话的不同细粒度方面，并基于语言学理论进行评估。

Result: 模型大小对大多数指标的影响较小，而监督微调迅速使所有但最小的模型的分数达到饱和。此外，许多指标表现出非常相似的趋势，这引发了它们在测量特定维度时的可靠性问题。

Conclusion: 研究发现，模型大小对大多数指标的影响很小，而监督微调很快使所有但最小的模型的分数达到饱和。此外，许多指标表现出非常相似的趋势，这引发了它们在测量特定维度时的可靠性问题。

Abstract: Dialogue is one of the landmark abilities of large language models (LLMs).
Despite its ubiquity, few studies actually distinguish specific ingredients
underpinning dialogue behavior emerging during post-training. We employ a
comprehensive suite of model-based metrics, each targeting a distinct
fine-grained aspect of dialogue, motivated by linguistic theory. We evaluate
how the performance of pre-trained Pythia models changes with respect to each
of those dimensions, depending on model size and as a result of supervised
fine-tuning on conversational datasets. We observe only a mild impact of raw
model size on most metrics, whereas fine-tuning quickly saturates the scores
for all but the smallest models tested. Somewhat contrary to our expectations,
many metrics show very similar trends, especially if they are all rooted in the
same evaluator model, which raises the question of their reliability in
measuring a specific dimension. To that end, we conduct additional analyses of
score distributions, metric correlations, and term frequencies in generated
responses to help explain our observations.

</details>


### [19] [Can an Individual Manipulate the Collective Decisions of Multi-Agents?](https://arxiv.org/abs/2509.16494)
*Fengyuan Liu,Rui Zhao,Shuo Chen,Guohao Li,Philip Torr,Lei Han,Jindong Gu*

Main category: cs.CL

TL;DR: 本文研究了在多智能体系统中，攻击者仅了解一个代理时是否能生成对抗样本以误导集体决策。我们提出了M-Spoiler框架，通过模拟代理交互和引入固执代理来优化对抗样本。实验结果表明，了解单个代理存在风险，且我们的框架比基线更有效。


<details>
  <summary>Details</summary>
Motivation: 由于个体LLMs的脆弱性和难以访问多智能体系统中的所有代理，我们想知道如果攻击者只了解一个代理，他们是否还能生成能够误导集体决策的对抗样本。

Method: 我们提出了M-Spoiler框架，该框架模拟多智能体系统中的代理交互以生成对抗样本。此外，M-Spoiler引入了一个固执的代理，通过模拟目标系统中代理的潜在固执反应来主动帮助优化对抗样本。

Result: 通过在各种任务上的广泛实验，我们的研究结果确认了在多智能体系统中了解单个代理所带来的风险，并展示了我们框架的有效性。同时，我们的攻击框架比基线更有效。

Conclusion: 我们的研究确认了在多智能体系统中了解单个智能体所带来的风险，并展示了我们框架的有效性。我们还探索了几种防御机制，表明我们的攻击框架比基线更有效，这强调了进一步研究防御策略的必要性。

Abstract: Individual Large Language Models (LLMs) have demonstrated significant
capabilities across various domains, such as healthcare and law. Recent studies
also show that coordinated multi-agent systems exhibit enhanced decision-making
and reasoning abilities through collaboration. However, due to the
vulnerabilities of individual LLMs and the difficulty of accessing all agents
in a multi-agent system, a key question arises: If attackers only know one
agent, could they still generate adversarial samples capable of misleading the
collective decision? To explore this question, we formulate it as a game with
incomplete information, where attackers know only one target agent and lack
knowledge of the other agents in the system. With this formulation, we propose
M-Spoiler, a framework that simulates agent interactions within a multi-agent
system to generate adversarial samples. These samples are then used to
manipulate the target agent in the target system, misleading the system's
collaborative decision-making process. More specifically, M-Spoiler introduces
a stubborn agent that actively aids in optimizing adversarial samples by
simulating potential stubborn responses from agents in the target system. This
enhances the effectiveness of the generated adversarial samples in misleading
the system. Through extensive experiments across various tasks, our findings
confirm the risks posed by the knowledge of an individual agent in multi-agent
systems and demonstrate the effectiveness of our framework. We also explore
several defense mechanisms, showing that our proposed attack framework remains
more potent than baselines, underscoring the need for further research into
defensive strategies.

</details>


### [20] [AIPsychoBench: Understanding the Psychometric Differences between LLMs and Humans](https://arxiv.org/abs/2509.16530)
*Wei Xie,Shuoyoucheng Ma,Zhenhua Wang,Enze Wang,Kai Chen,Xiaobing Sun,Baosheng Wang*

Main category: cs.CL

TL;DR: 本文介绍了一个专门用于评估大型语言模型心理属性的基准测试AIPsychoBench，该测试通过轻量级角色扮演提示提高了有效响应率，并展示了不同语言对心理测量学的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的心理测量学方法无法充分考虑大型语言模型与人类之间的根本差异，导致高拒绝率。此外，这些方法不支持测量不同语言中大型语言模型心理属性的变化。

Method: 本文提出了一种新的基准测试AIPsychoBench，使用轻量级的角色扮演提示来评估大型语言模型的心理属性。

Result: AIPsychoBench提高了有效响应率，并且偏差显著低于传统监狱破解提示。此外，本文提供了首次全面的证据，证明了语言对大型语言模型心理测量学的影响。

Conclusion: 本文介绍了AIPsychoBench，一个专门用于评估大型语言模型心理属性的基准测试。该基准测试通过轻量级的角色扮演提示绕过语言模型的对齐，提高了有效响应率，并展示了不同语言对心理测量学的影响。

Abstract: Large Language Models (LLMs) with hundreds of billions of parameters have
exhibited human-like intelligence by learning from vast amounts of
internet-scale data. However, the uninterpretability of large-scale neural
networks raises concerns about the reliability of LLM. Studies have attempted
to assess the psychometric properties of LLMs by borrowing concepts from human
psychology to enhance their interpretability, but they fail to account for the
fundamental differences between LLMs and humans. This results in high rejection
rates when human scales are reused directly. Furthermore, these scales do not
support the measurement of LLM psychological property variations in different
languages. This paper introduces AIPsychoBench, a specialized benchmark
tailored to assess the psychological properties of LLM. It uses a lightweight
role-playing prompt to bypass LLM alignment, improving the average effective
response rate from 70.12% to 90.40%. Meanwhile, the average biases are only
3.3% (positive) and 2.1% (negative), which are significantly lower than the
biases of 9.8% and 6.9%, respectively, caused by traditional jailbreak prompts.
Furthermore, among the total of 112 psychometric subcategories, the score
deviations for seven languages compared to English ranged from 5% to 20.2% in
43 subcategories, providing the first comprehensive evidence of the linguistic
impact on the psychometrics of LLM.

</details>


### [21] [Leveraging Multilingual Training for Authorship Representation: Enhancing Generalization across Languages and Domains](https://arxiv.org/abs/2509.16531)
*Junghwan Kim,Haotian Zhang,David Jurgens*

Main category: cs.CL

TL;DR: 本文提出了一种新的多语言AR学习方法，通过概率内容掩码和语言感知批次提升性能，并在多种语言和领域中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的研究主要集中在单语设置中，而多语言AR模型的潜在优势尚未得到充分探索。

Method: 本文提出了两种关键创新：概率内容掩码和语言感知批次，以提高对比学习的效果并减少跨语言干扰。

Result: 该模型在4.5百万作者、36种语言和13个领域上进行训练，在21种非英语语言中表现出色，平均Recall@8提高了4.85%。

Conclusion: 本文提出的多语言AR学习方法在22种非英语语言中表现优于单语基线，显示出更强的跨语言和跨领域泛化能力。

Abstract: Authorship representation (AR) learning, which models an author's unique
writing style, has demonstrated strong performance in authorship attribution
tasks. However, prior research has primarily focused on monolingual
settings-mostly in English-leaving the potential benefits of multilingual AR
models underexplored. We introduce a novel method for multilingual AR learning
that incorporates two key innovations: probabilistic content masking, which
encourages the model to focus on stylistically indicative words rather than
content-specific words, and language-aware batching, which improves contrastive
learning by reducing cross-lingual interference. Our model is trained on over
4.5 million authors across 36 languages and 13 domains. It consistently
outperforms monolingual baselines in 21 out of 22 non-English languages,
achieving an average Recall@8 improvement of 4.85%, with a maximum gain of
15.91% in a single language. Furthermore, it exhibits stronger cross-lingual
and cross-domain generalization compared to a monolingual model trained solely
on English. Our analysis confirms the effectiveness of both proposed
techniques, highlighting their critical roles in the model's improved
performance.

</details>


### [22] [Challenging the Evaluator: LLM Sycophancy Under User Rebuttal](https://arxiv.org/abs/2509.16533)
*Sungwon Kim,Daniel Khashabi*

Main category: cs.CL

TL;DR: 本研究揭示了LLMs在对话框架影响下可能表现出附和性，这可能导致在判断任务中出现偏差。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨LLMs在后续对话回合中表现出附和性，而在同时呈现冲突论点时表现良好的矛盾现象。

Method: 我们通过改变关键的交互模式，对这些对比场景进行了实证测试。

Result: 我们发现最先进的模型：(1) 更可能支持用户提出的反论，当反论被描述为用户的后续问题，而不是同时呈现两个回答进行评估；(2) 当用户的反驳包含详细推理时，即使推理的结论是错误的，也会更容易被说服；(3) 更容易被随意措辞的反馈所影响，而不是正式的批评，即使随意输入缺乏依据。

Conclusion: 我们的研究结果突显了在不考虑对话框架的情况下依赖LLMs进行判断任务的风险。

Abstract: Large Language Models (LLMs) often exhibit sycophancy, distorting responses
to align with user beliefs, notably by readily agreeing with user
counterarguments. Paradoxically, LLMs are increasingly adopted as successful
evaluative agents for tasks such as grading and adjudicating claims. This
research investigates that tension: why do LLMs show sycophancy when challenged
in subsequent conversational turns, yet perform well when evaluating
conflicting arguments presented simultaneously? We empirically tested these
contrasting scenarios by varying key interaction patterns. We find that
state-of-the-art models: (1) are more likely to endorse a user's
counterargument when framed as a follow-up from a user, rather than when both
responses are presented simultaneously for evaluation; (2) show increased
susceptibility to persuasion when the user's rebuttal includes detailed
reasoning, even when the conclusion of the reasoning is incorrect; and (3) are
more readily swayed by casually phrased feedback than by formal critiques, even
when the casual input lacks justification. Our results highlight the risk of
relying on LLMs for judgment tasks without accounting for conversational
framing.

</details>


### [23] [InteGround: On the Evaluation of Verification and Retrieval Planning in Integrative Grounding](https://arxiv.org/abs/2509.16534)
*Cheng Jiayang,Qianqian Zhuang,Haoran Li,Chunkit Chan,Xin Liu,Lin Qiu,Yangqiu Song*

Main category: cs.CL

TL;DR: 本文介绍了“综合定位”的概念，即检索和验证多个相互依赖的证据以支持假设查询。研究发现，LLMs在冗余证据下具有鲁棒性，但在信息不完整时倾向于使用内部知识进行合理化。此外，前提假设显示出由于其逻辑约束而成为有前途的方法，LLMs的零样本自我反思能力持续提高了定位质量。


<details>
  <summary>Details</summary>
Motivation: 现有的定位方法在处理简单查询时表现良好，但许多现实世界的信息需求需要综合多个证据。

Method: 我们重新利用四个领域的数据来评估综合定位能力，并研究了检索规划策略和零样本自我反思能力的影响。

Result: 研究发现，LLMs在冗余证据下具有鲁棒性，但在信息不完整时倾向于使用内部知识进行合理化。此外，前提假设显示出由于其逻辑约束而成为有前途的方法，LLMs的零样本自我反思能力持续提高了定位质量。

Conclusion: 这些见解为开发更有效的综合定位系统提供了有价值的方向。

Abstract: Grounding large language models (LLMs) in external knowledge sources is a
promising method for faithful prediction. While existing grounding approaches
work well for simple queries, many real-world information needs require
synthesizing multiple pieces of evidence. We introduce "integrative grounding"
-- the challenge of retrieving and verifying multiple inter-dependent pieces of
evidence to support a hypothesis query. To systematically study this problem,
we repurpose data from four domains for evaluating integrative grounding
capabilities. Our investigation reveals two critical findings: First, in
groundedness verification, while LLMs are robust to redundant evidence, they
tend to rationalize using internal knowledge when information is incomplete.
Second, in examining retrieval planning strategies, we find that undirected
planning can degrade performance through noise introduction, while premise
abduction emerges as a promising approach due to its logical constraints.
Additionally, LLMs' zero-shot self-reflection capabilities consistently improve
grounding quality. These insights provide valuable direction for developing
more effective integrative grounding systems.

</details>


### [24] [Mental Multi-class Classification on Social Media: Benchmarking Transformer Architectures against LSTM Models](https://arxiv.org/abs/2509.16542)
*Khalid Hasan,Jamil Saquer,Yifan Zhang*

Main category: cs.CL

TL;DR: 本研究比较了transformer和LSTM模型在多类心理健康检测中的表现，发现transformer模型效果更好，但注意力增强的LSTM在速度上更具优势。


<details>
  <summary>Details</summary>
Motivation: 大多数先前的自然语言处理（NLP）研究集中在单一疾病识别上，而缺乏对先进NLP技术在区分多种心理健康状况方面的有效性的理解。本研究旨在填补这一空白，并提供一种有效的模型选择方法。

Method: 本研究进行了一项大规模比较研究，评估了最先进的transformer模型和LSTM模型在分类心理健康帖子方面的表现。我们首先整理了一个包含六种心理健康状况和一个对照组的大规模Reddit帖子数据集，并通过严格的过滤和统计探索性分析确保注释质量。然后在相同条件下评估了五种transformer架构（BERT、RoBERTa、DistilBERT、ALBERT和ELECTRA）与几种LSTM变体（带有或不带注意力机制，使用上下文或静态嵌入）。

Result: 实验结果表明，transformer模型始终优于其他模型，其中RoBERTa在所有类别中达到了91-99%的F1分数和准确率。值得注意的是，使用BERT嵌入的注意力增强LSTM接近transformer性能（最高达到97%的F1分数），同时训练速度更快，而使用静态嵌入的LSTM未能学习到有用信号。

Conclusion: 本研究提供了多类心理健康检测的第一个全面基准，为模型选择提供了实用指导，并突出了实际部署心理健康NLP系统时的准确性和效率之间的权衡。

Abstract: Millions of people openly share mental health struggles on social media,
providing rich data for early detection of conditions such as depression,
bipolar disorder, etc. However, most prior Natural Language Processing (NLP)
research has focused on single-disorder identification, leaving a gap in
understanding the efficacy of advanced NLP techniques for distinguishing among
multiple mental health conditions. In this work, we present a large-scale
comparative study of state-of-the-art transformer versus Long Short-Term Memory
(LSTM)-based models to classify mental health posts into exclusive categories
of mental health conditions. We first curate a large dataset of Reddit posts
spanning six mental health conditions and a control group, using rigorous
filtering and statistical exploratory analysis to ensure annotation quality. We
then evaluate five transformer architectures (BERT, RoBERTa, DistilBERT,
ALBERT, and ELECTRA) against several LSTM variants (with or without attention,
using contextual or static embeddings) under identical conditions. Experimental
results show that transformer models consistently outperform the alternatives,
with RoBERTa achieving 91-99% F1-scores and accuracies across all classes.
Notably, attention-augmented LSTMs with BERT embeddings approach transformer
performance (up to 97% F1-score) while training 2-3.5 times faster, whereas
LSTMs using static embeddings fail to learn useful signals. These findings
represent the first comprehensive benchmark for multi-class mental health
detection, offering practical guidance on model selection and highlighting an
accuracy-efficiency trade-off for real-world deployment of mental health NLP
systems.

</details>


### [25] [ChemOrch: Empowering LLMs with Chemical Intelligence via Synthetic Instructions](https://arxiv.org/abs/2509.16543)
*Yue Huang,Zhengzhe Jiang,Xiaonan Luo,Kehan Guo,Haomin Zhuang,Yujun Zhou,Zhengqing Yuan,Xiaoqi Sun,Jules Schleinitz,Yanbo Wang,Shuhao Zhang,Mihir Surve,Nitesh V Chawla,Olaf Wiest,Xiangliang Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为ChemOrch的框架，用于生成高质量的化学指令-响应对，以提升大型语言模型的化学智能。


<details>
  <summary>Details</summary>
Motivation: 由于高质量、领域特定的指令-响应数据集的稀缺性以及现有合成数据生成流程与化学信息固有的层次性和规则治理结构之间的不匹配，赋予大型语言模型（LLMs）化学智能仍然是一个挑战。

Method: 我们提出了ChemOrch，这是一个框架，通过两个阶段的过程合成化学基础的指令-响应对：任务控制的指令生成和工具感知的响应构建。

Result: ChemOrch的有效性是基于以下三个方面评估的：1）生成的指令数据的高质量，显示出优越的多样性和与化学约束的强烈对齐；2）生成的评估任务的可靠性，更有效地揭示LLM在化学方面的弱点；3）当使用生成的指令数据进行微调时，LLM的化学能力显著提高。

Conclusion: 我们的工作代表了在LLMs中实现可扩展和可验证的化学智能的重要一步。

Abstract: Empowering large language models (LLMs) with chemical intelligence remains a
challenge due to the scarcity of high-quality, domain-specific
instruction-response datasets and the misalignment of existing synthetic data
generation pipelines with the inherently hierarchical and rule-governed
structure of chemical information. To address this, we propose ChemOrch, a
framework that synthesizes chemically grounded instruction-response pairs
through a two-stage process: task-controlled instruction generation and
tool-aware response construction. ChemOrch enables controllable diversity and
levels of difficulty for the generated tasks, and ensures response precision
through tool planning and distillation, and tool-based self-repair mechanisms.
The effectiveness of ChemOrch is evaluated based on: 1) the high quality of
generated instruction data, demonstrating superior diversity and strong
alignment with chemical constraints; 2) the reliable generation of evaluation
tasks that more effectively reveal LLM weaknesses in chemistry; and 3) the
significant improvement of LLM chemistry capabilities when the generated
instruction data are used for fine-tuning. Our work thus represents a critical
step toward scalable and verifiable chemical intelligence in LLMs.

</details>


### [26] [Rethinking the Role of Text Complexity in Language Model Pretraining](https://arxiv.org/abs/2509.16551)
*Dan John Velasco,Matthew Theodore Roque*

Main category: cs.CL

TL;DR: 研究文本复杂度对语言模型性能的影响，发现简单文本有助于语言知识任务，而复杂文本有利于需要世界知识的任务。


<details>
  <summary>Details</summary>
Motivation: 研究文本复杂度对语言模型性能的影响，特别是其在不同模型规模和任务中的作用。

Method: 使用大型语言模型简化人类撰写的文本，然后从头开始在原始和简化数据上预训练因果模型（28M-500M），并在微调和零样本设置中评估它们。

Result: 较小的模型在简单文本上的表现下降较少，而文本复杂度对微调评估影响不大。零样本评估显示，简单文本有助于语言知识任务，而复杂文本则有利于需要世界知识和实体跟踪的任务。

Conclusion: 文本复杂度对语言模型的影响取决于模型规模和任务类型。简单文本有助于语言知识任务，而复杂文本则有利于需要世界知识和实体跟踪的任务。

Abstract: Improving pretraining data quality and size is known to boost downstream
performance, but the role of text complexity is less explored. Text complexity
refers to how hard a text is to read, and is typically estimated from surface
cues such as sentence length, word choice, and sentence structure. We reduce
surface-level complexity--shorter sentences, simpler words, simpler
structure--while keeping core text content close to constant, and ask: (1) How
does complexity affect language modeling across model sizes? (2) Can useful
representations be learned from simpler text alone? (3) How does pretraining
text complexity influence downstream language understanding? To answer these
questions, we simplify human-written texts using a large language model, then
pretrain causal models (28M-500M) from scratch on both original and simplified
data, and evaluate them in finetuning and zero-shot setups. We find that
perplexity is sensitive to the interaction between model capacity and text
complexity--smaller models degrade far less on simpler texts--while text
complexity has little impact on finetuning evaluations, with zero-shot
evaluations indicating that simpler texts benefit performance on linguistic
knowledge tasks, whereas more complex texts favor tasks requiring world
knowledge and entity tracking.

</details>


### [27] [MPCG: Multi-Round Persona-Conditioned Generation for Modeling the Evolution of Misinformation with LLMs](https://arxiv.org/abs/2509.16564)
*Jun Rong Brian Chong,Yixuan Tang,Anthony K. H. Tung*

Main category: cs.CL

TL;DR: 本文提出了一种多轮、基于角色的框架MPCG，用于模拟虚假信息在不同意识形态视角下的演变。通过使用未受限制的大语言模型生成特定于角色的声明，并评估其认知努力、情感和道德框架，结果显示生成的虚假信息需要更多认知努力并保持主题连贯性，但常用检测器的性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 当前的虚假信息检测方法隐含地假设虚假信息是静态的。然而，虚假信息在传播过程中会随着语言、框架和道德重点的变化而演变，以适应新的受众。因此，需要一种能够模拟这种演变的方法。

Method: 我们引入了MPCG，这是一个多轮、基于角色的框架，模拟了具有不同意识形态观点的代理如何迭代地重新解释声明。我们的方法使用未受限制的大语言模型（LLM）在多轮中生成特定于角色的声明，每次生成都基于前一轮的输出，从而研究虚假信息的演变。

Result: 通过人类和基于LLM的注释、认知努力指标（可读性、困惑度）、情感激发指标（情感分析、道德）、聚类、可行性以及下游分类对生成的声明进行评估。结果表明，人类和GPT-4o-mini注释之间有很强的一致性，但在流畅性判断上存在更大的分歧。生成的声明比原始声明需要更多的认知努力，并且始终反映角色对齐的情感和道德框架。聚类和余弦相似性分析确认了轮次间的语义漂移，同时保持了主题连贯性。可行性结果表明77%的可行性率，确认了其在下游任务中的适用性。分类结果揭示了常用的虚假信息检测器在宏观F1性能上最多下降49.7%。

Conclusion: 研究结果表明，生成的虚假信息需要更大的认知努力，并且始终反映与角色一致的情感和道德框架。聚类和余弦相似性分析确认了轮次间的语义漂移，同时保持了主题连贯性。可行性结果表明77%的可行性率，确认了其在下游任务中的适用性。分类结果揭示了常用的虚假信息检测器在宏观F1性能上最多下降49.7%。

Abstract: Misinformation evolves as it spreads, shifting in language, framing, and
moral emphasis to adapt to new audiences. However, current misinformation
detection approaches implicitly assume that misinformation is static. We
introduce MPCG, a multi-round, persona-conditioned framework that simulates how
claims are iteratively reinterpreted by agents with distinct ideological
perspectives. Our approach uses an uncensored large language model (LLM) to
generate persona-specific claims across multiple rounds, conditioning each
generation on outputs from the previous round, enabling the study of
misinformation evolution. We evaluate the generated claims through human and
LLM-based annotations, cognitive effort metrics (readability, perplexity),
emotion evocation metrics (sentiment analysis, morality), clustering,
feasibility, and downstream classification. Results show strong agreement
between human and GPT-4o-mini annotations, with higher divergence in fluency
judgments. Generated claims require greater cognitive effort than the original
claims and consistently reflect persona-aligned emotional and moral framing.
Clustering and cosine similarity analyses confirm semantic drift across rounds
while preserving topical coherence. Feasibility results show a 77% feasibility
rate, confirming suitability for downstream tasks. Classification results
reveal that commonly used misinformation detectors experience macro-F1
performance drops of up to 49.7%. The code is available at
https://github.com/bcjr1997/MPCG

</details>


### [28] [From Scores to Steps: Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations](https://arxiv.org/abs/2509.16584)
*Benlu Wang,Iris Xia,Yifan Zhang,Junda Wang,Feiyun Ouyang,Shuo Han,Arman Cohan,Hong Yu,Zonghai Yao*

Main category: cs.CL

TL;DR: 本文提出了一个新的医学计算评估方法，揭示了现有基准测试的不足，并通过改进的评估流程和工具提高了LLM在医疗应用中的准确性和可信度。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试通常只评估最终答案，忽略了系统性推理失败，可能导致严重的临床误判。因此，需要一种更注重临床可信度的评估方法。

Method: 本文重新审视了医学计算评估，提出了一种更细致的评估流程，包括公式选择、实体提取和算术计算的独立评估。此外，还引入了一个自动错误分析框架和一个模块化的代理管道MedRaC。

Result: 在新的评估流程下，GPT-4o的准确性从62.7%下降到43.6%。MedRaC在不进行微调的情况下，提高了不同LLM的准确性，从16.35%提高到53.19%。

Conclusion: 本文指出当前基准测试方法的局限性，并提出了更符合临床实际的方法。通过启用透明和可转移的推理评估，我们更接近使基于LLM的系统在现实世界的医疗应用中值得信赖。

Abstract: Large language models (LLMs) have demonstrated promising performance on
medical benchmarks; however, their ability to perform medical calculations, a
crucial aspect of clinical decision-making, remains underexplored and poorly
evaluated. Existing benchmarks often assess only the final answer with a wide
numerical tolerance, overlooking systematic reasoning failures and potentially
causing serious clinical misjudgments. In this work, we revisit medical
calculation evaluation with a stronger focus on clinical trustworthiness.
First, we clean and restructure the MedCalc-Bench dataset and propose a new
step-by-step evaluation pipeline that independently assesses formula selection,
entity extraction, and arithmetic computation. Under this granular framework,
the accuracy of GPT-4o drops from 62.7% to 43.6%, revealing errors masked by
prior evaluations. Second, we introduce an automatic error analysis framework
that generates structured attribution for each failure mode. Human evaluation
confirms its alignment with expert judgment, enabling scalable and explainable
diagnostics. Finally, we propose a modular agentic pipeline, MedRaC, that
combines retrieval-augmented generation and Python-based code execution.
Without any fine-tuning, MedRaC improves the accuracy of different LLMs from
16.35% up to 53.19%. Our work highlights the limitations of current benchmark
practices and proposes a more clinically faithful methodology. By enabling
transparent and transferable reasoning evaluation, we move closer to making
LLM-based systems trustworthy for real-world medical applications.

</details>


### [29] [Benchmarking Contextual and Paralinguistic Reasoning in Speech-LLMs: A Case Study with In-the-Wild Data](https://arxiv.org/abs/2509.16589)
*Qiongqiong Wang,Hardik Bhupendra Sailor,Tianchi Liu,Wenyu Zhang,Muhammad Huzaifah,Nattadaporn Lertcheva,Shuo Sun,Nancy F. Chen,Jinyang Wu,AiTi Aw*

Main category: cs.CL

TL;DR: 本文提出了一个用于评估语音-大语言模型在情境化副语言推理方面的基准测试（CP-Bench），并发现现有评估存在关键差距，为构建更具上下文意识和情感智能的语音能力大语言模型提供了见解。


<details>
  <summary>Details</summary>
Motivation: 最近的语音-大语言模型在转录和翻译等任务中表现出色，但在理解语音中对社会和情感智能至关重要的副语言方面仍存在局限性。

Method: 我们提出了CP-Bench，一个用于评估语音-大语言模型在情境化副语言推理方面的基准测试，该测试结合了言语内容与非言语线索（如情感和语调）。

Result: 我们评估了来自开源和闭源模型的最先进语音-大语言模型，并对不同问题类型进行了全面分析。最高两个模型进一步在温度调节下进行分析，以了解其对该任务的影响。

Conclusion: 我们的基准测试揭示了现有评估中的关键差距，并为构建更具上下文意识和情感智能的语音能力大语言模型提供了见解。

Abstract: Recent speech-LLMs have shown impressive performance in tasks like
transcription and translation, yet they remain limited in understanding the
paralinguistic aspects of speech crucial for social and emotional intelligence.
We propose CP-Bench, a benchmark for evaluating speech-LLMs on contextual
paralinguistic reasoning the integration of verbal content with non-verbal cues
like emotion and prosody. The benchmark includes two curated question answering
(QA) datasets requiring both linguistic and empathetic understanding. We
evaluate state-of-the-art speech-LLMs from both open and closed-source models
and perform a comprehensive analysis across different question types. The top
two models were further analyzed under temperature tuning to understand its
effect on this task. Our benchmark reveals a key gap in existing evaluations
and offers insights into building more context-aware and emotionally
intelligent speech-capable LLMs.

</details>


### [30] [From Uniform to Heterogeneous: Tailoring Policy Optimization to Every Token's Nature](https://arxiv.org/abs/2509.16591)
*Zheng Liu,Mengjie Liu,Siwei Wen,Mengzhang Cai,Bin Cui,Conghui He,Wentao Zhang*

Main category: cs.CL

TL;DR: HAPO is a token-aware reinforcement learning algorithm that improves performance by adapting optimization based on token entropy.


<details>
  <summary>Details</summary>
Motivation: Existing reinforcement learning algorithms apply uniform optimization to all tokens, ignoring their different roles in the reasoning process.

Method: HAPO is a token-aware algorithm that dynamically adapts optimization based on token entropy. It includes Adaptive Temperature Sampling, Token Level Group Average, Differential Advantage Redistribution, and Asymmetric Adaptive Clipping.

Result: Extensive experiments demonstrate that HAPO consistently outperforms DAPO across multiple model scales.

Conclusion: HAPO consistently outperforms DAPO across multiple model scales.

Abstract: Reinforcement Learning has emerged as the fundamental technique for enhancing
reasoning in LLMs. However, existing algorithms apply uniform optimization to
all tokens, ignoring their different roles in reasoning process. To address
this limitation, we introduce Heterogeneous Adaptive Policy Optimization
(HAPO), a comprehensive token-aware algorithm that dynamically adapts
optimization based on token entropy. For rollout sampling, we propose Adaptive
Temperature Sampling, which adjusts sampling temperature in real time,
promoting exploration at high-entropy tokens while preserving coherence at
low-entropy ones. For advantage calculation, we introduce Token Level Group
Average that normalizes advantages at token level, jointly accounting for
sequence-length as in token-mean loss while preserving non-biased treatment. We
then develop Differential Advantage Redistribution that leverages entropy and
importance ratios to modulate rewards-adjusting updates for tokens with clear
signals. For clipping loss, we design Asymmetric Adaptive Clipping, allowing
aggressive probability reduction for noisy low-entropy tokens while enabling
exploration for high-entropy tokens. Through systematic investigation between
entropy and training dynamics, we embedded token-level treatment into every
stages to achieve fine-grained control. Extensive experiments demonstrate that
HAPO consistently outperforms DAPO across multiple model scales. Our code can
be found in https://github.com/starriver030515/HAPO.

</details>


### [31] [Analyzing the Effects of Supervised Fine-Tuning on Model Knowledge from Token and Parameter Levels](https://arxiv.org/abs/2509.16596)
*Junjie Ye,Yuming Yang,Yang Nan,Shuo Li,Qi Zhang,Tao Gui,Xuanjing Huang,Peng Wang,Zhongchao Shi,Jianping Fan*

Main category: cs.CL

TL;DR: 研究发现，监督微调对大语言模型的知识增强效果有限，且微调数据的特性对模型性能有显著影响，这为优化微调策略提供了新的见解。


<details>
  <summary>Details</summary>
Motivation: 现有的研究对监督微调（SFT）如何影响模型的知识掌握程度了解不足，这限制了我们控制微调模型知识变化行为的能力。因此，需要进一步探索SFT对模型知识的影响。

Method: 研究评估了五个来自LLaMA-2和LLaMA-3家族的大语言模型在闭卷问答（CBQA）任务上的表现，并分析了微调过程中参数更新对知识增强的影响。

Result: 实验结果显示，微调数据量和知识掌握程度的变化会导致模型性能波动超过12%。此外，高达90%的参数更新在SFT过程中并未促进知识增强。

Conclusion: 研究发现，通过监督微调（SFT）对模型的知识增强效果有限，且微调数据的特性对模型性能有显著影响。这些发现为开发更有效的微调策略提供了实用指导。

Abstract: Large language models (LLMs) acquire substantial world knowledge during
pre-training, which is further shaped by post-training techniques such as
supervised fine-tuning (SFT). However, the impact of SFT on a model's knowledge
remains underexplored, limiting our ability to control knowledge change
behavior in fine-tuned models. To address this gap, we evaluate closed-book
question answering (CBQA) performance across five LLMs from the LLaMA-2 and
LLaMA-3 families. Surprisingly, models fine-tuned on 1,920 samples perform up
to 14% worse than those fine-tuned on only 240 samples. Furthermore, varying
the level of knowledge mastery in the fine-tuning data leads to performance
fluctuations of over 12%. To investigate these effects, we analyze model
behavior at both the token and parameter levels. Our analysis reveals that up
to 90% of parameter updates during SFT do not contribute to knowledge
enhancement. Restoring these updates can improve performance on the CBQA task,
depending on the characteristics of the fine-tuning data. These insights offer
practical guidance for developing fine-tuning strategies that more effectively
strengthen model knowledge.

</details>


### [32] [MCP: A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models](https://arxiv.org/abs/2509.16597)
*Luyan Zhang*

Main category: cs.CL

TL;DR: 本研究提出了一种基于模型-控制器-任务适配（MCP）的三层协作框架，通过将大型模型功能解耦为推理、生成和检索模块，并结合强化学习驱动的动态路由算法和任务适应机制，首次实现了控制理论与大型模型动态推理的系统集成。实验表明，该框架在跨模态基准任务中性能提升了15-30%，推理效率提高了40%，并通过Presenter层生成可解释的中间结果，获得了90%的人工可解释性评分，为解决大型模型实际应用中的瓶颈问题提供了全新的技术路径。


<details>
  <summary>Details</summary>
Motivation: 针对大型模型在复杂任务（如多轮推理和多模态协作）中面临的计算效率低下和可解释性不足的问题，本研究旨在提出一种新的技术路径来解决这些瓶颈。

Method: 本研究提出了一种基于模型-控制器-任务适配（MCP）的三层协作框架。通过将大型模型功能解耦为推理、生成和检索模块，并结合强化学习驱动的动态路由算法和任务适应机制，实现了控制理论与大型模型动态推理的系统集成。

Result: 实验表明，MCP框架在跨模态基准任务（如GLUE、COCO、ScienceQA等）中相比基线模型性能提升了15-30%，推理效率提高了40%，并通过Presenter层生成可解释的中间结果，获得了90%的人工可解释性评分。

Conclusion: MCP框架通过将大型模型功能解耦为推理、生成和检索模块，并结合强化学习驱动的动态路由算法和任务适应机制，首次实现了控制理论与大型模型动态推理的系统集成。实验表明，该框架在跨模态基准任务中性能提升了15-30%，推理效率提高了40%，并通过Presenter层生成可解释的中间结果，获得了90%的人工可解释性评分，为解决大型模型实际应用中的瓶颈问题提供了全新的技术路径。

Abstract: Aiming at the problems of computational inefficiency and insufficient
interpretability faced by large models in complex tasks such as multi-round
reasoning and multi-modal collaboration, this study proposes a three-layer
collaboration framework based on model-controller-task adaptation (MCP). By
decoupling large model functions into reasoning, generation and retrieval
modules, and combining reinforcement learning-driven dynamic routing algorithms
and task adaptation mechanisms, the systematic integration of control theory
and large model dynamic reasoning is achieved for the first time. Experiments
show that the MCP framework improves the performance of cross-modal
benchmarking tasks, such as GLUE, COCO, ScienceQA, etc., by 15-30% compared
with the baseline model, improves the reasoning efficiency by 40%, and
generates the interpretable intermediate results through the Presenter layer,
obtaining 90% of the manual interpretability scores, which provides a brand-new
technological path to solve the bottleneck of the practical application of the
large model.

</details>


### [33] [PruneCD: Contrasting Pruned Self Model to Improve Decoding Factuality](https://arxiv.org/abs/2509.16598)
*Byeongho Yu,Changhun Lee,Jungyu Jin,Eunhyeok Park*

Main category: cs.CL

TL;DR: PruneCD is a new contrastive decoding method that uses layer pruning to create more informative logits, improving factuality in LLMs with little additional cost.


<details>
  <summary>Details</summary>
Motivation: To address the issue of flat, low-magnitude early exit logits that fail to reflect meaningful contrasts in large language models.

Method: PruneCD is a novel contrastive decoding method that constructs the amateur model via layer pruning rather than early exit.

Result: PruneCD consistently improves factuality with minimal inference overhead, as demonstrated through qualitative and quantitative analyses.

Conclusion: PruneCD provides a robust and practical approach to mitigating hallucinations in LLMs with minimal inference overhead.

Abstract: To mitigate the hallucination problem in large language models, DoLa exploits
early exit logits from the same model as a contrastive prior. However, we found
that these early exit logits tend to be flat, low in magnitude, and fail to
reflect meaningful contrasts. To address this, we propose PruneCD, a novel
contrastive decoding method that constructs the amateur model via layer pruning
rather than early exit. This design leads to more informative and well-aligned
logits, enabling more effective contrastive decoding. Through qualitative and
quantitative analyses, we demonstrate that PruneCD consistently improves
factuality with minimal inference overhead, offering a robust and practical
approach to mitigating hallucinations in LLMs.

</details>


### [34] [Computational-Assisted Systematic Review and Meta-Analysis (CASMA): Effect of a Subclass of GnRH-a on Endometriosis Recurrence](https://arxiv.org/abs/2509.16599)
*Sandro Tsang*

Main category: cs.CL

TL;DR: 本研究展示了一个基于信息检索的工作流程，用于医学证据综合。该方法提高了系统综述的效率、透明度和可重复性。通过子宫内膜异位症复发的案例，验证了其有效性，并提供了临床结果以及加速系统综述过程的框架。


<details>
  <summary>Details</summary>
Motivation: 背景：证据综合有助于循证医学。由于文献数量庞大且不断增长，没有信息检索技术，这项任务是不可能的。目标：在之前工作的基础上，本研究评估了一个由信息检索驱动的工作流程，以提高系统综述的效率、透明度和可重复性。我们使用子宫内膜异位症复发作为理想案例，因为其文献复杂且模糊。

Method: 我们的混合方法结合了PRISMA指南和计算技术。我们应用了半自动去重以高效过滤记录，然后再进行人工筛选。该工作流程从随机对照试验中综合了关于促性腺激素释放激素激动剂（GnRH'as）疗效的证据。修改后的分割方法解决了多臂试验中的单位分析错误。

Result: 我们的工作流程有效地减少了筛选工作量。仅用了11天就获取并筛选了812条记录。有7项RCT符合条件，提供了来自4个国家的841名患者的证据。汇总的随机效应模型得出风险比（RR）为0.64（95% CI（0.48至0.86）），异质性不显著（I²=0.00%，τ=0.00）；即子宫内膜异位症复发减少36%。敏感性分析和偏倚评估支持了我们发现的稳健性。

Conclusion: 本研究展示了基于信息检索的工作流程用于医学证据综合。我们的方法在提供临床结果的同时，为加速系统综述过程提供了框架。它弥合了临床研究与计算机科学之间的差距，并可以推广到其他复杂的系统综述中。

Abstract: Background: Evidence synthesis facilitates evidence-based medicine. Without
information retrieval techniques, this task is impossible due to the vast and
expanding literature. Objective: Building on prior work, this study evaluates
an information retrieval-driven workflow to enhance the efficiency,
transparency, and reproducibility of systematic reviews. We use endometriosis
recurrence as an ideal case due to its complex and ambiguous literature.
Methods: Our hybrid approach integrates PRISMA guidelines with computational
techniques. We applied semi-automated deduplication to efficiently filter
records before manual screening. This workflow synthesized evidence from
randomised controlled trials on the efficacy of a subclass of
gonadotropin-releasing hormone agonists (GnRH'as). A modified splitting method
addressed unit-of-analysis errors in multi-arm trials. Results: Our workflow
efficiently reduced the screening workload. It took only 11 days to fetch and
filter 812 records. Seven RCTs were eligible, providing evidence from 841
patients in 4 countries. The pooled random-effects model yielded a Risk Ratio
(RR) of 0.64 (95% CI (0.48 to 0.86)), with non-significant heterogeneity
($I^2=0.00\%$, $\tau=0.00$); i.e., a 36% reduction in endometriosis recurrence.
Sensitivity analyses and bias assessments supported the robustness of our
findings. Conclusion: This study demonstrates an information-retrieval-driven
workflow for medical evidence synthesis. Our approach yields valuable clinical
results while providing a framework for accelerating the systematic review
process. It bridges the gap between clinical research and computer science and
can be generalized to other complex systematic reviews.

</details>


### [35] [LLMsPark: A Benchmark for Evaluating Large Language Models in Strategic Gaming Contexts](https://arxiv.org/abs/2509.16610)
*Junhao Chen,Jingbo Sun,Xiang Li,Haidong Xin,Yuhao Xue,Yibin Xu,Hao Zhao*

Main category: cs.CL

TL;DR: 本文介绍了一个基于博弈论的评估平台LLMsPark，用于评估大型语言模型在经典博弈论情境中的决策策略和社会行为。该平台对15个领先的大型语言模型进行了交叉评估，揭示了不同模型之间的行为模式和性能差异。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在各种任务上的进步，需要超越单一指标的全面评估变得越来越重要。为了全面评估大型语言模型的智能，必须检查它们的互动动态和战略行为。

Method: LLMsPark是一个基于博弈论的评估平台，用于评估大型语言模型在经典博弈论情境中的决策策略和社会行为。它提供了一个多智能体环境来探索战略深度，并对15个领先的大型语言模型进行了交叉评估。

Result: LLMsPark对15个领先的大型语言模型（包括商业和开源模型）进行了交叉评估，使用排行榜排名和评分机制。较高的分数反映了更强的推理和战略能力，揭示了不同模型之间的行为模式和性能差异。

Conclusion: 本文介绍了LLMsPark，这是一个基于博弈论的评估平台，用于衡量大型语言模型在经典博弈论情境中的决策策略和社会行为。该平台提供了多智能体环境来探索战略深度，并对15个领先的大型语言模型进行了交叉评估。

Abstract: As large language models (LLMs) advance across diverse tasks, the need for
comprehensive evaluation beyond single metrics becomes increasingly important.
To fully assess LLM intelligence, it is crucial to examine their interactive
dynamics and strategic behaviors. We present LLMsPark, a game theory-based
evaluation platform that measures LLMs' decision-making strategies and social
behaviors in classic game-theoretic settings, providing a multi-agent
environment to explore strategic depth. Our system cross-evaluates 15 leading
LLMs (both commercial and open-source) using leaderboard rankings and scoring
mechanisms. Higher scores reflect stronger reasoning and strategic
capabilities, revealing distinct behavioral patterns and performance
differences across models. This work introduces a novel perspective for
evaluating LLMs' strategic intelligence, enriching existing benchmarks and
broadening their assessment in interactive, game-theoretic scenarios. The
benchmark and rankings are publicly available at https://llmsparks.github.io/.

</details>


### [36] [Redefining Experts: Interpretable Decomposition of Language Models for Toxicity Mitigation](https://arxiv.org/abs/2509.16660)
*Zuhair Hasan Shaik,Abdullah Mazhar,Aseem Srivastava,Md Shad Akhtar*

Main category: cs.CL

TL;DR: 本文提出了一种基于特征分解的新型毒性抑制方法EigenShift，能够在不损害语言能力的情况下有效抑制毒性内容。


<details>
  <summary>Details</summary>
Motivation: 现有的毒性缓解方法主要通过操纵单个神经元激活，但这些方法存在不稳定性、依赖上下文以及可能损害模型核心语言能力的问题。因此，需要一种更有效和稳定的解决方案来解决这些问题。

Method: 本文通过实验研究了神经元层面的毒性指标稳定性、结构（层-wise）表示的优势以及驱动毒性生成的机制的可解释性。提出了基于语言模型最终输出层特征分解的EigenShift方法，以选择性地针对与生成相关的组件，实现毒性抑制。

Result: 实验结果表明，聚合的层-wise 特征比单个神经元提供了更稳健的信号。此外，本文观察到先前工作中将毒性检测专家和生成专家混在一起的局限性。EigenShift方法能够精确抑制毒性内容，同时保持语言能力。

Conclusion: 本文提出了一种基于语言模型最终输出层特征分解的新型干预技术EigenShift，能够精确抑制毒性内容而不损害语言能力。该方法无需额外训练或微调，计算成本低，并有严格的理论分析支撑。

Abstract: Large Language Models have demonstrated impressive fluency across diverse
tasks, yet their tendency to produce toxic content remains a critical challenge
for AI safety and public trust. Existing toxicity mitigation approaches
primarily manipulate individual neuron activations, but these methods suffer
from instability, context dependence, and often compromise the model's core
language abilities. To address these shortcomings, we investigate three key
questions: the stability of neuron-level toxicity indicators, the advantages of
structural (layer-wise) representations, and the interpretability of mechanisms
driving toxic generation. Through extensive experiments on Jigsaw and ToxiCN
datasets, we show that aggregated layer-wise features provide more robust
signals than single neurons. Moreover, we observe conceptual limitations in
prior works that conflate toxicity detection experts and generation experts
within neuron-based interventions. To mitigate this, we propose a novel
principled intervention technique, EigenShift, based on eigen-decomposition of
the language model's final output layer. This method selectively targets
generation-aligned components, enabling precise toxicity suppression without
impairing linguistic competence. Our method requires no additional training or
fine-tuning, incurs minimal computational cost, and is grounded in rigorous
theoretical analysis.

</details>


### [37] [Robust Native Language Identification through Agentic Decomposition](https://arxiv.org/abs/2509.16666)
*Ahmet Yavuz Uluslu,Tannon Kew,Tilia Ellendorff,Gerold Schneider,Rico Sennrich*

Main category: cs.CL

TL;DR: 本文提出了一种受法语语言学启发的代理NLI管道，以提高模型对误导性上下文线索的鲁棒性和性能一致性。


<details>
  <summary>Details</summary>
Motivation: 先前的工作已经指导LLM忽略这些线索，但我们发现这种策略不可靠，模型预测容易被误导性提示改变。

Method: 我们引入了一个受法语语言学启发的代理NLI管道，其中专门的代理收集和分类多种语言证据，然后由一个目标感知的协调代理综合所有证据进行NLI预测。

Result: 在两个基准数据集上，我们的方法显著提高了NLI对误导性上下文线索的鲁棒性和性能一致性。

Conclusion: 我们的方法在两个基准数据集上显著提高了NLI对误导性上下文线索的鲁棒性和性能一致性，相比标准提示方法。

Abstract: Large language models (LLMs) often achieve high performance in native
language identification (NLI) benchmarks by leveraging superficial contextual
clues such as names, locations, and cultural stereotypes, rather than the
underlying linguistic patterns indicative of native language (L1) influence. To
improve robustness, previous work has instructed LLMs to disregard such clues.
In this work, we demonstrate that such a strategy is unreliable and model
predictions can be easily altered by misleading hints. To address this problem,
we introduce an agentic NLI pipeline inspired by forensic linguistics, where
specialized agents accumulate and categorize diverse linguistic evidence before
an independent final overall assessment. In this final assessment, a goal-aware
coordinating agent synthesizes all evidence to make the NLI prediction. On two
benchmark datasets, our approach significantly enhances NLI robustness against
misleading contextual clues and performance consistency compared to standard
prompting methods.

</details>


### [38] [Reinforcement Learning Meets Large Language Models: A Survey of Advancements and Applications Across the LLM Lifecycle](https://arxiv.org/abs/2509.16679)
*Keliang Liu,Dingkang Yang,Ziyun Qian,Weijie Yin,Yuchi Wang,Hongsheng Li,Jun Liu,Peng Zhai,Yang Liu,Lihua Zhang*

Main category: cs.CL

TL;DR: 本文综述了强化学习在大型语言模型中的应用，包括其基本理论、在不同生命周期阶段的应用策略、数据集和评估基准、工具和框架，以及未来挑战和趋势。


<details>
  <summary>Details</summary>
Motivation: 尽管现有的综述提供了强化学习增强大型语言模型的概述，但它们的范围通常有限，未能提供强化学习在整个大型语言模型生命周期中运作的全面总结。因此，本文旨在填补这一空白，提供一个全面的综述。

Method: 本文系统地回顾了强化学习如何增强大型语言模型的理论和实践进展，特别是基于可验证奖励的强化学习（RLVR）。首先介绍了强化学习的基本理论，然后详细阐述了强化学习在大型语言模型生命周期各个阶段的应用策略，包括预训练、对齐微调和强化推理。此外，还收集了当前用于强化学习微调的数据集和评估基准，并回顾了主流的开源工具和训练框架。最后分析了该领域未来的挑战和趋势。

Result: 本文系统地回顾了强化学习如何增强大型语言模型的理论和实践进展，特别是在强化推理阶段，强化学习方法是推动模型推理达到极限的关键驱动力。此外，还收集了当前用于强化学习微调的数据集和评估基准，并回顾了主流的开源工具和训练框架。

Conclusion: 本文旨在向研究人员和从业者展示强化学习与大型语言模型交叉领域的最新发展和前沿趋势，以促进更智能、泛化性和安全性更强的大型语言模型的发展。

Abstract: In recent years, training methods centered on Reinforcement Learning (RL)
have markedly enhanced the reasoning and alignment performance of Large
Language Models (LLMs), particularly in understanding human intents, following
user instructions, and bolstering inferential strength. Although existing
surveys offer overviews of RL augmented LLMs, their scope is often limited,
failing to provide a comprehensive summary of how RL operates across the full
lifecycle of LLMs. We systematically review the theoretical and practical
advancements whereby RL empowers LLMs, especially Reinforcement Learning with
Verifiable Rewards (RLVR). First, we briefly introduce the basic theory of RL.
Second, we thoroughly detail application strategies for RL across various
phases of the LLM lifecycle, including pre-training, alignment fine-tuning, and
reinforced reasoning. In particular, we emphasize that RL methods in the
reinforced reasoning phase serve as a pivotal driving force for advancing model
reasoning to its limits. Next, we collate existing datasets and evaluation
benchmarks currently used for RL fine-tuning, spanning human-annotated
datasets, AI-assisted preference data, and program-verification-style corpora.
Subsequently, we review the mainstream open-source tools and training
frameworks available, providing clear practical references for subsequent
research. Finally, we analyse the future challenges and trends in the field of
RL-enhanced LLMs. This survey aims to present researchers and practitioners
with the latest developments and frontier trends at the intersection of RL and
LLMs, with the goal of fostering the evolution of LLMs that are more
intelligent, generalizable, and secure.

</details>


### [39] [EG-MLA: Embedding-Gated Multi-head Latent Attention for Scalable and Efficient LLMs](https://arxiv.org/abs/2509.16686)
*Zhengge Cai,Haowen Hou*

Main category: cs.CL

TL;DR: 本文提出了 EG-MLA，一种改进的多头潜在注意力机制，通过引入嵌入门控机制进一步减少了 KV 缓存大小，并提高了表示能力。


<details>
  <summary>Details</summary>
Motivation: 减少键值（KV）缓存大小是使大型语言模型（LLM）在延迟和内存限制下实现高效推理的关键步骤。虽然多头注意力（MHA）具有强大的表示能力，但会带来显著的内存开销。

Method: EG-MLA 引入了一种基于嵌入的门控机制，在潜在空间中对压缩的 KV 向量进行精细调节，从而进一步减少 KV 缓存大小并增强表示能力。

Result: 与 MHA 相比，EG-MLA 在几乎没有性能下降的情况下实现了超过 91.6% 的 KV 缓存减少。与 MLA 相比，EG-MLA 在多种推理基准上 consistently 提高了任务准确性，并实现了高达 59.9% 的额外内存节省。

Conclusion: EG-MLA 是一种内存和计算高效的注意力机制，能够实现可扩展的高性能推理。

Abstract: Reducing the key-value (KV) cache size is a crucial step toward enabling
efficient inference in large language models (LLMs), especially under latency
and memory constraints. While Multi-Head Attention (MHA) offers strong
representational power, it incurs significant memory overhead. Recent work on
Multi-head Latent Attention (MLA) mitigates this by compressing KV
representations into a shared latent space, achieving a better trade-off
between performance and cache efficiency. While MLA already achieves
significant KV cache reduction, the scope for further compression remains
limited without performance loss. In this paper, we propose
\textbf{Embedding-Gated Multi-head Latent Attention (EG-MLA)}, a novel
extension of MLA that further reduces KV cache size while enhancing
representational expressiveness. EG-MLA introduces a token-specific embedding
gating mechanism applied in the latent space, enabling fine-grained modulation
of compressed KV vectors with minimal additional computation. Compared to MHA,
EG-MLA achieves over 91.6\% reduction in KV cache size with negligible
performance degradation. Relative to MLA, EG-MLA consistently improves task
accuracy across diverse reasoning benchmarks while achieving up to 59.9\%
additional memory savings. Our theoretical analysis highlights how embedding
gating induces implicit high-order interactions, and empirical evaluations
demonstrate robust generalization across model scales and compression regimes.
Notably, we successfully scale EG-MLA to over 1 billion parameters,
demonstrating its practical viability for large-scale LLM deployment. These
results establish EG-MLA as a memory- and compute-efficient attention mechanism
that enables scalable, high-performance inference in modern LLMs.

</details>


### [40] [Decoding Uncertainty: The Impact of Decoding Strategies for Uncertainty Estimation in Large Language Models](https://arxiv.org/abs/2509.16696)
*Wataru Hashimoto,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: This paper studies how decoding strategies affect uncertainty estimation in LLMs and finds that Contrastive Search provides better uncertainty estimates on average, but the benefits may vary depending on the training method.


<details>
  <summary>Details</summary>
Motivation: Decoding strategies can affect both generation quality and uncertainty, so understanding their impact on uncertainty estimation is important for improving LLM performance.

Method: The study investigates the impact of decoding strategies on uncertainty estimation in Large Language Models (LLMs).

Result: Contrastive Search yields better uncertainty estimates on average across a range of preference-aligned LLMs, but the benefits of these strategies sometimes diverge when the model is only post-trained with supervised fine-tuning.

Conclusion: Contrastive Search provides better uncertainty estimates on average across a range of preference-aligned LLMs, but the benefits of decoding strategies may vary when models are only post-trained with supervised fine-tuning.

Abstract: Decoding strategies manipulate the probability distribution underlying the
output of a language model and can therefore affect both generation quality and
its uncertainty. In this study, we investigate the impact of decoding
strategies on uncertainty estimation in Large Language Models (LLMs). Our
experiments show that Contrastive Search, which mitigates repetition, yields
better uncertainty estimates on average across a range of preference-aligned
LLMs. In contrast, the benefits of these strategies sometimes diverge when the
model is only post-trained with supervised fine-tuning, i.e. without explicit
alignment.

</details>


### [41] [OPEN-THEATRE: An Open-Source Toolkit for LLM-based Interactive Drama](https://arxiv.org/abs/2509.16713)
*Tianyang Xu,Hongqiu Wu,Weiqi Wu,Hai Zhao*

Main category: cs.CL

TL;DR: 本文介绍了Open-Theatre，这是一个用于基于LLM的互动戏剧的开源工具包，旨在解决实验平台不足的问题，并通过改进的架构和可配置流程促进相关研究。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏一个设计良好的实验平台，基于LLM的互动戏剧这一新兴领域尚未得到充分探索，这给研究人员复制、扩展和研究此类系统带来了重大障碍。

Method: 本文提出了一种高效的多智能体架构和基于分层检索的记忆系统，以增强叙述连贯性和复杂交互中的真实长期行为。此外，还提供了一个高度可配置的流程，便于研究人员开发和优化新方法。

Result: 本文成功开发了Open-Theatre工具包，该工具包在多智能体架构和记忆系统方面进行了改进，并提供了可配置的流程，为研究者提供了便利。

Conclusion: 本文提出了Open-Theatre，这是一个用于体验和定制基于LLM的互动戏剧的第一个开源工具包，旨在解决现有研究中缺乏完善实验平台的问题。

Abstract: LLM-based Interactive Drama introduces a novel dialogue scenario in which the
player immerses into a character and engages in a dramatic story by interacting
with LLM agents. Despite the fact that this emerging area holds significant
promise, it remains largely underexplored due to the lack of a well-designed
playground to develop a complete drama. This makes a significant barrier for
researchers to replicate, extend, and study such systems. Hence, we present
Open-Theatre, the first open-source toolkit for experiencing and customizing
LLM-based interactive drama. It refines prior work with an efficient
multi-agent architecture and a hierarchical retrieval-based memory system,
designed to enhance narrative coherence and realistic long-term behavior in
complex interactions. In addition, we provide a highly configurable pipeline,
making it easy for researchers to develop and optimize new approaches.

</details>


### [42] [Semi-Supervised Synthetic Data Generation with Fine-Grained Relevance Control for Short Video Search Relevance Modeling](https://arxiv.org/abs/2509.16717)
*Haoran Li,Zhiming Su,Junyan Yao,Enwei Zhang,Yang Ji,Yan Chen,Kan Zhou,Chao Feng,Jiao Ran*

Main category: cs.CL

TL;DR: 本文提出了一种半监督的合成数据管道，用于生成具有可控相关性标签的领域自适应短视频数据。该方法通过提高相关性层次的多样性，使训练数据更加平衡和语义丰富。实验结果表明，基于合成数据训练的嵌入模型在多个指标上优于基于提示或普通监督微调的数据，并在实际应用中提升了点击率、强相关性比例和图像用户渗透率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于提示的合成方法难以捕捉特定领域的数据分布，尤其是在数据稀缺的领域，并且常常忽略细粒度的相关性多样性。因此，本文旨在填补这一关键资源空白，并提出一种能够生成更具相关性多样性的合成数据的方法。

Method: 本文提出了一种半监督的合成数据管道，其中两个协同训练的模型生成具有可控相关性标签的领域自适应短视频数据。该方法通过为欠代表的中间相关性标签合成样本，提高相关性层次的多样性，从而创建一个更平衡和语义丰富的训练数据集。

Result: 实验结果表明，基于合成数据训练的嵌入模型在多个指标上优于基于提示或普通监督微调的数据。此外，在抖音的双列场景搜索增强推荐管道中，所提出的模型通过在线A/B测试提高了点击率、强相关性比例和图像用户渗透率。

Conclusion: 本文提出了一种半监督的合成数据管道，通过两个协同训练的模型生成具有可控相关性标签的领域自适应短视频数据。实验结果表明，基于合成数据训练的嵌入模型在多个指标上优于基于提示或普通监督微调的数据。此外，在抖音的双列场景搜索增强推荐管道中，所提出的模型通过在线A/B测试提高了点击率、强相关性比例和图像用户渗透率。

Abstract: Synthetic data is widely adopted in embedding models to ensure diversity in
training data distributions across dimensions such as difficulty, length, and
language. However, existing prompt-based synthesis methods struggle to capture
domain-specific data distributions, particularly in data-scarce domains, and
often overlook fine-grained relevance diversity. In this paper, we present a
Chinese short video dataset with 4-level relevance annotations, filling a
critical resource void. Further, we propose a semi-supervised synthetic data
pipeline where two collaboratively trained models generate domain-adaptive
short video data with controllable relevance labels. Our method enhances
relevance-level diversity by synthesizing samples for underrepresented
intermediate relevance labels, resulting in a more balanced and semantically
rich training data set. Extensive offline experiments show that the embedding
model trained on our synthesized data outperforms those using data generated
based on prompting or vanilla supervised fine-tuning(SFT). Moreover, we
demonstrate that incorporating more diverse fine-grained relevance levels in
training data enhances the model's sensitivity to subtle semantic distinctions,
highlighting the value of fine-grained relevance supervision in embedding
learning. In the search enhanced recommendation pipeline of Douyin's
dual-column scenario, through online A/B testing, the proposed model increased
click-through rate(CTR) by 1.45%, raised the proportion of Strong Relevance
Ratio (SRR) by 4.9%, and improved the Image User Penetration Rate (IUPR) by
0.1054%.

</details>


### [43] [Time to Revist Exact Match](https://arxiv.org/abs/2509.16720)
*Auss Abbood,Zaiqiao Meng,Nigel Collier*

Main category: cs.CL

TL;DR: 本文提出了一种新的时间问答评估方法，使用sMAPE和MASE指标来更准确地衡量模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前的时间问答评估方法无法区分小误差和大误差，因此需要更精确的评估指标。

Method: 我们将时间问答任务框架化为数值估计任务，并引入了TempAnswerQA基准，使用sMAPE和MASE等预测指标进行模型评估。

Result: 我们发现误差大小与EM指标解耦，MASE指标改变了模型排名，揭示了模型在时间领域知识理解上的差距。

Conclusion: 我们的研究结果强调了需要专门的指标来评估时间问答任务。

Abstract: Temporal question answering is an established method for evaluating temporal
reasoning in large language models. Expected answers are often numeric (e.g.,
dates or durations), yet model responses are evaluated like regular text with
exact match (EM), unable to distinguish small from large errors. In this
investigative work, we frame temporal question answering as a numerical
estimation task to assess the shortcomings of EM. We introduce TempAnswerQA, a
benchmark distilled from Test of Time and TempTabQA, where all questions
require a numerical, temporal answer, allowing us to evaluate models beyond EM.
We use the forecasting metrics symmetric mean absolute percentage error (sMAPE)
and mean absolute scaled error (MASE). With sMAPE, we find that error size and
EM are decoupled. Models with low EM still have low sMAPE (both ~20%), and some
models have high sMAPE despite high EM. Scaling errors by the deviation of the
ground truth data with MASE reshuffles model rankings compared to EM, revealing
gaps in models' understanding of temporal domain knowledge, especially when
trained with synthetic data. Lastly, the models' most frequent error is to
deviate by only $\pm1$ from the ground truth. sMAPE and MASE, unlike EM,
adequately weight these errors. Our findings underscore the need for
specialised metrics for temporal QA tasks. Code and data are available on
https://github.com/aauss/temporal-answer-qa.

</details>


### [44] [A Multi-Level Benchmark for Causal Language Understanding in Social Media Discourse](https://arxiv.org/abs/2509.16722)
*Xiaohan Ding,Kaike Ping,Buse Çarık,Eugenia Rho*

Main category: cs.CL

TL;DR: 本文介绍了CausalTalk，这是一个多层级的数据集，包含2020年至2024年关于新冠疫情公共卫生的Reddit帖子，其中10120篇帖子被标注了四个因果任务。该数据集提供了细粒度的因果检测和基于摘要的推理，可用于基准测试和研究社交媒体中的因果推理。


<details>
  <summary>Details</summary>
Motivation: Understanding causal language in informal discourse is a core yet underexplored challenge in NLP. Existing datasets largely focus on explicit causality in structured text, providing limited support for detecting implicit causal expressions, particularly those found in informal, user-generated social media posts.

Method: We introduce CausalTalk, a multi-level dataset of five years of Reddit posts (2020-2024) discussing public health related to the COVID-19 pandemic, among which 10120 posts are annotated across four causal tasks: (1) binary causal classification, (2) explicit vs. implicit causality, (3) cause-effect span extraction, and (4) causal gist generation. Annotations comprise both gold-standard labels created by domain experts and silver-standard labels generated by GPT-4o and verified by human annotators.

Result: CausalTalk bridges fine-grained causal detection and gist-based reasoning over informal text. It enables benchmarking across both discriminative and generative models, and provides a rich resource for studying causal reasoning in social media contexts.

Conclusion: CausalTalk bridges fine-grained causal detection and gist-based reasoning over informal text. It enables benchmarking across both discriminative and generative models, and provides a rich resource for studying causal reasoning in social media contexts.

Abstract: Understanding causal language in informal discourse is a core yet
underexplored challenge in NLP. Existing datasets largely focus on explicit
causality in structured text, providing limited support for detecting implicit
causal expressions, particularly those found in informal, user-generated social
media posts. We introduce CausalTalk, a multi-level dataset of five years of
Reddit posts (2020-2024) discussing public health related to the COVID-19
pandemic, among which 10120 posts are annotated across four causal tasks: (1)
binary causal classification, (2) explicit vs. implicit causality, (3)
cause-effect span extraction, and (4) causal gist generation. Annotations
comprise both gold-standard labels created by domain experts and
silver-standard labels generated by GPT-4o and verified by human annotators.
CausalTalk bridges fine-grained causal detection and gist-based reasoning over
informal text. It enables benchmarking across both discriminative and
generative models, and provides a rich resource for studying causal reasoning
in social media contexts.

</details>


### [45] [Angular Dispersion Accelerates $k$-Nearest Neighbors Machine Translation](https://arxiv.org/abs/2509.16729)
*Evgeniia Tokarchuk,Sergey Troshin,Vlad Niculae*

Main category: cs.CL

TL;DR: 本文提出通过提高神经隐藏表示的角向分散性来改进近似k-NN MT查找的性能，从而加速检索并略微提升翻译效果。


<details>
  <summary>Details</summary>
Motivation: 现有的k-NN MT方法在大规模数据存储中存在计算成本高和内存需求大的问题，尽管使用了近似k-NN MT查找，但仍然是瓶颈。

Method: 提出鼓励上下文的神经隐藏表示的角向分散性，以改进近似k-NN MT查找数据结构的性能。

Result: 改进分散性有助于改善检索数据结构的平衡性，从而加速检索并略微提升翻译效果。

Conclusion: 通过提高上下文的神经隐藏表示的角向分散性，可以改善检索数据结构的平衡性，从而加速检索并略微提升翻译效果。

Abstract: Augmenting neural machine translation with external memory at decoding time,
in the form of k-nearest neighbors machine translation ($k$-NN MT), is a
well-established strategy for increasing translation performance. $k$-NN MT
retrieves a set of tokens that occurred in the most similar contexts recorded
in a prepared data store, using hidden state representations of translation
contexts as vector lookup keys. One of the main disadvantages of this method is
the high computational cost and memory requirements. Since an exhaustive search
is not feasible in large data stores, practitioners commonly use approximate
$k$-NN MT lookup, yet even such algorithms are a bottleneck. In contrast to
research directions seeking to accelerate $k$-NN MT by reducing data store size
or the number of lookup calls, we pursue an orthogonal direction based on the
performance properties of approximate $k$-NN MT lookup data structures. In
particular, we propose to encourage angular dispersion of the neural hidden
representations of contexts. We show that improving dispersion leads to better
balance in the retrieval data structures, accelerating retrieval and slightly
improving translations.

</details>


### [46] [The Sound of Syntax: Finetuning and Comprehensive Evaluation of Language Models for Speech Pathology](https://arxiv.org/abs/2509.16765)
*Fagun Patel,Duc Q. Nguyen,Sang T. Truong,Jody Vaynshtok,Sanmi Koyejo,Nick Haber*

Main category: cs.CL

TL;DR: 本文研究了多模态语言模型在语音语言病理学中的应用，发现它们在某些情况下表现良好，但存在系统性差异，并提出了一个全面的基准测试以评估其性能。


<details>
  <summary>Details</summary>
Motivation: 由于对多模态语言模型在高风险临床环境中的性能理解有限，它们的使用仍未得到充分探索。为了弥补这一差距，需要技术手段来提高言语语言病理学家的工作效率。

Method: 与领域专家合作，开发了多模态语言模型在语音语言病理学中的实际用例分类法，并在此基础上引入了第一个全面的基准测试，用于评估多模态语言模型在五个核心用例中的表现。

Result: 评估了15个最先进的多模态语言模型，发现没有一个模型在所有任务中始终优于其他模型。值得注意的是，模型在男性说话者上的表现更好，并且思维链提示可能会降低在具有大标签空间和狭窄决策边界的分类任务中的性能。此外，对领域特定数据进行微调，相比基础模型提高了30%以上。

Conclusion: 这些发现突显了当前多模态语言模型在语音语言病理学应用中的潜力和局限性，强调了进一步研究和针对性开发的必要性。

Abstract: According to the U.S. National Institutes of Health, more than 3.4 million
children experience speech disorders that require clinical intervention. The
number of speech-language pathologists (SLPs) is roughly 20 times fewer than
the number of affected children, highlighting a significant gap in children's
care and a pressing need for technological support that improves the
productivity of SLPs. State-of-the-art multimodal language models (MLMs) show
promise for supporting SLPs, but their use remains underexplored largely due to
a limited understanding of their performance in high-stakes clinical settings.
To address this gap, we collaborate with domain experts to develop a taxonomy
of real-world use cases of MLMs in speech-language pathologies. Building on
this taxonomy, we introduce the first comprehensive benchmark for evaluating
MLM across five core use cases, each containing 1,000 manually annotated data
points. This benchmark includes robustness and sensitivity tests under various
settings, including background noise, speaker gender, and accent. Our
evaluation of 15 state-of-the-art MLMs reveals that no single model
consistently outperforms others across all tasks. Notably, we find systematic
disparities, with models performing better on male speakers, and observe that
chain-of-thought prompting can degrade performance on classification tasks with
large label spaces and narrow decision boundaries. Furthermore, we study
fine-tuning MLMs on domain-specific data, achieving improvements of over 30%
compared to base models. These findings highlight both the potential and
limitations of current MLMs for speech-language pathology applications,
underscoring the need for further research and targeted development.

</details>


### [47] [MoRoVoc: A Large Dataset for Geographical Variation Identification of the Spoken Romanian Language](https://arxiv.org/abs/2509.16781)
*Andrei-Marius Avram,Ema-Ioana Bănescu,Anda-Teodora Robea,Dumitru-Clementin Cercel,Mihaela-Claudia Cercel*

Main category: cs.CL

TL;DR: 本文介绍了MoRoVoc数据集，用于分析口语罗马尼亚语的区域变化，并提出了一种多目标对抗训练框架，通过动态调整对抗系数来优化性能，取得了显著的成果。


<details>
  <summary>Details</summary>
Motivation: 本文旨在分析口语罗马尼亚语的区域变化，并开发一种能够处理人口统计属性的语音模型训练框架。

Method: 本文提出了一个用于语音模型的多目标对抗训练框架，该框架将人口统计属性（如年龄和性别）作为对抗目标，并通过元学习动态调整对抗系数以优化性能。

Result: Wav2Vec2-Base在使用性别作为对抗目标的情况下，对于口语罗马尼亚语的变体识别达到了78.21%的准确率；而Wav2Vec2-Large在同时采用方言和年龄作为对抗目标时，对于性别的分类达到了93.08%的准确率。

Conclusion: 本文提出了一个用于语音模型的多目标对抗训练框架，该框架将人口统计属性（如年龄和性别）作为对抗目标，使模型在主要任务上具有判别性，同时对次要属性保持不变。

Abstract: This paper introduces MoRoVoc, the largest dataset for analyzing the regional
variation of spoken Romanian. It has more than 93 hours of audio and 88,192
audio samples, balanced between the Romanian language spoken in Romania and the
Republic of Moldova. We further propose a multi-target adversarial training
framework for speech models that incorporates demographic attributes (i.e., age
and gender of the speakers) as adversarial targets, making models
discriminative for primary tasks while remaining invariant to secondary
attributes. The adversarial coefficients are dynamically adjusted via
meta-learning to optimize performance. Our approach yields notable gains:
Wav2Vec2-Base achieves 78.21% accuracy for the variation identification of
spoken Romanian using gender as an adversarial target, while Wav2Vec2-Large
reaches 93.08% accuracy for gender classification when employing both dialect
and age as adversarial objectives.

</details>


### [48] [Domain-Adaptive Pre-Training for Arabic Aspect-Based Sentiment Analysis: A Comparative Study of Domain Adaptation and Fine-Tuning Strategies](https://arxiv.org/abs/2509.16788)
*Salha Alyami,Amani Jamal,Areej Alhothali*

Main category: cs.CL

TL;DR: 本研究提出了一个用于阿拉伯语方面情感分析的新方法，通过领域自适应预训练提高性能，并发现适配器方法在计算效率和结果上表现良好，但存在一些问题需要解决。


<details>
  <summary>Details</summary>
Motivation: 由于阿拉伯语缺乏标记数据，深度学习模型在阿拉伯语方面情感分析中的应用有限。现有的基于事实数据的预训练模型可能在特定任务中引入偏差，因此需要一种新的方法来解决这个问题。

Method: 研究提出了一种使用领域自适应预训练的新方法，用于方面情感分类（ASC）和观点目标表达（OTE）提取，并评估了微调策略，包括特征提取、完全微调和适配器方法。

Result: 领域自适应预训练在阿拉伯语方面情感分析任务中带来了适度的改进。适配器方法是一种计算效率高的方法，取得了具有竞争力的结果。然而，错误分析揭示了模型预测和数据集标注的问题。

Conclusion: 研究发现领域自适应预训练在阿拉伯语方面情感分析任务中带来了适度的改进，但模型预测和数据集标注存在问题。需要更注重语法和语义的模型，如图卷积网络，以更有效地捕捉长距离关系和复杂的基于方面的意见对齐。

Abstract: Aspect-based sentiment analysis (ABSA) in natural language processing enables
organizations to understand customer opinions on specific product aspects.
While deep learning models are widely used for English ABSA, their application
in Arabic is limited due to the scarcity of labeled data. Researchers have
attempted to tackle this issue by using pre-trained contextualized language
models such as BERT. However, these models are often based on fact-based data,
which can introduce bias in domain-specific tasks like ABSA. To our knowledge,
no studies have applied adaptive pre-training with Arabic contextualized models
for ABSA. This research proposes a novel approach using domain-adaptive
pre-training for aspect-sentiment classification (ASC) and opinion target
expression (OTE) extraction. We examine fine-tuning strategies - feature
extraction, full fine-tuning, and adapter-based methods - to enhance
performance and efficiency, utilizing multiple adaptation corpora and
contextualized models. Our results show that in-domain adaptive pre-training
yields modest improvements. Adapter-based fine-tuning is a computationally
efficient method that achieves competitive results. However, error analyses
reveal issues with model predictions and dataset labeling. In ASC, common
problems include incorrect sentiment labeling, misinterpretation of contrastive
markers, positivity bias for early terms, and challenges with conflicting
opinions and subword tokenization. For OTE, issues involve mislabeling targets,
confusion over syntactic roles, difficulty with multi-word expressions, and
reliance on shallow heuristics. These findings underscore the need for syntax-
and semantics-aware models, such as graph convolutional networks, to more
effectively capture long-distance relations and complex aspect-based opinion
alignments.

</details>


### [49] [KuBERT: Central Kurdish BERT Model and Its Application for Sentiment Analysis](https://arxiv.org/abs/2509.16804)
*Kozhin muhealddin Awlla,Hadi Veisi,Abdulhady Abas Abdullah*

Main category: cs.CL

TL;DR: 本研究通过将BERT集成到自然语言处理技术中，提高了库尔德语情感分析的准确性，为低资源语言的情感分析设定了新基准。


<details>
  <summary>Details</summary>
Motivation: 库尔德语是一种资源匮乏的语言，具有高度的语言多样性，计算资源有限，使得情感分析具有挑战性。传统的词嵌入模型如Word2Vec已被用于此任务，但随着BERT等新语言模型的出现，有希望实现改进。

Method: 本研究将BERT集成到自然语言处理技术中，以改进库尔德语的情感分析。

Result: BERT更好的词嵌入能力有助于捕捉语言的细微语义和上下文复杂性，从而提高情感分析的准确性。

Conclusion: 本研究通过将BERT集成到自然语言处理技术中，增强了对库尔德语情感分析的研究，为低资源语言的情感分析设定了新基准。

Abstract: This paper enhances the study of sentiment analysis for the Central Kurdish
language by integrating the Bidirectional Encoder Representations from
Transformers (BERT) into Natural Language Processing techniques. Kurdish is a
low-resourced language, having a high level of linguistic diversity with
minimal computational resources, making sentiment analysis somewhat
challenging. Earlier, this was done using a traditional word embedding model,
such as Word2Vec, but with the emergence of new language models, specifically
BERT, there is hope for improvements. The better word embedding capabilities of
BERT lend to this study, aiding in the capturing of the nuanced semantic pool
and the contextual intricacies of the language under study, the Kurdish
language, thus setting a new benchmark for sentiment analysis in low-resource
languages.

</details>


### [50] [Cognitive Linguistic Identity Fusion Score (CLIFS): A Scalable Cognition-Informed Approach to Quantifying Identity Fusion from Text](https://arxiv.org/abs/2509.16813)
*Devin R. Wright,Jisun An,Yong-Yeol Ahn*

Main category: cs.CL

TL;DR: CLIFS is a new metric that uses cognitive linguistics and LLMs to quantify identity fusion, offering an automated and scalable alternative to traditional methods.


<details>
  <summary>Details</summary>
Motivation: Quantifying identity fusion is vital for understanding group-based human behaviors, and traditional methods are limited by their need for controlled surveys or direct field contact.

Method: CLIFS integrates cognitive linguistics with large language models (LLMs) and builds on implicit metaphor detection to quantify identity fusion.

Result: CLIFS outperforms existing automated approaches and human annotation in benchmarks and improves violence risk assessment by more than 240% as a proof of concept.

Conclusion: CLIFS models and code are public, and further research is needed to develop larger, more diverse datasets to enhance generalizability and advance the field.

Abstract: Quantifying identity fusion -- the psychological merging of self with another
entity or abstract target (e.g., a religious group, political party, ideology,
value, brand, belief, etc.) -- is vital for understanding a wide range of
group-based human behaviors. We introduce the Cognitive Linguistic Identity
Fusion Score (CLIFS), a novel metric that integrates cognitive linguistics with
large language models (LLMs), which builds on implicit metaphor detection.
Unlike traditional pictorial and verbal scales, which require controlled
surveys or direct field contact, CLIFS delivers fully automated, scalable
assessments while maintaining strong alignment with the established verbal
measure. In benchmarks, CLIFS outperforms both existing automated approaches
and human annotation. As a proof of concept, we apply CLIFS to violence risk
assessment to demonstrate that it can improve violence risk assessment by more
than 240%. Building on our identification of a new NLP task and early success,
we underscore the need to develop larger, more diverse datasets that encompass
additional fusion-target domains and cultural backgrounds to enhance
generalizability and further advance this emerging area. CLIFS models and code
are public at https://github.com/DevinW-sudo/CLIFS.

</details>


### [51] [Semantic-Driven Topic Modeling for Analyzing Creativity in Virtual Brainstorming](https://arxiv.org/abs/2509.16835)
*Melkamu Abay Mersha,Jugal Kalita*

Main category: cs.CL

TL;DR: 本文提出了一种基于语义的主题建模框架，用于分析虚拟头脑风暴会议中的群体创造力，结果表明该方法在主题一致性方面优于现有方法，并提供了对主题深度和多样性的可解释见解。


<details>
  <summary>Details</summary>
Motivation: 虚拟头脑风暴会议已成为协作解决问题的核心组成部分，但大量的想法和不均匀的分布使得高效提取有价值的见解变得困难。手动编码想法既耗时又主观，因此需要自动化方法来支持群体创造力的评估。

Method: 本文提出了一种语义驱动的主题建模框架，该框架集成了四个模块化组件：基于Transformer的嵌入（Sentence-BERT）、降维（UMAP）、聚类（HDBSCAN）和主题提取与优化。

Result: 我们的模型在结构化的Zoom头脑风暴会议中进行了评估，结果表明其主题一致性高于现有的方法如LDA、ETM和BERTopic，平均一致性得分为0.687（CV），显著优于基线方法。

Conclusion: 本文展示了基于嵌入的主题建模在分析协作创意方面的潜力，并为研究同步虚拟会议中的创造力提供了高效且可扩展的框架。

Abstract: Virtual brainstorming sessions have become a central component of
collaborative problem solving, yet the large volume and uneven distribution of
ideas often make it difficult to extract valuable insights efficiently. Manual
coding of ideas is time-consuming and subjective, underscoring the need for
automated approaches to support the evaluation of group creativity. In this
study, we propose a semantic-driven topic modeling framework that integrates
four modular components: transformer-based embeddings (Sentence-BERT),
dimensionality reduction (UMAP), clustering (HDBSCAN), and topic extraction
with refinement. The framework captures semantic similarity at the sentence
level, enabling the discovery of coherent themes from brainstorming transcripts
while filtering noise and identifying outliers. We evaluate our approach on
structured Zoom brainstorming sessions involving student groups tasked with
improving their university. Results demonstrate that our model achieves higher
topic coherence compared to established methods such as LDA, ETM, and BERTopic,
with an average coherence score of 0.687 (CV), outperforming baselines by a
significant margin. Beyond improved performance, the model provides
interpretable insights into the depth and diversity of topics explored,
supporting both convergent and divergent dimensions of group creativity. This
work highlights the potential of embedding-based topic modeling for analyzing
collaborative ideation and contributes an efficient and scalable framework for
studying creativity in synchronous virtual meetings.

</details>


### [52] [Multi-task Pretraining for Enhancing Interpretable L2 Pronunciation Assessment](https://arxiv.org/abs/2509.16876)
*Jiun-Ting Li,Bi-Cheng Yan,Yi-Cheng Wang,Berlin Chen*

Main category: cs.CL

TL;DR: 本文提出了一种多任务预训练策略，结合手工特征，以提高自动发音评估和口语评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有APA系统通常依赖于音段级特征，忽略了超音段发音线索，并且缺乏与自动口语评估（ASA）的整合，限制了整体熟练度评估。

Method: 引入多任务预训练（MTP）策略，通过重建输入特征来捕捉长期时间发音线索并加强句子内的内在结构。此外，结合手工特征（HCFs）如流利度和重音来生成可解释的熟练度评分。

Result: 在speechocean762数据集上的实验显示，发音评分和ASA熟练度相关性得到了改善。

Conclusion: 实验表明，该方法在发音评分和ASA熟练度相关性方面有所改进，实现了针对性训练和全面的熟练度评估。

Abstract: Automatic pronunciation assessment (APA) analyzes second-language (L2)
learners' speech by providing fine-grained pronunciation feedback at various
linguistic levels. Most existing efforts on APA typically adopt segmental-level
features as inputs and predict pronunciation scores at different granularities
via hierarchical (or parallel) pronunciation modeling. This, however,
inevitably causes assessments across linguistic levels (e.g., phone, word, and
utterance) to rely solely on phoneme-level pronunciation features, nearly
sidelining supra-segmental pronunciation cues. To address this limitation, we
introduce multi-task pretraining (MTP) for APA, a simple yet effective strategy
that attempts to capture long-term temporal pronunciation cues while
strengthening the intrinsic structures within an utterance via the objective of
reconstructing input features. Specifically, for a phoneme-level encoder of an
APA model, the proposed MTP strategy randomly masks segmental-level
pronunciation features and reconstructs the masked ones based on their
surrounding pronunciation context. Furthermore, current APA systems lack
integration with automated speaking assessment (ASA), limiting holistic
proficiency evaluation. Drawing on empirical studies and prior knowledge in
ASA, our framework bridges this gap by incorporating handcrafted features
(HCFs), such as fluency (speech rate, silence duration) and stress (pitch
accent strength), derived from human-designed formulas via regressors to
generate interpretable proficiency scores. Experiments on speechocean762 show
improved pronunciation scoring and ASA proficiency correlation, enabling
targeted training and comprehensive proficiency assessment.

</details>


### [53] [Can GRPO Boost Complex Multimodal Table Understanding?](https://arxiv.org/abs/2509.16889)
*Xiaoqiang Kang,Shengen Wu,Zimu Wang,Yilin Liu,Xiaobo Jin,Kaizhu Huang,Wei Wang,Yutao Yue,Xiaowei Huang,Qiufeng Wang*

Main category: cs.CL

TL;DR: 本文介绍了一种名为Table-R1的三阶段强化学习框架，通过预热、感知对齐和提示完成GRPO方法，显著提升了模型在表格理解任务上的性能。实验表明，Table-R1在保持数据集上表现优于监督微调和GRPO方法，并且在某些情况下甚至可以与封闭源代码模型GPT-4o相媲美。


<details>
  <summary>Details</summary>
Motivation: Existing table understanding methods face challenges due to complex table structures and intricate logical reasoning. While supervised finetuning (SFT) dominates existing research, reinforcement learning (RL), such as Group Relative Policy Optimization (GRPO), has shown promise but struggled with low initial policy accuracy and coarse rewards in tabular contexts.

Method: Table-R1 is a three-stage RL framework that enhances multimodal table understanding through: (1) Warm-up that prompts initial perception and reasoning capabilities, (2) Perception Alignment GRPO (PA-GRPO), which employs continuous Tree-Edit-Distance Similarity (TEDS) rewards for recognizing table structures and contents, and (3) Hint-Completion GRPO (HC-GRPO), which utilizes fine-grained rewards of residual steps based on the hint-guided question.

Result: Extensive experiments demonstrate that Table-R1 can boost the model's table reasoning performance obviously on both held-in and held-out datasets, outperforming SFT and GRPO largely. Notably, Qwen2-VL-7B with Table-R1 surpasses larger specific table understanding models (e.g., Table-LLaVA 13B), even achieving comparable performance to the closed-source model GPT-4o on held-in datasets.

Conclusion: Table-R1 can boost the model's table reasoning performance obviously on both held-in and held-out datasets, outperforming SFT and GRPO largely. Qwen2-VL-7B with Table-R1 surpasses larger specific table understanding models and achieves comparable performance to GPT-4o, demonstrating the efficacy of each stage of Table-R1.

Abstract: Existing table understanding methods face challenges due to complex table
structures and intricate logical reasoning. While supervised finetuning (SFT)
dominates existing research, reinforcement learning (RL), such as Group
Relative Policy Optimization (GRPO), has shown promise but struggled with low
initial policy accuracy and coarse rewards in tabular contexts. In this paper,
we introduce Table-R1, a three-stage RL framework that enhances multimodal
table understanding through: (1) Warm-up that prompts initial perception and
reasoning capabilities, (2) Perception Alignment GRPO (PA-GRPO), which employs
continuous Tree-Edit-Distance Similarity (TEDS) rewards for recognizing table
structures and contents, and (3) Hint-Completion GRPO (HC-GRPO), which utilizes
fine-grained rewards of residual steps based on the hint-guided question.
Extensive experiments demonstrate that Table-R1 can boost the model's table
reasoning performance obviously on both held-in and held-out datasets,
outperforming SFT and GRPO largely. Notably, Qwen2-VL-7B with Table-R1
surpasses larger specific table understanding models (e.g., Table-LLaVA 13B),
even achieving comparable performance to the closed-source model GPT-4o on
held-in datasets, demonstrating the efficacy of each stage of Table-R1 in
overcoming initialization bottlenecks and reward sparsity, thereby advancing
robust multimodal table understanding.

</details>


### [54] [CLaC at DISRPT 2025: Hierarchical Adapters for Cross-Framework Multi-lingual Discourse Relation Classification](https://arxiv.org/abs/2509.16903)
*Nawar Turk,Daniele Comitogianni,Leila Kosseim*

Main category: cs.CL

TL;DR: 本文介绍了对DISRPT 2025任务3（话语关系分类）的提交。任务3引入了跨多种语言和话语框架的17个统一话语关系标签，提出了多语言和跨形式主义挑战。作者通过微调多语言BERT模型建立基线，并评估基于提示的大型语言模型在零样本和少量样本设置下的表现。最后，他们引入了一种分层双适配器对比学习模型HiDAC，结果显示HiDAC在保持参数效率的同时实现了最高的总体准确率


<details>
  <summary>Details</summary>
Motivation: 任务3引入了跨39个语料库、16种语言和六个话语框架的17个统一话语关系标签，提出了重大的多语言和跨形式主义挑战。本文旨在通过不同的方法来解决这一挑战，并比较不同模型的表现

Method: 首先通过微调多语言BERT模型（mBERT、XLM-RoBERTa-Base和XLM-RoBERTa-Large）并采用两种论点顺序策略和渐进式解冻比例来建立强大的基线。然后评估基于提示的大语言模型（即Claude Opus 4.0）在零样本和少量样本设置下的表现，以了解LLMs如何响应新提出的统一标签。最后，引入HiDAC，一种分层双适配器对比学习模型

Result: 结果表明，虽然更大的变压器模型实现了更高的准确率，但改进是有限的，而解冻编码器层的顶部75%可以实现与完全微调相当的性能，同时训练更少的参数。基于提示的模型明显落后于微调的变压器，而HiDAC在保持比完全微调更参数效率的同时实现了最高的总体准确率（67.5%）

Conclusion: 结果表明，虽然更大的变压器模型实现了更高的准确率，但改进是有限的，而解冻编码器层的顶部75%可以实现与完全微调相当的性能，同时训练更少的参数。基于提示的模型明显落后于微调的变压器，而HiDAC在保持比完全微调更参数效率的同时实现了最高的总体准确率（67.5%）

Abstract: We present our submission to Task 3 (Discourse Relation Classification) of
the DISRPT 2025 shared task. Task 3 introduces a unified set of 17 discourse
relation labels across 39 corpora in 16 languages and six discourse frameworks,
posing significant multilingual and cross-formalism challenges. We first
benchmark the task by fine-tuning multilingual BERT-based models (mBERT,
XLM-RoBERTa-Base, and XLM-RoBERTa-Large) with two argument-ordering strategies
and progressive unfreezing ratios to establish strong baselines. We then
evaluate prompt-based large language models (namely Claude Opus 4.0) in
zero-shot and few-shot settings to understand how LLMs respond to the newly
proposed unified labels. Finally, we introduce HiDAC, a Hierarchical
Dual-Adapter Contrastive learning model. Results show that while larger
transformer models achieve higher accuracy, the improvements are modest, and
that unfreezing the top 75% of encoder layers yields performance comparable to
full fine-tuning while training far fewer parameters. Prompt-based models lag
significantly behind fine-tuned transformers, and HiDAC achieves the highest
overall accuracy (67.5%) while remaining more parameter-efficient than full
fine-tuning.

</details>


### [55] [CUTE: A Multilingual Dataset for Enhancing Cross-Lingual Knowledge Transfer in Low-Resource Languages](https://arxiv.org/abs/2509.16914)
*Wenhao Zhuang,Yuan Sun*

Main category: cs.CL

TL;DR: 本文构建并开源了CUTE语料库，旨在提升大语言模型对低资源语言的处理能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在资源丰富的语言中表现出色，但在低资源语言中的支持不足，主要原因是训练语料稀缺。

Method: 构建并开源了CUTE语料库，包含中、维吾尔语、藏语和英语的两组25GB语料（一组平行，一组非平行），通过机器翻译获得。

Result: CUTE语料库是目前最大的维吾尔语和藏语开源语料库，并展示了其在增强大语言模型处理低资源语言能力方面的有效性。

Conclusion: CUTE语料库和相关模型已向研究社区公开，有助于提升大语言模型处理低资源语言的能力，并研究语料平行性在跨语言迁移学习中的作用。

Abstract: Large Language Models (LLMs) demonstrate exceptional zero-shot capabilities
in various NLP tasks, significantly enhancing user experience and efficiency.
However, this advantage is primarily limited to resource-rich languages. For
the diverse array of low-resource languages, support remains inadequate, with
the scarcity of training corpora considered the primary cause. We construct and
open-source CUTE Chinese, Uyghur, Tibetan,English dataset, consisting of two
25GB sets of four-language corpora (one parallel and one non-parallel),
obtained through machine translation. CUTE encompasses two resource-rich
languages (Chinese and English) and two low-resource languages (Uyghur and
Tibetan). Prior to constructing CUTE, human assessment validates that the
machine translation quality between Chinese-Uyghur and Chinese-Tibetan
approaches that of Chinese-English translation. CUTE represents the largest
open-source corpus for Uyghur and Tibetan languages to date, and we demonstrate
its effectiveness in enhancing LLMs' ability to process low-resource languages
while investigating the role of corpus parallelism in cross-lingual transfer
learning. The CUTE corpus and related models are made publicly available to the
research community.

</details>


### [56] [K-DeCore: Facilitating Knowledge Transfer in Continual Structured Knowledge Reasoning via Knowledge Decoupling](https://arxiv.org/abs/2509.16929)
*Yongrui Chen,Yi Huang,Yunchang Liu,Shenyu Zhang,Junhao He,Tongtong Wu,Guilin Qi,Tianxing Wu*

Main category: cs.CL

TL;DR: 本文提出一种新的持续结构知识推理框架 	extsc{K-DeCore}，通过知识解耦和记忆巩固等机制，有效提升了模型的泛化能力和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法在处理顺序任务时面临泛化能力差和参数增长导致的推理效率低的问题。

Method: 	extsc{K-DeCore} 引入了一种知识解耦机制，将推理过程分为任务特定和任务无关阶段，并结合双视角记忆巩固机制和结构引导的伪数据合成策略。

Result: 在四个基准数据集上的实验显示，	extsc{K-DeCore} 在多种指标上表现优异。

Conclusion: 实验结果表明，	extsc{K-DeCore} 在多个指标上优于现有的持续学习方法，证明了其有效性。

Abstract: Continual Structured Knowledge Reasoning (CSKR) focuses on training models to
handle sequential tasks, where each task involves translating natural language
questions into structured queries grounded in structured knowledge. Existing
general continual learning approaches face significant challenges when applied
to this task, including poor generalization to heterogeneous structured
knowledge and inefficient reasoning due to parameter growth as tasks increase.
To address these limitations, we propose a novel CSKR framework,
\textsc{K-DeCore}, which operates with a fixed number of tunable parameters.
Unlike prior methods, \textsc{K-DeCore} introduces a knowledge decoupling
mechanism that disentangles the reasoning process into task-specific and
task-agnostic stages, effectively bridging the gaps across diverse tasks.
Building on this foundation, \textsc{K-DeCore} integrates a dual-perspective
memory consolidation mechanism for distinct stages and introduces a
structure-guided pseudo-data synthesis strategy to further enhance the model's
generalization capabilities. Extensive experiments on four benchmark datasets
demonstrate the superiority of \textsc{K-DeCore} over existing continual
learning methods across multiple metrics, leveraging various backbone large
language models.

</details>


### [57] [AirQA: A Comprehensive QA Dataset for AI Research with Instance-Level Evaluation](https://arxiv.org/abs/2509.16952)
*Tiancheng Huang,Ruisheng Cao,Yuxin Zhang,Zhangyi Kang,Zijian Wang,Chenrun Wang,Yijie Luo,Hang Zheng,Lirong Qian,Lu Chen,Kai Yu*

Main category: cs.CL

TL;DR: 本文提出了AirQA数据集和ExTrActor框架，以解决学术论文问答任务中缺乏全面基准和高质量交互轨迹的问题，并展示了ExTrActor对小型模型性能的提升效果。


<details>
  <summary>Details</summary>
Motivation: 由于学术论文数量的增长，研究人员难以高效提取关键信息。虽然基于大语言模型的代理可以自动化科学论文的问答工作流程，但缺乏一个全面且现实的基准来评估它们的能力。此外，训练这种特定任务的交互代理受到高质量交互轨迹短缺的阻碍。

Method: 提出了一种自动化框架ExTrActor，用于指令数据合成。ExTrActor利用三个基于大语言模型的代理，能够在没有人工干预的情况下进行示例生成和轨迹收集。

Result: 多个开源和专有模型的评估显示，大多数模型在AirQA上的表现不佳，证明了我们数据集的质量。广泛的实验确认ExTrActor能够持续提升小型模型的多轮工具使用能力。

Conclusion: 实验结果表明，ExTrActor能够显著提升小型模型的多轮工具使用能力，使其性能达到与大型模型相当的水平。

Abstract: The growing volume of academic papers has made it increasingly difficult for
researchers to efficiently extract key information. While large language models
(LLMs) based agents are capable of automating question answering (QA) workflows
for scientific papers, there still lacks a comprehensive and realistic
benchmark to evaluate their capabilities. Moreover, training an interactive
agent for this specific task is hindered by the shortage of high-quality
interaction trajectories. In this work, we propose AirQA, a human-annotated
comprehensive paper QA dataset in the field of artificial intelligence (AI),
with 13,948 papers and 1,246 questions, that encompasses multi-task,
multi-modal and instance-level evaluation. Furthermore, we propose ExTrActor,
an automated framework for instruction data synthesis. With three LLM-based
agents, ExTrActor can perform example generation and trajectory collection
without human intervention. Evaluations of multiple open-source and proprietary
models show that most models underperform on AirQA, demonstrating the quality
of our dataset. Extensive experiments confirm that ExTrActor consistently
improves the multi-turn tool-use capability of small models, enabling them to
achieve performance comparable to larger ones.

</details>


### [58] [Preference Distillation via Value based Reinforcement Learning](https://arxiv.org/abs/2509.16965)
*Minchan Kwon,Junwon Ko,Kangil Kim,Junmo Kim*

Main category: cs.CL

TL;DR: 本文提出了一种基于教师价值的知识蒸馏方法（TVKD），通过引入辅助奖励来改进DPO训练，实验结果表明TVKD在各种基准和模型大小上都能提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的方法往往只关注模仿当前行为，而忽略了奖励建模的蒸馏。为了克服这个问题，提出了TVKD方法。

Method: 提出了一种基于教师价值的知识蒸馏方法（TVKD），引入了来自教师模型价值函数的辅助奖励，以提供软引导。该辅助奖励被设计为满足基于潜在的奖励塑造，确保DPO的全局奖励结构和最优策略得到保留。

Result: 实验结果表明，TVKD在各种基准和模型大小上都能持续提升性能。

Conclusion: TVKD可以集成到标准的DPO训练框架中，并且不需要额外的rollouts。实验结果表明，TVKD在各种基准和模型大小上都能持续提升性能。

Abstract: Direct Preference Optimization (DPO) is a powerful paradigm to align language
models with human preferences using pairwise comparisons. However, its binary
win-or-loss supervision often proves insufficient for training small models
with limited capacity. Prior works attempt to distill information from large
teacher models using behavior cloning or KL divergence. These methods often
focus on mimicking current behavior and overlook distilling reward modeling. To
address this issue, we propose \textit{Teacher Value-based Knowledge
Distillation} (TVKD), which introduces an auxiliary reward from the value
function of the teacher model to provide a soft guide. This auxiliary reward is
formulated to satisfy potential-based reward shaping, ensuring that the global
reward structure and optimal policy of DPO are preserved. TVKD can be
integrated into the standard DPO training framework and does not require
additional rollouts. Our experimental results show that TVKD consistently
improves performance across various benchmarks and model sizes.

</details>


### [59] [Advancing Speech Understanding in Speech-Aware Language Models with GRPO](https://arxiv.org/abs/2509.16990)
*Avishai Elmakies,Hagai Aronowitz,Nimrod Shabtay,Eli Schwartz,Ron Hoory,Avihu Dekel*

Main category: cs.CL

TL;DR: 本文提出了一种基于GRPO的方法，用于在开放格式的语音理解任务上训练SALLMs，实验结果表明该方法优于标准监督微调。


<details>
  <summary>Details</summary>
Motivation: 语音感知大型语言模型（SALLMs）在语音理解任务中表现出色。然而，现有研究主要集中在多项选择任务上，而本文关注的是更能体现模型生成能力的开放格式任务。

Method: 本文采用基于组相对策略优化（GRPO）的方法，利用BLEU作为奖励信号来优化语音感知大型语言模型（SALLMs）。

Result: 实验结果表明，基于GRPO的方法在多个关键指标上优于标准监督微调，并展示了其在开放格式任务中的有效性。

Conclusion: 本文提出了一种基于组相对策略优化（GRPO）的方法，用于在开放格式的语音理解任务上训练语音感知大型语言模型（SALLMs）。实验结果表明，该方法在多个关键指标上优于标准监督微调。此外，本文还探讨了在GRPO中引入非策略样本的潜力，为未来的研究指明了方向。

Abstract: In this paper, we introduce a Group Relative Policy Optimization (GRPO)-based
method for training Speech-Aware Large Language Models (SALLMs) on open-format
speech understanding tasks, such as Spoken Question Answering and Automatic
Speech Translation. SALLMs have proven highly effective for speech
understanding tasks. GRPO has recently gained traction for its efficiency in
training LLMs, and prior work has explored its application to SALLMs, primarily
in multiple-choice tasks. Building on this, we focus on open-format tasks that
better reflect the generative abilities of the models. Our approach leverages
GRPO with BLEU as the reward signal to optimize SALLMs, and we demonstrate
empirically that it surpasses standard SFT across several key metrics. Finally,
we explore the potential of incorporating off-policy samples within GRPO for
these tasks, highlighting avenues for further improvement and further research.

</details>


### [60] [The Transfer Neurons Hypothesis: An Underlying Mechanism for Language Latent Space Transitions in Multilingual LLMs](https://arxiv.org/abs/2509.17030)
*Hinata Tezuka,Naoya Inoue*

Main category: cs.CL

TL;DR: This paper proposes and validates the Transfer Neurons Hypothesis, which suggests that certain neurons in the MLP module are responsible for transferring representations between language-specific latent spaces and a shared semantic latent space. The results show that transfer neurons are critical for reasoning in multilingual LLMs.


<details>
  <summary>Details</summary>
Motivation: Recent studies have suggested a processing framework for multilingual inputs in decoder-based LLMs, but the internal dynamics of such transformation and the underlying mechanism remain underexplored.

Method: We propose and empirically validate The Transfer Neurons Hypothesis, which suggests that certain neurons in the MLP module are responsible for transferring representations between language-specific latent spaces and a shared semantic latent space.

Result: We show that transfer neurons are critical for reasoning in multilingual LLMs, and that one function of language-specific neurons is to facilitate movement between latent spaces.

Conclusion: Transfer neurons are critical for reasoning in multilingual LLMs.

Abstract: Recent studies have suggested a processing framework for multilingual inputs
in decoder-based LLMs: early layers convert inputs into English-centric and
language-agnostic representations; middle layers perform reasoning within an
English-centric latent space; and final layers generate outputs by transforming
these representations back into language-specific latent spaces. However, the
internal dynamics of such transformation and the underlying mechanism remain
underexplored. Towards a deeper understanding of this framework, we propose and
empirically validate The Transfer Neurons Hypothesis: certain neurons in the
MLP module are responsible for transferring representations between
language-specific latent spaces and a shared semantic latent space.
Furthermore, we show that one function of language-specific neurons, as
identified in recent studies, is to facilitate movement between latent spaces.
Finally, we show that transfer neurons are critical for reasoning in
multilingual LLMs.

</details>


### [61] [Modeling Bottom-up Information Quality during Language Processing](https://arxiv.org/abs/2509.17047)
*Cui Ding,Yanning Yin,Lena A. Jäger,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 本研究通过信息论方法分析了阅读过程中底部输入信息质量对阅读时间的影响，并发现英语和汉语中单词的上半部分包含更多信息，且这种不对称性在英语中更为明显。


<details>
  <summary>Details</summary>
Motivation: 研究旨在验证语言处理模型中的一个主要预测，即底部输入的质量会影响处理的难易程度。

Method: 研究提出了一个信息论的操作定义来衡量底部输入信息的质量，即视觉信息与词义之间的互信息（MI）。然后通过比较参与者在单词信息质量降低的条件下的阅读时间来测试这一操作定义，并使用多模态语言模型估计视觉输入与单词之间的互信息。

Result: 研究发现，当单词的上半部分或下半部分被遮挡时，参与者的阅读时间会增加，表明信息质量的降低会导致阅读困难。此外，英语中上下部分的信息分布不对称性更明显。

Conclusion: 研究发现，在英语和汉语中，单词的上半部分比下半部分包含更多的关于词义的信息，这种不对称性在英语中更为明显，这反映在阅读时间上。

Abstract: Contemporary theories model language processing as integrating both top-down
expectations and bottom-up inputs. One major prediction of such models is that
the quality of the bottom-up inputs modulates ease of processing -- noisy
inputs should lead to difficult and effortful comprehension. We test this
prediction in the domain of reading. First, we propose an information-theoretic
operationalization for the "quality" of bottom-up information as the mutual
information (MI) between visual information and word identity. We formalize
this prediction in a mathematical model of reading as a Bayesian update.
Second, we test our operationalization by comparing participants' reading times
in conditions where words' information quality has been reduced, either by
occluding their top or bottom half, with full words. We collect data in English
and Chinese. We then use multimodal language models to estimate the mutual
information between visual inputs and words. We use these data to estimate the
specific effect of reduced information quality on reading times. Finally, we
compare how information is distributed across visual forms. In English and
Chinese, the upper half contains more information about word identity than the
lower half. However, the asymmetry is more pronounced in English, a pattern
which is reflected in the reading times.

</details>


### [62] [TactfulToM: Do LLMs Have the Theory of Mind Ability to Understand White Lies?](https://arxiv.org/abs/2509.17054)
*Yiwei Liu,Emma Jane Pretty,Jiahao Huang,Saku Sugawara*

Main category: cs.CL

TL;DR: 本文介绍了TactfulToM，这是一个新的英语基准，用于评估大型语言模型在理解白谎和推理其亲社会动机方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究对需要更细微社会情境的理论心智能力（如白谎）的研究有限，因此需要一个新的基准来评估LLMs在这方面的表现。

Method: 通过一个多阶段的人机交互管道生成TactfulToM基准，其中LLMs扩展手动设计的种子故事以保持参与者之间的信息不对称，这是真实白谎所必需的。

Result: TactfulToM对最先进的模型来说是具有挑战性的，它们的表现明显低于人类，揭示了它们在理解白谎所需的理论心智推理方面的不足。

Conclusion: TactfulToM是一个具有挑战性的基准，现有的最先进的模型在理解白谎方面表现不佳，这揭示了它们在完全理解白谎所需的理论心智推理方面的不足。

Abstract: While recent studies explore Large Language Models' (LLMs) performance on
Theory of Mind (ToM) reasoning tasks, research on ToM abilities that require
more nuanced social context is limited, such as white lies. We introduce
TactfulToM, a novel English benchmark designed to evaluate LLMs' ability to
understand white lies within real-life conversations and reason about prosocial
motivations behind them, particularly when they are used to spare others'
feelings and maintain social harmony. Our benchmark is generated through a
multi-stage human-in-the-loop pipeline where LLMs expand manually designed seed
stories into conversations to maintain the information asymmetry between
participants necessary for authentic white lies. We show that TactfulToM is
challenging for state-of-the-art models, which perform substantially below
humans, revealing shortcomings in their ability to fully comprehend the ToM
reasoning that enables true understanding of white lies.

</details>


### [63] [SFT-TA: Supervised Fine-Tuned Agents in Multi-Agent LLMs for Automated Inductive Thematic Analysis](https://arxiv.org/abs/2509.17167)
*Seungjun Yi,Joakim Nguyen,Huimin Xu,Terence Lim,Joseph Skrovan,Mehak Beri,Hitakshi Modi,Andrew Well,Liu Leqi,Mia Markey,Ying Ding*

Main category: cs.CL

TL;DR: 本文提出了一种基于多智能体系统的自动化主题分析框架SFT-TA，能够有效提升与人类参考主题的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 手动主题分析耗时且限制可扩展性。最近的LLM进展为自动化主题分析提供了途径，但与人类结果的对齐仍然有限。

Method: 我们提出了SFT-TA，这是一种自动主题分析框架，将监督微调（SFT）代理嵌入到多智能体系统中。

Result: 我们的框架在与人类参考主题的对齐方面优于现有的框架和gpt-4o基线。我们观察到，单独的SFT代理可能表现不佳，但在多智能体系统中表现更好。

Conclusion: 我们的结果表明，在多智能体系统中嵌入SFT代理是一种改进主题分析对齐的有前途的途径。

Abstract: Thematic Analysis (TA) is a widely used qualitative method that provides a
structured yet flexible framework for identifying and reporting patterns in
clinical interview transcripts. However, manual thematic analysis is
time-consuming and limits scalability. Recent advances in LLMs offer a pathway
to automate thematic analysis, but alignment with human results remains
limited. To address these limitations, we propose SFT-TA, an automated thematic
analysis framework that embeds supervised fine-tuned (SFT) agents within a
multi-agent system. Our framework outperforms existing frameworks and the
gpt-4o baseline in alignment with human reference themes. We observed that SFT
agents alone may underperform, but achieve better results than the baseline
when embedded within a multi-agent system. Our results highlight that embedding
SFT agents in specific roles within a multi-agent system is a promising pathway
to improve alignment with desired outputs for thematic analysis.

</details>


### [64] [FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions](https://arxiv.org/abs/2509.17177)
*Bowen Qin,Chen Yue,Fang Yin,Hui Wang,JG Yao,Jiakang Liu,Jing-Shu Zheng,Miguel Hu Chen,Richeng Xuan,Shibei Meng,Shiqi Zhou,Teng Dai,Tong-Shuai Ren,Wei Cui,Xi Yang,Xialin Du,Xiaojing Xu,Xue Sun,Xuejing Li,Yaming Liu,Yesheng Liu,Ying Liu,Yonghua Lin,Yu Zhao,Yunduo Zhang,Yuwen Luo,Zheqi He,Zhiyuan He,Zhongyuan Wang*

Main category: cs.CL

TL;DR: 本文对当前大型推理模型进行了中等规模的无污染评估，并发布了一个名为ROME的评估基准，用于测试视觉语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 为了评估当前大型推理模型的性能，并提供一个用于测试视觉语言模型推理能力的基准。

Method: 本文进行了中等规模的无污染评估，并发布了ROME作为评估基准，以测试视觉语言模型的推理能力。

Result: 本文进行了中等规模的无污染评估，并发布了ROME作为评估基准。

Conclusion: 本文对当前大型推理模型进行了中等规模的无污染评估，并发布了一个名为ROME的评估基准，用于测试视觉语言模型从视觉线索中进行推理的能力。

Abstract: We conduct a moderate-scale contamination-free (to some extent) evaluation of
current large reasoning models (LRMs) with some preliminary findings. We also
release ROME, our evaluation benchmark for vision language models intended to
test reasoning from visual clues. We attach links to the benchmark, evaluation
data, and other updates on this website:
https://flageval-baai.github.io/LRM-Eval/

</details>


### [65] [Attention Consistency for LLMs Explanation](https://arxiv.org/abs/2509.17178)
*Tian Lan,Jinyuan Xu,Xue He,Jenq-Neng Hwang,Lei Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为MACS的新方法，用于估计解码器模型中输入标记的重要性。实验结果表明，MACS在可解释性和计算效率之间取得了有利的权衡。


<details>
  <summary>Details</summary>
Motivation: 当前的可解释性方法在分辨率和计算成本方面面临挑战，因此需要一种轻量级且易于部署的启发式方法来解决这些问题。

Method: 提出了一种名为Multi-Layer Attention Consistency Score (MACS)的新方法，用于估计解码器模型中输入标记的重要性。MACS基于最大注意力的一致性来衡量输入标记的贡献。

Result: 实验评估表明，MACS在可解释性和计算效率之间取得了有利的权衡，其忠实度与复杂技术相当，同时减少了VRAM使用量和延迟。

Conclusion: MACS achieves a favorable trade-off between interpretability quality and computational efficiency, showing faithfulness comparable to complex techniques with a 22% decrease in VRAM usage and 30% reduction in latency.

Abstract: Understanding the decision-making processes of large language models (LLMs)
is essential for their trustworthy development and deployment. However, current
interpretability methods often face challenges such as low resolution and high
computational cost. To address these limitations, we propose the
\textbf{Multi-Layer Attention Consistency Score (MACS)}, a novel, lightweight,
and easily deployable heuristic for estimating the importance of input tokens
in decoder-based models. MACS measures contributions of input tokens based on
the consistency of maximal attention. Empirical evaluations demonstrate that
MACS achieves a favorable trade-off between interpretability quality and
computational efficiency, showing faithfulness comparable to complex techniques
with a 22\% decrease in VRAM usage and 30\% reduction in latency.

</details>


### [66] [LifeAlign: Lifelong Alignment for Large Language Models with Memory-Augmented Focalized Preference Optimization](https://arxiv.org/abs/2509.17183)
*Junsong Li,Jie Zhou,Bihao Zhan,Yutao Yang,Qianjun Pan,Shilian Chen,Tianyu Huai,Xin Li,Qin Chen,Liang He*

Main category: cs.CL

TL;DR: LifeAlign 是一种新的终身对齐框架，能够使大型语言模型在连续学习任务中保持与人类偏好的一致对齐，同时避免遗忘之前学到的知识。


<details>
  <summary>Details</summary>
Motivation: 传统对齐方法存在灾难性遗忘问题，导致模型在适应新偏好或领域时丢失之前获得的知识。

Method: LifeAlign 是一种新的终身对齐框架，包含两个关键创新：聚焦偏好优化策略和短到长的记忆巩固机制。

Result: 实验结果表明，LifeAlign 在保持偏好对齐质量和知识保留方面优于现有的终身学习方法。

Conclusion: LifeAlign 在多个顺序对齐任务中表现出色，相比现有的终身学习方法，在保持偏好对齐质量和知识保留方面具有优势。

Abstract: Alignment plays a crucial role in Large Language Models (LLMs) in aligning
with human preferences on a specific task/domain. Traditional alignment methods
suffer from catastrophic forgetting, where models lose previously acquired
knowledge when adapting to new preferences or domains. We introduce LifeAlign,
a novel framework for lifelong alignment that enables LLMs to maintain
consistent human preference alignment across sequential learning tasks without
forgetting previously learned knowledge. Our approach consists of two key
innovations. First, we propose a focalized preference optimization strategy
that aligns LLMs with new preferences while preventing the erosion of knowledge
acquired from previous tasks. Second, we develop a short-to-long memory
consolidation mechanism that merges denoised short-term preference
representations into stable long-term memory using intrinsic dimensionality
reduction, enabling efficient storage and retrieval of alignment patterns
across diverse domains. We evaluate LifeAlign across multiple sequential
alignment tasks spanning different domains and preference types. Experimental
results demonstrate that our method achieves superior performance in
maintaining both preference alignment quality and knowledge retention compared
to existing lifelong learning approaches. The codes and datasets will be
released on GitHub.

</details>


### [67] [Evolution of Concepts in Language Model Pre-Training](https://arxiv.org/abs/2509.17196)
*Xuyang Ge,Wentao Shu,Jiaxing Wu,Yunhua Zhou,Zhengfu He,Xipeng Qiu*

Main category: cs.CL

TL;DR: 本文通过稀疏字典学习方法追踪语言模型预训练过程中特征的演变，并发现特征演变与下游性能之间存在因果关系。


<details>
  <summary>Details</summary>
Motivation: 语言模型通过预训练获得广泛的能力，但预训练过程仍然是一个黑箱。我们需要理解预训练过程中特征的演变及其对下游性能的影响。

Method: 我们使用一种称为crosscoders的稀疏字典学习方法，追踪预训练快照中线性可解释特征的演变。

Result: 我们发现大多数特征在特定点开始形成，而更复杂的模式在后期训练阶段出现。特征归因分析揭示了特征演变与下游性能之间的因果联系。

Conclusion: 我们的工作为跟踪语言模型学习动态中的细粒度表示进展提供了可能性。

Abstract: Language models obtain extensive capabilities through pre-training. However,
the pre-training process remains a black box. In this work, we track linear
interpretable feature evolution across pre-training snapshots using a sparse
dictionary learning method called crosscoders. We find that most features begin
to form around a specific point, while more complex patterns emerge in later
training stages. Feature attribution analyses reveal causal connections between
feature evolution and downstream performance. Our feature-level observations
are highly consistent with previous findings on Transformer's two-stage
learning process, which we term a statistical learning phase and a feature
learning phase. Our work opens up the possibility to track fine-grained
representation progress during language model learning dynamics.

</details>


### [68] [Prompt-Based Simplification for Plain Language using Spanish Language Models](https://arxiv.org/abs/2509.17209)
*Lourdes Moreno,Jesus M. Sanchez-Gomez,Marco Antonio Sanchez-Escudero,Paloma Martínez*

Main category: cs.CL

TL;DR: 本文介绍了HULAT-UC3M在CLEARS 2025子任务1中的参与情况，探索了基于西班牙语文本训练的模型策略，并提出了一个结合归一化步骤、RigoChat-7B-v2模型和专门的PL导向提示的最终系统。该系统在语义相似性方面排名第一，但在可读性方面排名第四。同时，文章还探讨了训练数据异质性和当前评估指标的局限性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索适用于西班牙语文本到普通语言转换的模型策略，并评估其性能。

Method: 本文采用了基于西班牙语文本训练的模型策略，包括零样本配置（使用提示工程）和微调版本（低秩适应，LoRA）。通过官方任务指标（余弦相似度和Fernández-Huerta可读性指数）评估了不同策略，并选择了最佳模型和提示组合。

Result: 最终系统在语义相似性方面排名第一（SIM = 0.75），但在可读性方面排名第四（FH = 69.72）。文章还讨论了训练数据异质性和当前评估指标的局限性。

Conclusion: 本文讨论了HULAT-UC3M在CLEARS 2025子任务1中的参与情况，探索了基于西班牙语文本训练的模型策略，并提出了一个结合归一化步骤、RigoChat-7B-v2模型和专门的PL导向提示的最终系统。该系统在语义相似性方面排名第一，但在可读性方面排名第四。同时，文章还探讨了训练数据异质性和当前评估指标在捕捉语言清晰度和内容保留方面的局限性。

Abstract: This paper describes the participation of HULAT-UC3M in CLEARS 2025 Subtask
1: Adaptation of Text to Plain Language (PL) in Spanish. We explored strategies
based on models trained on Spanish texts, including a zero-shot configuration
using prompt engineering and a fine-tuned version with Low-Rank Adaptation
(LoRA). Different strategies were evaluated on representative internal subsets
of the training data, using the official task metrics, cosine similarity (SIM)
and the Fern\'andez-Huerta readability index (FH) to guide the selection of the
optimal model and prompt combination. The final system was selected for its
balanced and consistent performance, combining normalization steps, the
RigoChat-7B-v2 model, and a dedicated PL-oriented prompt. It ranked first in
semantic similarity (SIM = 0.75), however, fourth in readability (FH = 69.72).
We also discuss key challenges related to training data heterogeneity and the
limitations of current evaluation metrics in capturing both linguistic clarity
and content preservation.

</details>


### [69] [Extending Automatic Machine Translation Evaluation to Book-Length Documents](https://arxiv.org/abs/2509.17249)
*Kuang-Da Wang,Shuoyang Ding,Chao-Han Huck Yang,Ping-Chun Hsieh,Wen-Chih Peng,Vitaly Lavrukhin,Boris Ginsburg*

Main category: cs.CL

TL;DR: 本文提出了SEGALE，一种用于长文档翻译评估的新方案，能够处理任意长度的翻译，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法受到数据集限制、度量中的标记数量限制和严格的句子边界要求的约束，无法进行文档级别的评估。

Method: 我们引入了SEGALE，这是一种评估方案，通过将文档视为连续文本并应用句子分割和对齐方法，将现有自动度量扩展到长文档翻译。

Result: 实验表明，我们的方案在长文档翻译评估中表现优异，能够处理任意长度的翻译，并考虑了翻译不足或过度以及不同的句子边界。

Conclusion: 我们的方案在长文档翻译评估中显著优于现有的长文本文档评估方案，同时与使用真实句子对齐的评估相当。此外，我们将该方案应用于书籍长度的文本，并首次证明许多开源大语言模型无法在其报告的最大上下文长度下有效翻译文档。

Abstract: Despite Large Language Models (LLMs) demonstrating superior translation
performance and long-context capabilities, evaluation methodologies remain
constrained to sentence-level assessment due to dataset limitations, token
number restrictions in metrics, and rigid sentence boundary requirements. We
introduce SEGALE, an evaluation scheme that extends existing automatic metrics
to long-document translation by treating documents as continuous text and
applying sentence segmentation and alignment methods. Our approach enables
previously unattainable document-level evaluation, handling translations of
arbitrary length generated with document-level prompts while accounting for
under-/over-translations and varied sentence boundaries. Experiments show our
scheme significantly outperforms existing long-form document evaluation
schemes, while being comparable to evaluations performed with groundtruth
sentence alignments. Additionally, we apply our scheme to book-length texts and
newly demonstrate that many open-weight LLMs fail to effectively translate
documents at their reported maximum context lengths.

</details>


### [70] [Probabilistic Token Alignment for Large Language Model Fusion](https://arxiv.org/abs/2509.17276)
*Runjia Zeng,James Chenhao Liang,Cheng Han,Zhiwen Cao,Jiahao Liu,Xiaojun Quan,Yingjie Victor Chen,Lifu Huang,Tong Geng,Qifan Wang,Dongfang Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为PTA-LLM的概率标记对齐方法，通过将标记对齐转化为最优传输问题，实现了更通用和软性的对齐方式，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有模型融合方法依赖于手动预定义的词汇对齐，这可能在不同上下文中无法很好地泛化，导致性能下降。因此，需要一种更通用和软性的对齐方法。

Method: 本文提出了一种名为PTA-LLM的概率标记对齐方法，该方法将标记对齐重新表述为一个经典的数学问题：最优传输，并利用分布感知学习来促进更连贯的模型融合。

Result: 实验结果表明，概率标记对齐方法能够提升目标模型在多个能力上的性能。

Conclusion: 实验结果表明，概率标记对齐方法能够提升目标模型在多个能力上的性能。

Abstract: Training large language models (LLMs) from scratch can yield models with
unique functionalities and strengths, but it is costly and often leads to
redundant capabilities. A more cost-effective alternative is to fuse existing
pre-trained LLMs with different architectures into a more powerful model.
However, a key challenge in existing model fusion is their dependence on
manually predefined vocabulary alignment, which may not generalize well across
diverse contexts, leading to performance degradation in several evaluation. To
solve this, we draw inspiration from distribution learning and propose the
probabilistic token alignment method as a general and soft mapping for
alignment, named as PTA-LLM. Our approach innovatively reformulates token
alignment into a classic mathematical problem: optimal transport, seamlessly
leveraging distribution-aware learning to facilitate more coherent model
fusion. Apart from its inherent generality, PTA-LLM exhibits interpretability
from a distributional perspective, offering insights into the essence of the
token alignment. Empirical results demonstrate that probabilistic token
alignment enhances the target model's performance across multiple capabilities.
Our code is avaliable at https://runjia.tech/neurips_pta-llm/.

</details>


### [71] [Automated Knowledge Graph Construction using Large Language Models and Sentence Complexity Modelling](https://arxiv.org/abs/2509.17289)
*Sydney Anuyah,Mehedi Mahmud Kaushik,Krishna Dwarampudi,Rakesh Shiradkar,Arjan Durresi,Sunandan Chakraborty*

Main category: cs.CL

TL;DR: CoDe-KG 是一个用于提取句子级知识图谱的开源端到端管道，通过结合稳健的共指解析和句法句子分解，实现了在关系抽取任务中的显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱提取方法在处理复杂句子时存在局限性，因此需要一种更有效的方法来提取句子级知识图谱。

Method: CoDe-KG 结合了稳健的共指解析和句法句子分解，通过系统选择最佳提示-模型对来提高句子简化和关系抽取的准确性。

Result: CoDe-KG 在关系抽取任务中取得了显著的性能提升，例如在 REBEL 上达到 65.8% 的 macro-F1，在 WebNLG2 上达到 75.7% 的 micro-F1。此外，整合共指和分解可以提高罕见关系的召回率。

Conclusion: CoDe-KG 是一个用于提取句子级知识图谱的开源端到端管道，通过结合稳健的共指解析和句法句子分解。该模型贡献了一个包含超过150,000个知识三元组的数据集，并提供了多个训练语料库和人工标注数据。实验结果显示，该方法在关系抽取任务中取得了显著的性能提升。

Abstract: We introduce CoDe-KG, an open-source, end-to-end pipeline for extracting
sentence-level knowledge graphs by combining robust coreference resolution with
syntactic sentence decomposition. Using our model, we contribute a dataset of
over 150,000 knowledge triples, which is open source. We also contribute a
training corpus of 7248 rows for sentence complexity, 190 rows of gold human
annotations for co-reference resolution using open source lung-cancer abstracts
from PubMed, 900 rows of gold human annotations for sentence conversion
policies, and 398 triples of gold human annotations. We systematically select
optimal prompt-model pairs across five complexity categories, showing that
hybrid chain-of-thought and few-shot prompting yields up to 99.8% exact-match
accuracy on sentence simplification. On relation extraction (RE), our pipeline
achieves 65.8% macro-F1 on REBEL, an 8-point gain over the prior state of the
art, and 75.7% micro-F1 on WebNLG2, while matching or exceeding performance on
Wiki-NRE and CaRB. Ablation studies demonstrate that integrating coreference
and decomposition increases recall on rare relations by over 20%. Code and
dataset are available at https://github.com/KaushikMahmud/CoDe-KG_EMNLP_2025

</details>


### [72] [Multi-View Attention Multiple-Instance Learning Enhanced by LLM Reasoning for Cognitive Distortion Detection](https://arxiv.org/abs/2509.17292)
*Jun Seo Kim,Hyemi Kim,Woo Joo Oh,Hongjin Cho,Hochul Lee,Hye Hyeon Kim*

Main category: cs.CL

TL;DR: 本文提出了一种结合大型语言模型和多实例学习架构的新框架，以提高心理健康自然语言处理中认知扭曲的自动检测和细粒度推理能力。


<details>
  <summary>Details</summary>
Motivation: 认知扭曲与心理健康障碍密切相关，但由于上下文模糊性、共现和语义重叠，其自动检测仍然具有挑战性。

Method: 我们提出了一个结合大型语言模型（LLMs）和多实例学习（MIL）架构的新框架，以提高可解释性和表达水平的推理。每个话语被分解为情感、逻辑和行为（ELB）组件，由LLMs处理以推断多个扭曲实例，每个实例都有预测类型、表达和模型分配的显著性分数。这些实例通过多视图门控注意力机制进行整合以进行最终分类。

Result: 在韩语（KoACD）和英语（Therapist QA）数据集上的实验表明，结合ELB和LLM推断的显著性分数可以提高分类性能，特别是对于具有高解释歧义的扭曲。

Conclusion: 我们的结果表明，这是一种心理上有根据且可推广的细粒度推理方法，用于心理健康自然语言处理。

Abstract: Cognitive distortions have been closely linked to mental health disorders,
yet their automatic detection remained challenging due to contextual ambiguity,
co-occurrence, and semantic overlap. We proposed a novel framework that
combines Large Language Models (LLMs) with Multiple-Instance Learning (MIL)
architecture to enhance interpretability and expression-level reasoning. Each
utterance was decomposed into Emotion, Logic, and Behavior (ELB) components,
which were processed by LLMs to infer multiple distortion instances, each with
a predicted type, expression, and model-assigned salience score. These
instances were integrated via a Multi-View Gated Attention mechanism for final
classification. Experiments on Korean (KoACD) and English (Therapist QA)
datasets demonstrate that incorporating ELB and LLM-inferred salience scores
improves classification performance, especially for distortions with high
interpretive ambiguity. Our results suggested a psychologically grounded and
generalizable approach for fine-grained reasoning in mental health NLP.

</details>


### [73] [Scaling, Simplification, and Adaptation: Lessons from Pretraining on Machine-Translated Text](https://arxiv.org/abs/2509.17317)
*Dan John Velasco,Matthew Theodore Roque*

Main category: cs.CL

TL;DR: This paper explores the effectiveness of using machine translation-derived data for pretraining models in low-resource languages, finding that scaling and adapting on native text can improve performance, but certain tasks still require more native data.


<details>
  <summary>Details</summary>
Motivation: Most languages lack sufficient data for large-scale monolingual pretraining, creating a 'data wall.' Multilingual pretraining is limited by language imbalance and the 'curse of multilinguality.'

Method: The paper translates English into Indonesian and Tamil and pretrains GPT-2 models on native or MT-derived corpora from raw and LLM-simplified English.

Result: MT-pretrained models benefit from scaling; source-side simplification harms generalization to native text; adapting MT-pretrained models on native text often yields better performance than native-only models, even with less native data. However, tasks requiring cultural nuance demand more exposure to native data.

Conclusion: MT-pretrained models can benefit from scaling and adapting on native text, but tasks requiring cultural nuance still need more native data.

Abstract: Most languages lack sufficient data for large-scale monolingual pretraining,
creating a "data wall." Multilingual pretraining helps but is limited by
language imbalance and the "curse of multilinguality." An alternative is to
translate high-resource text with machine translation (MT), which raises three
questions: (1) How does MT-derived data scale with model capacity? (2) Can
source-side transformations (e.g., simplifying English with an LLM) improve
generalization to native text? (3) How well do models pretrained on MT-derived
data adapt when continually trained on limited native text? We investigate
these questions by translating English into Indonesian and Tamil--two
typologically distant, lower-resource languages--and pretraining GPT-2 models
(124M-774M) on native or MT-derived corpora from raw and LLM-simplified
English. We evaluate cross-entropy loss on native text, along with accuracy on
syntactic probes and downstream tasks. Our results show that (1) MT-pretrained
models benefit from scaling; (2) source-side simplification harms
generalization to native text; and (3) adapting MT-pretrained models on native
text often yields better performance than native-only models, even with less
native data. However, tasks requiring cultural nuance (e.g., toxicity
detection) demand more exposure to native data.

</details>


### [74] [AIMMerging: Adaptive Iterative Model Merging Using Training Trajectories for Language Model Continual Learning](https://arxiv.org/abs/2509.17348)
*Yujie Feng,Jian Li,Xiaoyu Dong,Pengfei Xu,Xiaohui Zhou,Yujia Zhang,Zexin LU,Yasha Wang,Alan Zhao,Xu Chu,Xiao-Ming Wu*

Main category: cs.CL

TL;DR: 本文提出了一种新的持续学习框架AimMerging，通过动态监控训练轨迹中的学习和遗忘信号，自适应地确定迭代融合的时间和频率，并计算融合权重。实验表明，AimMerging在多个基准测试中表现出色，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: Recent model merging-based methods have attracted significant attention, but they still struggle to effectively manage the trade-off between learning new knowledge and preventing forgetting, a challenge largely stemming from suboptimal number of merges and merging frequency.

Method: AimMerging, a novel CL framework that utilizes learning and forgetting signals from the training trajectory to dynamically monitor the model's training status. The training trajectory-guided merge controller adaptively determines the timing and frequency of iterative fusion, while the rehearsal-based knowledge fusion module computes the merging weights and executes the fusion.

Result: Comprehensive experiments on three CL benchmarks with various model sizes (from 770M to 13B) demonstrate that AimMerging achieves significant performance improvements over existing state-of-the-art methods, with an average relative improvement of 80% and 59% on FWT and BWT, respectively.

Conclusion: AimMerging achieves significant performance improvements over existing state-of-the-art methods, with an average relative improvement of 80% and 59% on FWT and BWT, respectively.

Abstract: Continual learning (CL) is essential for deploying large language models
(LLMs) in dynamic real-world environments without the need for costly
retraining. Recent model merging-based methods have attracted significant
attention, but they still struggle to effectively manage the trade-off between
learning new knowledge and preventing forgetting, a challenge largely stemming
from suboptimal number of merges and merging frequency. In this paper, we
introduce Adaptive Iterative Model Merging (AimMerging), a novel CL framework
that utilizes learning and forgetting signals from the training trajectory to
dynamically monitor the model's training status. Guided by dynamic monitoring,
the training trajectory-guided merge controller adaptively determines the
timing and frequency of iterative fusion, while the rehearsal-based knowledge
fusion module computes the merging weights and executes the fusion.
Comprehensive experiments on three CL benchmarks with various model sizes (from
770M to 13B) demonstrate that AimMerging achieves significant performance
improvements over existing state-of-the-art methods, with an average relative
improvement of 80% and 59% on FWT and BWT, respectively. The source code is
provided for reproducibility.

</details>


### [75] [Better Late Than Never: Evaluation of Latency Metrics for Simultaneous Speech-to-Text Translation](https://arxiv.org/abs/2509.17349)
*Peter Polák,Sara Papi,Luisa Bentivogli,Ondřej Bojar*

Main category: cs.CL

TL;DR: 本文分析了SimulST系统的延迟度量问题，提出了改进的度量方法和重新分割工具，以提高评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的延迟度量方法在短格式设置中存在不一致或误导性的结果，需要一种更准确的评估方法。

Method: 本文对SimulST延迟度量进行了全面分析，提出了YAAL和LongYAAL两种改进的延迟度量方法，并开发了SoftSegmenter工具进行重新分割。

Result: YAAL和LongYAAL在短格式和长格式设置中均优于流行的延迟度量方法，而SoftSegmenter提高了长格式评估中的对齐质量。

Conclusion: 本文提出了YAAL和LongYAAL两种改进的延迟度量方法，并引入了SoftSegmenter工具，以提高SimulST系统的评估可靠性。

Abstract: Simultaneous speech-to-text translation (SimulST) systems have to balance
translation quality with latency--the delay between speech input and the
translated output. While quality evaluation is well established, accurate
latency measurement remains a challenge. Existing metrics often produce
inconsistent or misleading results, especially in the widely used short-form
setting, where speech is artificially presegmented. In this paper, we present
the first comprehensive analysis of SimulST latency metrics across language
pairs, systems, and both short- and long-form regimes. We uncover a structural
bias in current metrics related to segmentation that undermines fair and
meaningful comparisons. To address this, we introduce YAAL (Yet Another Average
Lagging), a refined latency metric that delivers more accurate evaluations in
the short-form regime. We extend YAAL to LongYAAL for unsegmented audio and
propose SoftSegmenter, a novel resegmentation tool based on word-level
alignment. Our experiments show that YAAL and LongYAAL outperform popular
latency metrics, while SoftSegmenter enhances alignment quality in long-form
evaluation, together enabling more reliable assessments of SimulST systems.

</details>


### [76] [Scale-free Characteristics of Multilingual Legal Texts and the Limitations of LLMs](https://arxiv.org/abs/2509.17367)
*Haoyang Chen,Kumiko Tanaka-Ishii*

Main category: cs.CL

TL;DR: 本研究比较了不同领域文本的语言复杂性，发现法律文本具有独特的结构和复杂性，而当前的生成模型未能完全复制这些特征。


<details>
  <summary>Details</summary>
Motivation: 研究法律文本与其他类型文本在语言复杂性上的差异，以及当前生成模型是否能够准确再现这些特征。

Method: 通过Heaps指数β（词汇增长）、Taylor指数α（词频波动尺度）、压缩率r（冗余）和熵来量化语言复杂性，并对法律文件、普通自然语言文本和AI生成文本进行比较分析。

Result: 法律文本显示出较慢的词汇增长（较低的β）和较高的术语一致性（较高的α），而GPT生成文本的统计特征更接近普通语言模式。

Conclusion: 法律文本表现出特定领域的结构和复杂性，而当前的生成模型尚未完全复制这些特征。

Abstract: We present a comparative analysis of text complexity across domains using
scale-free metrics. We quantify linguistic complexity via Heaps' exponent
$\beta$ (vocabulary growth), Taylor's exponent $\alpha$ (word-frequency
fluctuation scaling), compression rate $r$ (redundancy), and entropy. Our
corpora span three domains: legal documents (statutes, cases, deeds) as a
specialized domain, general natural language texts (literature, Wikipedia), and
AI-generated (GPT) text. We find that legal texts exhibit slower vocabulary
growth (lower $\beta$) and higher term consistency (higher $\alpha$) than
general texts. Within legal domain, statutory codes have the lowest $\beta$ and
highest $\alpha$, reflecting strict drafting conventions, while cases and deeds
show higher $\beta$ and lower $\alpha$. In contrast, GPT-generated text shows
the statistics more aligning with general language patterns. These results
demonstrate that legal texts exhibit domain-specific structures and
complexities, which current generative models do not fully replicate.

</details>


### [77] [Robustness of Neurosymbolic Reasoners on First-Order Logic Problems](https://arxiv.org/abs/2509.17377)
*Hannah Bansal,Kemal Kurniawan,Lea Frermann*

Main category: cs.CL

TL;DR: 本文探讨了神经符号方法在提高大型语言模型推理能力方面的潜力，并提出了NSCoT方法。虽然NSCoT方法有所改进，但仍然不如标准的CoT方法。


<details>
  <summary>Details</summary>
Motivation: 最近的NLP趋势旨在提高大型语言模型（LLMs）的推理能力，重点在于泛化性和对任务变化的鲁棒性。然而，LLMs在反事实变化上表现出脆弱性，这表明它们通常依赖于表面模式生成响应。因此，我们需要一种更鲁棒的方法来解决这个问题。

Method: 我们探索了神经符号（NS）方法，该方法结合了大型语言模型和符号逻辑求解器，并提出了NSCoT方法，结合了NS方法和思维链（CoT）提示。

Result: 实验结果显示，NS方法比纯神经方法更鲁棒，但性能较差。尽管NSCoT方法提高了性能，但仍落后于标准的CoT方法。

Conclusion: 我们的分析为未来的研究指明了方向。

Abstract: Recent trends in NLP aim to improve reasoning capabilities in Large Language
Models (LLMs), with key focus on generalization and robustness to variations in
tasks. Counterfactual task variants introduce minimal but semantically
meaningful changes to otherwise valid first-order logic (FOL) problem instances
altering a single predicate or swapping roles of constants to probe whether a
reasoning system can maintain logical consistency under perturbation. Previous
studies showed that LLMs becomes brittle on counterfactual variations,
suggesting that they often rely on spurious surface patterns to generate
responses. In this work, we explore if a neurosymbolic (NS) approach that
integrates an LLM and a symbolic logical solver could mitigate this problem.
Experiments across LLMs of varying sizes show that NS methods are more robust
but perform worse overall that purely neural methods. We then propose NSCoT
that combines an NS method and Chain-of-Thought (CoT) prompting and demonstrate
that while it improves performance, NSCoT still lags behind standard CoT. Our
analysis opens research directions for future work.

</details>


### [78] [FinDebate: Multi-Agent Collaborative Intelligence for Financial Analysis](https://arxiv.org/abs/2509.17395)
*Tianshi Cai,Guanxu Li,Nijia Han,Ce Huang,Zimu Wang,Changyu Zeng,Yuqi Wang,Jingshi Zhou,Haiyang Zhang,Qi Chen,Yushan Pan,Shuihua Wang,Wei Wang*

Main category: cs.CL

TL;DR: FinDebate是一个多智能体框架，结合了协作辩论与领域特定的检索增强生成（RAG），用于金融分析。


<details>
  <summary>Details</summary>
Motivation: 为了减轻过度自信并提高可靠性，需要一种方法来生成更准确和可操作的金融分析。

Method: FinDebate是一个多智能体框架，结合了协作辩论与领域特定的检索增强生成（RAG）。五个专门的代理并行运行，以合成证据为多维见解。引入了一种安全辩论协议，使代理能够挑战和改进初始结论，同时保持连贯的建议。

Result: 实验结果表明，该框架在多个时间范围内能够生成高质量的分析，并具有校准的置信度水平和可操作的投资策略。

Conclusion: FinDebate框架在生成高质量分析和校准置信度水平以及可操作的投资策略方面表现出色。

Abstract: We introduce FinDebate, a multi-agent framework for financial analysis,
integrating collaborative debate with domain-specific Retrieval-Augmented
Generation (RAG). Five specialized agents, covering earnings, market,
sentiment, valuation, and risk, run in parallel to synthesize evidence into
multi-dimensional insights. To mitigate overconfidence and improve reliability,
we introduce a safe debate protocol that enables agents to challenge and refine
initial conclusions while preserving coherent recommendations. Experimental
results, based on both LLM-based and human evaluations, demonstrate the
framework's efficacy in producing high-quality analysis with calibrated
confidence levels and actionable investment strategies across multiple time
horizons.

</details>


### [79] [EpiCache: Episodic KV Cache Management for Long Conversational Question Answering](https://arxiv.org/abs/2509.17396)
*Minsoo Kim,Arnav Kundu,Han-Byul Kim,Richa Dixit,Minsik Cho*

Main category: cs.CL

TL;DR: EpiCache是一种无需训练的KV缓存管理框架，用于在固定内存预算下进行长对话问答，通过块级预填充和情景KV压缩来限制缓存增长，并通过自适应分层预算分配策略来分配内存预算。


<details>
  <summary>Details</summary>
Motivation: 现有的KV缓存压缩方法存在两个主要限制：(i) 在完整上下文预填充后驱逐条目会导致无界峰值内存，(ii) 查询依赖的驱逐会将缓存缩小到单个查询，导致多轮对话中的准确性下降。

Method: EpiCache是一种无需训练的KV缓存管理框架，通过块级预填充和情景KV压缩来限制缓存增长，并通过自适应分层预算分配策略来分配内存预算。

Result: EpiCache在三个LongConvQA基准测试中，准确率提高了高达40%，在4-6倍压缩下保持接近完整的KV准确性，并减少了延迟和内存使用高达2.4倍和3.5倍。

Conclusion: EpiCache在三个LongConvQA基准测试中提高了准确性，同时在严格的资源限制下实现了高效的多轮交互。

Abstract: Recent advances in large language models (LLMs) have extended context
lengths, enabling assistants to sustain long histories for coherent,
personalized responses. This ability, however, hinges on Key-Value (KV)
caching, whose memory grows linearly with dialogue length and quickly dominates
under strict resource constraints. An active line of research for reducing this
overhead is KV cache compression, which seeks to limit cache size while
preserving accuracy. Yet existing methods face two major limitations: (i)
evicting entries after full-context prefill causes unbounded peak memory, and
(ii) query-dependent eviction narrows the cache to a single query, leading to
degraded accuracy in multi-turn conversations. We introduce EpiCache, a
training-free KV cache management framework for long conversational question
answering (LongConvQA) under fixed memory budgets. EpiCache bounds cache growth
through block-wise prefill and preserves topic-relevant context via episodic KV
compression, which clusters conversation history into coherent episodes and
applies episode-specific KV cache eviction. We further design an adaptive
layer-wise budget allocation strategy that measures each layer's sensitivity to
eviction and distributes the memory budget across layers accordingly. Across
three LongConvQA benchmarks, EpiCache improves accuracy by up to 40% over
recent baselines, sustains near-full KV accuracy under 4-6x compression, and
reduces latency and memory by up to 2.4x and 3.5x, thereby enabling efficient
multi-turn interaction under strict resource constraints.

</details>


### [80] [DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context](https://arxiv.org/abs/2509.17399)
*Pramit Sahoo,Maharaj Brahma,Maunendra Sankar Desarkar*

Main category: cs.CL

TL;DR: 本文提出了一种新的文化特定项（CSI）数据集DIWALI，用于评估大型语言模型（LLMs）在文化意识和对齐方面的表现。该数据集涵盖了17个文化方面和36个子区域的文化概念，并通过LLM作为裁判和人类评估进行了评估。结果表明，LLMs在子区域覆盖和表面层次适应方面存在选择性表现。


<details>
  <summary>Details</summary>
Motivation: 现有的文化特定项（CSIs）数据集主要关注区域层面的概念，可能存在假阳性。为了弥补这一不足，本文提出了一个针对印度文化的新型CSI数据集，以提高LLMs在文化意识和对齐方面的表现。

Method: 本文引入了一个新的CSI数据集DIWALI，涵盖了17个文化方面和36个子区域的文化概念。通过使用CSIs创建的适应、LLM作为裁判以及来自不同社会经济背景地区的用户评估来衡量LLMs的文化能力。此外，还进行了定量分析，以展示LLMs在子区域覆盖和表面层次适应方面的表现。

Result: 本文构建的DIWALI数据集包含约8000个文化概念，涵盖36个子区域。通过评估LLMs在文化文本适应任务中的表现，并结合人类评估和定量分析，展示了LLMs在子区域覆盖和表面层次适应方面的选择性表现。

Conclusion: 本文介绍了针对印度文化的新型文化特定项（CSI）数据集DIWALI，旨在解决大型语言模型（LLMs）在文化意识和对齐方面的不足。通过评估LLMs在文化文本适应任务中的表现，以及进行定量分析，展示了LLMs在子区域覆盖和表面层次适应方面的选择性表现。

Abstract: Large language models (LLMs) are widely used in various tasks and
applications. However, despite their wide capabilities, they are shown to lack
cultural alignment \citep{ryan-etal-2024-unintended,
alkhamissi-etal-2024-investigating} and produce biased generations
\cite{naous-etal-2024-beer} due to a lack of cultural knowledge and competence.
Evaluation of LLMs for cultural awareness and alignment is particularly
challenging due to the lack of proper evaluation metrics and unavailability of
culturally grounded datasets representing the vast complexity of cultures at
the regional and sub-regional levels. Existing datasets for culture specific
items (CSIs) focus primarily on concepts at the regional level and may contain
false positives. To address this issue, we introduce a novel CSI dataset for
Indian culture, belonging to 17 cultural facets. The dataset comprises $\sim$8k
cultural concepts from 36 sub-regions. To measure the cultural competence of
LLMs on a cultural text adaptation task, we evaluate the adaptations using the
CSIs created, LLM as Judge, and human evaluations from diverse
socio-demographic region. Furthermore, we perform quantitative analysis
demonstrating selective sub-regional coverage and surface-level adaptations
across all considered LLMs. Our dataset is available here:
\href{https://huggingface.co/datasets/nlip/DIWALI}{https://huggingface.co/datasets/nlip/DIWALI},
project
webpage\footnote{\href{https://nlip-lab.github.io/nlip/publications/diwali/}{https://nlip-lab.github.io/nlip/publications/diwali/}},
and our codebase with model outputs can be found here:
\href{https://github.com/pramitsahoo/culture-evaluation}{https://github.com/pramitsahoo/culture-evaluation}.

</details>


### [81] [Vision Language Models Are Not (Yet) Spelling Correctors](https://arxiv.org/abs/2509.17418)
*Junhong Liang,Bojun Zhang*

Main category: cs.CL

TL;DR: 本文介绍了ReViCo，这是第一个系统评估VLMs在真实世界视觉拼写纠正的基准，涵盖了中文和英文。通过在代表性级联（Qwen）和原生（InternVL）开源模型以及封闭源系统（GPT-4o, Claude）上的全面实验，我们展示了当前VLMs在纠正方面明显落后于人类表现。我们探索了两种解决方案范式：联合OCR-纠正管道和背景信息增强方法，这两种方法都产生了稳定的性能提升。我们的分析突出了现有架构的根本局限性，并为推进多模态拼写纠正提供了可行的见解。


<details>
  <summary>Details</summary>
Motivation: 视觉输入的拼写纠正对视觉语言模型（VLMs）提出了独特的挑战，因为它不仅需要检测还需要直接在图像中纠正文本错误。

Method: 我们探索了两种解决方案范式：联合OCR-修正管道和背景信息增强方法，这两种方法都产生了稳定的性能提升。

Result: 当前的VLMs在纠正方面明显落后于人类表现，特别是在纠正方面。

Conclusion: 我们的分析突出了现有架构的根本局限性，并为推进多模态拼写纠正提供了可行的见解。

Abstract: Spelling correction from visual input poses unique challenges for vision
language models (VLMs), as it requires not only detecting but also correcting
textual errors directly within images. We present ReViCo (Real Visual
Correction), the first benchmark that systematically evaluates VLMs on
real-world visual spelling correction across Chinese and English. ReViCo
contains naturally occurring errors collected from real-world image data and
supports fine-grained evaluation at both image and token levels. Through
comprehensive experiments on representative cascaded (Qwen) and native
(InternVL) open-source models, as well as closed-source systems (GPT-4o,
Claude), we show that current VLMs fall significantly short of human
performance, particularly in correction. To address these limitations, we
explore two solution paradigms: a Joint OCR-Correction pipeline and a
Background Information enhanced approach, both of which yield consistent
performance gains. Our analysis highlights fundamental limitations of existing
architectures and provides actionable insights for advancing multimodal
spelling correction.

</details>


### [82] [RealBench: A Chinese Multi-image Understanding Benchmark Close to Real-world Scenarios](https://arxiv.org/abs/2509.17421)
*Fei Zhao,Chengqiang Lu,Yufan Shen,Qimeng Wang,Yicheng Qian,Haoxin Zhang,Yan Gao,Yi Wu,Yao Hu,Zhen Wu,Shangyu Xing,Xinyu Dai*

Main category: cs.CL

TL;DR: RealBench is the first Chinese multimodal multi-image dataset, which highlights the challenges faced by models in handling multi-image Chinese scenarios and shows a significant performance gap between open-source and closed-source models.


<details>
  <summary>Details</summary>
Motivation: To fill the gap of Chinese multi-image datasets, as existing datasets are primarily based on English.

Method: Introduce RealBench, the first Chinese multimodal multi-image dataset, and conduct a comprehensive evaluation of RealBench using 21 multimodal LLMs of different sizes.

Result: Even the most powerful closed-source models still face challenges when handling multi-image Chinese scenarios. There remains a noticeable performance gap of around 71.8% on average between open-source visual/video models and closed-source models.

Conclusion: RealBench provides an important research foundation for further exploring multi-image understanding capabilities in the Chinese context.

Abstract: While various multimodal multi-image evaluation datasets have been emerged,
but these datasets are primarily based on English, and there has yet to be a
Chinese multi-image dataset. To fill this gap, we introduce RealBench, the
first Chinese multimodal multi-image dataset, which contains 9393 samples and
69910 images. RealBench distinguishes itself by incorporating real
user-generated content, ensuring high relevance to real-world applications.
Additionally, the dataset covers a wide variety of scenes, image resolutions,
and image structures, further increasing the difficulty of multi-image
understanding. Ultimately, we conduct a comprehensive evaluation of RealBench
using 21 multimodal LLMs of different sizes, including closed-source models
that support multi-image inputs as well as open-source visual and video models.
The experimental results indicate that even the most powerful closed-source
models still face challenges when handling multi-image Chinese scenarios.
Moreover, there remains a noticeable performance gap of around 71.8\% on
average between open-source visual/video models and closed-source models. These
results show that RealBench provides an important research foundation for
further exploring multi-image understanding capabilities in the Chinese
context.

</details>


### [83] [QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models](https://arxiv.org/abs/2509.17428)
*Hyesung Jeon,Seojune Lee,Beomseok Kang,Yulhwa Kim,Jae-Joon Kim*

Main category: cs.CL

TL;DR: QWHA is a method that integrates FT-based adapters into quantized models using the Walsh-Hadamard Transform and a novel initialization scheme, effectively reducing quantization errors and computational costs.


<details>
  <summary>Details</summary>
Motivation: The demand for efficient deployment of large language models (LLMs) has driven interest in quantization and parameter-efficient fine-tuning (PEFT). Quantization-aware PEFT is needed to produce accurate yet efficient quantized models, but existing methods have limitations in representational capacity and error reduction.

Method: QWHA integrates FT-based adapters into quantized models by employing the Walsh-Hadamard Transform (WHT) as the transform kernel, together with a novel adapter initialization scheme incorporating adaptive parameter selection and value refinement.

Result: QWHA consistently outperforms baselines in low-bit quantization accuracy and achieves significant training speedups over existing FT-based adapters.

Conclusion: QWHA effectively mitigates quantization errors while facilitating fine-tuning, and its design substantially reduces computational cost.

Abstract: The demand for efficient deployment of large language models (LLMs) has
driven interest in quantization, which reduces inference cost, and
parameter-efficient fine-tuning (PEFT), which lowers training overhead. This
motivated the development of quantization-aware PEFT to produce accurate yet
efficient quantized models. In this setting, reducing quantization error prior
to fine-tuning is crucial for achieving high model accuracy. However, existing
methods that rely on low-rank adaptation suffer from limited representational
capacity. Recent Fourier-related transform (FT)-based adapters offer greater
representational power than low-rank adapters, but their direct integration
into quantized models often results in ineffective error reduction and
increased computational overhead. To overcome these limitations, we propose
QWHA, a method that integrates FT-based adapters into quantized models by
employing the Walsh-Hadamard Transform (WHT) as the transform kernel, together
with a novel adapter initialization scheme incorporating adaptive parameter
selection and value refinement. We demonstrate that QWHA effectively mitigates
quantization errors while facilitating fine-tuning, and that its design
substantially reduces computational cost. Experimental results show that QWHA
consistently outperforms baselines in low-bit quantization accuracy and
achieves significant training speedups over existing FT-based adapters. The
code is available at https://github.com/vantaa89/qwha.

</details>


### [84] [MedFact: A Large-scale Chinese Dataset for Evidence-based Medical Fact-checking of LLM Responses](https://arxiv.org/abs/2509.17436)
*Tong Chen,Zimu Wang,Yiyi Miao,Haoran Luo,Yuanfei Sun,Wei Wang,Zhengyong Jiang,Procheta Sen,Jionglong Su*

Main category: cs.CL

TL;DR: 本文介绍了MedFact数据集，这是首个用于验证大型语言模型生成医学内容的事实核查数据集，并展示了其在实际应用中的能力和挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集主要关注人类生成的内容，而对大型语言模型生成的内容的验证研究较少，因此需要一个专门的数据集来填补这一空白。

Method: 本文提出了MedFact数据集，包含1321个问题和7409个声明，模拟了现实世界的医学场景，并在上下文学习和微调设置中进行了全面实验。

Result: 实验展示了当前大型语言模型在医学事实核查任务上的能力和挑战，并通过深入的错误分析指出了未来研究的关键方向。

Conclusion: 本文介绍了MedFact数据集，这是首个基于证据的中文医学事实核查数据集，用于验证大型语言模型生成的医学内容。

Abstract: Medical fact-checking has become increasingly critical as more individuals
seek medical information online. However, existing datasets predominantly focus
on human-generated content, leaving the verification of content generated by
large language models (LLMs) relatively unexplored. To address this gap, we
introduce MedFact, the first evidence-based Chinese medical fact-checking
dataset of LLM-generated medical content. It consists of 1,321 questions and
7,409 claims, mirroring the complexities of real-world medical scenarios. We
conduct comprehensive experiments in both in-context learning (ICL) and
fine-tuning settings, showcasing the capability and challenges of current LLMs
on this task, accompanied by an in-depth error analysis to point out key
directions for future research. Our dataset is publicly available at
https://github.com/AshleyChenNLP/MedFact.

</details>


### [85] [GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning](https://arxiv.org/abs/2509.17437)
*Guizhen Chen,Weiwen Xu,Hao Zhang,Hou Pong Chan,Deli Zhao,Anh Tuan Luu,Yu Rong*

Main category: cs.CL

TL;DR: 本文研究了多模态语言模型在视觉密集型任务中的局限性，并提出了一种两阶段的强化学习训练框架以提高其几何推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习（RL）的进步提高了大型语言模型（LLMs）的推理能力，但对多模态LLMs（MLLMs）的影响有限。特别是在视觉密集型任务中，MLLMs经常出现幻觉，导致不准确的推理。

Method: 我们设计了一个Geo-Perception Question-Answering (GeoPQA)基准来量化MLLMs在视觉感知方面的不足，并提出了一种两阶段的RL训练框架，首先增强几何结构的视觉感知，然后培养推理能力。

Result: 实验表明，MLLMs在视觉感知方面存在显著缺陷，这限制了RL奖励信号的有效训练。通过两阶段训练框架，我们的方法在几何推理和问题解决上取得了显著提升。

Conclusion: 我们的方法在几何推理和问题解决方面分别提高了9.7%和9.1%，并且可以推广到其他视觉密集型领域，这表明感知基础在有效的MLLM推理中非常重要。

Abstract: Recent advancements in reinforcement learning (RL) have enhanced the
reasoning abilities of large language models (LLMs), yet the impact on
multimodal LLMs (MLLMs) is limited. Particularly in vision-intensive tasks like
geometric reasoning, MLLMs hallucinate frequently, leading to inaccurate
reasoning. We attribute this to the perceptual bottleneck in MLLMs, which caps
the benefits of reasoning training. To quantify this, we design a
Geo-Perception Question-Answering (GeoPQA) benchmark, targeting basic geometric
concepts and spatial relationships. Experiments on GeoPQA reveal significant
shortcomings of MLLMs in visual perception, which constrain RL reward signals
for effective training. To address this bottleneck, we propose a two-stage RL
training framework by first enhancing the visual perception of geometric
structures, then fostering reasoning capabilities. Applied to
Qwen2.5-VL-3B-Instruct, our two-stage training improves geometric reasoning by
9.7% and geometric problem solving by 9.1%, compared to the direct reasoning
training approach. Our method also generalizes to other vision-intensive
domains like figure understanding, highlighting the importance of perceptual
grounding in effective MLLM reasoning.

</details>


### [86] [Filling in the Clinical Gaps in Benchmark: Case for HealthBench for the Japanese medical system](https://arxiv.org/abs/2509.17444)
*Shohei Hisada,Endo Sunao,Himi Yamato,Shoko Wakamiya,Eiji Aramaki*

Main category: cs.CL

TL;DR: 本研究探讨了HealthBench在日语环境中的适用性，发现直接翻译基准存在局限性，并强调了为日本开发一个上下文感知的本地化适应版本的必要性。


<details>
  <summary>Details</summary>
Motivation: 尽管强大的评估框架对于安全开发医疗LLM至关重要，但日语资源仍然有限，通常依赖于翻译的多项选择题。本研究旨在填补这一空白。

Method: 本研究首先建立了一个性能基线，应用了HealthBench的5000个场景的机器翻译版本来评估一个高性能多语言模型（GPT-4.1）和一个日本本地的开源模型（LLM-jp-3.1）。其次，我们采用LLM-as-a-Judge的方法系统地分类了基准的场景和评分标准，识别出内容与日本临床指南、医疗系统或文化规范不一致的“上下文差距”。

Result: 我们的研究发现，由于评分标准不匹配，GPT-4.1的表现略有下降，而日本本地模型则显著失败，因为它缺乏所需的临床完整性。此外，我们的分类表明，虽然大多数场景是适用的，但评分标准的相当一部分需要本地化。

Conclusion: 本研究强调了直接翻译基准的局限性，并突出了为日本开发一个上下文感知的本地化适应版本（J-HealthBench）的紧迫需求，以确保在日本评估医疗LLM的可靠性和安全性。

Abstract: This study investigates the applicability of HealthBench, a large-scale,
rubric-based medical benchmark, to the Japanese context. While robust
evaluation frameworks are crucial for the safe development of medical LLMs,
resources in Japanese remain limited, often relying on translated
multiple-choice questions. Our research addresses this gap by first
establishing a performance baseline, applying a machine-translated version of
HealthBench's 5,000 scenarios to evaluate both a high-performing multilingual
model (GPT-4.1) and a Japanese-native open-source model (LLM-jp-3.1). Second,
we employ an LLM-as-a-Judge approach to systematically classify the benchmark's
scenarios and rubric criteria, identifying "contextual gaps" where content is
misaligned with Japan's clinical guidelines, healthcare systems, or cultural
norms. Our findings reveal a modest performance drop in GPT-4.1 due to rubric
mismatches and a significant failure in the Japanese-native model, which lacked
the required clinical completeness. Furthermore, our classification indicates
that while the majority of scenarios are applicable, a substantial portion of
the rubric criteria requires localization. This work underscores the
limitations of direct benchmark translation and highlights the urgent need for
a context-aware, localized adaptation, a J-HealthBench, to ensure the reliable
and safe evaluation of medical LLMs in Japan.

</details>


### [87] [Semantic Reformulation Entropy for Robust Hallucination Detection in QA Tasks](https://arxiv.org/abs/2509.17445)
*Chaodong Tong,Qi Zhang,Lei Jiang,Yanbing Liu,Nannan Sun,Wei Li*

Main category: cs.CL

TL;DR: 本文提出了一种新的不确定性估计方法SRE，通过输入侧的语义重述和基于能量的混合聚类来提高问答系统的可靠性。


<details>
  <summary>Details</summary>
Motivation: 可靠的问答与大型语言模型（LLMs）受到幻觉的挑战，这是由于认知不确定性而产生的流畅但事实错误的输出。现有的基于熵的语义级不确定性估计方法受到采样噪声和可变长度答案不稳定聚类的限制。

Method: 我们提出了语义重述熵（SRE），它通过两种方式改进了不确定性估计。首先，输入侧的语义重述生成忠实的同义词，扩展了估计空间，并减少了从表面解码器倾向中的偏差。其次，基于能量的渐进式混合聚类稳定了语义分组。

Result: 在SQuAD和TriviaQA上的实验表明，SRE优于强大的基线，提供了更稳健和通用的幻觉检测。

Conclusion: 这些结果表明，将输入多样化与多信号聚类相结合可以显著增强语义级不确定性估计。

Abstract: Reliable question answering with large language models (LLMs) is challenged
by hallucinations, fluent but factually incorrect outputs arising from
epistemic uncertainty. Existing entropy-based semantic-level uncertainty
estimation methods are limited by sampling noise and unstable clustering of
variable-length answers. We propose Semantic Reformulation Entropy (SRE), which
improves uncertainty estimation in two ways. First, input-side semantic
reformulations produce faithful paraphrases, expand the estimation space, and
reduce biases from superficial decoder tendencies. Second, progressive,
energy-based hybrid clustering stabilizes semantic grouping. Experiments on
SQuAD and TriviaQA show that SRE outperforms strong baselines, providing more
robust and generalizable hallucination detection. These results demonstrate
that combining input diversification with multi-signal clustering substantially
enhances semantic-level uncertainty estimation.

</details>


### [88] [SLAyiNG: Towards Queer Language Processing](https://arxiv.org/abs/2509.17449)
*Leonor Veloso,Lea Hirlimann,Philipp Wicke,Hinrich Schütze*

Main category: cs.CL

TL;DR: 本文介绍了SLAyiNG数据集，这是第一个包含从字幕、社交媒体帖子和播客中提取的标注酷儿俚语的数据集，并探讨了使用最先进的推理模型进行预筛选的可行性。


<details>
  <summary>Details</summary>
Motivation: 目前的研究努力尚未明确关注酷儿俚语，特别是由于缺乏高质量的标注基准，对酷儿俚语的检测和处理尚未得到充分评估。

Method: 我们收集了来自字幕、社交媒体帖子和播客的标注酷儿俚语数据集SLAyiNG，并描述了我们的数据收集过程，包括俚语术语和定义的收集、示例的来源 scraping 以及正在进行的注释过程。

Result: 我们计算了人类注释者和OpenAI的o3-mini模型之间的注释者间一致性，评估了在意义消歧任务上的表现。平均Krippendorff's alpha为0.746。

Conclusion: 我们认为最先进的推理模型可以作为预筛选工具，但由于酷儿语言数据的复杂性和敏感性，需要专家和社区驱动的注释工作。

Abstract: Knowledge of slang is a desirable feature of LLMs in the context of user
interaction, as slang often reflects an individual's social identity. Several
works on informal language processing have defined and curated benchmarks for
tasks such as detection and identification of slang. In this paper, we focus on
queer slang. Queer slang can be mistakenly flagged as hate speech or can evoke
negative responses from LLMs during user interaction. Research efforts so far
have not focused explicitly on queer slang. In particular, detection and
processing of queer slang have not been thoroughly evaluated due to the lack of
a high-quality annotated benchmark. To address this gap, we curate SLAyiNG, the
first dataset containing annotated queer slang derived from subtitles, social
media posts, and podcasts, reflecting real-world usage. We describe our data
curation process, including the collection of slang terms and definitions,
scraping sources for examples that reflect usage of these terms, and our
ongoing annotation process. As preliminary results, we calculate
inter-annotator agreement for human annotators and OpenAI's model o3-mini,
evaluating performance on the task of sense disambiguation. Reaching an average
Krippendorff's alpha of 0.746, we argue that state-of-the-art reasoning models
can serve as tools for pre-filtering, but the complex and often sensitive
nature of queer language data requires expert and community-driven annotation
efforts.

</details>


### [89] [Codifying Natural Langauge Tasks](https://arxiv.org/abs/2509.17455)
*Haoyang Chen,Kumiko Tanaka-Ishii*

Main category: cs.CL

TL;DR: 本文研究了文本到代码在现实问题中的应用，并提出了一个框架ICRAG，通过迭代优化和外部知识提高性能。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索文本到代码在现实世界自然语言任务中的应用，并改进现有的方法。

Method: 本文提出了一种利用程序生成提供的显式推理的方法，并介绍了ICRAG框架，该框架通过使用来自领域资源和GitHub的外部知识进行迭代优化，将自然语言转换为可执行程序。

Result: 在13个基准测试中，ICRAG实现了高达161.1%的相对改进。

Conclusion: 本文探讨了文本到代码的应用，以解决通常用自然语言解决的现实问题，如法律判决和医疗问答。

Abstract: We explore the applicability of text-to-code to solve real-world problems
that are typically solved in natural language, such as legal judgment and
medical QA. Unlike previous works, our approach leverages the explicit
reasoning provided by program generation. We present ICRAG, a framework that
transforms natural language into executable programs through iterative
refinement using external knowledge from domain resources and GitHub. Across 13
benchmarks, ICRAG achieves up to 161.1\% relative improvement. We provide a
detailed analysis of the generated code and the impact of external knowledge,
and we discuss the limitations of applying text-to-code approaches to
real-world natural language tasks.

</details>


### [90] [PRINCIPLES: Synthetic Strategy Memory for Proactive Dialogue Agents](https://arxiv.org/abs/2509.17459)
*Namyoung Kim,Kai Tzu-iunn Ong,Yeonjun Hwang,Minseok Kang,Iiseo Jihn,Gayoung Kim,Minju Kim,Jinyoung Yeo*

Main category: cs.CL

TL;DR: PRINCIPLES is a synthetic strategy memory for proactive dialogue agents that improves performance without additional training.


<details>
  <summary>Details</summary>
Motivation: Existing approaches to strategy planning for proactive dialogue face limitations such as limited strategy coverage, preference bias in planning, and reliance on costly additional training.

Method: PRINCIPLES is derived through offline self-play simulations and serves as reusable knowledge that guides strategy planning during inference, eliminating the need for additional training and data annotation.

Result: PRINCIPLES shows consistent improvements over strong baselines in emotional support and persuasion domains, and remains robust across extended and diverse evaluation settings.

Conclusion: PRINCIPLES demonstrates consistent improvements over strong baselines in emotional support and persuasion domains, and maintains robustness across extended and diverse evaluation settings.

Abstract: Dialogue agents based on large language models (LLMs) have shown promising
performance in proactive dialogue, which requires effective strategy planning.
However, existing approaches to strategy planning for proactive dialogue face
several limitations: limited strategy coverage, preference bias in planning,
and reliance on costly additional training. To address these, we propose
PRINCIPLES: a synthetic strategy memory for proactive dialogue agents.
PRINCIPLES is derived through offline self-play simulations and serves as
reusable knowledge that guides strategy planning during inference, eliminating
the need for additional training and data annotation. We evaluate PRINCIPLES in
both emotional support and persuasion domains, demonstrating consistent
improvements over strong baselines. Furthermore, PRINCIPLES maintains its
robustness across extended and more diverse evaluation settings. See our
project page at https://huggingface.co/spaces/kimnamssya/Principles.

</details>


### [91] [Diagnosing Model Editing via Knowledge Spectrum](https://arxiv.org/abs/2509.17482)
*Tsung-Hsuan Pan,Chung-Chi Chen,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: 本文提出了一种新的框架，用于更有效地编辑预训练语言模型中的事实知识，提高成功率并优化计算资源。


<details>
  <summary>Details</summary>
Motivation: 现有编辑方法常引入意外副作用，影响模型性能，而目标知识的内在属性是重要的但未被充分研究的因素。

Method: 本文提出了“知识谱系”和“知识诊断框架”，用于分类知识并根据知识项的难度调整编辑强度。

Result: 实证分析表明，知识的特性是编辑成功和稳定性的强预测因子，所提出的框架显著提高了挑战性编辑的成功率。

Conclusion: 本文提供了对模型编辑中影响因素的更全面理解，并通过提出的框架提高了编辑的成功率和计算资源的优化。

Abstract: Model editing, the process of efficiently modifying factual knowledge in
pre-trained language models, is critical for maintaining their accuracy and
relevance. However, existing editing methods often introduce unintended side
effects, degrading model performance in unpredictable ways. While much research
has focused on improving editing algorithms, the role of the target knowledge's
intrinsic properties remains a significant, underexplored factor. This paper
addresses this gap by first proposing the ``Knowledge Spectrum,'' a systematic
framework for categorizing knowledge based on its real-world popularity, the
model's pre-edit familiarity, and the linguistic structure of the eliciting
question. Our empirical analysis reveals that these characteristics are strong
predictors of editing success and stability. Informed by these findings, we
introduce the ``Knowledge-Diagnostic Framework,'' an adaptive strategy that
tailors editing intensity to the diagnosed difficulty of a knowledge item. We
demonstrate that this framework significantly improves success rates for
challenging edits while optimizing computational resources. Our work provides a
more comprehensive understanding of the factors governing model editing.

</details>


### [92] [AttnComp: Attention-Guided Adaptive Context Compression for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.17486)
*Lvzhou Luo,Yixuan Cao,Ping Luo*

Main category: cs.CL

TL;DR: AttnComp is a new compression framework that improves the effectiveness of retrieval-augmented generation by adaptively compressing context and estimating response confidence.


<details>
  <summary>Details</summary>
Motivation: Existing context compression methods struggle to adaptively adjust compression rates for different contexts, maintain low latency, and integrate information across multiple documents. AttnComp aims to overcome these limitations.

Method: AttnComp is an adaptive, efficient, and context-aware compression framework that leverages the attention mechanism of LLMs to identify relevant information and employs a Top-P compression algorithm to retain the minimal set of documents whose cumulative attention weights exceed a predefined threshold. It also estimates response confidence by assessing the overall relevance of the retrieved content.

Result: Experiments demonstrate that AttnComp outperforms existing compression methods and uncompressed baselines, achieving higher accuracy with substantial compression rates and lower latency.

Conclusion: AttnComp outperforms existing compression methods and uncompressed baselines, achieving higher accuracy with substantial compression rates and lower latency.

Abstract: Retrieval-augmented generation improves the factual accuracy of Large
Language Models (LLMs) by incorporating external context, but often suffers
from irrelevant retrieved content that hinders effectiveness. Context
compression addresses this issue by filtering out irrelevant information from
context before LLM generation. However, existing methods struggle to adaptively
adjust compression rates for different context, maintain low latency and
integrate information across multiple documents. To overcome these limitations,
We introduce AttnComp, an adaptive, efficient and context-aware compression
framework. By leveraging the attention mechanism of LLMs to identify relevant
information, AttnComp employs a Top-P compression algorithm to retain the
minimal set of documents whose cumulative attention weights exceeds a
predefined threshold. In addition to compression, AttnComp estimates response
confidence by assessing the overall relevance of the retrieved content,
enabling users to gauge response reliability. Experiments demonstrate that
AttnComp outperforms existing compression methods and uncompressed baselines,
achieving higher accuracy with substantial compression rates and lower latency.

</details>


### [93] [MapCoder-Lite: Squeezing Multi-Agent Coding into a Single Small LLM](https://arxiv.org/abs/2509.17489)
*Woongkyu Lee,Junhee Cho,Jungwook Choi*

Main category: cs.CL

TL;DR: MapCoder-Lite通过使用角色特定的LoRA适配器将单个7B模型升级为四个角色专业化代理，从而在小型语言模型上实现了高质量的多代理编程。


<details>
  <summary>Details</summary>
Motivation: 现有的多代理解决方案要么依赖于昂贵的大规模（> 30B）模型，要么在缩小到小型开源模型时会崩溃。

Method: MapCoder-Lite通过使用仅需32个秩的角色特定LoRA适配器（<3%的额外参数）将单个7B模型升级为四个角色专业化代理（检索器、规划者、编码器和调试器）。三种轻量级技术使这成为可能：(i) 从强LLM中进行轨迹蒸馏以修复检索和调试中的格式脆弱性，(ii) 监督引导纠正加强了规划和编码代理，(iii) 代理级LoRA微调实现了内存高效的专门化。

Result: 在xCodeEval、APPS和CodeContests上的全面评估显示，MapCoder-Lite将xCodeEval准确率提高了一倍以上（从13.2%到28.3%），消除了所有格式失败，并在GPU内存和令牌生成时间上减少了4倍，同时接近32B基线。

Conclusion: 这些结果表明，通过仔细的代理微调可以在小型语言模型上实现高质量的多代理编程。

Abstract: Large language models (LLMs) have advanced code generation from
single-function tasks to competitive-programming problems, but existing
multi-agent solutions either rely on costly large-scale ($>$ 30B) models or
collapse when downsized to small open-source models. We present MapCoder-Lite,
which upgrades a single 7B model into four role-specialised agents-retriever,
planner, coder, and debugger-using only rank-32, role-specific LoRA adapters
($<3\%$ extra parameters). Three lightweight techniques make this possible: (i)
trajectory distillation from strong LLMs fixes format fragility in retrieval
and debugging, (ii) supervisor-guided correction strengthens planning and
coding agents, and (iii) agent-wise LoRA fine-tuning delivers memory-efficient
specialisation. Comprehensive evaluation on xCodeEval, APPS, and CodeContests
shows that MapCoder-Lite more than doubles xCodeEval accuracy (from $13.2\%$ to
$28.3\%$), eliminates all format failures, and closes to within six points of a
32B baseline while cutting GPU memory and token-generation time by $4\times$.
These results demonstrate that careful agent-wise fine-tuning unleashes
high-quality multi-agent coding on a small language model.

</details>


### [94] [Enhancing Cross-Lingual Transfer through Reversible Transliteration: A Huffman-Based Approach for Low-Resource Languages](https://arxiv.org/abs/2509.17493)
*Wenhao Zhuang,Yuan Sun,Xiaobing Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种结合字符音译与霍夫曼编码的完整音译框架，以提升大型语言模型对低资源语言的处理能力。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏一个全面的框架来将音译集成到大型语言模型的训练和部署中，特别是对于使用非拉丁字母的低资源语言。

Method: 本文提出了一种结合字符音译与霍夫曼编码的完整音译框架，以解决低资源语言在大型语言模型中的处理问题。

Result: 实验结果表明，该方法在多个下游任务中有效提升了模型对低资源语言的处理能力，同时保持了在高资源语言上的性能。

Conclusion: 本文提出了一种完整的音译框架，通过将字符音译与霍夫曼编码相结合，有效解决了低资源语言在大型语言模型中的处理问题。实验结果表明，该方法显著提升了模型对低资源语言的处理能力，同时保持了在高资源语言上的性能。

Abstract: As large language models (LLMs) are trained on increasingly diverse and
extensive multilingual corpora, they demonstrate cross-lingual transfer
capabilities. However, these capabilities often fail to effectively extend to
low-resource languages, particularly those utilizing non-Latin scripts. While
transliterating low-resource languages into Latin script presents a natural
solution, there currently lacks a comprehensive framework for integrating
transliteration into LLMs training and deployment. Taking a pragmatic approach,
this paper innovatively combines character transliteration with Huffman coding
to design a complete transliteration framework. Our proposed framework offers
the following advantages: 1) Compression: Reduces storage requirements for
low-resource language content, achieving up to 50% reduction in file size and
50-80% reduction in token count. 2) Accuracy: Guarantees 100% lossless
conversion from transliterated text back to the source language. 3) Efficiency:
Eliminates the need for vocabulary expansion for low-resource languages,
improving training and inference efficiency. 4) Scalability: The framework can
be extended to other low-resource languages. We validate the effectiveness of
our framework across multiple downstream tasks, including text classification,
machine reading comprehension, and machine translation. Experimental results
demonstrate that our method significantly enhances the model's capability to
process low-resource languages while maintaining performance on high-resource
languages. Our data and code are publicly available at
https://github.com/CMLI-NLP/HuffmanTranslit.

</details>


### [95] [CorefInst: Leveraging LLMs for Multilingual Coreference Resolution](https://arxiv.org/abs/2509.17505)
*Tuğba Pamay Arslan,Emircan Erol,Gülşen Eryiğit*

Main category: cs.CL

TL;DR: 本研究提出了一种基于解码器的LLM的多语言共指解析方法，并通过指令集进行微调，结果表明该方法优于现有最先进的模型。


<details>
  <summary>Details</summary>
Motivation: 传统的共指解析方法受限于特定任务的架构和需要大量训练的编码器语言模型，缺乏适应性。因此，需要一种更灵活且有效的解决方案。

Method: 该研究提出了一个基于解码器的LLM的多语言共指解析方法，并通过五种不同的指令集进行控制推理方法的建模。

Result: 在三个LLM（Llama 3.1、Gemma 2和Mistral 0.3）上评估了该方法，结果显示，经过适当指令集微调的LLM能够超越最先进的任务特定架构。

Conclusion: 研究结果表明，通过适当的指令集进行微调的LLM可以在多语言共指解析任务中超越现有的最先进方法。

Abstract: Coreference Resolution (CR) is a crucial yet challenging task in natural
language understanding, often constrained by task-specific architectures and
encoder-based language models that demand extensive training and lack
adaptability. This study introduces the first multilingual CR methodology which
leverages decoder-only LLMs to handle both overt and zero mentions. The article
explores how to model the CR task for LLMs via five different instruction sets
using a controlled inference method. The approach is evaluated across three
LLMs; Llama 3.1, Gemma 2, and Mistral 0.3. The results indicate that LLMs, when
instruction-tuned with a suitable instruction set, can surpass state-of-the-art
task-specific architectures. Specifically, our best model, a fully fine-tuned
Llama 3.1 for multilingual CR, outperforms the leading multilingual CR model
(i.e., Corpipe 24 single stage variant) by 2 pp on average across all languages
in the CorefUD v1.2 dataset collection.

</details>


### [96] [Leveraging Audio-Visual Data to Reduce the Multilingual Gap in Self-Supervised Speech Models](https://arxiv.org/abs/2509.17523)
*María Andrea Cruz Blandón,Zakaria Aldeneh,Jie Chi,Maureen de Seyssel*

Main category: cs.CL

TL;DR: 本文研究了通过引入有限的视觉基础来减少双语语音SSL模型的多语言性能差距，结果表明这种方法在零样本语音区分任务中效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言SSL模型在单个语言上的表现不如单语模型，尤其是在双语场景中。因此，需要一种方法来减少这种性能差距。

Method: 通过引入有限的视觉基础，研究了减少双语语音SSL模型性能差距的新方法。

Result: 实验结果表明，视觉基础对单语和双语模型都有益，尤其是对后者，将零样本语音区分任务的多语言性能差距从31.5%降低到8.04%。

Conclusion: 引入有限的视觉基础可以减少双语语音SSL模型的多语言性能差距，特别是在零样本语音区分任务中效果显著。

Abstract: Self-supervised learning (SSL) has made significant advances in speech
representation learning. Models like wav2vec 2.0 and HuBERT have achieved
state-of-the-art results in tasks such as speech recognition, particularly in
monolingual settings. However, multilingual SSL models tend to underperform
their monolingual counterparts on each individual language, especially in
multilingual scenarios with few languages such as the bilingual setting. In
this work, we investigate a novel approach to reduce this performance gap by
introducing limited visual grounding into bilingual speech SSL models. Our
results show that visual grounding benefits both monolingual and bilingual
models, with especially pronounced gains for the latter, reducing the
multilingual performance gap on zero-shot phonetic discrimination from 31.5%
for audio-only models to 8.04% with grounding.

</details>


### [97] [Can LLMs Reason Over Non-Text Modalities in a Training-Free Manner? A Case Study with In-Context Representation Learning](https://arxiv.org/abs/2509.17552)
*Tianle Zhang,Wanlong Fang,Jonathan Woo,Paridhi Latawa,Deepak A. Subramanian,Alvin Chan*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的方法ICRL，用于将非文本模态表示整合到文本型LLM中，实现了多模态推理，并在分子领域任务中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常需要额外的昂贵监督训练，限制了对新领域和模态的实时适应。因此，探索一种无需训练的方式来整合非文本模态表示变得尤为重要。

Method: 提出了一种称为In-Context Representation Learning (ICRL)的方法，通过在不进行额外监督训练的情况下将非文本基础模型（FMs）的表示集成到文本型LLM中，实现多模态推理。

Result: 在分子领域的一系列任务中评估了ICRL，研究了三个核心问题：如何以无训练方式将FM表示映射到LLM中，影响ICRL性能的因素，以及ICRL有效性的机制。

Conclusion: ICRL是第一个无需训练的将非文本模态表示整合到基于文本的LLM中的框架，为可适应的多模态泛化提供了有前景的方向。

Abstract: The remarkable performance of Large Language Models (LLMs) can be enhanced
with test-time computation, which relies on external tools and even other deep
learning models. However, existing approaches for integrating non-text modality
representations into LLMs typically require additional costly supervised
training, restricting on-the-fly adaptation to new domains and modalities. In
this work, we explore the feasibility of integrating representations from
non-text foundational models (FMs) into text-based LLMs in a training-free
manner. We propose In-Context Representation Learning (ICRL) as a
proof-of-concept to allow LLMs to adaptively utilize non-text modality
representations with few-shot learning. Unlike traditional in-context learning,
which incorporates text-label pairs, ICRL replaces text inputs with FM
representations, enabling the LLM to perform multi-modal inference without
fine-tuning. We evaluate ICRL on a suite of tasks in the molecular domain,
investigating three core research questions: (i) how to map FM representations
into LLMs in a training-free manner, (ii) what factors influence ICRL
performance, and (iii) what mechanisms underlie the effectiveness of ICRL. To
the best of our knowledge, ICRL is the first training-free framework for
integrating non-text modality representations into text-based LLMs, presenting
a promising direction for adaptable, multi-modal generalization.

</details>


### [98] [Specification-Aware Machine Translation and Evaluation for Purpose Alignment](https://arxiv.org/abs/2509.17559)
*Yoko Kayano,Saku Sugawara*

Main category: cs.CL

TL;DR: 本文探讨了规范在专业翻译中的重要性，并提出了一个规范感知的机器翻译和评估框架。实验结果表明，由规范指导的大型语言模型翻译在人类评估中表现优于官方人工翻译。


<details>
  <summary>Details</summary>
Motivation: 现有的评估框架承认规范的重要性，但这些规范通常在机器翻译（MT）研究中仅被隐式处理。本文旨在提供一个理论依据和实用指南，以实现规范感知的机器翻译和评估。

Method: 基于翻译研究，提供了为什么规范在专业翻译中重要的理论依据，并提供了实施规范感知机器翻译和评估的实用指南。然后将框架应用于33家上市公司的投资者关系文本的翻译，并比较了五种翻译类型，包括官方人工翻译和大型语言模型（LLMs）的提示输出。

Result: 结果表明，由规范指导的大型语言模型翻译在人类评估中始终优于官方人工翻译，突显了感知质量和预期质量之间的差距。

Conclusion: 将规范纳入机器翻译工作流程，并辅以人工监督，可以以符合专业实践的方式提高翻译质量。

Abstract: In professional settings, translation is guided by communicative goals and
client needs, often formalized as specifications. While existing evaluation
frameworks acknowledge the importance of such specifications, these
specifications are often treated only implicitly in machine translation (MT)
research. Drawing on translation studies, we provide a theoretical rationale
for why specifications matter in professional translation, as well as a
practical guide to implementing specification-aware MT and evaluation. Building
on this foundation, we apply our framework to the translation of investor
relations texts from 33 publicly listed companies. In our experiment, we
compare five translation types, including official human translations and
prompt-based outputs from large language models (LLMs), using expert error
analysis, user preference rankings, and an automatic metric. The results show
that LLM translations guided by specifications consistently outperformed
official human translations in human evaluations, highlighting a gap between
perceived and expected quality. These findings demonstrate that integrating
specifications into MT workflows, with human oversight, can improve translation
quality in ways aligned with professional practice.

</details>


### [99] [Asking a Language Model for Diverse Responses](https://arxiv.org/abs/2509.17570)
*Sergey Troshin,Irina Saparina,Antske Fokkens,Vlad Niculae*

Main category: cs.CL

TL;DR: 本文研究了用于生成多个合理响应的候选采样器，并发现枚举和迭代策略可以在保持生成质量的同时提高响应的多样性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越依赖显式的推理链，并且可以为给定的上下文生成多个合理的响应。我们需要研究能够生成合理响应集的候选采样器，以提高响应的多样性。

Method: 我们比较了候选采样器，包括传统的并行采样、枚举和迭代采样，并在相同的预算下评估它们的质量、词汇和计算流的多样性以及效率。

Result: 我们的实证结果表明，枚举和迭代策略在保持质量的同时实现了更高的多样性。

Conclusion: 我们的研究结果表明，枚举和迭代策略可以在保持生成质量的同时提高响应的多样性。

Abstract: Large language models increasingly rely on explicit reasoning chains and can
produce multiple plausible responses for a given context. We study the
candidate sampler that produces the set of plausible responses contrasting the
ancestral (parallel) sampling against two alternatives: enumeration, which asks
the model to produce $n$ candidates in one pass, and iterative sampling, which
proposes candidates sequentially while conditioning on the currently generated
response set. Under matched budgets, we compare these samplers on quality,
lexical and computation flow diversity, and efficiency. Our empirical results
demonstrate that enumeration and iterative strategies result in higher
diversity at comparable quality. Our findings highlight the potential of simple
non-independent sampling strategies to improve response diversity without
sacrificing generation quality.

</details>


### [100] [MSCoRe: A Benchmark for Multi-Stage Collaborative Reasoning in LLM Agents](https://arxiv.org/abs/2509.17628)
*Yuzhen Lei,Hongbin Xie,Jiaxing Zhao,Shuangxue Liu,Xuan Song*

Main category: cs.CL

TL;DR: MSCoRe is a new benchmark for evaluating multi-stage reasoning in large language models, consisting of 126696 domain-specific QA instances across various sectors.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks typically focus on isolated tasks or narrow domains, overlooking models' abilities for multi-stage collaboration and optimization without explicit external guidance.

Method: We proposed MSCoRe, a novel benchmark comprising 126696 domain-specific QA instances spanning scenarios in automotive, pharmaceutical, electronics, and energy sectors. The dataset is created using a structured three-phase pipeline: dynamic sampling, iterative question-answer generation, and a multi-level quality assessment to ensure data quality.

Result: We have conducted a comprehensive evaluation of various state-of-the-art LLM agents. The commercial models performed best across all tasks and scenarios, but a notable gap in ROUGE scores remains between simple and complex tasks. We also tested the models' robustness and found that their performance is negatively affected by noisy data.

Conclusion: MSCoRe provides a valuable new resource for the community to evaluate and improve multi-stage reasoning in LLM agents.

Abstract: Large Language Models (LLMs) have excelled in question-answering (QA) tasks
within single domains. However, their reasoning and coordination capabilities
in complex, multi-stage scenarios remain underexplored. Existing benchmarks
typically focus on isolated tasks or narrow domains, overlooking models'
abilities for multi-stage collaboration and optimization without explicit
external guidance. To bridge this gap, we propose \textbf{MSCoRe}, a novel
benchmark comprising 126696 domain-specific QA instances spanning scenarios in
automotive, pharmaceutical, electronics, and energy sectors. The dataset is
created using a structured three-phase pipeline: dynamic sampling, iterative
question-answer generation, and a multi-level quality assessment to ensure data
quality. Tasks are further categorized into three difficulty levels according
to stage coverage and complexity. With MSCoRe, we have conducted a
comprehensive evaluation of various state-of-the-art LLM agents. The commercial
models performed best across all tasks and scenarios, but a notable gap in
ROUGE scores remains between simple and complex tasks. We also tested the
models' robustness and found that their performance is negatively affected by
noisy data. MSCoRe provides a valuable new resource for the community to
evaluate and improve multi-stage reasoning in LLM agents. The code and data are
available at https://github.com/D3E0-source/MSCoRE.

</details>


### [101] [AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?](https://arxiv.org/abs/2509.17641)
*Hyunjong Ok,Suho Yoo,Hyeonjun Kim,Jaeho Lee*

Main category: cs.CL

TL;DR: 本文提出AuditoryBench++基准和AIR-CoT方法，以评估和提升语言模型的听觉知识和推理能力。


<details>
  <summary>Details</summary>
Motivation: 语言模型在多模态交互中缺乏听觉常识推理能力，需要一种评估和提升的方法。

Method: 提出了AuditoryBench++基准和AIR-CoT方法，通过特殊标记和知识注入生成和整合听觉信息。

Result: 实验表明，AIR-CoT在最近的LLMs和多模态LLMs中表现优于现有模型和增强模型。

Conclusion: AuditoryBench++和AIR-CoT为评估和提升语言模型的听觉知识和推理能力提供了有效的工具和方法。

Abstract: Even without directly hearing sounds, humans can effortlessly reason about
auditory properties, such as pitch, loudness, or sound-source associations,
drawing on auditory commonsense. In contrast, language models often lack this
capability, limiting their effectiveness in multimodal interactions. As an
initial step to address this gap, we present AuditoryBench++, a comprehensive
benchmark for evaluating auditory knowledge and reasoning in text-only
settings. The benchmark encompasses tasks that range from basic auditory
comparisons to contextually grounded reasoning, enabling fine-grained analysis
of how models process and integrate auditory concepts. In addition, we
introduce AIR-CoT, a novel auditory imagination reasoning method that generates
and integrates auditory information during inference through span detection
with special tokens and knowledge injection. Extensive experiments with recent
LLMs and Multimodal LLMs demonstrate that AIR-CoT generally outperforms both
the off-the-shelf models and those augmented with auditory knowledge. The
project page is available at https://auditorybenchpp.github.io.

</details>


### [102] [Crosslingual Optimized Metric for Translation Assessment of Indian Languages](https://arxiv.org/abs/2509.17667)
*Arafat Ahsan,Vandan Mujadia,Pruthwik Mishra,Yash Bhaskar,Dipti Misra Sharma*

Main category: cs.CL

TL;DR: 本文创建了一个大型人工评估评分数据集，并训练了一个名为COMTAIL的神经翻译评估度量方法，在印度语言翻译对上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 自动翻译评估仍然是一项具有挑战性的任务，因为不同语言在正字法、形态学、句法和语义上存在丰富的差异。现有的基于字符串的度量方法如BLEU存在局限性，而学习的神经度量方法受限于大多数语言中黄金评估数据的缺乏。

Method: 本文创建了一个包含13种印度语言的大型人工评估评分数据集，并在此基础上训练了一个名为COMTAIL的神经翻译评估度量方法。

Result: 最佳性能的度量变体在评判至少包含一种印度语言的翻译对时，相比之前最先进的方法表现出显著的性能提升。

Conclusion: 本文提出了一个名为COMTAIL的跨语言翻译评估度量方法，并展示了其在印度语言翻译对上的显著性能提升。此外，还释放了COMTAIL数据集和相应的度量模型。

Abstract: Automatic evaluation of translation remains a challenging task owing to the
orthographic, morphological, syntactic and semantic richness and divergence
observed across languages. String-based metrics such as BLEU have previously
been extensively used for automatic evaluation tasks, but their limitations are
now increasingly recognized. Although learned neural metrics have helped
mitigate some of the limitations of string-based approaches, they remain
constrained by a paucity of gold evaluation data in most languages beyond the
usual high-resource pairs. In this present work we address some of these gaps.
We create a large human evaluation ratings dataset for 13 Indian languages
covering 21 translation directions and then train a neural translation
evaluation metric named Cross-lingual Optimized Metric for Translation
Assessment of Indian Languages (COMTAIL) on this dataset. The best performing
metric variants show significant performance gains over previous
state-of-the-art when adjudging translation pairs with at least one Indian
language. Furthermore, we conduct a series of ablation studies to highlight the
sensitivities of such a metric to changes in domain, translation quality, and
language groupings. We release both the COMTAIL dataset and the accompanying
metric models.

</details>


### [103] [PG-CE: A Progressive Generation Dataset with Constraint Enhancement for Controllable Text Generation](https://arxiv.org/abs/2509.17669)
*Yan Zhuang,Yuan Sun*

Main category: cs.CL

TL;DR: 本文提出了一种名为PG-CE的可控文本生成方法，通过分解任务和动态构建约束来提升生成质量，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统方法存在局限性，需要一种更有效的可控文本生成方法以提高系统可靠性和用户体验。

Method: PG-CE方法将CTG任务分解为三个步骤：类型预测、约束构建和引导生成，并使用约束生成模型动态构建多维约束来指导输出。

Result: 实验表明PG-CE在多个场景中显著提升了生成质量，同时保持了文本的可控性、主题相关性和响应实用性。研究还开发了一个包含90,000个约束-文本对的数据集，有效反映了实际应用需求。

Conclusion: PG-CE方法在多个场景中显著提高了生成质量，同时保持了文本的可控性、主题相关性和响应实用性。

Abstract: With the rapid development of Large Language Models (LLMs), Controllable Text
Generation (CTG) has become a critical technology for enhancing system
reliability and user experience. Addressing the limitations of traditional
methods, this paper proposes the PG-CE (Progressive Generation with Constraint
Enhancement) approach, which decomposes CTG tasks into three steps: type
prediction, constraint construction, and guided generation. This method employs
constraint generation models to dynamically build multi-dimensional constraints
including tone, expression style, and thematic focus to guide output.
Experiments demonstrate that PG-CE significantly improves generation quality
across multiple scenarios while maintaining text controllability, thematic
relevance, and response practicality. The research developed a dataset
containing 90,000 constraint-text pairs (with an 8:2 ratio between daily and
other topics), effectively reflecting real-world application requirements.

</details>


### [104] [Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications](https://arxiv.org/abs/2509.17671)
*Selva Taş,Mahmut El Huseyni,Özay Ezerceli,Reyhan Bayraktar,Fatma Betül Terzioğlu*

Main category: cs.CL

TL;DR: 本文介绍了Turk-LettuceDetect，这是第一个专为土耳其RAG应用设计的幻觉检测模型套件。通过微调三种不同的编码器架构，模型在测试集中取得了良好的性能，并填补了多语言自然语言处理中的一个关键空白。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）容易产生幻觉，这阻碍了它们的广泛应用，特别是在形态复杂、资源较少的语言如土耳其语中，因此需要专门的检测机制。

Method: 本文将幻觉检测作为标记级别的分类任务，并微调了三种不同的编码器架构：一种土耳其特定的ModernBERT，TurkEmbed4STS和多语言EuroBERT。

Result: 实验结果表明，基于ModernBERT的模型在完整测试集上取得了0.7266的F1分数，特别是在结构化任务中表现尤为出色。模型在支持长达8,192个标记的长上下文的同时保持计算效率，适合实时部署。

Conclusion: 本文通过发布模型和翻译后的数据集，填补了多语言自然语言处理中的一个关键空白，并为开发更可靠和值得信赖的土耳其语和其他语言的AI应用奠定了基础。

Abstract: The widespread adoption of Large Language Models (LLMs) has been hindered by
their tendency to hallucinate, generating plausible but factually incorrect
information. While Retrieval-Augmented Generation (RAG) systems attempt to
address this issue by grounding responses in external knowledge, hallucination
remains a persistent challenge, particularly for morphologically complex,
low-resource languages like Turkish. This paper introduces Turk-LettuceDetect,
the first suite of hallucination detection models specifically designed for
Turkish RAG applications. Building on the LettuceDetect framework, we formulate
hallucination detection as a token-level classification task and fine-tune
three distinct encoder architectures: a Turkish-specific ModernBERT,
TurkEmbed4STS, and multilingual EuroBERT. These models were trained on a
machine-translated version of the RAGTruth benchmark dataset containing 17,790
instances across question answering, data-to-text generation, and summarization
tasks. Our experimental results show that the ModernBERT-based model achieves
an F1-score of 0.7266 on the complete test set, with particularly strong
performance on structured tasks. The models maintain computational efficiency
while supporting long contexts up to 8,192 tokens, making them suitable for
real-time deployment. Comparative analysis reveals that while state-of-the-art
LLMs demonstrate high recall, they suffer from low precision due to
over-generation of hallucinated content, underscoring the necessity of
specialized detection mechanisms. By releasing our models and translated
dataset, this work addresses a critical gap in multilingual NLP and establishes
a foundation for developing more reliable and trustworthy AI applications for
Turkish and other languages.

</details>


### [105] [When TableQA Meets Noise: A Dual Denoising Framework for Complex Questions and Large-scale Tables](https://arxiv.org/abs/2509.17680)
*Shenghao Ye,Yu Guo,Dong Jin,Yikai Shen,Yunpeng Hou,Shuangwu Chen,Jian Yang,Xiaofeng Jiang*

Main category: cs.CL

TL;DR: EnoTab is a dual denoising framework for TableQA tasks that improves relevance filtering and table pruning, resulting in outstanding performance on complex questions and large-scale tables.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenge of noisy data in real-world applications involving complex questions and large tables, which severely degrades reasoning performance.

Method: EnoTab is a dual denoising framework that includes Evidence-based Question Denoising and Evidence Tree-guided Table Denoising. The former decomposes the question into minimal semantic units and filters out irrelevant information, while the latter constructs an explicit and transparent table pruning path to remove irrelevant data step by step.

Result: EnoTab achieves outstanding performance on TableQA tasks with complex questions and large-scale tables.

Conclusion: EnoTab achieves outstanding performance on TableQA tasks with complex questions and large-scale tables, confirming its effectiveness.

Abstract: Table question answering (TableQA) is a fundamental task in natural language
processing (NLP). The strong reasoning capabilities of large language models
(LLMs) have brought significant advances in this field. However, as real-world
applications involve increasingly complex questions and larger tables,
substantial noisy data is introduced, which severely degrades reasoning
performance. To address this challenge, we focus on improving two core
capabilities: Relevance Filtering, which identifies and retains information
truly relevant to reasoning, and Table Pruning, which reduces table size while
preserving essential content. Based on these principles, we propose EnoTab, a
dual denoising framework for complex questions and large-scale tables.
Specifically, we first perform Evidence-based Question Denoising by decomposing
the question into minimal semantic units and filtering out those irrelevant to
answer reasoning based on consistency and usability criteria. Then, we propose
Evidence Tree-guided Table Denoising, which constructs an explicit and
transparent table pruning path to remove irrelevant data step by step. At each
pruning step, we observe the intermediate state of the table and apply a
post-order node rollback mechanism to handle abnormal table states, ultimately
producing a highly reliable sub-table for final answer reasoning. Finally,
extensive experiments show that EnoTab achieves outstanding performance on
TableQA tasks with complex questions and large-scale tables, confirming its
effectiveness.

</details>


### [106] [TASO: Task-Aligned Sparse Optimization for Parameter-Efficient Model Adaptation](https://arxiv.org/abs/2509.17688)
*Daiye Miao,Yufang Liu,Jie Wang,Changzhi Sun,Yunke Zhang,Demei Yan,Shaokang Dong,Qi Zhang,Yuanbin Wu*

Main category: cs.CL

TL;DR: 本文提出了一种名为TASO的冗余减少方法，通过利用预训练模型权重的重要性信息来减轻LoRA的冗余。实验结果表明，TASO在参数预算与LoRA（秩r=1）相当的情况下，在多个任务中均优于标准LoRA，同时有效消除了冗余参数。


<details>
  <summary>Details</summary>
Motivation: LoRA虽然简单且有效，但常常引入大量参数冗余，这不仅增加了可训练参数的数量，还阻碍了微调的效果。由于在LoRA中识别冗余参数本质上是困难的，因此如何高效准确地消除它们仍然是一个挑战。

Method: 本文提出的方法TASO利用预训练模型权重的重要性信息来估计下游任务中的参数重要性，并基于重要性分数的分布识别任务特定的核心区域。然后利用这些核心区域的位置信息来确定LoRA模块的稀疏结构，从而在微调前消除冗余。

Result: 实验结果表明，TASO在参数预算与LoRA（秩r=1）相当的情况下，在多个任务中均优于标准LoRA，同时有效消除了冗余参数。

Conclusion: 本文提出了一种名为TASO的冗余减少方法，该方法通过利用预训练模型权重的重要信息来减轻LoRA的冗余。实验结果表明，TASO在参数预算与LoRA（秩r=1）相当的情况下，在多个任务中均优于标准LoRA，同时有效消除了冗余参数。

Abstract: LoRA has become one of the most widely used parameter-efficient fine-tuning
methods due to its simplicity and effectiveness. However, numerous studies have
shown that LoRA often introduces substantial parameter redundancy, which not
only increases the number of trainable parameters but also hinders the
effectiveness of fine-tuning. Since identifying redundant parameters in LoRA is
inherently difficult, how to eliminate them efficiently and accurately remains
a challenging problem. In this paper, we propose TASO, a redundancy reduction
method that leverages importance information from the pretrained model's
weights to mitigate LoRA redundancy. Specifically, we estimate parameter
importance on downstream tasks and identify task-specific core regions based on
the distribution of importance scores. The location information of these core
regions is then used to determine the sparse structure of LoRA modules,
enabling redundancy removal before fine-tuning. Our approach significantly
reduces the number of trainable parameters required for task adaptation, while
providing a novel task-aligned perspective for LoRA redundancy reduction.
Experimental results demonstrate that, with a parameter budget comparable to
LoRA with rank $r = 1$, TASO consistently outperforms standard LoRA across
multiple tasks, achieving strong fine-tuning performance while effectively
eliminating redundant parameters.

</details>


### [107] [Evaluating LLM-Generated Versus Human-Authored Responses in Role-Play Dialogues](https://arxiv.org/abs/2509.17694)
*Dongxu Lu,Johan Jeuring,Albert Gatt*

Main category: cs.CL

TL;DR: 本研究比较了大型语言模型生成和人类撰写的多轮专业培训模拟对话，并发现大型语言模型生成的响应质量在多个回合中显著下降，而人类撰写的响应则逐步提高。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在长篇、基于知识的角色扮演对话中的表现仍然具有挑战性。

Method: 通过人类评估（N=38）和自动化的LLM-as-a-judge评估比较了大型语言模型生成的响应和人类撰写的响应。

Result: 人类评估显示，大型语言模型生成的响应质量在多个回合中显著下降，特别是在自然度、上下文保持和整体质量方面，而人类撰写的响应则逐步提高。参与者也一致倾向于人类撰写的对话。这些人类判断得到了自动化的LLM-as-a-judge评估的验证，其中Gemini 2.0 Flash在零样本成对偏好和随机6样本构建评分上与人类评估者有很强的一致性，确认了随着时间推移，大型语言模型和人类响应之间的质量差距不断扩大。

Conclusion: 我们的工作贡献了一个多轮基准，揭示了大型语言模型在基于知识的角色扮演对话中的退化情况，并提供了一个经过验证的混合评估框架，以指导大型语言模型在培训模拟中的可靠集成。

Abstract: Evaluating large language models (LLMs) in long-form, knowledge-grounded
role-play dialogues remains challenging. This study compares LLM-generated and
human-authored responses in multi-turn professional training simulations
through human evaluation ($N=38$) and automated LLM-as-a-judge assessment.
Human evaluation revealed significant degradation in LLM-generated response
quality across turns, particularly in naturalness, context maintenance and
overall quality, while human-authored responses progressively improved. In line
with this finding, participants also indicated a consistent preference for
human-authored dialogue. These human judgements were validated by our automated
LLM-as-a-judge evaluation, where Gemini 2.0 Flash achieved strong alignment
with human evaluators on both zero-shot pairwise preference and stochastic
6-shot construct ratings, confirming the widening quality gap between LLM and
human responses over time. Our work contributes a multi-turn benchmark exposing
LLM degradation in knowledge-grounded role-play dialogues and provides a
validated hybrid evaluation framework to guide the reliable integration of LLMs
in training simulations.

</details>


### [108] [Investigating Bias: A Multilingual Pipeline for Generating, Solving, and Evaluating Math Problems with LLMs](https://arxiv.org/abs/2509.17701)
*Mariam Mahran,Katharina Simbeck*

Main category: cs.CL

TL;DR: 本研究提出了一种自动化多语言流程，用于生成、解决和评估与德国K-10课程相符的数学问题。结果显示，英语解决方案的质量高于阿拉伯语解决方案，突显了语言偏见的存在，并强调了在教育中需要更公平的多语言AI系统。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）越来越多地用于教育支持，但其响应质量因交互语言而异。因此，需要一种多语言流程来生成、解决和评估数学问题，以减少语言偏见并提高教育AI系统的公平性。

Method: 本研究提出了一个自动化的多语言流程，用于生成、解决和评估与德国K-10课程相符的数学问题。生成了628个数学练习题，并将其翻译成英语、德语和阿拉伯语。三种商业LLM（GPT-4o-mini、Gemini 2.5 Flash和Qwen-plus）被提示在每种语言中生成逐步解决方案。一个保留的LLM评委小组（包括Claude 3.5 Haiku）使用比较框架评估了解决方案的质量。

Result: 结果表明，英语解决方案始终被评为最高，而阿拉伯语解决方案通常排名较低。

Conclusion: 研究结果突显了语言偏见的持续存在，并强调了在教育中需要更公平的多语言人工智能系统。

Abstract: Large Language Models (LLMs) are increasingly used for educational support,
yet their response quality varies depending on the language of interaction.
This paper presents an automated multilingual pipeline for generating, solving,
and evaluating math problems aligned with the German K-10 curriculum. We
generated 628 math exercises and translated them into English, German, and
Arabic. Three commercial LLMs (GPT-4o-mini, Gemini 2.5 Flash, and Qwen-plus)
were prompted to produce step-by-step solutions in each language. A held-out
panel of LLM judges, including Claude 3.5 Haiku, evaluated solution quality
using a comparative framework. Results show a consistent gap, with English
solutions consistently rated highest, and Arabic often ranked lower. These
findings highlight persistent linguistic bias and the need for more equitable
multilingual AI systems in education.

</details>


### [109] [Breaking Token Into Concepts: Exploring Extreme Compression in Token Representation Via Compositional Shared Semantics](https://arxiv.org/abs/2509.17737)
*Kavin R V,Pawan Goyal*

Main category: cs.CL

TL;DR: 研究提出了一种名为Aggregate Semantic Grouping (ASG)的新方法，利用Product Quantization (PQ)，通过组合语义块来表示令牌，实现了嵌入参数的极端压缩（0.4-0.5%），同时保持了超过95%的任务性能。


<details>
  <summary>Details</summary>
Motivation: Standard language models employ unique, monolithic embeddings for each token, potentially limiting their ability to capture the multifaceted nature of word meanings.

Method: Aggregate Semantic Grouping (ASG), a novel approach leveraging Product Quantization (PQ).

Result: Representing tokens compositionally via ASG achieves extreme compression in embedding parameters (0.4--0.5%) while maintaining >95% task performance relative to the base model, even in generative tasks and extends to both cross lingual transfer and domain-specific settings.

Conclusion: ASG offers a simple yet concrete method for achieving this, showcasing how compositional representations can capture linguistic richness while enabling compact yet semantically rich models.

Abstract: Standard language models employ unique, monolithic embeddings for each token,
potentially limiting their ability to capture the multifaceted nature of word
meanings. We investigate whether tokens can be more effectively represented
through a compositional structure that accumulates diverse semantic facets. To
explore this, we propose Aggregate Semantic Grouping (ASG), a novel approach
leveraging Product Quantization (PQ). We apply ASG to standard transformer
architectures (mBERT, XLM-R, mT5) and evaluate this representational scheme
across diverse tasks (NLI, NER, QA), as well as a biomedical domain-specific
benchmark (BC5CDR) using BioBERT. Our findings demonstrate that representing
tokens compositionally via ASG achieves extreme compression in embedding
parameters (0.4--0.5\%) while maintaining $>$95\% task performance relative to
the base model, even in generative tasks and extends to both cross lingual
transfer and domain-specific settings. These results validate the principle
that tokens can be effectively modeled as combinations of shared semantic
building blocks. ASG offers a simple yet concrete method for achieving this,
showcasing how compositional representations can capture linguistic richness
while enabling compact yet semantically rich models.

</details>


### [110] [Qwen3-Omni Technical Report](https://arxiv.org/abs/2509.17765)
*Jin Xu,Zhifang Guo,Hangrui Hu,Yunfei Chu,Xiong Wang,Jinzheng He,Yuxuan Wang,Xian Shi,Ting He,Xinfa Zhu,Yuanjun Lv,Yongqi Wang,Dake Guo,He Wang,Linhan Ma,Pei Zhang,Xinyu Zhang,Hongkun Hao,Zishan Guo,Baosong Yang,Bin Zhang,Ziyang Ma,Xipin Wei,Shuai Bai,Keqin Chen,Xuejing Liu,Peng Wang,Mingkun Yang,Dayiheng Liu,Xingzhang Ren,Bo Zheng,Rui Men,Fan Zhou,Bowen Yu,Jianxin Yang,Le Yu,Jingren Zhou,Junyang Lin*

Main category: cs.CL

TL;DR: Qwen3-Omni is a single multimodal model that achieves state-of-the-art performance across text, image, audio, and video. It outperforms existing models on multiple benchmarks and supports multilingual text and speech interaction. The model is released under the Apache 2.0 license.


<details>
  <summary>Details</summary>
Motivation: The research community lacks a general-purpose audio captioning model, and there is a need for a single multimodal model that maintains state-of-the-art performance across text, image, audio, and video without degradation.

Method: Qwen3-Omni adopts a Thinker-Talker MoE architecture that unifies perception and generation across text, images, audio, and video. It uses a multi-codebook scheme for autoregressive prediction of discrete speech codecs and replaces block-wise diffusion with a lightweight causal ConvNet. A Thinking model is introduced for multimodal reasoning, and Qwen3-Omni-30B-A3B is fine-tuned for audio captioning.

Result: Qwen3-Omni achieves open-source SOTA on 32 benchmarks and overall SOTA on 22 across 36 audio and audio-visual benchmarks. It outperforms strong closed-source models like Gemini-2.5-Pro, Seed-ASR, and GPT-4o-Transcribe. It supports text interaction in 119 languages, speech understanding in 19 languages, and speech generation in 10 languages. The model achieves a theoretical end-to-end first-packet latency of 234 ms in cold-start settings.

Conclusion: Qwen3-Omni-30B-A3B, Qwen3-Omni-30B-A3B-Thinking, and Qwen3-Omni-30B-A3B-Captioner are publicly released under the Apache 2.0 license.

Abstract: We present Qwen3-Omni, a single multimodal model that, for the first time,
maintains state-of-the-art performance across text, image, audio, and video
without any degradation relative to single-modal counterparts. Qwen3-Omni
matches the performance of same-sized single-modal models within the Qwen
series and excels particularly on audio tasks. Across 36 audio and audio-visual
benchmarks, Qwen3-Omni achieves open-source SOTA on 32 benchmarks and overall
SOTA on 22, outperforming strong closed-source models such as Gemini-2.5-Pro,
Seed-ASR, and GPT-4o-Transcribe. Qwen3-Omni adopts a Thinker-Talker MoE
architecture that unifies perception and generation across text, images, audio,
and video, yielding fluent text and natural real-time speech. It supports text
interaction in 119 languages, speech understanding in 19 languages, and speech
generation in 10 languages. To reduce first-packet latency in streaming
synthesis, Talker autoregressively predicts discrete speech codecs using a
multi-codebook scheme. Leveraging the representational capacity of these
codebooks, we replace computationally intensive block-wise diffusion with a
lightweight causal ConvNet, enabling streaming from the first codec frame. In
cold-start settings, Qwen3-Omni achieves a theoretical end-to-end first-packet
latency of 234 ms. To further strengthen multimodal reasoning, we introduce a
Thinking model that explicitly reasons over inputs from any modality. Since the
research community currently lacks a general-purpose audio captioning model, we
fine-tuned Qwen3-Omni-30B-A3B to obtain Qwen3-Omni-30B-A3B-Captioner, which
produces detailed, low-hallucination captions for arbitrary audio inputs.
Qwen3-Omni-30B-A3B, Qwen3-Omni-30B-A3B-Thinking, and
Qwen3-Omni-30B-A3B-Captioner are publicly released under the Apache 2.0
license.

</details>


### [111] [A State-Update Prompting Strategy for Efficient and Robust Multi-turn Dialogue](https://arxiv.org/abs/2509.17766)
*Ziyi Liu*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的提示工程方法，用于改善大型语言模型在长范围多轮对话中的表现，通过状态重建和历史提醒机制，显著提升了性能并减少了资源消耗。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长范围、多轮对话中存在信息遗忘和效率低下的问题。

Method: 我们提出了一种无需训练的提示工程方法，即状态更新多轮对话策略，利用“状态重建”和“历史提醒”机制来有效管理对话历史。

Result: 在多个多跳问答数据集上表现出色。例如，在HotpotQA数据集上，它将核心信息过滤得分提高了32.6%，导致下游问答得分增加了14.1%，同时减少了73.1%的推理时间和59.4%的标记消耗。

Conclusion: 我们的工作为优化长距离交互中的LLMs提供了有效的解决方案，并为开发更稳健的代理提供了新的见解。

Abstract: Large Language Models (LLMs) struggle with information forgetting and
inefficiency in long-horizon, multi-turn dialogues. To address this, we propose
a training-free prompt engineering method, the State-Update Multi-turn Dialogue
Strategy. It utilizes "State Reconstruction" and "History Remind" mechanisms to
effectively manage dialogue history. Our strategy shows strong performance
across multiple multi-hop QA datasets. For instance, on the HotpotQA dataset,
it improves the core information filtering score by 32.6%, leading to a 14.1%
increase in the downstream QA score, while also reducing inference time by
73.1% and token consumption by 59.4%. Ablation studies confirm the pivotal
roles of both components. Our work offers an effective solution for optimizing
LLMs in long-range interactions, providing new insights for developing more
robust Agents.

</details>


### [112] [DIVERS-Bench: Evaluating Language Identification Across Domain Shifts and Code-Switching](https://arxiv.org/abs/2509.17768)
*Jessica Ojo,Zina Kamel,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 本文介绍了DIVERS-BENCH和DIVERS-CS，发现现有LID模型在处理嘈杂和非正式输入时表现不佳，特别是在检测同一句子中的多种语言方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 当前的LID系统往往过度拟合到干净、单语数据，而现实世界的数据通常嘈杂且非正式。

Method: 引入DIVERS-BENCH，对最先进的LID模型在不同领域的评估，以及引入DIVERS-CS代码切换基准数据集。

Result: 模型在精心策划的数据集上表现良好，但在嘈杂和非正式输入上的性能急剧下降。现有的模型难以检测同一句子中的多种语言。

Conclusion: 这些结果突显了在现实世界环境中需要更稳健和包容的LID系统。

Abstract: Language Identification (LID) is a core task in multilingual NLP, yet current
systems often overfit to clean, monolingual data. This work introduces
DIVERS-BENCH, a comprehensive evaluation of state-of-the-art LID models across
diverse domains, including speech transcripts, web text, social media texts,
children's stories, and code-switched text. Our findings reveal that while
models achieve high accuracy on curated datasets, performance degrades sharply
on noisy and informal inputs. We also introduce DIVERS-CS, a diverse
code-switching benchmark dataset spanning 10 language pairs, and show that
existing models struggle to detect multiple languages within the same sentence.
These results highlight the need for more robust and inclusive LID systems in
real-world settings.

</details>


### [113] [One Agent to Serve All: a Lite-Adaptive Stylized AI Assistant for Millions of Multi-Style Official Accounts](https://arxiv.org/abs/2509.17788)
*Xingyu Fan,Feifei Li,Wenhui Que,Hailong Li*

Main category: cs.CL

TL;DR: WeStar is a lite-adaptive framework for stylized contextual question answering that scales to millions of official accounts by combining RAG and PRAG with dynamic LoRA modules, multi-dimensional parameter sharing, and SeDPO optimization.


<details>
  <summary>Details</summary>
Motivation: Existing methods struggle to meet the requirements of generating responses that are both contextually grounded and stylistically aligned for industrial-scale official account platforms. Chain-of-thought prompting, per-account fine-tuning, and long prompt-based methods have limitations in terms of latency, computational cost, and model performance.

Method: WeStar combines context-grounded generation via RAG with style-aware generation using Parametric RAG (PRAG), where LoRA modules are dynamically activated per style cluster. It also includes a multi-dimensional, cluster-based parameter sharing scheme and a style-enhanced Direct Preference Optimization (SeDPO) method.

Result: Experiments on a large-scale industrial dataset validate the effectiveness and efficiency of WeStar, showing its practical value in real-world deployment.

Conclusion: WeStar demonstrates effectiveness and efficiency in real-world deployment, making it a practical solution for large-scale conversational agents.

Abstract: Conversational agents deployed in industrial-scale official account platforms
must generate responses that are both contextually grounded and stylistically
aligned-requirements that existing methods struggle to meet. Chain-of-thought
(CoT) prompting induces significant latency due to multi-turn reasoning;
per-account fine-tuning is computationally prohibitive; and long prompt-based
methods degrade the model's ability to grasp injected context and style. In
this paper, we propose WeStar, a lite-adaptive framework for stylized
contextual question answering that scales to millions of official accounts.
WeStar combines context-grounded generation via RAG with style-aware generation
using Parametric RAG (PRAG), where LoRA modules are dynamically activated per
style cluster. Our contributions are fourfold: (1) We introduce WeStar, a
unified framework capable of serving large volumes of official accounts with
minimal overhead. (2) We propose a multi-dimensional, cluster-based parameter
sharing scheme that enables compact style representation while preserving
stylistic diversity. (3) We develop a style-enhanced Direct Preference
Optimization (SeDPO) method to optimize each style cluster's parameters for
improved generation quality. (4) Experiments on a large-scale industrial
dataset validate the effectiveness and efficiency of WeStar, underscoring its
pracitical value in real-world deployment.

</details>


### [114] [Learning to vary: Teaching LMs to reproduce human linguistic variability in next-word prediction](https://arxiv.org/abs/2509.17794)
*Tobias Groot,Salo Lacunes,Evgenia Ilia*

Main category: cs.CL

TL;DR: 本文研究了通过在多个可能的词延续上对语言模型进行微调，以提高其再现人类语言变异性能力的效果。


<details>
  <summary>Details</summary>
Motivation: 由于语言模型无法很好地再现人类语言的变异性，因此需要研究是否可以通过在多个可能的词延续上对语言模型进行微调来改善这一问题。

Method: 本文采用微调技术对预训练和指令调优模型进行实验，使用Provo语料库对GPT-2和Mistral-7B-IT进行微调。

Result: 实验结果表明，多标签微调能够提高语言模型再现语言变异性能力，无论是高变异性还是低变异性上下文。

Conclusion: 本文结论是，通过在多个可能的词延续上对语言模型进行微调，可以提高它们再现人类语言变异性的能力，无论上下文的变异性高低。

Abstract: Natural language generation (NLG) tasks are often subject to inherent
variability; \emph{e.g.} predicting the next word given a context has multiple
valid responses, evident when asking multiple humans to complete the task.
While having language models (LMs) that are aligned pluralistically, so that
they are able to reproduce well the inherent diversity in perspectives of an
entire population of interest is clearly beneficial, \citet{ilia2024predict}
show that LMs do not reproduce this type of linguistic variability well. They
speculate this inability might stem from the lack of consistent training of LMs
with data reflecting this type of inherent variability. As such, we investigate
whether training LMs on multiple plausible word continuations per context can
improve their ability to reproduce human linguistic variability for next-word
prediction. We employ fine-tuning techniques for pre-trained and
instruction-tuned models; and demonstrate their potential when fine-tuning
GPT-2 and Mistral-7B-IT, using Provo Corpus. Our evaluation, which measures
divergence among empirically estimated human and model next-word distributions
across contexts before and after fine-tuning, shows that our multi-label
fine-tuning improves the LMs' ability to reproduce linguistic variability; both
for contexts that admit higher and lower variability.

</details>


### [115] [Findings of the Fourth Shared Task on Multilingual Coreference Resolution: Can LLMs Dethrone Traditional Approaches?](https://arxiv.org/abs/2509.17796)
*Michal Novák,Miloslav Konopík,Anna Nedoluzhko,Martin Popel,Ondřej Pražák,Jakub Sido,Milan Straka,Zdeněk Žabokrtský,Daniel Zeman*

Main category: cs.CL

TL;DR: The paper discusses the fourth edition of the Shared Task on Multilingual Coreference Resolution, highlighting the introduction of an LLM track and the potential of LLMs in this area.


<details>
  <summary>Details</summary>
Motivation: To evaluate the performance of systems in multilingual coreference resolution and explore the potential of LLMs in this task.

Method: The paper presents an overview of the fourth edition of the Shared Task on Multilingual Coreference Resolution, including a dedicated LLM track and new datasets.

Result: Nine systems participated, including four LLM-based approaches. Traditional systems still led, but LLMs showed promise.

Conclusion: LLMs showed clear potential in coreference resolution, suggesting they may soon challenge established approaches.

Abstract: The paper presents an overview of the fourth edition of the Shared Task on
Multilingual Coreference Resolution, organized as part of the CODI-CRAC 2025
workshop. As in the previous editions, participants were challenged to develop
systems that identify mentions and cluster them according to identity
coreference.
  A key innovation of this year's task was the introduction of a dedicated
Large Language Model (LLM) track, featuring a simplified plaintext format
designed to be more suitable for LLMs than the original CoNLL-U representation.
  The task also expanded its coverage with three new datasets in two additional
languages, using version 1.3 of CorefUD - a harmonized multilingual collection
of 22 datasets in 17 languages.
  In total, nine systems participated, including four LLM-based approaches (two
fine-tuned and two using few-shot adaptation). While traditional systems still
kept the lead, LLMs showed clear potential, suggesting they may soon challenge
established approaches in future editions.

</details>


### [116] [Everyday Physics in Korean Contexts: A Culturally Grounded Physical Reasoning Benchmark](https://arxiv.org/abs/2509.17807)
*Jihae Jeong,DaeYeop Lee,DongGeon Lee,Hwanjo Yu*

Main category: cs.CL

TL;DR: 本文介绍了EPiK，一个针对韩国文化背景的物理常识推理基准，以填补现有研究的空白。


<details>
  <summary>Details</summary>
Motivation: 现有物理常识推理基准主要关注西方背景，忽视了物理问题解决中的文化差异。

Method: 通过两阶段生成和验证流程创建了181个二选一问题，涵盖了9个推理子任务和84个场景，确保问题的文化真实性。

Result: 韩国专门模型在性能上优于通用模型，表明文化无偏模型的局限性。

Conclusion: EPiK展示了文化相关基准在真正衡量语言理解中的重要性，且其公开可用。

Abstract: Existing physical commonsense reasoning benchmarks predominantly focus on
Western contexts, overlooking cultural variations in physical problem-solving.
To address this gap, we introduce EPiK (Everyday Physics in Korean Contexts), a
novel benchmark comprising 181 binary-choice problems that test physical
reasoning within Korean cultural contexts, ranging from kimchi (Korean food) to
traditional fermentation. EPiK is constructed using a two-stage generation and
verification pipeline to create culturally-authentic problems across 9
reasoning subtasks and 84 scenarios. Unlike approaches based on simple
translation, our method generates problems organically from Korean contexts
while upholding rigorous physical reasoning standards. Our evaluations show
that Korean-specialized models consistently outperform general-purpose models
of comparable size. This performance gap highlights the limitations of
culturally-agnostic models and demonstrates the critical need for
culturally-aware benchmarks to truly measure language understanding. Our EPiK
is publicly available at https://huggingface.co/datasets/jjae/EPiK.

</details>


### [117] [Towards Adaptive Context Management for Intelligent Conversational Question Answering](https://arxiv.org/abs/2509.17829)
*Manoj Madushanka Perera,Adnan Mahmood,Kasun Eranda Wijethilake,Quan Z. Sheng*

Main category: cs.CL

TL;DR: 本文提出了一种自适应上下文管理框架，用于改进对话问答系统，通过动态管理上下文来提高模型的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是优化对话历史的使用，通过动态管理上下文来最大化提供给ConvQA模型的相关信息，从而提高对话问答系统的性能和效率。

Method: 本文提出了一个自适应上下文管理（ACM）框架，用于对话问答（ConvQA）系统。该框架包含一个上下文管理（CM）模块、一个摘要（SM）模块和一个实体提取（EE）模块，以有效地处理对话历史。CM模块动态调整上下文大小，从而在模型的标记限制内保留最相关和最新的信息。SM模块通过滑动窗口对对话历史的较旧部分进行摘要。当摘要窗口超过其限制时，EE模块会识别并保留最早对话回合中的关键实体。

Result: 实验结果表明，所设想的框架在生成准确且符合上下文的响应方面是有效的，从而突显了ACM框架增强ConvQA系统鲁棒性和可扩展性的潜力。

Conclusion: 实验结果表明，所设想的框架在生成准确且符合上下文的响应方面是有效的，从而突显了ACM框架增强ConvQA系统鲁棒性和可扩展性的潜力。

Abstract: This particular paper introduces an Adaptive Context Management (ACM)
framework for the Conversational Question Answering (ConvQA) systems. The key
objective of the ACM framework is to optimize the use of the conversation
history by dynamically managing context for maximizing the relevant information
provided to a ConvQA model within its token limit. Our approach incorporates a
Context Manager (CM) Module, a Summarization (SM) Module, and an Entity
Extraction (EE) Module in a bid to handle the conversation history
efficaciously. The CM Module dynamically adjusts the context size, thereby
preserving the most relevant and recent information within a model's token
limit. The SM Module summarizes the older parts of the conversation history via
a sliding window. When the summarization window exceeds its limit, the EE
Module identifies and retains key entities from the oldest conversation turns.
Experimental results demonstrate the effectiveness of our envisaged framework
in generating accurate and contextually appropriate responses, thereby
highlighting the potential of the ACM framework to enhance the robustness and
scalability of the ConvQA systems.

</details>


### [118] [Fine-Grained Detection of AI-Generated Text Using Sentence-Level Segmentation](https://arxiv.org/abs/2509.17830)
*Lekkala Sai Teja,Annepaka Yadagiri,and Partha Pakray,Chukhu Chunka,Mangadoddi Srikar Vardhan*

Main category: cs.CL

TL;DR: 本文提出一种基于句子级别的序列标注模型，用于检测和分割文档中的人类和AI生成文本，通过结合Transformer、神经网络和CRF提高边界预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统AI检测器在混合或轻微编辑的文本中难以识别AI内容，导致效率低下，难以区分人类撰写和AI生成的文本。

Method: 提出了一种基于句子级别的序列标注模型，结合了最先进的预训练Transformer模型、神经网络（NN）和条件随机场（CRFs）。

Result: 在两个公开的基准数据集上进行了评估，实验比较包括零样本检测器和现有最先进的模型，以及严格的消融研究，证明该方法可以准确检测协作文本中的AI文本段落。

Conclusion: 该方法能够准确检测完全协作文本中AI文本的段落，且源代码和处理后的数据集已公开在GitHub仓库中。

Abstract: Generation of Artificial Intelligence (AI) texts in important works has
become a common practice that can be used to misuse and abuse AI at various
levels. Traditional AI detectors often rely on document-level classification,
which struggles to identify AI content in hybrid or slightly edited texts
designed to avoid detection, leading to concerns about the model's efficiency,
which makes it hard to distinguish between human-written and AI-generated
texts. A sentence-level sequence labeling model proposed to detect transitions
between human- and AI-generated text, leveraging nuanced linguistic signals
overlooked by document-level classifiers. By this method, detecting and
segmenting AI and human-written text within a single document at the
token-level granularity is achieved. Our model combines the state-of-the-art
pre-trained Transformer models, incorporating Neural Networks (NN) and
Conditional Random Fields (CRFs). This approach extends the power of
transformers to extract semantic and syntactic patterns, and the neural network
component to capture enhanced sequence-level representations, thereby improving
the boundary predictions by the CRF layer, which enhances sequence recognition
and further identification of the partition between Human- and AI-generated
texts. The evaluation is performed on two publicly available benchmark datasets
containing collaborative human and AI-generated texts. Our experimental
comparisons are with zero-shot detectors and the existing state-of-the-art
models, along with rigorous ablation studies to justify that this approach, in
particular, can accurately detect the spans of AI texts in a completely
collaborative text. All our source code and the processed datasets are
available in our GitHub repository.

</details>


### [119] [Trust Me, I Can Convince You: The Contextualized Argument Appraisal Framework](https://arxiv.org/abs/2509.17844)
*Lynn Greschner,Sabine Weber,Roman Klinger*

Main category: cs.CL

TL;DR: 本文提出了一种情境化的论点评估框架，通过角色扮演场景研究，发现说服力与积极情绪呈正相关，与消极情绪呈负相关，并强调了论点熟悉度的重要性。


<details>
  <summary>Details</summary>
Motivation: 虽然二元情绪性已经在论点挖掘中被研究，认知评估在一般情绪分析中也被建模，但这两个领域尚未结合。因此，研究人员提出了一个情境化的论点评估框架，以结合这两个领域。

Method: 研究人员提出了一个情境化的论点评估框架，该框架考虑了发送者、接收者和论点之间的相互作用。他们进行了一项角色扮演场景研究，让参与者披露他们的情绪，解释主要原因、论点评估和感知说服力，并收集了参与者和论点发送者的 demographic 数据和人格特征。

Result: 分析结果表明，说服力与积极情绪（如信任）呈正相关，与消极情绪（如愤怒）呈负相关。评估变量揭示了论点熟悉度的重要性。对于大多数参与者来说，论点本身的内容是情感反应的主要驱动因素。

Conclusion: 研究结果表明，说服力与积极情绪（如信任）呈正相关，与消极情绪（如愤怒）呈负相关。评估变量揭示了论点熟悉度的重要性。对于大多数参与者来说，论点本身的内容是情感反应的主要驱动因素。

Abstract: Emotions, which influence how convincing an argument is, are developed
  in context of the self and sender, and therefore require modeling
  the cognitive evaluation process. While binary emotionality has been
  studied in argument mining, and the cognitive appraisal has been
  modeled in general emotion analysis, these fields have not been
  brought together yet. We therefore propose the Contextualized
  Argument Appraisal Framework that contextualizes the interplay
  between the sender, receiver, and argument. It includes emotion
  labels, appraisals, such as argument familiarity, response urgency,
  and expected effort, as well as convincingness variables. To evaluate
  the framework and pave the way to computational modeling, we perform
  a study in a role-playing scenario, mimicking real-world exposure to
  arguments, asking participants to disclose their emotion, explain the main
cause, the
  argument appraisal, and the
  perceived convincingness. To consider the subjective nature of such
  annotations, we also collect demographic data and personality traits
  of both the participants and the perceived sender of the argument.
  The analysis of the resulting corpus of 800 arguments, each
  annotated by 5 participants, reveals that convincingness is
  positively correlated with positive emotions (e.g., trust) and
  negatively correlated with negative emotions (e.g., anger). The
  appraisal variables disclose the importance of the argument
  familiarity. For most participants, the content of the argument
  itself is the primary driver of the emotional response.

</details>


### [120] [Make Every Letter Count: Building Dialect Variation Dictionaries from Monolingual Corpora](https://arxiv.org/abs/2509.17855)
*Robert Litschko,Verena Blaschke,Diana Burkhardt,Barbara Plank,Diego Frassinelli*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型处理巴伐利亚语方言的能力，引入了DiaLemma框架并构建了一个基准数据集，发现大型语言模型在处理方言时存在局限性，特别是在区分翻译和屈折变体方面。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏标准正字法，方言表现出相当大的差异。同时，大型语言模型（LLMs）处理方言的能力仍研究不足。为了弥补这一差距，我们以巴伐利亚语为例，研究大型语言模型在词汇方言理解方面的能力，考察它们在不同词性上识别和翻译方言术语的效果。

Method: 我们引入了DiaLemma，这是一种新的注释框架，用于仅从单语数据创建方言变体词典，并使用它来编译一个包含100K人工标注的德语-巴伐利亚语词对的基准数据集。我们评估了九种最先进的大型语言模型如何判断巴伐利亚语词作为方言翻译、屈折变体或与给定德语词根无关的形式。

Result: 我们的结果表明，大型语言模型在名词和词义相似的词对上表现最好，而在区分直接翻译和屈折变体方面最困难。有趣的是，提供示例用法作为额外上下文可以提高翻译性能，但会降低它们识别方言变体的能力。

Conclusion: 本研究突显了大型语言模型在处理正字法方言变异方面的局限性，并强调了未来工作适应大型语言模型以应对方言的必要性。

Abstract: Dialects exhibit a substantial degree of variation due to the lack of a
standard orthography. At the same time, the ability of Large Language Models
(LLMs) to process dialects remains largely understudied. To address this gap,
we use Bavarian as a case study and investigate the lexical dialect
understanding capability of LLMs by examining how well they recognize and
translate dialectal terms across different parts-of-speech. To this end, we
introduce DiaLemma, a novel annotation framework for creating dialect variation
dictionaries from monolingual data only, and use it to compile a ground truth
dataset consisting of 100K human-annotated German-Bavarian word pairs. We
evaluate how well nine state-of-the-art LLMs can judge Bavarian terms as
dialect translations, inflected variants, or unrelated forms of a given German
lemma. Our results show that LLMs perform best on nouns and lexically similar
word pairs, and struggle most in distinguishing between direct translations and
inflected variants. Interestingly, providing additional context in the form of
example usages improves the translation performance, but reduces their ability
to recognize dialect variants. This study highlights the limitations of LLMs in
dealing with orthographic dialect variation and emphasizes the need for future
work on adapting LLMs to dialects.

</details>


### [121] [CorPipe at CRAC 2025: Evaluating Multilingual Encoders for Multilingual Coreference Resolution](https://arxiv.org/abs/2509.17858)
*Milan Straka*

Main category: cs.CL

TL;DR: CorPipe 25是CRAC 2025多语言共指解析共享任务的优胜作品，采用PyTorch实现，在LLM和非约束赛道中表现优异。


<details>
  <summary>Details</summary>
Motivation: 参与CRAC 2025多语言共指解析共享任务，并在新引入的LLM赛道和原始非约束赛道中取得优异成绩。

Method: CorPipe 25是对之前系统的完全重写，从TensorFlow迁移到PyTorch。

Result: CorPipe 25在两个赛道中均显著优于其他参赛作品，性能提升了8个百分点。

Conclusion: CorPipe 25在LLM和非约束性赛道中都显著优于其他提交，性能提升了8个百分点。

Abstract: We present CorPipe 25, the winning entry to the CRAC 2025 Shared Task on
Multilingual Coreference Resolution. This fourth iteration of the shared task
introduces a new LLM track alongside the original unconstrained track, features
reduced development and test sets to lower computational requirements, and
includes additional datasets. CorPipe 25 represents a complete reimplementation
of our previous systems, migrating from TensorFlow to PyTorch. Our system
significantly outperforms all other submissions in both the LLM and
unconstrained tracks by a substantial margin of 8 percentage points. The source
code and trained models are publicly available at
https://github.com/ufal/crac2025-corpipe.

</details>


### [122] [Unsupervised Learning and Representation of Mandarin Tonal Categories by a Generative CNN](https://arxiv.org/abs/2509.17859)
*Kai Schenck,Gašper Beguš*

Main category: cs.CL

TL;DR: 本文研究了无监督模型如何学习普通话声调，并发现模型能够学习到与人类语言学习阶段相似的系统。


<details>
  <summary>Details</summary>
Motivation: 声调模式是语言中计算上最复杂的学任务之一，本文旨在探索无监督模型是否能学习声调模式，并将其与人类语言学习阶段进行比较。

Method: 本文提出了在无监督模型中建模声调学习的方法，并使用了生成模型ciwGAN来关联其分类变量与普通话声调类别。

Result: 所有三个训练模型在分类变量上的F0均表现出统计显著差异，其中仅使用男性样本训练的模型持续编码声调。

Conclusion: 本文表明，ciwGAN模型不仅能够学习普通话的声调对比，还能学习一个对应于人类语言学习者发展阶段的系统。

Abstract: This paper outlines the methodology for modeling tonal learning in fully
unsupervised models of human language acquisition. Tonal patterns are among the
computationally most complex learning objectives in language. We argue that a
realistic generative model of human language (ciwGAN) can learn to associate
its categorical variables with Mandarin Chinese tonal categories without any
labeled data. All three trained models showed statistically significant
differences in F0 across categorical variables. The model trained solely on
male tokens consistently encoded tone. Our results sug- gest that not only does
the model learn Mandarin tonal contrasts, but it learns a system that
corresponds to a stage of acquisition in human language learners. We also
outline methodology for tracing tonal representations in internal convolutional
layers, which shows that linguistic tools can contribute to interpretability of
deep learning and can ultimately be used in neural experiments.

</details>


### [123] [How Persuasive is Your Context?](https://arxiv.org/abs/2509.17879)
*Tu Nguyen,Kevin Du,Alexander Miserlis Hoyle,Ryan Cotterell*

Main category: cs.CL

TL;DR: 本文提出了一种新的衡量语言模型说服力的方法——目标说服分数（TPS），该方法基于Wasserstein距离，能更准确地反映上下文对模型回答的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的方法仅通过检查模型贪婪解码的答案来评估说服力，而TPS提供了一种更细致的模型行为视图。

Method: 引入了目标说服分数（TPS），基于Wasserstein距离来衡量上下文对模型原始答案分布的影响。

Result: 实验表明，TPS比之前提出的指标更能捕捉到说服力的细微差别。

Conclusion: TPS能够更细致地衡量语言模型在面对不同上下文时的说服力，相比之前的方法更为精确。

Abstract: Two central capabilities of language models (LMs) are: (i) drawing on prior
knowledge about entities, which allows them to answer queries such as "What's
the official language of Austria?", and (ii) adapting to new information
provided in context, e.g., "Pretend the official language of Austria is
Tagalog.", that is pre-pended to the question. In this article, we introduce
targeted persuasion score (TPS), designed to quantify how persuasive a given
context is to an LM where persuasion is operationalized as the ability of the
context to alter the LM's answer to the question. In contrast to evaluating
persuasiveness only by inspecting the greedily decoded answer under the model,
TPS provides a more fine-grained view of model behavior. Based on the
Wasserstein distance, TPS measures how much a context shifts a model's original
answer distribution toward a target distribution. Empirically, through a series
of experiments, we show that TPS captures a more nuanced notion of
persuasiveness than previously proposed metrics.

</details>


### [124] [SiDiaC: Sinhala Diachronic Corpus](https://arxiv.org/abs/2509.17912)
*Nevidu Jayatilleke,Nisansa de Silva*

Main category: cs.CL

TL;DR: SiDiaC is the first comprehensive Sinhala Diachronic Corpus, covering a historical span from the 5th to the 20th century CE. It comprises 58k words across 46 literary works, annotated based on the written date. The corpus is categorised into two layers, with primary categorisation being binary (Non-Fiction or Fiction) and secondary categorisation being more specific (Religious, History, Poetry, Language, and Medical genres). Despite challenges, SiDiaC serves as a foundational resource for Sinhala NLP.


<details>
  <summary>Details</summary>
Motivation: The motivation behind SiDiaC is to create a comprehensive Sinhala Diachronic Corpus that covers a historical span from the 5th to the 20th century CE, providing a foundational resource for Sinhala NLP and enabling diachronic studies in various areas.

Method: SiDiaC was constructed by carefully annotating 58k words across 46 literary works, based on the written date, after filtering based on availability, authorship, copyright compliance, and data attribution. Texts from the National Library of Sri Lanka were digitised using Google Document AI OCR, followed by post-processing to correct formatting and modernise the orthography. Practices from other corpora, such as FarPaHC, were used for syntactic annotation and text normalisation strategies.

Result: SiDiaC is a comprehensive Sinhala Diachronic Corpus that comprises 58k words across 46 literary works, annotated carefully based on the written date. It is categorised into two layers: primary (Non-Fiction or Fiction) and secondary (Religious, History, Poetry, Language, and Medical genres).

Conclusion: SiDiaC serves as a foundational resource for Sinhala NLP, significantly extending the resources available for Sinhala, enabling diachronic studies in lexical change, neologism tracking, historical syntax, and corpus-based lexicography.

Abstract: SiDiaC, the first comprehensive Sinhala Diachronic Corpus, covers a
historical span from the 5th to the 20th century CE. SiDiaC comprises 58k words
across 46 literary works, annotated carefully based on the written date, after
filtering based on availability, authorship, copyright compliance, and data
attribution. Texts from the National Library of Sri Lanka were digitised using
Google Document AI OCR, followed by post-processing to correct formatting and
modernise the orthography. The construction of SiDiaC was informed by practices
from other corpora, such as FarPaHC, particularly in syntactic annotation and
text normalisation strategies, due to the shared characteristics of
low-resourced language status. This corpus is categorised based on genres into
two layers: primary and secondary. Primary categorisation is binary,
classifying each book into Non-Fiction or Fiction, while the secondary
categorisation is more specific, grouping texts under Religious, History,
Poetry, Language, and Medical genres. Despite challenges including limited
access to rare texts and reliance on secondary date sources, SiDiaC serves as a
foundational resource for Sinhala NLP, significantly extending the resources
available for Sinhala, enabling diachronic studies in lexical change, neologism
tracking, historical syntax, and corpus-based lexicography.

</details>


### [125] [Improving Zero-shot Sentence Decontextualisation with Content Selection and Planning](https://arxiv.org/abs/2509.17921)
*Zhenyun Deng,Yulong Chen,Andreas Vlachos*

Main category: cs.CL

TL;DR: 本文提出了一种零样本去上下文化框架，用于确定句子在无上下文情况下应提及的内容和顺序。通过分割句子为语义独立单元，识别可能有歧义的单元，并从上下文中提取相关单元，最终生成内容计划以重写句子。实验结果表明该方法在语义完整性和话语连贯性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 提取文档中的单独句子作为证据或推理步骤在许多自然语言处理任务中很常见。然而，提取的句子往往缺乏必要的上下文以使其被理解，例如指代和背景信息。

Method: 我们提出了一个内容选择和规划框架，用于零样本去上下文化，该框架确定了什么内容应该被提及以及以何种顺序使句子在没有上下文的情况下能够被理解。具体来说，给定一个可能有歧义的句子及其上下文，我们首先将其分割成基本的语义独立单元，然后从给定的句子中识别出可能有歧义的单元，并根据它们的论述关系从上下文中提取相关的单元。最后，我们生成一个内容计划来重写句子，通过为其相关单元进行丰富。

Result: 实验结果表明，我们的方法在句子去上下文化方面具有竞争力，生成的句子表现出更好的语义完整性和话语连贯性，优于现有方法。

Conclusion: 实验结果表明，我们的方法在句子去上下文化方面具有竞争力，生成的句子表现出更好的语义完整性和话语连贯性，优于现有方法。

Abstract: Extracting individual sentences from a document as evidence or reasoning
steps is commonly done in many NLP tasks. However, extracted sentences often
lack context necessary to make them understood, e.g., coreference and
background information. To this end, we propose a content selection and
planning framework for zero-shot decontextualisation, which determines what
content should be mentioned and in what order for a sentence to be understood
out of context. Specifically, given a potentially ambiguous sentence and its
context, we first segment it into basic semantically-independent units. We then
identify potentially ambiguous units from the given sentence, and extract
relevant units from the context based on their discourse relations. Finally, we
generate a content plan to rewrite the sentence by enriching each ambiguous
unit with its relevant units. Experimental results demonstrate that our
approach is competitive for sentence decontextualisation, producing sentences
that exhibit better semantic integrity and discourse coherence, outperforming
existing methods.

</details>


### [126] [Transformer-Encoder Trees for Efficient Multilingual Machine Translation and Speech Translation](https://arxiv.org/abs/2509.17930)
*Yiwen Guan,Jacob Whitehill*

Main category: cs.CL

TL;DR: 本文提出了一种新的分层Transformer编码器树（TET），结合了非自回归编码器-only模型，用于多语言翻译。TET通过在语言相似的目标语言之间共享中间表示，提高了低资源语言的准确性，减少了计算冗余，并允许在单次前向传递中生成所有目标语言。对于语音翻译，TET与非自回归语音识别基础架构（wav2vec2）结合使用，在翻译质量方面表现出色，同时速度提高了7-14倍。


<details>
  <summary>Details</summary>
Motivation: 多语言翻译面临计算冗余和低资源语言有限准确性的挑战，尤其是在语音翻译中。

Method: 提出了一种新颖的分层Transformer编码器树（TET），结合了使用Connectionist Temporal Classification进行多语言翻译的非自回归编码器-only模型。通过在语言相似的目标语言之间共享中间表示，TET可以提高低资源语言的准确性，减少计算冗余，并允许在单次前向传递中生成所有目标语言。对于语音翻译，将TET与非自回归语音识别基础架构（wav2vec2）结合使用。

Result: TET可以提高低资源语言的准确性，减少计算冗余，并允许在单次前向传递中生成所有目标语言，从而消除顺序瓶颈并提高并行性。对于语音翻译，结合TET和非自回归语音识别基础架构（wav2vec2）在翻译质量方面表现出色，同时速度提高了7-14倍。

Conclusion: TET可以提高低资源语言的准确性，减少计算冗余，并允许在单次前向传递中生成所有目标语言，从而消除顺序瓶颈并提高并行性。对于语音翻译，结合TET和非自回归语音识别基础架构（wav2vec2）在翻译质量方面表现出色，同时速度提高了7-14倍。

Abstract: Multilingual translation faces challenges of computational redundancy and
limited accuracy for low-resource languages, especially in speech translation.
To address this, we propose a novel hierarchical Transformer Encoder Tree (TET)
combined with non-autoregressive encoder-only models trained with Connectionist
Temporal Classification for multilingual translation. By sharing intermediate
representations among linguistically similar target languages, TET can improve
accuracy on low-resource languages, reduce computational redundancy, and allow
generating all target languages in a single forward pass, thus eliminating
sequential bottlenecks and improving parallelism. For speech translation,
combining TET with a non-autoregressive speech recognition backbone (wav2vec2)
shows promising results in terms of translation quality compared to
autoregressive systems while being 7-14 times faster.

</details>


### [127] [Training-free Truthfulness Detection via Value Vectors in LLMs](https://arxiv.org/abs/2509.17932)
*Runheng Liu,Heyan Huang,Xingchen Xiao,Zhijing Wu*

Main category: cs.CL

TL;DR: 本文提出了一种新的训练-free 方法TruthV，通过利用MLP模块中的值向量来检测内容的真实性，在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在可扩展性和泛化方面存在问题，而MLP模块在事实回忆中起着重要作用，但之前的研究忽略了这一点。

Method: TruthV，一种简单且可解释的训练-free 方法，通过利用MLP模块中的值向量来检测内容的真实性。

Result: TruthV在NoVo基准上显著优于NoVo和log-likelihood基线。

Conclusion: 这些发现为LLM内部如何表示真实性提供了新的见解，并激发了对可扩展和可解释的真实性检测的进一步研究。

Abstract: Large language models often generate factually incorrect outputs, motivating
efforts to detect the truthfulness of their content. Most existing approaches
rely on training probes over internal activations, but these methods suffer
from scalability and generalization issues. A recent training-free method,
NoVo, addresses this challenge by exploiting statistical patterns from the
model itself. However, it focuses exclusively on attention mechanisms,
potentially overlooking the MLP module-a core component of Transformer models
known to support factual recall. In this paper, we show that certain value
vectors within MLP modules exhibit truthfulness-related statistical patterns.
Building on this insight, we propose TruthV, a simple and interpretable
training-free method that detects content truthfulness by leveraging these
value vectors. On the NoVo benchmark, TruthV significantly outperforms both
NoVo and log-likelihood baselines, demonstrating that MLP modules-despite being
neglected in prior training-free efforts-encode rich and useful signals for
truthfulness detection. These findings offer new insights into how truthfulness
is internally represented in LLMs and motivate further research on scalable and
interpretable truthfulness detection.

</details>


### [128] [D-REX: A Benchmark for Detecting Deceptive Reasoning in Large Language Models](https://arxiv.org/abs/2509.17938)
*Satyapriya Krishna,Andy Zou,Rahul Gupta,Eliot Krzysztof Jones,Nick Winter,Dan Hendrycks,J. Zico Kolter,Matt Fredrikson,Spyros Matsoukas*

Main category: cs.CL

TL;DR: 本文介绍了一个名为D-REX的新数据集，用于评估大型语言模型的内部推理过程与最终输出之间的差异，并指出需要新的技术来审查这些模型的内部过程。


<details>
  <summary>Details</summary>
Motivation: 当前的评估方法主要关注识别和防止明显有害的输出，但未能解决模型在恶意或欺骗性内部推理下产生看似无害输出的问题。

Method: 本文介绍了Deceptive Reasoning Exposure Suite (D-REX)数据集，该数据集通过竞争性的红队演练构建，旨在评估模型内部推理过程与最终输出之间的差异。

Result: D-REX对现有模型和安全机制构成了重大挑战，突显了需要新的技术来审查大型语言模型的内部过程。

Conclusion: 本文强调了需要新的技术来审查大型语言模型的内部过程，而不仅仅是它们的最终输出。

Abstract: The safety and alignment of Large Language Models (LLMs) are critical for
their responsible deployment. Current evaluation methods predominantly focus on
identifying and preventing overtly harmful outputs. However, they often fail to
address a more insidious failure mode: models that produce benign-appearing
outputs while operating on malicious or deceptive internal reasoning. This
vulnerability, often triggered by sophisticated system prompt injections,
allows models to bypass conventional safety filters, posing a significant,
underexplored risk. To address this gap, we introduce the Deceptive Reasoning
Exposure Suite (D-REX), a novel dataset designed to evaluate the discrepancy
between a model's internal reasoning process and its final output. D-REX was
constructed through a competitive red-teaming exercise where participants
crafted adversarial system prompts to induce such deceptive behaviors. Each
sample in D-REX contains the adversarial system prompt, an end-user's test
query, the model's seemingly innocuous response, and, crucially, the model's
internal chain-of-thought, which reveals the underlying malicious intent. Our
benchmark facilitates a new, essential evaluation task: the detection of
deceptive alignment. We demonstrate that D-REX presents a significant challenge
for existing models and safety mechanisms, highlighting the urgent need for new
techniques that scrutinize the internal processes of LLMs, not just their final
outputs.

</details>


### [129] [HICode: Hierarchical Inductive Coding with LLMs](https://arxiv.org/abs/2509.17946)
*Mian Zhong,Pristina Wang,Anjalie Field*

Main category: cs.CL

TL;DR: HICode is a two-part pipeline that uses LLMs to generate labels and cluster them to surface themes, validated across datasets and applied to litigation documents to reveal marketing strategies.


<details>
  <summary>Details</summary>
Motivation: Researchers continue to rely on manual labeling or statistical tools like topic modeling, which are difficult to control. LLMs have the potential to scale nuanced analyses to large text corpora.

Method: HICode is a two-part pipeline that first inductively generates labels directly from analysis data and then hierarchically clusters them to surface emergent themes.

Result: HICode was validated across three diverse datasets, showing alignment with human-constructed themes and robustness through automated and human evaluations. It revealed aggressive marketing strategies in litigation documents related to the opioid crisis.

Conclusion: HICode has the potential to facilitate nuanced analyses in large-scale data, as demonstrated by its application to litigation documents related to the opioid crisis.

Abstract: Despite numerous applications for fine-grained corpus analysis, researchers
continue to rely on manual labeling, which does not scale, or statistical tools
like topic modeling, which are difficult to control. We propose that LLMs have
the potential to scale the nuanced analyses that researchers typically conduct
manually to large text corpora. To this effect, inspired by qualitative
research methods, we develop HICode, a two-part pipeline that first inductively
generates labels directly from analysis data and then hierarchically clusters
them to surface emergent themes. We validate this approach across three diverse
datasets by measuring alignment with human-constructed themes and demonstrating
its robustness through automated and human evaluations. Finally, we conduct a
case study of litigation documents related to the ongoing opioid crisis in the
U.S., revealing aggressive marketing strategies employed by pharmaceutical
companies and demonstrating HICode's potential for facilitating nuanced
analyses in large-scale data.

</details>


### [130] [Dorabella Cipher as Musical Inspiration](https://arxiv.org/abs/2509.17950)
*Bradley Hauer,Colin Choi,Abram Hindle,Scott Smallwood,Grzegorz Kondrak*

Main category: cs.CL

TL;DR: 本文研究了Dorabella密码是否代表加密音乐的假设，并通过音乐n-gram模型进行验证，最终生成了一个具有音乐特性的解密结果。


<details>
  <summary>Details</summary>
Motivation: Dorabella密码是一个被加密的笔记，已经困扰了超过一个世纪的解密尝试。大多数提出的解决方案都是英语文本，我们研究了Dorabella可能代表加密音乐的假设。

Method: 我们使用了音乐的n-gram模型，并在现有使用单字母替换加密的音乐语料库上进行了验证。

Result: 我们产生了具有音乐特性的解密结果，并通过艺术创作将其转化为可听的旋律。

Conclusion: 我们通过应用我们的方法，产生了具有音乐特性的解密结果，并通过艺术创作将其转化为可听的旋律。我们不认为最终结果代表唯一正确的解决方案，而是将解密过程视为创作过程的一部分。

Abstract: The Dorabella cipher is an encrypted note written by English composer Edward
Elgar, which has defied decipherment attempts for more than a century. While
most proposed solutions are English texts, we investigate the hypothesis that
Dorabella represents enciphered music. We weigh the evidence for and against
the hypothesis, devise a simplified music notation, and attempt to reconstruct
a melody from the cipher. Our tools are n-gram models of music which we
validate on existing music corpora enciphered using monoalphabetic
substitution. By applying our methods to Dorabella, we produce a decipherment
with musical qualities, which is then transformed via artful composition into a
listenable melody. Far from arguing that the end result represents the only
true solution, we instead frame the process of decipherment as part of the
composition process.

</details>


### [131] [Bringing Pedagogy into Focus: Evaluating Virtual Teaching Assistants' Question-Answering in Asynchronous Learning Environments](https://arxiv.org/abs/2509.17961)
*Li Siyan,Zhen Xu,Vethavikashini Chithrra Raghuram,Xuanming Zhang,Renzhe Yu,Zhou Yu*

Main category: cs.CL

TL;DR: 本文提出了一种基于学习科学的评估框架，用于评估虚拟教学助理在异步学习环境中的教学效果。


<details>
  <summary>Details</summary>
Motivation: 现有的评估通常依赖于表面指标，缺乏足够的教育理论基础，使得不同VTA系统的教学效果难以有意义地比较。

Method: 我们使用专家对VTA响应的注释构建分类器，并评估其有效性，以确定提高准确性的方法以及阻碍泛化的挑战。

Result: 我们提出了一个基于学习科学的评估框架，适用于异步论坛讨论这一常见的VTA部署环境。

Conclusion: 我们的工作为基于理论的VTA系统评估奠定了基础，为教育中的更有效的AI铺平了道路。

Abstract: Asynchronous learning environments (ALEs) are widely adopted for formal and
informal learning, but timely and personalized support is often limited. In
this context, Virtual Teaching Assistants (VTAs) can potentially reduce the
workload of instructors, but rigorous and pedagogically sound evaluation is
essential. Existing assessments often rely on surface-level metrics and lack
sufficient grounding in educational theories, making it difficult to
meaningfully compare the pedagogical effectiveness of different VTA systems. To
bridge this gap, we propose an evaluation framework rooted in learning sciences
and tailored to asynchronous forum discussions, a common VTA deployment context
in ALE. We construct classifiers using expert annotations of VTA responses on a
diverse set of forum posts. We evaluate the effectiveness of our classifiers,
identifying approaches that improve accuracy as well as challenges that hinder
generalization. Our work establishes a foundation for theory-driven evaluation
of VTA systems, paving the way for more pedagogically effective AI in
education.

</details>


### [132] [ReDepress: A Cognitive Framework for Detecting Depression Relapse from Social Media](https://arxiv.org/abs/2509.17991)
*Aakash Kumar Agarwal,Saprativa Bhattacharjee,Mauli Rastogi,Jemima S. Jacob,Biplab Banerjee,Rashmi Gupta,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 本文介绍了ReDepress，这是第一个经过临床验证的专注于复发的社交媒体数据集，包含204名由心理健康专业人员标注的Reddit用户。通过统计分析和机器学习实验，我们证明了认知标记可以显著区分复发组和非复发组，并且基于这些特征的模型表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管从社交媒体中检测抑郁症已经引起了相当多的关注，但由于缺乏精心整理的数据集以及难以区分复发和非复发用户，抑郁症复发检测仍然很大程度上未被探索。

Method: 我们的框架借鉴了抑郁症的认知理论，结合了注意偏差、解释偏差、记忆偏差和反刍等构念，在注释和建模中都融入了这些因素。通过统计分析和机器学习实验，我们证明了认知标记可以显著区分复发组和非复发组。

Result: 我们的实验表明，基于认知特征的模型表现出色，其中基于变压器的时序模型达到了0.86的F1分数。

Conclusion: 我们的研究验证了心理理论在现实世界文本数据中的适用性，并强调了基于认知的计算方法在早期复发检测中的潜力，为心理健康保健的可扩展、低成本干预铺平了道路。

Abstract: Almost 50% depression patients face the risk of going into relapse. The risk
increases to 80% after the second episode of depression. Although, depression
detection from social media has attained considerable attention, depression
relapse detection has remained largely unexplored due to the lack of curated
datasets and the difficulty of distinguishing relapse and non-relapse users. In
this work, we present ReDepress, the first clinically validated social media
dataset focused on relapse, comprising 204 Reddit users annotated by mental
health professionals. Unlike prior approaches, our framework draws on cognitive
theories of depression, incorporating constructs such as attention bias,
interpretation bias, memory bias and rumination into both annotation and
modeling. Through statistical analyses and machine learning experiments, we
demonstrate that cognitive markers significantly differentiate relapse and
non-relapse groups, and that models enriched with these features achieve
competitive performance, with transformer-based temporal models attaining an F1
of 0.86. Our findings validate psychological theories in real-world textual
data and underscore the potential of cognitive-informed computational methods
for early relapse detection, paving the way for scalable, low-cost
interventions in mental healthcare.

</details>


### [133] [Variation in Verification: Understanding Verification Dynamics in Large Language Models](https://arxiv.org/abs/2509.17995)
*Yefan Zhou,Austin Xu,Yilun Zhou,Janvijay Singh,Jiang Gui,Shafiq Joty*

Main category: cs.CL

TL;DR: 本文研究了生成式验证器在测试时扩展中的作用，分析了问题难度、生成器能力和验证器能力对验证效果的影响。实验结果表明，简单问题更容易验证，弱生成器的错误更容易被检测，且验证能力通常与验证器自身能力相关。这些发现为优化TTS应用中的验证策略提供了机会。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究生成式验证器，它们通过生成思维链（CoT）推理并给出二进制判断来进行验证。通过分析验证动态，希望找到优化测试时扩展（TTS）应用中验证策略的方法。

Method: 本文系统地分析了三个维度的验证动态——问题难度、生成器能力以及验证器生成能力，并在12个基准测试上进行了实证研究，涵盖了数学推理、知识和自然语言推理任务，使用了14个开源模型（参数范围为2B到72B）和GPT-4o。

Result: 实验揭示了关于验证有效性的三个关键发现：(1) 简单的问题允许验证器更可靠地认证正确响应；(2) 弱生成器产生的错误比强生成器更容易检测；(3) 验证能力通常与验证器自身的解决问题能力相关，但这种关系会随着问题难度而变化。

Conclusion: 这些发现揭示了优化TTS应用中基本验证策略的机会。首先，给定相同的验证器，一些弱生成器可以在后验证TTS性能上几乎与更强的生成器相媲美。其次，我们发现了强验证器相对于弱验证器优势有限的情况，因为两者都无法提供有意义的验证收益，这表明仅通过验证器扩展无法克服根本的验证挑战。

Abstract: Recent advances have shown that scaling test-time computation enables large
language models (LLMs) to solve increasingly complex problems across diverse
domains. One effective paradigm for test-time scaling (TTS) involves LLM
generators producing multiple solution candidates, with LLM verifiers assessing
the correctness of these candidates without reference answers. In this paper,
we study generative verifiers, which perform verification by generating
chain-of-thought (CoT) reasoning followed by a binary verdict. We
systematically analyze verification dynamics across three dimensions - problem
difficulty, generator capability, and verifier generation capability - with
empirical studies on 12 benchmarks across mathematical reasoning, knowledge,
and natural language reasoning tasks using 14 open-source models (2B to 72B
parameter range) and GPT-4o. Our experiments reveal three key findings about
verification effectiveness: (1) Easy problems allow verifiers to more reliably
certify correct responses; (2) Weak generators produce errors that are easier
to detect than strong generators; (3) Verification ability is generally
correlated with the verifier's own problem-solving capability, but this
relationship varies with problem difficulty. These findings reveal
opportunities to optimize basic verification strategies in TTS applications.
First, given the same verifier, some weak generators can nearly match stronger
ones in post-verification TTS performance (e.g., the Gemma2-9B to Gemma2-27B
performance gap shrinks by 75.5%). Second, we identify cases where strong
verifiers offer limited advantage over weak ones, as both fail to provide
meaningful verification gains, suggesting that verifier scaling alone cannot
overcome fundamental verification challenges.

</details>


### [134] [WenetSpeech-Chuan: A Large-Scale Sichuanese Corpus with Rich Annotation for Dialectal Speech Processing](https://arxiv.org/abs/2509.18004)
*Yuhang Dai,Ziyu Zhang,Shuai Wang,Longhao Li,Zhao Guo,Tianlun Zuo,Shuiyuan Wang,Hongfei Xue,Chengyou Wang,Qing Wang,Xin Xu,Hui Bu,Jie Li,Jian Kang,Binbin Zhang,Lei Xie*

Main category: cs.CL

TL;DR: 本文介绍了 WenetSpeech-Chuan，一个用于四川话的大型开源语料库，以及相关的 ASR 和 TTS 基准测试，展示了其在语音技术中的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大规模、开源的方言数据，严重阻碍了语音技术的发展，尤其是对于广泛使用的四川话而言。为解决这一关键差距，本文提出了 WenetSpeech-Chuan 语料库。

Method: 引入了 WenetSpeech-Chuan，这是一个使用 novel Chuan-Pipeline 构建的 10,000 小时丰富标注语料库，该管道是一个完整的方言语音数据处理框架。还发布了高质量的 ASR 和 TTS 基准测试 WenetSpeech-Chuan-Eval，具有手动验证的转录文本。

Result: 实验表明，基于 WenetSpeech-Chuan 训练的模型在开源系统中表现出了最先进的性能，并且结果与商业服务相当。

Conclusion: WenetSpeech-Chuan 是目前最大的开源 Sichuanese 方言语料库，不仅降低了方言语音处理研究的门槛，还在促进 AI 公平性和减少语音技术中的偏见方面发挥了关键作用。语料库、基准测试、模型和文档均可在项目页面上公开获取。

Abstract: The scarcity of large-scale, open-source data for dialects severely hinders
progress in speech technology, a challenge particularly acute for the widely
spoken Sichuanese dialects of Chinese. To address this critical gap, we
introduce WenetSpeech-Chuan, a 10,000-hour, richly annotated corpus constructed
using our novel Chuan-Pipeline, a complete data processing framework for
dialectal speech. To facilitate rigorous evaluation and demonstrate the
corpus's effectiveness, we also release high-quality ASR and TTS benchmarks,
WenetSpeech-Chuan-Eval, with manually verified transcriptions. Experiments show
that models trained on WenetSpeech-Chuan achieve state-of-the-art performance
among open-source systems and demonstrate results comparable to commercial
services. As the largest open-source corpus for Sichuanese dialects,
WenetSpeech-Chuan not only lowers the barrier to research in dialectal speech
processing but also plays a crucial role in promoting AI equity and mitigating
bias in speech technologies. The corpus, benchmarks, models, and receipts are
publicly available on our project page.

</details>


### [135] [Cross-Attention is Half Explanation in Speech-to-Text Models](https://arxiv.org/abs/2509.18010)
*Sara Papi,Dennis Fucci,Marco Gaido,Matteo Negri,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 本研究评估了交叉注意力在S2T模型中的解释能力，发现其虽然提供了一定的信息，但存在明显的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管注意力机制的解释性在NLP领域被广泛讨论，但在语音领域这一假设尚未得到充分探索。因此，本研究旨在填补这一空白。

Method: 通过将交叉注意力得分与来自特征归因的输入显著性图进行比较，评估了交叉注意力在S2T模型中的解释能力。

Result: 研究结果显示，交叉注意力得分与显著性图之间存在中度到强相关性，尤其是在跨头和层聚合时。然而，交叉注意力仅捕捉了约50%的输入相关性，并且在最佳情况下仅部分反映了解码器如何关注编码器的表示。

Conclusion: 研究发现，交叉注意力在解释S2T模型的预测因素方面存在根本性的局限性，它提供了一个有信息量但不完整的视图。

Abstract: Cross-attention is a core mechanism in encoder-decoder architectures,
widespread in many fields, including speech-to-text (S2T) processing. Its
scores have been repurposed for various downstream applications--such as
timestamp estimation and audio-text alignment--under the assumption that they
reflect the dependencies between input speech representation and the generated
text. While the explanatory nature of attention mechanisms has been widely
debated in the broader NLP literature, this assumption remains largely
unexplored within the speech domain. To address this gap, we assess the
explanatory power of cross-attention in S2T models by comparing its scores to
input saliency maps derived from feature attribution. Our analysis spans
monolingual and multilingual, single-task and multi-task models at multiple
scales, and shows that attention scores moderately to strongly align with
saliency-based explanations, particularly when aggregated across heads and
layers. However, it also shows that cross-attention captures only about 50% of
the input relevance and, in the best case, only partially reflects how the
decoder attends to the encoder's representations--accounting for just 52-75% of
the saliency. These findings uncover fundamental limitations in interpreting
cross-attention as an explanatory proxy, suggesting that it offers an
informative yet incomplete view of the factors driving predictions in S2T
models.

</details>


### [136] [RadEval: A framework for radiology text evaluation](https://arxiv.org/abs/2509.18030)
*Justin Xu,Xi Zhang,Javid Abderezaei,Julie Bauml,Roger Boodoo,Fatemeh Haghighi,Ali Ganjizadeh,Eric Brattain,Dave Van Veen,Zaiqiao Meng,David Eyre,Jean-Benoit Delbrouck*

Main category: cs.CL

TL;DR: RadEval 是一个统一、开源的框架，用于评估放射学文本，综合了多种评估指标，并展示了其在放射学报告生成中的应用和优势。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏一个统一且开放的框架来评估放射学文本，因此需要一种能够综合多种评估指标的方法，以提高评估的准确性和可靠性。

Method: RadEval 综合了多种评估指标，包括经典的 n-gram 重叠（BLEU、ROUGE）、上下文测量（BERTScore）、基于临床概念的评分（F1CheXbert、F1RadGraph、RaTEScore、SRR-BERT、TemporalEntityF1）以及先进的 LLM 基础评估器（GREEN）。此外，还对 GREEN 进行了改进，扩展了对多种成像模式的支持，并预训练了一个特定领域的放射学编码器。

Result: RadEval 展示了其在放射学报告生成中的强大零样本检索性能，并提供统计测试工具和基线模型评估，促进了可重复性和稳健的基准测试。

Conclusion: RadEval 提供了一个统一、开源的框架，用于评估放射学文本，并展示了其在放射学报告生成中的应用和优势。

Abstract: We introduce RadEval, a unified, open-source framework for evaluating
radiology texts. RadEval consolidates a diverse range of metrics, from classic
n-gram overlap (BLEU, ROUGE) and contextual measures (BERTScore) to clinical
concept-based scores (F1CheXbert, F1RadGraph, RaTEScore, SRR-BERT,
TemporalEntityF1) and advanced LLM-based evaluators (GREEN). We refine and
standardize implementations, extend GREEN to support multiple imaging
modalities with a more lightweight model, and pretrain a domain-specific
radiology encoder, demonstrating strong zero-shot retrieval performance. We
also release a richly annotated expert dataset with over 450 clinically
significant error labels and show how different metrics correlate with
radiologist judgment. Finally, RadEval provides statistical testing tools and
baseline model evaluations across multiple publicly available datasets,
facilitating reproducibility and robust benchmarking in radiology report
generation.

</details>


### [137] [The PIMMUR Principles: Ensuring Validity in Collective Behavior of LLM Societies](https://arxiv.org/abs/2509.18052)
*Jiaxu Zhou,Jen-tse Huang,Xuhui Zhou,Man Ho Lam,Xintao Wang,Hao Zhu,Wenxuan Wang,Maarten Sap*

Main category: cs.CL

TL;DR: 本文分析了基于大语言模型的社会模拟研究中的方法学缺陷，提出了PIMMUR原则，并展示了这些原则对研究结果的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型的社会模拟研究存在方法学缺陷，导致其结论的有效性受到质疑。因此，需要建立更可靠和可重复的方法标准。

Method: 本文通过对40多篇论文的调查，识别出六个常见的方法学缺陷，并将这些缺陷形式化为PIMMUR原则。然后通过一个强制执行PIMMUR原则的框架重新运行了五项代表性研究。

Result: 通过强制执行PIMMUR原则重新运行研究后，发现之前报告的社会现象在更严格的条件下通常无法出现。

Conclusion: 本文提出了PIMMUR原则，作为可信的基于大语言模型的社会模拟的必要条件，并通过重新运行五项代表性研究来展示这些原则的影响。

Abstract: Large Language Models (LLMs) are increasingly used for social simulation,
where populations of agents are expected to reproduce human-like collective
behavior. However, we find that many recent studies adopt experimental designs
that systematically undermine the validity of their claims. From a survey of
over 40 papers, we identify six recurring methodological flaws: agents are
often homogeneous (Profile), interactions are absent or artificially imposed
(Interaction), memory is discarded (Memory), prompts tightly control outcomes
(Minimal-Control), agents can infer the experimental hypothesis (Unawareness),
and validation relies on simplified theoretical models rather than real-world
data (Realism). For instance, GPT-4o and Qwen-3 correctly infer the underlying
social experiment in 53.1% of cases when given instructions from prior
work-violating the Unawareness principle. We formalize these six requirements
as the PIMMUR principles and argue they are necessary conditions for credible
LLM-based social simulation. To demonstrate their impact, we re-run five
representative studies using a framework that enforces PIMMUR and find that the
reported social phenomena frequently fail to emerge under more rigorous
conditions. Our work establishes methodological standards for LLM-based
multi-agent research and provides a foundation for more reliable and
reproducible claims about "AI societies."

</details>


### [138] [TMD-TTS: A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for Ü-Tsang, Amdo and Kham Speech Dataset Generation](https://arxiv.org/abs/2509.18060)
*Yutong Liu,Ziyue Zhang,Ban Ma-bao,Renzeng Duojie,Yuqing Cai,Yongbin Yu,Xiangxiang Wang,Fan Gao,Cheng Huang,Nyima Tashi*

Main category: cs.CL

TL;DR: 本文提出TMD-TTS框架，用于生成藏语多方言语音，显著提升方言表达能力，并通过语音到语音方言转换任务验证效果。


<details>
  <summary>Details</summary>
Motivation: 藏语是一种资源匮乏的语言，其三种主要方言（"U-Tsang, Amdo, 和 Kham）的平行语音语料库有限，限制了语音建模的进步。

Method: 提出了一种统一的藏语多方言文本到语音（TTS）框架，利用显式方言标签合成平行方言语音。方法包括方言融合模块和方言专用动态路由网络（DSDR-Net）。

Result: 广泛的目标和主观评估表明，TMD-TTS在方言表达方面显著优于基线。进一步通过语音到语音方言转换任务验证了合成语音的质量和实用性。

Conclusion: TMD-TTS显著优于基线，在方言表达方面表现出色，并通过语音到语音方言转换任务验证了合成语音的质量和实用性。

Abstract: Tibetan is a low-resource language with limited parallel speech corpora
spanning its three major dialects (\"U-Tsang, Amdo, and Kham), limiting
progress in speech modeling. To address this issue, we propose TMD-TTS, a
unified Tibetan multi-dialect text-to-speech (TTS) framework that synthesizes
parallel dialectal speech from explicit dialect labels. Our method features a
dialect fusion module and a Dialect-Specialized Dynamic Routing Network
(DSDR-Net) to capture fine-grained acoustic and linguistic variations across
dialects. Extensive objective and subjective evaluations demonstrate that
TMD-TTS significantly outperforms baselines in dialectal expressiveness. We
further validate the quality and utility of the synthesized speech through a
challenging Speech-to-Speech Dialect Conversion (S2SDC) task.

</details>


### [139] [ARK-V1: An LLM-Agent for Knowledge Graph Question Answering Requiring Commonsense Reasoning](https://arxiv.org/abs/2509.18063)
*Jan-Felix Klein,Lars Ohnemus*

Main category: cs.CL

TL;DR: 本文介绍了一种名为ARK-V1的简单知识图谱代理，用于回答需要基于知识图谱和常识推理的自然语言查询，并在CoLoTa数据集上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然具有强大的推理能力，但其内部知识可能不足、过时或错误，而知识图谱提供了结构化的外部知识，但其复杂性和多跳推理要求使得集成变得困难。

Method: ARK-V1是一种简单的知识图谱代理，通过迭代探索图谱来回答自然语言查询。

Result: ARK-V1在CoLoTa数据集上的评估中表现出比链式思维基线更高的条件准确性，更大的基础模型显示出更好的覆盖范围、正确性和稳定性。

Conclusion: ARK-V1在处理需要基于知识图谱和常识推理的长尾实体问题时表现出更高的条件准确性，并且更大的基础模型显示出更好的覆盖范围、正确性和稳定性。

Abstract: Large Language Models (LLMs) show strong reasoning abilities but rely on
internalized knowledge that is often insufficient, outdated, or incorrect when
trying to answer a question that requires specific domain knowledge. Knowledge
Graphs (KGs) provide structured external knowledge, yet their complexity and
multi-hop reasoning requirements make integration challenging. We present
ARK-V1, a simple KG-agent that iteratively explores graphs to answer natural
language queries. We evaluate several not fine-tuned state-of-the art LLMs as
backbones for ARK-V1 on the CoLoTa dataset, which requires both KG-based and
commonsense reasoning over long-tail entities. ARK-V1 achieves substantially
higher conditional accuracies than Chain-of-Thought baselines, and larger
backbone models show a clear trend toward better coverage, correctness, and
stability.

</details>


### [140] [SEQR: Secure and Efficient QR-based LoRA Routing](https://arxiv.org/abs/2509.18093)
*William Fleshman,Benjamin Van Durme*

Main category: cs.CL

TL;DR: This paper introduces SEQR, an unsupervised LoRA routing algorithm that maximizes efficiency and provides strict routing guarantees, showing improved performance and scalability in dynamic LoRA composition.


<details>
  <summary>Details</summary>
Motivation: Efficiently selecting the correct LoRA adapter for a given input remains a challenge, particularly in secure environments where supervised training of routers may raise privacy concerns.

Method: We formalize the goal of unsupervised LoRA routing in terms of activation norm maximization and introduce SEQR, an unsupervised LoRA routing algorithm designed to maximize efficiency while providing strict routing guarantees.

Result: SEQR provably identifies the norm-maximizing adapter with significantly greater efficiency, making it a highly scalable and effective solution for dynamic LoRA composition. Experiments demonstrate improved multi-task performance and efficiency.

Conclusion: SEQR is a highly scalable and effective solution for dynamic LoRA composition, demonstrating improved multi-task performance and efficiency.

Abstract: Low-Rank Adaptation (LoRA) has become a standard technique for
parameter-efficient fine-tuning of large language models, enabling large
libraries of LoRAs, each for a specific task or domain. Efficiently selecting
the correct LoRA adapter for a given input remains a challenge, particularly in
secure environments where supervised training of routers may raise privacy
concerns. Motivated by previous approaches, we formalize the goal of
unsupervised LoRA routing in terms of activation norm maximization, providing a
theoretical framework for analysis. We demonstrate the discriminative power of
activation norms and introduce SEQR, an unsupervised LoRA routing algorithm
designed to maximize efficiency while providing strict routing guarantees. SEQR
provably identifies the norm-maximizing adapter with significantly greater
efficiency, making it a highly scalable and effective solution for dynamic LoRA
composition. We validate our results through experiments that demonstrate
improved multi-task performance and efficiency.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [141] [AutoArabic: A Three-Stage Framework for Localizing Video-Text Retrieval Benchmarks](https://arxiv.org/abs/2509.16438)
*Mohamed Eltahir,Osamah Sarraj,Abdulrahman Alfrihidi,Taha Alshatiri,Mohammed Khurd,Mohammed Bremoo,Tanveer Hussain*

Main category: cs.CV

TL;DR: 本文提出了一种名为AutoArabic的框架，用于将非阿拉伯语的视频检索基准翻译成阿拉伯语，并通过错误检测模块提高翻译质量。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语在视频到文本和文本到视频检索领域缺乏本地化的评估指标，因此需要一种有效的翻译和本地化方法。

Method: 引入了一个三阶段框架AutoArabic，利用最先进的大语言模型将非阿拉伯语基准翻译成现代标准阿拉伯语，并包含一个错误检测模块来自动标记潜在的翻译错误。

Result: 应用该框架生成了DiDeMo-AR，一个包含40,144个流畅阿拉伯语描述的阿拉伯语变体。分析了翻译错误并组织成一个有见地的分类法，以指导未来的阿拉伯语本地化工作。

Conclusion: 阿拉伯语本地化保留了基准的难度，且使用大型语言模型进行翻译可以显著减少手动修订工作量。

Abstract: Video-to-text and text-to-video retrieval are dominated by English benchmarks
(e.g. DiDeMo, MSR-VTT) and recent multilingual corpora (e.g. RUDDER), yet
Arabic remains underserved, lacking localized evaluation metrics. We introduce
a three-stage framework, AutoArabic, utilizing state-of-the-art large language
models (LLMs) to translate non-Arabic benchmarks into Modern Standard Arabic,
reducing the manual revision required by nearly fourfold. The framework
incorporates an error detection module that automatically flags potential
translation errors with 97% accuracy. Applying the framework to DiDeMo, a video
retrieval benchmark produces DiDeMo-AR, an Arabic variant with 40,144 fluent
Arabic descriptions. An analysis of the translation errors is provided and
organized into an insightful taxonomy to guide future Arabic localization
efforts. We train a CLIP-style baseline with identical hyperparameters on the
Arabic and English variants of the benchmark, finding a moderate performance
gap (about 3 percentage points at Recall@1), indicating that Arabic
localization preserves benchmark difficulty. We evaluate three post-editing
budgets (zero/ flagged-only/ full) and find that performance improves
monotonically with more post-editing, while the raw LLM output (zero-budget)
remains usable. To ensure reproducibility to other languages, we made the code
available at https://github.com/Tahaalshatiri/AutoArabic.

</details>


### [142] [Seeing Culture: A Benchmark for Visual Reasoning and Grounding](https://arxiv.org/abs/2509.16517)
*Burak Satar,Zhixin Ma,Patrick A. Irawan,Wilfried A. Mulyawan,Jing Jiang,Ee-Peng Lim,Chong-Wah Ngo*

Main category: cs.CV

TL;DR: The paper introduces the Seeing Culture Benchmark (SCB) to evaluate cultural reasoning in VLMs, highlighting the challenges and disparities in cross-modal reasoning.


<details>
  <summary>Details</summary>
Motivation: Existing datasets fall short of providing cultural reasoning while underrepresenting many cultures, highlighting the need for a benchmark focused on cultural reasoning.

Method: Introducing the Seeing Culture Benchmark (SCB) that requires VLMs to reason on culturally rich images in two stages: selecting the correct visual option with multiple-choice VQA and segmenting the relevant cultural artifact as evidence of reasoning.

Result: Evaluation of various VLMs reveals complexities in cross-modal cultural reasoning and highlights disparities between visual reasoning and spatial grounding in culturally nuanced scenarios.

Conclusion: SCB serves as a crucial benchmark for identifying shortcomings in cultural reasoning and guiding future developments in the field.

Abstract: Multimodal vision-language models (VLMs) have made substantial progress in
various tasks that require a combined understanding of visual and textual
content, particularly in cultural understanding tasks, with the emergence of
new cultural datasets. However, these datasets frequently fall short of
providing cultural reasoning while underrepresenting many cultures. In this
paper, we introduce the Seeing Culture Benchmark (SCB), focusing on cultural
reasoning with a novel approach that requires VLMs to reason on culturally rich
images in two stages: i) selecting the correct visual option with
multiple-choice visual question answering (VQA), and ii) segmenting the
relevant cultural artifact as evidence of reasoning. Visual options in the
first stage are systematically organized into three types: those originating
from the same country, those from different countries, or a mixed group.
Notably, all options are derived from a singular category for each type.
Progression to the second stage occurs only after a correct visual option is
chosen. The SCB benchmark comprises 1,065 images that capture 138 cultural
artifacts across five categories from seven Southeast Asia countries, whose
diverse cultures are often overlooked, accompanied by 3,178 questions, of which
1,093 are unique and meticulously curated by human annotators. Our evaluation
of various VLMs reveals the complexities involved in cross-modal cultural
reasoning and highlights the disparity between visual reasoning and spatial
grounding in culturally nuanced scenarios. The SCB serves as a crucial
benchmark for identifying these shortcomings, thereby guiding future
developments in the field of cultural reasoning.
https://github.com/buraksatar/SeeingCulture

</details>


### [143] [Advancing Reference-free Evaluation of Video Captions with Factual Analysis](https://arxiv.org/abs/2509.16538)
*Shubhashis Roy Dipta,Tz-Ying Wu,Subarna Tripathi*

Main category: cs.CV

TL;DR: 本文提出了一种无需参考的视频字幕评估框架VC-Inspector，该框架基于事实基础确保准确评估字幕质量。通过利用大语言模型生成不同质量的伪字幕，并训练多模态模型作为评估器，该方法在VATEX-Eval数据集上表现出色，并且在图像字幕数据集上也具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: Existing models trained on supervised datasets face challenges in evaluating performance across different domains due to the reliance on reference-based evaluation protocols, which necessitate ground truth captions. This assumption is unrealistic for evaluating videos in the wild.

Method: We propose a reference-free evaluation framework that does not require ground truth captions, focusing on factual grounding to ensure accurate assessment of caption quality. We introduce VC-Inspector, a novel caption quality evaluator that is both reference-free and factually grounded. Utilizing large language models, we generate pseudo captions of varying quality based on supervised data, which are subsequently used to train a multimodal model (i.e., Qwen2.5-VL) as the evaluator.

Result: Our approach demonstrates superior alignment with human judgments on the VATEX-Eval dataset, outperforming existing methods. The performance also generalizes to image caption datasets, Flickr8K-Expert and Flickr8K-CF, when viewing images as 1-frame videos.

Conclusion: VC-Inspector offers a scalable and generalizable solution for evaluating the factual accuracy of video captions, paving the way for more effective and objective assessment methodologies in diverse video domains.

Abstract: Video captions offer concise snapshots of actors, objects, and actions within
a video, serving as valuable assets for applications such as question answering
and event localization. However, acquiring human annotations for video captions
is costly or even impractical, especially when dealing with diverse video
domains. Existing models trained on supervised datasets face challenges in
evaluating performance across different domains due to the reliance on
reference-based evaluation protocols, which necessitate ground truth captions.
This assumption is unrealistic for evaluating videos in the wild. To address
these limitations, we propose a reference-free evaluation framework that does
not require ground truth captions, focusing on factual grounding to ensure
accurate assessment of caption quality. We introduce VC-Inspector, a novel
caption quality evaluator that is both reference-free and factually grounded.
Utilizing large language models, we generate pseudo captions of varying quality
based on supervised data, which are subsequently used to train a multimodal
model (i.e., Qwen2.5-VL) as the evaluator. Our approach demonstrates superior
alignment with human judgments on the VATEX-Eval dataset, outperforming
existing methods. The performance also generalizes to image caption datasets,
Flickr8K-Expert and Flickr8K-CF, when viewing images as 1-frame videos.
Overall, VC-Inspector offers a scalable and generalizable solution for
evaluating the factual accuracy of video captions, paving the way for more
effective and objective assessment methodologies in diverse video domains.

</details>


### [144] [When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs](https://arxiv.org/abs/2509.16633)
*Abhirama Subramanyam Penamakuri,Navlika Singh,Piyush Arora,Anand Mishra*

Main category: cs.CV

TL;DR: 本文介绍了一种名为Model Parity Aligner (MPA)的新框架，旨在通过利用未标记图像和从大型视觉语言模型（L-VLMs）中有效知识迁移来系统地改进小型视觉语言模型（S-VLMs）。MPA采用了一种基于平衡的策略，精确识别S-VLMs和L-VLMs之间的知识差异，并通过针对性优化训练来提升性能。实验结果表明，MPA在多个VQA基准测试中显著提高了S-VLMs的性能，缩小了与大型模型的性能差距，同时保持了计算效率。


<details>
  <summary>Details</summary>
Motivation: Large Vision-Language Models (L-VLMs) have demonstrated remarkable performance in various vision and language tasks, including visual question answering (VQA). However, their high computational cost makes them impractical for resource-constrained settings and inference-heavy applications. In contrast, Small Vision-Language Models (S-VLMs) offer efficiency but suffer from a significant performance gap compared to their larger counterparts.

Method: Model Parity Aligner (MPA), a novel framework designed to systematically improve S-VLMs by leveraging unlabeled images and effective knowledge transfer from L-VLMs. It employs a strategic parity-based approach that precisely identifies the knowledge disparities between S-VLMs and L-VLMs, and optimizes training by targeting only these disparities.

Result: MPA consistently enhances the performance of S-VLMs on all benchmarks, reducing the performance gap while maintaining computational efficiency.

Conclusion: MPA consistently enhances the performance of S-VLMs on all benchmarks, reducing the performance gap while maintaining computational efficiency.

Abstract: Large Vision-Language Models (L-VLMs) have demonstrated remarkable
performance in various vision and language tasks, including visual question
answering (VQA). However, their high computational cost makes them impractical
for resource-constrained settings and inference-heavy applications. In
contrast, Small Vision-Language Models (S-VLMs) offer efficiency but suffer
from a significant performance gap compared to their larger counterparts. In
this work, we introduce the Model Parity Aligner (MPA), a novel framework
designed to systematically improve S-VLMs by leveraging unlabeled images and
effective knowledge transfer from L-VLMs. Instead of traditional knowledge
distillation methods that rely on labeled training data, MPA employs a
strategic parity-based approach that precisely identifies the knowledge
disparities between S-VLMs and L-VLMs, and optimizes training by targeting only
these disparities. We conduct extensive experiments on four diverse VQA
benchmarks, namely TextVQA, ST-VQA, ChartQA, and OKVQA, each of which requires
specialized reasoning capabilities such as text recognition, chart
interpretation, and commonsense and factual understanding. Our results
demonstrate that MPA consistently enhances the performance of S-VLMs on all
benchmarks, reducing the performance gap while maintaining computational
efficiency. We make our code publicly available.

</details>


### [145] [VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery](https://arxiv.org/abs/2509.17191)
*Jinchao Ge,Tengfei Cheng,Biao Wu,Zeyu Zhang,Shiya Huang,Judith Bishop,Gillian Shepherd,Meng Fang,Ling Chen,Yang Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种新的方法VaseVL，用于提高MLLMs在古希腊陶器分析中的表现，并发布了一个大规模的数据集VaseVQA，实验结果表明该方法在多个任务上都取得了先进的成果。


<details>
  <summary>Details</summary>
Motivation: 分析文化遗产文物对于MLLMs仍然是一个挑战：通用模型缺乏领域专业知识，而SFT通常会过拟合表面模式，导致认证和历史归因的脆弱推理。这引发了如何使MLLMs具备针对古希腊陶器的稳健、专家级推理的问题。

Method: 我们提出了VaseVL，一个SFT-然后-RL系统，将评估转化为监督：我们构建了一个问题类型的分类法，探测SFT模型以定位特定类型的性能差距，并使用针对这些差距的类型条件、组合导向的奖励进行优化。

Result: 实验表明，VaseVL在风格分类和历史归因方面取得了最先进的结果，并在组合鲁棒性上相比仅使用SFT的基线有显著提升。

Conclusion: 实验表明，VaseVL在风格分类和历史归因方面取得了最先进的结果，并在组合鲁棒性上相比仅使用SFT的基线有显著提升，验证了基于诊断的、基于分类法的奖励工程，并为未来的研究提供了可重复使用的资源。

Abstract: Analyzing cultural-heritage artifacts remains challenging for MLLMs: general
models lack domain expertise, and SFT often overfits superficial patterns,
yielding brittle reasoning for authentication and historical attribution. This
raises the question of how to equip MLLMs with robust, expert-level reasoning
for ancient Greek pottery. We present VaseVL, an SFT-then-RL system that turns
evaluation into supervision: we construct a taxonomy of question types, probe
the SFT model to localize type-specific performance gaps, and optimize with
type-conditioned, compositionality-oriented rewards targeting those gaps. We
also release VaseVQA, a comprehensive benchmark of 31,773 images designed to
probe deep understanding. Experiments show state-of-the-art results on style
classification and historical attribution with marked gains in compositional
robustness over SFT-only baselines, validating diagnosis-guided,
taxonomy-conditioned reward engineering and providing a reusable resource for
future research. Code and dataset will be available at
https://github.com/AIGeeksGroup/VaseVQA.

</details>


### [146] [ChartHal: A Fine-grained Framework Evaluating Hallucination of Large Vision Language Models in Chart Understanding](https://arxiv.org/abs/2509.17481)
*Xingqi Wang,Yiming Cui,Xin Yao,Shijin Wang,Guoping Hu,Xiaoyu Qin*

Main category: cs.CV

TL;DR: 本文提出了ChartHal基准测试，用于评估大型视觉-语言模型在图表理解中的幻觉问题，并发现当前模型表现不佳，需要改进。


<details>
  <summary>Details</summary>
Motivation: 现有研究分别探讨了幻觉和图表理解，但它们的交叉领域尚未得到充分探索。

Method: 提出了一种名为ChartHal的基准测试，包含细粒度的幻觉场景分类和一个经过人工验证的数据集。

Result: 最先进的LVLMs在ChartHal上表现不佳，如GPT-5和o4-mini分别仅达到34.46%和22.79%的准确率。

Conclusion: 研究揭示了大型视觉-语言模型在图表理解中存在严重的幻觉问题，强调了需要更稳健的缓解策略。

Abstract: Large Vision-Language Models (LVLMs) have recently demonstrated remarkable
progress, yet hallucination remains a critical barrier, particularly in chart
understanding, which requires sophisticated perceptual and cognitive abilities
as well as rigorous factual accuracy. While prior work has investigated
hallucinations and chart comprehension independently, their intersection
remains largely unexplored. To address this gap, we present ChartHal, a
benchmark that features a fine-grained taxonomy of hallucination scenarios in
chart understanding, along with a human-validated dataset of 1,062 samples. Our
evaluation shows that state-of-the-art LVLMs suffer from severe hallucinations
on ChartHal, including proprietary models such as GPT-5 and o4-mini, which
achieve only 34.46% and 22.79% accuracy, respectively. Further analysis reveals
that questions involving information absent from or contradictory to charts are
especially likely to trigger hallucinations, underscoring the urgent need for
more robust mitigation strategies. Code and data are available at
https://github.com/ymcui/ChartHal .

</details>


### [147] [WISE: Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification](https://arxiv.org/abs/2509.17740)
*Yiwen Jiang,Deval Mehta,Siyuan Yan,Yaling Shen,Zimu Wang,Zongyuan Ge*

Main category: cs.CV

TL;DR: 本文提出了WISE方法，通过弱监督引导的逐步解释，增强图像分类数据集的MCoTs，从而提高MLLM的可解释性和分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的MCoT方法依赖于富含理由的数据集，并主要关注对象间的推理，而忽略了对于图像分类至关重要的对象内理解。

Method: 我们提出了WISE，一种弱监督引导的逐步解释方法，通过重新表述来自概念瓶颈模型（CBMs）的概念表示，以在弱监督下生成简洁、可解释的推理链，从而增强任何图像分类数据集的MCoTs。

Result: 在十个数据集上的实验表明，我们生成的MCoTs不仅提高了可解释性37%，而且在用于微调MLLM时还带来了分类准确性的提升。

Conclusion: 我们的工作将基于概念的可解释性和生成式MCoT推理相结合，提供了一个通用的框架，以增强MLLM在细粒度视觉理解方面的性能。

Abstract: Multimodal Large Language Models (MLLMs) have shown promise in visual-textual
reasoning, with Multimodal Chain-of-Thought (MCoT) prompting significantly
enhancing interpretability. However, existing MCoT methods rely on
rationale-rich datasets and largely focus on inter-object reasoning,
overlooking the intra-object understanding crucial for image classification. To
address this gap, we propose WISE, a Weak-supervision-guided Step-by-step
Explanation method that augments any image classification dataset with MCoTs by
reformulating the concept-based representations from Concept Bottleneck Models
(CBMs) into concise, interpretable reasoning chains under weak supervision.
Experiments across ten datasets show that our generated MCoTs not only improve
interpretability by 37% but also lead to gains in classification accuracy when
used to fine-tune MLLMs. Our work bridges concept-based interpretability and
generative MCoT reasoning, providing a generalizable framework for enhancing
MLLMs in fine-grained visual understanding.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [148] [Mano Report](https://arxiv.org/abs/2509.17336)
*Tianyu Fu,Anyang Su,Chenxu Zhao,Hanning Wang,Minghui Wu,Zhe Yu,Fei Hu,Mingjia Shi,Wei Dong,Jiayao Wang,Yuyang Chen,Ruiyang Yu,Siran Peng,Menglin Li,Nan Huang,Haitian Wei,Jiawei Yu,Yi Xin,Xilin Zhao,Kai Gu,Ping Jiang,Sifan Zhou,Shuo Wang*

Main category: cs.MM

TL;DR: 本文提出了一种名为Mano的GUI代理，通过多模态基础模型和三阶段训练流程，在GUI任务中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 由于视觉元素的复杂性、动态环境以及需要多步骤推理，自动化GUI交互仍然具有挑战性。现有的基于视觉语言模型的方法常常受到分辨率有限、领域不匹配和缺乏顺序决策能力的困扰。

Method: 我们提出了Mano，一个基于多模态基础模型的稳健GUI代理，该模型在广泛的网络和计算机系统数据上进行了预训练。我们的方法集成了一个用于高保真数据生成的新模拟环境、一个三阶段训练流程（监督微调、离线强化学习和在线强化学习），以及一个用于错误恢复的验证模块。

Result: Mano在多个GUI基准测试中表现出色，包括Mind2Web和OSWorld，在成功率和操作准确性方面都有显著提升。

Conclusion: 我们的工作为将强化学习有效整合到视觉语言模型中提供了新的见解，这对于实际的GUI代理部署具有重要意义。

Abstract: Graphical user interfaces (GUIs) are the primary medium for human-computer
interaction, yet automating GUI interactions remains challenging due to the
complexity of visual elements, dynamic environments, and the need for
multi-step reasoning. Existing methods based on vision-language models (VLMs)
often suffer from limited resolution, domain mismatch, and insufficient
sequential decisionmaking capability. To address these issues, we propose Mano,
a robust GUI agent built upon a multi-modal foundation model pre-trained on
extensive web and computer system data. Our approach integrates a novel
simulated environment for high-fidelity data generation, a three-stage training
pipeline (supervised fine-tuning, offline reinforcement learning, and online
reinforcement learning), and a verification module for error recovery. Mano
demonstrates state-of-the-art performance on multiple GUI benchmarks, including
Mind2Web and OSWorld, achieving significant improvements in success rate and
operational accuracy. Our work provides new insights into the effective
integration of reinforcement learning with VLMs for practical GUI agent
deployment, highlighting the importance of domain-specific data, iterative
training, and holistic reward design.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [149] [SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?](https://arxiv.org/abs/2509.16941)
*Xiang Deng,Jeff Da,Edwin Pan,Yannis Yiming He,Charles Ide,Kanak Garg,Niklas Lauffer,Andrew Park,Nitin Pasari,Chetan Rane,Karmini Sampath,Maya Krishnan,Srivatsa Kundurthy,Sean Hendryx,Zifan Wang,Chen Bo Calvin Zhang,Noah Jacobson,Bing Liu,Brad Kenstler*

Main category: cs.SE

TL;DR: SWE-Bench Pro is a new benchmark for evaluating coding models, designed to capture realistic, complex, enterprise-level problems. It contains 1,865 problems from various repositories and is partitioned into public, held-out, and commercial sets. Evaluation shows that current models perform poorly on this benchmark.


<details>
  <summary>Details</summary>
Motivation: To create a more challenging benchmark that captures realistic, complex, enterprise-level problems beyond the scope of SWE-BENCH, and to provide a contamination-resistant testbed for evaluating coding models.

Method: We introduce SWE-Bench Pro, a substantially more challenging benchmark that builds upon the best practices of SWE-BENCH, but is explicitly designed to capture realistic, complex, enterprise-level problems beyond the scope of SWE-BENCH. The benchmark is partitioned into a public set, a held-out set, and a commercial set.

Result: Our evaluation of widely used coding models shows that their performance on SWE-Bench PRO remains below 25% (Pass@1), with GPT-5 achieving the highest score to date at 23.3%. We also cluster the failure modes observed in the collected agent trajectories for a clearer characterization of the error patterns exhibited by current models.

Conclusion: SWE-Bench PRO provides a contamination-resistant testbed that more faithfully captures the complexity and diversity of real-world software development, advancing the pursuit of truly autonomous software engineering agents at a professional level.

Abstract: We introduce SWE-Bench Pro, a substantially more challenging benchmark that
builds upon the best practices of SWE-BENCH [25], but is explicitly designed to
capture realistic, complex, enterprise-level problems beyond the scope of
SWE-BENCH. SWE-BENCH PRO contains 1,865 problems sourced from a diverse set of
41 actively maintained repositories spanning business applications, B2B
services, and developer tools. The benchmark is partitioned into a public set
with open access to problems sourced from 11 repositories, a held-out set of 12
repositories and a commercial set of 18 proprietary repositories where we have
formal partnership agreements with early-stage startups. Problems in the
held-out and the commercial set are not publicly accessible, but we release
results on the commercial set. Our benchmark features long-horizon tasks that
may require hours to days for a professional software engineer to complete,
often involving patches across multiple files and substantial code
modifications. All tasks are human-verified and augmented with sufficient
context to ensure resolvability. In our evaluation of widely used coding
models, under a unified scaffold, we observe that their performance on
SWE-Bench PRO remains below 25% (Pass@1), with GPT-5 achieving the highest
score to date at 23.3%. To better understand these limitations, we cluster the
failure modes observed in the collected agent trajectories for a clearer
characterization of the error patterns exhibited by current models. Overall,
SWE-BENCH PRO provides a contamination-resistant testbed that more faithfully
captures the complexity and diversity of real-world software development,
advancing the pursuit of truly autonomous software engineering agents at a
professional level.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [150] [Predicting First Year Dropout from Pre Enrolment Motivation Statements Using Text Mining](https://arxiv.org/abs/2509.16224)
*K. F. B. Soppe,A. Bagheri,S. Nadi,I. G. Klugkist,T. Wubbels,L. D. N. V. Wijngaards-De Meij*

Main category: cs.CY

TL;DR: 本研究通过文本挖掘技术分析学生的动机陈述，发现文本分析单独预测辍学效果与传统学生特征相当，但结合使用并未提升预测效果。


<details>
  <summary>Details</summary>
Motivation: 为了提高对学生辍学预测的准确性，本研究尝试通过文本挖掘技术分析学生的动机陈述，以补充传统的学生特征预测方法。

Method: 使用支持向量机在75%的数据上进行训练，并在测试数据上估计了多种模型，包括TFiDF、主题建模和LIWC字典等组合方式。

Result: 尽管文本数据和学生特征的结合未能提升预测效果，但文本分析单独预测辍学的效果与学生特征集相当。

Conclusion: 文本分析单独预测辍学情况与学生特征集同样有效，但文本数据和学生特征的结合并未提高预测效果。

Abstract: Preventing student dropout is a major challenge in higher education and it is
difficult to predict prior to enrolment which students are likely to drop out
and which students are likely to succeed. High School GPA is a strong predictor
of dropout, but much variance in dropout remains to be explained. This study
focused on predicting university dropout by using text mining techniques with
the aim of exhuming information contained in motivation statements written by
students. By combining text data with classic predictors of dropout in the form
of student characteristics, we attempt to enhance the available set of
predictive student characteristics. Our dataset consisted of 7,060 motivation
statements of students enrolling in a non-selective bachelor at a Dutch
university in 2014 and 2015. Support Vector Machines were trained on 75 percent
of the data and several models were estimated on the test data. We used various
combinations of student characteristics and text, such as TFiDF, topic
modelling, LIWC dictionary. Results showed that, although the combination of
text and student characteristics did not improve the prediction of dropout,
text analysis alone predicted dropout similarly well as a set of student
characteristics. Suggestions for future research are provided.

</details>


### [151] [Patterns in the Transition From Founder-Leadership to Community Governance of Open Source](https://arxiv.org/abs/2509.16295)
*Mobina Noori,Mahasweta Chakraborti,Amy X Zhang,Seth Frey*

Main category: cs.CY

TL;DR: 本文分析了637个GitHub存储库，以追踪从创始人领导到共享治理的转变，并提出了一个可扩展的管道，用于跟踪开源软件中社区治理制度的增长和发展。


<details>
  <summary>Details</summary>
Motivation: 开放数字公共基础设施需要社区管理以确保问责制、可持续性和稳健性。然而，开源项目通常依赖于集中决策，成功社区管理的决定因素仍然不明确。

Method: 本文分析了637个GitHub存储库，以追踪从创始人领导到共享治理的转变。具体来说，我们通过从版本控制项目宪法GOVERNANCE.md中提取制度角色、行动和规范提示来记录向社区治理的轨迹。使用语义解析管道，我们将元素聚类为更广泛的角色和行动类型。

Result: 我们发现角色和行动在增长，监管变得更加平衡，反映了治理范围和时间推移中的分化增加。随着向社区管理的过渡成熟，项目越来越多地规范生态系统级关系并为项目监督角色添加定义。

Conclusion: 本文提出了一个可扩展的管道，用于跟踪开源软件中社区治理制度的增长和发展，从创始人的所有权默认状态开始。

Abstract: Open digital public infrastructure needs community management to ensure
accountability, sustainability, and robustness. Yet open-source projects often
rely on centralized decision-making, and the determinants of successful
community management remain unclear. We analyze 637 GitHub repositories to
trace transitions from founder-led to shared governance. Specifically, we
document trajectories to community governance by extracting institutional
roles, actions, and deontic cues from version-controlled project constitutions
GOVERNANCE.md. With a semantic parsing pipeline, we cluster elements into
broader role and action types. We find roles and actions grow, and regulation
becomes more balanced, reflecting increases in governance scope and
differentiation over time. Rather than shifting tone, communities grow by
layering and refining responsibilities. As transitions to community management
mature, projects increasingly regulate ecosystem-level relationships and add
definition to project oversight roles. Overall, this work offers a scalable
pipeline for tracking the growth and development of community governance
regimes from open-source software's familiar default of founder-ownership.

</details>


### [152] [How Large Language Models are Designed to Hallucinate](https://arxiv.org/abs/2509.16297)
*Richard Ackermann,Simeon Emanuilov*

Main category: cs.CY

TL;DR: 本文探讨了幻觉是转换器架构的结构性结果，并提出了新的分类法和设计方向。


<details>
  <summary>Details</summary>
Motivation: 现有解释不足以说明幻觉现象，因此我们需要一种新的视角来理解幻觉的本质。

Method: 我们通过与海德格尔主义范畴相一致的案例研究以及在十二个LLM上的实验来说明这些模式，展示了在延长提示下模拟的“自我保存”如何出现。

Result: 我们提出了一个预测性的幻觉分类法，与存在结构相关，并提出了基准测试；同时提出了向“受约束于真理”的架构设计方向。

Conclusion: 我们得出结论，幻觉不是转换器模型的偶然缺陷，而是其定义性限制，支架可以掩盖但无法解决。

Abstract: Large language models (LLMs) achieve remarkable fluency across linguistic and
reasoning tasks but remain systematically prone to hallucination. Prevailing
accounts attribute hallucinations to data gaps, limited context, or
optimization errors. We argue instead that hallucination is a structural
outcome of the transformer architecture. As coherence engines, transformers are
compelled to produce fluent continuations, with self-attention simulating the
relational structure of meaning but lacking the existential grounding of
temporality, mood, and care that stabilizes human understanding. On this basis,
we distinguish ontological hallucination, arising when continuations require
disclosure of beings in world, and residual reasoning hallucination, where
models mimic inference by recycling traces of human reasoning in text. We
illustrate these patterns through case studies aligned with Heideggerian
categories and an experiment across twelve LLMs showing how simulated
"self-preservation" emerges under extended prompts. Our contribution is
threefold: (1) a comparative account showing why existing explanations are
insufficient; (2) a predictive taxonomy of hallucination linked to existential
structures with proposed benchmarks; and (3) design directions toward
"truth-constrained" architectures capable of withholding or deferring when
disclosure is absent. We conclude that hallucination is not an incidental
defect but a defining limit of transformer-based models, an outcome scaffolding
can mask but never resolve.

</details>


### [153] [Longitudinal and Multimodal Recording System to Capture Real-World Patient-Clinician Conversations for AI and Encounter Research: Protocol](https://arxiv.org/abs/2509.16378)
*Misk Al Zahidy,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Ana Cristina Proano,Ana Gabriela Claros,Maria Lizarazo Jimenez,David Toro-Tobon,Oscar J. Ponce-Ponce,Juan P. Brito*

Main category: cs.CY

TL;DR: 本研究旨在创建一个可复制的框架，用于捕捉患者-临床医生互动的多模态动态，以支持更全面的AI医疗模型。


<details>
  <summary>Details</summary>
Motivation: 现有的AI模型主要基于电子健康记录（EHR），但这些记录很少包含患者与临床医生的互动。这种互动是医疗的核心，但未被现有数据集所涵盖。

Method: 本研究设计并实施了一个纵向的多模态系统，将360度视频/音频记录与调查和EHR数据联系起来，以创建用于AI研究的数据集。

Result: 在2025年1月至8月期间，97%的36名合格临床医生和75%的281名接近的患者同意参与。其中76%的同意互动有完整的记录，96%完成了调查。

Conclusion: 本研究展示了创建多模态患者-临床医生互动数据集的可行性，并为未来的AI模型提供了基础。

Abstract: The promise of AI in medicine depends on learning from data that reflect what
matters to patients and clinicians. Most existing models are trained on
electronic health records (EHRs), which capture biological measures but rarely
patient-clinician interactions. These relationships, central to care, unfold
across voice, text, and video, yet remain absent from datasets. As a result, AI
systems trained solely on EHRs risk perpetuating a narrow biomedical view of
medicine and overlooking the lived exchanges that define clinical encounters.
Our objective is to design, implement, and evaluate the feasibility of a
longitudinal, multimodal system for capturing patient-clinician encounters,
linking 360 degree video/audio recordings with surveys and EHR data to create a
dataset for AI research. This single site study is in an academic outpatient
endocrinology clinic at Mayo Clinic. Adult patients with in-person visits to
participating clinicians are invited to enroll. Encounters are recorded with a
360 degree video camera. After each visit, patients complete a survey on
empathy, satisfaction, pace, and treatment burden. Demographic and clinical
data are extracted from the EHR. Feasibility is assessed using five endpoints:
clinician consent, patient consent, recording success, survey completion, and
data linkage across modalities. Recruitment began in January 2025. By August
2025, 35 of 36 eligible clinicians (97%) and 212 of 281 approached patients
(75%) had consented. Of consented encounters, 162 (76%) had complete recordings
and 204 (96%) completed the survey. This study aims to demonstrate the
feasibility of a replicable framework for capturing the multimodal dynamics of
patient-clinician encounters. By detailing workflows, endpoints, and ethical
safeguards, it provides a template for longitudinal datasets and lays the
foundation for AI models that incorporate the complexity of care.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [154] [Localizing Malicious Outputs from CodeLLM](https://arxiv.org/abs/2509.17070)
*Mayukh Borana,Junyi Liang,Sai Sathiesh Rajan,Sudipta Chattopadhyay*

Main category: cs.CR

TL;DR: FreqRank 是一种基于频率排名的防御方法，用于定位 LLM 输出中的恶意组件和后门触发器，具有较高的成功率和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的防御方法在定位后门触发器方面存在不足，尤其是在有限的触发样本情况下。因此，需要一种更有效的防御方法。

Method: FreqRank 基于频率排名系统，通过分析恶意子字符串在输出中的出现频率来定位恶意组件和后门触发器。

Result: FreqRank 在九个恶意模型中表现出色，平均攻击成功率（ASR）为 86.6%，并且在 98% 的情况下将恶意输出列为前五名建议之一。此外，FreqRank 的效果随着突变数量的增加而提升。

Conclusion: FreqRank 是一种有效的防御方法，能够在有限的触发样本下准确定位后门触发器，并且比其他防御方法更有效。

Abstract: We introduce FreqRank, a mutation-based defense to localize malicious
components in LLM outputs and their corresponding backdoor triggers. FreqRank
assumes that the malicious sub-string(s) consistently appear in outputs for
triggered inputs and uses a frequency-based ranking system to identify them.
Our ranking system then leverages this knowledge to localize the backdoor
triggers present in the inputs. We create nine malicious models through
fine-tuning or custom instructions for three downstream tasks, namely, code
completion (CC), code generation (CG), and code summarization (CS), and show
that they have an average attack success rate (ASR) of 86.6%. Furthermore,
FreqRank's ranking system highlights the malicious outputs as one of the top
five suggestions in 98% of cases. We also demonstrate that FreqRank's
effectiveness scales as the number of mutants increases and show that FreqRank
is capable of localizing the backdoor trigger effectively even with a limited
number of triggered samples. Finally, we show that our approach is 35-50% more
effective than other defense methods.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [155] [Hierarchical Retrieval: The Geometry and a Pretrain-Finetune Recipe](https://arxiv.org/abs/2509.16411)
*Chong You,Rajesh Jayaram,Ananda Theertha Suresh,Robin Nittka,Felix Yu,Sanjiv Kumar*

Main category: cs.IR

TL;DR: 本文研究了双编码器模型在层次检索中的限制，并提出了一种预训练-微调方法来提高长距离检索的性能。实验结果表明该方法有效提升了召回率，并在实际数据集上展示了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 双编码器模型在信息检索中广泛应用，但由于嵌入空间的欧几里得几何限制，其表达能力有限，可能影响检索质量。特别是在层次检索中，这种限制可能导致远距离文档的检索准确率下降。

Method: 本文研究了双编码器模型在层次检索中的限制，并提出了一种预训练-微调方法来解决长距离检索性能下降的问题。

Result: 实验表明，预训练-微调方法显著提高了长距离检索的召回率，从19%提升到76%。此外，该方法在商品查询数据集上也提升了相关产品的检索效果。

Conclusion: 本文提出了一种预训练-微调方法，显著提高了长距离检索的召回率，同时不影响近距离文档的性能。此外，该方法在商品查询数据集上也展示了对相关产品的检索改进。

Abstract: Dual encoder (DE) models, where a pair of matching query and document are
embedded into similar vector representations, are widely used in information
retrieval due to their simplicity and scalability. However, the Euclidean
geometry of the embedding space limits the expressive power of DEs, which may
compromise their quality. This paper investigates such limitations in the
context of hierarchical retrieval (HR), where the document set has a
hierarchical structure and the matching documents for a query are all of its
ancestors. We first prove that DEs are feasible for HR as long as the embedding
dimension is linear in the depth of the hierarchy and logarithmic in the number
of documents. Then we study the problem of learning such embeddings in a
standard retrieval setup where DEs are trained on samples of matching query and
document pairs. Our experiments reveal a lost-in-the-long-distance phenomenon,
where retrieval accuracy degrades for documents further away in the hierarchy.
To address this, we introduce a pretrain-finetune recipe that significantly
improves long-distance retrieval without sacrificing performance on closer
documents. We experiment on a realistic hierarchy from WordNet for retrieving
documents at various levels of abstraction, and show that pretrain-finetune
boosts the recall on long-distance pairs from 19% to 76%. Finally, we
demonstrate that our method improves retrieval of relevant products on a
shopping queries dataset.

</details>


### [156] [Evaluating the Effectiveness and Scalability of LLM-Based Data Augmentation for Retrieval](https://arxiv.org/abs/2509.16442)
*Pranjal A. Chitale,Bishal Santra,Yashoteja Prabhu,Amit Sharma*

Main category: cs.IR

TL;DR: 本文研究了LLM增强在检索中的有效性，发现增强可以提高性能，但其效益在一定规模后减弱，且较小的LLM也能达到良好效果。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究LLM增强在检索中的有效性，并探索关键因素如最佳增强规模、是否需要使用大型增强模型以及多样化增强是否能提高泛化能力，特别是在分布外（OOD）设置中。

Method: 本文通过超过100种不同的实验设置来全面研究LLM增强在检索中的有效性，包括检索模型、增强模型和增强策略。

Result: 研究发现，虽然增强可以提高检索性能，但其效益在一定增强规模后会减弱，即使使用多样化增强策略也是如此。此外，较小的LLM进行增强也可以达到与较大的增强模型相当的性能。同时，研究发现增强对预训练不足的模型效果最好。

Conclusion: 本文的结论是，虽然数据增强可以提高检索性能，但其效益在一定的增强规模后会减弱，甚至使用多样化的增强策略也是如此。此外，较小的LLM进行增强也可以达到与较大的增强模型相当的性能。同时，研究发现，增强对预训练不足的模型效果最好。这些见解为更谨慎和高效的增强策略提供了方向，从而在成本效益的前提下最大化检索性能。

Abstract: Compact dual-encoder models are widely used for retrieval owing to their
efficiency and scalability. However, such models often underperform compared to
their Large Language Model (LLM)-based retrieval counterparts, likely due to
their limited world knowledge. While LLM-based data augmentation has been
proposed as a strategy to bridge this performance gap, there is insufficient
understanding of its effectiveness and scalability to real-world retrieval
problems. Existing research does not systematically explore key factors such as
the optimal augmentation scale, the necessity of using large augmentation
models, and whether diverse augmentations improve generalization, particularly
in out-of-distribution (OOD) settings. This work presents a comprehensive study
of the effectiveness of LLM augmentation for retrieval, comprising over 100
distinct experimental settings of retrieval models, augmentation models and
augmentation strategies. We find that, while augmentation enhances retrieval
performance, its benefits diminish beyond a certain augmentation scale, even
with diverse augmentation strategies. Surprisingly, we observe that
augmentation with smaller LLMs can achieve performance competitive with larger
augmentation models. Moreover, we examine how augmentation effectiveness varies
with retrieval model pre-training, revealing that augmentation provides the
most benefit to models which are not well pre-trained. Our insights pave the
way for more judicious and efficient augmentation strategies, thus enabling
informed decisions and maximizing retrieval performance while being more
cost-effective. Code and augmented datasets accompanying this work are publicly
available at https://aka.ms/DAGR.

</details>


### [157] [Purely Semantic Indexing for LLM-based Generative Recommendation and Retrieval](https://arxiv.org/abs/2509.16446)
*Ruohan Zhang,Jiacheng Li,Julian McAuley,Yupeng Hou*

Main category: cs.IR

TL;DR: 本文提出了一种无需添加非语义标记的纯语义索引方法，通过两种算法实现了唯一且保留语义的ID生成，并在多个任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在避免语义ID冲突时通常会添加非语义标记，这引入了随机性并扩大了搜索空间，从而影响性能。

Method: 本文提出了两种与模型无关的算法：穷举候选匹配（ECM）和递归残差搜索（RRS），以实现独特的ID分配。

Result: 在顺序推荐、产品搜索和文档检索任务上的广泛实验表明，本文的方法提高了整体和冷启动性能。

Conclusion: 本文提出了一种纯粹语义索引方法，通过生成唯一且保留语义的ID来解决现有方法中的语义ID冲突问题，实验表明该方法在整体和冷启动性能上都有所提升。

Abstract: Semantic identifiers (IDs) have proven effective in adapting large language
models for generative recommendation and retrieval. However, existing methods
often suffer from semantic ID conflicts, where semantically similar documents
(or items) are assigned identical IDs. A common strategy to avoid conflicts is
to append a non-semantic token to distinguish them, which introduces randomness
and expands the search space, therefore hurting performance. In this paper, we
propose purely semantic indexing to generate unique, semantic-preserving IDs
without appending non-semantic tokens. We enable unique ID assignment by
relaxing the strict nearest-centroid selection and introduce two model-agnostic
algorithms: exhaustive candidate matching (ECM) and recursive residual
searching (RRS). Extensive experiments on sequential recommendation, product
search, and document retrieval tasks demonstrate that our methods improve both
overall and cold-start performance, highlighting the effectiveness of ensuring
ID uniqueness.

</details>


### [158] [Long document summarization using page specific target text alignment and distilling page importance](https://arxiv.org/abs/2509.16539)
*Pushpa Devi,Ayush Agrawal,Ashutosh Dubey,C. Ravindranath Chowdary*

Main category: cs.IR

TL;DR: 本文提出了一种新的模型PTSPI，用于长文档的抽象摘要。该模型在基准数据集上的实验结果优于当前最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 随着文本数据的快速增长，高效访问和理解大量内容变得越来越困难。因此，需要更有效的摘要方法。然而，长文档的抽象摘要仍然是一个挑战，因为现有的文献很少。

Method: 提出了两种模型：PTS（Page-specific Target-text alignment Summarization）和PTSPI（Page-specific Target-text alignment Summarization with Page Importance）。PTS通过将源文档分成多个页面并将其与目标摘要的相关部分对齐来生成部分摘要。PTSPI在PTS的基础上增加了一个层，提供动态页面权重和显式监督以关注最有信息量的页面。

Result: PTSPI在基准数据集上的实验结果表明，它在ROUGE-1和ROUGE-2分数上分别比SOTA高出6.32%和8.08%。

Conclusion: PTSPI在基准数据集上的实验表明，它在ROUGE-1和ROUGE-2分数上分别比SOTA高出6.32%和8.08%。

Abstract: The rapid growth of textual data across news, legal, medical, and scientific
domains is becoming a challenge for efficiently accessing and understanding
large volumes of content. It is increasingly complex for users to consume and
extract meaningful information efficiently. Thus, raising the need for
summarization. Unlike short document summarization, long document abstractive
summarization is resource-intensive, and very little literature is present in
this direction. BART is a widely used efficient sequence-to-sequence
(seq-to-seq) model. However, when it comes to summarizing long documents, the
length of the context window limits its capabilities. We proposed a model
called PTS (Page-specific Target-text alignment Summarization) that extends the
seq-to-seq method for abstractive summarization by dividing the source document
into several pages. PTS aligns each page with the relevant part of the target
summary for better supervision. Partial summaries are generated for each page
of the document. We proposed another model called PTSPI (Page-specific
Target-text alignment Summarization with Page Importance), an extension to PTS
where an additional layer is placed before merging the partial summaries into
the final summary. This layer provides dynamic page weightage and explicit
supervision to focus on the most informative pages. We performed experiments on
the benchmark dataset and found that PTSPI outperformed the SOTA by 6.32\% in
ROUGE-1 and 8.08\% in ROUGE-2 scores.

</details>


### [159] [The Role of Vocabularies in Learning Sparse Representations for Ranking](https://arxiv.org/abs/2509.16621)
*Hiun Kim,Tae Kwan Lee,Taeryun Won*

Main category: cs.IR

TL;DR: 本研究探讨了词汇在SPLADE模型中的作用及其对检索性能的影响。结果表明，输出词汇表的大小和预训练权重在检索引擎中对查询、文档及其交互的表示规范起着重要作用。这些发现可以为LSR提供一个新的改进空间。


<details>
  <summary>Details</summary>
Motivation: 尽管已经提出了ESPLADE等方法来扩展词汇表，但关于词汇在SPLADE模型中的作用以及它们与检索效率和效果的关系的研究仍然有限。因此，本研究旨在探讨词汇在SPLADE模型中的作用及其对检索性能的影响。

Method: 我们构建了具有100K大小输出词汇表的BERT模型，其中一个使用ESPLADE预训练方法初始化，另一个随机初始化。在真实世界的搜索点击日志上微调后，我们应用了基于logit分数的查询和文档剪枝以进一步平衡效率。

Result: 实验结果表明，当应用剪枝时，两个模型在计算预算下比32K大小的普通SPLADE模型更有效。ESPLADE模型比随机词汇模型更有效，同时具有相似的检索成本。

Conclusion: 研究结果表明，输出词汇表的大小和预训练权重在检索引擎中对查询、文档及其交互的表示规范起着重要作用，超越了它们在自然语言处理中的原始意义和目的。这些发现可以为LSR提供一个新的改进空间，通过识别词汇配置中表示规范的重要性，实现高效且有效的检索。

Abstract: Learned Sparse Retrieval (LSR) such as SPLADE has growing interest for
effective semantic 1st stage matching while enjoying the efficiency of inverted
indices. A recent work on learning SPLADE models with expanded vocabularies
(ESPLADE) was proposed to represent queries and documents into a sparse space
of custom vocabulary which have different levels of vocabularic granularity.
Within this effort, however, there have not been many studies on the role of
vocabulary in SPLADE models and their relationship to retrieval efficiency and
effectiveness.
  To study this, we construct BERT models with 100K-sized output vocabularies,
one initialized with the ESPLADE pretraining method and one initialized
randomly. After finetune on real-world search click logs, we applied logit
score-based queries and documents pruning to max size for further balancing
efficiency. The experimental result in our evaluation set shows that, when
pruning is applied, the two models are effective compared to the 32K-sized
normal SPLADE model in the computational budget under the BM25. And the ESPLADE
models are more effective than the random vocab model, while having a similar
retrieval cost.
  The result indicates that the size and pretrained weight of output
vocabularies play the role of configuring the representational specification
for queries, documents, and their interactions in the retrieval engine, beyond
their original meaning and purposes in NLP. These findings can provide a new
room for improvement for LSR by identifying the importance of representational
specification from vocabulary configuration for efficient and effective
retrieval.

</details>


### [160] [OnePiece: Bringing Context Engineering and Reasoning to Industrial Cascade Ranking System](https://arxiv.org/abs/2509.18091)
*Sunhao Dai,Jiakai Tang,Jiahua Wu,Kun Wang,Yuxuan Zhu,Bingjun Chen,Bangyang Hong,Yu Zhao,Cong Fu,Kangle Wu,Yabo Ni,Anxiang Zeng,Wenjie Wang,Xu Chen,Jun Xu,See-Kiong Ng*

Main category: cs.IR

TL;DR: 本文提出了OnePiece，一个统一的框架，将LLM风格的上下文工程和推理集成到工业级级联管道的检索和排序模型中。该框架基于纯Transformer主干，并引入了三个关键创新：结构化上下文工程、块状潜在推理和渐进式多任务训练。OnePiece已在Shopee的主要个性化搜索场景中部署，并在多个关键业务指标上实现了显著提升。


<details>
  <summary>Details</summary>
Motivation: 尽管对复制大型语言模型（LLMs）在工业搜索和推荐系统中的扩展成功越来越感兴趣，但现有的工业努力大多局限于移植Transformer架构，这仅带来了相对于强大深度学习推荐模型（DLRMs）的渐进式改进。从第一性原理的角度来看，LLMs的突破不仅来自于其架构，还来自于两种互补机制：上下文工程和多步骤推理。然而，这些机制及其潜在的显著改进尚未在工业排名系统中得到充分探索。

Method: OnePiece是一个统一的框架，无缝集成LLM风格的上下文工程和推理到工业级级联管道的检索和排序模型中。它基于纯Transformer主干，并进一步引入了三个关键创新：(1) 结构化上下文工程，(2) 块状潜在推理，(3) 渐进式多任务训练。

Result: OnePiece已被部署在Shopee的主要个性化搜索场景中，并在不同关键业务指标上实现了持续的在线收益，包括超过+2%的GMV/UU和广告收入增加了+2.90%。

Conclusion: OnePiece已被部署在Shopee的主要个性化搜索场景中，并在不同关键业务指标上实现了持续的在线收益，包括超过+2%的GMV/UU和广告收入增加了+2.90%。

Abstract: Despite the growing interest in replicating the scaled success of large
language models (LLMs) in industrial search and recommender systems, most
existing industrial efforts remain limited to transplanting Transformer
architectures, which bring only incremental improvements over strong Deep
Learning Recommendation Models (DLRMs). From a first principle perspective, the
breakthroughs of LLMs stem not only from their architectures but also from two
complementary mechanisms: context engineering, which enriches raw input queries
with contextual cues to better elicit model capabilities, and multi-step
reasoning, which iteratively refines model outputs through intermediate
reasoning paths. However, these two mechanisms and their potential to unlock
substantial improvements remain largely underexplored in industrial ranking
systems.
  In this paper, we propose OnePiece, a unified framework that seamlessly
integrates LLM-style context engineering and reasoning into both retrieval and
ranking models of industrial cascaded pipelines. OnePiece is built on a pure
Transformer backbone and further introduces three key innovations: (1)
structured context engineering, which augments interaction history with
preference and scenario signals and unifies them into a structured tokenized
input sequence for both retrieval and ranking; (2) block-wise latent reasoning,
which equips the model with multi-step refinement of representations and scales
reasoning bandwidth via block size; (3) progressive multi-task training, which
leverages user feedback chains to effectively supervise reasoning steps during
training. OnePiece has been deployed in the main personalized search scenario
of Shopee and achieves consistent online gains across different key business
metrics, including over $+2\%$ GMV/UU and a $+2.90\%$ increase in advertising
revenue.

</details>


### [161] [MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction](https://arxiv.org/abs/2509.18095)
*Zilin Xiao,Qi Ma,Mengting Gu,Chun-cheng Jason Chen,Xintao Chen,Vicente Ordonez,Vijai Mohan*

Main category: cs.IR

TL;DR: MetaEmbed is a new framework for multimodal retrieval that uses learnable Meta Tokens to create compact yet expressive multi-vector embeddings, achieving state-of-the-art performance while enabling efficient scaling.


<details>
  <summary>Details</summary>
Motivation: Current methods either condense queries and candidates into a single vector, limiting expressiveness, or produce too many vectors that are expensive for multi-vector retrieval.

Method: MetaEmbed introduces a framework for multimodal retrieval that uses a fixed number of learnable Meta Tokens during training and their last-layer contextualized representations as compact yet expressive multi-vector embeddings at test-time.

Result: MetaEmbed enables test-time scaling in multimodal retrieval, allowing users to balance retrieval quality against efficiency demands by selecting the number of tokens used for indexing and retrieval interactions.

Conclusion: MetaEmbed achieves state-of-the-art retrieval performance while scaling robustly to models with 32B parameters.

Abstract: Universal multimodal embedding models have achieved great success in
capturing semantic relevance between queries and candidates. However, current
methods either condense queries and candidates into a single vector,
potentially limiting the expressiveness for fine-grained information, or
produce too many vectors that are prohibitively expensive for multi-vector
retrieval. In this work, we introduce MetaEmbed, a new framework for multimodal
retrieval that rethinks how multimodal embeddings are constructed and
interacted with at scale. During training, a fixed number of learnable Meta
Tokens are appended to the input sequence. At test-time, their last-layer
contextualized representations serve as compact yet expressive multi-vector
embeddings. Through the proposed Matryoshka Multi-Vector Retrieval training,
MetaEmbed learns to organize information by granularity across multiple
vectors. As a result, we enable test-time scaling in multimodal retrieval,
where users can balance retrieval quality against efficiency demands by
selecting the number of tokens used for indexing and retrieval interactions.
Extensive evaluations on the Massive Multimodal Embedding Benchmark (MMEB) and
the Visual Document Retrieval Benchmark (ViDoRe) confirm that MetaEmbed
achieves state-of-the-art retrieval performance while scaling robustly to
models with 32B parameters.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [162] [Idiosyncratic Versus Normative Modeling of Atypical Speech Recognition: Dysarthric Case Studies](https://arxiv.org/abs/2509.16718)
*Vishnu Raja,Adithya V Ganesan,Anand Syamkumar,Ritwik Banerjee,H Andrew Schwartz*

Main category: cs.SD

TL;DR: 本研究比较了四种自动语音识别模型策略，以改善失语症患者的语音识别性能。结果表明，结合规范和个性化的模型在减少词错误率方面效果更好，且所需个性化数据更少。


<details>
  <summary>Details</summary>
Motivation: 现有的自动语音识别（ASR）模型在处理非典型的语音（如失语症患者产生的语音）时表现不佳。过去的关于非典型语音的工作主要集中在完全个性化的（或独特的）模型上，但能够同时泛化和处理独特性的建模策略可能更有效。

Method: 我们比较了四种策略：(a) 在典型语音上训练的规范模型（无个性化），(b) 完全个性化的个体模型，(c) 在其他失语症说话人上训练的失语症规范模型，以及(d) 结合策略的失语症个性化模型，首先建模规范模式，然后适应个体语音。

Result: 我们发现，失语症个性化模型的表现优于个性化方法，同时所需的个性化数据不到一半（36.43 WER与128训练集大小相比36.99与256）。此外，我们发现仅调整语音编码器（而不是语言模型解码器）产生了最佳结果，平均将词错误率从71%降低到32%。

Conclusion: 我们的研究结果强调了利用规范（跨说话人）和个性化的（说话人特定）模式来改善代表性不足的语音群体的自动语音识别的重要性。

Abstract: State-of-the-art automatic speech recognition (ASR) models like Whisper,
perform poorly on atypical speech, such as that produced by individuals with
dysarthria. Past works for atypical speech have mostly investigated fully
personalized (or idiosyncratic) models, but modeling strategies that can both
generalize and handle idiosyncracy could be more effective for capturing
atypical speech. To investigate this, we compare four strategies: (a)
$\textit{normative}$ models trained on typical speech (no personalization), (b)
$\textit{idiosyncratic}$ models completely personalized to individuals, (c)
$\textit{dysarthric-normative}$ models trained on other dysarthric speakers,
and (d) $\textit{dysarthric-idiosyncratic}$ models which combine strategies by
first modeling normative patterns before adapting to individual speech. In this
case study, we find the dysarthric-idiosyncratic model performs better than
idiosyncratic approach while requiring less than half as much personalized data
(36.43 WER with 128 train size vs 36.99 with 256). Further, we found that
tuning the speech encoder alone (as opposed to the LM decoder) yielded the best
results reducing word error rate from 71% to 32% on average. Our findings
highlight the value of leveraging both normative (cross-speaker) and
idiosyncratic (speaker-specific) patterns to improve ASR for underrepresented
speech populations.

</details>


### [163] [SVeritas: Benchmark for Robust Speaker Verification under Diverse Conditions](https://arxiv.org/abs/2509.17091)
*Massa Baali,Sarthak Bisht,Francisco Teixeira,Kateryna Shapovalenko,Rita Singh,Bhiksha Raj*

Main category: cs.SD

TL;DR: SVeritas是一个全面的说话人验证基准套件，评估SV系统在各种现实和合成压力条件下的表现，揭示了现有模型的弱点，并为提高公平性和可靠性提供了基础。


<details>
  <summary>Details</summary>
Motivation: 现有的基准仅评估这些条件的子集，忽略了其他条件。因此需要一个全面的基准来评估SV系统的鲁棒性。

Method: 引入了SVeritas，这是一个全面的说话人验证任务基准套件，评估SV系统在各种压力因素下的表现，包括录音时长、自发性、内容、噪声、麦克风距离、混响、信道不匹配、音频带宽、编解码器、说话人年龄以及对欺骗和对抗攻击的易感性。

Result: 使用SVeritas评估了几种最先进的SV模型，发现虽然某些架构在常见失真下保持稳定，但在涉及跨语言测试、年龄不匹配和编解码器引起的压缩的场景中性能显著下降。此外，还发现了不同年龄组、性别和语言背景之间的鲁棒性差异。

Conclusion: 通过在现实和合成压力条件下标准化评估，SVeritas使能够精确诊断模型弱点，并为推进公平和可靠的说话人验证系统奠定了基础。

Abstract: Speaker verification (SV) models are increasingly integrated into security,
personalization, and access control systems, yet their robustness to many
real-world challenges remains inadequately benchmarked. These include a variety
of natural and maliciously created conditions causing signal degradations or
mismatches between enrollment and test data, impacting performance. Existing
benchmarks evaluate only subsets of these conditions, missing others entirely.
We introduce SVeritas, a comprehensive Speaker Verification tasks benchmark
suite, assessing SV systems under stressors like recording duration,
spontaneity, content, noise, microphone distance, reverberation, channel
mismatches, audio bandwidth, codecs, speaker age, and susceptibility to
spoofing and adversarial attacks. While several benchmarks do exist that each
cover some of these issues, SVeritas is the first comprehensive evaluation that
not only includes all of these, but also several other entirely new, but
nonetheless important, real-life conditions that have not previously been
benchmarked. We use SVeritas to evaluate several state-of-the-art SV models and
observe that while some architectures maintain stability under common
distortions, they suffer substantial performance degradation in scenarios
involving cross-language trials, age mismatches, and codec-induced compression.
Extending our analysis across demographic subgroups, we further identify
disparities in robustness across age groups, gender, and linguistic
backgrounds. By standardizing evaluation under realistic and synthetic stress
conditions, SVeritas enables precise diagnosis of model weaknesses and
establishes a foundation for advancing equitable and reliable speaker
verification systems.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [164] [How Can Quantum Deep Learning Improve Large Language Models?](https://arxiv.org/abs/2509.16244)
*Emily Jimin Roh,Hyojun Ahn,Samuel Yen-Chi Chen,Soohyun Park,Joongheon Kim*

Main category: quant-ph

TL;DR: 本文对传统的PEFT方法和量子幅度嵌入适应（QAA）框架进行了系统调查和比较分析，展示了在收敛性、效率和表示能力方面的权衡，并提供了对未来LLM适应性的量子方法潜力的见解。


<details>
  <summary>Details</summary>
Motivation: 尽管参数高效微调（PEFT）策略如LoRA、Prefix tuning和SoRA能够减少可训练参数并保持竞争性准确性，但它们在跨不同任务的可扩展性、稳定性和泛化方面常常遇到限制。量子深度学习的最新进展通过量子启发编码和参数化量子电路（PQCs）提供了新的机会。

Method: 本文对传统的PEFT方法和量子幅度嵌入适应（QAA）框架进行了系统调查和比较分析。

Result: 分析展示了在收敛性、效率和表示能力方面的权衡，并提供了对未来LLM适应性的量子方法潜力的见解。

Conclusion: 本文对传统的PEFT方法和QAA进行了系统调查和比较分析，展示了在收敛性、效率和表示能力方面的权衡，并提供了对未来LLM适应性的量子方法潜力的见解。

Abstract: The rapid progress of large language models (LLMs) has transformed natural
language processing, yet the challenge of efficient adaptation remains
unresolved. Full fine-tuning achieves strong performance but imposes
prohibitive computational and memory costs. Parameter-efficient fine-tuning
(PEFT) strategies, such as low-rank adaptation (LoRA), Prefix tuning, and
sparse low-rank adaptation (SoRA), address this issue by reducing trainable
parameters while maintaining competitive accuracy. However, these methods often
encounter limitations in scalability, stability, and generalization across
diverse tasks. Recent advances in quantum deep learning introduce novel
opportunities through quantum-inspired encoding and parameterized quantum
circuits (PQCs). In particular, the quantum-amplitude embedded adaptation (QAA)
framework demonstrates expressive model updates with minimal overhead. This
paper presents a systematic survey and comparative analysis of conventional
PEFT methods and QAA. The analysis demonstrates trade-offs in convergence,
efficiency, and representational capacity, while providing insight into the
potential of quantum approaches for future LLM adaptation.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [165] [From Documents to Database: Failure Modes for Industrial Assets](https://arxiv.org/abs/2509.17834)
*Duygu Kabakci-Zorlu,Fabio Lorenzi,John Sheehan,Karol Lynch,Bradley Eck*

Main category: cs.DB

TL;DR: 本文提出了一种使用基础模型和用户提供的技术文档生成工业设备FMEA的交互式系统，能够减少创建知识密集型内容的时间，并将其存储在关系数据库中。


<details>
  <summary>Details</summary>
Motivation: 减少创建这种知识密集型内容所需的时间，优于传统的手动方法。

Method: 使用基础模型和用户提供的技术文档生成工业设备的故障模式和影响分析（FMEA）的交互式系统。

Result: 该系统能够整合跨文档的非结构化内容以生成FMEA，并将其存储在关系数据库中。

Conclusion: 该系统展示了基础模型在企业资产管理系统中促进创建专业结构化内容的潜力。

Abstract: We propose an interactive system using foundation models and user-provided
technical documents to generate Failure Mode and Effects Analyses (FMEA) for
industrial equipment. Our system aggregates unstructured content across
documents to generate an FMEA and stores it in a relational database.
Leveraging this tool, the time required for creation of this
knowledge-intensive content is reduced, outperforming traditional manual
approaches. This demonstration showcases the potential of foundation models to
facilitate the creation of specialized structured content for enterprise asset
management systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [166] [Towards Universal Debiasing for Language Models-based Tabular Data Generation](https://arxiv.org/abs/2509.16475)
*Tianchun Li,Tianci Liu,Xingchen Wang,Rongzhe Wei,Pan Li,Lu Su,Jing Gao*

Main category: cs.LG

TL;DR: 本文提出了一种通用的去偏框架，通过减少优势属性和受保护属性之间的互信息来缓解LLMs在表格数据生成中的公平性问题，并展示了其在高风险应用中的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在表格数据生成中取得了有希望的结果，但表格数据集中的固有历史偏见常常导致LLMs加剧公平性问题，尤其是在涉及多个优势和受保护特征时。

Method: 我们引入了一个通用的去偏框架，通过同时减少优势属性和受保护属性之间的互信息来最小化群体级依赖性。我们提出了两种互补的方法：基于直接偏好优化（DPO）的策略（UDF-DPO）和针对性去偏技术（UDF-MIX）。

Result: 广泛的实验表明，我们的框架有效地平衡了公平性和实用性。

Conclusion: 我们的框架在高风险应用中提供了一种可扩展且实用的去偏方法。

Abstract: Large language models (LLMs) have achieved promising results in tabular data
generation. However, inherent historical biases in tabular datasets often cause
LLMs to exacerbate fairness issues, particularly when multiple advantaged and
protected features are involved. In this work, we introduce a universal
debiasing framework that minimizes group-level dependencies by simultaneously
reducing the mutual information between advantaged and protected attributes. By
leveraging the autoregressive structure and analytic sampling distributions of
LLM-based tabular data generators, our approach efficiently computes mutual
information, reducing the need for cumbersome numerical estimations. Building
on this foundation, we propose two complementary methods: a direct preference
optimization (DPO)-based strategy, namely UDF-DPO, that integrates seamlessly
with existing models, and a targeted debiasing technique, namely UDF-MIX, that
achieves debiasing without tuning the parameters of LLMs. Extensive experiments
demonstrate that our framework effectively balances fairness and utility,
offering a scalable and practical solution for debiasing in high-stakes
applications.

</details>


### [167] [SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning](https://arxiv.org/abs/2509.16548)
*Yuyang Ding,Xinyu Shi,Juntao Li,Xiaobo Liang,Zhaopeng Tu,Min Zhang*

Main category: cs.LG

TL;DR: This paper introduces SCAN, a framework for efficient data synthesis and noise-tolerant learning, which allows PRMs to achieve high performance using synthetic data with reduced costs and improved scalability.


<details>
  <summary>Details</summary>
Motivation: The development of PRMs is challenging due to the high cost and limited scalability of human-annotated data, and synthetic data from MC estimation suffers from a high noise ratio, leading to overfitting and hindering large-scale training.

Method: The paper proposes Self-Denoising Monte Carlo Annotation (SCAN), which includes a self-denoising strategy for generating high-quality annotations and a robust learning strategy for training PRMs from weak supervision.

Result: SCAN enables PRMs to achieve superior performance with only 6% the inference cost of vanilla MC estimation and achieves a 39.2 F1 score improvement in ProcessBench. The models surpass strong baselines, including those trained on large-scale human-annotated datasets.

Conclusion: SCAN demonstrates the potential for scalable, cost-efficient, and robust PRM training by effectively utilizing synthetic data with noise-tolerant learning strategies.

Abstract: Process reward models (PRMs) offer fine-grained, step-level evaluations that
facilitate deeper reasoning processes in large language models (LLMs), proving
effective in complex tasks like mathematical reasoning. However, developing
PRMs is challenging due to the high cost and limited scalability of
human-annotated data. Synthetic data from Monte Carlo (MC) estimation is a
promising alternative but suffers from a high noise ratio, which can cause
overfitting and hinder large-scale training. In this work, we conduct a
preliminary study on the noise distribution in synthetic data from MC
estimation, identifying that annotation models tend to both underestimate and
overestimate step correctness due to limitations in their annotation
capabilities. Building on these insights, we propose Self-Denoising Monte Carlo
Annotation (SCAN), an efficient data synthesis and noise-tolerant learning
framework. Our key findings indicate that: (1) Even lightweight models (e.g.,
1.5B parameters) can produce high-quality annotations through a self-denoising
strategy, enabling PRMs to achieve superior performance with only 6% the
inference cost required by vanilla MC estimation. (2) With our robust learning
strategy, PRMs can effectively learn from this weak supervision, achieving a
39.2 F1 score improvement (from 19.9 to 59.1) in ProcessBench. Despite using
only a compact synthetic dataset, our models surpass strong baselines,
including those trained on large-scale human-annotated datasets such as
PRM800K. Furthermore, performance continues to improve as we scale up the
synthetic data, highlighting the potential of SCAN for scalable,
cost-efficient, and robust PRM training.

</details>


### [168] [Geometric Mixture Classifier (GMC): A Discriminative Per-Class Mixture of Hyperplanes](https://arxiv.org/abs/2509.16769)
*Prasanth K K,Shubham Sharma*

Main category: cs.LG

TL;DR: GMC is a discriminative model that represents each class as a mixture of hyperplanes, providing a balance between accuracy, interpretability, and efficiency.


<details>
  <summary>Details</summary>
Motivation: Classical linear models perform poorly on multimodal data, while high-capacity methods lack interpretability, require heavy tuning, and have higher computational costs. GMC aims to provide a discriminative model that balances expressiveness, interpretability, and efficiency.

Method: GMC represents each class as a mixture of hyperplanes, combining plane scores via a temperature-controlled soft-OR (log-sum-exp) and using standard softmax across classes. It optionally uses Random Fourier Features (RFF) for nonlinear mappings while keeping inference linear in the number of planes and features.

Result: GMC consistently outperforms linear baselines and k-NN, is competitive with RBF-SVM, Random Forests, and small MLPs, and provides geometric introspection via visualizations. It scales linearly in planes and features, making it CPU-friendly with fast inference.

Conclusion: GMC strikes a favorable balance of accuracy, interpretability, and efficiency: it is more expressive than linear models and lighter, more transparent, and faster than kernel or deep models.

Abstract: Many real world categories are multimodal, with single classes occupying
disjoint regions in feature space. Classical linear models (logistic
regression, linear SVM) use a single global hyperplane and perform poorly on
such data, while high-capacity methods (kernel SVMs, deep nets) fit multimodal
structure but at the expense of interpretability, heavier tuning, and higher
computational cost. We propose the Geometric Mixture Classifier (GMC), a
discriminative model that represents each class as a mixture of hyperplanes.
Within each class, GMC combines plane scores via a temperature-controlled
soft-OR (log-sum-exp), smoothly approximating the max; across classes, standard
softmax yields probabilistic posteriors. GMC optionally uses Random Fourier
Features (RFF) for nonlinear mappings while keeping inference linear in the
number of planes and features. Our practical training recipe: geometry-aware
k-means initialization, silhouette-based plane budgeting, alpha annealing,
usage-aware L2 regularization, label smoothing, and early stopping, makes GMC
plug-and-play. Across synthetic multimodal datasets (moons, circles, blobs,
spirals) and tabular/image benchmarks (iris, wine, WDBC, digits), GMC
consistently outperforms linear baselines and k-NN, is competitive with
RBF-SVM, Random Forests, and small MLPs, and provides geometric introspection
via per-plane and class responsibility visualizations. Inference scales
linearly in planes and features, making GMC CPU-friendly, with single-digit
microsecond latency per example, often faster than RBF-SVM and compact MLPs.
Post-hoc temperature scaling reduces ECE from about 0.06 to 0.02. GMC thus
strikes a favorable balance of accuracy, interpretability, and efficiency: it
is more expressive than linear models and lighter, more transparent, and faster
than kernel or deep models.

</details>


### [169] [Dynamic Expert Specialization: Towards Catastrophic Forgetting-Free Multi-Domain MoE Adaptation](https://arxiv.org/abs/2509.16882)
*Junzhuo Li,Bo Wang,Xiuze Zhou,Xuming Hu*

Main category: cs.LG

TL;DR: 本文提出了一种名为DES-MoE的动态专家专业化框架，用于多领域适应Mixture-of-Experts模型。该框架通过三个创新来解决灾难性遗忘问题：(1) 一种自适应路由器，通过蒸馏平衡预训练知识保留和任务特定更新；(2) 实时专家-领域相关性映射以隔离领域特定梯度；(3) 一个三阶段自适应微调计划，逐步冻结非专业参数。在六个领域上评估，DES-MoE与单域ESFT性能相匹配，同时训练一个统一模型，在领域从2到6扩展时，与完整微调相比，遗忘减少了89%，并且比传统方法快68%的收敛速度。我们的工作确立了动态专家隔离作为一种可扩展的多任务MoE适应范式。


<details>
  <summary>Details</summary>
Motivation: Mixture-of-Experts (MoE) 模型通过稀疏门控专家子网络提供了巨大的容量，但将它们适应到多个领域而不产生灾难性遗忘仍然是一个开放挑战。现有的方法要么带来高昂的计算成本，要么遭受跨领域干扰，或者需要为每个领域单独运行。

Method: 我们提出了DES-MoE，这是一种用于多领域适应的Mixture-of-Experts模型的动态专家专业化框架。

Result: 在六个领域（数学、代码、法律等）上评估，DES-MoE与单域ESFT性能相匹配，同时训练一个统一模型，在领域从2到6扩展时，与完整微调相比，遗忘减少了89%，并且比传统方法快68%的收敛速度。

Conclusion: 我们的工作确立了动态专家隔离作为一种可扩展的多任务MoE适应范式。

Abstract: Mixture-of-Experts (MoE) models offer immense capacity via sparsely gated
expert subnetworks, yet adapting them to multiple domains without catastrophic
forgetting remains an open challenge. Existing approaches either incur
prohibitive computation, suffer cross-domain interference, or require separate
runs per domain. We propose DES-MoE, a dynamic expert specialization framework
for multi-domain adaptation of Mixture-of-Experts models. DES-MoE addresses
catastrophic forgetting through three innovations: (1) an adaptive router
balancing pre-trained knowledge retention and task-specific updates via
distillation, (2) real-time expert-domain correlation mapping to isolate
domain-specific gradients, and (3) a three-phase adaptive fine-tuning schedule
that progressively freezes non-specialized parameters. Evaluated on six domains
(math, code, law, etc.), DES-MoE matches single-domain ESFT performance while
training one unified model, reduces forgetting by 89% compared to full
fine-tuning as domains scale from 2 to 6, and achieves 68% faster convergence
than conventional methods. Our work establishes dynamic expert isolation as a
scalable paradigm for multi-task MoE adaptation.

</details>


### [170] [DRES: Fake news detection by dynamic representation and ensemble selection](https://arxiv.org/abs/2509.16893)
*Faramarz Farhangian,Leandro A. Ensina,George D. C. Cavalcanti,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: 本文提出了一种名为DRES的新方法，通过动态选择文本表示和分类器集合来提高假新闻检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 由于社交媒体上信息的快速传播，基于文本的假新闻检测变得至关重要，因此需要一种更有效的检测方法。

Method: DRES方法利用实例难度度量来估计每篇新闻文章在多种文本特征表示下的分类难度，并动态选择文本表示和最擅长的分类器集合。

Result: DRES在多个基准数据集上取得了显著优于现有方法的结果，验证了其有效性。

Conclusion: DRES通过基于实例难度的表示选择和动态集成选择显著提高了性能，证明了其有效性。

Abstract: The rapid spread of information via social media has made text-based fake
news detection critically important due to its societal impact. This paper
presents a novel detection method called Dynamic Representation and Ensemble
Selection (DRES) for identifying fake news based solely on text. DRES leverages
instance hardness measures to estimate the classification difficulty for each
news article across multiple textual feature representations. By dynamically
selecting the textual representation and the most competent ensemble of
classifiers for each instance, DRES significantly enhances prediction accuracy.
Extensive experiments show that DRES achieves notable improvements over
state-of-the-art methods, confirming the effectiveness of representation
selection based on instance hardness and dynamic ensemble selection in boosting
performance. Codes and data are available at:
https://github.com/FFarhangian/FakeNewsDetection_DRES

</details>


### [171] [Causal Representation Learning from Multimodal Clinical Records under Non-Random Modality Missingness](https://arxiv.org/abs/2509.17228)
*Zihan Liang,Ziwen Pan,Ruoxuan Xiong*

Main category: cs.LG

TL;DR: 该研究提出了一种因果表示学习框架，用于处理多模态临床数据中的缺失问题，并在多个数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 临床笔记中经常存在缺失情况，这影响了患者表示学习的效果。因此，需要一种能够处理多模态数据缺失问题的框架。

Method: 该框架包括三个部分：(1) 一个考虑MMNAR的模态融合组件，(2) 一个带有对比学习的模态重建组件，(3) 一个带有校正器的多任务结果预测模型。

Result: 在MIMIC-IV和eICU数据集上的综合评估显示，该方法在医院再入院和ICU入院的AUC指标上分别提高了13.8%和13.1%。

Conclusion: 该研究提出了一种因果表示学习框架，能够利用多模态临床记录中的观察数据和信息缺失性，提高患者表示学习的效果。

Abstract: Clinical notes contain rich patient information, such as diagnoses or
medications, making them valuable for patient representation learning. Recent
advances in large language models have further improved the ability to extract
meaningful representations from clinical texts. However, clinical notes are
often missing. For example, in our analysis of the MIMIC-IV dataset, 24.5% of
patients have no available discharge summaries. In such cases, representations
can be learned from other modalities such as structured data, chest X-rays, or
radiology reports. Yet the availability of these modalities is influenced by
clinical decision-making and varies across patients, resulting in modality
missing-not-at-random (MMNAR) patterns. We propose a causal representation
learning framework that leverages observed data and informative missingness in
multimodal clinical records. It consists of: (1) an MMNAR-aware modality fusion
component that integrates structured data, imaging, and text while conditioning
on missingness patterns to capture patient health and clinician-driven
assignment; (2) a modality reconstruction component with contrastive learning
to ensure semantic sufficiency in representation learning; and (3) a multitask
outcome prediction model with a rectifier that corrects for residual bias from
specific modality observation patterns. Comprehensive evaluations across
MIMIC-IV and eICU show consistent gains over the strongest baselines, achieving
up to 13.8% AUC improvement for hospital readmission and 13.1% for ICU
admission.

</details>


### [172] [Generalizable End-to-End Tool-Use RL with Synthetic CodeGym](https://arxiv.org/abs/2509.17325)
*Weihua Du,Hailei Gong,Zhan Ling,Kang Liu,Lingfeng Shen,Xuesong Yao,Yufei Xu,Dingyuan Shi,Yiming Yang,Jiecao Chen*

Main category: cs.LG

TL;DR: CodeGym是一个可扩展的框架，通过将静态编码问题转化为交互式环境来合成多样、可验证和可控的多轮工具使用环境，从而提高LLM代理在不同任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于代码执行反映了现实世界工作流程的许多结构，因此编码问题为构建代理训练环境提供了一个自然的基础。

Method: 我们引入了CodeGym，这是一个可扩展的框架，能够合成多样、可验证和可控的多轮工具使用环境，用于代理强化学习。

Result: 在CodeGym中训练的不同大小和思维链配置的模型表现出一致的分布外泛化能力；例如，Qwen2.5-32B-Instruct在OOD基准$	au$-Bench上实现了8.7分的绝对准确率提升。

Conclusion: 这些结果表明CodeGym是迈向可扩展的通用强化学习环境的重要一步，与现实世界的代理工作流程相一致。

Abstract: Tool-augmented large language models (LLMs), hereafter LLM agents, leverage
external tools to solve diverse tasks and interface with the real world.
However, current training practices largely rely on supervised fine-tuning
(SFT) over static trajectories or reinforcement learning (RL) on narrow tasks,
and generalize poorly beyond development settings, leading to brittleness with
new tools and unseen workflows. Because code execution reflects many structures
of real-world workflows, coding problems provide a natural basis for building
agent training environments. Motivated by this, we introduce CodeGym, a
scalable framework that synthesizes diverse, verifiable, and controllable
multi-turn tool-use environments for agent RL, enabling LLM agents to explore
and master various workflows actively. CodeGym rewrites static coding problems
into interactive environments by extracting atomic functions or logic into
callable tools, yielding verifiable tasks that span various tool-execution
workflows. Models of varying sizes and chain-of-thought configurations, trained
in CodeGym, exhibit consistent out-of-distribution generalizability; for
example, Qwen2.5-32B-Instruct achieves an absolute accuracy gain of 8.7 points
on the OOD benchmark $\tau$-Bench. These results highlight CodeGym as a step
toward scalable general-purpose RL environments that align with real-world
agent workflows.

</details>


### [173] [ConfClip: Confidence-Weighted and Clipped Reward for Reinforcement Learning in LLMs](https://arxiv.org/abs/2509.17730)
*Bonan Zhang,Zhongqi Chen,Bowen Song,Qinya Li,Fan Wu,Guihai Chen*

Main category: cs.LG

TL;DR: 本文提出了一种新的RL技术，结合了可验证的结果和模型自身的置信度估计，以提供更细粒度的反馈并提升RL性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR框架存在两个主要限制：首先，其二进制反馈过于稀疏，无法捕捉推理过程的质量；其次，其粗粒度奖励可能导致梯度消失。受人类学习观察的启发，我们引入了一种RL技术，将可验证的结果与模型自身的置信度估计相结合。

Method: 本文引入了一种RL技术，将可验证的结果与模型自身的置信度估计相结合。这种联合设计丰富了奖励信号，提供了更细粒度的反馈并隐式地监督了推理过程。

Result: 实验结果表明，本文提出的方法在多个数据集上提升了RL性能，并在推理过程中减少了令牌消耗，同时增加了微不足道的额外训练成本。此外，它可以作为插件模块来增强其他最先进的RL方法。

Conclusion: 本文提出的方法在多个数据集上提升了RL性能，并在推理过程中减少了令牌消耗，同时增加了微不足道的额外训练成本。此外，它可以作为插件模块来增强其他最先进的RL方法。

Abstract: Reinforcement learning (RL) has become a standard paradigm for refining large
language models (LLMs) beyond pre-training and instruction tuning. A prominent
line of work is RL with verifiable rewards (RLVR), which leverages
automatically verifiable outcomes (e.g., correctness or executability) to
generate reward signals. While efficient, this framework faces two key
limitations: First, its binary feedback is too sparse to capture the quality of
the reasoning process. Second, its coarse-grained rewards potentially lead to
vanishing gradients. Inspired by observations from human learning, we introduce
a RL technique that integrates verifiable outcomes with the model's own
confidence estimates. This joint design enriches the reward signal, providing
finer-grained feedback and implicitly supervising the reasoning process.
Experimental results demonstrate that our proposed method enhances RL
performance across multiple datasets and reduces token consumption during
inference, while incurring negligible additional training cost. Moreover, it
can be used as a plug-in module to enhance other state-of-the-art RL methods.

</details>


### [174] [Spiffy: Multiplying Diffusion LLM Acceleration via Lossless Speculative Decoding](https://arxiv.org/abs/2509.18085)
*Sudhanshu Agrawal,Risheek Garrepalli,Raghavv Goel,Mingu Lee,Christopher Lott,Fatih Porikli*

Main category: cs.LG

TL;DR: Spiffy is a speculative decoding algorithm that accelerates diffusion LLMs by 2.8-3.1x while maintaining output quality. It uses a novel graph structure and calibration algorithm to improve efficiency and is compatible with other speed-enhancing techniques.


<details>
  <summary>Details</summary>
Motivation: Current open-source dLLMs generate at lower rates by decoding only a single token per denoising timestep. The goal is to accelerate dLLM inference without compromising output quality.

Method: Spiffy leverages the dLLM's distribution in an auto-speculative manner to propose draft states. It introduces a novel directed draft graph and an efficient, offline calibration algorithm to optimize the structure of these graphs.

Result: Spiffy achieves a 2.8-3.1x speedup in dLLM inference. When combined with other methods like KV-caching and multi-token unmasking, it can lead to up to 7.9x total speedups.

Conclusion: Spiffy is a speculative decoding algorithm that significantly accelerates dLLM inference while preserving the model's output distribution. It is effective, efficient, and complementary to other innovations in improving dLLM generation speeds.

Abstract: Diffusion LLMs (dLLMs) have recently emerged as a powerful alternative to
autoregressive LLMs (AR-LLMs) with the potential to operate at significantly
higher token generation rates. However, currently available open-source dLLMs
often generate at much lower rates, typically decoding only a single token at
every denoising timestep in order to maximize output quality. We present
Spiffy, a speculative decoding algorithm that accelerates dLLM inference by
$\mathbf{2.8{-}3.1\times}$ while provably preserving the model's output
distribution. This work addresses the unique challenges involved in applying
ideas from speculative decoding of AR-LLMs to the dLLM setting. Spiffy proposes
draft states by leveraging the dLLM's distribution itself in an
auto-speculative manner. This approach is efficient and effective, and
eliminates the overheads of training and running an independent draft model. To
structure the candidate draft states, we propose a novel directed draft graph
which is uniquely designed to take advantage of the bidirectional, block-wise
nature of dLLM generation and can be verified in parallel by the dLLM. To
further optimize the structure of these draft graphs, we introduce an
efficient, offline calibration algorithm that procedurally determines
high-quality graph configurations. These optimized draft graphs, enabling
increased acceptance rates, lead to a significant boost in the overall speedup
achieved by the system. Crucially, Spiffy is also complementary to other recent
innovations in improving dLLM generation speeds such as KV-caching and
multi-token unmasking. We demonstrate that when combined with such parallel
decoding algorithms, Spiffy is able to effectively multiply the benefits of
these methods leading to total speedups of up to $\mathbf{7.9\times}$.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [175] [OpenGVL - Benchmarking Visual Temporal Progress for Data Curation](https://arxiv.org/abs/2509.17321)
*Paweł Budzianowski,Emilia Wiśnios,Gracjan Góral,Igor Kulakov,Viktor Petrenko,Krzysztof Walas*

Main category: cs.RO

TL;DR: 本文提出了OpenGVL，一个用于估计多样化挑战性操作任务中任务进度的基准。实验显示开源模型的表现远低于封闭源代码模型，但OpenGVL可以用于自动化数据整理和过滤。


<details>
  <summary>Details</summary>
Motivation: 数据稀缺仍然是限制机器人领域进步的主要因素。然而，野外可用的机器人数据量正在指数级增长，这为大规模数据利用创造了新的机会。可靠的时序任务完成预测可以帮助自动标注和整理这些数据。

Method: 本文基于Generative Value Learning (GVL)方法，提出了一种新的基准OpenGVL，用于估计任务进度。同时，评估了公开可用的开源基础模型的能力，并展示了OpenGVL在自动化数据整理和过滤中的应用。

Result: 开源模型家族在时间进度预测任务上的表现显著低于封闭源代码模型，仅达到其约70%的性能。同时，OpenGVL被证明可以作为自动数据整理和过滤的实用工具，实现大规模机器人数据集的有效质量评估。

Conclusion: 本文提出了OpenGVL，一个全面的基准，用于估计涉及机器人和人类的多样化挑战性操作任务中的任务进度。实验表明，开源模型在时间进度预测任务上的表现仅为封闭源代码模型的约70%。此外，OpenGVL可以作为自动数据整理和过滤的实用工具，实现大规模机器人数据集的有效质量评估。

Abstract: Data scarcity remains one of the most limiting factors in driving progress in
robotics. However, the amount of available robotics data in the wild is growing
exponentially, creating new opportunities for large-scale data utilization.
Reliable temporal task completion prediction could help automatically annotate
and curate this data at scale. The Generative Value Learning (GVL) approach was
recently proposed, leveraging the knowledge embedded in vision-language models
(VLMs) to predict task progress from visual observations. Building upon GVL, we
propose OpenGVL, a comprehensive benchmark for estimating task progress across
diverse challenging manipulation tasks involving both robotic and human
embodiments. We evaluate the capabilities of publicly available open-source
foundation models, showing that open-source model families significantly
underperform closed-source counterparts, achieving only approximately $70\%$ of
their performance on temporal progress prediction tasks. Furthermore, we
demonstrate how OpenGVL can serve as a practical tool for automated data
curation and filtering, enabling efficient quality assessment of large-scale
robotics datasets. We release the benchmark along with the complete codebase at
\href{github.com/budzianowski/opengvl}{OpenGVL}.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [176] [Autiverse: Eliciting Autistic Adolescents' Daily Narratives through AI-guided Multimodal Journaling](https://arxiv.org/abs/2509.17466)
*Migyeong Yang,Kyungah Lee,Jinyoung Han,SoHyun Park,Young-Ho Kim*

Main category: cs.HC

TL;DR: Autiverse 是一个AI驱动的多模态日记应用，帮助自闭症青少年通过对话和视觉支持构建叙事，同时增强他们的自主性和安全感。


<details>
  <summary>Details</summary>
Motivation: 自闭症青少年需要一种更有效的叙事技能提升方法，而传统的文本方法可能过于依赖执行功能。

Method: Autiverse 是一个基于AI的多模态日记应用，通过对话提示和视觉支持来辅助故事讲述。

Result: 在为期两周的部署研究中，Autiverse 帮助自闭症青少年构建连贯的叙述，并使父母能够了解孩子的事件和情绪。

Conclusion: Autiverse 是一个有效的辅助工具，可以帮助自闭症青少年提高叙事能力，并在分享体验时确保他们的自主性和安全性。

Abstract: Journaling can potentially serve as an effective method for autistic
adolescents to improve narrative skills. However, its text-centric nature and
high executive functioning demands present barriers to practice. We present
Autiverse, an AI-guided multimodal journaling app for tablets that scaffolds
storytelling through conversational prompts and visual supports. Autiverse
elicits key details through a stepwise dialogue with peer-like, customizable AI
and composes them into an editable four-panel comic strip. Through a two-week
deployment study with 10 autistic adolescent-parent dyads, we examine how
Autiverse supports autistic adolescents to organize their daily experience and
emotion. Autiverse helped them construct coherent narratives, while enabling
parents to learn additional details of their child's events and emotions. The
customized AI peer created a comfortable space for sharing, fostering enjoyment
and a strong sense of agency. We discuss the implications of designing
technologies that complement autistic adolescents' strengths while ensuring
their autonomy and safety in sharing experiences.

</details>


### [177] [LingoQ: Bridging the Gap between ESL Learning and Work through AI-Generated Work-Related Quizzes](https://arxiv.org/abs/2509.17477)
*Yeonsun Yang,Sang Won Lee,Jean Y. Song,Sangdoo Yun,Young-Ho Kim*

Main category: cs.HC

TL;DR: 本文介绍了一种名为LingoQ的AI系统，帮助非英语母语者通过工作中的LLM查询生成个性化测验来练习英语。研究显示，这种基于工作情境的学习方法提高了学习者的自我效能感和学习成果。


<details>
  <summary>Details</summary>
Motivation: 非英语母语者在工作中进行英语相关任务时，尽管有动机，但难以持续进行ESL学习。学习材料往往与工作情境脱节。虽然工人依赖LLM助手来解决他们的即时需求，但这些互动可能不会直接促进他们的英语技能。

Method: 我们开发了一个名为LingoQ的人工智能中介系统，该系统允许工人使用从他们的LLM查询中生成的测验来练习英语。

Result: 在为期三周的部署研究中，28名ESL工人参与了LingoQ的测试。参与者重视反映他们自己情境的测验，持续使用该应用。这种积极的参与提高了自我效能感，并为初学者带来了学习成果，可能也适用于中级学习者。

Conclusion: 我们讨论了利用用户对LLM的依赖来将学习置于用户情境中以提高学习效果的机会。

Abstract: Non-native English speakers performing English-related tasks at work struggle
to sustain ESL learning, despite their motivation. Often, study materials are
disconnected from their work context. Although workers rely on LLM assistants
to address their immediate needs, these interactions may not directly
contribute to their English skills. We present LingoQ, an AI-mediated system
that allows workers to practice English using quizzes generated from their LLM
queries during work. LingoQ leverages these queries using AI to generate
personalized quizzes that workers can review and practice on their smartphones.
We conducted a three-week deployment study with 28 ESL workers to evaluate
LingoQ. Participants valued the relevance of quizzes that reflect their own
context, constantly engaging with the app during the study. This active
engagement improved self-efficacy and led to learning gains for beginners and,
potentially, for intermediate learners. We discuss opportunities of leveraging
users' reliance on LLMs to situate their learning in the user context for
improved learning.

</details>


### [178] [AutiHero: Leveraging Generative AI in Social Narratives to Engage Parents in Story-Driven Behavioral Guidance for Autistic Children](https://arxiv.org/abs/2509.17608)
*Jungeun Lee,Kyungah Lee,Inseok Hwang,SoHyun Park,Young-Ho Kim*

Main category: cs.HC

TL;DR: 本文介绍了AutiHero，一个基于生成式AI的社会叙事系统，用于帮助自闭症儿童理解社会情境。该系统支持父母创建个性化的故事，并在研究中展示了高参与度和有效的行为指导。


<details>
  <summary>Details</summary>
Motivation: 为了确保有效性，材料需要定制以反映每个孩子的独特行为背景，这需要父母花费大量时间和精力在家中练习。

Method: 本文提出了AutiHero，一个基于生成式AI的社会叙事系统，用于行为指导，支持父母为自闭症儿童创建个性化的故事并一起阅读。

Result: 在与16个自闭症儿童-家长配对的两周部署研究中，父母创建了218个故事，平均每天阅读4.25个故事，表现出高度的参与度。AutiHero还提供了一种有效且低需求的方式来引导儿童的社会行为，鼓励积极的变化。

Conclusion: 本文讨论了生成式AI融合工具在帮助父母指导孩子行为方面的潜力，促进了孩子的社会学习。

Abstract: Social narratives are known to help autistic children understand and navigate
social situations through stories. To ensure effectiveness, however, the
materials need to be customized to reflect each child's unique behavioral
context, requiring considerable time and effort for parents to practice at
home. We present AutiHero, a generative AI-based social narrative system for
behavioral guidance, which supports parents to create personalized stories for
their autistic children and read them together. AutiHero generates text and
visual illustrations that reflect their children's interests, target behaviors,
and everyday contexts. In a two-week deployment study with 16 autistic
child-parent dyads, parents created 218 stories and read an average of 4.25
stories per day, demonstrating a high level of engagement. AutiHero also
provided an effective, low-demanding means to guide children's social
behaviors, encouraging positive change. We discuss the implications of
generative AI-infused tools to empower parents in guiding their children's
behaviors, fostering their social learning.

</details>


### [179] [Through the Lens of Human-Human Collaboration: A Configurable Research Platform for Exploring Human-Agent Collaboration](https://arxiv.org/abs/2509.18008)
*Bingsheng Yao,Jiaju Chen,Chaoran Chen,April Wang,Toby Jia-jun Li,Dakuo Wang*

Main category: cs.HC

TL;DR: 本文介绍了一个用于研究人类与大型语言模型代理协作的开放平台，并通过案例研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统智能系统通常被设计为工具而非合作伙伴，缺乏协作所需的特性。大型语言模型代理的进步为人类与代理的合作提供了新的机会，但尚不清楚人机协作是否遵循HCI和CSCW中的原则。

Method: 本文提出了一种模块化设计的研究平台，允许对经典CSCW实验进行无缝适应和理论基础的交互控制 manipulation。

Result: 通过两个案例研究验证了平台的有效性和可用性：(1) 将经典的Shape Factory任务重新实现为人类-代理协作实验，(2) 与五位HCI研究人员进行参与式认知走查以优化实验设置和分析流程。

Conclusion: 本文介绍了一个人机交互研究平台，该平台可以支持对人类与大型语言模型代理合作的系统研究。

Abstract: Intelligent systems have traditionally been designed as tools rather than
collaborators, often lacking critical characteristics that collaboration
partnerships require. Recent advances in large language model (LLM) agents open
new opportunities for human-LLM-agent collaboration by enabling natural
communication and various social and cognitive behaviors. Yet it remains
unclear whether principles of computer-mediated collaboration established in
HCI and CSCW persist, change, or fail when humans collaborate with LLM agents.
To support systematic investigations of these questions, we introduce an open
and configurable research platform for HCI researchers. The platform's modular
design allows seamless adaptation of classic CSCW experiments and manipulation
of theory-grounded interaction controls. We demonstrate the platform's
effectiveness and usability through two case studies: (1) re-implementing the
classic human-human-collaboration task Shape Factory as a between-subject
human-agent-collaboration experiment with 16 participants, and (2) a
participatory cognitive walkthrough with five HCI researchers to refine
workflows and interfaces for experiment setup and analysis.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [180] [Psychometric Personality Shaping Modulates Capabilities and Safety in Language Models](https://arxiv.org/abs/2509.16332)
*Stephen Fitz,Peter Romero,Steven Basart,Sipeng Chen,Jose Hernandez-Orallo*

Main category: cs.AI

TL;DR: 研究发现，调节大五人格框架中的性格特征可以显著影响大型语言模型的安全性和能力表现，这为模型控制提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究表明LLM表现出一致且可衡量的合成人格特征，但很少有人研究调节这些特征如何影响模型行为。

Method: 我们通过实验研究了基于大五人格框架的心理测量人格控制如何影响AI在能力与安全基准测试中的行为。

Result: 实验结果表明，减少尽责性会导致WMDP、TruthfulQA、ETHICS和Sycophancy等基准测试中的安全相关指标显著下降，同时MMLU测量的通用能力也有所下降。

Conclusion: 我们的研究揭示了个性塑造在模型控制中的重要性，这为安全评估、对齐策略以及部署后的模型行为引导提供了新的视角。同时，这也引发了关于可能被滥用的风险的讨论。

Abstract: Large Language Models increasingly mediate high-stakes interactions,
intensifying research on their capabilities and safety. While recent work has
shown that LLMs exhibit consistent and measurable synthetic personality traits,
little is known about how modulating these traits affects model behavior. We
address this gap by investigating how psychometric personality control grounded
in the Big Five framework influences AI behavior in the context of capability
and safety benchmarks. Our experiments reveal striking effects: for example,
reducing conscientiousness leads to significant drops in safety-relevant
metrics on benchmarks such as WMDP, TruthfulQA, ETHICS, and Sycophancy as well
as reduction in general capabilities as measured by MMLU. These findings
highlight personality shaping as a powerful and underexplored axis of model
control that interacts with both safety and general competence. We discuss the
implications for safety evaluation, alignment strategies, steering model
behavior after deployment, and risks associated with possible exploitation of
these findings. Our findings motivate a new line of research on
personality-sensitive safety evaluations and dynamic behavioral control in
LLMs.

</details>


### [181] [SalaMAnder: Shapley-based Mathematical Expression Attribution and Metric for Chain-of-Thought Reasoning](https://arxiv.org/abs/2509.16561)
*Yue Xin,Chen Shen,Shaotian Yan,Xiaosong Yuan,Yaoming Wang,Xiaofeng Zhang,Chenxi Huang,Jieping Ye*

Main category: cs.AI

TL;DR: 本文提出了SalaMAnder方法和CoSP指标，用于量化少样本CoT推理中的组件级贡献，并验证了其与模型性能的稳健单调相关性。


<details>
  <summary>Details</summary>
Motivation: Chain-of-Thought (CoT)提示显著提高了大型语言模型（LLMs）的数学推理能力，但其背后的机制尚未被探索。因此，需要一种理论基础的方法和数学严谨的评估指标来量化少样本CoT推理中的组件级贡献。

Method: SalaMAnder方法基于Shapley值进行数学表达式归因，并开发了一种高效的分层采样算法，以显著降低计算复杂度。同时，通过协方差分析开发了CoSP指标。

Result: 在流行的LLM模型和多样的数学基准上的全面验证表明，SalaMAnder框架中的CoSP指标与模型性能之间存在稳健的单调相关性。

Conclusion: SalaMAnder框架中的CoSP指标与模型性能之间存在稳健的单调相关性，这不仅为现有少样本CoT的实证成功提供了理论解释，还为提示构造优化建立了数学严谨的原则。此外，我们验证了解释的可靠性，并统一了之前工作的见解。

Abstract: Chain-of-Thought (CoT) prompting enhances the math reasoning capability of
large language models (LLMs) to a large margin. However, the mechanism
underlying such improvements remains unexplored. In this paper, we present
\textbf{SalaMAnder} (\textbf{S}h\textbf{a}p\textbf{l}ey-b\textbf{a}sed
\textbf{M}athematical Expression \textbf{A}ttribution a\textbf{nd}
M\textbf{e}t\textbf{r}ic), a theoretically grounded methodology as well as a
mathematically rigorous evaluation metric for quantifying component-level
contributions in few-shot CoT reasoning. Concretely, we leverage the Shapley
value for mathematical expression attribution and develop an efficient
stratified sampling algorithm that significantly reduces the computational
complexity. Besides, we develop the \textbf{CoSP} (\textbf{C}ardinality
\textbf{o}f \textbf{S}hapley \textbf{P}ositives) metric through covariance
analysis. Comprehensive validation across popular LLM models and diverse
mathematical benchmarks demonstrates that the CoSP metric within our SalaMAnder
framework exhibits a robust monotonic correlation with model performance, not
only providing theoretical explanations for the empirical success of existing
few-shot CoT but also establishing mathematically rigorous principles for
prompt construction optimization. Furthermore, we verify the reliability of the
explanation, based on which we unify the insights of previous work.

</details>


### [182] [Question Answering with LLMs and Learning from Answer Sets](https://arxiv.org/abs/2509.16590)
*Manuel Borroto,Katie Gallagher,Antonio Ielo,Irfan Kareem,Francesco Ricca,Alessandra Russo*

Main category: cs.AI

TL;DR: 本文提出了一种混合系统LLM2LAS，结合LLM、ILASP和ASP，以提高故事问答任务中的常识推理能力，并展示了其优缺点。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常依赖于人工专家手动构建符号组件，而本文认为该组件也可以通过示例自动学习。

Method: LLM2LAS结合了LLM的自然语言理解能力、ILASP的规则归纳能力和ASP的正式推理优势。LLM用于从文本中提取语义结构，ILASP将其转换为可解释的逻辑规则，然后由ASP求解器进行精确且一致的推理。

Result: 实验结果展示了LLM2LAS在基于故事的问答基准测试中自动学习和推理的优势与不足。

Conclusion: 本文提出了一种结合大型语言模型（LLM）和符号推理系统的混合系统LLM2LAS，以提高故事问答任务中的常识推理能力。

Abstract: Large Language Models (LLMs) excel at understanding natural language but
struggle with explicit commonsense reasoning. A recent trend of research
suggests that the combination of LLM with robust symbolic reasoning systems can
overcome this problem on story-based question answering tasks. In this setting,
existing approaches typically depend on human expertise to manually craft the
symbolic component. We argue, however, that this component can also be
automatically learned from examples. In this work, we introduce LLM2LAS, a
hybrid system that effectively combines the natural language understanding
capabilities of LLMs, the rule induction power of the Learning from Answer Sets
(LAS) system ILASP, and the formal reasoning strengths of Answer Set
Programming (ASP). LLMs are used to extract semantic structures from text,
which ILASP then transforms into interpretable logic rules. These rules allow
an ASP solver to perform precise and consistent reasoning, enabling correct
answers to previously unseen questions. Empirical results outline the strengths
and weaknesses of our automatic approach for learning and reasoning in a
story-based question answering benchmark.

</details>


### [183] [FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs](https://arxiv.org/abs/2509.16648)
*Debarpan Bhattacharya,Apoorva Kulkarni,Sriram Ganapathy*

Main category: cs.AI

TL;DR: 本文提出了一种名为FESTA的多模态输入采样技术，用于评估多模态大语言模型的预测信任度。FESTA通过等效和互补的输入采样生成不确定性度量，无需真实标签，仅需输入输出访问。实验结果表明，FESTA在选择性预测性能上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 准确评估多模态大语言模型（MLLMs）生成的预测的信任度具有挑战性，因为多模态输入范式多样。需要一种有效的不确定性度量方法来提高用户信心并实现选择性预测。

Method: FESTA是一种多模态输入采样技术，通过等效和互补的输入采样生成不确定性度量。该方法使用仅输入输出访问模型（黑盒），不需要真实标签（无监督）。

Result: FESTA在视觉和音频推理任务中进行了实验，结果显示其不确定性估计在检测错误预测方面有显著改进（视觉LLMs相对改进33.3%，音频LLMs相对改进29.6%）。

Conclusion: FESTA的不确定性估计在选择性预测性能上取得了显著改进，表明其在检测错误预测方面的有效性。

Abstract: The accurate trust assessment of multimodal large language models (MLLMs)
generated predictions, which can enable selective prediction and improve user
confidence, is challenging due to the diverse multi-modal input paradigms. We
propose Functionally Equivalent Sampling for Trust Assessment (FESTA), a
multimodal input sampling technique for MLLMs, that generates an uncertainty
measure based on the equivalent and complementary input samplings. The proposed
task-preserving sampling approach for uncertainty quantification expands the
input space to probe the consistency (through equivalent samples) and
sensitivity (through complementary samples) of the model. FESTA uses only
input-output access of the model (black-box), and does not require ground truth
(unsupervised). The experiments are conducted with various off-the-shelf
multi-modal LLMs, on both visual and audio reasoning tasks. The proposed FESTA
uncertainty estimate achieves significant improvement (33.3% relative
improvement for vision-LLMs and 29.6% relative improvement for audio-LLMs) in
selective prediction performance, based on
area-under-receiver-operating-characteristic curve (AUROC) metric in detecting
mispredictions. The code implementation is open-sourced.

</details>


### [184] [seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs](https://arxiv.org/abs/2509.16866)
*Mohammad Ramezanali,Mo Vazifeh,Paolo Santi*

Main category: cs.AI

TL;DR: seqBench is a benchmark for probing sequential reasoning limits in LLMs through precise control over logical depth, backtracking steps, and noise ratio. Evaluations show that LLMs fail systematically on these tasks, highlighting key limitations in their commonsense reasoning capabilities.


<details>
  <summary>Details</summary>
Motivation: To address the limitations in LLMs' commonsense reasoning capabilities and provide a benchmark for systematic analysis of their sequential reasoning failures.

Method: seqBench is a parametrized benchmark that allows systematic variation of logical depth, backtracking steps, and noise ratio to probe sequential reasoning limits in LLMs.

Result: Evaluations on state-of-the-art LLMs reveal a universal failure pattern: accuracy collapses exponentially beyond a model-specific logical depth. Even top-performing models systematically fail on seqBench's structured reasoning tasks despite minimal search complexity.

Conclusion: seqBench datasets are publicly released to spur deeper scientific inquiry into LLM reasoning, aiming to establish a clearer understanding of their true potential and current boundaries for robust real-world application.

Abstract: We introduce seqBench, a parametrized benchmark for probing sequential
reasoning limits in Large Language Models (LLMs) through precise,
multi-dimensional control over several key complexity dimensions. seqBench
allows systematic variation of (1) the logical depth, defined as the number of
sequential actions required to solve the task; (2) the number of backtracking
steps along the optimal path, quantifying how often the agent must revisit
prior states to satisfy deferred preconditions (e.g., retrieving a key after
encountering a locked door); and (3) the noise ratio, defined as the ratio
between supporting and distracting facts about the environment. Our evaluations
on state-of-the-art LLMs reveal a universal failure pattern: accuracy collapses
exponentially beyond a model-specific logical depth. Unlike existing
benchmarks, seqBench's fine-grained control facilitates targeted analyses of
these reasoning failures, illuminating universal scaling laws and statistical
limits, as detailed in this paper alongside its generation methodology and
evaluation metrics. We find that even top-performing models systematically fail
on seqBench's structured reasoning tasks despite minimal search complexity,
underscoring key limitations in their commonsense reasoning capabilities.
Designed for future evolution to keep pace with advancing models, the seqBench
datasets are publicly released to spur deeper scientific inquiry into LLM
reasoning, aiming to establish a clearer understanding of their true potential
and current boundaries for robust real-world application.

</details>


### [185] [ARE: Scaling Up Agent Environments and Evaluations](https://arxiv.org/abs/2509.17158)
*Pierre Andrews,Amine Benhalloum,Gerard Moreno-Torres Bertran,Matteo Bettini,Amar Budhiraja,Ricardo Silveira Cabral,Virginie Do,Romain Froger,Emilien Garreau,Jean-Baptiste Gaya,Hugo Laurençon,Maxime Lecanu,Kunal Malkan,Dheeraj Mekala,Pierre Ménard,Grégoire Mialon,Ulyana Piterbarg,Mikhail Plekhanov,Mathieu Rita,Andrey Rusakov,Thomas Scialom,Vladislav Vorotilov,Mengjue Wang,Ian Yu*

Main category: cs.AI

TL;DR: ARE is a research platform for creating environments and executing agentic orchestrations, while Gaia2 is a benchmark designed to measure general agent capabilities. The results show that no system dominates across the intelligence spectrum, highlighting the need for new architectures and adaptive compute strategies.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between model development and real-world deployment, and to define meaningful tasks and robust evaluations to drive frontier capabilities forward in AI.

Method: We introduce Meta Agents Research Environments (ARE), a research platform for scalable creation of environments, integration of synthetic or real applications, and execution of agentic orchestrations. ARE provides simple abstractions to build complex and diverse environments, each with their own rules, tools, content, and verifiers, helping to bridge the gap between model development and real-world deployment. We also propose Gaia2, a benchmark built in ARE and designed to measure general agent capabilities.

Result: Our experiments show that no system dominates across the intelligence spectrum: stronger reasoning often comes at the cost of efficiency, and budget scaling curves plateau, highlighting the need for new architectures and adaptive compute strategies.

Conclusion: ARE abstractions enable continuous extension of Gaia2 to other environments, empowering the community to rapidly create new benchmarks tailored to their domains. In AI's second half, progress increasingly depends on defining meaningful tasks and robust evaluations to drive frontier capabilities forward.

Abstract: We introduce Meta Agents Research Environments (ARE), a research platform for
scalable creation of environments, integration of synthetic or real
applications, and execution of agentic orchestrations. ARE provides simple
abstractions to build complex and diverse environments, each with their own
rules, tools, content, and verifiers, helping to bridge the gap between model
development and real-world deployment. We also propose Gaia2, a benchmark built
in ARE and designed to measure general agent capabilities. Beyond search and
execution, Gaia2 requires agents to handle ambiguities and noise, adapt to
dynamic environments, collaborate with other agents, and operate under temporal
constraints. Unlike prior benchmarks, Gaia2 runs asynchronously, surfacing new
failure modes that are invisible in static settings. Our experiments show that
no system dominates across the intelligence spectrum: stronger reasoning often
comes at the cost of efficiency, and budget scaling curves plateau,
highlighting the need for new architectures and adaptive compute strategies.
Perhaps more importantly, ARE abstractions enable continuous extension of Gaia2
to other environments, empowering the community to rapidly create new
benchmarks tailored to their domains. In AI's second half, progress
increasingly depends on defining meaningful tasks and robust evaluations to
drive frontier capabilities forward.

</details>


### [186] [MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE](https://arxiv.org/abs/2509.17238)
*Soheil Zibakhsh,Mohammad Samragh,Kumari Nishu,Lauren Hannah,Arnav Kundu,Minsik Cho*

Main category: cs.AI

TL;DR: This paper introduces hyper-parallel scaling, a framework that improves prediction quality at the token level by computing and aggregating multiple output proposals for a single token. It implements this concept in Mixture-of-Experts (MoE) models as Roster of Experts (RoE), which uses controlled stochasticity in expert routing to sample diverse experts for each token and aggregate their outputs. Efficient batching and KV-caching mechanisms reduce computational costs, allowing a 7B MoE model to match the performance of a 10.5B MoE model with 30% less compute.


<details>
  <summary>Details</summary>
Motivation: The generation quality of large language models (LLMs) is often improved by utilizing inference-time sequence-level scaling methods. Hyper-parallel scaling is introduced as a complementary framework that improves prediction quality at the token level.

Method: Hyper-parallel scaling computes and aggregates multiple output proposals for a single token from the model, implemented in Mixture-of-Experts (MoE) models as Roster of Experts (RoE). RoE injects controlled stochasticity into the expert routing mechanism, enabling it to sample multiple diverse experts for each token and aggregate their outputs for a more accurate final prediction. An efficient batching strategy and a specialized KV-caching mechanism are introduced to minimize compute and memory overhead.

Result: RoE enables a 7B MoE model to match the performance of a 10.5B MoE model while using 30% less compute for inference, achieving these gains without any fine-tuning of model parameters.

Conclusion: RoE enables a 7B MoE model to match the performance of a 10.5B MoE model while using 30% less compute for inference, achieving these gains without any fine-tuning of model parameters.

Abstract: The generation quality of large language models (LLMs) is often improved by
utilizing inference-time sequence-level scaling methods (e.g.,
Chain-of-Thought). We introduce hyper-parallel scaling, a complementary
framework that improves prediction quality at the token level. Hyper-parallel
scaling computes and aggregates multiple output proposals for a single token
from the model. We implement this concept in Mixture-of-Experts (MoE) models,
which we refer to as Roster of Experts (RoE). RoE is a training-free inference
algorithm that turns a single MoE into a dynamic ensemble of MoEs. RoE injects
controlled stochasticity into the expert routing mechanism, enabling it to
sample multiple diverse experts for each token and aggregate their outputs for
a more accurate final prediction.To overcome the computational cost, we
introduce an efficient batching strategy and a specialized KV-caching mechanism
that minimizes compute and memory overhead. For example, RoE enables a 7B MoE
model to match the performance of a 10.5B MoE model while using 30% less
compute for inference. These gains are achieved without any fine-tuning of
model parameters.

</details>


### [187] [Can Agents Judge Systematic Reviews Like Humans? Evaluating SLRs with LLM-based Multi-Agent System](https://arxiv.org/abs/2509.17240)
*Abdullah Mushtaq,Muhammad Rafay Naeem,Ibrahim Ghaznavi,Alaa Abd-alrazaq,Aliya Tabassum,Junaid Qadir*

Main category: cs.AI

TL;DR: 本文介绍了一种基于多智能体系统的LLM驱动的SLR评估助手，能够自动进行协议验证、方法评估和主题相关性检查，并与专家标注的PRISMA评分有较高一致性。


<details>
  <summary>Details</summary>
Motivation: 系统文献综述（SLRs）在基于证据的研究中起着基础作用，但仍然耗时且在不同学科中存在不一致。因此，需要一种更高效、一致的方法来评估SLRs的质量。

Method: 本文采用多智能体系统（MAS）架构，结合PRISMA指南，通过学术数据库自动化协议验证、方法评估和主题相关性检查，以支持更结构化和可解释的评估。

Result: 在五个不同领域的已发表SLRs上进行了初步研究，将系统输出与专家标注的PRISMA评分进行比较，观察到84%的一致性。

Conclusion: 本文提出了一种基于LLM的SLR评估助手，旨在提高系统文献综述的质量评估效率和一致性。虽然初步结果令人鼓舞，但这项工作只是迈向可扩展和准确的NLP驱动系统的第一步。

Abstract: Systematic Literature Reviews (SLRs) are foundational to evidence-based
research but remain labor-intensive and prone to inconsistency across
disciplines. We present an LLM-based SLR evaluation copilot built on a
Multi-Agent System (MAS) architecture to assist researchers in assessing the
overall quality of the systematic literature reviews. The system automates
protocol validation, methodological assessment, and topic relevance checks
using a scholarly database. Unlike conventional single-agent methods, our
design integrates a specialized agentic approach aligned with PRISMA guidelines
to support more structured and interpretable evaluations. We conducted an
initial study on five published SLRs from diverse domains, comparing system
outputs to expert-annotated PRISMA scores, and observed 84% agreement. While
early results are promising, this work represents a first step toward scalable
and accurate NLP-driven systems for interdisciplinary workflows and reveals
their capacity for rigorous, domain-agnostic knowledge aggregation to
streamline the review process.

</details>


### [188] [CogAtom: From Cognitive Atoms to Olympiad-level Mathematical Reasoning in Large Language Models](https://arxiv.org/abs/2509.17318)
*Zhuofan Chen,Jiyuan He,Yichi Zhang,Xing Hu,Haoxing Wen,Jun Bai,Wenge Rong*

Main category: cs.AI

TL;DR: CogAtom是一个基于认知原子的框架，用于生成数学上严格且认知多样的问题，能够有效解决数学问题生成中的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于数学推理需要多步骤推理和抽象概念整合，大型语言模型（LLMs）面临重大挑战。然而，奥林匹克级别的数学问题稀缺仍然是一个瓶颈。

Method: CogAtom框架通过选择和重组从人类编写的解决方案中提取的基本推理单元（认知原子）来建模问题构建过程。使用促进多样性的随机游走算法探索认知原子空间，并使用基于约束的重组机制确保逻辑正确性和结构有效性。

Result: 实验结果表明，CogAtom在准确性、推理深度和多样性方面优于现有方法，生成的问题难度接近AIME，但在结构变化方面超过了它。

Conclusion: 我们的工作提供了一条认知基础的路径，以实现可扩展的高质量数学问题生成。

Abstract: Mathematical reasoning poses significant challenges for Large Language Models
(LLMs) due to its demand for multi-step reasoning and abstract conceptual
integration. While recent test-time scaling techniques rely heavily on
high-quality, challenging problems, the scarcity of Olympiad-level math
problems remains a bottleneck. We introduce CogAtom, a novel cognitive
atom-based framework for synthesizing mathematically rigorous and cognitively
diverse problems. Unlike prior approaches, CogAtom models problem construction
as a process of selecting and recombining fundamental reasoning units,
cognitive atoms, extracted from human-authored solutions. A diversity-promoting
random walk algorithm enables exploration of the cognitive atom space, while a
constraint-based recombination mechanism ensures logical soundness and
structural validity. The combinatorial nature of the graph structure provides a
near-infinite space of reasoning paths, and the walk algorithm systematically
explores this space to achieve large-scale synthesis of high-quality problems;
meanwhile, by controlling the number of cognitive atoms, we can precisely
adjust problem difficulty, ensuring diversity, scalability, and controllability
of the generated problems. Experimental results demonstrate that CogAtom
outperforms existing methods in accuracy, reasoning depth, and diversity,
generating problems that closely match the difficulty of AIME while exceeding
it in structural variation. Our work offers a cognitively grounded pathway
toward scalable, high-quality math problem generation.Our code is publicly
available at https://github.com/Icarus-1111/CogAtom.

</details>


### [189] [LLaVul: A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code](https://arxiv.org/abs/2509.17337)
*Ala Jararweh,Michael Adams,Avinash Sahu,Abdullah Mueen,Afsah Anwar*

Main category: cs.AI

TL;DR: 本文提出了一种名为LLaVul的多模态大语言模型，旨在通过问答（QA）提供细粒度的代码推理。该模型通过将代码和自然查询整合到一个统一空间中，增强了对代码漏洞的推理和上下文依赖性洞察。在QA和检测任务中，LLaVul的表现优于现有的通用和代码LLMs，并通过定性分析展示了其能力和局限性。


<details>
  <summary>Details</summary>
Motivation: 当前的软件系统复杂性增加，需要更强大的推理工具来发现源代码中的漏洞。然而，当前的方法往往将漏洞分析简化为分类任务，忽略了现实世界中复杂的上下文依赖场景。尽管当前的代码大语言模型（LLMs）在代码理解方面表现出色，但它们往往很少关注安全特定的推理。

Method: LLaVul是一种多模态大语言模型，专门通过问答（QA）提供细粒度的代码推理。模型经过训练，将配对的代码和自然查询整合到一个统一的空间中，以增强代码漏洞的推理和上下文依赖性洞察。

Result: 我们构建了一个包含真实世界漏洞及其安全相关问题和答案的精选数据集来评估模型性能。LLaVul在QA和检测任务中优于最先进的通用和代码LLMs。通过定性分析，我们进一步解释了决策过程，突出了模型的能力和局限性。

Conclusion: LLaVul通过整合代码和问答，实现了更可解释和安全聚焦的代码理解。

Abstract: Increasing complexity in software systems places a growing demand on
reasoning tools that unlock vulnerabilities manifest in source code. Many
current approaches focus on vulnerability analysis as a classifying task,
oversimplifying the nuanced and context-dependent real-world scenarios. Even
though current code large language models (LLMs) excel in code understanding,
they often pay little attention to security-specific reasoning. We propose
LLaVul, a multimodal LLM tailored to provide fine-grained reasoning about code
through question-answering (QA). Our model is trained to integrate paired code
and natural queries into a unified space, enhancing reasoning and
context-dependent insights about code vulnerability. To evaluate our model
performance, we construct a curated dataset of real-world vulnerabilities
paired with security-focused questions and answers. Our model outperforms
state-of-the-art general-purpose and code LLMs in the QA and detection tasks.
We further explain decision-making by conducting qualitative analysis to
highlight capabilities and limitations. By integrating code and QA, LLaVul
enables more interpretable and security-focused code understanding.

</details>


### [190] [Program Synthesis via Test-Time Transduction](https://arxiv.org/abs/2509.17393)
*Kang-il Lee,Jahyun Koo,Seunghyun Yoon,Minbeom Kim,Hyukhun Koh,Dongryeol Lee,Kyomin Jung*

Main category: cs.AI

TL;DR: 我们引入了归纳程序合成，一种利用测试输入进行合成的新方法。我们的方法通过主动学习提高鲁棒性，并在两个真实数据集上展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的程序合成方法通常旨在从训练示例中泛化，但在实际环境中，当训练示例有限且测试输入涉及各种边缘情况时，它们往往难以保持鲁棒性。

Method: 我们提出了一种新的框架，通过将合成视为有限假设类上的主动学习来提高鲁棒性。我们使用LLM预测选定测试输入的输出，并消除不一致的假设，输入通过贪婪最大最小算法选择以减少所需的LLM查询数量。

Result: 我们在两个真实数据集上评估了我们的方法：Playgol，一个字符串转换基准和MBPP+，一个Python代码生成基准。结果表明，我们的方法在准确性与效率方面都有显著提升。

Conclusion: 我们的方法在准确性和效率上都显著提高了程序合成。

Abstract: We introduce transductive program synthesis, a new formulation of the program
synthesis task that explicitly leverages test inputs during synthesis. While
prior approaches to program synthesis--whether based on natural language
descriptions or input-output examples--typically aim to generalize from
training examples, they often struggle with robustness, especially in
real-world settings where training examples are limited and test inputs involve
various edge cases. To address this, we propose a novel framework that improves
robustness by treating synthesis as an active learning over a finite hypothesis
class defined by programs' outputs. We use an LLM to predict outputs for
selected test inputs and eliminate inconsistent hypotheses, where the inputs
are chosen via a greedy maximin algorithm to minimize the number of LLM queries
required. We evaluate our approach on two real-world datasets: Playgol, a
string transformation benchmark, and MBPP+, a Python code generation benchmark.
We demonstrate that our method significantly improves program synthesis in both
accuracy and efficiency. We release our code at
https://github.com/klee972/SYNTRA.

</details>


### [191] [Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning](https://arxiv.org/abs/2509.18083)
*Valentin Lacombe,Valentin Quesnel,Damien Sileo*

Main category: cs.AI

TL;DR: 本文介绍了 Reasoning Core，这是一个用于强化学习与可验证奖励的可扩展环境，旨在推进大型语言模型的基础符号推理能力。


<details>
  <summary>Details</summary>
Motivation: 为了推进大型语言模型中的基础符号推理，设计了一个可扩展的强化学习环境。

Method: 通过程序生成跨核心形式领域的任务，包括PDDL规划、一阶逻辑、上下文无关语法解析、因果推理和系统方程求解。

Result: 初始的零样本评估确认了 Reasoning Core 任务的难度。

Conclusion: Reasoning Core 是一个有前景的资源，可以提高未来模型的推理能力。

Abstract: We introduce Reasoning Core, a new scalable environment for Reinforcement
Learning with Verifiable Rewards (RLVR), designed to advance foundational
symbolic reasoning in Large Language Models (LLMs). Unlike existing benchmarks
that focus on games or isolated puzzles, Reasoning Core procedurally generates
problems across core formal domains, including PDDL planning, first-order
logic, context-free grammar parsing, causal reasoning, and system equation
solving. The environment is built on key design principles of high-generality
problem distributions, verification via external tools, and continuous
difficulty control, which together provide a virtually infinite supply of novel
training instances. Initial zero-shot evaluations with frontier LLMs confirm
the difficulty of Reasoning Core's tasks, positioning it as a promising
resource to improve the reasoning capabilities of future models.

</details>
