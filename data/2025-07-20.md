<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 36]
- [cs.CC](#cs.CC) [Total: 1]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.SE](#cs.SE) [Total: 2]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.CV](#cs.CV) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models](https://arxiv.org/abs/2507.12547)
*Lionel Wong,Katherine M. Collins,Lance Ying,Cedegao E. Zhang,Adrian Weller,Tobias Gersternberg,Timothy O'Donnell,Alexander K. Lew,Jacob D. Andreas,Joshua B. Tenenbaum,Tyler Brooke-Wilson*

Main category: cs.CL

TL;DR: 本文提出了一种名为“模型合成架构”（MSA）的计算模型，利用语言模型和概率程序来模拟人类在面对新情境时的推理能力。实验结果显示，MSA在捕捉人类判断方面优于仅使用语言模型的基线。


<details>
  <summary>Details</summary>
Motivation: 人们如何能够从广泛的背景知识中调动相关考虑因素，并将其用于推断和预测？我们探索了假设，即人们使用分布式和符号表示的组合来构建针对新情况的定制心理模型。

Method: 我们提出了一个计算实现，即“模型合成架构”（MSA），使用语言模型来实现基于全局相关性的检索和模型合成，并使用概率程序来实现定制的、连贯的世界模型。

Result: 我们的MSA方法比仅使用语言模型的基线更好地捕捉了人类判断，在支持模型合成的LM的直接和链式思维生成中均表现出色。

Conclusion: 这些结果表明，MSA可以以一种模仿人类在开放领域中提供局部连贯推理的方式实现，为理解和复制人类推理提供了一条路径。

Abstract: When faced with novel situations, people are able to marshal relevant
considerations from a wide range of background knowledge and put these to use
in inferences and predictions. What permits us to draw in globally relevant
information and reason over it coherently? Here, we explore the hypothesis that
people use a combination of distributed and symbolic representations to
construct bespoke mental models tailored to novel situations. We propose a
computational implementation of this idea -- a ``Model Synthesis Architecture''
(MSA) -- using language models to implement global relevance-based retrieval
and model synthesis and probabilistic programs to implement bespoke, coherent
world models. We evaluate our MSA as a model of human judgments on a novel
reasoning dataset. The dataset -- built around a `Model Olympics` domain of
sports vignettes -- tests models' capacity for human-like, open-ended reasoning
by requiring (i) judgments about novel causal structures described in language;
(ii) drawing on large bodies of background knowledge; and (iii) doing both in
light of observations that introduce arbitrary novel variables. Our MSA
approach captures human judgments better than language model-only baselines,
under both direct and chain-of-thought generations from the LM that supports
model synthesis. These results suggest that MSAs can be implemented in a way
that mirrors people's ability to deliver locally coherent reasoning over
globally relevant variables, offering a path to understanding and replicating
human reasoning in open-ended domains.

</details>


### [2] [Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility](https://arxiv.org/abs/2507.12553)
*Michael A. Lepori,Jennifer Hu,Ishita Dasgupta,Roma Patel,Thomas Serre,Ellie Pavlick*

Main category: cs.CL

TL;DR: 本文研究了语言模型的模态分类能力，并发现它们可以通过模态差异向量来建模人类的分类行为。


<details>
  <summary>Details</summary>
Motivation: 尽管语言模型被广泛用于各种任务，但最近的研究质疑了它们对句子进行模态分类的能力。因此，本文旨在研究语言模型是否能够可靠地进行模态分类，并探索其与人类模态分类行为的关系。

Method: 本文识别了在各种语言模型中区分模态类别的线性表示，即模态差异向量，并分析了这些向量如何反映语言模型的模态分类判断。此外，还探讨了模态差异向量与人类参与者对可解释特征的评分之间的相关性。

Result: 分析表明，语言模型拥有比之前报告的更可靠的模态分类判断能力。此外，模态差异向量在模型变得更强大时以一致的顺序出现。最后，模态差异向量可以用来建模人类的细粒度分类行为。

Conclusion: 本文通过机制解释技术，得出了关于语言模型模态分类的新见解，并有可能帮助我们理解人类的模态分类。

Abstract: Language models (LMs) are used for a diverse range of tasks, from question
answering to writing fantastical stories. In order to reliably accomplish these
tasks, LMs must be able to discern the modal category of a sentence (i.e.,
whether it describes something that is possible, impossible, completely
nonsensical, etc.). However, recent studies have called into question the
ability of LMs to categorize sentences according to modality (Michaelov et al.,
2025; Kauf et al., 2023). In this work, we identify linear representations that
discriminate between modal categories within a variety of LMs, or modal
difference vectors. Analysis of modal difference vectors reveals that LMs have
access to more reliable modal categorization judgments than previously
reported. Furthermore, we find that modal difference vectors emerge in a
consistent order as models become more competent (i.e., through training steps,
layers, and parameter count). Notably, we find that modal difference vectors
identified within LM activations can be used to model fine-grained human
categorization behavior. This potentially provides a novel view into how human
participants distinguish between modal categories, which we explore by
correlating projections along modal difference vectors with human participants'
ratings of interpretable features. In summary, we derive new insights into LM
modal categorization using techniques from mechanistic interpretability, with
the potential to inform our understanding of modal categorization in humans.

</details>


### [3] [The first open machine translation system for the Chechen language](https://arxiv.org/abs/2507.12672)
*Abu-Viskhan A. Umishov,Vladislav A. Grigorian*

Main category: cs.CL

TL;DR: 本文介绍了一个用于车臣语和俄语之间翻译的开源模型，并提供了相应的数据集。


<details>
  <summary>Details</summary>
Motivation: 为了实现车臣语和俄语之间的翻译，需要一个开源模型和相应的数据集。

Method: 本文探索了将新语言纳入多语言翻译NLLB-200大型语言模型系统的微调能力。

Result: 本文提出的模型在俄语到车臣语和反向翻译中的BLEU/ChrF++得分分别为8.34/34.69和20.89/44.55。

Conclusion: 本文介绍了第一个用于车臣语和俄语之间翻译的开源模型，并收集了用于训练和评估该模型的数据集。

Abstract: We introduce the first open-source model for translation between the
vulnerable Chechen language and Russian, and the dataset collected to train and
evaluate it. We explore fine-tuning capabilities for including a new language
into a large language model system for multilingual translation NLLB-200. The
BLEU / ChrF++ scores for our model are 8.34 / 34.69 and 20.89 / 44.55 for
translation from Russian to Chechen and reverse direction, respectively. The
release of the translation models is accompanied by the distribution of
parallel words, phrases and sentences corpora and multilingual sentence encoder
adapted to the Chechen language.

</details>


### [4] [Improving Drug Identification in Overdose Death Surveillance using Large Language Models](https://arxiv.org/abs/2507.12679)
*Arthur J. Funnell,Panayiotis Petousis,Fabrice Harel-Canada,Ruby Romero,Alex A. T. Bui,Adam Koncsol,Hritika Chaturvedi,Chelsea Shover,David Goodman-Meza*

Main category: cs.CL

TL;DR: NLP models, especially fine-tuned clinical variants like BioClinicalBERT, provide highly accurate and scalable solutions for classifying overdose deaths from free-text reports, significantly improving surveillance workflows and enabling near real-time detection of substance use trends.


<details>
  <summary>Details</summary>
Motivation: The rising rate of drug-related deaths in the United States, largely driven by fentanyl, requires timely and accurate surveillance. However, critical overdose data are often buried in free-text coroner reports, leading to delays and information loss when coded into ICD (International Classification of Disease)-10 classifications. Natural language processing (NLP) models may automate and enhance overdose surveillance, but prior applications have been limited.

Method: Multiple NLP approaches were evaluated for classifying specific drug involvement from unstructured death certificate text. These included traditional single- and multi-label classifiers, as well as fine-tuned encoder-only language models such as Bidirectional Encoder Representations from Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large language models such as Qwen 3 and Llama 3.

Result: Fine-tuned BioClinicalBERT models achieved near-perfect performance, with macro F1 scores >=0.998 on the internal test set. External validation confirmed robustness (macro F1=0.966), outperforming conventional machine learning, general-domain BERT models, and various decoder-only large language models.

Conclusion: NLP models, particularly fine-tuned clinical variants like BioClinicalBERT, offer a highly accurate and scalable solution for overdose death classification from free-text reports. These methods can significantly accelerate surveillance workflows, overcoming the limitations of manual ICD-10 coding and supporting near real-time detection of emerging substance use trends.

Abstract: The rising rate of drug-related deaths in the United States, largely driven
by fentanyl, requires timely and accurate surveillance. However, critical
overdose data are often buried in free-text coroner reports, leading to delays
and information loss when coded into ICD (International Classification of
Disease)-10 classifications. Natural language processing (NLP) models may
automate and enhance overdose surveillance, but prior applications have been
limited. A dataset of 35,433 death records from multiple U.S. jurisdictions in
2020 was used for model training and internal testing. External validation was
conducted using a novel separate dataset of 3,335 records from 2023-2024.
Multiple NLP approaches were evaluated for classifying specific drug
involvement from unstructured death certificate text. These included
traditional single- and multi-label classifiers, as well as fine-tuned
encoder-only language models such as Bidirectional Encoder Representations from
Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large
language models such as Qwen 3 and Llama 3. Model performance was assessed
using macro-averaged F1 scores, and 95% confidence intervals were calculated to
quantify uncertainty. Fine-tuned BioClinicalBERT models achieved near-perfect
performance, with macro F1 scores >=0.998 on the internal test set. External
validation confirmed robustness (macro F1=0.966), outperforming conventional
machine learning, general-domain BERT models, and various decoder-only large
language models. NLP models, particularly fine-tuned clinical variants like
BioClinicalBERT, offer a highly accurate and scalable solution for overdose
death classification from free-text reports. These methods can significantly
accelerate surveillance workflows, overcoming the limitations of manual ICD-10
coding and supporting near real-time detection of emerging substance use
trends.

</details>


### [5] [AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.12695)
*S M Rafiuddin,Sadia Kamal,Mohammed Rakib,Arunkumar Bagavathi,Atriya Sen*

Main category: cs.CL

TL;DR: AdaptiSent is a new framework for Multimodal Aspect-Based Sentiment Analysis that improves sentiment classification and aspect term extraction using adaptive cross-modal attention mechanisms, outperforming existing models on standard Twitter datasets.


<details>
  <summary>Details</summary>
Motivation: The paper aims to improve sentiment classification and aspect term extraction from multimodal data by focusing on the interaction between textual cues and visual context.

Method: AdaptiSent uses adaptive cross-modal attention mechanisms, dynamic modality weighting, and context-adaptive attention to enhance sentiment classification and aspect term extraction from both text and images.

Result: AdaptiSent surpasses existing models in precision, recall, and F1 score, particularly in identifying nuanced inter-modal relationships crucial for accurate sentiment and aspect term extraction.

Conclusion: AdaptiSent sets a new standard for MABSA, significantly outperforming current methods, especially in understanding complex multimodal information.

Abstract: We introduce AdaptiSent, a new framework for Multimodal Aspect-Based
Sentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms
to improve sentiment classification and aspect term extraction from both text
and images. Our model integrates dynamic modality weighting and
context-adaptive attention, enhancing the extraction of sentiment and
aspect-related information by focusing on how textual cues and visual context
interact. We tested our approach against several baselines, including
traditional text-based models and other multimodal methods. Results from
standard Twitter datasets show that AdaptiSent surpasses existing models in
precision, recall, and F1 score, and is particularly effective in identifying
nuanced inter-modal relationships that are crucial for accurate sentiment and
aspect term extraction. This effectiveness comes from the model's ability to
adjust its focus dynamically based on the context's relevance, improving the
depth and accuracy of sentiment analysis across various multimodal data sets.
AdaptiSent sets a new standard for MABSA, significantly outperforming current
methods, especially in understanding complex multimodal information.

</details>


### [6] [AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation](https://arxiv.org/abs/2507.12705)
*Potsawee Manakul,Woody Haosheng Gan,Michael J. Ryan,Ali Sartaz Khan,Warit Sirichotedumrong,Kunat Pipatanakul,William Held,Diyi Yang*

Main category: cs.CL

TL;DR: 本文提出了AudioJudge，一个基于大型音频模型的统一评估框架，用于解决当前语音评估中的两个关键问题。通过不同的提示工程策略，AudioJudge在多个任务中表现出色，并在系统排名基准上与人类偏好具有高相关性。然而，LAM在声学噪声下表现良好，但存在冗长性和位置偏差，需要仔细缓解。


<details>
  <summary>Details</summary>
Motivation: 当前语音评估面临两个关键限制：需要设计针对特定音频特征的专用系统，以及自动评估方法与人类偏好之间的相关性较差。本文旨在提出一种统一的评估框架，以解决这些问题。

Method: 本文系统地研究了AudioJudge，通过不同的提示工程策略，包括音频拼接和上下文学习，提高了性能。还引入了一个多方面集成的AudioJudge，将语音评估分解为专门的评委，分别处理词汇内容、语音质量和副语言特征。

Result: AudioJudge在音频特征检测任务和人类偏好模拟任务中表现出色，特别是在系统排名基准上实现了高达0.91的Spearman相关性。然而，LAM在声学噪声下表现良好，但存在显著的冗长性和位置偏差。

Conclusion: 本文提出了一种基于大型音频模型（LAM）的统一评估框架AudioJudge，能够解决当前语音评估中的两个关键问题。实验结果表明，AudioJudge在多个任务中表现出色，并且在系统排名基准上与人类偏好具有高相关性。然而，LAM在声学噪声下表现良好，但存在显著的冗长性和位置偏差，需要仔细缓解。

Abstract: Current speech evaluation suffers from two critical limitations: the need and
difficulty of designing specialized systems targeting individual audio
characteristics, and poor correlation between automatic evaluation methods and
human preferences. This work presents a systematic study of Large Audio Model
(LAM) as a Judge, AudioJudge, investigating whether it can provide a unified
evaluation framework that addresses both challenges. We systematically explore
AudioJudge across audio characteristic detection tasks, including
pronunciation, speaking rate, speaker identification and speech quality, and
system-level human preference simulation for automated benchmarking. We
investigate different prompt engineering strategies, finding that audio
concatenation combined with in-context learning significantly improves
performance across both audio characteristic detection and human preference
simulation tasks. We further introduce a multi-aspect ensemble AudioJudge to
enable general-purpose multi-aspect audio evaluation. This method decomposes
speech assessment into specialized judges for lexical content, speech quality,
and paralinguistic features, achieving up to 0.91 Spearman correlation with
human preferences on our system ranking benchmark. Robustness analysis reveals
that while LAMs maintain strong performance under acoustic noise, they exhibit
significant verbosity and positional biases that require careful mitigation.

</details>


### [7] [FLEXITOKENS: Flexible Tokenization for Evolving Language Models](https://arxiv.org/abs/2507.12720)
*Abraham Toluase Owodunni,Orevaoghene Ahia,Sachin Kumar*

Main category: cs.CL

TL;DR: 本文提出了一种名为FLEXITOKENS的新方法，用于改进语言模型的分词过程，使其更具适应性，并在多个任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的无分词器方法使用辅助损失来强制在整个训练语料库中保持固定的压缩率，这引入了一种新的刚性。而简单微调语言模型难以适应新的数据分布，因为它们的子词分词器通常在适应过程中保持不变。

Method: 开发了具有可学习分词器的字节级语言模型，其中包含一个模块，该模块学习预测输入字节序列之间的边界，将其编码为可变长度段。提出了一种简化的训练目标FLEXITOKENS，以在适应过程中实现更大的灵活性。

Result: FLEXITOKENS在多个多语言基准测试、形态学多样任务和领域中表现出色，能够显著减少令牌过度分割，并在下游任务性能上相比子词和其他基于梯度的分词器提高了高达10%。

Conclusion: FLEXITOKENS在多个多语言基准测试、形态学多样任务和领域中表现出色，能够显著减少令牌过度分割，并在下游任务性能上相比子词和其他基于梯度的分词器提高了高达10%。

Abstract: Language models (LMs) are challenging to adapt to new data distributions by
simple finetuning. This is due to the rigidity of their subword tokenizers,
which typically remain unchanged during adaptation. This inflexibility often
leads to inefficient tokenization, causing overfragmentation of
out-of-distribution domains, unseen languages, or scripts. In this work, we
develop byte-level LMs with learnable tokenizers to make tokenization adaptive.
Our models include a submodule that learns to predict boundaries between the
input byte sequence, encoding it into variable-length segments. Existing
tokenizer-free methods train this boundary predictor using an auxiliary loss
that enforces a fixed compression rate across the training corpus, introducing
a new kind of rigidity. We propose FLEXITOKENS, a simplified training objective
that enables significantly greater flexibility during adaptation. Evaluating
across multiple multilingual benchmarks, morphologically diverse tasks, and
domains, we demonstrate that FLEXITOKENS consistently reduces token
over-fragmentation and achieves up to 10\% improvements on downstream task
performance compared to subword and other gradient-based tokenizers. Code and
data for our experiments will be released at
https://github.com/owos/flexitokens

</details>


### [8] [TransEvalnia: Reasoning-based Evaluation and Ranking of Translations](https://arxiv.org/abs/2507.12724)
*Richard Sproat,Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: TransEvalnia是一种基于提示的翻译评估和排名系统，能够提供细粒度的评估，并且其结果与人类评分者高度一致。


<details>
  <summary>Details</summary>
Motivation: 现有的翻译评估系统可能无法充分考虑翻译的质量维度，因此需要一种更全面、更准确的评估方法。

Method: TransEvalnia使用推理进行翻译评估和排名，基于Multidimensional Quality Metrics的子集进行细粒度评估，并返回最佳翻译的评估结果和数值分数。

Result: TransEvalnia在英语-日语数据以及多个WMT共享任务的语言对上表现优于或与最先进的MT-Ranker相当。同时，其评估结果得到了人类评分者的高度认可，并且与LLM评分者的结果有良好的相关性。

Conclusion: TransEvalnia是一个有效的翻译评估和排名系统，能够提供细粒度的评估，并且其结果与人类评分者高度一致。此外，该系统对翻译顺序的敏感性得到了解决。

Abstract: We present TransEvalnia, a prompting-based translation evaluation and ranking
system that uses reasoning in performing its evaluations and ranking. This
system presents fine-grained evaluations based on a subset of the
Multidimensional Quality Metrics (https://themqm.org/), returns an assessment
of which translation it deems the best, and provides numerical scores for the
various dimensions and for the overall translation. We show that TransEvalnia
performs as well as or better than the state-of-the-art MT-Ranker (Moosa et al.
2024) on our own English-Japanese data as well as several language pairs from
various WMT shared tasks. Using Anthropic's Claude-3.5-Sonnet and
Qwen-2.5-72B-Instruct as the evaluation LLMs, we show that the evaluations
returned are deemed highly acceptable to human raters, and that the scores
assigned to the translations by Sonnet, as well as other LLMs, correlate well
with scores assigned by the human raters. We also note the sensitivity of our
system -- as well as MT-Ranker -- to the order in which the translations are
presented, and we propose methods to address this position bias. All data,
including the system's evaluation and reasoning, human assessments, as well as
code is released.

</details>


### [9] [Strategy Adaptation in Large Language Model Werewolf Agents](https://arxiv.org/abs/2507.12732)
*Fuya Nakamori,Yin Jou Huang,Fei Cheng*

Main category: cs.CL

TL;DR: 本研究提出了一种基于游戏背景和玩家角色估计的策略切换方法，以提高狼人杀代理人的性能，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 先前的狼人杀代理人研究使用提示工程，采用隐式定义有效策略的方法，但无法适应变化的情况。因此，需要一种能够适应变化情况的策略选择方法。

Method: 本研究提出了一种显式选择适当策略的方法，该方法基于游戏背景和对其他玩家角色的估计。

Result: 与使用隐式或固定策略的基线代理进行比较，验证了策略适应狼人杀代理的有效性。

Conclusion: 本研究提出了一种方法，通过根据其他玩家的态度和对话背景在预定义策略之间切换来提高狼人杀代理人的性能。实验结果验证了所提出方法的有效性。

Abstract: This study proposes a method to improve the performance of Werewolf agents by
switching between predefined strategies based on the attitudes of other players
and the context of conversations. While prior works of Werewolf agents using
prompt engineering have employed methods where effective strategies are
implicitly defined, they cannot adapt to changing situations. In this research,
we propose a method that explicitly selects an appropriate strategy based on
the game context and the estimated roles of other players. We compare the
strategy adaptation Werewolf agents with baseline agents using implicit or
fixed strategies and verify the effectiveness of our proposed method.

</details>


### [10] [Logit Arithmetic Elicits Long Reasoning Capabilities Without Training](https://arxiv.org/abs/2507.12759)
*Yunxiang Zhang,Muhammad Khalifa,Lechen Zhang,Xin Liu,Ayoung Lee,Xinliang Frederick Zhang,Farima Fatahi Bayat,Lu Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为ThinkLogit的方法，用于在不进行额外训练的情况下激发大型语言模型的长期推理能力，并通过ThinkLogit-DPO进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 最近的研究表明，一些模型本质上具有这些长期推理能力，可能通过额外训练来解锁。我们的工作首先调查是否可以在没有任何训练的情况下激发这种行为。

Method: 我们提出了一个解码时间方法，ThinkLogit，利用logits算术来调整目标大语言模型，使用一个较小的模型作为引导者。然后，我们通过在正确/错误推理对上进行偏好优化来进一步提升性能，这被称为ThinkLogit-DPO。

Result: 实验表明，ThinkLogit和ThinkLogit-DPO分别在四个数学数据集上相对于Qwen2.5-32B提高了26%和29%的pass@1。此外，ThinkLogit可以转移通过强化学习获得的长期推理技能，相对于Qwen2.5-32B基础模型提高了13%的pass@1。

Conclusion: 我们的工作提出了一种计算效率高的方法，在无需额外训练的情况下激发大型模型的长期推理能力。

Abstract: Large reasoning models (LRMs) can do complex reasoning via long
chain-of-thought (CoT) involving cognitive strategies such as backtracking and
self-correction. Recent studies suggest that some models inherently possess
these long reasoning abilities, which may be unlocked via extra training. Our
work first investigates whether we can elicit such behavior without any
training. To this end, we propose a decoding-time approach, ThinkLogit, which
utilizes logits arithmetic (Liu et al., 2024) to tune a target large LM for
long reasoning using a substantially smaller model as guider. We then show that
we can further boost performance by training the guider model with preference
optimization over correct/incorrect reasoning pairs sampled from both the
target and guider model -- a setup we refer to as ThinkLogit-DPO. Our
experiments demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative
improvement in pass@1 by 26% and 29%, respectively, over four mathematical
datasets using the Qwen2.5-32B when guided by R1-Distill-Qwen-1.5B -- a model
21x smaller. Lastly, we show that ThinkLogit can transfer long reasoning skills
acquired through reinforcement learning, improving pass@1 by 13% relative
compared to the Qwen2.5-32B base model. Our work presents a
computationally-efficient method to elicit long reasoning in large models with
minimal or no additional training.

</details>


### [11] [Synergy: End-to-end Concept Model](https://arxiv.org/abs/2507.12769)
*Keli Zheng,Zerong Xie*

Main category: cs.CL

TL;DR: 本文介绍了Synergy，这是一种通过学习的路由机制在端到端方式下弥合不同抽象层次的语言模型。


<details>
  <summary>Details</summary>
Motivation: 我们旨在通过一种学习的路由机制，在端到端的方式下弥合不同抽象层次。

Method: 我们训练了一个字节级的语言模型，并通过学习的路由机制在端到端方式下弥合不同抽象层次。

Result: 我们的模型自发地学习对字节进行分词，产生的概念标记比Byte-level Byte Pair Encoder (BBPE)分词器更少，同时保持了相当的性能。与Llama3相比，在相同的模型规模和训练数据集大小下，Synergy表现出优势。进一步的研究表明，当移除位置编码时，模型的中间部分（更高抽象部分）表现更好，这表明出现了与位置无关的概念。

Conclusion: 这些发现证明了无需分词器的架构的可行性，为更稳健和灵活的流程铺平了道路。

Abstract: In this paper, we present Synergy, a language model that bridges different
levels of abstraction in an end-to-end fashion through a learned routing
mechanism. Focusing on low-level linguistic abstraction, we trained our model
as a byte-level language model. Our model spontaneously learns to tokenize
bytes, producing fewer concept tokens than Byte-level Byte Pair Encoder (BBPE)
tokenizers while keeping comparable performance. By comparing with Llama3, we
observed an advantage of Synergy under the same model scale and training
dataset size. Further studies show that the middle part (the higher abstraction
part) of our model performs better when positional encodings are removed,
suggesting the emergence of position-independent concepts. These findings
demonstrate the feasibility of tokenizer-free architectures, paving the way for
more robust and flexible pipelines.

</details>


### [12] [Learning Robust Negation Text Representations](https://arxiv.org/abs/2507.12782)
*Thinh Hung Truong,Karin Verspoor,Trevor Cohn,Timothy Baldwin*

Main category: cs.CL

TL;DR: 本文提出了一种通过从大型语言模型中蒸馏数据来提高文本编码器否定鲁棒性的方法，并展示了该方法在保持性能的同时显著提升了否定理解能力，同时也可以适应大型语言模型以提高否定基准的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管自回归大型语言模型被迅速采用，但较小的文本编码器在需要丰富上下文表示的文本理解任务中仍然发挥着重要作用。否定是一个重要的语义功能，目前仍未被这些方法正确捕捉，影响了许多依赖文本嵌入的下游应用。

Method: 我们提出了一种策略，通过使用多样化的否定和犹豫模式从大型语言模型中蒸馏数据，以提高文本编码器的否定鲁棒性。我们采用标准的对比学习策略来微调一个基于BERT的强模型。

Result: 我们观察到在保持一般基准竞争性能的同时，否定理解能力有显著提升。此外，我们的方法还可以适应大型语言模型，从而在否定基准上取得更好的表现。

Conclusion: 我们的方法可以提升文本编码器对否定的理解能力，并且可以在大型语言模型上进行适应，从而提高否定基准的表现。

Abstract: Despite rapid adoption of autoregressive large language models, smaller text
encoders still play an important role in text understanding tasks that require
rich contextualized representations. Negation is an important semantic function
that is still not properly captured by such methods, affecting many downstream
applications relying on text embeddings. We propose a strategy to improve
negation robustness of text encoders, by distilling data from large language
models using diverse patterns of negation and hedging. We adopt a standard
contrastive learning strategy to finetune a strong BERT-based model, and
observe large improvement in negation understanding capabilities while
maintaining competitive performance on general benchmarks. In addition, we also
show that our method can be adapted to LLMs, leading to improved performance on
negation benchmarks.

</details>


### [13] [Large Language Models' Internal Perception of Symbolic Music](https://arxiv.org/abs/2507.12808)
*Andrew Shin,Kunitake Kaneko*

Main category: cs.CL

TL;DR: This paper explores how large language models (LLMs) represent musical concepts by generating symbolic music data from textual prompts and evaluating their utility through recognition and generation tasks.


<details>
  <summary>Details</summary>
Motivation: To investigate how LLMs represent musical concepts and explore their potential for generating symbolic music.

Method: We generate symbolic music data from textual prompts describing combinations of genres and styles, and evaluate their utility through recognition and generation tasks. We produce a dataset of LLM-generated MIDI files without relying on explicit musical training, then train neural networks on this dataset for genre and style classification as well as melody completion.

Result: Our results demonstrate that LLMs can infer rudimentary musical structures and temporal relationships from text, but they also highlight limitations due to a lack of explicit musical context.

Conclusion: LLMs can infer rudimentary musical structures and temporal relationships from text, highlighting their potential to implicitly encode musical patterns and their limitations due to a lack of explicit musical context.

Abstract: Large language models (LLMs) excel at modeling relationships between strings
in natural language and have shown promise in extending to other symbolic
domains like coding or mathematics. However, the extent to which they
implicitly model symbolic music remains underexplored. This paper investigates
how LLMs represent musical concepts by generating symbolic music data from
textual prompts describing combinations of genres and styles, and evaluating
their utility through recognition and generation tasks. We produce a dataset of
LLM-generated MIDI files without relying on explicit musical training. We then
train neural networks entirely on this LLM-generated MIDI dataset and perform
genre and style classification as well as melody completion, benchmarking their
performance against established models. Our results demonstrate that LLMs can
infer rudimentary musical structures and temporal relationships from text,
highlighting both their potential to implicitly encode musical patterns and
their limitations due to a lack of explicit musical context, shedding light on
their generative capabilities for symbolic music.

</details>


### [14] [Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?](https://arxiv.org/abs/2507.12838)
*Xi Ai,Mahardika Krisna Ihsani,Min-Yen Kan*

Main category: cs.CL

TL;DR: 本文研究了多语言模型的跨语言一致性，发现代码切换训练和跨语言词对齐目标在提高多语言性能和跨语言一致性方面效果最佳。


<details>
  <summary>Details</summary>
Motivation: 本文旨在分析、评估和解释事实知识的跨语言一致性，以评估跨语言迁移能力，保持模型知识的真实性，并保持语言模型性能的平衡。

Method: 本文使用了一些可解释性方法来分析模型在跨语言环境中的行为，研究了代码混合的指代性陈述以探讨跨语言知识的一致性。

Result: 研究发现，多语言模型在跨语言一致性方面表现出不同的水平，受语言家族、语言因素以及特定层上的跨语言一致性瓶颈的影响。此外，评估了旨在提高多语言性能的常见策略，观察这些策略是否能同时提高知识一致性。

Conclusion: 本文得出结论，代码切换训练和跨语言词对齐目标在提高多语言性能和跨语言一致性方面表现出最令人瞩目的结果，强调了跨语言对齐监督和代码切换训练的重要性。

Abstract: Cross-lingual consistency should be considered to assess cross-lingual
transferability, maintain the factuality of the model knowledge across
languages, and preserve the parity of language model performance. We are thus
interested in analyzing, evaluating, and interpreting cross-lingual consistency
for factual knowledge. We examine code-mixed coreferential statements conveyed
identical knowledge across languages to study cross-lingual knowledge
consistency. We use some interpretability approaches to analyze the behavior of
a model in cross-lingual contexts, discovering that multilingual models show
different levels of consistency, subject to language families, linguistic
factors, and a bottleneck in cross-lingual consistency on a particular layer.
In addition, we evaluate common strategies aimed at improving multilingual
performance to observe whether these strategies can improve knowledge
consistency at the same time. While knowledge is not cross-lingual consistency
in many cases, code-switching training and cross-lingual word alignment
objectives show the most promising results, emphasizing the noteworthiness of
cross-lingual alignment supervision and code-switching training for both
multilingual performance and cross-lingual consistency enhancement.

</details>


### [15] [Making Language Model a Hierarchical Classifier and Generator](https://arxiv.org/abs/2507.12930)
*Yihong Wang,Zhonglin Jiang,Ningyuan Xi,Yue Zhao,Qingqing Gu,Xiyuan Chen,Hao Wu,Sheng Xu,Hange Zhou,Yong Chen,Luo Ji*

Main category: cs.CL

TL;DR: 本研究提出了一种层次解码器架构，通过将语言头复制到不同的中间层并进行微调，实现了在多个任务上的先进性能。


<details>
  <summary>Details</summary>
Motivation: 受人类层次思维能力的启发，我们提出可以构建一个层次解码器架构，其中不同层同时解码文本。

Method: 我们将最后一个层的语言头复制到不同的选定中间层，并用不同的任务输入进行微调，以构建层次解码器架构。

Result: 实验结果表明，这些选择的中间层可以适应生成有意义和合理的文本，并且这种层次解码器范式在多个任务上取得了最先进的性能。

Conclusion: 本研究表明，层次解码器范式可以在多个任务上获得最先进的性能，并提出了一个通用层次推理器的可能性，可以从头开始预训练。

Abstract: Decoder-only language models, such as GPT and LLaMA, generally decode on the
last layer. Motivated by human's hierarchical thinking capability, we propose
that a hierarchical decoder architecture could be built with different layers
decoding texts simultaneously. Due to limited time and computationally
resources, we choose to adapt a pretrained language model into this form of
hierarchical decoder. Language heads of the last layer are copied to different
selected intermediate layers, and fine-tuned with different task inputs. By
thorough experiments, we validate that these selective intermediate layers
could be adapted to speak meaningful and reasonable contents, and this paradigm
of hierarchical decoder can obtain state-of-the-art performances on multiple
tasks such as hierarchical text classification, classification-guided
generation, and hierarchical text generation. This study suggests the
possibility of a generalized hierarchical reasoner, pretraining from scratch.

</details>


### [16] [MRT at IberLEF-2025 PRESTA Task: Maximizing Recovery from Tables with Multiple Steps](https://arxiv.org/abs/2507.12981)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Héctor Cerezo-Costas,Pedro Alonso Doval,Jorge Alcalde Vesteiro*

Main category: cs.CL

TL;DR: 本文介绍了针对IberLEF 2025任务PRESTA的解决方案，利用LLM生成Python代码来过滤和处理表格数据，最终实现了85%的准确率。


<details>
  <summary>Details</summary>
Motivation: 为了应对IberLEF 2025任务PRESTA：关于西班牙语表格的问题和答案，我们开发了这一解决方案。

Method: 通过实现Python代码生成与LLM结合，用于过滤和处理表格中的数据。

Result: 该方法在任务中实现了85%的准确率。

Conclusion: 通过这种方法，我们在任务中取得了85%的准确率。

Abstract: This paper presents our approach for the IberLEF 2025 Task PRESTA: Preguntas
y Respuestas sobre Tablas en Espa\~nol (Questions and Answers about Tables in
Spanish). Our solution obtains answers to the questions by implementing Python
code generation with LLMs that is used to filter and process the table. This
solution evolves from the MRT implementation for the Semeval 2025 related task.
The process consists of multiple steps: analyzing and understanding the content
of the table, selecting the useful columns, generating instructions in natural
language, translating these instructions to code, running it, and handling
potential errors or exceptions. These steps use open-source LLMs and
fine-grained optimized prompts for each step. With this approach, we achieved
an accuracy score of 85\% in the task.

</details>


### [17] [Formalizing Attack Scenario Description: A Proposed Model](https://arxiv.org/abs/2507.13076)
*Quentin Goux,Nadira Lammari*

Main category: cs.CL

TL;DR: 本文提出了一种基于UML类模型的形式化模型，用于描述攻击的上下文和场景，并展示了其在攻击分析和自动攻击脚本生成中的应用。


<details>
  <summary>Details</summary>
Motivation: 组织面临不断变化的威胁环境，需要持续努力保护资产，因此采用更多的网络安全自动化是不可避免的。然而，流程自动化需要输入数据的正式化。本文旨在解决使用攻击场景作为输入的过程的需求。

Method: 本文提出了一个基于UML类模型的形式化模型，用于描述攻击的上下文和场景。

Result: 本文展示了所提出的模型如何用于上游攻击分析过程以及在网络安全培训中自动生成攻击脚本。

Conclusion: 本文的主要研究贡献是一个新的形式化模型，涵盖了攻击的上下文描述和其场景，并通过UML类模型进行抽象。该模型可以用于上游攻击分析过程以及自动攻击脚本生成，以支持网络安全培训。

Abstract: Organizations face an ever-changing threat landscape. They must continuously
dedicate significant efforts to protect their assets, making their adoption of
increased cybersecurity automation inevitable. However, process automation
requires formalization of input data. Through this paper, we address this need
for processes that use attack scenarios as input. Among these processes, one
can mention both the generation of scripts for attack simulation and training
purposes, as well as the analysis of attacks. Therefore, the paper's main
research contribution is a novel formal model that encompasses the attack's
context description and its scenario. It is abstracted using UML class model.
Once the description of our model done, we will show how it could serve an
upstream attack analysis process. We will show also its use for an automatic
generation of attack scripts in the context of cybersecurity training. These
two uses cases constitute the second contribution of this present research
work.

</details>


### [18] [SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts](https://arxiv.org/abs/2507.13105)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

TL;DR: SemCSE is an unsupervised method for learning semantic embeddings of scientific texts that outperforms traditional citation-based approaches.


<details>
  <summary>Details</summary>
Motivation: Traditional citation-based approaches do not necessarily reflect semantic similarity, so there is a need for a method that captures the true semantic content of a text.

Method: SemCSE is an unsupervised method that leverages LLM-generated summaries of scientific abstracts to train a model that positions semantically related summaries closer together in the embedding space.

Result: SemCSE demonstrates a stronger semantic separation within the embedding space and achieves state-of-the-art performance on the SciRepEval benchmark.

Conclusion: SemCSE achieves state-of-the-art performance on the SciRepEval benchmark, highlighting the benefits of a semantically focused training approach.

Abstract: We introduce SemCSE, an unsupervised method for learning semantic embeddings
of scientific texts. Building on recent advances in contrastive learning for
text embeddings, our approach leverages LLM-generated summaries of scientific
abstracts to train a model that positions semantically related summaries closer
together in the embedding space. This resulting objective ensures that the
model captures the true semantic content of a text, in contrast to traditional
citation-based approaches that do not necessarily reflect semantic similarity.
To validate this, we propose a novel benchmark designed to assess a model's
ability to understand and encode the semantic content of scientific texts,
demonstrating that our method enforces a stronger semantic separation within
the embedding space. Additionally, we evaluate SemCSE on the comprehensive
SciRepEval benchmark for scientific text embeddings, where it achieves
state-of-the-art performance among models of its size, thus highlighting the
benefits of a semantically focused training approach.

</details>


### [19] [A Computational Framework to Identify Self-Aspects in Text](https://arxiv.org/abs/2507.13115)
*Jaya Caporusso,Matthew Purver,Senja Pollak*

Main category: cs.CL

TL;DR: 该论文提案计划开发一个计算框架，用于识别文本中的自我方面，并通过案例研究验证其在心理健康和经验现象学中的应用。


<details>
  <summary>Details</summary>
Motivation: 自我是一个多方面的概念，在语言中有所体现，但在自然语言处理（NLP）中尚未得到充分研究。许多自我方面与心理健康的其他已深入研究的现象相吻合，因此需要系统性的NLP分析。

Method: 提出自我方面的本体论和金标准注释数据集，并开发和评估传统判别模型、生成式大语言模型和基于嵌入的检索方法。

Result: 将根据可解释性、真实数据一致性、准确性和计算效率四个主要标准评估模型，并将表现最佳的模型应用于心理健康和经验现象学的案例研究。

Conclusion: 该论文提案旨在开发一个计算框架，以识别文本中的自我方面，并通过案例研究在心理健康和经验现象学中应用表现最佳的模型。

Abstract: This Ph.D. proposal introduces a plan to develop a computational framework to
identify Self-aspects in text. The Self is a multifaceted construct and it is
reflected in language. While it is described across disciplines like cognitive
science and phenomenology, it remains underexplored in natural language
processing (NLP). Many of the aspects of the Self align with psychological and
other well-researched phenomena (e.g., those related to mental health),
highlighting the need for systematic NLP-based analysis. In line with this, we
plan to introduce an ontology of Self-aspects and a gold-standard annotated
dataset. Using this foundation, we will develop and evaluate conventional
discriminative models, generative large language models, and embedding-based
retrieval approaches against four main criteria: interpretability, ground-truth
adherence, accuracy, and computational efficiency. Top-performing models will
be applied in case studies in mental health and empirical phenomenology.

</details>


### [20] [Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation](https://arxiv.org/abs/2507.13138)
*Hadi Mohammadi,Tina Shahedi,Pablo Mosteiro,Massimo Poesio,Ayoub Bagheri,Anastasia Giachanou*

Main category: cs.CL

TL;DR: 本研究探讨了标注者人口统计特征对标注决策的影响，并评估了生成式AI模型作为标注者的可靠性。结果表明，内容是主要因素，而基于角色的提示效果不佳。


<details>
  <summary>Details</summary>
Motivation: 理解注释中的变异来源对于开发公平的自然语言处理系统至关重要，尤其是在像性别歧视检测这样的任务中，存在人口统计偏差的问题。

Method: 本文使用广义线性混合模型来量化标注者人口统计特征对标注决策的影响，并评估生成式AI（GenAI）模型作为标注者的可靠性，同时探讨了通过人口统计学角色提示是否能提高与人类判断的一致性。

Result: 研究发现，虽然统计上存在影响，但人口统计因素仅占观察到的方差的8%，而推文内容是主要因素。此外，简单的角色提示通常无法提高性能，有时甚至会降低性能。解释性AI技术显示，模型预测主要依赖于与性别歧视相关的特定内容标记，而不是人口统计特征的相关因素。

Conclusion: 本文认为，关注内容驱动的解释和稳健的注释协议比潜在的人格模拟更能可靠地实现公平性。

Abstract: Understanding the sources of variability in annotations is crucial for
developing fair NLP systems, especially for tasks like sexism detection where
demographic bias is a concern. This study investigates the extent to which
annotator demographic features influence labeling decisions compared to text
content. Using a Generalized Linear Mixed Model, we quantify this inf luence,
finding that while statistically present, demographic factors account for a
minor fraction ( 8%) of the observed variance, with tweet content being the
dominant factor. We then assess the reliability of Generative AI (GenAI) models
as annotators, specifically evaluating if guiding them with demographic
personas improves alignment with human judgments. Our results indicate that
simplistic persona prompting often fails to enhance, and sometimes degrades,
performance compared to baseline models. Furthermore, explainable AI (XAI)
techniques reveal that model predictions rely heavily on content-specific
tokens related to sexism, rather than correlates of demographic
characteristics. We argue that focusing on content-driven explanations and
robust annotation protocols offers a more reliable path towards fairness than
potentially persona simulation.

</details>


### [21] [Feature-based analysis of oral narratives from Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13164)
*Emma Sharratt,Annelien Smith,Retief Louw,Daleen Klop,Febe de Wet,Herman Kamper*

Main category: cs.CL

TL;DR: 该研究分析了四岁和五岁南非语和科萨语儿童的口头叙述，发现词汇多样性和话语长度是典型发展的指标，而特定动词和助动词的使用与较少需要干预的可能性相关。


<details>
  <summary>Details</summary>
Motivation: 研究目的是确定需要干预的儿童的口头叙述特征，并探索语言特定和共享的预测因素，以支持多语言环境中的早期评估。

Method: 使用简单的机器学习方法分析四岁和五岁南非语和科萨语儿童的录音故事。

Result: 词汇多样性（独特单词）和基于长度的特征（平均话语长度）是典型发展的指标，而发音率等特征则不太有用。特定动词和助动词的使用与较少需要干预的可能性相关。

Conclusion: 我们的分析揭示了语言特定和共享的叙事能力预测因素，这对多语言环境中的早期评估具有重要意义。

Abstract: Oral narrative skills are strong predictors of later literacy development.
This study examines the features of oral narratives from children who were
identified by experts as requiring intervention. Using simple machine learning
methods, we analyse recorded stories from four- and five-year-old Afrikaans-
and isiXhosa-speaking children. Consistent with prior research, we identify
lexical diversity (unique words) and length-based features (mean utterance
length) as indicators of typical development, but features like articulation
rate prove less informative. Despite cross-linguistic variation in
part-of-speech patterns, the use of specific verbs and auxiliaries associated
with goal-directed storytelling is correlated with a reduced likelihood of
requiring intervention. Our analysis of two linguistically distinct languages
reveals both language-specific and shared predictors of narrative proficiency,
with implications for early assessment in multilingual contexts.

</details>


### [22] [GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems](https://arxiv.org/abs/2507.13190)
*Jisoo Lee,Raeyoung Chang,Dongwook Kwon,Harmanpreet Singh,Nikhil Verma*

Main category: cs.CL

TL;DR: 本文介绍了GEMMAS，一种基于图的评估框架，用于分析多智能体系统的内部协作过程。通过提出信息多样性得分和不必要的路径比率两个过程级指标，研究发现仅依赖最终输出的指标不足以评估多智能体系统的性能，并强调了过程级诊断的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的评估只关注最终输出的正确性，而忽略了低效通信和不良协调导致的冗余推理和更高的计算成本。

Method: 引入GEMMAS，一种基于图的评估框架，通过将代理交互建模为有向无环图来分析内部协作过程。提出两个过程级指标：信息多样性得分（IDS）和不必要的路径比率（UPR）。

Result: 在五个基准测试中评估GEMMAS，并在GSM8K上突出结果显示，准确率仅有2.1%差异的系统在IDS上相差12.8%，在UPR上相差80%，揭示了内部协作的显著差异。

Conclusion: 结果表明，仅依赖最终输出的指标不足以评估多智能体系统的性能，并强调了过程级诊断在设计更可解释和资源高效的协作人工智能系统中的重要性。

Abstract: Multi-agent systems built on language models have shown strong performance on
collaborative reasoning tasks. However, existing evaluations focus only on the
correctness of the final output, overlooking how inefficient communication and
poor coordination contribute to redundant reasoning and higher computational
costs. We introduce GEMMAS, a graph-based evaluation framework that analyzes
the internal collaboration process by modeling agent interactions as a directed
acyclic graph. To capture collaboration quality, we propose two process-level
metrics: Information Diversity Score (IDS) to measure semantic variation in
inter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant
reasoning paths. We evaluate GEMMAS across five benchmarks and highlight
results on GSM8K, where systems with only a 2.1% difference in accuracy differ
by 12.8% in IDS and 80% in UPR, revealing substantial variation in internal
collaboration. These findings demonstrate that outcome-only metrics are
insufficient for evaluating multi-agent performance and highlight the
importance of process-level diagnostics in designing more interpretable and
resource-efficient collaborative AI systems.

</details>


### [23] [Automatically assessing oral narratives of Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13205)
*R. Louw,E. Sharratt,F. de Wet,C. Jacobs,A. Smith,H. Kamper*

Main category: cs.CL

TL;DR: 本文提出了一种自动评估幼儿口语叙述的系统，该系统使用自动语音识别和机器学习评分模型，结果表明基于大语言模型的系统表现优于线性模型，并且在标记需要干预的儿童方面与人类专家相当。


<details>
  <summary>Details</summary>
Motivation: 在大型幼儿园班级中，教师难以准确识别需要干预的学生，因此需要一种自动评估系统来帮助他们。

Method: 我们提出了一个系统，可以自动评估南非语和科萨语的幼儿口语叙述，该系统使用自动语音识别，然后使用机器学习评分模型来预测叙述和理解分数。

Result: 基于大语言模型的系统在大多数情况下优于线性模型，但尽管其简单性，线性系统仍具有竞争力。基于大语言模型的系统在标记需要干预的儿童方面与人类专家相当。

Conclusion: 我们为课堂中的自动口语评估奠定了基础，使教师能够额外关注儿童学习的个性化支持。

Abstract: Developing narrative and comprehension skills in early childhood is critical
for later literacy. However, teachers in large preschool classrooms struggle to
accurately identify students who require intervention. We present a system for
automatically assessing oral narratives of preschool children in Afrikaans and
isiXhosa. The system uses automatic speech recognition followed by a machine
learning scoring model to predict narrative and comprehension scores. For
scoring predicted transcripts, we compare a linear model to a large language
model (LLM). The LLM-based system outperforms the linear model in most cases,
but the linear system is competitive despite its simplicity. The LLM-based
system is comparable to a human expert in flagging children who require
intervention. We lay the foundation for automatic oral assessments in
classrooms, giving teachers extra capacity to focus on personalised support for
children's learning.

</details>


### [24] [Enhancing Cross-task Transfer of Large Language Models via Activation Steering](https://arxiv.org/abs/2507.13236)
*Xinyu Tang,Zhihao Lv,Xiaoxue Cheng,Junyi Li,Wayne Xin Zhao,Zujie Wen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种名为CAST的新方法，通过操纵模型的内部激活状态实现跨任务传输，无需参数更新或输入扩展。实验表明，该方法在跨领域和跨语言转移设置中表现优异，具有更好的可扩展性和更低的计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在通过提示利用预训练知识方面表现出色，但在处理未见过的任务时，尤其是在数据稀缺的情况下，常常遇到困难。虽然跨任务上下文学习提供了一种直接的解决方案，但仍然面临鲁棒性、可扩展性和效率方面的关键挑战。

Method: 我们提出了CAST，一种新颖的跨任务激活引导传输框架，通过操纵模型的内部激活状态来实现有效的传输。首先从高资源任务中选择有影响力和多样化的样本，然后利用其对比表示增强的激活来适应低资源任务。

Result: 通过分析LLMs潜在空间中的激活模式，我们观察到由上下文示例引起的增强激活在不同任务中具有一致的模式。基于这些发现，我们提出了CAST，该框架能够通过操纵模型的内部激活状态实现有效的跨任务传输。

Conclusion: 我们的方法在跨领域和跨语言转移设置中表现出色，优于竞争基线，并展示了更好的可扩展性和更低的计算成本。

Abstract: Large language models (LLMs) have shown impressive abilities in leveraging
pretrained knowledge through prompting, but they often struggle with unseen
tasks, particularly in data-scarce scenarios. While cross-task in-context
learning offers a direct solution for transferring knowledge across tasks, it
still faces critical challenges in terms of robustness, scalability, and
efficiency. In this paper, we investigate whether cross-task transfer can be
achieved via latent space steering without parameter updates or input
expansion. Through an analysis of activation patterns in the latent space of
LLMs, we observe that the enhanced activations induced by in-context examples
have consistent patterns across different tasks. Inspired by these findings, we
propose CAST, a novel Cross-task Activation Steering Transfer framework that
enables effective transfer by manipulating the model's internal activation
states. Our approach first selects influential and diverse samples from
high-resource tasks, then utilizes their contrastive representation-enhanced
activations to adapt LLMs to low-resource tasks. Extensive experiments across
both cross-domain and cross-lingual transfer settings show that our method
outperforms competitive baselines and demonstrates superior scalability and
lower computational costs.

</details>


### [25] [HATS: Hindi Analogy Test Set for Evaluating Reasoning in Large Language Models](https://arxiv.org/abs/2507.13238)
*Ashray Gupta,Rohan Joseph,Sunny Rai*

Main category: cs.CL

TL;DR: 本文介绍了一个新的印地语类比测试集（HATS），并提出了一种基于认知理论的链式思维方法，以提高模型在印地语类比问题上的性能。实验表明，模型在英语提示下的表现最佳。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型在印地语中的能力研究不足，限制了我们对其跨语言泛化能力的理解，因此需要一个新的测试集来评估它们的推理能力。

Method: 我们引入了一个新的印地语类比测试集（HATS），并使用各种提示策略对最先进的多语言LLM进行了基准测试，还提出了一种基于认知理论的类比推理的链式思维方法。

Result: 实验表明，无论采用何种提示策略，模型在英语提示下的表现最佳。基于认知理论的链式思维方法提高了模型在印地语类比问题上的性能。

Conclusion: 我们的测试集解决了缺乏评估大型语言模型在印地语中推理能力的关键资源的问题。

Abstract: Analogies test a model's ability to infer implicit relationships between
concepts, making them a key benchmark for evaluating reasoning capabilities.
While large language models (LLMs) are widely evaluated for reasoning in
English, their abilities in Indic languages remain understudied, limiting our
understanding of whether these models generalize across languages. To address
this gap, we introduce a new Hindi Analogy Test Set (HATS), comprising 405
multiple-choice questions sourced from Indian government exams. We benchmark
state-of-the-art multilingual LLMs using various prompting strategies and
introduce a grounded Chain of Thought approach that leverages cognitive
theories of analogical reasoning. This approach improves model performance on
Hindi analogy questions. Our experiments show that models perform best with
English prompts, irrespective of the prompting strategy. Our test set addresses
the lack of a critical resource to evaluate LLM reasoning capabilities in
Hindi.

</details>


### [26] [Automating Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2507.13255)
*Lyucheng Wu,Mengru Wang,Ziwen Xu,Tri Cao,Nay Oo,Bryan Hooi,Shumin Deng*

Main category: cs.CL

TL;DR: AutoSteer是一种无需微调模型的自适应推理时干预技术，能够有效降低多模态大语言模型在面对对抗性输入时的安全风险。


<details>
  <summary>Details</summary>
Motivation: 为了提高多模态大语言模型（MLLMs）在推理过程中的安全性，特别是在面对对抗性多模态输入时，需要一种无需对底层模型进行微调的技术。

Method: AutoSteer引入了一种模块化和自适应的推理时干预技术，包含三个核心组件：(1) 一种新的安全意识评分(SAS)，用于自动识别模型内部层中最相关的安全区别；(2) 一个自适应的安全探测器，用于估计从中间表示中产生有害输出的可能性；(3) 一个轻量级的拒绝头，用于在检测到安全风险时选择性地干预以调节生成。

Result: 在LLaVA-OV和Chameleon上进行的实验表明，AutoSteer显著降低了文本、视觉和跨模态威胁的攻击成功率（ASR），同时保持了通用能力。

Conclusion: AutoSteer作为一种实用、可解释且有效的框架，为多模态AI系统的安全部署提供了支持。

Abstract: Recent progress in Multimodal Large Language Models (MLLMs) has unlocked
powerful cross-modal reasoning abilities, but also raised new safety concerns,
particularly when faced with adversarial multimodal inputs. To improve the
safety of MLLMs during inference, we introduce a modular and adaptive
inference-time intervention technology, AutoSteer, without requiring any
fine-tuning of the underlying model. AutoSteer incorporates three core
components: (1) a novel Safety Awareness Score (SAS) that automatically
identifies the most safety-relevant distinctions among the model's internal
layers; (2) an adaptive safety prober trained to estimate the likelihood of
toxic outputs from intermediate representations; and (3) a lightweight Refusal
Head that selectively intervenes to modulate generation when safety risks are
detected. Experiments on LLaVA-OV and Chameleon across diverse safety-critical
benchmarks demonstrate that AutoSteer significantly reduces the Attack Success
Rate (ASR) for textual, visual, and cross-modal threats, while maintaining
general abilities. These findings position AutoSteer as a practical,
interpretable, and effective framework for safer deployment of multimodal AI
systems.

</details>


### [27] [QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation](https://arxiv.org/abs/2507.13266)
*Jiazheng Li,Hong Lu,Kaiyue Wen,Zaiwen Yang,Jiaxuan Gao,Hongzhou Lin,Yi Wu,Jingzhao Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为QuestA的强化学习策略，通过引入部分解决方案来提升模型在数学推理任务中的表现，并在多个基准测试中取得了新的最先进结果。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在处理复杂问题时效果有限，尤其是在多步骤推理任务中。因此，需要一种更有效的策略来提升模型的推理能力。

Method: QuestA方法通过在训练过程中引入部分解决方案来降低问题难度并提供更有信息量的学习信号，从而改进强化学习在多步骤推理中的效果。

Result: QuestA方法在数学推理任务中不仅提高了pass@1指标，还提高了pass@k指标，特别是在标准强化学习难以取得进展的问题上。在1.5B参数模型上，QuestA在AIME24、AIME25和HMMT25基准测试中分别达到了67.1%、59.5%和35.5%的准确率。

Conclusion: QuestA方法在数学推理任务中显著提升了模型的性能，并在多个基准测试中取得了新的最先进结果。此外，QuestA通过提高样本效率，为通过强化学习扩展推理能力提供了一种实用且可推广的路径。

Abstract: Reinforcement learning (RL) has become a key component in training large
language reasoning models (LLMs). However, recent studies questions its
effectiveness in improving multi-step reasoning-particularly on hard problems.
To address this challenge, we propose a simple yet effective strategy via
Question Augmentation: introduce partial solutions during training to reduce
problem difficulty and provide more informative learning signals. Our method,
QuestA, when applied during RL training on math reasoning tasks, not only
improves pass@1 but also pass@k-particularly on problems where standard RL
struggles to make progress. This enables continual improvement over strong
open-source models such as DeepScaleR and OpenMath Nemotron, further enhancing
their reasoning capabilities. We achieve new state-of-the-art results on math
benchmarks using 1.5B-parameter models: 67.1% (+5.3%) on AIME24, 59.5% (+10.0%)
on AIME25, and 35.5% (+4.0%) on HMMT25. Further, we provide theoretical
explanations that QuestA improves sample efficiency, offering a practical and
generalizable pathway for expanding reasoning capability through RL.

</details>


### [28] [Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management](https://arxiv.org/abs/2507.13275)
*Luis Gasco,Hermenegildo Fabregat,Laura García-Sardiña,Paula Estrella,Daniel Deniz,Alvaro Rodrigo,Rabih Zbib*

Main category: cs.CL

TL;DR: The paper introduces TalentCLEF 2025, the first public benchmark for skill and job title intelligence in Human Capital Management, highlighting the importance of reliable and fair language technologies.


<details>
  <summary>Details</summary>
Motivation: The adoption and progress of language technologies in Human Capital Management depend on reliable and fair models evaluated on public data, which have been unavailable in this domain.

Method: The paper presents TalentCLEF 2025, the first evaluation campaign focused on skill and job title intelligence, consisting of two tasks: Task A - Multilingual Job Title Matching and Task B - Job Title-Based Skill Prediction. The corpora were built from real job applications and manually annotated.

Result: TalentCLEF attracted 76 registered teams with more than 280 submissions. Most systems relied on multilingual encoder-based models fine-tuned with contrastive learning, and several incorporated large language models for data augmentation or re-ranking. The results show that training strategies have a larger effect than model size alone.

Conclusion: TalentCLEF provides the first public benchmark in this field and encourages the development of robust, fair, and transferable language technologies for the labor market.

Abstract: Advances in natural language processing and large language models are driving
a major transformation in Human Capital Management, with a growing interest in
building smart systems based on language technologies for talent acquisition,
upskilling strategies, and workforce planning. However, the adoption and
progress of these technologies critically depend on the development of reliable
and fair models, properly evaluated on public data and open benchmarks, which
have so far been unavailable in this domain.
  To address this gap, we present TalentCLEF 2025, the first evaluation
campaign focused on skill and job title intelligence. The lab consists of two
tasks: Task A - Multilingual Job Title Matching, covering English, Spanish,
German, and Chinese; and Task B - Job Title-Based Skill Prediction, in English.
Both corpora were built from real job applications, carefully anonymized, and
manually annotated to reflect the complexity and diversity of real-world labor
market data, including linguistic variability and gender-marked expressions.
  The evaluations included monolingual and cross-lingual scenarios and covered
the evaluation of gender bias.
  TalentCLEF attracted 76 registered teams with more than 280 submissions. Most
systems relied on information retrieval techniques built with multilingual
encoder-based models fine-tuned with contrastive learning, and several of them
incorporated large language models for data augmentation or re-ranking. The
results show that the training strategies have a larger effect than the size of
the model alone. TalentCLEF provides the first public benchmark in this field
and encourages the development of robust, fair, and transferable language
technologies for the labor market.

</details>


### [29] [Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis](https://arxiv.org/abs/2507.13285)
*Wang Xi,Quan Shi,Tian Yu,Yujie Peng,Jiayi Sun,Mengxing Ren,Zenghui Ding,Ningguang Yao*

Main category: cs.CL

TL;DR: 本文提出了一种新的框架RCPS，用于生成高质量的媒体演示文稿，并引入了PREVAL评估框架，以更准确地评估演示文稿的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的方法常常产生逻辑不一致和布局不佳的演示文稿，难以满足专业标准。因此，需要一种新的框架来解决这些问题。

Method: RCPS（反思连贯演示合成）框架，包括三个关键组件：(1) 深度结构化叙事规划；(2) 自适应布局生成；(3) 迭代优化循环。此外，还提出了PREVAL，一种基于偏好的评估框架，采用增强理由的多维模型来评估演示文稿的质量。

Result: 实验结果表明，RCPS在所有质量维度上均显著优于基线方法，生成的演示文稿接近人类专家标准。PREVAL与人类判断有很强的相关性，验证了其作为评估演示文稿质量的可靠自动化工具的有效性。

Conclusion: RCPS显著优于基线方法，在所有质量维度上都表现出色，生成的演示文稿接近人类专家标准。PREVAL与人类判断有很强的相关性，验证了其作为评估演示文稿质量的可靠自动化工具的有效性。

Abstract: Automated generation of high-quality media presentations is challenging,
requiring robust content extraction, narrative planning, visual design, and
overall quality optimization. Existing methods often produce presentations with
logical inconsistencies and suboptimal layouts, thereby struggling to meet
professional standards. To address these challenges, we introduce RCPS
(Reflective Coherent Presentation Synthesis), a novel framework integrating
three key components: (1) Deep Structured Narrative Planning; (2) Adaptive
Layout Generation; (3) an Iterative Optimization Loop. Additionally, we propose
PREVAL, a preference-based evaluation framework employing rationale-enhanced
multi-dimensional models to assess presentation quality across Content,
Coherence, and Design. Experimental results demonstrate that RCPS significantly
outperforms baseline methods across all quality dimensions, producing
presentations that closely approximate human expert standards. PREVAL shows
strong correlation with human judgments, validating it as a reliable automated
tool for assessing presentation quality.

</details>


### [30] [AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research](https://arxiv.org/abs/2507.13300)
*Yilun Zhao,Weiyuan Chen,Zhijian Xu,Manasi Patwardhan,Yixin Liu,Chengye Wang,Lovekesh Vig,Arman Cohan*

Main category: cs.CL

TL;DR: 本文介绍了AbGen，这是第一个用于评估LLMs在设计消融实验方面能力的基准。评估显示，LLMs的表现与人类专家存在差距，且现有自动化评估方法不可靠。为此，作者开发了AbGen-Eval来评估自动化评估系统的可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前的自动化评估方法在评估LLMs设计消融实验的能力时不可靠，因此需要一个新的基准来评估LLMs的表现，并探索更有效的评估系统。

Method: 本文提出了AbGen，一个用于评估LLMs在设计消融实验方面能力的基准。AbGen包含从807篇NLP论文中提取的1,500个专家标注示例。我们评估了DeepSeek-R1-0528和o4-mini等领先的LLMs，并开发了AbGen-Eval来评估自动化评估系统的可靠性。

Result: 评估结果显示，LLMs在消融实验设计的重要性、忠实性和合理性方面与人类专家存在显著差距。同时，现有的自动化评估方法与人类评估结果之间存在显著差异。通过AbGen-Eval，我们进一步验证了这一发现，并为未来研究提供了见解。

Conclusion: 本文介绍了AbGen，这是第一个用于评估大型语言模型（LLMs）在设计消融实验方面的基准。AbGen由807篇NLP论文中的1,500个专家标注示例组成。我们的评估表明，这些模型在消融实验设计的重要性、忠实性和合理性方面与人类专家存在显著差距。此外，我们展示了当前的自动化评估方法不可靠，因为它们与人类评估相比存在显著差异。为了更好地研究这一点，我们开发了AbGen-Eval，这是一个元评估基准，用于评估常用自动化评估系统在测量LLM在该任务上的性能时的可靠性。

Abstract: We introduce AbGen, the first benchmark designed to evaluate the capabilities
of LLMs in designing ablation studies for scientific research. AbGen consists
of 1,500 expert-annotated examples derived from 807 NLP papers. In this
benchmark, LLMs are tasked with generating detailed ablation study designs for
a specified module or process based on the given research context. Our
evaluation of leading LLMs, such as DeepSeek-R1-0528 and o4-mini, highlights a
significant performance gap between these models and human experts in terms of
the importance, faithfulness, and soundness of the ablation study designs.
Moreover, we demonstrate that current automated evaluation methods are not
reliable for our task, as they show a significant discrepancy when compared to
human assessment. To better investigate this, we develop AbGen-Eval, a
meta-evaluation benchmark designed to assess the reliability of commonly used
automated evaluation systems in measuring LLM performance on our task. We
investigate various LLM-as-Judge systems on AbGen-Eval, providing insights for
future research on developing more effective and reliable LLM-based evaluation
systems for complex scientific tasks.

</details>


### [31] [HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals](https://arxiv.org/abs/2507.13318)
*Guimin Hu,Daniel Hershcovich,Hasti Seifi*

Main category: cs.CL

TL;DR: 本文介绍了HapticCap数据集和触觉描述检索任务，通过结合语言模型T5和音频模型AST，在触觉信号与文本描述的匹配任务中取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 设计能够与用户产生有意义共鸣的触觉信号具有挑战性，因此需要一个大规模的、带有文本描述注释的触觉振动数据集。

Method: 引入了一个多模态数据集和任务，即匹配用户描述与振动触觉信号，并提出了基于监督对比学习框架的触觉描述检索任务。

Result: 创建了HapticCap数据集，包含92,070个触觉-文本对，用于用户对振动的感官、情感和联想属性的描述。基于HapticCap，提出了触觉描述检索任务，并展示了使用T5和AST模型的最好性能。

Conclusion: 通过HapticCap数据集和基于T5和AST模型的监督对比学习框架，该研究在触觉描述检索任务中取得了最佳性能，特别是在每个描述类别上单独训练时。

Abstract: Haptic signals, from smartphone vibrations to virtual reality touch feedback,
can effectively convey information and enhance realism, but designing signals
that resonate meaningfully with users is challenging. To facilitate this, we
introduce a multimodal dataset and task, of matching user descriptions to
vibration haptic signals, and highlight two primary challenges: (1) lack of
large haptic vibration datasets annotated with textual descriptions as
collecting haptic descriptions is time-consuming, and (2) limited capability of
existing tasks and models to describe vibration signals in text. To advance
this area, we create HapticCap, the first fully human-annotated
haptic-captioned dataset, containing 92,070 haptic-text pairs for user
descriptions of sensory, emotional, and associative attributes of vibrations.
Based on HapticCap, we propose the haptic-caption retrieval task and present
the results of this task from a supervised contrastive learning framework that
brings together text representations within specific categories and vibrations.
Overall, the combination of language model T5 and audio model AST yields the
best performance in the haptic-caption retrieval task, especially when
separately trained for each description category.

</details>


### [32] [Social and Political Framing in Search Engine Results](https://arxiv.org/abs/2507.13325)
*Amrit Poudel,Tim Weninger*

Main category: cs.CL

TL;DR: 本研究探讨了搜索引擎和有意识形态动机的用户查询如何共同导致搜索结果中的偏见，并发现搜索引擎在优先考虑内容方面存在差异，这可能加剧信息极化。


<details>
  <summary>Details</summary>
Motivation: 先前的研究已经广泛探讨了搜索偏见的各种维度，但一个重要的问题仍未得到充分研究：搜索引擎和有意识形态动机的用户查询如何共同导致搜索结果中的偏见。

Method: 该研究使用政治和社会议题的数据集分析了主要搜索引擎的输出。

Result: 研究发现，搜索引擎不仅以反映潜在偏见的方式优先考虑内容，而且有意识形态驱动的用户查询会加剧这些偏见，导致特定叙述的放大。此外，在搜索引擎优先考虑的来源方面观察到了显著差异。

Conclusion: 研究结果表明，搜索引擎可能在通过强化意识形态分歧来塑造公众认知方面发挥关键作用，从而对信息极化问题做出贡献。

Abstract: Search engines play a crucial role in shaping public discourse by influencing
how information is accessed and framed. While prior research has extensively
examined various dimensions of search bias -- such as content prioritization,
indexical bias, political polarization, and sources of bias -- an important
question remains underexplored: how do search engines and
ideologically-motivated user queries contribute to bias in search results. This
study analyzes the outputs of major search engines using a dataset of political
and social topics. The findings reveal that search engines not only prioritize
content in ways that reflect underlying biases but also that
ideologically-driven user queries exacerbate these biases, resulting in the
amplification of specific narratives. Moreover, significant differences were
observed across search engines in terms of the sources they prioritize. These
results suggest that search engines may play a pivotal role in shaping public
perceptions by reinforcing ideological divides, thereby contributing to the
broader issue of information polarization.

</details>


### [33] [Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It](https://arxiv.org/abs/2507.13328)
*Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim*

Main category: cs.CL

TL;DR: 研究显示，视觉-语言训练不会显著改变语言模型的分类知识，但会改善这些知识在特定任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究视觉-语言训练是否能以有意义的方式改变语言模型的语义表示，特别是分类知识的表示方式。

Method: 通过比较仅文本的语言模型和其VL训练后的对应模型，在需要概念分类理解的文本问答任务中进行评估，并使用行为和表示分析来研究模型之间的差异。

Result: VL模型在需要分类理解的任务中表现优于仅文本模型，但在分类知识本身上没有显著差异，只是在处理分类关系和非分类关系的概念时的表示方式不同。

Conclusion: VL训练不会显著改变语言模型的语义知识，但会改善这些知识在特定任务中的应用。

Abstract: Does vision-and-language (VL) training change the linguistic representations
of language models in meaningful ways? Most results in the literature have
shown inconsistent or marginal differences, both behaviorally and
representationally. In this work, we start from the hypothesis that the domain
in which VL training could have a significant effect is lexical-conceptual
knowledge, in particular its taxonomic organization. Through comparing minimal
pairs of text-only LMs and their VL-trained counterparts, we first show that
the VL models often outperform their text-only counterparts on a text-only
question-answering task that requires taxonomic understanding of concepts
mentioned in the questions. Using an array of targeted behavioral and
representational analyses, we show that the LMs and VLMs do not differ
significantly in terms of their taxonomic knowledge itself, but they differ in
how they represent questions that contain concepts in a taxonomic relation vs.
a non-taxonomic relation. This implies that the taxonomic knowledge itself does
not change substantially through additional VL training, but VL training does
improve the deployment of this knowledge in the context of a specific task,
even when the presentation of the task is purely linguistic.

</details>


### [34] [The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner](https://arxiv.org/abs/2507.13332)
*Zhouqi Hua,Wenwei Zhang,Chengqi Lyu,Yuzhe Gu,Songyang Gao,Kuikun Liu,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出TAIL方法，通过模仿图灵机执行过程生成思维链数据，以提高LLM的长度泛化能力，并在实验中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要集中在特定任务上，缺乏整体性能。本文旨在寻找一种更通用的解决方案，以解决Transformer-based LLM在处理更长序列时的挑战。

Method: 本文提出了Turing MAchine Imitation Learning (TAIL)，通过计算机程序生成模仿图灵机执行过程的思维链数据，以提高LLM的长度泛化能力。

Result: TAIL在各种任务中显著提高了Qwen2.5-7B的长度泛化能力和性能，超越了之前的方法和DeepSeek-R1。

Conclusion: 本文提供了一种有前景的方向，用于未来研究从合成数据中学习LLM推理。

Abstract: Length generalization, the ability to solve problems of longer sequences than
those observed during training, poses a core challenge of Transformer-based
large language models (LLM). Although existing studies have predominantly
focused on data-driven approaches for arithmetic operations and symbolic
manipulation tasks, these approaches tend to be task-specific with limited
overall performance. To pursue a more general solution, this paper focuses on a
broader case of reasoning problems that are computable, i.e., problems that
algorithms can solve, thus can be solved by the Turing Machine. From this
perspective, this paper proposes Turing MAchine Imitation Learning (TAIL) to
improve the length generalization ability of LLMs. TAIL synthesizes
chain-of-thoughts (CoT) data that imitate the execution process of a Turing
Machine by computer programs, which linearly expands the reasoning steps into
atomic states to alleviate shortcut learning and explicit memory fetch
mechanism to reduce the difficulties of dynamic and long-range data access in
elementary operations. To validate the reliability and universality of TAIL, we
construct a challenging synthetic dataset covering 8 classes of algorithms and
18 tasks. Without bells and whistles, TAIL significantly improves the length
generalization ability as well as the performance of Qwen2.5-7B on various
tasks using only synthetic data, surpassing previous methods and DeepSeek-R1.
The experimental results reveal that the key concepts in the Turing Machine,
instead of the thinking styles, are indispensable for TAIL for length
generalization, through which the model exhibits read-and-write behaviors
consistent with the properties of the Turing Machine in their attention layers.
This work provides a promising direction for future research in the learning of
LLM reasoning from synthetic data.

</details>


### [35] [A Survey of Context Engineering for Large Language Models](https://arxiv.org/abs/2507.13334)
*Lingrui Mei,Jiayu Yao,Yuyao Ge,Yiwei Wang,Baolong Bi,Yujun Cai,Jiazhi Liu,Mingyu Li,Zhong-Zhi Li,Duzhen Zhang,Chenlin Zhou,Jiayi Mao,Tianze Xia,Jiafeng Guo,Shenghua Liu*

Main category: cs.CL

TL;DR: 本文介绍了一种名为上下文工程的正式学科，通过系统优化信息负载来提升大型语言模型的性能，并提出了一个全面的分类体系，揭示了模型在生成复杂输出方面的限制。


<details>
  <summary>Details</summary>
Motivation: 本文旨在超越简单的提示设计，提出一种正式的学科——上下文工程，以系统优化信息负载，提升大型语言模型的性能。

Method: 本文通过系统分析超过1300篇研究论文，提出了一个全面的分类体系，分解了上下文工程的基础组件及其复杂实现。

Result: 本文不仅建立了该领域的技术路线图，还揭示了一个关键的研究空白：模型能力之间存在根本性的不对称性，当前模型在理解复杂上下文方面表现出色，但在生成同样复杂的长格式输出方面存在明显限制。

Conclusion: 本文提供了统一的框架，为推进上下文感知AI的研究人员和工程师提供了指导。

Abstract: The performance of Large Language Models (LLMs) is fundamentally determined
by the contextual information provided during inference. This survey introduces
Context Engineering, a formal discipline that transcends simple prompt design
to encompass the systematic optimization of information payloads for LLMs. We
present a comprehensive taxonomy decomposing Context Engineering into its
foundational components and the sophisticated implementations that integrate
them into intelligent systems. We first examine the foundational components:
context retrieval and generation, context processing and context management. We
then explore how these components are architecturally integrated to create
sophisticated system implementations: retrieval-augmented generation (RAG),
memory systems and tool-integrated reasoning, and multi-agent systems. Through
this systematic analysis of over 1300 research papers, our survey not only
establishes a technical roadmap for the field but also reveals a critical
research gap: a fundamental asymmetry exists between model capabilities. While
current models, augmented by advanced context engineering, demonstrate
remarkable proficiency in understanding complex contexts, they exhibit
pronounced limitations in generating equally sophisticated, long-form outputs.
Addressing this gap is a defining priority for future research. Ultimately,
this survey provides a unified framework for both researchers and engineers
advancing context-aware AI.

</details>


### [36] [Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour Understanding from Traditional Puns to Topical Jokes](https://arxiv.org/abs/2507.13335)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 本研究分析了大型语言模型在解释不同类型幽默（如双关语、网络幽默和时事笑话）方面的表现，发现现有模型在处理复杂幽默时存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有计算幽默的研究主要集中在简短的双关语笑话上，而我们希望探讨大型语言模型解释幽默的能力是否依赖于特定的幽默形式，特别是更复杂的需要现实世界知识和事件理解的幽默形式。

Method: 我们创建了一个包含600个笑话的数据集，分为4种笑话类型，并手动编写了高质量的解释。然后，我们使用这个数据集比较了多种大型语言模型在零样本设置下准确且全面解释不同类型的笑话的能力。

Result: 我们发现，所有测试的模型（包括推理模型）都无法可靠地生成所有笑话类型的充分解释，这表明当前模型在处理复杂幽默时存在明显不足。

Conclusion: 我们的研究发现，现有的大型语言模型在解释不同类型的幽默方面存在显著的局限性，这突显了计算幽默领域对过于简单的笑话形式的狭隘关注。

Abstract: Humour, as a complex language form, is derived from myriad aspects of life,
whilst existing work on computational humour has focussed almost exclusively on
short pun-based jokes. In this work, we investigate whether the ability of
Large Language Models (LLMs) to explain humour depends on the particular humour
form. We compare models on simple puns and more complex topical humour that
requires knowledge of real-world entities and events. In doing so, we curate a
dataset of 600 jokes split across 4 joke types and manually write high-quality
explanations. These jokes include heterographic and homographic puns,
contemporary internet humour, and topical jokes, where understanding relies on
reasoning beyond "common sense", rooted instead in world knowledge regarding
news events and pop culture. Using this dataset, we compare the zero-shot
abilities of a range of LLMs to accurately and comprehensively explain jokes of
different types, identifying key research gaps in the task of humour
explanation. We find that none of the tested models (inc. reasoning models) are
capable of reliably generating adequate explanations of all joke types, further
highlighting the narrow focus of most works in computational humour on overly
simple joke forms.

</details>


<div id='cs.CC'></div>

# cs.CC [[Back]](#toc)

### [37] [Perfect diffusion is $\mathsf{TC}^0$ -- Bad diffusion is Turing-complete](https://arxiv.org/abs/2507.12469)
*Yuxi Liu*

Main category: cs.CC

TL;DR: 本文分析了扩散模型在语言建模任务中的理论限制和能力，并提出了一种可能的改进方向。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨扩散模型在语言建模任务中的理论限制和潜在能力，以及如何改进现有模型。

Method: 本文通过证明基于得分匹配网络质量的二分法，分析了扩散模型的计算复杂性。

Result: 本文证明了当得分匹配网络精确计算初始分布的得分函数时，扩散模型只能在 TC^0 复杂度类中进行语言建模；而当没有这种要求时，扩散模型可以模拟任何图灵机。

Conclusion: 本文通过理论分析揭示了扩散模型在语言建模任务中的能力与限制，并提出了可能的改进方向。

Abstract: This paper explores the computational complexity of diffusion-based language
modeling. We prove a dichotomy based on the quality of the score-matching
network in a diffusion model. In one direction, a network that exactly computes
the score function of some initial distribution can only perform language
modeling within the $\mathsf{TC}^0$ complexity class, reflecting limitations
tied to rapid convergence. In the other direction, we show that if there is no
requirement for the network to match any score function, then diffusion
modeling can simulate any Turing machine in a certain sense. This dichotomy
provides a theoretical lens on the capabilities and limitations of diffusion
models, particularly concerning tasks requiring sequential computation. We
conjecture extensions of our theoretical results, including for the case where
the diffusion model is not perfect, but merely good. We also discuss the wider
context and practical implications, and hypothesize that a machine learning
architecture that can interpolate between sequential and parallel modes of
operation would be superior to both Transformers and diffusion models.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [38] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu,Jielin Qiu,Shiyu Wang,Jianguo Zhang,Zuxin Liu,Roshan Ram,Haolin Chen,Weiran Yao,Huan Wang,Shelby Heinecke,Silvio Savarese,Caiming Xiong*

Main category: cs.AI

TL;DR: 本文介绍了一种基于 MCP 的框架 MCPEval，用于自动化 LLM 代理的端到端任务生成和深度评估，并展示了其在多个领域中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法依赖于静态基准和人工数据收集，限制了实际评估。因此，需要一种更强大、可扩展的评估框架。

Method: 我们引入了一个基于 Model Context Protocol (MCP) 的框架 MCPEval，该框架自动化了端到端任务生成和深度评估 LLM 代理 across 多个领域。

Result: 在五个现实领域的实证结果表明，MCPEval 在揭示领域特定性能方面是有效的。

Conclusion: MCPEval 是一种有效的框架，可以揭示不同领域中 LLM 代理的细微性能，并且通过公开发布，促进了可重复和标准化的 LLM 代理评估。

Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [39] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang,Ruiyu Fang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 本文介绍了针对NLPCC 2025任务8 ESC评估的解决方案，通过大规模语言模型和提示工程与微调技术相结合的方法，探索了参数高效低秩适应和全参数微调策略，以提升模型生成支持性回应的能力。最佳模型在比赛中获得第二名，展示了该方法在ESC任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 情感支持对话（ESC）旨在通过对话提供共情和有效的心理支持，满足日益增长的心理健康支持需求。

Method: 我们利用大规模语言模型，通过提示工程和微调技术来解决NLPCC 2025任务8的ESC评估问题。我们探索了参数高效的低秩适应和全参数微调策略，以提高模型生成支持性和上下文适当的回应的能力。

Result: 我们的最佳模型在比赛中排名第二，这表明结合大型语言模型和有效的适应方法在ESC任务中具有潜力。

Conclusion: 我们的最佳模型在比赛中排名第二，这表明结合大型语言模型和有效的适应方法在ESC任务中具有潜力。未来的工作将专注于进一步增强情感理解和回应个性化，以构建更实用和可靠的的情感支持系统。

Abstract: Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [40] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
*Ahmed Bahloul,Simon Malberg*

Main category: cs.AI

TL;DR: 本文提出了一种动态强化学习框架，用于改进基于树的推理方法，提高解决方案质量和计算效率，同时保持概率严谨性。


<details>
  <summary>Details</summary>
Motivation: 现有的ProbTree框架存在两个关键限制：推理树在初始构建阶段是固定的，无法根据中间结果进行动态调整；每个节点需要对所有可能的解决方案策略进行详尽评估，导致计算效率低下。因此，需要一种更高效和灵活的解决方案。

Method: 本文提出了一种动态强化学习框架，用于将基于树的推理转化为自适应过程。该方法根据实时置信度估计逐步构建推理树，并学习最优的动作选择策略（分解、检索或聚合）。

Result: 本文提出的动态强化学习框架在保持ProbTree的概率严谨性的同时，通过选择性扩展和集中资源分配提高了解决方案质量和计算效率。该工作建立了一个新的树结构推理范式，平衡了概率框架的可靠性与现实问答系统所需的灵活性。

Conclusion: 本文提出了一种动态强化学习框架，将基于树的推理转化为自适应过程，从而在保持ProbTree的概率严谨性的同时，通过选择性扩展和集中资源分配提高了解决方案质量和计算效率。该工作建立了一个新的树结构推理范式，平衡了概率框架的可靠性与现实问答系统所需的灵活性。

Abstract: Modern language models address complex questions through chain-of-thought
(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,
2021), yet struggle with error propagation and knowledge integration.
Tree-structured reasoning methods, particularly the Probabilistic
Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues
by decomposing questions into hierarchical structures and selecting answers
through confidence-weighted aggregation of parametric and retrieved knowledge
(Yao et al., 2023). However, ProbTree's static implementation introduces two
key limitations: (1) the reasoning tree is fixed during the initial
construction phase, preventing dynamic adaptation to intermediate results, and
(2) each node requires exhaustive evaluation of all possible solution
strategies, creating computational inefficiency. We present a dynamic
reinforcement learning (Sutton and Barto, 2018) framework that transforms
tree-based reasoning into an adaptive process. Our approach incrementally
constructs the reasoning tree based on real-time confidence estimates, while
learning optimal policies for action selection (decomposition, retrieval, or
aggregation). This maintains ProbTree's probabilistic rigor while improving
both solution quality and computational efficiency through selective expansion
and focused resource allocation. The work establishes a new paradigm for
treestructured reasoning that balances the reliability of probabilistic
frameworks with the flexibility required for real-world question answering
systems.

</details>


### [41] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
*Carlos Arriaga,Gonzalo Martínez,Eneko Sendin,Javier Conde,Pedro Reviriego*

Main category: cs.AI

TL;DR: 本文提出了一种新的评估平台GEA，用于研究用户在了解模型能耗情况下的选择行为。实验结果表明，用户更倾向于选择能效更高的模型，而不是性能更好但能耗更高的模型。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）是一个复杂的任务，传统的自动化基准测试与人类评估之间存在相关性不足的问题。同时，随着模型数量的增长，传统的人工评估方法变得不切实际且昂贵。因此，需要一种更有效的方法来评估LLM，特别是在考虑能耗的情况下。

Method: 本文提出了GEA（Generative Energy Arena），这是一个在评估过程中融入模型能耗信息的平台。通过GEA进行初步实验，分析用户在了解能耗情况下的选择行为。

Result: 通过GEA进行的初步实验结果显示，当用户了解模型的能耗时，他们更倾向于选择较小且能效更高的模型。这表明，对于大多数用户交互，复杂且性能优越的模型所增加的成本和能耗并不值得。

Conclusion: 研究表明，当用户了解模型的能耗时，他们更倾向于选择较小且能效更高的模型。这表明，对于大多数用户交互，复杂且表现更好的模型所带来的额外成本和能耗并没有带来响应质量的提升，从而不值得使用。

Abstract: The evaluation of large language models is a complex task, in which several
approaches have been proposed. The most common is the use of automated
benchmarks in which LLMs have to answer multiple-choice questions of different
topics. However, this method has certain limitations, being the most
concerning, the poor correlation with the humans. An alternative approach, is
to have humans evaluate the LLMs. This poses scalability issues as there is a
large and growing number of models to evaluate making it impractical (and
costly) to run traditional studies based on recruiting a number of evaluators
and having them rank the responses of the models. An alternative approach is
the use of public arenas, such as the popular LM arena, on which any user can
freely evaluate models on any question and rank the responses of two models.
The results are then elaborated into a model ranking. An increasingly important
aspect of LLMs is their energy consumption and, therefore, evaluating how
energy awareness influences the decisions of humans in selecting a model is of
interest. In this paper, we present GEA, the Generative Energy Arena, an arena
that incorporates information on the energy consumption of the model in the
evaluation process. Preliminary results obtained with GEA are also presented,
showing that for most questions, when users are aware of the energy
consumption, they favor smaller and more energy efficient models. This suggests
that for most user interactions, the extra cost and energy incurred by the more
complex and top-performing models do not provide an increase in the perceived
quality of the responses that justifies their use.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [42] [Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training](https://arxiv.org/abs/2507.12507)
*Mingjie Liu,Shizhe Diao,Jian Hu,Ximing Lu,Xin Dong,Hao Zhang,Alexander Bukharin,Shaokun Zhang,Jiaqi Zeng,Makesh Narsimhan Sreedhar,Gerald Shen,David Mosallanezhad,Di Zhang,Jonas Yang,June Yang,Oleksii Kuchaiev,Guilin Liu,Zhiding Yu,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong*

Main category: cs.LG

TL;DR: 本研究探讨了长时间强化学习对小语言模型在多个推理领域的影响，并提出了关键的训练方法以实现显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 最近的进展表明，通过链式思维推理和迭代探索来扩展测试时计算可以显著提高复杂任务的表现。本研究旨在探索长时间强化学习对小语言模型在多个推理领域的影响。

Method: 我们研究了在小语言模型上进行长时间强化学习的效果，并识别了有效训练的关键要素，包括使用可验证的奖励任务、对Group Relative Policy Optimization (GRPO)的改进以及提高训练稳定性和泛化的实用技术。

Result: 我们的模型在数学、编程和逻辑谜题任务上分别取得了+14.7%、+13.9%和+54.8%的提升。

Conclusion: 我们的模型在数学、编程和逻辑谜题任务上相对于强基线有显著提升，展示了长期性能增益的潜力。

Abstract: Recent advancements in reasoning-focused language models such as OpenAI's O1
and DeepSeek-R1 have shown that scaling test-time computation-through
chain-of-thought reasoning and iterative exploration-can yield substantial
improvements on complex tasks like mathematics and code generation. These
breakthroughs have been driven by large-scale reinforcement learning (RL),
particularly when combined with verifiable reward signals that provide
objective and grounded supervision. In this report, we investigate the effects
of prolonged reinforcement learning on a small language model across a diverse
set of reasoning domains. Our work identifies several key ingredients for
effective training, including the use of verifiable reward tasks, enhancements
to Group Relative Policy Optimization (GRPO), and practical techniques to
improve training stability and generalization. We introduce controlled KL
regularization, clipping ratio, and periodic reference policy resets as
critical components for unlocking long-term performance gains. Our model
achieves significant improvements over strong baselines, including +14.7% on
math, +13.9% on coding, and +54.8% on logic puzzle tasks. To facilitate
continued research, we release our model publicly.

</details>


### [43] [A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models](https://arxiv.org/abs/2507.12774)
*Weijieying Ren,Jingxi Zhu,Zehao Liu,Tianxiang Zhao,Vasant Honavar*

Main category: cs.LG

TL;DR: 本文提供了深度学习和大型语言模型在电子健康记录建模中的最新进展的全面概述，并提出了一个统一的分类法，以帮助推动AI驱动的医疗健康领域的研究。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）数据固有的异质性、时间不规则性和领域特定性带来了与视觉和自然语言任务不同的独特挑战。本文旨在全面概述深度学习、大型语言模型（LLMs）和EHR建模的最新进展。

Method: 本文提出了一个统一的分类法，涵盖了五个关键设计维度：数据导向的方法、神经网络架构设计、学习导向的策略、多模态学习以及基于大型语言模型的建模系统。

Result: 本文回顾了在数据质量增强、结构和时间表示、自监督学习以及与临床知识整合方面解决代表性方法的进展。同时，还强调了基础模型、LLM驱动的临床代理和EHR到文本的翻译等新兴趋势。

Conclusion: 本文旨在为推进AI驱动的EHR建模和临床决策支持提供一个结构化的路线图。

Abstract: Artificial intelligence (AI) has demonstrated significant potential in
transforming healthcare through the analysis and modeling of electronic health
records (EHRs). However, the inherent heterogeneity, temporal irregularity, and
domain-specific nature of EHR data present unique challenges that differ
fundamentally from those in vision and natural language tasks. This survey
offers a comprehensive overview of recent advancements at the intersection of
deep learning, large language models (LLMs), and EHR modeling. We introduce a
unified taxonomy that spans five key design dimensions: data-centric
approaches, neural architecture design, learning-focused strategies, multimodal
learning, and LLM-based modeling systems. Within each dimension, we review
representative methods addressing data quality enhancement, structural and
temporal representation, self-supervised learning, and integration with
clinical knowledge. We further highlight emerging trends such as foundation
models, LLM-driven clinical agents, and EHR-to-text translation for downstream
reasoning. Finally, we discuss open challenges in benchmarking, explainability,
clinical alignment, and generalization across diverse clinical settings. This
survey aims to provide a structured roadmap for advancing AI-driven EHR
modeling and clinical decision support. For a comprehensive list of EHR-related
methods, kindly refer to https://survey-on-tabular-data.github.io/.

</details>


### [44] [PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database](https://arxiv.org/abs/2507.12805)
*Hui Sun,Yanfeng Ding,Liping Yi,Huidong Ma,Gang Wang,Xiaoguang Liu,Cheng Zhong,Wentong Cai*

Main category: cs.LG

TL;DR: 本文提出了一种基于并行多知识学习的新型无损压缩器PMKLC，通过四个关键设计提高了压缩比、吞吐量和鲁棒性，并在多个真实数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的无损压缩器在压缩比、压缩和解压吞吐量以及压缩鲁棒性方面存在不足，限制了其在工业和学术界的广泛应用。

Method: 提出了一种基于并行多知识学习的压缩框架PMKLC，包括自动化多知识学习压缩框架、GPU加速的(s,k)-mer编码器、数据块分区和逐步模型传递机制，以及两种压缩模式PMKLC-S和PMKLC-M。

Result: PMKLC-S/M在15个真实世界数据集上与14个基线（7个传统和7个学习-based）进行基准测试，平均压缩比提升高达73.609%和73.480%，平均吞吐量提升高达3.036倍和10.710倍，并且实现了最佳鲁棒性和有竞争力的内存成本。

Conclusion: PMKLC-S/M在压缩比、吞吐量和鲁棒性方面表现出色，表明其在不同数据集上的稳定性和在内存受限设备上的强大能力。

Abstract: Learning-based lossless compressors play a crucial role in large-scale
genomic database backup, storage, transmission, and management. However, their
1) inadequate compression ratio, 2) low compression \& decompression
throughput, and 3) poor compression robustness limit their widespread adoption
and application in both industry and academia. To solve those challenges, we
propose a novel \underline{P}arallel \underline{M}ulti-\underline{K}nowledge
\underline{L}earning-based \underline{C}ompressor (PMKLC) with four crucial
designs: 1) We propose an automated multi-knowledge learning-based compression
framework as compressors' backbone to enhance compression ratio and robustness;
2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compression
throughput and computing resource usage; 3) we introduce data block
partitioning and Step-wise Model Passing (SMP) mechanisms for parallel
acceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meet
the complex application scenarios, where the former runs on a
resource-constrained single GPU and the latter is multi-GPU accelerated. We
benchmark PMKLC-S/M and 14 baselines (7 traditional and 7 leaning-based) on 15
real-world datasets with different species and data sizes. Compared to
baselines on the testing datasets, PMKLC-S/M achieve the average compression
ratio improvement up to 73.609\% and 73.480\%, the average throughput
improvement up to 3.036$\times$ and 10.710$\times$, respectively. Besides,
PMKLC-S/M also achieve the best robustness and competitive memory cost,
indicating its greater stability against datasets with different probability
distribution perturbations, and its strong ability to run on memory-constrained
devices.

</details>


### [45] [Probabilistic Soundness Guarantees in LLM Reasoning Chains](https://arxiv.org/abs/2507.12948)
*Weiqiu You,Anton Xue,Shreya Havaldar,Delip Rao,Helen Jin,Chris Callison-Burch,Eric Wong*

Main category: cs.LG

TL;DR: 本文提出了一种名为ARES的新概率框架，用于检测大型语言模型生成的推理链中的传播错误。该方法通过仅基于先前评估的合理前提来判断每个主张，从而防止错误传播，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的错误检测方法往往无法检测传播错误，因为它们没有正确考虑早期错误如何影响下游推理的判断。

Method: 引入了自回归推理蕴含稳定性（ARES），这是一种新的概率框架，通过仅基于之前评估的合理前提来判断每个主张，从而防止错误传播。

Result: ARES在四个基准测试中实现了72.1%的宏F1分数，比现有方法高出8.2分，并在非常长的合成推理链中表现出色，检测传播错误的F1分数为90.3%，比现有方法高出27.6分。

Conclusion: ARES在四个基准测试中实现了最先进的性能，并在非常长的合成推理链中表现出色，能够有效检测传播错误。

Abstract: In reasoning chains generated by large language models (LLMs), initial errors
often propagate and undermine the reliability of the final conclusion. Current
LLM-based error detection methods often fail to detect propagated errors
because they do not properly account for how earlier errors might corrupt
judgments of downstream reasoning. To better detect such propagated errors, we
introduce Autoregressive Reasoning Entailment Stability (ARES), a novel
probabilistic framework that prevents error propagation by judging each claim
based only on previously-assessed sound premises. This inductive method yields
a nuanced score for each step and provides certified statistical guarantees of
its soundness, rather than a brittle binary label. ARES achieves
state-of-the-art performance across four benchmarks (72.1% Macro-F1, +8.2
points) and demonstrates superior robustness on very long synthetic reasoning
chains, where it excels at detecting propagated errors (90.3% F1, +27.6
points).

</details>


### [46] [Teach Old SAEs New Domain Tricks with Boosting](https://arxiv.org/abs/2507.12990)
*Nikita Koriagin,Yaroslav Aksenov,Daniil Laptev,Gleb Gerasimov,Nikita Balagansky,Daniil Gavrilov*

Main category: cs.LG

TL;DR: 本文提出了一种残差学习方法，用于改进稀疏自编码器（SAE）在特定领域特征上的表现，通过训练一个次级SAE来建模主SAE的重建误差，并在推理过程中将两个模型的输出相加，从而显著提升了LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器（SAE）虽然在解释大型语言模型（LLM）的内部表示方面表现出色，但它们往往无法捕捉训练语料库中不常见的领域特定特征。因此，需要一种方法来解决这一特征盲点问题，而无需完全重新训练SAE。

Method: 本文提出了一种残差学习方法，通过训练一个次级SAE来建模预训练SAE在特定领域文本上的重建误差，从而捕捉主模型遗漏的特征。在推理过程中，将两个模型的输出相加，以提高性能。

Result: 实验结果表明，该方法能够有效地将新领域的知识整合到现有的SAE中，同时保持其在通用任务上的性能。在多个专业领域中，LLM的交叉熵和解释方差指标都有显著提升。

Conclusion: 本文提出了一种残差学习方法，能够在不完全重新训练的情况下解决稀疏自编码器（SAE）在特定领域特征上的盲点问题。通过将主模型和次级模型的输出相加，显著提高了LLM的交叉熵和解释方差指标，同时保持了在通用任务上的性能。这种方法使研究人员能够有针对性地增强SAE在特定领域的可解释性，为LLM的机制解释开辟了新的可能性。

Abstract: Sparse Autoencoders have emerged as powerful tools for interpreting the
internal representations of Large Language Models, yet they often fail to
capture domain-specific features not prevalent in their training corpora. This
paper introduces a residual learning approach that addresses this feature
blindness without requiring complete retraining. We propose training a
secondary SAE specifically to model the reconstruction error of a pretrained
SAE on domain-specific texts, effectively capturing features missed by the
primary model. By summing the outputs of both models during inference, we
demonstrate significant improvements in both LLM cross-entropy and explained
variance metrics across multiple specialized domains. Our experiments show that
this method efficiently incorporates new domain knowledge into existing SAEs
while maintaining their performance on general tasks. This approach enables
researchers to selectively enhance SAE interpretability for specific domains of
interest, opening new possibilities for targeted mechanistic interpretability
of LLMs.

</details>


### [47] [Inverse Reinforcement Learning Meets Large Language Model Post-Training: Basics, Advances, and Opportunities](https://arxiv.org/abs/2507.13158)
*Hao Sun,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 本文通过逆强化学习的视角全面回顾了大型语言模型对齐的最新进展，强调了强化学习技术在其中的应用与传统任务的区别，并探讨了相关挑战、机遇及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型（LLM）时代，对齐已成为追求更可靠、可控和强大机器智能的基本但具有挑战性的问题。最近的推理模型和对话AI系统的成功凸显了强化学习（RL）在增强这些系统中的关键作用，推动了RL和LLM对齐交叉领域的研究兴趣。

Method: 本文通过逆强化学习（IRL）的视角全面回顾了LLM对齐的最新进展，强调了在LLM对齐中使用的RL技术与传统RL任务中的区别。

Result: 本文介绍了RL的基础概念，以提供对不熟悉该领域的读者的基础知识。然后，我们检查了这一研究议程的最新进展，讨论了在LLM对齐中进行IRL的关键挑战和机遇。除了方法论方面的考虑，我们还探讨了实际方面，包括数据集、基准测试、评估指标、基础设施以及计算高效的训练和推理技术。最后，我们从稀疏奖励RL的文献中获得见解，以确定开放问题和潜在的研究方向。

Conclusion: 本文旨在提供一个结构化且批判性的领域概述，突出未解决的挑战，并概述通过强化学习（RL）和逆强化学习（IRL）技术改进LLM对齐的有前景的未来方向。

Abstract: In the era of Large Language Models (LLMs), alignment has emerged as a
fundamental yet challenging problem in the pursuit of more reliable,
controllable, and capable machine intelligence. The recent success of reasoning
models and conversational AI systems has underscored the critical role of
reinforcement learning (RL) in enhancing these systems, driving increased
research interest at the intersection of RL and LLM alignment. This paper
provides a comprehensive review of recent advances in LLM alignment through the
lens of inverse reinforcement learning (IRL), emphasizing the distinctions
between RL techniques employed in LLM alignment and those in conventional RL
tasks. In particular, we highlight the necessity of constructing neural reward
models from human data and discuss the formal and practical implications of
this paradigm shift. We begin by introducing fundamental concepts in RL to
provide a foundation for readers unfamiliar with the field. We then examine
recent advances in this research agenda, discussing key challenges and
opportunities in conducting IRL for LLM alignment. Beyond methodological
considerations, we explore practical aspects, including datasets, benchmarks,
evaluation metrics, infrastructure, and computationally efficient training and
inference techniques. Finally, we draw insights from the literature on
sparse-reward RL to identify open questions and potential research directions.
By synthesizing findings from diverse studies, we aim to provide a structured
and critical overview of the field, highlight unresolved challenges, and
outline promising future directions for improving LLM alignment through RL and
IRL techniques.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [48] [A Survey of AIOps in the Era of Large Language Models](https://arxiv.org/abs/2507.12472)
*Lingzhe Zhang,Tong Jia,Mengxi Jia,Yifan Wu,Aiwei Liu,Yong Yang,Zhonghai Wu,Xuming Hu,Philip S. Yu,Ying Li*

Main category: cs.SE

TL;DR: 本文对LLM在AIOps中的应用进行了详细调查，分析了183篇相关论文，探讨了LLM在AIOps中的潜在作用和挑战，并提出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）变得越来越复杂和普遍，它们在各种人工智能用于IT运营（AIOps）任务中的应用引起了广泛关注。然而，对LLMs在AIOps中的影响、潜力和局限性的全面理解仍处于初级阶段。

Method: 本文对2020年1月至2024年12月间发表的183篇研究论文进行了详细调查，以回答四个关键研究问题（RQs）。

Result: 本文分析了LLM在AIOps中的不同故障数据源、AIOps任务的演变、基于LLM的方法以及评估方法。

Conclusion: 本文讨论了LLM在AIOps领域的最新进展和趋势，指出了现有研究中的不足，并提出了未来研究的有希望的方向。

Abstract: As large language models (LLMs) grow increasingly sophisticated and
pervasive, their application to various Artificial Intelligence for IT
Operations (AIOps) tasks has garnered significant attention. However, a
comprehensive understanding of the impact, potential, and limitations of LLMs
in AIOps remains in its infancy. To address this gap, we conducted a detailed
survey of LLM4AIOps, focusing on how LLMs can optimize processes and improve
outcomes in this domain. We analyzed 183 research papers published between
January 2020 and December 2024 to answer four key research questions (RQs). In
RQ1, we examine the diverse failure data sources utilized, including advanced
LLM-based processing techniques for legacy data and the incorporation of new
data sources enabled by LLMs. RQ2 explores the evolution of AIOps tasks,
highlighting the emergence of novel tasks and the publication trends across
these tasks. RQ3 investigates the various LLM-based methods applied to address
AIOps challenges. Finally, RQ4 reviews evaluation methodologies tailored to
assess LLM-integrated AIOps approaches. Based on our findings, we discuss the
state-of-the-art advancements and trends, identify gaps in existing research,
and propose promising directions for future exploration.

</details>


### [49] [A Fuzzy Approach to Project Success: Measuring What Matters](https://arxiv.org/abs/2507.12653)
*João Granja-Correia,Remedios Hernández-Linares,Luca Ferranti,Arménio Rego*

Main category: cs.SE

TL;DR: 本文介绍了一种将模糊逻辑整合到现有结构中的新方法，以更准确地评估项目成功。


<details>
  <summary>Details</summary>
Motivation: 传统Likert量表测量常常忽略了项目成功的上下文依赖性和多维性质，因此需要一种更全面的评估方法。

Method: 该论文引入了一种基于模糊逻辑的项目成功评估方法，采用分层的Type-1 Mamdani模糊系统，以优先考虑对最终用户的持续积极影响。

Result: 该动态方法可能提供更准确的项目成功衡量，并可适应复杂的评估。

Conclusion: 该论文提出了一种新的项目成功评估方法，通过将模糊逻辑整合到现有结构中，可能为项目成功提供更准确的衡量标准，并可用于复杂评估。

Abstract: This paper introduces a novel approach to project success evaluation by
integrating fuzzy logic into an existing construct. Traditional Likert-scale
measures often overlook the context-dependent and multifaceted nature of
project success. The proposed hierarchical Type-1 Mamdani fuzzy system
prioritizes sustained positive impact for end-users, reducing emphasis on
secondary outcomes like stakeholder satisfaction and internal project success.
This dynamic approach may provide a more accurate measure of project success
and could be adaptable to complex evaluations. Future research will focus on
empirical testing and broader applications of fuzzy logic in social science.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [50] [UniSLU: Unified Spoken Language Understanding from Heterogeneous Cross-Task Datasets](https://arxiv.org/abs/2507.12951)
*Zhichao Sheng,Shilin Zhou,Chen Gong,Zhenghua Li*

Main category: eess.AS

TL;DR: 本文提出了一种名为UniSLU的统一框架，用于在单一架构中联合建模多个SLU任务，通过统一表示和生成方法提高任务交互和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常依赖于单独的模型架构来处理各个任务，如口语NER和SA，这增加了系统复杂性，限制了跨任务交互，并未能充分利用任务间的异构数据集。

Method: 我们提出了UniSLU，一个统一的框架，在单一架构中联合建模多个SLU任务。具体来说，我们为多样化的SLU任务提出了一个统一的表示，以充分利用跨多个任务的异构数据集。在此表示基础上，我们提出了一个统一的生成方法，联合建模ASR、口语NER和SA任务，增强任务交互并实现与大型语言模型的无缝集成，以利用其强大的生成能力。

Result: 我们的方法在公共SLU数据集上进行了广泛的实验，证明了其有效性，相比几种基准方法取得了优越的SLU性能，使其非常适合现实世界的基于语音的多媒体场景。

Conclusion: 我们的方法在公共SLU数据集上进行了广泛的实验，证明了其有效性，相比几种基准方法取得了优越的SLU性能，使其非常适合现实世界的基于语音的多媒体场景。

Abstract: Spoken Language Understanding (SLU) plays a crucial role in speech-centric
multimedia applications, enabling machines to comprehend spoken language in
scenarios such as meetings, interviews, and customer service interactions. SLU
encompasses multiple tasks, including Automatic Speech Recognition (ASR),
spoken Named Entity Recognition (NER), and spoken Sentiment Analysis (SA).
However, existing methods often rely on separate model architectures for
individual tasks such as spoken NER and SA, which increases system complexity,
limits cross-task interaction, and fails to fully exploit heterogeneous
datasets available across tasks. To address these limitations, we propose
UniSLU, a unified framework that jointly models multiple SLU tasks within a
single architecture. Specifically, we propose a unified representation for
diverse SLU tasks, enabling full utilization of heterogeneous datasets across
multiple tasks. Built upon this representation, we propose a unified generative
method that jointly models ASR, spoken NER, and SA tasks, enhancing task
interactions and enabling seamless integration with large language models to
harness their powerful generative capabilities. Extensive experiments on public
SLU datasets demonstrate the effectiveness of our approach, achieving superior
SLU performance compared to several benchmark methods, making it well-suited
for real-world speech-based multimedia scenarios. We will release all code and
models at github to facilitate future research.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [51] [Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities](https://arxiv.org/abs/2507.13019)
*Liuyi Wang,Xinyuan Xia,Hui Zhao,Hanqing Wang,Tai Wang,Yilun Chen,Chengju Liu,Qijun Chen,Jiangmiao Pang*

Main category: cs.RO

TL;DR: This paper introduces VLN-PE, a physically realistic VLN platform, and evaluates several VLN methods in physical robotic settings. The results show significant performance degradation due to physical challenges, but VLN-PE offers a new pathway for improving adaptability.


<details>
  <summary>Details</summary>
Motivation: Recent VLN advancements have idealized assumptions about robot movement and control that fail to reflect physically embodied deployment challenges. We aim to bridge this gap by introducing a physically realistic VLN platform.

Method: We introduce VLN-PE, a physically realistic VLN platform supporting different types of robots. We evaluate several ego-centric VLN methods in physical robotic settings across different technical pipelines.

Result: The results reveal significant performance degradation due to limited robot observation space, environmental lighting variations, and physical challenges like collisions and falls. It also exposes locomotion constraints for legged robots in complex environments.

Conclusion: VLN-PE provides a new pathway for improving cross-embodiment's overall adaptability. The findings and tools hope to inspire the community to rethink VLN limitations and advance robust, practical VLN models.

Abstract: Recent Vision-and-Language Navigation (VLN) advancements are promising, but
their idealized assumptions about robot movement and control fail to reflect
physically embodied deployment challenges. To bridge this gap, we introduce
VLN-PE, a physically realistic VLN platform supporting humanoid, quadruped, and
wheeled robots. For the first time, we systematically evaluate several
ego-centric VLN methods in physical robotic settings across different technical
pipelines, including classification models for single-step discrete action
prediction, a diffusion model for dense waypoint prediction, and a train-free,
map-based large language model (LLM) integrated with path planning. Our results
reveal significant performance degradation due to limited robot observation
space, environmental lighting variations, and physical challenges like
collisions and falls. This also exposes locomotion constraints for legged
robots in complex environments. VLN-PE is highly extensible, allowing seamless
integration of new scenes beyond MP3D, thereby enabling more comprehensive VLN
evaluation. Despite the weak generalization of current models in physical
deployment, VLN-PE provides a new pathway for improving cross-embodiment's
overall adaptability. We hope our findings and tools inspire the community to
rethink VLN limitations and advance robust, practical VLN models. The code is
available at https://crystalsixone.github.io/vln_pe.github.io/.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [52] [Spatially Grounded Explanations in Vision Language Models for Document Visual Question Answering](https://arxiv.org/abs/2507.12490)
*Maximiliano Hormazábal Lagos,Héctor Cerezo-Costas,Dimosthenis Karatzas*

Main category: cs.CV

TL;DR: EaGERS是一个无需训练且与模型无关的管道，通过生成自然语言推理、基于多模态嵌入相似性进行空间子区域定位，并仅从相关区域生成响应，提高了DocVQA的准确性、透明度和可重复性。


<details>
  <summary>Details</summary>
Motivation: 提高DocVQA任务的准确性、透明度和可重复性，同时避免额外的模型微调。

Method: EaGERS通过生成自然语言推理、基于多模态嵌入相似性进行空间子区域定位，并仅从相关区域生成响应来实现目标。

Result: EaGERS在DocVQA数据集上表现出色，优于基础模型，并提高了透明度和可重复性。

Conclusion: EaGERS是一种有效的无需训练且与模型无关的方法，可以提高DocVQA任务的性能和可解释性。

Abstract: We introduce EaGERS, a fully training-free and model-agnostic pipeline that
(1) generates natural language rationales via a vision language model, (2)
grounds these rationales to spatial sub-regions by computing multimodal
embedding similarities over a configurable grid with majority voting, and (3)
restricts the generation of responses only from the relevant regions selected
in the masked image. Experiments on the DocVQA dataset demonstrate that our
best configuration not only outperforms the base model on exact match accuracy
and Average Normalized Levenshtein Similarity metrics but also enhances
transparency and reproducibility in DocVQA without additional model
fine-tuning.

</details>


### [53] [Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal Large Language Models](https://arxiv.org/abs/2507.12566)
*Gen Luo,Wenhan Dou,Wenhao Li,Zhaokai Wang,Xue Yang,Changyao Tian,Hao Li,Weiyun Wang,Wenhai Wang,Xizhou Zhu,Yu Qiao,Jifeng Dai*

Main category: cs.CV

TL;DR: This paper presents Mono-InternVL and Mono-InternVL-1.5, advanced monolithic MLLMs that incorporate visual experts and an improved pre-training strategy (EViP++). These models achieve competitive performance while reducing training and inference costs.


<details>
  <summary>Details</summary>
Motivation: Existing structures and pre-training strategies for monolithic MLLMs often suffer from unstable optimization and catastrophic forgetting. The paper aims to address these challenges by embedding a new visual parameter space into a pre-trained LLM, enabling stable learning of visual knowledge from noisy data via delta tuning.

Method: The paper introduces Mono-InternVL, a monolithic MLLM that incorporates a set of visual experts through a multimodal mixture-of-experts architecture. It also designs an innovative Endogenous Visual Pre-training (EViP) for Mono-InternVL to maximize its visual capabilities. Mono-InternVL-1.5 is a cheaper and stronger version of Mono-InternVL with an improved EViP++ that introduces additional visual attention experts and reorganizes the pre-training process efficiently.

Result: Mono-InternVL outperforms existing monolithic MLLMs on 12 out of 15 benchmarks, including an 114-point improvement over Emu3 on OCRBench. Mono-InternVL-1.5 achieves similar multimodal performance to its modular counterpart, InternVL-1.5, but with up to 69% reduction in first-token latency.

Conclusion: Mono-InternVL-1.5 significantly reduces training and inference costs while maintaining competitive performance with Mono-InternVL. It achieves similar multimodal performance to its modular counterpart, InternVL-1.5, but with reduced first-token latency.

Abstract: This paper focuses on monolithic Multimodal Large Language Models (MLLMs),
which integrate visual encoding and language decoding into a single model.
Existing structures and pre-training strategies for monolithic MLLMs often
suffer from unstable optimization and catastrophic forgetting. To address these
challenges, our key idea is to embed a new visual parameter space into a
pre-trained LLM, enabling stable learning of visual knowledge from noisy data
via delta tuning. Based on this principle, we first introduce Mono-InternVL, an
advanced monolithic MLLM that incorporates a set of visual experts through a
multimodal mixture-of-experts architecture. In addition, we design an
innovative Endogenous Visual Pre-training (EViP) for Mono-InternVL to maximize
its visual capabilities via progressive learning. Mono-InternVL achieves
competitive performance against existing MLLMs but also leads to relatively
expensive data cost. Therefore, we further present Mono-InternVL-1.5, a cheaper
and stronger monolithic MLLM equipped with an improved EViP (EViP++). EViP++
introduces additional visual attention experts to Mono-InternVL-1.5 and
re-organizes the pre-training process in an efficient manner. During inference,
it includes a fused CUDA kernel to speed up its MoE operations. With these
designs, Mono-InternVL-1.5 significantly reduces training and inference costs,
while still maintaining competitive performance with Mono-InternVL. To evaluate
our approach, we conduct extensive experiments across 15 benchmarks. Results
demonstrate that Mono-InternVL outperforms existing monolithic MLLMs on 12 out
of 15 benchmarks, e.g., +114-point improvement over Emu3 on OCRBench. Compared
to its modular counterpart, i.e., InternVL-1.5, Mono-InternVL-1.5 achieves
similar multimodal performance while reducing first-token latency by up to 69%.
Code and models are released at https://github.com/OpenGVLab/Mono-InternVL.

</details>


### [54] [VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning](https://arxiv.org/abs/2507.13348)
*Senqiao Yang,Junyi Li,Xin Lai,Bei Yu,Hengshuang Zhao,Jiaya Jia*

Main category: cs.CV

TL;DR: VisionThink is a new paradigm for visual token compression that dynamically processes samples with different resolutions, improving performance on OCR-related tasks while saving visual tokens on simpler tasks.


<details>
  <summary>Details</summary>
Motivation: Most real-world scenarios do not require an extensive number of visual tokens. While performance drops in some OCR-related tasks, models still perform accurately in most other general VQA tasks with only 1/4 resolution.

Method: VisionThink dynamically processes distinct samples with different resolutions. It starts with a downsampled image and smartly decides whether it is sufficient for problem solving. Otherwise, the model could output a special token to request the higher-resolution image. Reinforcement learning and the LLM-as-Judge strategy are used to apply RL to general VQA tasks.

Result: VisionThink shows strong fine-grained visual understanding capability on OCR-related tasks and saves substantial visual tokens on simpler tasks. The method is proven to be superior, efficient, and effective through extensive experiments.

Conclusion: VisionThink demonstrates strong fine-grained visual understanding capability on OCR-related tasks, and meanwhile saves substantial visual tokens on simpler tasks. The method is superior, efficient, and effective.

Abstract: Recent advancements in vision-language models (VLMs) have improved
performance by increasing the number of visual tokens, which are often
significantly longer than text tokens. However, we observe that most real-world
scenarios do not require such an extensive number of visual tokens. While the
performance drops significantly in a small subset of OCR-related tasks, models
still perform accurately in most other general VQA tasks with only 1/4
resolution. Therefore, we propose to dynamically process distinct samples with
different resolutions, and present a new paradigm for visual token compression,
namely, VisionThink. It starts with a downsampled image and smartly decides
whether it is sufficient for problem solving. Otherwise, the model could output
a special token to request the higher-resolution image. Compared to existing
Efficient VLM methods that compress tokens using fixed pruning ratios or
thresholds, VisionThink autonomously decides whether to compress tokens case by
case. As a result, it demonstrates strong fine-grained visual understanding
capability on OCR-related tasks, and meanwhile saves substantial visual tokens
on simpler tasks. We adopt reinforcement learning and propose the LLM-as-Judge
strategy to successfully apply RL to general VQA tasks. Moreover, we carefully
design a reward function and penalty mechanism to achieve a stable and
reasonable image resize call ratio. Extensive experiments demonstrate the
superiority, efficiency, and effectiveness of our method. Our code is available
at https://github.com/dvlab-research/VisionThink.

</details>
