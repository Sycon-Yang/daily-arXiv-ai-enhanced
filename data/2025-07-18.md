<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 36]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.CC](#cs.CC) [Total: 1]
- [cs.CV](#cs.CV) [Total: 3]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.RO](#cs.RO) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models](https://arxiv.org/abs/2507.12547)
*Lionel Wong,Katherine M. Collins,Lance Ying,Cedegao E. Zhang,Adrian Weller,Tobias Gersternberg,Timothy O'Donnell,Alexander K. Lew,Jacob D. Andreas,Joshua B. Tenenbaum,Tyler Brooke-Wilson*

Main category: cs.CL

TL;DR: This paper proposes a Model Synthesis Architecture (MSA) that uses language models and probabilistic programs to create mental models for novel situations. The MSA outperforms language model-only approaches in capturing human-like reasoning on a new dataset, suggesting a promising path for replicating human reasoning in open-ended domains.


<details>
  <summary>Details</summary>
Motivation: To explore how people draw in globally relevant information and reason coherently about it, we hypothesize that people use a combination of distributed and symbolic representations to construct bespoke mental models tailored to novel situations.

Method: We propose a computational implementation of the idea called a 'Model Synthesis Architecture' (MSA) using language models for global relevance-based retrieval and model synthesis, and probabilistic programs for bespoke, coherent world models.

Result: Our MSA approach captures human judgments better than language model-only baselines, under both direct and chain-of-thought generations from the LM that supports model synthesis.

Conclusion: MSAs can be implemented in a way that mirrors people's ability to deliver locally coherent reasoning over globally relevant variables, offering a path to understanding and replicating human reasoning in open-ended domains.

Abstract: When faced with novel situations, people are able to marshal relevant
considerations from a wide range of background knowledge and put these to use
in inferences and predictions. What permits us to draw in globally relevant
information and reason over it coherently? Here, we explore the hypothesis that
people use a combination of distributed and symbolic representations to
construct bespoke mental models tailored to novel situations. We propose a
computational implementation of this idea -- a ``Model Synthesis Architecture''
(MSA) -- using language models to implement global relevance-based retrieval
and model synthesis and probabilistic programs to implement bespoke, coherent
world models. We evaluate our MSA as a model of human judgments on a novel
reasoning dataset. The dataset -- built around a `Model Olympics` domain of
sports vignettes -- tests models' capacity for human-like, open-ended reasoning
by requiring (i) judgments about novel causal structures described in language;
(ii) drawing on large bodies of background knowledge; and (iii) doing both in
light of observations that introduce arbitrary novel variables. Our MSA
approach captures human judgments better than language model-only baselines,
under both direct and chain-of-thought generations from the LM that supports
model synthesis. These results suggest that MSAs can be implemented in a way
that mirrors people's ability to deliver locally coherent reasoning over
globally relevant variables, offering a path to understanding and replicating
human reasoning in open-ended domains.

</details>


### [2] [Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility](https://arxiv.org/abs/2507.12553)
*Michael A. Lepori,Jennifer Hu,Ishita Dasgupta,Roma Patel,Thomas Serre,Ellie Pavlick*

Main category: cs.CL

TL;DR: 本文通过分析语言模型中的模态差异向量，揭示了它们在模态分类上的潜力，并发现这些向量可以用来建模人类的分类行为。


<details>
  <summary>Details</summary>
Motivation: 尽管语言模型被广泛用于各种任务，但最近的研究质疑了它们对句子模态分类的能力。本文旨在探索语言模型在模态分类上的潜力，并揭示其与人类行为的关联。

Method: 本文通过识别语言模型中的线性表示（即模态差异向量）来分析模态分类能力，并将其与人类参与者对可解释特征的评分进行相关性分析。

Result: 研究发现，语言模型具有比之前报告的更可靠的模态分类判断能力，模态差异向量在模型变得更强大时以一致的顺序出现，并且可以用来建模人类的细粒度分类行为。

Conclusion: 本文通过机制可解释性技术，为语言模型的模态分类提供了新的见解，并可能有助于理解人类的模态分类。

Abstract: Language models (LMs) are used for a diverse range of tasks, from question
answering to writing fantastical stories. In order to reliably accomplish these
tasks, LMs must be able to discern the modal category of a sentence (i.e.,
whether it describes something that is possible, impossible, completely
nonsensical, etc.). However, recent studies have called into question the
ability of LMs to categorize sentences according to modality (Michaelov et al.,
2025; Kauf et al., 2023). In this work, we identify linear representations that
discriminate between modal categories within a variety of LMs, or modal
difference vectors. Analysis of modal difference vectors reveals that LMs have
access to more reliable modal categorization judgments than previously
reported. Furthermore, we find that modal difference vectors emerge in a
consistent order as models become more competent (i.e., through training steps,
layers, and parameter count). Notably, we find that modal difference vectors
identified within LM activations can be used to model fine-grained human
categorization behavior. This potentially provides a novel view into how human
participants distinguish between modal categories, which we explore by
correlating projections along modal difference vectors with human participants'
ratings of interpretable features. In summary, we derive new insights into LM
modal categorization using techniques from mechanistic interpretability, with
the potential to inform our understanding of modal categorization in humans.

</details>


### [3] [The first open machine translation system for the Chechen language](https://arxiv.org/abs/2507.12672)
*Abu-Viskhan A. Umishov,Vladislav A. Grigorian*

Main category: cs.CL

TL;DR: 本文介绍了第一个用于车臣语和俄语之间翻译的开源模型，并收集了用于训练和评估该模型的数据集。


<details>
  <summary>Details</summary>
Motivation: 为了实现车臣语和俄语之间的翻译，需要一个开源模型和相应的数据集。

Method: 本文探索了将新语言纳入多语言翻译NLLB-200大型语言模型系统的微调能力。

Result: 本文提出的模型在从俄语到车臣语和反向翻译中的BLEU/ChrF++得分分别为8.34/34.69和20.89/44.55。

Conclusion: 本文介绍了第一个用于车臣语和俄语之间翻译的开源模型，并收集了用于训练和评估该模型的数据集。

Abstract: We introduce the first open-source model for translation between the
vulnerable Chechen language and Russian, and the dataset collected to train and
evaluate it. We explore fine-tuning capabilities for including a new language
into a large language model system for multilingual translation NLLB-200. The
BLEU / ChrF++ scores for our model are 8.34 / 34.69 and 20.89 / 44.55 for
translation from Russian to Chechen and reverse direction, respectively. The
release of the translation models is accompanied by the distribution of
parallel words, phrases and sentences corpora and multilingual sentence encoder
adapted to the Chechen language.

</details>


### [4] [Improving Drug Identification in Overdose Death Surveillance using Large Language Models](https://arxiv.org/abs/2507.12679)
*Arthur J. Funnell,Panayiotis Petousis,Fabrice Harel-Canada,Ruby Romero,Alex A. T. Bui,Adam Koncsol,Hritika Chaturvedi,Chelsea Shover,David Goodman-Meza*

Main category: cs.CL

TL;DR: 本研究探讨了利用自然语言处理（NLP）模型自动和增强过量用药监测的潜力。通过评估多种NLP方法，包括传统分类器和微调的语言模型，如BioClinicalBERT，发现这些模型在分类特定药物参与方面表现出色，尤其是在内部测试集上取得了接近完美的性能，并在外部验证中保持了稳健性。研究结果表明，NLP模型，特别是微调的临床变体，为从自由文本报告中进行过量死亡分类提供了高度准确且可扩展的解决方案，可以显著加速监测工作流程，克服手动ICD-10编码的局限性，并支持近实时检测新兴物质使用趋势。


<details>
  <summary>Details</summary>
Motivation: The rising rate of drug-related deaths in the United States, largely driven by fentanyl, requires timely and accurate surveillance. However, critical overdose data are often buried in free-text coroner reports, leading to delays and information loss when coded into ICD (International Classification of Disease)-10 classifications. Natural language processing (NLP) models may automate and enhance overdose surveillance, but prior applications have been limited.

Method: Multiple NLP approaches were evaluated for classifying specific drug involvement from unstructured death certificate text. These included traditional single- and multi-label classifiers, as well as fine-tuned encoder-only language models such as Bidirectional Encoder Representations from Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large language models such as Qwen 3 and Llama 3.

Result: Fine-tuned BioClinicalBERT models achieved near-perfect performance, with macro F1 scores >=0.998 on the internal test set. External validation confirmed robustness (macro F1=0.966), outperforming conventional machine learning, general-domain BERT models, and various decoder-only large language models.

Conclusion: NLP models, particularly fine-tuned clinical variants like BioClinicalBERT, offer a highly accurate and scalable solution for overdose death classification from free-text reports. These methods can significantly accelerate surveillance workflows, overcoming the limitations of manual ICD-10 coding and supporting near real-time detection of emerging substance use trends.

Abstract: The rising rate of drug-related deaths in the United States, largely driven
by fentanyl, requires timely and accurate surveillance. However, critical
overdose data are often buried in free-text coroner reports, leading to delays
and information loss when coded into ICD (International Classification of
Disease)-10 classifications. Natural language processing (NLP) models may
automate and enhance overdose surveillance, but prior applications have been
limited. A dataset of 35,433 death records from multiple U.S. jurisdictions in
2020 was used for model training and internal testing. External validation was
conducted using a novel separate dataset of 3,335 records from 2023-2024.
Multiple NLP approaches were evaluated for classifying specific drug
involvement from unstructured death certificate text. These included
traditional single- and multi-label classifiers, as well as fine-tuned
encoder-only language models such as Bidirectional Encoder Representations from
Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large
language models such as Qwen 3 and Llama 3. Model performance was assessed
using macro-averaged F1 scores, and 95% confidence intervals were calculated to
quantify uncertainty. Fine-tuned BioClinicalBERT models achieved near-perfect
performance, with macro F1 scores >=0.998 on the internal test set. External
validation confirmed robustness (macro F1=0.966), outperforming conventional
machine learning, general-domain BERT models, and various decoder-only large
language models. NLP models, particularly fine-tuned clinical variants like
BioClinicalBERT, offer a highly accurate and scalable solution for overdose
death classification from free-text reports. These methods can significantly
accelerate surveillance workflows, overcoming the limitations of manual ICD-10
coding and supporting near real-time detection of emerging substance use
trends.

</details>


### [5] [AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.12695)
*S M Rafiuddin,Sadia Kamal,Mohammed Rakib,Arunkumar Bagavathi,Atriya Sen*

Main category: cs.CL

TL;DR: AdaptiSent is a new framework for Multimodal Aspect-Based Sentiment Analysis that improves sentiment classification and aspect term extraction using adaptive cross-modal attention mechanisms, showing superior performance on standard Twitter datasets.


<details>
  <summary>Details</summary>
Motivation: The paper aims to improve sentiment classification and aspect term extraction by better understanding the interaction between textual cues and visual context in multimodal data.

Method: AdaptiSent uses adaptive cross-modal attention mechanisms, dynamic modality weighting, and context-adaptive attention to enhance sentiment classification and aspect term extraction from both text and images.

Result: AdaptiSent surpasses existing models in precision, recall, and F1 score, particularly in identifying nuanced inter-modal relationships crucial for accurate sentiment and aspect term extraction.

Conclusion: AdaptiSent sets a new standard for MABSA, significantly outperforming current methods, especially in understanding complex multimodal information.

Abstract: We introduce AdaptiSent, a new framework for Multimodal Aspect-Based
Sentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms
to improve sentiment classification and aspect term extraction from both text
and images. Our model integrates dynamic modality weighting and
context-adaptive attention, enhancing the extraction of sentiment and
aspect-related information by focusing on how textual cues and visual context
interact. We tested our approach against several baselines, including
traditional text-based models and other multimodal methods. Results from
standard Twitter datasets show that AdaptiSent surpasses existing models in
precision, recall, and F1 score, and is particularly effective in identifying
nuanced inter-modal relationships that are crucial for accurate sentiment and
aspect term extraction. This effectiveness comes from the model's ability to
adjust its focus dynamically based on the context's relevance, improving the
depth and accuracy of sentiment analysis across various multimodal data sets.
AdaptiSent sets a new standard for MABSA, significantly outperforming current
methods, especially in understanding complex multimodal information.

</details>


### [6] [AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation](https://arxiv.org/abs/2507.12705)
*Potsawee Manakul,Woody Haosheng Gan,Michael J. Ryan,Ali Sartaz Khan,Warit Sirichotedumrong,Kunat Pipatanakul,William Held,Diyi Yang*

Main category: cs.CL

TL;DR: 本研究提出了一种基于大型音频模型的统一评估框架AudioJudge，用于解决当前语音评估中的两个关键问题。通过多方面集成的AudioJudge，实现了对语音评估的通用性，并在系统排名基准上取得了与人类偏好高度相关的成果。然而，LAM在声学噪声下仍需注意其冗长性和位置偏差问题。


<details>
  <summary>Details</summary>
Motivation: 当前语音评估存在两个关键限制：需要设计针对特定音频特性的专用系统，以及自动评估方法与人类偏好之间的相关性较差。因此，本研究旨在探索一种统一的评估框架，以解决这些问题。

Method: 本研究系统地探索了AudioJudge在音频特征检测任务（包括发音、语速、说话人识别和语音质量）以及系统级人类偏好模拟中的应用。研究还探讨了不同的提示工程策略，发现音频拼接结合上下文学习显著提高了性能。此外，引入了一个多方面集成的AudioJudge，将语音评估分解为专门的判断者，分别处理词汇内容、语音质量和副语言特征。

Result: AudioJudge在音频特征检测和人类偏好模拟任务中表现出色，特别是在系统排名基准上，其Spearman相关系数高达0.91。同时，研究发现LAM在声学噪声下表现良好，但存在显著的冗长性和位置偏差问题。

Conclusion: 本研究提出了一种基于大型音频模型（LAM）的统一评估框架AudioJudge，能够解决当前语音评估中的两个关键问题。通过多方面集成的AudioJudge，实现了对语音评估的通用性，并在系统排名基准上取得了与人类偏好高度相关的成果。然而，LAM在声学噪声下仍需注意其冗长性和位置偏差问题。

Abstract: Current speech evaluation suffers from two critical limitations: the need and
difficulty of designing specialized systems targeting individual audio
characteristics, and poor correlation between automatic evaluation methods and
human preferences. This work presents a systematic study of Large Audio Model
(LAM) as a Judge, AudioJudge, investigating whether it can provide a unified
evaluation framework that addresses both challenges. We systematically explore
AudioJudge across audio characteristic detection tasks, including
pronunciation, speaking rate, speaker identification and speech quality, and
system-level human preference simulation for automated benchmarking. We
investigate different prompt engineering strategies, finding that audio
concatenation combined with in-context learning significantly improves
performance across both audio characteristic detection and human preference
simulation tasks. We further introduce a multi-aspect ensemble AudioJudge to
enable general-purpose multi-aspect audio evaluation. This method decomposes
speech assessment into specialized judges for lexical content, speech quality,
and paralinguistic features, achieving up to 0.91 Spearman correlation with
human preferences on our system ranking benchmark. Robustness analysis reveals
that while LAMs maintain strong performance under acoustic noise, they exhibit
significant verbosity and positional biases that require careful mitigation.

</details>


### [7] [FLEXITOKENS: Flexible Tokenization for Evolving Language Models](https://arxiv.org/abs/2507.12720)
*Abraham Toluase Owodunni,Orevaoghene Ahia,Sachin Kumar*

Main category: cs.CL

TL;DR: 本文提出了一种名为FLEXITOKENS的新方法，通过使用可学习的分词器来提高语言模型在新数据分布上的适应能力，从而减少了令牌过度碎片化并提升了下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有的无分词器方法使用辅助损失来强制在整个训练语料库中保持固定的压缩率，这引入了一种新的刚性。因此，需要一种更灵活的方法来适应新数据分布。

Method: 开发了具有可学习分词器的字节级语言模型，其中包含一个子模块，该模块学习预测输入字节序列之间的边界，将其编码为可变长度的段。提出了FLEXITOKENS，一种简化的训练目标，以在适应过程中实现更大的灵活性。

Result: FLEXITOKENS在多个多语言基准测试、形态多样任务和领域中表现出色，能够显著减少令牌过度碎片化，并在下游任务性能上相比子词和其他基于梯度的分词器提高了高达10%。

Conclusion: FLEXITOKENS在多个多语言基准测试、形态多样任务和领域中表现出色，能够显著减少令牌过度碎片化，并在下游任务性能上相比子词和其他基于梯度的分词器提高了高达10%。

Abstract: Language models (LMs) are challenging to adapt to new data distributions by
simple finetuning. This is due to the rigidity of their subword tokenizers,
which typically remain unchanged during adaptation. This inflexibility often
leads to inefficient tokenization, causing overfragmentation of
out-of-distribution domains, unseen languages, or scripts. In this work, we
develop byte-level LMs with learnable tokenizers to make tokenization adaptive.
Our models include a submodule that learns to predict boundaries between the
input byte sequence, encoding it into variable-length segments. Existing
tokenizer-free methods train this boundary predictor using an auxiliary loss
that enforces a fixed compression rate across the training corpus, introducing
a new kind of rigidity. We propose FLEXITOKENS, a simplified training objective
that enables significantly greater flexibility during adaptation. Evaluating
across multiple multilingual benchmarks, morphologically diverse tasks, and
domains, we demonstrate that FLEXITOKENS consistently reduces token
over-fragmentation and achieves up to 10\% improvements on downstream task
performance compared to subword and other gradient-based tokenizers. Code and
data for our experiments will be released at
https://github.com/owos/flexitokens

</details>


### [8] [TransEvalnia: Reasoning-based Evaluation and Ranking of Translations](https://arxiv.org/abs/2507.12724)
*Richard Sproat,Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: TransEvalnia是一个基于提示的翻译评估和排名系统，能够提供细粒度的评估，并在多个语言对上表现优异。其评估结果得到人类评分者的认可，且与其他LLM的评分相关性良好。


<details>
  <summary>Details</summary>
Motivation: 现有的翻译评估系统可能无法充分捕捉翻译质量的多维特性，因此需要一种更细致、更准确的评估方法。

Method: TransEvalnia使用基于提示的方法进行翻译评估和排名，利用推理来执行评估。它基于Multidimensional Quality Metrics的一个子集进行细粒度评估，并返回最佳翻译的评估以及各个维度和总体翻译的数值分数。

Result: TransEvalnia在多个语言对上表现出色，其评估结果得到人类评分者的高度认可，并且与其他LLM的评分具有良好的相关性。此外，系统对翻译呈现顺序敏感，并提出了应对位置偏差的方法。

Conclusion: TransEvalnia是一个有效的翻译评估和排名系统，能够提供细粒度的评估，并且在多个语言对上表现优于或与最先进的MT-Ranker相当。此外，该系统的评估结果得到了人类评分者的高度认可，且与其他LLM的评分具有良好的相关性。

Abstract: We present TransEvalnia, a prompting-based translation evaluation and ranking
system that uses reasoning in performing its evaluations and ranking. This
system presents fine-grained evaluations based on a subset of the
Multidimensional Quality Metrics (https://themqm.org/), returns an assessment
of which translation it deems the best, and provides numerical scores for the
various dimensions and for the overall translation. We show that TransEvalnia
performs as well as or better than the state-of-the-art MT-Ranker (Moosa et al.
2024) on our own English-Japanese data as well as several language pairs from
various WMT shared tasks. Using Anthropic's Claude-3.5-Sonnet and
Qwen-2.5-72B-Instruct as the evaluation LLMs, we show that the evaluations
returned are deemed highly acceptable to human raters, and that the scores
assigned to the translations by Sonnet, as well as other LLMs, correlate well
with scores assigned by the human raters. We also note the sensitivity of our
system -- as well as MT-Ranker -- to the order in which the translations are
presented, and we propose methods to address this position bias. All data,
including the system's evaluation and reasoning, human assessments, as well as
code is released.

</details>


### [9] [Strategy Adaptation in Large Language Model Werewolf Agents](https://arxiv.org/abs/2507.12732)
*Fuya Nakamori,Yin Jou Huang,Fei Cheng*

Main category: cs.CL

TL;DR: 本研究提出了一种基于游戏上下文和玩家角色估计的狼人杀代理人策略适应方法，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 先前的狼人杀代理人研究使用提示工程，采用隐式定义有效策略的方法，但无法适应变化的情况。

Method: 本研究提出了一种显式选择适当策略的方法，基于游戏上下文和对其他玩家角色的估计。

Result: 比较了策略适应的狼人杀代理人与使用隐式或固定策略的基线代理人，并验证了所提出方法的有效性。

Conclusion: 本研究提出了一种方法，通过根据其他玩家的态度和对话背景在预定义策略之间切换来提高狼人杀代理人的性能。

Abstract: This study proposes a method to improve the performance of Werewolf agents by
switching between predefined strategies based on the attitudes of other players
and the context of conversations. While prior works of Werewolf agents using
prompt engineering have employed methods where effective strategies are
implicitly defined, they cannot adapt to changing situations. In this research,
we propose a method that explicitly selects an appropriate strategy based on
the game context and the estimated roles of other players. We compare the
strategy adaptation Werewolf agents with baseline agents using implicit or
fixed strategies and verify the effectiveness of our proposed method.

</details>


### [10] [Logit Arithmetic Elicits Long Reasoning Capabilities Without Training](https://arxiv.org/abs/2507.12759)
*Yunxiang Zhang,Muhammad Khalifa,Lechen Zhang,Xin Liu,Ayoung Lee,Xinliang Frederick Zhang,Farima Fatahi Bayat,Lu Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为ThinkLogit的方法，利用较小的模型作为引导者，以计算效率高的方式激发大型模型的长期推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究是否可以在不进行任何训练的情况下激发模型的这种行为。

Method: 我们提出了一个解码时间的方法，ThinkLogit，利用logits算术来调整目标大型语言模型，使用一个较小的模型作为引导者。此外，我们还通过在正确/错误推理对上进行偏好优化来训练引导模型，这种方法称为ThinkLogit-DPO。

Result: ThinkLogit和ThinkLogit-DPO在四个数学数据集上分别实现了26%和29%的pass@1相对改进，并且ThinkLogit可以转移通过强化学习获得的长期推理技能，相对于Qwen2.5-32B基础模型提高了13%的pass@1。

Conclusion: 我们的工作提出了一种计算效率高的方法，在无需额外训练的情况下激发大型模型的长期推理能力。

Abstract: Large reasoning models (LRMs) can do complex reasoning via long
chain-of-thought (CoT) involving cognitive strategies such as backtracking and
self-correction. Recent studies suggest that some models inherently possess
these long reasoning abilities, which may be unlocked via extra training. Our
work first investigates whether we can elicit such behavior without any
training. To this end, we propose a decoding-time approach, ThinkLogit, which
utilizes logits arithmetic (Liu et al., 2024) to tune a target large LM for
long reasoning using a substantially smaller model as guider. We then show that
we can further boost performance by training the guider model with preference
optimization over correct/incorrect reasoning pairs sampled from both the
target and guider model -- a setup we refer to as ThinkLogit-DPO. Our
experiments demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative
improvement in pass@1 by 26% and 29%, respectively, over four mathematical
datasets using the Qwen2.5-32B when guided by R1-Distill-Qwen-1.5B -- a model
21x smaller. Lastly, we show that ThinkLogit can transfer long reasoning skills
acquired through reinforcement learning, improving pass@1 by 13% relative
compared to the Qwen2.5-32B base model. Our work presents a
computationally-efficient method to elicit long reasoning in large models with
minimal or no additional training.

</details>


### [11] [Synergy: End-to-end Concept Model](https://arxiv.org/abs/2507.12769)
*Keli Zheng,Zerong Xie*

Main category: cs.CL

TL;DR: 本文介绍了Synergy，一种通过学习的路由机制在端到端方式下弥合不同抽象层次的语言模型。该模型作为字节级语言模型进行训练，自发学习对字节进行分词，产生比BBPE分词器更少的概念标记，同时保持相当的性能。与Llama3相比，在相同的模型规模和训练数据集大小下，Synergy表现出优势。进一步的研究表明，当移除位置编码时，模型的中间部分（更高抽象部分）表现更好，这表明出现了与位置无关的概念。这些发现证明了无需分词器的架构的可行性，为更稳健和灵活的流程铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 本文旨在通过一种学习的路由机制，弥合不同抽象层次的差异，并探索无需分词器的架构的可行性。

Method: 我们通过一种学习的路由机制，在端到端的方式下弥合了不同抽象层次的差异。我们训练模型作为字节级语言模型，并自发地学习对字节进行分词，产生比BBPE分词器更少的概念标记，同时保持相当的性能。

Result: 与Llama3相比，在相同的模型规模和训练数据集大小下，Synergy表现出优势。进一步的研究表明，当移除位置编码时，模型的中间部分（更高抽象部分）表现更好，这表明出现了与位置无关的概念。

Conclusion: 这些发现证明了无需分词器的架构的可行性，为更稳健和灵活的流程铺平了道路。

Abstract: In this paper, we present Synergy, a language model that bridges different
levels of abstraction in an end-to-end fashion through a learned routing
mechanism. Focusing on low-level linguistic abstraction, we trained our model
as a byte-level language model. Our model spontaneously learns to tokenize
bytes, producing fewer concept tokens than Byte-level Byte Pair Encoder (BBPE)
tokenizers while keeping comparable performance. By comparing with Llama3, we
observed an advantage of Synergy under the same model scale and training
dataset size. Further studies show that the middle part (the higher abstraction
part) of our model performs better when positional encodings are removed,
suggesting the emergence of position-independent concepts. These findings
demonstrate the feasibility of tokenizer-free architectures, paving the way for
more robust and flexible pipelines.

</details>


### [12] [Learning Robust Negation Text Representations](https://arxiv.org/abs/2507.12782)
*Thinh Hung Truong,Karin Verspoor,Trevor Cohn,Timothy Baldwin*

Main category: cs.CL

TL;DR: 本文提出了一种通过从大型语言模型中蒸馏数据来提高文本编码器否定鲁棒性的策略，并展示了该方法在保持一般性能的同时显著提升了否定理解能力，同时也可以适应大型语言模型以改善否定基准的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管自回归大语言模型被迅速采用，但较小的文本编码器在需要丰富上下文表示的文本理解任务中仍然起着重要作用。否定是一个重要的语义功能，目前仍未能被这些方法正确捕捉，影响了许多依赖于文本嵌入的下游应用。

Method: 我们提出了一种策略，通过使用多样化的否定和犹豫模式从大型语言模型中蒸馏数据，以提高文本编码器的否定鲁棒性。我们采用标准的对比学习策略微调了一个基于BERT的强模型。

Result: 我们观察到在保持一般基准上的竞争力的同时，文本编码器的否定理解能力有了显著提升。此外，我们的方法还可以适应大型语言模型，从而在否定基准上取得更好的性能。

Conclusion: 我们的方法可以提高文本编码器对否定的理解能力，并且可以在大型语言模型上进行适应，从而在否定基准上取得更好的性能。

Abstract: Despite rapid adoption of autoregressive large language models, smaller text
encoders still play an important role in text understanding tasks that require
rich contextualized representations. Negation is an important semantic function
that is still not properly captured by such methods, affecting many downstream
applications relying on text embeddings. We propose a strategy to improve
negation robustness of text encoders, by distilling data from large language
models using diverse patterns of negation and hedging. We adopt a standard
contrastive learning strategy to finetune a strong BERT-based model, and
observe large improvement in negation understanding capabilities while
maintaining competitive performance on general benchmarks. In addition, we also
show that our method can be adapted to LLMs, leading to improved performance on
negation benchmarks.

</details>


### [13] [Large Language Models' Internal Perception of Symbolic Music](https://arxiv.org/abs/2507.12808)
*Andrew Shin,Kunitake Kaneko*

Main category: cs.CL

TL;DR: This paper explores how LLMs can generate and understand symbolic music from text, showing their potential and limitations in encoding musical patterns.


<details>
  <summary>Details</summary>
Motivation: To investigate how LLMs represent musical concepts and evaluate their utility in symbolic music tasks without relying on explicit musical training.

Method: We generate symbolic music data from textual prompts describing combinations of genres and styles, and evaluate their utility through recognition and generation tasks. We also train neural networks on this LLM-generated MIDI dataset and perform genre and style classification as well as melody completion.

Result: Our results demonstrate that LLMs can infer rudimentary musical structures and temporal relationships from text, but they have limitations due to a lack of explicit musical context.

Conclusion: LLMs can infer rudimentary musical structures and temporal relationships from text, highlighting both their potential to implicitly encode musical patterns and their limitations due to a lack of explicit musical context.

Abstract: Large language models (LLMs) excel at modeling relationships between strings
in natural language and have shown promise in extending to other symbolic
domains like coding or mathematics. However, the extent to which they
implicitly model symbolic music remains underexplored. This paper investigates
how LLMs represent musical concepts by generating symbolic music data from
textual prompts describing combinations of genres and styles, and evaluating
their utility through recognition and generation tasks. We produce a dataset of
LLM-generated MIDI files without relying on explicit musical training. We then
train neural networks entirely on this LLM-generated MIDI dataset and perform
genre and style classification as well as melody completion, benchmarking their
performance against established models. Our results demonstrate that LLMs can
infer rudimentary musical structures and temporal relationships from text,
highlighting both their potential to implicitly encode musical patterns and
their limitations due to a lack of explicit musical context, shedding light on
their generative capabilities for symbolic music.

</details>


### [14] [Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?](https://arxiv.org/abs/2507.12838)
*Xi Ai,Mahardika Krisna Ihsani,Min-Yen Kan*

Main category: cs.CL

TL;DR: 本文研究了跨语言一致性的重要性，并通过分析代码混合的核心指代陈述和使用可解释性方法来探讨多语言模型的行为。研究发现，多语言模型在跨语言一致性方面存在差异，并且代码切换训练和跨语言词对齐目标显示出良好的效果。


<details>
  <summary>Details</summary>
Motivation: 跨语言一致性对于评估跨语言可转移性、保持模型知识的真实性以及保持语言模型性能的平衡非常重要。

Method: 本文通过分析代码混合的核心指代陈述来研究跨语言知识的一致性，并使用一些可解释性方法来分析模型在跨语言环境中的行为。

Result: 研究发现，多语言模型在跨语言一致性方面表现出不同的水平，受语言家族、语言因素以及特定层上的瓶颈影响。此外，代码切换训练和跨语言词对齐目标显示出最令人瞩目的结果。

Conclusion: 本文认为，跨语言一致性对于评估跨语言可转移性、保持模型知识的真实性以及保持语言模型性能的平衡非常重要。此外，本文强调了跨语言对齐监督和代码切换训练在提升多语言性能和跨语言一致性方面的价值。

Abstract: Cross-lingual consistency should be considered to assess cross-lingual
transferability, maintain the factuality of the model knowledge across
languages, and preserve the parity of language model performance. We are thus
interested in analyzing, evaluating, and interpreting cross-lingual consistency
for factual knowledge. We examine code-mixed coreferential statements conveyed
identical knowledge across languages to study cross-lingual knowledge
consistency. We use some interpretability approaches to analyze the behavior of
a model in cross-lingual contexts, discovering that multilingual models show
different levels of consistency, subject to language families, linguistic
factors, and a bottleneck in cross-lingual consistency on a particular layer.
In addition, we evaluate common strategies aimed at improving multilingual
performance to observe whether these strategies can improve knowledge
consistency at the same time. While knowledge is not cross-lingual consistency
in many cases, code-switching training and cross-lingual word alignment
objectives show the most promising results, emphasizing the noteworthiness of
cross-lingual alignment supervision and code-switching training for both
multilingual performance and cross-lingual consistency enhancement.

</details>


### [15] [Making Language Model a Hierarchical Classifier and Generator](https://arxiv.org/abs/2507.12930)
*Yihong Wang,Zhonglin Jiang,Ningyuan Xi,Yue Zhao,Qingqing Gu,Xiyuan Chen,Hao Wu,Sheng Xu,Hange Zhou,Yong Chen,Luo Ji*

Main category: cs.CL

TL;DR: 本研究提出了一种分层解码器架构，通过将预训练语言模型的最后层的语言头复制到不同的中间层并进行微调，实现了在多个任务上的先进性能。


<details>
  <summary>Details</summary>
Motivation: 受人类分层思维能力的启发，提出分层解码器架构可以同时解码文本。

Method: 将预训练语言模型的最后层的语言头复制到不同的中间层，并使用不同的任务输入进行微调，以构建分层解码器架构。

Result: 实验表明，这些选择的中间层可以生成有意义且合理的文本内容，这种分层解码范式在多个任务上取得了最先进的性能。

Conclusion: 本研究表明，通过将预训练语言模型的最后层的语言头复制到不同的中间层并进行微调，可以构建一种分层解码器架构，从而在多个任务上获得最先进的性能。这表明从零开始预训练一个通用的分层推理器是可能的。

Abstract: Decoder-only language models, such as GPT and LLaMA, generally decode on the
last layer. Motivated by human's hierarchical thinking capability, we propose
that a hierarchical decoder architecture could be built with different layers
decoding texts simultaneously. Due to limited time and computationally
resources, we choose to adapt a pretrained language model into this form of
hierarchical decoder. Language heads of the last layer are copied to different
selected intermediate layers, and fine-tuned with different task inputs. By
thorough experiments, we validate that these selective intermediate layers
could be adapted to speak meaningful and reasonable contents, and this paradigm
of hierarchical decoder can obtain state-of-the-art performances on multiple
tasks such as hierarchical text classification, classification-guided
generation, and hierarchical text generation. This study suggests the
possibility of a generalized hierarchical reasoner, pretraining from scratch.

</details>


### [16] [MRT at IberLEF-2025 PRESTA Task: Maximizing Recovery from Tables with Multiple Steps](https://arxiv.org/abs/2507.12981)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Héctor Cerezo-Costas,Pedro Alonso Doval,Jorge Alcalde Vesteiro*

Main category: cs.CL

TL;DR: 本文提出了一种基于LLMs的解决方案，用于回答关于西班牙语表格的问题，并在任务中取得了85%的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决关于西班牙语表格的问题，特别是在IberLEF 2025任务PRESTA中。

Method: 通过实现Python代码生成与LLMs结合，用于过滤和处理表格中的数据。

Result: 实现了85%的准确率。

Conclusion: 通过这种方法，我们在任务中获得了85%的准确率。

Abstract: This paper presents our approach for the IberLEF 2025 Task PRESTA: Preguntas
y Respuestas sobre Tablas en Espa\~nol (Questions and Answers about Tables in
Spanish). Our solution obtains answers to the questions by implementing Python
code generation with LLMs that is used to filter and process the table. This
solution evolves from the MRT implementation for the Semeval 2025 related task.
The process consists of multiple steps: analyzing and understanding the content
of the table, selecting the useful columns, generating instructions in natural
language, translating these instructions to code, running it, and handling
potential errors or exceptions. These steps use open-source LLMs and
fine-grained optimized prompts for each step. With this approach, we achieved
an accuracy score of 85\% in the task.

</details>


### [17] [Formalizing Attack Scenario Description: A Proposed Model](https://arxiv.org/abs/2507.13076)
*Quentin Goux,Nadira Lammari*

Main category: cs.CL

TL;DR: 本文提出了一种新的形式化模型，用于描述攻击的上下文和场景，并通过UML类模型进行抽象。该模型可用于攻击分析过程和自动生成攻击脚本，以支持网络安全培训。


<details>
  <summary>Details</summary>
Motivation: 组织面临不断变化的威胁环境，需要持续努力保护资产，因此采用更多的网络安全自动化是不可避免的。然而，流程自动化需要输入数据的正式化。本文旨在解决使用攻击场景作为输入的过程中的需求。

Method: 本文提出了一种新的形式化模型，通过UML类模型抽象攻击的上下文和场景。

Result: 该模型可以用于上游攻击分析过程以及自动生成功能攻击脚本，以支持网络安全培训。

Conclusion: 本文的主要研究贡献是提出了一种新的形式化模型，能够涵盖攻击的上下文描述和场景，并展示了其在攻击分析和自动攻击脚本生成中的应用。

Abstract: Organizations face an ever-changing threat landscape. They must continuously
dedicate significant efforts to protect their assets, making their adoption of
increased cybersecurity automation inevitable. However, process automation
requires formalization of input data. Through this paper, we address this need
for processes that use attack scenarios as input. Among these processes, one
can mention both the generation of scripts for attack simulation and training
purposes, as well as the analysis of attacks. Therefore, the paper's main
research contribution is a novel formal model that encompasses the attack's
context description and its scenario. It is abstracted using UML class model.
Once the description of our model done, we will show how it could serve an
upstream attack analysis process. We will show also its use for an automatic
generation of attack scripts in the context of cybersecurity training. These
two uses cases constitute the second contribution of this present research
work.

</details>


### [18] [SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts](https://arxiv.org/abs/2507.13105)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

TL;DR: SemCSE是一种无监督方法，通过利用大语言模型生成的摘要来训练模型，以捕捉科学文本的真实语义内容，并在基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统基于引用的方法不一定反映语义相似性，因此需要一种能够捕捉文本真实语义内容的方法。

Method: SemCSE是一种无监督方法，利用大语言模型生成的科学摘要来训练模型，使语义相关的摘要在嵌入空间中更接近。

Result: SemCSE在SciRepEval基准测试中取得了最先进的性能，证明了其在科学文本嵌入任务中的有效性。

Conclusion: SemCSE在科学文本嵌入任务中表现出色，展示了语义聚焦训练方法的优势。

Abstract: We introduce SemCSE, an unsupervised method for learning semantic embeddings
of scientific texts. Building on recent advances in contrastive learning for
text embeddings, our approach leverages LLM-generated summaries of scientific
abstracts to train a model that positions semantically related summaries closer
together in the embedding space. This resulting objective ensures that the
model captures the true semantic content of a text, in contrast to traditional
citation-based approaches that do not necessarily reflect semantic similarity.
To validate this, we propose a novel benchmark designed to assess a model's
ability to understand and encode the semantic content of scientific texts,
demonstrating that our method enforces a stronger semantic separation within
the embedding space. Additionally, we evaluate SemCSE on the comprehensive
SciRepEval benchmark for scientific text embeddings, where it achieves
state-of-the-art performance among models of its size, thus highlighting the
benefits of a semantically focused training approach.

</details>


### [19] [A Computational Framework to Identify Self-Aspects in Text](https://arxiv.org/abs/2507.13115)
*Jaya Caporusso,Matthew Purver,Senja Pollak*

Main category: cs.CL

TL;DR: 该论文提案提出开发一个计算框架，用于识别文本中的自我方面，并评估不同NLP方法在心理健康和经验现象学中的应用效果。


<details>
  <summary>Details</summary>
Motivation: 自我是一个多方面的构造，在语言中有所体现，但在自然语言处理（NLP）中仍研究不足。许多自我方面与心理和其他已深入研究的现象相关，因此需要系统性的NLP分析。

Method: 论文计划引入自我方面的本体论和标准标注数据集，并使用传统判别模型、生成式大语言模型和基于嵌入的检索方法进行评估。

Result: 论文将评估不同方法在四个主要标准下的表现：可解释性、真实数据适应性、准确性和计算效率，并将表现最佳的模型应用于心理健康和经验现象学的案例研究。

Conclusion: 该论文提案旨在开发一个计算框架，以识别文本中的自我方面，并通过案例研究在心理健康和经验现象学中应用表现最佳的模型。

Abstract: This Ph.D. proposal introduces a plan to develop a computational framework to
identify Self-aspects in text. The Self is a multifaceted construct and it is
reflected in language. While it is described across disciplines like cognitive
science and phenomenology, it remains underexplored in natural language
processing (NLP). Many of the aspects of the Self align with psychological and
other well-researched phenomena (e.g., those related to mental health),
highlighting the need for systematic NLP-based analysis. In line with this, we
plan to introduce an ontology of Self-aspects and a gold-standard annotated
dataset. Using this foundation, we will develop and evaluate conventional
discriminative models, generative large language models, and embedding-based
retrieval approaches against four main criteria: interpretability, ground-truth
adherence, accuracy, and computational efficiency. Top-performing models will
be applied in case studies in mental health and empirical phenomenology.

</details>


### [20] [Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation](https://arxiv.org/abs/2507.13138)
*Hadi Mohammadi,Tina Shahedi,Pablo Mosteiro,Massimo Poesio,Ayoub Bagheri,Anastasia Giachanou*

Main category: cs.CL

TL;DR: 本研究分析了标注者人口统计特征对标注决策的影响，并评估了生成式AI模型作为标注者的可靠性。结果表明，内容是主要影响因素，而使用人口统计角色提示并未有效提升性能。


<details>
  <summary>Details</summary>
Motivation: 理解注释中变异的来源对于开发公平的自然语言处理系统至关重要，特别是在像性别歧视检测这样的任务中，人口统计偏差是一个关注点。

Method: 本文使用广义线性混合模型来量化标注者人口统计特征对标注决策的影响，并评估生成式AI（GenAI）模型作为标注者的可靠性，同时探讨了使用人口统计学角色提示是否能提高与人类判断的一致性。

Result: 研究发现，尽管统计上存在影响，但人口统计因素仅占观察到的方差的8%，而推文内容是主要因素。此外，简单的角色提示通常无法提高性能，有时甚至会降低性能。解释性AI（XAI）技术显示，模型预测主要依赖于与性别歧视相关的特定内容标记，而不是人口统计特征的关联。

Conclusion: 本文认为，专注于内容驱动的解释和稳健的注释协议比潜在的人格模拟更能可靠地实现公平性。

Abstract: Understanding the sources of variability in annotations is crucial for
developing fair NLP systems, especially for tasks like sexism detection where
demographic bias is a concern. This study investigates the extent to which
annotator demographic features influence labeling decisions compared to text
content. Using a Generalized Linear Mixed Model, we quantify this inf luence,
finding that while statistically present, demographic factors account for a
minor fraction ( 8%) of the observed variance, with tweet content being the
dominant factor. We then assess the reliability of Generative AI (GenAI) models
as annotators, specifically evaluating if guiding them with demographic
personas improves alignment with human judgments. Our results indicate that
simplistic persona prompting often fails to enhance, and sometimes degrades,
performance compared to baseline models. Furthermore, explainable AI (XAI)
techniques reveal that model predictions rely heavily on content-specific
tokens related to sexism, rather than correlates of demographic
characteristics. We argue that focusing on content-driven explanations and
robust annotation protocols offers a more reliable path towards fairness than
potentially persona simulation.

</details>


### [21] [Feature-based analysis of oral narratives from Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13164)
*Emma Sharratt,Annelien Smith,Retief Louw,Daleen Klop,Febe de Wet,Herman Kamper*

Main category: cs.CL

TL;DR: 该研究通过分析四岁和五岁儿童的口头叙述，发现了语言特定和共享的叙事能力预测因素，对多语言环境下的早期评估有重要启示。


<details>
  <summary>Details</summary>
Motivation: 研究旨在识别需要干预的儿童的口头叙述特征，并探索语言特定和共享的预测因素。

Method: 使用简单的机器学习方法分析四岁和五岁阿非利堪语和科萨语儿童的录音故事。

Result: 词汇多样性（独特单词）和长度相关特征（平均话语长度）是典型发展的指标，而发音速度等特征则不太有信息量。特定动词和助动词的使用与较少需要干预的可能性相关。

Conclusion: 研究揭示了语言特定和共享的叙事能力预测因素，对多语言环境下的早期评估具有重要意义。

Abstract: Oral narrative skills are strong predictors of later literacy development.
This study examines the features of oral narratives from children who were
identified by experts as requiring intervention. Using simple machine learning
methods, we analyse recorded stories from four- and five-year-old Afrikaans-
and isiXhosa-speaking children. Consistent with prior research, we identify
lexical diversity (unique words) and length-based features (mean utterance
length) as indicators of typical development, but features like articulation
rate prove less informative. Despite cross-linguistic variation in
part-of-speech patterns, the use of specific verbs and auxiliaries associated
with goal-directed storytelling is correlated with a reduced likelihood of
requiring intervention. Our analysis of two linguistically distinct languages
reveals both language-specific and shared predictors of narrative proficiency,
with implications for early assessment in multilingual contexts.

</details>


### [22] [GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems](https://arxiv.org/abs/2507.13190)
*Jisoo Lee,Raeyoung Chang,Dongwook Kwon,Harmanpreet Singh,Nikhil Verma*

Main category: cs.CL

TL;DR: 本文介绍了GEMMAS，一个基于图的评估框架，用于分析多智能体系统的内部协作过程，并提出了两个过程级度量来评估协作质量。评估结果显示，仅基于结果的度量不足以评估多智能体性能，强调了过程级诊断的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有评估仅关注最终输出的正确性，忽视了低效通信和不良协调导致的冗余推理和更高计算成本的问题。

Method: 引入了GEMMAS，这是一个基于图的评估框架，通过将智能体交互建模为有向无环图来分析内部协作过程。提出了两个过程级度量：信息多样性得分（IDS）和不必要的路径比率（UPR）。

Result: 在五个基准测试中评估了GEMMAS，并在GSM8K上突出显示结果，其中准确率仅有2.1%差异的系统在IDS上相差12.8%，在UPR上相差80%，揭示了内部协作的显著变化。

Conclusion: 结果表明，仅基于结果的度量不足以评估多智能体性能，并强调了过程级诊断在设计更可解释和资源高效的协作AI系统中的重要性。

Abstract: Multi-agent systems built on language models have shown strong performance on
collaborative reasoning tasks. However, existing evaluations focus only on the
correctness of the final output, overlooking how inefficient communication and
poor coordination contribute to redundant reasoning and higher computational
costs. We introduce GEMMAS, a graph-based evaluation framework that analyzes
the internal collaboration process by modeling agent interactions as a directed
acyclic graph. To capture collaboration quality, we propose two process-level
metrics: Information Diversity Score (IDS) to measure semantic variation in
inter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant
reasoning paths. We evaluate GEMMAS across five benchmarks and highlight
results on GSM8K, where systems with only a 2.1% difference in accuracy differ
by 12.8% in IDS and 80% in UPR, revealing substantial variation in internal
collaboration. These findings demonstrate that outcome-only metrics are
insufficient for evaluating multi-agent performance and highlight the
importance of process-level diagnostics in designing more interpretable and
resource-efficient collaborative AI systems.

</details>


### [23] [Automatically assessing oral narratives of Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13205)
*R. Louw,E. Sharratt,F. de Wet,C. Jacobs,A. Smith,H. Kamper*

Main category: cs.CL

TL;DR: 本文介绍了一种自动评估幼儿口头叙述的系统，该系统使用自动语音识别和机器学习评分模型，结果表明基于大型语言模型的系统表现优于线性模型，并且与人类专家相当。


<details>
  <summary>Details</summary>
Motivation: 在大型幼儿园教室中，教师难以准确识别需要干预的学生。发展早期儿童的叙述和理解技能对以后的阅读能力至关重要。

Method: 我们提出了一种系统，可以自动评估南非语和科萨语的幼儿口头叙述。该系统使用自动语音识别，然后使用机器学习评分模型来预测叙述和理解分数。

Result: 基于大型语言模型的系统在大多数情况下都优于线性模型，但尽管其简单性，线性系统仍具有竞争力。基于大型语言模型的系统在标记需要干预的儿童方面与人类专家相当。

Conclusion: 我们为课堂中的自动口语评估奠定了基础，使教师能够额外关注儿童学习的个性化支持。

Abstract: Developing narrative and comprehension skills in early childhood is critical
for later literacy. However, teachers in large preschool classrooms struggle to
accurately identify students who require intervention. We present a system for
automatically assessing oral narratives of preschool children in Afrikaans and
isiXhosa. The system uses automatic speech recognition followed by a machine
learning scoring model to predict narrative and comprehension scores. For
scoring predicted transcripts, we compare a linear model to a large language
model (LLM). The LLM-based system outperforms the linear model in most cases,
but the linear system is competitive despite its simplicity. The LLM-based
system is comparable to a human expert in flagging children who require
intervention. We lay the foundation for automatic oral assessments in
classrooms, giving teachers extra capacity to focus on personalised support for
children's learning.

</details>


### [24] [Enhancing Cross-task Transfer of Large Language Models via Activation Steering](https://arxiv.org/abs/2507.13236)
*Xinyu Tang,Zhihao Lv,Xiaoxue Cheng,Junyi Li,Wayne Xin Zhao,Zujie Wen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种名为CAST的新方法，通过操纵模型的内部激活状态来实现跨任务的知识转移，该方法在跨领域和跨语言转移设置中表现出色，优于竞争性基线，并展示了更好的可扩展性和更低的计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在通过提示利用预训练知识方面表现出色，但它们在处理未见过的任务时，特别是在数据稀缺的情况下，常常遇到困难。虽然跨任务上下文学习为跨任务转移知识提供了直接的解决方案，但它在鲁棒性、可扩展性和效率方面仍面临关键挑战。

Method: 我们提出了CAST，一种新颖的跨任务激活引导传输框架，通过操纵模型的内部激活状态来实现有效的传输。首先从高资源任务中选择有影响力和多样化的样本，然后利用其对比表示增强的激活来适应低资源任务。

Result: 通过分析LLMs潜在空间中的激活模式，我们观察到由上下文示例引起的增强激活在不同任务中具有一致的模式。基于这些发现，我们提出了CAST，一种新颖的跨任务激活引导传输框架，能够通过操纵模型的内部激活状态来实现有效的传输。

Conclusion: 我们的方法在跨领域和跨语言转移设置中表现出色，优于竞争性基线，并展示了更好的可扩展性和更低的计算成本。

Abstract: Large language models (LLMs) have shown impressive abilities in leveraging
pretrained knowledge through prompting, but they often struggle with unseen
tasks, particularly in data-scarce scenarios. While cross-task in-context
learning offers a direct solution for transferring knowledge across tasks, it
still faces critical challenges in terms of robustness, scalability, and
efficiency. In this paper, we investigate whether cross-task transfer can be
achieved via latent space steering without parameter updates or input
expansion. Through an analysis of activation patterns in the latent space of
LLMs, we observe that the enhanced activations induced by in-context examples
have consistent patterns across different tasks. Inspired by these findings, we
propose CAST, a novel Cross-task Activation Steering Transfer framework that
enables effective transfer by manipulating the model's internal activation
states. Our approach first selects influential and diverse samples from
high-resource tasks, then utilizes their contrastive representation-enhanced
activations to adapt LLMs to low-resource tasks. Extensive experiments across
both cross-domain and cross-lingual transfer settings show that our method
outperforms competitive baselines and demonstrates superior scalability and
lower computational costs.

</details>


### [25] [HATS: Hindi Analogy Test Set for Evaluating Reasoning in Large Language Models](https://arxiv.org/abs/2507.13238)
*Ashray Gupta,Rohan Joseph,Sunny Rai*

Main category: cs.CL

TL;DR: 本文介绍了新的印地语类比测试集（HATS），并提出了一种基于认知理论的类比推理方法，以评估大型语言模型在印地语中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型在印地语中的能力研究不足，限制了我们对这些模型是否能跨语言泛化的理解，因此需要一个新的测试集来评估它们的推理能力。

Method: 我们引入了一个新的印地语类比测试集（HATS），并使用各种提示策略对最先进的多语言LLM进行了基准测试，还提出了一种基于认知理论的类比推理的方法。

Result: 实验表明，无论采用何种提示策略，模型在英语提示下的表现最佳。

Conclusion: 我们的测试集解决了缺乏评估大型语言模型在印地语中推理能力的关键资源的问题。

Abstract: Analogies test a model's ability to infer implicit relationships between
concepts, making them a key benchmark for evaluating reasoning capabilities.
While large language models (LLMs) are widely evaluated for reasoning in
English, their abilities in Indic languages remain understudied, limiting our
understanding of whether these models generalize across languages. To address
this gap, we introduce a new Hindi Analogy Test Set (HATS), comprising 405
multiple-choice questions sourced from Indian government exams. We benchmark
state-of-the-art multilingual LLMs using various prompting strategies and
introduce a grounded Chain of Thought approach that leverages cognitive
theories of analogical reasoning. This approach improves model performance on
Hindi analogy questions. Our experiments show that models perform best with
English prompts, irrespective of the prompting strategy. Our test set addresses
the lack of a critical resource to evaluate LLM reasoning capabilities in
Hindi.

</details>


### [26] [Automating Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2507.13255)
*Lyucheng Wu,Mengru Wang,Ziwen Xu,Tri Cao,Nay Oo,Bryan Hooi,Shumin Deng*

Main category: cs.CL

TL;DR: 本文提出了一种名为AutoSteer的模块化和自适应推理时干预技术，旨在提高多模态大语言模型的安全性，而无需对底层模型进行微调。


<details>
  <summary>Details</summary>
Motivation: 为了在推理过程中提高多模态大语言模型（MLLMs）的安全性，而不需要对底层模型进行微调。

Method: AutoSteer是一种模块化和自适应的推理时干预技术，包含三个核心组件：(1) 一种新的安全意识评分(SAS)，用于自动识别模型内部层中最相关的安全区别；(2) 一个自适应的安全探测器，用于估计从中间表示中产生有害输出的可能性；(3) 一个轻量级拒绝头，用于在检测到安全风险时选择性地干预以调节生成。

Result: 在LLaVA-OV和Chameleon上进行的实验表明，AutoSteer显著降低了文本、视觉和跨模态威胁的攻击成功率（ASR），同时保持了通用能力。

Conclusion: AutoSteer被证明是一种实用、可解释且有效的框架，可用于更安全的多模态AI系统部署。

Abstract: Recent progress in Multimodal Large Language Models (MLLMs) has unlocked
powerful cross-modal reasoning abilities, but also raised new safety concerns,
particularly when faced with adversarial multimodal inputs. To improve the
safety of MLLMs during inference, we introduce a modular and adaptive
inference-time intervention technology, AutoSteer, without requiring any
fine-tuning of the underlying model. AutoSteer incorporates three core
components: (1) a novel Safety Awareness Score (SAS) that automatically
identifies the most safety-relevant distinctions among the model's internal
layers; (2) an adaptive safety prober trained to estimate the likelihood of
toxic outputs from intermediate representations; and (3) a lightweight Refusal
Head that selectively intervenes to modulate generation when safety risks are
detected. Experiments on LLaVA-OV and Chameleon across diverse safety-critical
benchmarks demonstrate that AutoSteer significantly reduces the Attack Success
Rate (ASR) for textual, visual, and cross-modal threats, while maintaining
general abilities. These findings position AutoSteer as a practical,
interpretable, and effective framework for safer deployment of multimodal AI
systems.

</details>


### [27] [QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation](https://arxiv.org/abs/2507.13266)
*Jiazheng Li,Hong Lu,Kaiyue Wen,Zaiwen Yang,Jiaxuan Gao,Hongzhou Lin,Yi Wu,Jingzhao Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为 QuestA 的简单而有效的策略，通过在训练过程中引入部分解决方案来提高强化学习在数学推理任务中的效果。该方法在多个基准测试中取得了新的最先进结果，并提供了理论解释，表明 QuestA 提高了样本效率。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习已成为训练大型语言推理模型的关键组件，但最近的研究质疑其在提高多步骤推理特别是困难问题上的有效性。因此，需要一种有效的方法来解决这一挑战。

Method: QuestA 是一种通过在训练过程中引入部分解决方案来降低问题难度并提供更丰富的学习信号的策略。这种方法在强化学习训练中应用，以提高多步骤推理的能力。

Result: QuestA 在数学推理任务中不仅提高了 pass@1 和 pass@k，还在标准强化学习难以取得进展的问题上表现出色。它在使用 1.5B 参数模型的数学基准测试中取得了新的最先进结果，如 AIME24、AIME25 和 HMMT25 的准确率分别提高了 5.3%、10.0% 和 4.0%。

Conclusion: QuestA 提高了强化学习在数学推理任务中的效果，并在多个基准测试中取得了新的最先进结果。此外，QuestA 通过提高样本效率，为通过强化学习扩展推理能力提供了一种实用且可推广的途径。

Abstract: Reinforcement learning (RL) has become a key component in training large
language reasoning models (LLMs). However, recent studies questions its
effectiveness in improving multi-step reasoning-particularly on hard problems.
To address this challenge, we propose a simple yet effective strategy via
Question Augmentation: introduce partial solutions during training to reduce
problem difficulty and provide more informative learning signals. Our method,
QuestA, when applied during RL training on math reasoning tasks, not only
improves pass@1 but also pass@k-particularly on problems where standard RL
struggles to make progress. This enables continual improvement over strong
open-source models such as DeepScaleR and OpenMath Nemotron, further enhancing
their reasoning capabilities. We achieve new state-of-the-art results on math
benchmarks using 1.5B-parameter models: 67.1% (+5.3%) on AIME24, 59.5% (+10.0%)
on AIME25, and 35.5% (+4.0%) on HMMT25. Further, we provide theoretical
explanations that QuestA improves sample efficiency, offering a practical and
generalizable pathway for expanding reasoning capability through RL.

</details>


### [28] [Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management](https://arxiv.org/abs/2507.13275)
*Luis Gasco,Hermenegildo Fabregat,Laura García-Sardiña,Paula Estrella,Daniel Deniz,Alvaro Rodrigo,Rabih Zbib*

Main category: cs.CL

TL;DR: TalentCLEF 2025 is introduced as the first evaluation campaign for skill and job title intelligence in Human Capital Management, aiming to provide a public benchmark for developing robust and fair language technologies.


<details>
  <summary>Details</summary>
Motivation: The adoption and progress of language technologies in Human Capital Management depend on reliable and fair models evaluated on public data and open benchmarks, which have been unavailable in this domain.

Method: The paper presents TalentCLEF 2025, the first evaluation campaign focused on skill and job title intelligence, consisting of two tasks: Task A - Multilingual Job Title Matching and Task B - Job Title-Based Skill Prediction. The corpora were built from real job applications and manually annotated.

Result: TalentCLEF attracted 76 registered teams with more than 280 submissions. Most systems relied on information retrieval techniques built with multilingual encoder-based models fine-tuned with contrastive learning, and several incorporated large language models for data augmentation or re-ranking. The results show that training strategies have a larger effect than model size alone.

Conclusion: TalentCLEF provides the first public benchmark in this field and encourages the development of robust, fair, and transferable language technologies for the labor market.

Abstract: Advances in natural language processing and large language models are driving
a major transformation in Human Capital Management, with a growing interest in
building smart systems based on language technologies for talent acquisition,
upskilling strategies, and workforce planning. However, the adoption and
progress of these technologies critically depend on the development of reliable
and fair models, properly evaluated on public data and open benchmarks, which
have so far been unavailable in this domain.
  To address this gap, we present TalentCLEF 2025, the first evaluation
campaign focused on skill and job title intelligence. The lab consists of two
tasks: Task A - Multilingual Job Title Matching, covering English, Spanish,
German, and Chinese; and Task B - Job Title-Based Skill Prediction, in English.
Both corpora were built from real job applications, carefully anonymized, and
manually annotated to reflect the complexity and diversity of real-world labor
market data, including linguistic variability and gender-marked expressions.
  The evaluations included monolingual and cross-lingual scenarios and covered
the evaluation of gender bias.
  TalentCLEF attracted 76 registered teams with more than 280 submissions. Most
systems relied on information retrieval techniques built with multilingual
encoder-based models fine-tuned with contrastive learning, and several of them
incorporated large language models for data augmentation or re-ranking. The
results show that the training strategies have a larger effect than the size of
the model alone. TalentCLEF provides the first public benchmark in this field
and encourages the development of robust, fair, and transferable language
technologies for the labor market.

</details>


### [29] [Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis](https://arxiv.org/abs/2507.13285)
*Wang Xi,Quan Shi,Tian Yu,Yujie Peng,Jiayi Sun,Mengxing Ren,Zenghui Ding,Ningguang Yao*

Main category: cs.CL

TL;DR: 本文提出了一种名为RCPS的新框架，用于生成高质量的媒体演示文稿，并引入了PREVAL评估框架来评估演示文稿的质量。实验结果表明，RCPS在所有质量维度上都显著优于基线方法，能够接近人类专家的标准。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在生成媒体演示文稿时常常存在逻辑不一致和布局不佳的问题，难以达到专业标准。

Method: RCPS框架包括三个关键组件：深度结构化叙事规划、自适应布局生成和迭代优化循环。此外，还提出了PREVAL评估框架，采用基于偏好的多维模型来评估演示文稿的质量。

Result: 实验结果表明，RCPS在所有质量维度上都显著优于基线方法，生成的演示文稿接近人类专家的标准。PREVAL与人类判断有很强的相关性，验证了其作为自动评估工具的可靠性。

Conclusion: RCPS和PREVAL为生成高质量的媒体演示文稿提供了有效的解决方案，并展示了在自动化评估方面的潜力。

Abstract: Automated generation of high-quality media presentations is challenging,
requiring robust content extraction, narrative planning, visual design, and
overall quality optimization. Existing methods often produce presentations with
logical inconsistencies and suboptimal layouts, thereby struggling to meet
professional standards. To address these challenges, we introduce RCPS
(Reflective Coherent Presentation Synthesis), a novel framework integrating
three key components: (1) Deep Structured Narrative Planning; (2) Adaptive
Layout Generation; (3) an Iterative Optimization Loop. Additionally, we propose
PREVAL, a preference-based evaluation framework employing rationale-enhanced
multi-dimensional models to assess presentation quality across Content,
Coherence, and Design. Experimental results demonstrate that RCPS significantly
outperforms baseline methods across all quality dimensions, producing
presentations that closely approximate human expert standards. PREVAL shows
strong correlation with human judgments, validating it as a reliable automated
tool for assessing presentation quality.

</details>


### [30] [AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research](https://arxiv.org/abs/2507.13300)
*Yilun Zhao,Weiyuan Chen,Zhijian Xu,Manasi Patwardhan,Yixin Liu,Chengye Wang,Lovekesh Vig,Arman Cohan*

Main category: cs.CL

TL;DR: 本文介绍了AbGen，这是第一个用于评估大语言模型（LLMs）在设计消融实验方面的基准。评估显示，LLMs在重要性、忠实性和合理性方面与人类专家存在差距，且现有自动化评估方法不可靠。为此，作者开发了AbGen-Eval，用于评估自动化评估系统的可靠性，并探讨了LLM-as-Judge系统的应用。


<details>
  <summary>Details</summary>
Motivation: 当前的自动化评估方法在测量LLM在设计消融实验方面的性能时不够可靠，因此需要一个专门的基准来评估LLMs的能力，并改进评估系统。

Method: 本文提出了AbGen，这是一个用于评估大语言模型（LLMs）在设计消融实验方面的基准。AbGen包含来自807篇NLP论文的1,500个专家标注示例。我们评估了领先的LLMs，如DeepSeek-R1-0528和o4-mini，并开发了AbGen-Eval来评估自动化评估系统的可靠性。

Result: 评估结果显示，当前的LLMs在设计消融实验方面与人类专家存在显著差距。同时，现有的自动化评估方法与人类评估结果存在显著差异，表明它们不可靠。通过AbGen-Eval，我们发现了一些LLM-as-Judge系统的不足之处，并为未来的改进提供了见解。

Conclusion: 本文介绍了AbGen，这是第一个用于评估大语言模型（LLMs）在设计消融实验方面的基准。AbGen由807篇NLP论文中的1,500个专家标注示例组成。我们的评估表明，这些模型在重要性、忠实性和合理性方面与人类专家存在显著差距。此外，我们展示了当前的自动化评估方法不可靠，因为它们与人类评估相比存在显著差异。为了更好地研究这一点，我们开发了AbGen-Eval，这是一个元评估基准，用于评估常用自动化评估系统在测量LLM在我们任务上的性能时的可靠性。我们研究了各种LLM-as-Judge系统，并为未来开发更有效和可靠的基于LLM的评估系统提供了见解。

Abstract: We introduce AbGen, the first benchmark designed to evaluate the capabilities
of LLMs in designing ablation studies for scientific research. AbGen consists
of 1,500 expert-annotated examples derived from 807 NLP papers. In this
benchmark, LLMs are tasked with generating detailed ablation study designs for
a specified module or process based on the given research context. Our
evaluation of leading LLMs, such as DeepSeek-R1-0528 and o4-mini, highlights a
significant performance gap between these models and human experts in terms of
the importance, faithfulness, and soundness of the ablation study designs.
Moreover, we demonstrate that current automated evaluation methods are not
reliable for our task, as they show a significant discrepancy when compared to
human assessment. To better investigate this, we develop AbGen-Eval, a
meta-evaluation benchmark designed to assess the reliability of commonly used
automated evaluation systems in measuring LLM performance on our task. We
investigate various LLM-as-Judge systems on AbGen-Eval, providing insights for
future research on developing more effective and reliable LLM-based evaluation
systems for complex scientific tasks.

</details>


### [31] [HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals](https://arxiv.org/abs/2507.13318)
*Guimin Hu,Daniel Hershcovich,Hasti Seifi*

Main category: cs.CL

TL;DR: 本文创建了一个大规模的触觉-文本数据集HapticCap，并提出了haptic-caption retrieval任务，展示了T5和AST模型在该任务中的最佳性能。


<details>
  <summary>Details</summary>
Motivation: 设计能够与用户产生共鸣的触觉信号是具有挑战性的，因此需要一个大规模的触觉数据集来辅助研究。

Method: 本文创建了HapticCap数据集，并提出了haptic-caption retrieval任务，使用监督对比学习框架进行研究。

Result: HapticCap数据集包含92,070个触觉-文本对，用于描述振动的感官、情感和关联属性。基于HapticCap，本文提出了haptic-caption retrieval任务，并展示了T5和AST模型的最佳性能。

Conclusion: 本文提出了HapticCap数据集和haptic-caption retrieval任务，展示了语言模型T5和音频模型AST在该任务中的最佳性能。

Abstract: Haptic signals, from smartphone vibrations to virtual reality touch feedback,
can effectively convey information and enhance realism, but designing signals
that resonate meaningfully with users is challenging. To facilitate this, we
introduce a multimodal dataset and task, of matching user descriptions to
vibration haptic signals, and highlight two primary challenges: (1) lack of
large haptic vibration datasets annotated with textual descriptions as
collecting haptic descriptions is time-consuming, and (2) limited capability of
existing tasks and models to describe vibration signals in text. To advance
this area, we create HapticCap, the first fully human-annotated
haptic-captioned dataset, containing 92,070 haptic-text pairs for user
descriptions of sensory, emotional, and associative attributes of vibrations.
Based on HapticCap, we propose the haptic-caption retrieval task and present
the results of this task from a supervised contrastive learning framework that
brings together text representations within specific categories and vibrations.
Overall, the combination of language model T5 and audio model AST yields the
best performance in the haptic-caption retrieval task, especially when
separately trained for each description category.

</details>


### [32] [Social and Political Framing in Search Engine Results](https://arxiv.org/abs/2507.13325)
*Amrit Poudel,Tim Weninger*

Main category: cs.CL

TL;DR: 本研究探讨了搜索引擎和有意识形态动机的用户查询如何共同导致搜索结果中的偏见，并发现搜索引擎可能在通过强化意识形态分歧来塑造公众认知方面发挥关键作用。


<details>
  <summary>Details</summary>
Motivation: 先前的研究已经广泛探讨了搜索偏见的各种维度，但一个重要的问题仍未得到充分探讨：搜索引擎和有意识形态动机的用户查询如何共同导致搜索结果中的偏见。

Method: 该研究使用政治和社会话题的数据集分析了主要搜索引擎的输出。

Result: 研究发现，搜索引擎不仅以反映潜在偏见的方式优先考虑内容，而且意识形态驱动的用户查询会加剧这些偏见，导致特定叙事的放大。此外，在搜索引擎优先考虑的来源方面观察到了显著差异。

Conclusion: 研究结果表明，搜索引擎可能在通过强化意识形态分歧来塑造公众认知方面发挥关键作用，从而加剧信息极化问题。

Abstract: Search engines play a crucial role in shaping public discourse by influencing
how information is accessed and framed. While prior research has extensively
examined various dimensions of search bias -- such as content prioritization,
indexical bias, political polarization, and sources of bias -- an important
question remains underexplored: how do search engines and
ideologically-motivated user queries contribute to bias in search results. This
study analyzes the outputs of major search engines using a dataset of political
and social topics. The findings reveal that search engines not only prioritize
content in ways that reflect underlying biases but also that
ideologically-driven user queries exacerbate these biases, resulting in the
amplification of specific narratives. Moreover, significant differences were
observed across search engines in terms of the sources they prioritize. These
results suggest that search engines may play a pivotal role in shaping public
perceptions by reinforcing ideological divides, thereby contributing to the
broader issue of information polarization.

</details>


### [33] [Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It](https://arxiv.org/abs/2507.13328)
*Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim*

Main category: cs.CL

TL;DR: 研究发现VL训练不会显著改变语言模型的语义知识，但会改善这些知识在特定任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究VL训练是否能以有意义的方式改变语言模型的语义表示，特别是在分类知识方面。

Method: 通过比较仅文本的语言模型和其VL训练后的对应模型，在需要概念分类理解的文本问答任务中进行实验分析。

Result: VL模型在需要分类理解的任务中表现优于仅文本模型，但在分类知识本身上没有显著差异。

Conclusion: VL训练不会显著改变语言模型的语义知识，但会改善这些知识在特定任务中的应用。

Abstract: Does vision-and-language (VL) training change the linguistic representations
of language models in meaningful ways? Most results in the literature have
shown inconsistent or marginal differences, both behaviorally and
representationally. In this work, we start from the hypothesis that the domain
in which VL training could have a significant effect is lexical-conceptual
knowledge, in particular its taxonomic organization. Through comparing minimal
pairs of text-only LMs and their VL-trained counterparts, we first show that
the VL models often outperform their text-only counterparts on a text-only
question-answering task that requires taxonomic understanding of concepts
mentioned in the questions. Using an array of targeted behavioral and
representational analyses, we show that the LMs and VLMs do not differ
significantly in terms of their taxonomic knowledge itself, but they differ in
how they represent questions that contain concepts in a taxonomic relation vs.
a non-taxonomic relation. This implies that the taxonomic knowledge itself does
not change substantially through additional VL training, but VL training does
improve the deployment of this knowledge in the context of a specific task,
even when the presentation of the task is purely linguistic.

</details>


### [34] [The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner](https://arxiv.org/abs/2507.13332)
*Zhouqi Hua,Wenwei Zhang,Chengqi Lyu,Yuzhe Gu,Songyang Gao,Kuikun Liu,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出了一种新的方法TAIL，用于提高Transformer-based LLM在长度泛化任务中的表现，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的数据驱动方法在处理算术操作和符号操作任务时存在局限性，无法实现更通用的解决方案。因此，本文旨在研究一种更通用的解决方案。

Method: 本文提出了一种名为TAIL的方法，该方法通过计算机程序生成模仿图灵机执行过程的思维链数据，以解决长度泛化问题。

Result: 实验结果表明，TAIL方法在各种任务上显著提高了Qwen2.5-7B模型的长度泛化能力和性能，并超越了之前的方法和DeepSeek-R1。

Conclusion: 本文提出了TAIL方法，通过模拟图灵机的执行过程来提高LLM在长度泛化任务中的表现，并展示了其在多个任务上的优越性能。

Abstract: Length generalization, the ability to solve problems of longer sequences than
those observed during training, poses a core challenge of Transformer-based
large language models (LLM). Although existing studies have predominantly
focused on data-driven approaches for arithmetic operations and symbolic
manipulation tasks, these approaches tend to be task-specific with limited
overall performance. To pursue a more general solution, this paper focuses on a
broader case of reasoning problems that are computable, i.e., problems that
algorithms can solve, thus can be solved by the Turing Machine. From this
perspective, this paper proposes Turing MAchine Imitation Learning (TAIL) to
improve the length generalization ability of LLMs. TAIL synthesizes
chain-of-thoughts (CoT) data that imitate the execution process of a Turing
Machine by computer programs, which linearly expands the reasoning steps into
atomic states to alleviate shortcut learning and explicit memory fetch
mechanism to reduce the difficulties of dynamic and long-range data access in
elementary operations. To validate the reliability and universality of TAIL, we
construct a challenging synthetic dataset covering 8 classes of algorithms and
18 tasks. Without bells and whistles, TAIL significantly improves the length
generalization ability as well as the performance of Qwen2.5-7B on various
tasks using only synthetic data, surpassing previous methods and DeepSeek-R1.
The experimental results reveal that the key concepts in the Turing Machine,
instead of the thinking styles, are indispensable for TAIL for length
generalization, through which the model exhibits read-and-write behaviors
consistent with the properties of the Turing Machine in their attention layers.
This work provides a promising direction for future research in the learning of
LLM reasoning from synthetic data.

</details>


### [35] [A Survey of Context Engineering for Large Language Models](https://arxiv.org/abs/2507.13334)
*Lingrui Mei,Jiayu Yao,Yuyao Ge,Yiwei Wang,Baolong Bi,Yujun Cai,Jiazhi Liu,Mingyu Li,Zhong-Zhi Li,Duzhen Zhang,Chenlin Zhou,Jiayi Mao,Tianze Xia,Jiafeng Guo,Shenghua Liu*

Main category: cs.CL

TL;DR: 本文介绍了一种名为上下文工程的正式学科，用于优化信息负载以提高大型语言模型的性能，并探讨了其组成部分及系统实现。


<details>
  <summary>Details</summary>
Motivation: 当前模型在理解复杂上下文方面表现出色，但在生成同样复杂的长格式输出方面存在明显限制，因此需要解决这一研究缺口。

Method: 本文通过系统分析超过1300篇研究论文，介绍了上下文工程，并将其分解为基本组成部分和复杂的实现。

Result: 本文不仅为该领域建立了技术路线图，还揭示了模型能力之间的根本不对称性。

Conclusion: 本文提出了一个统一的框架，为推进上下文感知AI的研究人员和工程师提供了指导。

Abstract: The performance of Large Language Models (LLMs) is fundamentally determined
by the contextual information provided during inference. This survey introduces
Context Engineering, a formal discipline that transcends simple prompt design
to encompass the systematic optimization of information payloads for LLMs. We
present a comprehensive taxonomy decomposing Context Engineering into its
foundational components and the sophisticated implementations that integrate
them into intelligent systems. We first examine the foundational components:
context retrieval and generation, context processing and context management. We
then explore how these components are architecturally integrated to create
sophisticated system implementations: retrieval-augmented generation (RAG),
memory systems and tool-integrated reasoning, and multi-agent systems. Through
this systematic analysis of over 1300 research papers, our survey not only
establishes a technical roadmap for the field but also reveals a critical
research gap: a fundamental asymmetry exists between model capabilities. While
current models, augmented by advanced context engineering, demonstrate
remarkable proficiency in understanding complex contexts, they exhibit
pronounced limitations in generating equally sophisticated, long-form outputs.
Addressing this gap is a defining priority for future research. Ultimately,
this survey provides a unified framework for both researchers and engineers
advancing context-aware AI.

</details>


### [36] [Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour Understanding from Traditional Puns to Topical Jokes](https://arxiv.org/abs/2507.13335)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型在解释不同类型幽默（如双关语和需要现实知识的幽默）方面的能力，发现现有模型在处理复杂幽默时存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有计算幽默的研究几乎只关注基于双关语的简短笑话，而本文旨在探讨大型语言模型解释幽默的能力是否依赖于特定的幽默形式，并揭示幽默解释任务中的关键研究空白。

Method: 本文通过创建一个包含600个笑话的数据集，分为4种笑话类型，并手动编写高质量的解释，来比较不同大型语言模型在零样本设置下准确且全面解释不同类型的笑话的能力。

Result: 本文发现，没有一个测试的模型（包括推理模型）能够可靠地生成所有笑话类型的适当解释，表明当前模型在处理更复杂的幽默形式时存在明显不足。

Conclusion: 本文发现，测试的模型（包括推理模型）都无法可靠地生成所有笑话类型的适当解释，进一步突显了大多数计算幽默研究对过于简单的笑话形式的狭隘关注。

Abstract: Humour, as a complex language form, is derived from myriad aspects of life,
whilst existing work on computational humour has focussed almost exclusively on
short pun-based jokes. In this work, we investigate whether the ability of
Large Language Models (LLMs) to explain humour depends on the particular humour
form. We compare models on simple puns and more complex topical humour that
requires knowledge of real-world entities and events. In doing so, we curate a
dataset of 600 jokes split across 4 joke types and manually write high-quality
explanations. These jokes include heterographic and homographic puns,
contemporary internet humour, and topical jokes, where understanding relies on
reasoning beyond "common sense", rooted instead in world knowledge regarding
news events and pop culture. Using this dataset, we compare the zero-shot
abilities of a range of LLMs to accurately and comprehensively explain jokes of
different types, identifying key research gaps in the task of humour
explanation. We find that none of the tested models (inc. reasoning models) are
capable of reliably generating adequate explanations of all joke types, further
highlighting the narrow focus of most works in computational humour on overly
simple joke forms.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [37] [A Survey of AIOps in the Era of Large Language Models](https://arxiv.org/abs/2507.12472)
*Lingzhe Zhang,Tong Jia,Mengxi Jia,Yifan Wu,Aiwei Liu,Yong Yang,Zhonghai Wu,Xuming Hu,Philip S. Yu,Ying Li*

Main category: cs.SE

TL;DR: 本文对LLM在AIOps中的应用进行了全面的综述，分析了183篇论文，探讨了LLMs在AIOps中的作用、挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）日益复杂和普及，它们在各种人工智能运维（AIOps）任务中的应用引起了广泛关注。然而，对LLMs在AIOps中的影响、潜力和限制的全面理解仍处于初期阶段。

Method: 我们分析了2020年1月至2024年12月间发表的183篇论文，以回答四个关键研究问题（RQs）。

Result: 我们进行了LLM4AIOps的详细调查，重点是LLMs如何优化流程并改善该领域的结果。

Conclusion: 基于我们的发现，我们讨论了最先进的进展和趋势，识别了现有研究中的差距，并提出了未来探索的有希望的方向。

Abstract: As large language models (LLMs) grow increasingly sophisticated and
pervasive, their application to various Artificial Intelligence for IT
Operations (AIOps) tasks has garnered significant attention. However, a
comprehensive understanding of the impact, potential, and limitations of LLMs
in AIOps remains in its infancy. To address this gap, we conducted a detailed
survey of LLM4AIOps, focusing on how LLMs can optimize processes and improve
outcomes in this domain. We analyzed 183 research papers published between
January 2020 and December 2024 to answer four key research questions (RQs). In
RQ1, we examine the diverse failure data sources utilized, including advanced
LLM-based processing techniques for legacy data and the incorporation of new
data sources enabled by LLMs. RQ2 explores the evolution of AIOps tasks,
highlighting the emergence of novel tasks and the publication trends across
these tasks. RQ3 investigates the various LLM-based methods applied to address
AIOps challenges. Finally, RQ4 reviews evaluation methodologies tailored to
assess LLM-integrated AIOps approaches. Based on our findings, we discuss the
state-of-the-art advancements and trends, identify gaps in existing research,
and propose promising directions for future exploration.

</details>


### [38] [A Fuzzy Approach to Project Success: Measuring What Matters](https://arxiv.org/abs/2507.12653)
*João Granja-Correia,Remedios Hernández-Linares,Luca Ferranti,Arménio Rego*

Main category: cs.SE

TL;DR: 本文引入了一种新的项目成功评估方法，通过将模糊逻辑整合到现有结构中，以更准确地衡量项目成功。


<details>
  <summary>Details</summary>
Motivation: 传统Likert量表往往忽略了项目成功的上下文依赖性和多维性质，因此需要一种更精确的评估方法。

Method: 本文提出了一个分层的Type-1 Mamdani模糊系统，以优先考虑对最终用户的持续积极影响，而不是次要结果如利益相关者满意度和内部项目成功。

Result: 该动态方法可能提供更准确的项目成功度量，并可适应复杂的评估。

Conclusion: 本文提出了一种新的项目成功评估方法，通过将模糊逻辑整合到现有结构中，可以更准确地衡量项目成功，并可能适用于复杂的评估。

Abstract: This paper introduces a novel approach to project success evaluation by
integrating fuzzy logic into an existing construct. Traditional Likert-scale
measures often overlook the context-dependent and multifaceted nature of
project success. The proposed hierarchical Type-1 Mamdani fuzzy system
prioritizes sustained positive impact for end-users, reducing emphasis on
secondary outcomes like stakeholder satisfaction and internal project success.
This dynamic approach may provide a more accurate measure of project success
and could be adaptable to complex evaluations. Future research will focus on
empirical testing and broader applications of fuzzy logic in social science.

</details>


<div id='cs.CC'></div>

# cs.CC [[Back]](#toc)

### [39] [Perfect diffusion is $\mathsf{TC}^0$ -- Bad diffusion is Turing-complete](https://arxiv.org/abs/2507.12469)
*Yuxi Liu*

Main category: cs.CC

TL;DR: 本文分析了扩散模型在语言建模任务中的计算复杂性，揭示了其在不同条件下的能力和限制，并提出了可能的改进方向。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究扩散模型在语言建模任务中的理论能力与限制，特别是在顺序计算任务中的表现。

Method: 本文基于分数匹配网络的质量对扩散模型的计算复杂性进行了二分法分析，并探讨了其在不同条件下的表现。

Result: 本文证明了当分数匹配网络精确计算初始分布的分数函数时，扩散模型只能在 TC^0 复杂度类中进行语言建模；而当没有要求网络匹配任何分数函数时，扩散模型可以模拟任意图灵机。

Conclusion: 本文通过理论分析揭示了扩散模型在语言建模任务中的能力与限制，特别是其在顺序计算任务中的表现。

Abstract: This paper explores the computational complexity of diffusion-based language
modeling. We prove a dichotomy based on the quality of the score-matching
network in a diffusion model. In one direction, a network that exactly computes
the score function of some initial distribution can only perform language
modeling within the $\mathsf{TC}^0$ complexity class, reflecting limitations
tied to rapid convergence. In the other direction, we show that if there is no
requirement for the network to match any score function, then diffusion
modeling can simulate any Turing machine in a certain sense. This dichotomy
provides a theoretical lens on the capabilities and limitations of diffusion
models, particularly concerning tasks requiring sequential computation. We
conjecture extensions of our theoretical results, including for the case where
the diffusion model is not perfect, but merely good. We also discuss the wider
context and practical implications, and hypothesize that a machine learning
architecture that can interpolate between sequential and parallel modes of
operation would be superior to both Transformers and diffusion models.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [40] [Spatially Grounded Explanations in Vision Language Models for Document Visual Question Answering](https://arxiv.org/abs/2507.12490)
*Maximiliano Hormazábal Lagos,Héctor Cerezo-Costas,Dimosthenis Karatzas*

Main category: cs.CV

TL;DR: EaGERS是一种无需训练的模型无关方法，通过生成自然语言推理并定位到图像相关区域，提高了DocVQA任务的透明度和准确性。


<details>
  <summary>Details</summary>
Motivation: 提高DocVQA任务中的透明度和可重复性，同时避免额外的模型微调。

Method: EaGERS是一个完全无需训练且与模型无关的流程，包括生成自然语言推理、通过计算多模态嵌入相似性将推理定位到空间子区域以及仅从选定的相关区域生成响应。

Result: EaGERS在精确匹配准确率和平均归一化Levenshtein相似性指标上优于基础模型。

Conclusion: EaGERS在DocVQA数据集上的最佳配置不仅优于基础模型，还在不进行额外模型微调的情况下提高了透明度和可重复性。

Abstract: We introduce EaGERS, a fully training-free and model-agnostic pipeline that
(1) generates natural language rationales via a vision language model, (2)
grounds these rationales to spatial sub-regions by computing multimodal
embedding similarities over a configurable grid with majority voting, and (3)
restricts the generation of responses only from the relevant regions selected
in the masked image. Experiments on the DocVQA dataset demonstrate that our
best configuration not only outperforms the base model on exact match accuracy
and Average Normalized Levenshtein Similarity metrics but also enhances
transparency and reproducibility in DocVQA without additional model
fine-tuning.

</details>


### [41] [Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal Large Language Models](https://arxiv.org/abs/2507.12566)
*Gen Luo,Wenhan Dou,Wenhao Li,Zhaokai Wang,Xue Yang,Changyao Tian,Hao Li,Weiyun Wang,Wenhai Wang,Xizhou Zhu,Yu Qiao,Jifeng Dai*

Main category: cs.CV

TL;DR: This paper introduces Mono-InternVL and its improved version, Mono-InternVL-1.5, to address challenges in monolithic MLLMs. These models use a multimodal mixture-of-experts architecture and enhanced pre-training methods to achieve competitive performance with reduced computational costs.


<details>
  <summary>Details</summary>
Motivation: Existing monolithic MLLMs suffer from unstable optimization and catastrophic forgetting. The goal is to address these issues by embedding a new visual parameter space into a pre-trained LLM, enabling stable learning of visual knowledge from noisy data via delta tuning.

Method: The paper introduces Mono-InternVL, a monolithic MLLM that incorporates visual experts through a multimodal mixture-of-experts architecture and uses Endogenous Visual Pre-training (EViP) for progressive learning. It then presents Mono-InternVL-1.5, which improves EViP (EViP++) by adding visual attention experts and reorganizing the pre-training process. A fused CUDA kernel is included for faster MoE operations during inference.

Result: Mono-InternVL outperforms existing monolithic MLLMs on 12 out of 15 benchmarks, including an 114-point improvement over Emu3 on OCRBench. Mono-InternVL-1.5 achieves similar multimodal performance to InternVL-1.5 but reduces first-token latency by up to 69%.

Conclusion: Mono-InternVL-1.5 significantly reduces training and inference costs while maintaining competitive performance with Mono-InternVL. It achieves similar multimodal performance to its modular counterpart, InternVL-1.5, but with reduced first-token latency.

Abstract: This paper focuses on monolithic Multimodal Large Language Models (MLLMs),
which integrate visual encoding and language decoding into a single model.
Existing structures and pre-training strategies for monolithic MLLMs often
suffer from unstable optimization and catastrophic forgetting. To address these
challenges, our key idea is to embed a new visual parameter space into a
pre-trained LLM, enabling stable learning of visual knowledge from noisy data
via delta tuning. Based on this principle, we first introduce Mono-InternVL, an
advanced monolithic MLLM that incorporates a set of visual experts through a
multimodal mixture-of-experts architecture. In addition, we design an
innovative Endogenous Visual Pre-training (EViP) for Mono-InternVL to maximize
its visual capabilities via progressive learning. Mono-InternVL achieves
competitive performance against existing MLLMs but also leads to relatively
expensive data cost. Therefore, we further present Mono-InternVL-1.5, a cheaper
and stronger monolithic MLLM equipped with an improved EViP (EViP++). EViP++
introduces additional visual attention experts to Mono-InternVL-1.5 and
re-organizes the pre-training process in an efficient manner. During inference,
it includes a fused CUDA kernel to speed up its MoE operations. With these
designs, Mono-InternVL-1.5 significantly reduces training and inference costs,
while still maintaining competitive performance with Mono-InternVL. To evaluate
our approach, we conduct extensive experiments across 15 benchmarks. Results
demonstrate that Mono-InternVL outperforms existing monolithic MLLMs on 12 out
of 15 benchmarks, e.g., +114-point improvement over Emu3 on OCRBench. Compared
to its modular counterpart, i.e., InternVL-1.5, Mono-InternVL-1.5 achieves
similar multimodal performance while reducing first-token latency by up to 69%.
Code and models are released at https://github.com/OpenGVLab/Mono-InternVL.

</details>


### [42] [VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning](https://arxiv.org/abs/2507.13348)
*Senqiao Yang,Junyi Li,Xin Lai,Bei Yu,Hengshuang Zhao,Jiaya Jia*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉标记压缩范式VisionThink，通过动态处理不同样本的分辨率，提高了OCR相关任务的表现，同时节省了视觉标记。


<details>
  <summary>Details</summary>
Motivation: 我们观察到大多数现实场景不需要如此多的视觉标记，而现有的高效VLM方法使用固定的修剪比例或阈值进行标记压缩，这可能不够灵活。

Method: 我们提出了VisionThink，这是一种新的视觉标记压缩范式，它动态地处理不同的样本以不同的分辨率，并采用强化学习和LLM-as-Judge策略来应用RL到一般的VQA任务中。

Result: 实验表明，我们的方法在OCR相关任务中表现优异，同时在简单任务中节省了大量视觉标记。

Conclusion: 我们的方法在OCR相关任务中表现出强大的细粒度视觉理解能力，同时在简单任务中节省了大量的视觉标记。

Abstract: Recent advancements in vision-language models (VLMs) have improved
performance by increasing the number of visual tokens, which are often
significantly longer than text tokens. However, we observe that most real-world
scenarios do not require such an extensive number of visual tokens. While the
performance drops significantly in a small subset of OCR-related tasks, models
still perform accurately in most other general VQA tasks with only 1/4
resolution. Therefore, we propose to dynamically process distinct samples with
different resolutions, and present a new paradigm for visual token compression,
namely, VisionThink. It starts with a downsampled image and smartly decides
whether it is sufficient for problem solving. Otherwise, the model could output
a special token to request the higher-resolution image. Compared to existing
Efficient VLM methods that compress tokens using fixed pruning ratios or
thresholds, VisionThink autonomously decides whether to compress tokens case by
case. As a result, it demonstrates strong fine-grained visual understanding
capability on OCR-related tasks, and meanwhile saves substantial visual tokens
on simpler tasks. We adopt reinforcement learning and propose the LLM-as-Judge
strategy to successfully apply RL to general VQA tasks. Moreover, we carefully
design a reward function and penalty mechanism to achieve a stable and
reasonable image resize call ratio. Extensive experiments demonstrate the
superiority, efficiency, and effectiveness of our method. Our code is available
at https://github.com/dvlab-research/VisionThink.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [43] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu,Jielin Qiu,Shiyu Wang,Jianguo Zhang,Zuxin Liu,Roshan Ram,Haolin Chen,Weiran Yao,Huan Wang,Shelby Heinecke,Silvio Savarese,Caiming Xiong*

Main category: cs.AI

TL;DR: 本文介绍了一个基于MCP的框架MCPEval，用于自动化评估LLM代理，并在多个领域中展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法依赖于静态基准和人工数据收集，限制了实际评估。

Method: 引入了一个基于Model Context Protocol (MCP)的框架，用于自动化端到端任务生成和深度评估LLM代理。

Result: 在五个现实领域中的实证结果表明其在揭示领域特定性能方面的有效性。

Conclusion: MCPEval被公开发布，以促进可重复和标准化的LLM代理评估。

Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [44] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang,Ruiyu Fang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 本文提出了一种解决方案用于NLPCC 2025任务8的ESC评估，通过使用大规模语言模型和微调技术来提高模型生成支持性回应的能力。最佳模型在比赛中获得第二名，显示出该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 情感支持对话（ESC）旨在通过对话提供共情和有效的心理支持，满足日益增长的心理健康需求。

Method: 我们利用大规模语言模型，通过提示工程和微调技术来解决NLPCC 2025任务8的ESC评估问题。我们探索了参数高效的低秩适应和全参数微调策略，以提高模型生成支持性和上下文适当响应的能力。

Result: 我们的最佳模型在比赛中排名第二，这表明结合大语言模型和有效的适应方法在ESC任务中具有潜力。

Conclusion: 我们的最佳模型在比赛中排名第二，这表明结合大语言模型和有效的适应方法在ESC任务中具有潜力。未来的工作将专注于进一步提升情感理解和响应个性化，以构建更实用和可靠的的情感支持系统。

Abstract: Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [45] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
*Ahmed Bahloul,Simon Malberg*

Main category: cs.AI

TL;DR: 本文提出了一种动态强化学习框架，用于改进基于树的推理方法，提高解决方案质量和计算效率，同时保持概率严谨性。


<details>
  <summary>Details</summary>
Motivation: 现有的ProbTree框架存在两个关键限制：推理树在初始构建阶段是固定的，无法动态适应中间结果；每个节点需要全面评估所有可能的解决方案策略，导致计算效率低下。因此，需要一种更高效和灵活的框架来改进树结构推理。

Method: 本文提出了一种动态强化学习框架，将基于树的推理转化为适应性过程。该方法根据实时置信度估计逐步构建推理树，并学习最优的动作选择策略（分解、检索或聚合）。

Result: 本文提出的动态强化学习框架在保持ProbTree的概率严谨性的同时，通过选择性扩展和集中资源分配提高了解决方案质量和计算效率。该工作建立了一个新的树结构推理范式，平衡了概率框架的可靠性与现实世界问答系统所需的灵活性。

Conclusion: 本文提出了一种动态强化学习框架，将基于树的推理转化为适应性过程，从而在保持ProbTree的概率严谨性的同时，通过选择性扩展和集中资源分配提高了解决方案质量和计算效率。该工作建立了一个新的树结构推理范式，平衡了概率框架的可靠性与现实世界问答系统所需的灵活性。

Abstract: Modern language models address complex questions through chain-of-thought
(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,
2021), yet struggle with error propagation and knowledge integration.
Tree-structured reasoning methods, particularly the Probabilistic
Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues
by decomposing questions into hierarchical structures and selecting answers
through confidence-weighted aggregation of parametric and retrieved knowledge
(Yao et al., 2023). However, ProbTree's static implementation introduces two
key limitations: (1) the reasoning tree is fixed during the initial
construction phase, preventing dynamic adaptation to intermediate results, and
(2) each node requires exhaustive evaluation of all possible solution
strategies, creating computational inefficiency. We present a dynamic
reinforcement learning (Sutton and Barto, 2018) framework that transforms
tree-based reasoning into an adaptive process. Our approach incrementally
constructs the reasoning tree based on real-time confidence estimates, while
learning optimal policies for action selection (decomposition, retrieval, or
aggregation). This maintains ProbTree's probabilistic rigor while improving
both solution quality and computational efficiency through selective expansion
and focused resource allocation. The work establishes a new paradigm for
treestructured reasoning that balances the reliability of probabilistic
frameworks with the flexibility required for real-world question answering
systems.

</details>


### [46] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
*Carlos Arriaga,Gonzalo Martínez,Eneko Sendin,Javier Conde,Pedro Reviriego*

Main category: cs.AI

TL;DR: 本文介绍了GEA，一个将模型能耗纳入评估过程的平台。结果显示，用户在了解能耗后更倾向于选择能效更高的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法存在局限性，如自动化基准测试与人类判断的相关性较差，而人工评估则面临可扩展性和成本问题。此外，随着LLM的发展，能耗成为一个越来越重要的因素，因此需要一种能够考虑能耗的评估方法。

Method: 本文提出了GEA（Generative Energy Arena），这是一个在评估过程中融入模型能耗信息的平台。通过该平台，用户可以在了解模型能耗的情况下对模型进行评估和排名。

Result: 初步结果表明，当用户了解模型的能耗时，他们更倾向于选择较小且能效更高的模型。这表明，对于大多数用户交互，复杂且性能更好的模型所带来的额外成本和能耗并未带来响应质量的显著提升。

Conclusion: 研究表明，当用户了解模型的能耗时，他们更倾向于选择较小且能效更高的模型。这表明，对于大多数用户交互，复杂且性能更好的模型所带来的额外成本和能耗并未带来响应质量的显著提升，因此不值得使用。

Abstract: The evaluation of large language models is a complex task, in which several
approaches have been proposed. The most common is the use of automated
benchmarks in which LLMs have to answer multiple-choice questions of different
topics. However, this method has certain limitations, being the most
concerning, the poor correlation with the humans. An alternative approach, is
to have humans evaluate the LLMs. This poses scalability issues as there is a
large and growing number of models to evaluate making it impractical (and
costly) to run traditional studies based on recruiting a number of evaluators
and having them rank the responses of the models. An alternative approach is
the use of public arenas, such as the popular LM arena, on which any user can
freely evaluate models on any question and rank the responses of two models.
The results are then elaborated into a model ranking. An increasingly important
aspect of LLMs is their energy consumption and, therefore, evaluating how
energy awareness influences the decisions of humans in selecting a model is of
interest. In this paper, we present GEA, the Generative Energy Arena, an arena
that incorporates information on the energy consumption of the model in the
evaluation process. Preliminary results obtained with GEA are also presented,
showing that for most questions, when users are aware of the energy
consumption, they favor smaller and more energy efficient models. This suggests
that for most user interactions, the extra cost and energy incurred by the more
complex and top-performing models do not provide an increase in the perceived
quality of the responses that justifies their use.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [47] [Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training](https://arxiv.org/abs/2507.12507)
*Mingjie Liu,Shizhe Diao,Jian Hu,Ximing Lu,Xin Dong,Hao Zhang,Alexander Bukharin,Shaokun Zhang,Jiaqi Zeng,Makesh Narsimhan Sreedhar,Gerald Shen,David Mosallanezhad,Di Zhang,Jonas Yang,June Yang,Oleksii Kuchaiev,Guilin Liu,Zhiding Yu,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong*

Main category: cs.LG

TL;DR: 本报告研究了延长强化学习对小型语言模型在多种推理领域的影响，并展示了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 最近的进展表明，通过链式思维推理和迭代探索来扩展测试时计算可以显著提高复杂任务的表现。这些突破是由大规模强化学习驱动的，特别是当结合可验证的奖励信号时。因此，我们想研究延长强化学习对小型语言模型的影响。

Method: 我们研究了延长强化学习对小型语言模型在多种推理领域的影响，并识别出有效的训练关键要素，包括使用可验证的奖励任务、对组相对策略优化（GRPO）的增强以及提高训练稳定性和泛化的实用技术。

Result: 我们的模型在数学任务上提高了14.7%，在编程任务上提高了13.9%，在逻辑谜题任务上提高了54.8%。

Conclusion: 我们的模型在数学、编程和逻辑谜题任务上相比强基线有显著提升，并且我们公开了模型以促进进一步的研究。

Abstract: Recent advancements in reasoning-focused language models such as OpenAI's O1
and DeepSeek-R1 have shown that scaling test-time computation-through
chain-of-thought reasoning and iterative exploration-can yield substantial
improvements on complex tasks like mathematics and code generation. These
breakthroughs have been driven by large-scale reinforcement learning (RL),
particularly when combined with verifiable reward signals that provide
objective and grounded supervision. In this report, we investigate the effects
of prolonged reinforcement learning on a small language model across a diverse
set of reasoning domains. Our work identifies several key ingredients for
effective training, including the use of verifiable reward tasks, enhancements
to Group Relative Policy Optimization (GRPO), and practical techniques to
improve training stability and generalization. We introduce controlled KL
regularization, clipping ratio, and periodic reference policy resets as
critical components for unlocking long-term performance gains. Our model
achieves significant improvements over strong baselines, including +14.7% on
math, +13.9% on coding, and +54.8% on logic puzzle tasks. To facilitate
continued research, we release our model publicly.

</details>


### [48] [A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models](https://arxiv.org/abs/2507.12774)
*Weijieying Ren,Jingxi Zhu,Zehao Liu,Tianxiang Zhao,Vasant Honavar*

Main category: cs.LG

TL;DR: 本文综述了深度学习和大型语言模型在电子健康记录建模中的应用，提出了一个统一的分类法，并讨论了未来的研究方向和挑战。


<details>
  <summary>Details</summary>
Motivation: 由于EHR数据的固有异质性、时间不规则性和领域特定性，AI在医疗保健中的应用面临独特的挑战。本文旨在综述深度学习、大型语言模型（LLMs）和EHR建模的最新进展。

Method: 本文介绍了一个统一的分类法，涵盖了五个关键设计维度：数据导向的方法、神经架构设计、学习导向的策略、多模态学习和基于LLM的建模系统。

Result: 本文回顾了在数据质量增强、结构和时间表示、自监督学习以及与临床知识的整合方面代表性的方法。还突出了基础模型、LLM驱动的临床代理和EHR到文本的翻译等新兴趋势。

Conclusion: 本文旨在为推进AI驱动的EHR建模和临床决策支持提供一个结构化的路线图。

Abstract: Artificial intelligence (AI) has demonstrated significant potential in
transforming healthcare through the analysis and modeling of electronic health
records (EHRs). However, the inherent heterogeneity, temporal irregularity, and
domain-specific nature of EHR data present unique challenges that differ
fundamentally from those in vision and natural language tasks. This survey
offers a comprehensive overview of recent advancements at the intersection of
deep learning, large language models (LLMs), and EHR modeling. We introduce a
unified taxonomy that spans five key design dimensions: data-centric
approaches, neural architecture design, learning-focused strategies, multimodal
learning, and LLM-based modeling systems. Within each dimension, we review
representative methods addressing data quality enhancement, structural and
temporal representation, self-supervised learning, and integration with
clinical knowledge. We further highlight emerging trends such as foundation
models, LLM-driven clinical agents, and EHR-to-text translation for downstream
reasoning. Finally, we discuss open challenges in benchmarking, explainability,
clinical alignment, and generalization across diverse clinical settings. This
survey aims to provide a structured roadmap for advancing AI-driven EHR
modeling and clinical decision support. For a comprehensive list of EHR-related
methods, kindly refer to https://survey-on-tabular-data.github.io/.

</details>


### [49] [PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database](https://arxiv.org/abs/2507.12805)
*Hui Sun,Yanfeng Ding,Liping Yi,Huidong Ma,Gang Wang,Xiaoguang Liu,Cheng Zhong,Wentong Cai*

Main category: cs.LG

TL;DR: 本文提出了一种新的PMKLC压缩器，通过多知识学习、GPU加速、并行加速和两种压缩模式，显著提升了压缩性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的无损压缩器在压缩比、压缩和解压吞吐量以及压缩鲁棒性方面存在不足，限制了其在工业和学术界的广泛应用。

Method: 提出了一种基于自动化多知识学习的压缩框架，设计了GPU加速的(s,k)-mer编码器，引入了数据块分割和逐步模型传递机制，并设计了两种压缩模式PMKLC-S和PMKLC-M。

Result: PMKLC-S/M在15个真实世界数据集上与14个基线进行比较，平均压缩比提升高达73.609%和73.480%，平均吞吐量提升高达3.036倍和10.710倍，同时具有最佳鲁棒性和有竞争力的内存成本。

Conclusion: PMKLC-S/M在压缩比、吞吐量和鲁棒性方面表现出色，显示出其在不同数据集上的稳定性和在内存受限设备上的强大能力。

Abstract: Learning-based lossless compressors play a crucial role in large-scale
genomic database backup, storage, transmission, and management. However, their
1) inadequate compression ratio, 2) low compression \& decompression
throughput, and 3) poor compression robustness limit their widespread adoption
and application in both industry and academia. To solve those challenges, we
propose a novel \underline{P}arallel \underline{M}ulti-\underline{K}nowledge
\underline{L}earning-based \underline{C}ompressor (PMKLC) with four crucial
designs: 1) We propose an automated multi-knowledge learning-based compression
framework as compressors' backbone to enhance compression ratio and robustness;
2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compression
throughput and computing resource usage; 3) we introduce data block
partitioning and Step-wise Model Passing (SMP) mechanisms for parallel
acceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meet
the complex application scenarios, where the former runs on a
resource-constrained single GPU and the latter is multi-GPU accelerated. We
benchmark PMKLC-S/M and 14 baselines (7 traditional and 7 leaning-based) on 15
real-world datasets with different species and data sizes. Compared to
baselines on the testing datasets, PMKLC-S/M achieve the average compression
ratio improvement up to 73.609\% and 73.480\%, the average throughput
improvement up to 3.036$\times$ and 10.710$\times$, respectively. Besides,
PMKLC-S/M also achieve the best robustness and competitive memory cost,
indicating its greater stability against datasets with different probability
distribution perturbations, and its strong ability to run on memory-constrained
devices.

</details>


### [50] [Probabilistic Soundness Guarantees in LLM Reasoning Chains](https://arxiv.org/abs/2507.12948)
*Weiqiu You,Anton Xue,Shreya Havaldar,Delip Rao,Helen Jin,Chris Callison-Burch,Eric Wong*

Main category: cs.LG

TL;DR: 本文提出了一种名为ARES的新概率框架，用于检测大型语言模型生成的推理链中的传播错误，该方法在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的错误检测方法往往无法检测到传播错误，因为它们没有正确考虑早期错误如何影响下游推理的判断。

Method: 引入了Autoregressive Reasoning Entailment Stability (ARES)，这是一种新颖的概率框架，通过仅基于之前评估的合理前提来判断每个主张，从而防止错误传播。

Result: ARES在四个基准测试中取得了72.1%的Macro-F1分数，比之前的方法高出8.2分，并在非常长的合成推理链中表现出色，检测传播错误的F1分数为90.3%，比之前的方法高出27.6分。

Conclusion: ARES在四个基准测试中达到了最先进的性能，并在非常长的合成推理链中表现出色，能够有效检测传播错误。

Abstract: In reasoning chains generated by large language models (LLMs), initial errors
often propagate and undermine the reliability of the final conclusion. Current
LLM-based error detection methods often fail to detect propagated errors
because they do not properly account for how earlier errors might corrupt
judgments of downstream reasoning. To better detect such propagated errors, we
introduce Autoregressive Reasoning Entailment Stability (ARES), a novel
probabilistic framework that prevents error propagation by judging each claim
based only on previously-assessed sound premises. This inductive method yields
a nuanced score for each step and provides certified statistical guarantees of
its soundness, rather than a brittle binary label. ARES achieves
state-of-the-art performance across four benchmarks (72.1% Macro-F1, +8.2
points) and demonstrates superior robustness on very long synthetic reasoning
chains, where it excels at detecting propagated errors (90.3% F1, +27.6
points).

</details>


### [51] [Teach Old SAEs New Domain Tricks with Boosting](https://arxiv.org/abs/2507.12990)
*Nikita Koriagin,Yaroslav Aksenov,Daniil Laptev,Gleb Gerasimov,Nikita Balagansky,Daniil Gavrilov*

Main category: cs.LG

TL;DR: 本文提出了一种残差学习方法，通过训练一个次级SAE来建模预训练SAE在特定领域文本上的重构误差，从而捕捉主模型遗漏的特征。在推理过程中，通过求和两个模型的输出，实现了显著的改进。该方法能够有效地将新领域的知识纳入现有的SAEs中，同时保持其在通用任务上的性能，为LLMs的定向机制可解释性打开了新的可能性。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器（SAE）在解释大型语言模型（LLM）的内部表示方面表现出色，但它们往往无法捕捉训练语料库中不常见的特定领域特征。本文旨在解决这一特征盲点问题，而无需完全重新训练。

Method: 本文引入了一种残差学习方法，通过训练一个次级SAE来建模预训练SAE在特定领域文本上的重构误差，从而捕捉主模型遗漏的特征。在推理过程中，通过求和两个模型的输出，实现了显著的改进。

Result: 实验表明，该方法在多个专业领域中显著提高了LLM的交叉熵和解释方差指标，并且能够高效地将新领域知识融入现有SAEs中，同时保持其在通用任务上的性能。

Conclusion: 该方法能够有效地将新领域的知识纳入现有的SAEs中，同时保持其在通用任务上的性能。这使得研究人员可以有选择地增强特定领域SAE的可解释性，为LLMs的定向机制可解释性打开了新的可能性。

Abstract: Sparse Autoencoders have emerged as powerful tools for interpreting the
internal representations of Large Language Models, yet they often fail to
capture domain-specific features not prevalent in their training corpora. This
paper introduces a residual learning approach that addresses this feature
blindness without requiring complete retraining. We propose training a
secondary SAE specifically to model the reconstruction error of a pretrained
SAE on domain-specific texts, effectively capturing features missed by the
primary model. By summing the outputs of both models during inference, we
demonstrate significant improvements in both LLM cross-entropy and explained
variance metrics across multiple specialized domains. Our experiments show that
this method efficiently incorporates new domain knowledge into existing SAEs
while maintaining their performance on general tasks. This approach enables
researchers to selectively enhance SAE interpretability for specific domains of
interest, opening new possibilities for targeted mechanistic interpretability
of LLMs.

</details>


### [52] [Inverse Reinforcement Learning Meets Large Language Model Post-Training: Basics, Advances, and Opportunities](https://arxiv.org/abs/2507.13158)
*Hao Sun,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 本文通过逆强化学习的视角全面回顾了大型语言模型对齐的最新进展，强调了强化学习技术在其中的作用，并探讨了相关挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型（LLM）时代，对齐已成为追求更可靠、可控和强大机器智能的基本但具有挑战性的问题。最近推理模型和对话AI系统的成功凸显了强化学习（RL）在增强这些系统中的关键作用，推动了RL和LLM对齐交叉领域的研究兴趣。

Method: 本文通过逆强化学习（IRL）的视角全面回顾了LLM对齐的最新进展，并强调了在LLM对齐中使用的RL技术与传统RL任务中的区别。

Result: 本文介绍了RL的基础概念，探讨了该研究议程的最新进展，讨论了进行LLM对齐IRL的关键挑战和机遇。此外，还探索了实际方面，包括数据集、基准测试、评估指标、基础设施以及计算高效的训练和推理技术。最后，从稀疏奖励RL的文献中汲取见解，确定开放问题和潜在的研究方向。

Conclusion: 本文旨在提供一个结构化且批判性的领域概述，突出未解决的挑战，并概述通过强化学习（RL）和逆强化学习（IRL）技术改进LLM对齐的有希望的未来方向。

Abstract: In the era of Large Language Models (LLMs), alignment has emerged as a
fundamental yet challenging problem in the pursuit of more reliable,
controllable, and capable machine intelligence. The recent success of reasoning
models and conversational AI systems has underscored the critical role of
reinforcement learning (RL) in enhancing these systems, driving increased
research interest at the intersection of RL and LLM alignment. This paper
provides a comprehensive review of recent advances in LLM alignment through the
lens of inverse reinforcement learning (IRL), emphasizing the distinctions
between RL techniques employed in LLM alignment and those in conventional RL
tasks. In particular, we highlight the necessity of constructing neural reward
models from human data and discuss the formal and practical implications of
this paradigm shift. We begin by introducing fundamental concepts in RL to
provide a foundation for readers unfamiliar with the field. We then examine
recent advances in this research agenda, discussing key challenges and
opportunities in conducting IRL for LLM alignment. Beyond methodological
considerations, we explore practical aspects, including datasets, benchmarks,
evaluation metrics, infrastructure, and computationally efficient training and
inference techniques. Finally, we draw insights from the literature on
sparse-reward RL to identify open questions and potential research directions.
By synthesizing findings from diverse studies, we aim to provide a structured
and critical overview of the field, highlight unresolved challenges, and
outline promising future directions for improving LLM alignment through RL and
IRL techniques.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [53] [Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities](https://arxiv.org/abs/2507.13019)
*Liuyi Wang,Xinyuan Xia,Hui Zhao,Hanqing Wang,Tai Wang,Yilun Chen,Chengju Liu,Qijun Chen,Jiangmiao Pang*

Main category: cs.RO

TL;DR: The paper introduces VLN-PE, a physically realistic VLN platform, and evaluates several VLN methods in physical robotic settings, revealing performance degradation due to various physical challenges.


<details>
  <summary>Details</summary>
Motivation: Recent VLN advancements have idealized assumptions about robot movement and control that fail to reflect physically embodied deployment challenges. We aim to bridge this gap by introducing a physically realistic VLN platform.

Method: We introduce VLN-PE, a physically realistic VLN platform supporting different types of robots. We evaluate several ego-centric VLN methods in physical robotic settings across different technical pipelines.

Result: Our results reveal significant performance degradation due to limited robot observation space, environmental lighting variations, and physical challenges like collisions and falls. This also exposes locomotion constraints for legged robots in complex environments.

Conclusion: VLN-PE provides a new pathway for improving cross-embodiment's overall adaptability and inspires the community to rethink VLN limitations and advance robust, practical VLN models.

Abstract: Recent Vision-and-Language Navigation (VLN) advancements are promising, but
their idealized assumptions about robot movement and control fail to reflect
physically embodied deployment challenges. To bridge this gap, we introduce
VLN-PE, a physically realistic VLN platform supporting humanoid, quadruped, and
wheeled robots. For the first time, we systematically evaluate several
ego-centric VLN methods in physical robotic settings across different technical
pipelines, including classification models for single-step discrete action
prediction, a diffusion model for dense waypoint prediction, and a train-free,
map-based large language model (LLM) integrated with path planning. Our results
reveal significant performance degradation due to limited robot observation
space, environmental lighting variations, and physical challenges like
collisions and falls. This also exposes locomotion constraints for legged
robots in complex environments. VLN-PE is highly extensible, allowing seamless
integration of new scenes beyond MP3D, thereby enabling more comprehensive VLN
evaluation. Despite the weak generalization of current models in physical
deployment, VLN-PE provides a new pathway for improving cross-embodiment's
overall adaptability. We hope our findings and tools inspire the community to
rethink VLN limitations and advance robust, practical VLN models. The code is
available at https://crystalsixone.github.io/vln_pe.github.io/.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [54] [UniSLU: Unified Spoken Language Understanding from Heterogeneous Cross-Task Datasets](https://arxiv.org/abs/2507.12951)
*Zhichao Sheng,Shilin Zhou,Chen Gong,Zhenghua Li*

Main category: eess.AS

TL;DR: 本文提出了UniSLU，一个统一的框架，用于在单一架构中联合建模多个SLU任务，包括ASR、spoken NER和SA。通过统一表示和生成方法，提升了任务交互并实现了与大型语言模型的无缝集成，实验结果表明该方法在公共SLU数据集上表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常为单个任务（如spoken NER和SA）使用单独的模型架构，这增加了系统复杂性，限制了跨任务交互，并未能充分利用任务间的异构数据集。

Method: 我们提出了UniSLU，一个统一的框架，在单一架构中联合建模多个SLU任务。具体来说，我们为多样化的SLU任务提出了一个统一的表示，以充分利用跨多个任务的异构数据集。在此表示基础上，我们提出了一个统一的生成方法，联合建模ASR、spoken NER和SA任务，增强任务交互并实现与大型语言模型的无缝集成，以利用它们强大的生成能力。

Result: 我们在公共SLU数据集上进行了广泛实验，结果表明我们的方法有效，相比几种基准方法取得了优越的SLU性能。

Conclusion: 我们的方法在公共SLU数据集上进行了广泛实验，证明了其有效性，相比几种基准方法取得了优越的SLU性能，使其非常适合现实世界的基于语音的多媒体场景。

Abstract: Spoken Language Understanding (SLU) plays a crucial role in speech-centric
multimedia applications, enabling machines to comprehend spoken language in
scenarios such as meetings, interviews, and customer service interactions. SLU
encompasses multiple tasks, including Automatic Speech Recognition (ASR),
spoken Named Entity Recognition (NER), and spoken Sentiment Analysis (SA).
However, existing methods often rely on separate model architectures for
individual tasks such as spoken NER and SA, which increases system complexity,
limits cross-task interaction, and fails to fully exploit heterogeneous
datasets available across tasks. To address these limitations, we propose
UniSLU, a unified framework that jointly models multiple SLU tasks within a
single architecture. Specifically, we propose a unified representation for
diverse SLU tasks, enabling full utilization of heterogeneous datasets across
multiple tasks. Built upon this representation, we propose a unified generative
method that jointly models ASR, spoken NER, and SA tasks, enhancing task
interactions and enabling seamless integration with large language models to
harness their powerful generative capabilities. Extensive experiments on public
SLU datasets demonstrate the effectiveness of our approach, achieving superior
SLU performance compared to several benchmark methods, making it well-suited
for real-world speech-based multimedia scenarios. We will release all code and
models at github to facilitate future research.

</details>
