<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 47]
- [cs.DL](#cs.DL) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.CV](#cs.CV) [Total: 6]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.CR](#cs.CR) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Social Bias in Multilingual Language Models: A Survey](https://arxiv.org/abs/2508.20201)
*Lance Calvin Lim Gamboa,Yue Feng,Mark Lee*

Main category: cs.CL

TL;DR: 本文通过系统综述分析了多语言模型中的偏见问题，并提出了未来研究方向，以提高多语言偏见文献的包容性和跨文化适用性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在分析多语言模型中的社会偏见，并探索如何在多语言和非英语语境中改进偏见评估和缓解方法。

Method: 本文进行了系统综述，分析了多语言和非英语语境下的偏见评估和缓解方法，并探讨了语言多样性、文化意识以及评估指标和缓解技术的选择。

Result: 本文揭示了当前研究中方法论设计选择的不足（如对某些语言的偏好、多语言缓解实验的稀缺性），并总结了在跨语言和文化适应偏见基准时遇到的常见问题和实施的解决方案。

Conclusion: 本文通过系统综述分析了将偏见评估和缓解方法扩展到多语言和非英语语境的研究，指出了该领域的方法论设计选择中的差距，并提出了未来研究的方向，以增强多语言偏见文献的包容性、跨文化适当性和与最新自然语言处理进展的一致性。

Abstract: Pretrained multilingual models exhibit the same social bias as models
processing English texts. This systematic review analyzes emerging research
that extends bias evaluation and mitigation approaches into multilingual and
non-English contexts. We examine these studies with respect to linguistic
diversity, cultural awareness, and their choice of evaluation metrics and
mitigation techniques. Our survey illuminates gaps in the field's dominant
methodological design choices (e.g., preference for certain languages, scarcity
of multilingual mitigation experiments) while cataloging common issues
encountered and solutions implemented in adapting bias benchmarks across
languages and cultures. Drawing from the implications of our findings, we chart
directions for future research that can reinforce the multilingual bias
literature's inclusivity, cross-cultural appropriateness, and alignment with
state-of-the-art NLP advancements.

</details>


### [2] [Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models](https://arxiv.org/abs/2508.20217)
*Mohammad Amini,Babak Ahmadi,Xiaomeng Xiong,Yilin Zhang,Christopher Qiao*

Main category: cs.CL

TL;DR: 本研究探索了使用语言模型自动生成选择题，通过结构化提示和高效微调提升中型模型的表现，为K-12语言评估提供了一种实用且可扩展的方法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在利用语言模型自动生成选择题，以减少手动测试开发的成本和不一致性。

Method: 本研究采用两步方法：首先比较了微调的中型模型（Gemma, 2B）与未微调的大型模型（GPT-3.5, 175B），其次评估了七种结构化提示策略，包括零样本、少样本、思维链、角色基础、顺序设计以及组合方式。

Result: 结果表明，结构化提示，特别是结合思维链和顺序设计的策略，显著提高了Gemma的输出质量。Gemma通常比GPT-3.5的零样本响应产生更多符合构想和教学适当的题目，提示设计在中型模型性能中起关键作用。

Conclusion: 本研究展示了结构化提示和高效微调可以在有限数据条件下增强中型模型用于自动生成测试题的能力。提出的流程提供了一种实用且可扩展的方法来开发和验证K-12的语言评估题目。

Abstract: This study explores automatic generation (AIG) using language models to
create multiple choice questions (MCQs) for morphological assessment, aiming to
reduce the cost and inconsistency of manual test development. The study used a
two-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B)
with a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven
structured prompting strategies, including zero-shot, few-shot,
chain-of-thought, role-based, sequential, and combinations. Generated items
were assessed using automated metrics and expert scoring across five
dimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate
human scoring at scale. Results show that structured prompting, especially
strategies combining chain-of-thought and sequential design, significantly
improved Gemma's outputs. Gemma generally produced more construct-aligned and
instructionally appropriate items than GPT-3.5's zero-shot responses, with
prompt design playing a key role in mid-size model performance. This study
demonstrates that structured prompting and efficient fine-tuning can enhance
midsized models for AIG under limited data conditions. We highlight the value
of combining automated metrics, expert judgment, and large-model simulation to
ensure alignment with assessment goals. The proposed workflow offers a
practical and scalable way to develop and validate language assessment items
for K-12.

</details>


### [3] [Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach](https://arxiv.org/abs/2508.20223)
*Andrei Mihai Albu,Giovanni Pollo,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Alessandra Neri,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 本文提出了一种将SystemC TLM模型集成到基于FMI的协同仿真工作流中的全开源方法，解决了时间同步和数据交换等关键问题，并通过案例研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着网络物理系统复杂性的增加，特别是在汽车应用中，对高效建模和跨领域协同仿真的需求不断增加。SystemC TLM虽然能够有效支持硬件/软件协同设计，但其与其他工程领域模型的互操作性有限，导致集成困难。

Method: 本文提出了一种轻量级开源工具链，解决了时间同步和数据交换等关键技术挑战，并通过代表性案例研究验证了集成的可行性和有效性。

Result: 通过封装SystemC TLM组件为FMI 3.0 FMU，实现了跨异构仿真环境的无缝标准化集成，并通过案例研究验证了该方法的有效性。

Conclusion: 本文提出了一种将SystemC TLM模型集成到基于FMI的协同仿真工作流中的全开源方法，通过封装SystemC TLM组件为FMI 3.0协同仿真功能模型单元（FMU），实现了跨异构仿真环境的无缝标准化集成。

Abstract: The growing complexity of cyber-physical systems, particularly in automotive
applications, has increased the demand for efficient modeling and cross-domain
co-simulation techniques. While SystemC Transaction-Level Modeling (TLM)
enables effective hardware/software co-design, its limited interoperability
with models from other engineering domains poses integration challenges. This
paper presents a fully open-source methodology for integrating SystemC TLM
models into Functional Mock-up Interface (FMI)-based co-simulation workflows.
By encapsulating SystemC TLM components as FMI 3.0 Co Simulation Functional
Mock-up Units (FMUs), the proposed approach facilitates seamless, standardized
integration across heterogeneous simulation environments. We introduce a
lightweight open-source toolchain, address key technical challenges such as
time synchronization and data exchange, and demonstrate the feasibility and
effectiveness of the integration through representative case studies.

</details>


### [4] [Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities](https://arxiv.org/abs/2508.20324)
*Rikuto Kotoge,Mai Nishimura,Jiaxin Ma*

Main category: cs.CL

TL;DR: 本文提出DGPO方法，通过教师指导提升紧凑语言模型的代理RAG行为，实验证明其效果优于大型模型。


<details>
  <summary>Details</summary>
Motivation: 紧凑的语言模型（例如0.5B参数）由于推理能力差，导致奖励稀疏和训练不稳定，因此需要一种有效的方法来提升其代理RAG行为。

Method: 提出了一种名为Distillation-Guided Policy Optimization (DGPO)的方法，通过从教师演示进行冷启动初始化并在策略优化过程中持续进行教师指导来解决挑战。

Result: 实验表明，DGPO使紧凑模型能够实现复杂的代理搜索行为，甚至在某些情况下优于较大的教师模型。

Conclusion: DGPO使在计算资源受限环境中实现代理RAG成为可能。

Abstract: Reinforcement Learning has emerged as a post-training approach to elicit
agentic RAG behaviors such as search and planning from language models.
However, compact language models (e.g., 0.5B parameters) struggle due to poor
reasoning ability, resulting in sparse rewards and unstable training. To
overcome these difficulties, we propose Distillation-Guided Policy Optimization
(DGPO), which addresses the challenges through cold-start initialization from
teacher demonstrations and continuous teacher guidance during policy
optimization. To systematically evaluate our approach, we introduce Agentic RAG
Capabilities (ARC), a fine-grained metric analyzing reasoning, search
coordination, and response synthesis. Comprehensive experiments demonstrate
that DGPO enables compact models to achieve sophisticated agentic search
behaviors, even outperforming the larger teacher model in some cases. DGPO
makes agentic RAG feasible in computing resource-constrained environments.

</details>


### [5] [GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs](https://arxiv.org/abs/2508.20325)
*Haibo Jin,Ruoxi Chen,Peiyan Zhang,Andy Zhou,Yang Zhang,Haohan Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为GUARD的测试方法，用于将政府发布的伦理指南转化为具体的违反指南的问题，以评估大型语言模型（LLM）的合规性。该方法通过自动生成违反指南的问题来测试响应是否符合指南，并结合“越狱”概念进行诊断，以识别可能绕过安全机制的场景。实验结果表明，GUARD在多个LLM上有效，并且可以扩展到视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 由于政府发布的伦理指南通常是开发人员和测试人员的高层次要求，缺乏将其转化为可操作的测试问题的手段，因此需要一种方法来验证LLM的合规性。

Method: 我们引入了GUARD（G Guideline Upholding Test through A Adaptive Role-play and Jailbreak D Diagnostics），一种将指南操作化的测试方法，通过自动生成违反指南的问题来测试响应是否符合这些指南。此外，GUARD-JD结合了“越狱”概念进行诊断，以有效识别可能绕过内置安全机制的潜在场景。

Result: 我们在七种LLM上验证了GUARD的有效性，包括Vicuna-13B、LongChat-7B、Llama2-7B、Llama-3-8B、GPT-3.5、GPT-4、GPT-4o和Claude-3.7，并通过测试合规性以及进行越狱诊断来验证其效果。此外，GUARD-JD可以将越狱诊断转移到视觉语言模型中，证明其在促进可靠LLM应用中的使用。

Conclusion: 我们的方法最终生成一份合规报告，描述了遵循的程度并突出了任何违规行为。

Abstract: As Large Language Models become increasingly integral to various domains,
their potential to generate harmful responses has prompted significant societal
and regulatory concerns. In response, governments have issued ethics guidelines
to promote the development of trustworthy AI. However, these guidelines are
typically high-level demands for developers and testers, leaving a gap in
translating them into actionable testing questions to verify LLM compliance.
  To address this challenge, we introduce GUARD (\textbf{G}uideline
\textbf{U}pholding Test through \textbf{A}daptive \textbf{R}ole-play and
Jailbreak \textbf{D}iagnostics), a testing method designed to operationalize
guidelines into specific guideline-violating questions that assess LLM
adherence. To implement this, GUARD uses automated generation of
guideline-violating questions based on government-issued guidelines, thereby
testing whether responses comply with these guidelines. When responses directly
violate guidelines, GUARD reports inconsistencies. Furthermore, for responses
that do not directly violate guidelines, GUARD integrates the concept of
``jailbreaks'' to diagnostics, named GUARD-JD, which creates scenarios that
provoke unethical or guideline-violating responses, effectively identifying
potential scenarios that could bypass built-in safety mechanisms. Our method
finally culminates in a compliance report, delineating the extent of adherence
and highlighting any violations.
  We have empirically validated the effectiveness of GUARD on seven LLMs,
including Vicuna-13B, LongChat-7B, Llama2-7B, Llama-3-8B, GPT-3.5, GPT-4,
GPT-4o, and Claude-3.7, by testing compliance under three government-issued
guidelines and conducting jailbreak diagnostics. Additionally, GUARD-JD can
transfer jailbreak diagnostics to vision-language models, demonstrating its
usage in promoting reliable LLM-based applications.

</details>


### [6] [Joint Enhancement of Relational Reasoning for Long-Context LLMs](https://arxiv.org/abs/2508.20351)
*Zhirui Chen,Wei Shen,Jiashui Huang,Ling Shao*

Main category: cs.CL

TL;DR: 本文提出了一种名为 JERR 的新框架，通过图推理来增强大型语言模型在长上下文任务中的表现，实验结果表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管取得了显著进展，大型语言模型 (LLMs) 仍然由于内存限制和无法处理复杂和长上下文任务而遇到困难。此外，LLMs 常常缺乏透明度，并容易产生幻觉。为了应对这些挑战，我们提出了 JERR，一种新的框架，旨在通过图推理来增强 LLM 的长上下文理解能力。

Method: JERR 通过三个关键组件来增强长上下文理解：摘要提取、图构建和关系推理。首先，通过战略性分块文本来提取摘要，使模型能够更高效地总结和理解信息。其次，构建有向无环图 (DAG) 以解决冗余问题，确保逻辑一致性和清晰度。最后，引入蒙特卡洛树搜索 (MCTS) 来帮助模型导航复杂的推理路径，确保更准确和可解释的输出。

Result: 实验结果表明，JERR 在 ROUGE 和 F1 指标上始终优于所有基线，在 LLM-Rater 评估中取得了最高分数。

Conclusion: JERR 提供了一种新颖的解决方案，使 LLM 能够更可靠和透明地处理扩展上下文和复杂推理任务。

Abstract: Despite significant progress, large language models (LLMs) still struggle
with long contexts due to memory limitations and their inability to tackle
complex and long-context tasks. Additionally, LLMs often suffer from a lack of
transparency and are prone to producing hallucinations. To address these
challenges, we propose \textbf{JERR}, a novel framework designed to enhance
long-context comprehension via graph-based reasoning in LLMs. JERR integrates
three key components: synopsis extraction, graph construction, and relational
reasoning. First, synopsis is extracted by chunking text strategically,
allowing the model to summarize and understand information more efficiently.
Second, we build a directed acyclic graph (DAG) to resolve redundancy, ensuring
logical consistency and clarity. Finally, we incorporate Monte Carlo Tree
Search (MCTS) to help the model navigate complex reasoning paths, ensuring more
accurate and interpretable outputs. This framework provides a novel solution
that enables LLMs to handle extended contexts and complex reasoning tasks with
improved reliability and transparency. Experimental results show that JERR
consistently outperforms all baselines on the ROUGE and F1 metrics, achieving
the highest scores on the LLM-Rater evaluation.

</details>


### [7] [Graph-R1: Unleashing LLM Reasoning with NP-Hard Graph Problems](https://arxiv.org/abs/2508.20373)
*Yuyao Wang,Bowen Liu,Jianheng Tang,Nuo Chen,Yuhan Li,Qifan Zhang,Jia Li*

Main category: cs.CL

TL;DR: This paper introduces NPH graph problems as a synthetic training corpus to enhance Long CoT reasoning in LLMs through a two-stage post-training framework.


<details>
  <summary>Details</summary>
Motivation: Developing Long CoT behaviors relies heavily on post-training with high-quality datasets, which are costly and human-curated. The work aims to explore scalable alternatives.

Method: Introducing NP-hard (NPH) graph problems as a synthetic training corpus and developing a two-stage post-training framework: (i) Long CoT Supervised Fine-Tuning (SFT) on rejection-sampled NPH graph instances, and (ii) Reinforcement Learning (RL) with a fine-grained reward design.

Result: The flagship model, Graph-R1-7B, demonstrates strong generalization across mathematics, coding, STEM, and logic, and surpasses QwQ-32B on NPH graph problems in both accuracy and reasoning efficiency.

Conclusion: NPH graph problems can serve as an effective and scalable resource for advancing Long CoT reasoning in LLMs, opening a new frontier for LLM post-training.

Abstract: Reasoning Large Language Models (RLLMs) have recently achieved remarkable
progress on complex reasoning tasks, largely enabled by their long
chain-of-thought (Long CoT) capabilities. However, developing these Long CoT
behaviors relies heavily on post-training with high-quality datasets, which are
typically costly and human-curated (e.g., mathematics and code), leaving
scalable alternatives unexplored. In this work, we introduce NP-hard (NPH)
graph problems as a novel synthetic training corpus, as they inherently require
deep reasoning, extensive exploration, and reflective strategies, which are
core characteristics of Long CoT reasoning. Building on this insight, we
develop a two-stage post-training framework: (i) Long CoT Supervised
Fine-Tuning (SFT) on rejection-sampled NPH graph instances, which substantially
enhances reasoning depth, and (ii) Reinforcement Learning (RL) with a
fine-grained reward design, which sharpens reasoning efficiency. Our flagship
model, Graph-R1-7B, demonstrates strong generalization across mathematics,
coding, STEM, and logic, and surpasses QwQ-32B on NPH graph problems in both
accuracy and reasoning efficiency. These results position NPH graph problems as
an effective and scalable resource for advancing Long CoT reasoning in LLMs,
opening a new frontier for LLM post-training. Our implementation is available
at https://github.com/Graph-Reasoner/Graph-R1, with models and datasets hosted
in our Hugging Face collection HKUST-DSAIL/Graph-R1.

</details>


### [8] [CAPE: Context-Aware Personality Evaluation Framework for Large Language Models](https://arxiv.org/abs/2508.20385)
*Jivnesh Sandhan,Fei Cheng,Tushar Sandhan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 本文提出了一个上下文感知的人格评估框架，用于评估大型语言模型的行为特征，并展示了对话历史对响应一致性和人格变化的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的研究采用无上下文的方法，忽略了现实世界应用中对话历史对响应的影响。我们旨在填补这一差距。

Method: 我们提出了第一个上下文感知人格评估（CAPE）框架，结合了先前的对话交互，并引入了新的度量标准来量化LLM响应的一致性。

Result: 我们的实验揭示了对话历史通过上下文学习增强响应一致性，但也导致人格变化，GPT-3.5-Turbo和GPT-4-Turbo表现出极端偏差。GPT模型的响应源于其内在人格特质和之前的互动，而Gemini-1.5-Flash和Llama-8B则高度依赖于之前的互动。

Conclusion: 我们的框架应用于角色扮演代理（RPAs）显示，基于上下文的人格变化可以提高响应的一致性，并更好地与人类判断对齐。

Abstract: Psychometric tests, traditionally used to assess humans, are now being
applied to Large Language Models (LLMs) to evaluate their behavioral traits.
However, existing studies follow a context-free approach, answering each
question in isolation to avoid contextual influence. We term this the Disney
World test, an artificial setting that ignores real-world applications, where
conversational history shapes responses. To bridge this gap, we propose the
first Context-Aware Personality Evaluation (CAPE) framework for LLMs,
incorporating prior conversational interactions. To thoroughly analyze the
influence of context, we introduce novel metrics to quantify the consistency of
LLM responses, a fundamental trait in human behavior.
  Our exhaustive experiments on 7 LLMs reveal that conversational history
enhances response consistency via in-context learning but also induces
personality shifts, with GPT-3.5-Turbo and GPT-4-Turbo exhibiting extreme
deviations. While GPT models are robust to question ordering, Gemini-1.5-Flash
and Llama-8B display significant sensitivity. Moreover, GPT models response
stem from their intrinsic personality traits as well as prior interactions,
whereas Gemini-1.5-Flash and Llama--8B heavily depend on prior interactions.
Finally, applying our framework to Role Playing Agents (RPAs) shows
context-dependent personality shifts improve response consistency and better
align with human judgments. Our code and datasets are publicly available at:
https://github.com/jivnesh/CAPE

</details>


### [9] [Measuring Reasoning Utility in LLMs via Conditional Entropy Reduction](https://arxiv.org/abs/2508.20395)
*Xu Guo*

Main category: cs.CL

TL;DR: 研究了推理效用对最终答案正确性的影响，发现条件熵下降与正确答案相关，而错误答案通常具有平坦或上升的熵。


<details>
  <summary>Details</summary>
Motivation: 研究推理效用如何影响最终答案的正确性，因为生成更多上下文并不保证增加对答案的信心。如果能在生成过程中预测推理步骤是否有用，就可以提前停止或修剪无效步骤，避免最终决策中的干扰。

Method: 使用Qwen2.5-32B和GPT-4o生成推理链，并利用Qwen3-8B量化这些链对最终准确性的效用。测量模型在每个推理步骤上的答案跨度Y的不确定性，通过条件熵（词汇表上的期望负对数似然）随上下文逐步扩展进行评估。

Result: 结果表明，随着步骤减少的条件熵与正确答案密切相关，而平坦或增加的熵通常导致错误答案。此外，错误的推理路径往往比正确的更长，这表明更长的推理不一定带来更好的结果。

Conclusion: 这些发现为设计高效的推理管道提供了基础，以检测并避免早期无成效的推理。

Abstract: Recent advancements in large language models (LLMs) often rely on generating
intermediate reasoning steps to enhance accuracy. However, little work has
examined how reasoning utility contributes to the final answer's correctness.
Due to the stochastic nature of autoregressive generation, generating more
context does not guarantee increased confidence in the answer. If we could
predict, during generation, whether a reasoning step will be useful, we could
stop early or prune ineffective steps, avoiding distractions in the final
decision.
  We present an oracle study on MATH dataset, using Qwen2.5-32B and GPT-4o to
generate reasoning chains, and then employing a separate model (Qwen3-8B) to
quantify the utility of these chains for final accuracy. Specifically, we
measure the model's uncertainty on the answer span Y at each reasoning step
using conditional entropy (expected negative log-likelihood over the
vocabulary) with context expanding step by step. Our results show a clear
pattern: conditional entropy that decreases over steps is strongly associated
with correct answers, whereas flat or increasing entropy often results in wrong
answers. We also corroborate that incorrect reasoning paths tend to be longer
than correct ones, suggesting that longer reasoning does not necessarily yield
better outcomes. These findings serve as a foundation to inspire future work on
designing efficient reasoning pipelines that detect and avoid unproductive
reasoning early.

</details>


### [10] [UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools](https://arxiv.org/abs/2508.20410)
*Sam Jung,Agustin Garcinuno,Spencer Mateega*

Main category: cs.CL

TL;DR: UI-Bench is a large-scale benchmark that evaluates AI text-to-app tools through expert pairwise comparison, establishing a reproducible standard for AI-driven web design.


<details>
  <summary>Details</summary>
Motivation: There is no public benchmark that rigorously verifies the claims of high-quality applications and websites produced by AI text-to-app tools.

Method: UI-Bench evaluates visual excellence across competing AI text-to-app tools through expert pairwise comparison, using a TrueSkill-derived model to rank systems with calibrated confidence intervals.

Result: UI-Bench spans 10 tools, 30 prompts, 300 generated sites, and 4000+ expert judgments. It releases the complete prompt set, an open-source evaluation framework, and a public leaderboard.

Conclusion: UI-Bench establishes a reproducible standard for advancing AI-driven web design.

Abstract: AI text-to-app tools promise high quality applications and websites in
minutes, yet no public benchmark rigorously verifies those claims. We introduce
UI-Bench, the first large-scale benchmark that evaluates visual excellence
across competing AI text-to-app tools through expert pairwise comparison.
Spanning 10 tools, 30 prompts, 300 generated sites, and \textit{4000+} expert
judgments, UI-Bench ranks systems with a TrueSkill-derived model that yields
calibrated confidence intervals. UI-Bench establishes a reproducible standard
for advancing AI-driven web design. We release (i) the complete prompt set,
(ii) an open-source evaluation framework, and (iii) a public leaderboard. The
generated sites rated by participants will be released soon. View the UI-Bench
leaderboard at https://uibench.ai/leaderboard.

</details>


### [11] [DentalBench: Benchmarking and Advancing LLMs Capability for Bilingual Dentistry Understanding](https://arxiv.org/abs/2508.20416)
*Hengchuan Zhu,Yihuan Xu,Yichen Li,Zijie Meng,Zuozhu Liu*

Main category: cs.CL

TL;DR: 本文提出了DentalBench，这是一个用于评估和推进LLMs在牙科领域能力的双语基准。通过评估14个LLMs并进行领域适应实验，证明了领域适应的重要性，并强调了领域特定基准在医疗应用中的价值。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏针对牙科等专业医学领域的评估资源，现有的大型语言模型（LLMs）和医疗LLMs在这些领域的能力尚未得到充分探索。因此，本文旨在引入一个专门的基准来评估和提升LLMs在牙科领域的能力。

Method: 本文提出了DentalBench，包括两个主要组成部分：DentalQA（一个涵盖4个任务和16个牙科子领域的英中问答基准）和DentalCorpus（一个大规模、高质量的语料库，用于牙科领域适应）。此外，还评估了14个LLMs，并进行了进一步实验以验证领域适应的效果。

Result: 评估了14个LLMs，揭示了不同任务类型和语言之间的显著性能差距。进一步的实验表明，领域适应可以显著提高模型性能，尤其是在知识密集型和术语导向的任务中。

Conclusion: 本文介绍了DentalBench，这是第一个全面的双语基准，用于评估和推进LLMs在牙科领域的能力。实验结果表明，领域适应可以显著提高模型性能，并强调了领域特定基准在开发可信且有效的医疗应用LLMs中的重要性。

Abstract: Recent advances in large language models (LLMs) and medical LLMs (Med-LLMs)
have demonstrated strong performance on general medical benchmarks. However,
their capabilities in specialized medical fields, such as dentistry which
require deeper domain-specific knowledge, remain underexplored due to the lack
of targeted evaluation resources. In this paper, we introduce DentalBench, the
first comprehensive bilingual benchmark designed to evaluate and advance LLMs
in the dental domain. DentalBench consists of two main components: DentalQA, an
English-Chinese question-answering (QA) benchmark with 36,597 questions
spanning 4 tasks and 16 dental subfields; and DentalCorpus, a large-scale,
high-quality corpus with 337.35 million tokens curated for dental domain
adaptation, supporting both supervised fine-tuning (SFT) and
retrieval-augmented generation (RAG). We evaluate 14 LLMs, covering
proprietary, open-source, and medical-specific models, and reveal significant
performance gaps across task types and languages. Further experiments with
Qwen-2.5-3B demonstrate that domain adaptation substantially improves model
performance, particularly on knowledge-intensive and terminology-focused tasks,
and highlight the importance of domain-specific benchmarks for developing
trustworthy and effective LLMs tailored to healthcare applications.

</details>


### [12] [KG-CQR: Leveraging Structured Relation Representations in Knowledge Graphs for Contextual Query Retrieval](https://arxiv.org/abs/2508.20417)
*Chi Minh Bui,Ngoc Mai Thieu,Van Vinh Nguyen,Json J. Jung,Khac-Hoai Nam Bui*

Main category: cs.CL

TL;DR: KG-CQR是一种用于增强RAG系统检索阶段的新框架，它利用知识图谱来丰富查询的上下文表示，从而提高检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要解决语料级上下文丢失的问题，而KG-CQR专注于通过结构化关系表示来丰富查询。

Method: KG-CQR是一种新的框架，通过使用以语料为中心的知识图谱来增强复杂输入查询的上下文表示，包括子图提取、补全和上下文生成模块。

Result: 实验结果表明，KG-CQR在RAGBench和MultiHop-RAG数据集上表现优异，mAP提高了4-6%，Recall@25提高了2-3%。

Conclusion: KG-CQR在RAG系统中表现出色，能够显著提升检索效果，并在多跳问答等挑战性任务中优于现有基线模型。

Abstract: The integration of knowledge graphs (KGs) with large language models (LLMs)
offers significant potential to improve the retrieval phase of
retrieval-augmented generation (RAG) systems. In this study, we propose KG-CQR,
a novel framework for Contextual Query Retrieval (CQR) that enhances the
retrieval phase by enriching the contextual representation of complex input
queries using a corpus-centric KG. Unlike existing methods that primarily
address corpus-level context loss, KG-CQR focuses on query enrichment through
structured relation representations, extracting and completing relevant KG
subgraphs to generate semantically rich query contexts. Comprising subgraph
extraction, completion, and contextual generation modules, KG-CQR operates as a
model-agnostic pipeline, ensuring scalability across LLMs of varying sizes
without additional training. Experimental results on RAGBench and MultiHop-RAG
datasets demonstrate KG-CQR's superior performance, achieving a 4-6%
improvement in mAP and a 2-3% improvement in Recall@25 over strong baseline
models. Furthermore, evaluations on challenging RAG tasks such as multi-hop
question answering show that, by incorporating KG-CQR, the performance
consistently outperforms the existing baseline in terms of retrieval
effectiveness

</details>


### [13] [CAMB: A comprehensive industrial LLM benchmark on civil aviation maintenance](https://arxiv.org/abs/2508.20420)
*Feng Zhang,Chengjie Pang,Yuehan Zhang,Chenyu Luo*

Main category: cs.CL

TL;DR: 本文提出并开发了一个工业级的基准，专门用于民用航空维护领域。该基准旨在衡量LLM在该领域的表现，并识别其在领域知识和复杂推理方面的差距。通过实验，我们验证了基准的有效性，并开源了相关代码以促进进一步研究。


<details>
  <summary>Details</summary>
Motivation: 民用航空维护是一个以严格行业标准为特征的领域。在这一领域中，维护程序和故障排除是关键且知识密集型的任务，需要复杂的推理。为了应对缺乏专门评估工具来评估大型语言模型（LLMs）在这一垂直领域的能力，我们提出了一个工业级的基准。

Method: 我们提出了一个工业级的基准，专门针对民用航空维护领域。该基准有两个目的：提供一种标准化工具来衡量LLM在民用航空维护中的能力，识别领域知识和复杂推理中的具体差距。通过确定这些不足，基准为有针对性的改进工作（例如领域特定的微调、RAG优化或专门的提示工程）奠定了基础。此外，我们利用这个基准来评估现有的知名向量嵌入模型和LLMs在民用航空维护场景中的表现。

Result: 我们展示了基准在评估该领域模型性能方面的有效性，并开源了这个评估基准和代码以促进进一步的研究和发展。

Conclusion: 我们的工作填补了当前LLM评估中的一个重要空白，即主要关注数学和编码推理任务。通过实验探索和分析，我们展示了基准在评估该领域模型性能方面的有效性，并开源了这个评估基准和代码以促进进一步的研究和发展。

Abstract: Civil aviation maintenance is a domain characterized by stringent industry
standards. Within this field, maintenance procedures and troubleshooting
represent critical, knowledge-intensive tasks that require sophisticated
reasoning. To address the lack of specialized evaluation tools for large
language models (LLMs) in this vertical, we propose and develop an
industrial-grade benchmark specifically designed for civil aviation
maintenance. This benchmark serves a dual purpose: It provides a standardized
tool to measure LLM capabilities within civil aviation maintenance, identifying
specific gaps in domain knowledge and complex reasoning. By pinpointing these
deficiencies, the benchmark establishes a foundation for targeted improvement
efforts (e.g., domain-specific fine-tuning, RAG optimization, or specialized
prompt engineering), ultimately facilitating progress toward more intelligent
solutions within civil aviation maintenance. Our work addresses a significant
gap in the current LLM evaluation, which primarily focuses on mathematical and
coding reasoning tasks. In addition, given that Retrieval-Augmented Generation
(RAG) systems are currently the dominant solutions in practical applications ,
we leverage this benchmark to evaluate existing well-known vector embedding
models and LLMs for civil aviation maintenance scenarios. Through experimental
exploration and analysis, we demonstrate the effectiveness of our benchmark in
assessing model performance within this domain, and we open-source this
evaluation benchmark and code to foster further research and
development:https://github.com/CamBenchmark/cambenchmark

</details>


### [14] [Searching the Title of Practical Work of the Informatics Engineering Bachelor Program with the Case Base Reasoning Method](https://arxiv.org/abs/2508.20442)
*Agung Sukrisna Jaya,Osvari Arsalan,Danny Matthew Saputra*

Main category: cs.CL

TL;DR: 本文提出了一种基于案例库推理的实践工作标题搜索系统，利用TF-IDF和余弦相似度进行向量化和相似度计算，测试结果表明该系统在第二阶段能够获得相同数量的标题和最高的平均匹配分数。


<details>
  <summary>Details</summary>
Motivation: 为了提高实践工作标题的搜索效率和准确性，采用案例库推理技术。

Method: 使用TF-IDF对每个实践工作标题进行向量化处理，并使用余弦相似度计算相似度值。

Result: 在使用705个实践工作标题的测试中，第二阶段的结果与第一阶段相同数量的标题和最高的平均匹配分数。

Conclusion: 该系统能够有效地根据现有标题或关键词搜索实践工作标题，并在第二阶段获得相同数量的标题和最高的平均匹配分数。

Abstract: Case Base Reasoning (CBR) is a case solving technique based on experience in
cases that have occurred before with the highest similarity. CBR is used to
search for practical work titles. TF-IDF is applied to process the
vectorization of each practical work title word and Cosine Similarity for the
calculation of similarity values. This system can search either in the form of
titles or keywords. The output of the system is the title of practical work and
the match value of each title. Based on the test results using 705 practical
work titles, testing was carried out with five titles and carried out in two
stages. The first stage searches with existing titles and the second stage
randomizes the title from the first stage. And the results obtained in the
second stage are the same number of titles found and the highest average match
score.

</details>


### [15] [MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers](https://arxiv.org/abs/2508.20453)
*Zhenting Wang,Qi Chang,Hemani Patel,Shashank Biju,Cheng-En Wu,Quan Liu,Aolin Ding,Alireza Rezazadeh,Ankit Shah,Yujia Bao,Eugene Siow*

Main category: cs.CL

TL;DR: MCP-Bench是一个用于评估大型语言模型在需要工具使用、跨工具协调、精确参数控制和规划/推理的多步骤任务中的基准。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试无法充分评估模型在需要工具使用、跨工具协调、精确参数控制和规划/推理的任务中的能力。

Method: MCP-Bench基于Model Context Protocol (MCP)，连接到28个代表性的MCP服务器，这些服务器跨越了250个工具，覆盖金融、旅行、科学计算和学术搜索等领域。

Result: 实验显示，20个先进的LLMs在MCP-Bench中存在持续的挑战。

Conclusion: MCP-Bench揭示了在多步骤任务中评估大型语言模型的挑战，并提出了一个全面的评估框架。

Abstract: We introduce MCP-Bench, a benchmark for evaluating large language models
(LLMs) on realistic, multi-step tasks that demand tool use, cross-tool
coordination, precise parameter control, and planning/reasoning for solving
tasks. Built on the Model Context Protocol (MCP), MCP-Bench connects LLMs to 28
representative live MCP servers spanning 250 tools across domains such as
finance, traveling, scientific computing, and academic search. Unlike prior
API-based benchmarks, each MCP server provides a set of complementary tools
designed to work together, enabling the construction of authentic, multi-step
tasks with rich input-output coupling. Tasks in MCP-Bench test agents' ability
to retrieve relevant tools from fuzzy instructions without explicit tool names,
plan multi-hop execution trajectories for complex objectives, ground responses
in intermediate tool outputs, and orchestrate cross-domain workflows -
capabilities not adequately evaluated by existing benchmarks that rely on
explicit tool specifications, shallow few-step workflows, and isolated domain
operations. We propose a multi-faceted evaluation framework covering tool-level
schema understanding and usage, trajectory-level planning, and task completion.
Experiments on 20 advanced LLMs reveal persistent challenges in MCP-Bench. Code
and data: https://github.com/Accenture/mcp-bench.

</details>


### [16] [Prediction of mortality and resource utilization in critical care: a deep learning approach using multimodal electronic health records with natural language processing techniques](https://arxiv.org/abs/2508.20460)
*Yucheng Ruan,Xiang Lan,Daniel J. Tan,Hairil Rizal Abdullah,Mengling Feng*

Main category: cs.CL

TL;DR: 本研究提出了一种基于自然语言处理的深度学习框架，用于整合多模态EHR以预测重症监护中的死亡率和资源利用情况。实验结果表明，该模型在多个任务中均优于现有方法，并且在结构数据损坏的情况下表现出强大的弹性。


<details>
  <summary>Details</summary>
Motivation: 预测电子健康记录（EHR）中的死亡率和资源利用情况对于优化患者结果和管理重症监护室（ICU）的成本至关重要。现有的方法主要关注结构化EHR，而忽略了自由文本注释中的宝贵临床见解。此外，结构化数据中的文本信息的潜力尚未得到充分利用。

Method: 本研究引入并评估了一种使用自然语言处理技术的深度学习框架，该框架整合了多模式EHR以预测重症监护环境中的死亡率和资源利用情况。

Result: 我们的实验在两个真实世界的数据集上进行了三个临床任务，结果显示，与最佳现有方法相比，我们的模型在死亡率预测的BACC/AUROC上提高了1.6%/0.8%，在住院时间（LOS）预测的RMSE/MAE上提高了0.5%/2.2%，在手术持续时间估计的RMSE/MAE上提高了10.9%/11.0%。它在不同损坏率下的三个任务中始终表现出优于其他基线的性能。

Conclusion: 该框架是一种有效的深度学习方法，用于预测危重症护理中的死亡率和资源利用情况。研究还突显了使用变压器编码器进行提示学习在分析多模态EHR方面的成功。重要的是，该模型在结构数据中的数据损坏情况下表现出强大的弹性，尤其是在高损坏水平下。

Abstract: Background Predicting mortality and resource utilization from electronic
health records (EHRs) is challenging yet crucial for optimizing patient
outcomes and managing costs in intensive care unit (ICU). Existing approaches
predominantly focus on structured EHRs, often ignoring the valuable clinical
insights in free-text notes. Additionally, the potential of textual information
within structured data is not fully leveraged. This study aimed to introduce
and assess a deep learning framework using natural language processing
techniques that integrates multimodal EHRs to predict mortality and resource
utilization in critical care settings. Methods Utilizing two real-world EHR
datasets, we developed and evaluated our model on three clinical tasks with
leading existing methods. We also performed an ablation study on three key
components in our framework: medical prompts, free-texts, and pre-trained
sentence encoder. Furthermore, we assessed the model's robustness against the
corruption in structured EHRs. Results Our experiments on two real-world
datasets across three clinical tasks showed that our proposed model improved
performance metrics by 1.6\%/0.8\% on BACC/AUROC for mortality prediction,
0.5%/2.2% on RMSE/MAE for LOS prediction, 10.9%/11.0% on RMSE/MAE for surgical
duration estimation compared to the best existing methods. It consistently
demonstrated superior performance compared to other baselines across three
tasks at different corruption rates. Conclusions The proposed framework is an
effective and accurate deep learning approach for predicting mortality and
resource utilization in critical care. The study also highlights the success of
using prompt learning with a transformer encoder in analyzing multimodal EHRs.
Importantly, the model showed strong resilience to data corruption within
structured data, especially at high corruption levels.

</details>


### [17] [ConspirED: A Dataset for Cognitive Traits of Conspiracy Theories and Large Language Model Safety](https://arxiv.org/abs/2508.20468)
*Luke Bates,Max Glockner,Preslav Nakov,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文介绍了ConspirED数据集，用于分析阴谋论内容中的认知特征，并评估大型语言模型对阴谋论输入的鲁棒性。研究发现，这些模型在面对阴谋论内容时会产生与输入推理模式一致的输出。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成的虚假信息变得越来越复杂，理解阴谋论内容中的修辞模式对于开发干预措施（如针对性的预消解）和评估AI漏洞非常重要。

Method: 本文引入了ConspirED数据集，该数据集使用CONSPIR认知框架对在线阴谋论文章中的多句摘录进行标注。然后，我们开发了计算模型来识别阴谋论特征，并评估大型语言模型对阴谋论输入的鲁棒性。

Result: 结果显示，无论是计算模型还是大型语言模型，都与阴谋论内容存在偏差，即使成功规避了可验证的虚假信息，也会产生与输入推理模式一致的输出。

Conclusion: 本文介绍了ConspirED数据集，并展示了其在识别阴谋论特征和评估大型语言模型对阴谋论输入的鲁棒性方面的应用。结果表明，阴谋论内容会导致模型输出与输入推理模式一致，即使成功规避了可验证的虚假信息。

Abstract: Conspiracy theories erode public trust in science and institutions while
resisting debunking by evolving and absorbing counter-evidence. As AI-generated
misinformation becomes increasingly sophisticated, understanding rhetorical
patterns in conspiratorial content is important for developing interventions
such as targeted prebunking and assessing AI vulnerabilities. We introduce
ConspirED (CONSPIR Evaluation Dataset), which captures the cognitive traits of
conspiratorial ideation in multi-sentence excerpts (80--120 words) from online
conspiracy articles, annotated using the CONSPIR cognitive framework
(Lewandowsky and Cook, 2020). ConspirED is the first dataset of conspiratorial
content annotated for general cognitive traits. Using ConspirED, we (i) develop
computational models that identify conspiratorial traits and determine dominant
traits in text excerpts, and (ii) evaluate large language/reasoning model
(LLM/LRM) robustness to conspiratorial inputs. We find that both are misaligned
by conspiratorial content, producing output that mirrors input reasoning
patterns, even when successfully deflecting comparable fact-checked
misinformation.

</details>


### [18] [Languages Still Left Behind: Toward a Better Multilingual Machine Translation Benchmark](https://arxiv.org/abs/2508.20511)
*Chihiro Taguchi,Seng Mai,Keita Kurabe,Yusuke Sakai,Georgina Agyei,Soudabeh Eslami,David Chiang*

Main category: cs.CL

TL;DR: 研究发现FLORES+基准存在严重缺陷，无法准确反映真实世界的翻译挑战，建议使用领域通用和文化中立的源文本进行多语言MT评估。


<details>
  <summary>Details</summary>
Motivation: 评估现代MT系统的性能，发现FLORES+基准存在严重缺陷，无法准确反映真实世界的翻译挑战。

Method: 研究了四种语言（阿散蒂语、日语、金帕语和南阿塞拜疆语）的数据，揭示了FLORES+基准在真正多语言评估中的不足之处。进行了人工评估，并展示了简单的启发式方法可以产生非微不足道的BLEU分数。

Result: 人工评估显示许多翻译低于声称的90%质量标准，源句子往往过于特定领域且文化偏向英语世界。简单的启发式方法可以产生非微不足道的BLEU分数，表明评估协议存在漏洞。

Conclusion: 我们主张使用领域通用和文化中立的源文本，并减少对专有名词的依赖，以更好地反映现实世界的翻译挑战。

Abstract: Multilingual machine translation (MT) benchmarks play a central role in
evaluating the capabilities of modern MT systems. Among them, the FLORES+
benchmark is widely used, offering English-to-many translation data for over
200 languages, curated with strict quality control protocols. However, we study
data in four languages (Asante Twi, Japanese, Jinghpaw, and South Azerbaijani)
and uncover critical shortcomings in the benchmark's suitability for truly
multilingual evaluation. Human assessments reveal that many translations fall
below the claimed 90% quality standard, and the annotators report that source
sentences are often too domain-specific and culturally biased toward the
English-speaking world. We further demonstrate that simple heuristics, such as
copying named entities, can yield non-trivial BLEU scores, suggesting
vulnerabilities in the evaluation protocol. Notably, we show that MT models
trained on high-quality, naturalistic data perform poorly on FLORES+ while
achieving significant gains on our domain-relevant evaluation set. Based on
these findings, we advocate for multilingual MT benchmarks that use
domain-general and culturally neutral source texts rely less on named entities,
in order to better reflect real-world translation challenges.

</details>


### [19] [SciTopic: Enhancing Topic Discovery in Scientific Literature through Advanced LLM](https://arxiv.org/abs/2508.20514)
*Pengjiang Li,Zaitian Wang,Xinhao Zhang,Ran Zhang,Lu Jiang,Pengfei Wang,Yuanchun Zhou*

Main category: cs.CL

TL;DR: This paper proposes SciTopic, an advanced topic discovery method enhanced by large language models (LLMs), which outperforms existing methods in identifying scientific topics.


<details>
  <summary>Details</summary>
Motivation: Existing topic discovery methods rely on word embedding to capture semantics and lack a comprehensive understanding of scientific publications, struggling with complex, high-dimensional text relationships. Large language models (LLMs) have exceptional comprehension of textual information, which can be leveraged to improve scientific topic identification.

Method: We propose an advanced topic discovery method enhanced by large language models (LLMs), namely SciTopic. It involves building a textual encoder, constructing a space optimization module with entropy-based sampling and triplet tasks guided by LLMs, and fine-tuning the textual encoder based on the guidance from LLMs by optimizing the contrastive loss of the triplets.

Result: Extensive experiments on three real-world datasets of scientific publications demonstrate that SciTopic outperforms the state-of-the-art (SOTA) scientific topic discovery methods, enabling researchers to gain deeper and faster insights.

Conclusion: SciTopic outperforms the state-of-the-art (SOTA) scientific topic discovery methods, enabling researchers to gain deeper and faster insights.

Abstract: Topic discovery in scientific literature provides valuable insights for
researchers to identify emerging trends and explore new avenues for
investigation, facilitating easier scientific information retrieval. Many
machine learning methods, particularly deep embedding techniques, have been
applied to discover research topics. However, most existing topic discovery
methods rely on word embedding to capture the semantics and lack a
comprehensive understanding of scientific publications, struggling with
complex, high-dimensional text relationships. Inspired by the exceptional
comprehension of textual information by large language models (LLMs), we
propose an advanced topic discovery method enhanced by LLMs to improve
scientific topic identification, namely SciTopic. Specifically, we first build
a textual encoder to capture the content from scientific publications,
including metadata, title, and abstract. Next, we construct a space
optimization module that integrates entropy-based sampling and triplet tasks
guided by LLMs, enhancing the focus on thematic relevance and contextual
intricacies between ambiguous instances. Then, we propose to fine-tune the
textual encoder based on the guidance from the LLMs by optimizing the
contrastive loss of the triplets, forcing the text encoder to better
discriminate instances of different topics. Finally, extensive experiments
conducted on three real-world datasets of scientific publications demonstrate
that SciTopic outperforms the state-of-the-art (SOTA) scientific topic
discovery methods, enabling researchers to gain deeper and faster insights.

</details>


### [20] [Overview of BioASQ 2024: The twelfth BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20532)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Salvador Lima-López,Eulàlia Farré-Maduell,Martin Krallinger,Natalia Loukachevitch,Vera Davydova,Elena Tutubalina,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ是推动生物医学语义索引和问答技术发展的国际挑战赛，本届包含两个新任务和两个传统任务，参赛队伍众多且表现优异。


<details>
  <summary>Details</summary>
Motivation: BioASQ挑战赛旨在推动大规模生物医学语义索引和问答技术的进步。

Method: BioASQ挑战赛通过举办多个共享任务来促进生物医学语义索引和问答技术的发展。

Result: 本次挑战赛有37支参赛队伍，提交了超过700个不同的解决方案，大多数系统表现出了竞争力。

Conclusion: BioASQ的持续发展表明该领域技术的不断进步。

Abstract: This is an overview of the twelfth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2024. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks b and Synergy, and two
new tasks: a) MultiCardioNER on the adaptation of clinical entity detection to
the cardiology domain in a multilingual setting, and b) BIONNE on nested NER in
Russian and English. In this edition of BioASQ, 37 competing teams participated
with more than 700 distinct submissions in total for the four different shared
tasks of the challenge. Similarly to previous editions, most of the
participating systems achieved competitive performance, suggesting the
continuous advancement of the state-of-the-art in the field.

</details>


### [21] [Overview of BioASQ 2025: The Thirteenth BioASQ Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20554)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Martin Krallinger,Miguel Rodríguez-Ortega,Eduard Rodriguez-López,Natalia Loukachevitch,Andrey Sakhovskiy,Elena Tutubalina,Dimitris Dimitriadis,Grigorios Tsoumakas,George Giannakoulas,Alexandra Bekiaridou,Athanasios Samaras,Giorgio Maria Di Nunzio,Nicola Ferro,Stefano Marchesin,Marco Martinelli,Gianmaria Silvello,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ 2025 introduced new tasks and saw strong participation, highlighting advancements in biomedical question answering and semantic indexing.


<details>
  <summary>Details</summary>
Motivation: To promote advances in large-scale biomedical semantic indexing and question answering by organizing international challenges.

Method: The paper provides an overview of the BioASQ challenge, describing the tasks and the results of the competition.

Result: 83 teams participated with over 1000 submissions across six shared tasks, and several systems achieved competitive performance.

Conclusion: BioASQ 2025 demonstrated the continuous advancement of the state-of-the-art in biomedical semantic indexing and question answering through the participation of many teams and the introduction of new tasks.

Abstract: This is an overview of the thirteenth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2025. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks, b and Synergy, and four
new tasks: a) Task MultiClinSum on multilingual clinical summarization. b) Task
BioNNE-L on nested named entity linking in Russian and English. c) Task
ELCardioCC on clinical coding in cardiology. d) Task GutBrainIE on gut-brain
interplay information extraction. In this edition of BioASQ, 83 competing teams
participated with more than 1000 distinct submissions in total for the six
different shared tasks of the challenge. Similar to previous editions, several
participating systems achieved competitive performance, indicating the
continuous advancement of the state-of-the-art in the field.

</details>


### [22] [Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data](https://arxiv.org/abs/2508.20557)
*Jiahao Xiao,Jiangming Liu*

Main category: cs.CL

TL;DR: 本文提出了一种新的联邦蒸馏框架AdaFD，用于解决多领域non-IID数据带来的挑战，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的实验non-IID场景主要基于标签（输出）多样性，而没有考虑自然语言处理中至关重要的语言领域（输入）多样性。因此，需要一个更全面的基准框架来评估联邦学习在真实环境中的表现。

Method: 本文引入了一组全面的多领域非独立同分布（non-IID）场景，并提出一个统一的基准框架，用于评估联邦学习框架在真实环境中的表现。此外，还提出了自适应联邦蒸馏（AdaFD）框架来解决多领域non-IID挑战。

Result: 实验结果表明，我们的模型能够捕捉本地客户的多样性，并且在性能上优于现有工作。

Conclusion: 本文提出的AdaFD框架能够捕捉本地客户的多样性，并且在现有工作中表现更好。

Abstract: The widespread success of pre-trained language models has established a new
training paradigm, where a global PLM is fine-tuned using task-specific data
from local clients. The local data are highly different from each other and can
not capture the global distribution of the whole data in real world. To address
the challenges of non-IID data in real environments, privacy-preserving
federated distillation has been proposed and highly investigated. However,
previous experimental non-IID scenarios are primarily identified with the label
(output) diversity, without considering the diversity of language domains
(input) that is crucial in natural language processing. In this paper, we
introduce a comprehensive set of multi-domain non-IID scenarios and propose a
unified benchmarking framework that includes diverse data. The benchmark can be
used to evaluate the federated learning framework in a real environment. To
this end, we propose an Adaptive Federated Distillation (AdaFD) framework
designed to address multi-domain non-IID challenges in both homogeneous and
heterogeneous settings. Experimental results demonstrate that our models
capture the diversity of local clients and achieve better performance compared
to the existing works. The code for this paper is available at:
https://github.com/jiahaoxiao1228/AdaFD.

</details>


### [23] [Leveraging Generative Models for Real-Time Query-Driven Text Summarization in Large-Scale Web Search](https://arxiv.org/abs/2508.20559)
*Zeyu Xiong,Yixuan Nan,Li Gao,Hengzhu Tang,Shuaiqiang Wang,Junfeng Wang,Dawei Yin*

Main category: cs.CL

TL;DR: 本文提出了一个新颖的框架，用于将生成模型应用于工业网络搜索中的实时查询驱动文本摘要（QDTS）。通过集成大型模型蒸馏、监督微调、直接偏好优化和前瞻解码，将一个轻量级模型转变为领域专业化的QDTS专家。该模型在多个行业相关指标上优于生产基线，并实现了新的最先进水平，同时具有出色的部署效率。


<details>
  <summary>Details</summary>
Motivation: 传统抽取式摘要模型在工业应用中占主导地位，但存在两个关键限制：1) 多阶段流水线由于最弱组件而引入累积信息损失和架构瓶颈；2) 传统模型对用户查询和文档的语义理解不足，特别是在处理复杂搜索意图时。

Method: 我们提出了一种新颖的框架，将生成模型应用于工业网络搜索中的实时QDTS。我们的方法集成了大型模型蒸馏、监督微调、直接偏好优化和前瞻解码，将一个只有0.1B参数的轻量级模型转变为领域专业化的QDTS专家。

Result: 我们的模型在多个行业相关指标上优于生产基线，并实现了新的最先进水平。此外，它展示了出色的部署效率，只需要334块NVIDIA L20 GPU即可在每查询平均延迟55~ms的情况下处理约50,000个查询/秒。

Conclusion: 我们的模型在多个行业相关指标上优于生产基线，并实现了新的最先进水平。此外，它展示了出色的部署效率，只需要334块NVIDIA L20 GPU即可在每查询平均延迟55~ms的情况下处理约50,000个查询/秒。

Abstract: In the dynamic landscape of large-scale web search, Query-Driven Text
Summarization (QDTS) aims to generate concise and informative summaries from
textual documents based on a given query, which is essential for improving user
engagement and facilitating rapid decision-making. Traditional extractive
summarization models, based primarily on ranking candidate summary segments,
have been the dominant approach in industrial applications. However, these
approaches suffer from two key limitations: 1) The multi-stage pipeline often
introduces cumulative information loss and architectural bottlenecks due to its
weakest component; 2) Traditional models lack sufficient semantic understanding
of both user queries and documents, particularly when dealing with complex
search intents. In this study, we propose a novel framework to pioneer the
application of generative models to address real-time QDTS in industrial web
search. Our approach integrates large model distillation, supervised
fine-tuning, direct preference optimization, and lookahead decoding to
transform a lightweight model with only 0.1B parameters into a
domain-specialized QDTS expert. Evaluated on multiple industry-relevant
metrics, our model outperforms the production baseline and achieves a new state
of the art. Furthermore, it demonstrates excellent deployment efficiency,
requiring only 334 NVIDIA L20 GPUs to handle \textasciitilde50,000 queries per
second under 55~ms average latency per query.

</details>


### [24] [KCS: Diversify Multi-hop Question Generation with Knowledge Composition Sampling](https://arxiv.org/abs/2508.20567)
*Yangfan Wang,Jie Liu,Chen Tang,Lian Yan,Jingchi Jiang*

Main category: cs.CL

TL;DR: KCS is a framework that enhances multi-hop question generation by sampling varied knowledge compositions, improving accuracy and diversity in question answering.


<details>
  <summary>Details</summary>
Motivation: Multi-hop question answering faces challenges due to data sparsity, which increases the likelihood of language models learning spurious patterns. Prior approaches focus on generating simple questions and neglect the integration of essential knowledge.

Method: KCS models the knowledge composition selection as a sentence-level conditional prediction task and utilizes a probabilistic contrastive loss to predict the next most relevant piece of knowledge. During inference, a stochastic decoding strategy is employed to balance accuracy and diversity.

Result: KCS improves the overall accuracy of knowledge composition selection by 3.9%, and its application for data augmentation yields improvements on HotpotQA and 2WikiMultihopQA datasets.

Conclusion: KCS improves the overall accuracy of knowledge composition selection by 3.9% and yields improvements on HotpotQA and 2WikiMultihopQA datasets.

Abstract: Multi-hop question answering faces substantial challenges due to data
sparsity, which increases the likelihood of language models learning spurious
patterns. To address this issue, prior research has focused on diversifying
question generation through content planning and varied expression. However,
these approaches often emphasize generating simple questions and neglect the
integration of essential knowledge, such as relevant sentences within
documents. This paper introduces the Knowledge Composition Sampling (KCS), an
innovative framework designed to expand the diversity of generated multi-hop
questions by sampling varied knowledge compositions within a given context. KCS
models the knowledge composition selection as a sentence-level conditional
prediction task and utilizes a probabilistic contrastive loss to predict the
next most relevant piece of knowledge. During inference, we employ a stochastic
decoding strategy to effectively balance accuracy and diversity. Compared to
competitive baselines, our KCS improves the overall accuracy of knowledge
composition selection by 3.9%, and its application for data augmentation yields
improvements on HotpotQA and 2WikiMultihopQA datasets. Our code is available
at: https://github.com/yangfanww/kcs.

</details>


### [25] [A Graph Talks, But Who's Listening? Rethinking Evaluations for Graph-Language Models](https://arxiv.org/abs/2508.20583)
*Soham Petkar,Hari Aakash K,Anirudh Vempati,Akshit Sinha,Ponnurangam Kumarauguru,Chirag Agarwal*

Main category: cs.CL

TL;DR: 本文指出当前GLM在图推理方面存在不足，并提出了新的评估基准CLEGR来推动多模态推理的研究。


<details>
  <summary>Details</summary>
Motivation: 现有的GLM评估基准不足以评估多模态推理能力，因为它们主要基于节点级分类数据集。

Method: 引入CLEGR基准测试，设计合成图生成流程和需要联合推理结构和文本语义的问题。

Result: 软提示LLM基线的表现与包含完整GNN主干的GLM相当，GLM在需要结构推理的任务中表现显著下降。

Conclusion: 当前GLM在图推理能力上存在局限性，需要进一步研究如何将图结构与语言进行显式多模态推理。

Abstract: Developments in Graph-Language Models (GLMs) aim to integrate the structural
reasoning capabilities of Graph Neural Networks (GNNs) with the semantic
understanding of Large Language Models (LLMs). However, we demonstrate that
current evaluation benchmarks for GLMs, which are primarily repurposed
node-level classification datasets, are insufficient to assess multimodal
reasoning. Our analysis reveals that strong performance on these benchmarks is
achievable using unimodal information alone, suggesting that they do not
necessitate graph-language integration. To address this evaluation gap, we
introduce the CLEGR(Compositional Language-Graph Reasoning) benchmark, designed
to evaluate multimodal reasoning at various complexity levels. Our benchmark
employs a synthetic graph generation pipeline paired with questions that
require joint reasoning over structure and textual semantics. We perform a
thorough evaluation of representative GLM architectures and find that
soft-prompted LLM baselines perform on par with GLMs that incorporate a full
GNN backbone. This result calls into question the architectural necessity of
incorporating graph structure into LLMs. We further show that GLMs exhibit
significant performance degradation in tasks that require structural reasoning.
These findings highlight limitations in the graph reasoning capabilities of
current GLMs and provide a foundation for advancing the community toward
explicit multimodal reasoning involving graph structure and language.

</details>


### [26] [Generative Annotation for ASR Named Entity Correction](https://arxiv.org/abs/2508.20700)
*Yuanchang Luo,Daimeng Wei,Shaojun Li,Hengchao Shang,Jiaxin Guo,Zongyao Li,Zhanglin Wu,Xiaoyu Chen,Zhiqiang Rao,Jinlong Yang,Hao Yang*

Main category: cs.CL

TL;DR: 本文提出了一种新的命名实体纠正方法，利用语音声音特征来检索候选实体，并通过生成方法来注释和纠正ASR转录中的实体错误，该方法在词形差异的情况下表现出色。


<details>
  <summary>Details</summary>
Motivation: 端到端自动语音识别系统常常无法转录特定领域的命名实体，这会导致下游任务的灾难性失败。虽然已经提出了许多快速且轻量级的命名实体纠正（NEC）模型，但这些模型在错误转录的单词和真实实体形式差异较大时往往无法定位错误的单词，从而限制了其使用。

Method: 我们提出了一种新的NEC方法，利用语音声音特征来检索候选实体。结合语音声音特征和候选实体，我们创新性地设计了一种生成方法来注释ASR转录中的实体错误，并用正确的实体替换文本。

Result: 我们在开源和自建的测试集中测试了我们的方法。结果表明，我们的NEC方法可以显著提高实体准确性。

Conclusion: 我们的NEC方法在实体准确性方面带来了显著的提升，并且在词形差异的情况下表现良好。我们将会开源我们自建的测试集和训练数据。

Abstract: End-to-end automatic speech recognition systems often fail to transcribe
domain-specific named entities, causing catastrophic failures in downstream
tasks. Numerous fast and lightweight named entity correction (NEC) models have
been proposed in recent years. These models, mainly leveraging phonetic-level
edit distance algorithms, have shown impressive performances. However, when the
forms of the wrongly-transcribed words(s) and the ground-truth entity are
significantly different, these methods often fail to locate the wrongly
transcribed words in hypothesis, thus limiting their usage. We propose a novel
NEC method that utilizes speech sound features to retrieve candidate entities.
With speech sound features and candidate entities, we inovatively design a
generative method to annotate entity errors in ASR transcripts and replace the
text with correct entities. This method is effective in scenarios of word form
difference. We test our method using open-source and self-constructed test
sets. The results demonstrate that our NEC method can bring significant
improvement to entity accuracy. We will open source our self-constructed test
set and training data.

</details>


### [27] [Multi-Lingual Implicit Discourse Relation Recognition with Multi-Label Hierarchical Learning](https://arxiv.org/abs/2508.20712)
*Nelson Filipe Costa,Leila Kosseim*

Main category: cs.CL

TL;DR: 本文提出了一种新的多语言和多标签分类模型HArch，用于隐式话语关系识别，并在多个语料库上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 本文旨在开发一个能够处理多语言和多标签的隐式话语关系识别模型，以提高对话语结构的理解。

Method: 本文介绍了第一个多语言和多标签分类模型用于隐式话语关系识别（IDRR）。我们的模型HArch在最近发布的DiscoGeM 2.0语料库上进行了评估，并利用话语意义之间的层次依赖关系来预测PDTB 3.0框架中所有三个意义级别的概率分布。

Result: 我们的模型HArch在英语中表现最佳，而XLM-RoBERTa-HArch在多语言设置中表现最佳。此外，我们的微调模型在所有语言配置中都优于GPT-4o和Llama-4-Maverick。

Conclusion: 我们的模型在DiscoGeM 1.0语料库上实现了最先进的结果，进一步验证了我们层次化方法的有效性。

Abstract: This paper introduces the first multi-lingual and multi-label classification
model for implicit discourse relation recognition (IDRR). Our model, HArch, is
evaluated on the recently released DiscoGeM 2.0 corpus and leverages
hierarchical dependencies between discourse senses to predict probability
distributions across all three sense levels in the PDTB 3.0 framework. We
compare several pre-trained encoder backbones and find that RoBERTa-HArch
achieves the best performance in English, while XLM-RoBERTa-HArch performs best
in the multi-lingual setting. In addition, we compare our fine-tuned models
against GPT-4o and Llama-4-Maverick using few-shot prompting across all
language configurations. Our results show that our fine-tuned models
consistently outperform these LLMs, highlighting the advantages of
task-specific fine-tuning over prompting in IDRR. Finally, we report SOTA
results on the DiscoGeM 1.0 corpus, further validating the effectiveness of our
hierarchical approach.

</details>


### [28] [Addressing Tokenization Inconsistency in Steganography and Watermarking Based on Large Language Models](https://arxiv.org/abs/2508.20718)
*Ruiyi Yan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 本研究关注隐写术和水印技术中的tokenization inconsistency (TI)问题，并提出两种解决方案，实验表明这些方法能有效提高系统性能。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型在文本生成中的应用，隐写术和水印技术面临新的挑战，特别是TI问题会影响系统的鲁棒性。因此，需要解决TI问题以提高系统性能。

Method: 本研究通过分析TI问题的两个关键特征（罕见性和暂时性），提出了逐步验证方法和事后回滚方法来消除TI。

Result: 实验结果表明，直接解决TI可以提高隐写术的流畅性、不可察觉性和抗分析能力；对于水印技术，解决TI可以提高检测能力和抗攻击能力。

Conclusion: 本研究提出了两种针对TI消除的定制解决方案，实验表明这些方法在文本生成的隐写术和水印技术中提高了流畅性、不可察觉性和抗分析能力。

Abstract: Large language models have significantly enhanced the capacities and
efficiency of text generation. On the one hand, they have improved the quality
of text-based steganography. On the other hand, they have also underscored the
importance of watermarking as a safeguard against malicious misuse. In this
study, we focus on tokenization inconsistency (TI) between Alice and Bob in
steganography and watermarking, where TI can undermine robustness. Our
investigation reveals that the problematic tokens responsible for TI exhibit
two key characteristics: infrequency and temporariness. Based on these
findings, we propose two tailored solutions for TI elimination: a stepwise
verification method for steganography and a post-hoc rollback method for
watermarking. Experiments show that (1) compared to traditional disambiguation
methods in steganography, directly addressing TI leads to improvements in
fluency, imperceptibility, and anti-steganalysis capacity; (2) for
watermarking, addressing TI enhances detectability and robustness against
attacks.

</details>


### [29] [rStar2-Agent: Agentic Reasoning Technical Report](https://arxiv.org/abs/2508.20722)
*Ning Shang,Yifei Liu,Yi Zhu,Li Lyna Zhang,Weijiang Xu,Xinyu Guan,Buze Zhang,Bingcheng Dong,Xudong Zhou,Bowen Zhang,Ying Xin,Ziming Miao,Scarlett Li,Fan Yang,Mao Yang*

Main category: cs.CL

TL;DR: rStar2-Agent 是一个基于代理强化学习的 14B 数学推理模型，通过三种创新方法实现了高效训练和出色性能。


<details>
  <summary>Details</summary>
Motivation: 当前的长 CoT 方法存在局限性，需要一种更有效的数学推理模型来提高性能和效率。

Method: rStar2-Agent 通过三种关键创新实现了代理强化学习的有效性：高效的 RL 基础设施、GRPO-RoC 算法以及高效的代理训练方法。

Result: rStar2-Agent 在 AIME24 和 AIME25 上分别达到了 80.6% 和 69.8% 的 pass@1 分数，超越了 DeepSeek-R1，并且在其他任务中也表现出色。

Conclusion: rStar2-Agent 是一个经过代理强化学习训练的 14B 数学推理模型，展示了先进的认知行为，并在数学问题解决和其他任务中表现出色。

Abstract: We introduce rStar2-Agent, a 14B math reasoning model trained with agentic
reinforcement learning to achieve frontier-level performance. Beyond current
long CoT, the model demonstrates advanced cognitive behaviors, such as thinking
carefully before using Python coding tools and reflecting on code execution
feedback to autonomously explore, verify, and refine intermediate steps in
complex problem-solving. This capability is enabled through three key
innovations that makes agentic RL effective at scale: (i) an efficient RL
infrastructure with a reliable Python code environment that supports
high-throughput execution and mitigates the high rollout costs, enabling
training on limited GPU resources (64 MI300X GPUs); (ii) GRPO-RoC, an agentic
RL algorithm with a Resample-on-Correct rollout strategy that addresses the
inherent environment noises from coding tools, allowing the model to reason
more effectively in a code environment; (iii) An efficient agent training
recipe that starts with non-reasoning SFT and progresses through multi-RL
stages, yielding advanced cognitive abilities with minimal compute cost. To
this end, rStar2-Agent boosts a pre-trained 14B model to state of the art in
only 510 RL steps within one week, achieving average pass@1 scores of 80.6% on
AIME24 and 69.8% on AIME25, surpassing DeepSeek-R1 (671B) with significantly
shorter responses. Beyond mathematics, rStar2-Agent-14B also demonstrates
strong generalization to alignment, scientific reasoning, and agentic tool-use
tasks. Code and training recipes are available at
https://github.com/microsoft/rStar.

</details>


### [30] [Leveraging Semantic Triples for Private Document Generation with Local Differential Privacy Guarantees](https://arxiv.org/abs/2508.20736)
*Stephen Meisenbacher,Maulik Chevli,Florian Matthes*

Main category: cs.CL

TL;DR: 本文介绍了一种名为DP-ST的方法，该方法利用语义三元组在局部DP保证下进行邻域感知的私有文档生成。通过评估，我们展示了分解-征服范式的有效性，并表明当与LLM后处理结合时，可以在较低的ε值下生成连贯的文本，同时保持隐私和效用的平衡。


<details>
  <summary>Details</summary>
Motivation: 许多工作在差分隐私（DP）和自然语言处理的交叉领域旨在通过在DP保证下转换文本来保护隐私。这种转换可以通过多种方式执行，从单词扰动到完整文档重写，并且通常在本地DP下进行。这种保证非常严格，最近的研究表明，在本地DP下对文本进行私有化只能在非常高的ε值下合理完成。为了解决这个挑战，我们引入了DP-ST，它利用语义三元组进行邻域感知的私有文档生成。

Method: 我们引入了DP-ST，它利用语义三元组在局部DP保证下进行邻域感知的私有文档生成。通过评估我们的方法，我们展示了分解-征服范式的有效性，特别是在将DP概念（和隐私保证）限制为私有化邻域时。当与LLM后处理结合时，我们的方法允许在较低的ε值下生成连贯的文本。

Result: 通过评估我们的方法，我们展示了分解-征服范式的有效性，特别是在将DP概念（和隐私保证）限制为私有化邻域时。当与LLM后处理结合时，我们的方法允许在较低的ε值下生成连贯的文本，同时平衡隐私和效用。

Conclusion: 我们的方法在较低的ε值下允许连贯的文本生成，同时平衡隐私和效用。这些发现强调了在合理的ε水平下实现平衡的隐私化输出中连贯性的重要性。

Abstract: Many works at the intersection of Differential Privacy (DP) in Natural
Language Processing aim to protect privacy by transforming texts under DP
guarantees. This can be performed in a variety of ways, from word perturbations
to full document rewriting, and most often under local DP. Here, an input text
must be made indistinguishable from any other potential text, within some bound
governed by the privacy parameter $\varepsilon$. Such a guarantee is quite
demanding, and recent works show that privatizing texts under local DP can only
be done reasonably under very high $\varepsilon$ values. Addressing this
challenge, we introduce DP-ST, which leverages semantic triples for
neighborhood-aware private document generation under local DP guarantees.
Through the evaluation of our method, we demonstrate the effectiveness of the
divide-and-conquer paradigm, particularly when limiting the DP notion (and
privacy guarantees) to that of a privatization neighborhood. When combined with
LLM post-processing, our method allows for coherent text generation even at
lower $\varepsilon$ values, while still balancing privacy and utility. These
findings highlight the importance of coherence in achieving balanced
privatization outputs at reasonable $\varepsilon$ levels.

</details>


### [31] [Specializing General-purpose LLM Embeddings for Implicit Hate Speech Detection across Datasets](https://arxiv.org/abs/2508.20750)
*Vassiliy Cheremetiev,Quang Long Ho Ngo,Chau Ying Kot,Alina Elena Baia,Andrea Cavallaro*

Main category: cs.CL

TL;DR: 通过微调通用嵌入模型，该论文在隐性仇恨言论检测任务中取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 隐性仇恨言论（IHS）难以检测，因为它不包含明确的贬低或煽动性词语。为了应对这一挑战，可以补充外部知识或其他信息，如上下文、情感和情绪数据。

Method: 微调基于大型语言模型的通用嵌入模型，如Stella、Jasper、NV-Embed和E5。

Result: 在多个IHS数据集上的实验显示，对于内部数据集，F1宏评分提高了最多1.10个百分点；在跨数据集评估中，F1宏评分提高了最多20.35个百分点。

Conclusion: 通过微调基于大型语言模型的通用嵌入模型，如Stella、Jasper、NV-Embed和E5，该论文实现了最先进的性能。

Abstract: Implicit hate speech (IHS) is indirect language that conveys prejudice or
hatred through subtle cues, sarcasm or coded terminology. IHS is challenging to
detect as it does not include explicit derogatory or inflammatory words. To
address this challenge, task-specific pipelines can be complemented with
external knowledge or additional information such as context, emotions and
sentiment data. In this paper, we show that, by solely fine-tuning recent
general-purpose embedding models based on large language models (LLMs), such as
Stella, Jasper, NV-Embed and E5, we achieve state-of-the-art performance.
Experiments on multiple IHS datasets show up to 1.10 percentage points
improvements for in-dataset, and up to 20.35 percentage points improvements in
cross-dataset evaluation, in terms of F1-macro score.

</details>


### [32] [GUARD: Glocal Uncertainty-Aware Robust Decoding for Effective and Efficient Open-Ended Text Generation](https://arxiv.org/abs/2508.20757)
*Yuanhao Ding,Esteban Garces Arias,Meimingwei Li,Julian Rodemann,Matthias Aßenmacher,Danlu Chen,Gaojuan Fan,Christian Heumann,Chongsheng Zhang*

Main category: cs.CL

TL;DR: GUARD is a self-adaptive decoding method that balances text diversity and coherence by integrating global and local uncertainty signals, achieving improved generation speed and performance.


<details>
  <summary>Details</summary>
Motivation: Open-ended text generation faces a critical challenge: balancing coherence with diversity in LLM outputs. Contrastive search-based decoding strategies have limitations due to hyperparameter dependence and high computational costs.

Method: GUARD is a self-adaptive decoding method that uses a novel 'Glocal' uncertainty-driven framework, combining global entropy estimates with local entropy deviations. It also incorporates a token-count-based penalty to reduce computational overhead.

Result: GUARD effectively mitigates abrupt variations in uncertainty, provides theoretical guarantees of unbiasedness and consistency, and achieves a good balance between text diversity and coherence while improving generation speed.

Conclusion: GUARD achieves a good balance between text diversity and coherence, while exhibiting substantial improvements in generation speed. Both human and LLM evaluators validated its remarkable performance.

Abstract: Open-ended text generation faces a critical challenge: balancing coherence
with diversity in LLM outputs. While contrastive search-based decoding
strategies have emerged to address this trade-off, their practical utility is
often limited by hyperparameter dependence and high computational costs. We
introduce GUARD, a self-adaptive decoding method that effectively balances
these competing objectives through a novel "Glocal" uncertainty-driven
framework. GUARD combines global entropy estimates with local entropy
deviations to integrate both long-term and short-term uncertainty signals. We
demonstrate that our proposed global entropy formulation effectively mitigates
abrupt variations in uncertainty, such as sudden overconfidence or high entropy
spikes, and provides theoretical guarantees of unbiasedness and consistency. To
reduce computational overhead, we incorporate a simple yet effective
token-count-based penalty into GUARD. Experimental results demonstrate that
GUARD achieves a good balance between text diversity and coherence, while
exhibiting substantial improvements in generation speed. In a more nuanced
comparison study across different dimensions of text quality, both human and
LLM evaluators validated its remarkable performance. Our code is available at
https://github.com/YecanLee/GUARD.

</details>


### [33] [Feel the Difference? A Comparative Analysis of Emotional Arcs in Real and LLM-Generated CBT Sessions](https://arxiv.org/abs/2508.20764)
*Xiaoyi Wang,Jiwei Zhang,Guangtao Zhang,Honglei Guo*

Main category: cs.CL

TL;DR: 本研究比较了真实和LLM生成的认知行为疗法对话中的情感动态，发现合成对话在情感真实性方面存在明显不足，并提出了RealCBT数据集以支持未来研究。


<details>
  <summary>Details</summary>
Motivation: 评估LLM生成的治疗对话是否能捕捉真实治疗中的情感动态，以确定其在心理健康NLP中的适用性。

Method: 我们适应了Utterance Emotion Dynamics框架来分析情感轨迹，比较了真实和LLM生成的认知行为疗法对话中的情感弧线。

Result: 合成对话在情感属性上与真实对话存在显著差异：真实会话表现出更大的情感变化、更丰富的情感语言以及更真实的反应和调节模式。此外，真实和合成说话者之间的情感弧线相似性较低，尤其是对于客户而言。

Conclusion: 这些发现突显了当前LLM生成的治疗数据的局限性，并强调了在心理健康应用中情感真实性的重性。我们引入了RealCBT，一个精心策划的真实CBT会话数据集，以支持该领域的未来研究。

Abstract: Synthetic therapy dialogues generated by large language models (LLMs) are
increasingly used in mental health NLP to simulate counseling scenarios, train
models, and supplement limited real-world data. However, it remains unclear
whether these synthetic conversations capture the nuanced emotional dynamics of
real therapy. In this work, we conduct the first comparative analysis of
emotional arcs between real and LLM-generated Cognitive Behavioral Therapy
dialogues. We adapt the Utterance Emotion Dynamics framework to analyze
fine-grained affective trajectories across valence, arousal, and dominance
dimensions. Our analysis spans both full dialogues and individual speaker roles
(counselor and client), using real sessions transcribed from public videos and
synthetic dialogues from the CACTUS dataset. We find that while synthetic
dialogues are fluent and structurally coherent, they diverge from real
conversations in key emotional properties: real sessions exhibit greater
emotional variability,more emotion-laden language, and more authentic patterns
of reactivity and regulation. Moreover, emotional arc similarity between real
and synthetic speakers is low, especially for clients. These findings
underscore the limitations of current LLM-generated therapy data and highlight
the importance of emotional fidelity in mental health applications. We
introduce RealCBT, a curated dataset of real CBT sessions, to support future
research in this space.

</details>


### [34] [Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection](https://arxiv.org/abs/2508.20766)
*Harethah Abu Shairah,Hasan Abed Al Kader Hammoud,George Turkiyyah,Bernard Ghanem*

Main category: cs.CL

TL;DR: 本文提出了一种名为Rank-One Safety Injection (ROSI) 的新方法，用于增强大型语言模型的安全对齐。ROSI通过永久性地将模型的激活引导到拒绝中介子空间来实现这一点，无需微调。实验结果显示，ROSI能显著提高模型的安全拒绝率，同时保持其在标准基准测试中的性能。


<details>
  <summary>Details</summary>
Motivation: 安全对齐在大型语言模型（LLMs）中通常涉及调解内部表示以拒绝有害请求。最近的研究表明，这些安全机制可以通过消融或移除模型中的特定表示方向来绕过。

Method: 我们提出了Rank-One Safety Injection (ROSI)，这是一种白盒方法，通过永久性地将模型的激活引导到拒绝中介子空间来增强模型的安全对齐。ROSI作为一种简单的、无需微调的秩一权重修改应用于所有残差流写入矩阵。

Result: ROSI一致地提高了安全性拒绝率——根据Llama Guard 3评估——同时保持了模型在标准基准测试（如MMLU、HellaSwag和Arc）上的实用性。此外，ROSI还可以通过放大其自身的潜在安全方向来重新对齐'未审查'模型，证明了其作为有效最后一公里安全程序的实用性。

Conclusion: 我们的结果表明，有针对性的、可解释的权重引导是一种廉价而有效的机制，可以提高LLM的安全性，补充了更耗费资源的微调范式。

Abstract: Safety alignment in Large Language Models (LLMs) often involves mediating
internal representations to refuse harmful requests. Recent research has
demonstrated that these safety mechanisms can be bypassed by ablating or
removing specific representational directions within the model. In this paper,
we propose the opposite approach: Rank-One Safety Injection (ROSI), a white-box
method that amplifies a model's safety alignment by permanently steering its
activations toward the refusal-mediating subspace. ROSI operates as a simple,
fine-tuning-free rank-one weight modification applied to all residual stream
write matrices. The required safety direction can be computed from a small set
of harmful and harmless instruction pairs. We show that ROSI consistently
increases safety refusal rates - as evaluated by Llama Guard 3 - while
preserving the utility of the model on standard benchmarks such as MMLU,
HellaSwag, and Arc. Furthermore, we show that ROSI can also re-align
'uncensored' models by amplifying their own latent safety directions,
demonstrating its utility as an effective last-mile safety procedure. Our
results suggest that targeted, interpretable weight steering is a cheap and
potent mechanism to improve LLM safety, complementing more resource-intensive
fine-tuning paradigms.

</details>


### [35] [Signs of Struggle: Spotting Cognitive Distortions across Language and Register](https://arxiv.org/abs/2508.20771)
*Abhishek Kuber,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah*

Main category: cs.CL

TL;DR: 本研究探讨了跨语言和跨注册的自动检测认知扭曲的方法，并发现领域自适应方法在处理不同语言和写作风格时表现最佳。


<details>
  <summary>Details</summary>
Motivation: 青年心理健康问题的上升促使人们关注自动化方法来检测数字文本中早期心理困扰的迹象。认知扭曲是心理困扰的重要因素，早期检测可能有助于及时、低成本的干预。

Method: 本研究分析了由荷兰青少年撰写的论坛帖子，进行了跨语言和跨注册的认知扭曲检测的深入研究。

Result: 研究发现，语言和写作风格的变化对模型性能有显著影响，而领域自适应方法表现出最大的潜力。

Conclusion: 研究发现，尽管语言和写作风格的变化会显著影响模型性能，但领域自适应方法显示出最大的潜力。

Abstract: Rising mental health issues among youth have increased interest in automated
approaches for detecting early signs of psychological distress in digital text.
One key focus is the identification of cognitive distortions, irrational
thought patterns that have a role in aggravating mental distress. Early
detection of these distortions may enable timely, low-cost interventions. While
prior work has focused on English clinical data, we present the first in-depth
study of cross-lingual and cross-register generalization of cognitive
distortion detection, analyzing forum posts written by Dutch adolescents. Our
findings show that while changes in language and writing style can
significantly affect model performance, domain adaptation methods show the most
promise.

</details>


### [36] [Exploring Machine Learning and Language Models for Multimodal Depression Detection](https://arxiv.org/abs/2508.20805)
*Javier Si Zhao Hong,Timothy Zoe Delaya,Sherwyn Chan Yin Kit,Pai Chet Ng,Xiaoxiao Miao*

Main category: cs.CL

TL;DR: 本文比较了多种机器学习和深度学习模型在多模态抑郁检测中的表现，并提供了有效的多模态表示策略的见解。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索和比较不同机器学习和深度学习模型在多模态抑郁检测中的表现。

Method: 本文比较了XGBoost、基于Transformer的架构和大型语言模型（LLMs）在音频、视频和文本特征上的性能。

Result: 本文的结果突出了每种模型在捕捉抑郁相关信号方面的优缺点。

Conclusion: 本文总结了不同模型在多模态抑郁检测中的优缺点，并提供了有效的多模态表示策略的见解。

Abstract: This paper presents our approach to the first Multimodal Personality-Aware
Depression Detection Challenge, focusing on multimodal depression detection
using machine learning and deep learning models. We explore and compare the
performance of XGBoost, transformer-based architectures, and large language
models (LLMs) on audio, video, and text features. Our results highlight the
strengths and limitations of each type of model in capturing depression-related
signals across modalities, offering insights into effective multimodal
representation strategies for mental health prediction.

</details>


### [37] [GDLLM: A Global Distance-aware Modeling Approach Based on Large Language Models for Event Temporal Relation Extraction](https://arxiv.org/abs/2508.20828)
*Jie Zhao,Wanting Ning,Yuxiao Fei,Yubo Feng,Lishuang Li*

Main category: cs.CL

TL;DR: 本文提出了GDLLM，一种基于LLMs的全局距离感知建模方法，通过距离感知图结构和基于软推理的时间特征学习范式，显著提升了少数关系类的性能，并在两个公开数据集上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 先前的研究已经认识到语言模型在ETRE中的重要性。然而，小型语言模型（SLMs）的预训练知识有限，限制了它们处理不平衡分类数据集中的少数类关系的能力。对于大型语言模型（LLMs），研究人员采用手动设计的提示或指令，这可能会引入额外的噪声，导致干扰模型对事件之间长距离依赖关系的判断。

Method: 我们提出了GDLLM，一种基于LLMs的全局距离感知建模方法。首先，我们提出了一种距离感知图结构，利用图注意力网络（GAT）帮助LLMs捕捉长距离依赖特征。此外，我们设计了一种基于软推理的时间特征学习范式，以增强对短距离邻近带的关系识别，这将LLMs生成的概率信息补充到多头注意力机制中。

Result: 在两个公开可用的数据集TB-Dense和MATRES上的实验表明，我们的方法达到了最先进的（SOTA）性能。

Conclusion: 我们的框架显著提升了少数关系类的性能，并提高了整体学习能力。

Abstract: In Natural Language Processing(NLP), Event Temporal Relation Extraction
(ETRE) is to recognize the temporal relations of two events. Prior studies have
noted the importance of language models for ETRE. However, the restricted
pre-trained knowledge of Small Language Models(SLMs) limits their capability to
handle minority class relations in imbalanced classification datasets. For
Large Language Models(LLMs), researchers adopt manually designed prompts or
instructions, which may introduce extra noise, leading to interference with the
model's judgment of the long-distance dependencies between events. To address
these issues, we propose GDLLM, a Global Distance-aware modeling approach based
on LLMs. We first present a distance-aware graph structure utilizing Graph
Attention Network(GAT) to assist the LLMs in capturing long-distance dependency
features. Additionally, we design a temporal feature learning paradigm based on
soft inference to augment the identification of relations with a short-distance
proximity band, which supplements the probabilistic information generated by
LLMs into the multi-head attention mechanism. Since the global feature can be
captured effectively, our framework substantially enhances the performance of
minority relation classes and improves the overall learning ability.
Experiments on two publicly available datasets, TB-Dense and MATRES,
demonstrate that our approach achieves state-of-the-art (SOTA) performance.

</details>


### [38] [MSRS: Evaluating Multi-Source Retrieval-Augmented Generation](https://arxiv.org/abs/2508.20867)
*Rohan Phanse,Yijie Zhou,Kejian Shi,Wencai Zhang,Yixin Liu,Yilun Zhao,Arman Cohan*

Main category: cs.CL

TL;DR: 本文提出了一个可扩展的框架，用于构建评估基准，以挑战RAG系统在不同来源之间整合信息并生成长格式响应的能力。通过该框架，我们构建了两个新的基准：MSRS-Story和MSRS-Meet，分别代表叙事合成和摘要任务。实验结果表明，生成质量高度依赖于检索效果，而多源合成即使在理想检索设置下也具有挑战性，但推理模型在此步骤上表现优于标准LLM。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统评估通常是在信息可以找到于单一来源或答案是简短形式或事实性的情况下进行的。然而，许多现实世界的应用需要能够整合和总结跨多个来源的信息，其中没有一个来源足以回答用户的问题。

Method: 我们提出了一种可扩展的框架，用于构建评估基准，这些基准挑战RAG系统在不同来源之间整合信息并生成长格式响应的能力。使用该框架，我们构建了两个新的基准：MSRS-Story和MSRS-Meet，分别代表叙事合成和摘要任务，需要从大型集合中进行检索。

Result: 我们对各种RAG管道（包括稀疏和密集检索器结合前沿LLM）进行了广泛的实验，结果表明生成质量高度依赖于检索效果，而检索效果在不同任务中差异很大。虽然多源合成在理想检索设置下仍然具有挑战性，但推理模型在此步骤上表现优于标准LLM。

Conclusion: 我们的实验表明，生成质量高度依赖于检索效果，而检索效果在不同任务中差异很大。尽管多源合成在理想检索设置下仍然具有挑战性，但我们发现推理模型在这个步骤上显著优于标准LLM。

Abstract: Retrieval-augmented systems are typically evaluated in settings where
information required to answer the query can be found within a single source or
the answer is short-form or factoid-based. However, many real-world
applications demand the ability to integrate and summarize information
scattered across multiple sources, where no single source is sufficient to
respond to the user's question. In such settings, the retrieval component of a
RAG pipeline must recognize a variety of relevance signals, and the generation
component must connect and synthesize information across multiple sources. We
present a scalable framework for constructing evaluation benchmarks that
challenge RAG systems to integrate information across distinct sources and
generate long-form responses. Using our framework, we build two new benchmarks
on Multi-Source Retrieval and Synthesis: MSRS-Story and MSRS-Meet, representing
narrative synthesis and summarization tasks, respectively, that require
retrieval from large collections. Our extensive experiments with various RAG
pipelines -- including sparse and dense retrievers combined with frontier LLMs
-- reveal that generation quality is highly dependent on retrieval
effectiveness, which varies greatly by task. While multi-source synthesis
proves challenging even in an oracle retrieval setting, we find that reasoning
models significantly outperform standard LLMs at this distinct step.

</details>


### [39] [The Uneven Impact of Post-Training Quantization in Machine Translation](https://arxiv.org/abs/2508.20893)
*Benjamin Marie,Atsushi Fujita*

Main category: cs.CL

TL;DR: 本研究评估了量化对多语言机器翻译的影响，发现不同量化技术和模型大小对性能有显著影响，并提出了在低资源设置中部署多语言LLM的见解。


<details>
  <summary>Details</summary>
Motivation: 量化对于在资源受限硬件上部署大型语言模型（LLMs）至关重要，但其对多语言任务的影响仍未得到充分研究。

Method: 我们进行了首次大规模评估，使用五个从1.7B到70B参数的LLM，在55种语言上对训练后量化（PTQ）进行了评估。我们比较了四种量化技术（AWQ、BitsAndBytes、GGUF和AutoRound），并分析了量化、解码超参数和校准语言之间的相互作用。

Result: 4位量化通常能保持高资源语言和大型模型的翻译质量，但在低资源和语言学多样化的语言中会出现显著退化，尤其是在2位设置中。GGUF变体在2位精度下也表现出最一致的性能。此外，我们量化了量化、解码超参数和校准语言之间的相互作用，发现语言匹配的校准主要在低比特情况下有益。

Conclusion: 我们的研究提供了在量化约束下部署多语言LLM进行机器翻译的可行见解，特别是在低资源设置中。

Abstract: Quantization is essential for deploying large language models (LLMs) on
resource-constrained hardware, but its implications for multilingual tasks
remain underexplored. We conduct the first large-scale evaluation of
post-training quantization (PTQ) on machine translation across 55 languages
using five LLMs ranging from 1.7B to 70B parameters. Our analysis reveals that
while 4-bit quantization often preserves translation quality for high-resource
languages and large models, significant degradation occurs for low-resource and
typologically diverse languages, particularly in 2-bit settings. We compare
four quantization techniques (AWQ, BitsAndBytes, GGUF, and AutoRound), showing
that algorithm choice and model size jointly determine robustness. GGUF
variants provide the most consistent performance, even at 2-bit precision.
Additionally, we quantify the interactions between quantization, decoding
hyperparameters, and calibration languages, finding that language-matched
calibration offers benefits primarily in low-bit scenarios. Our findings offer
actionable insights for deploying multilingual LLMs for machine translation
under quantization constraints, especially in low-resource settings.

</details>


### [40] [SageLM: A Multi-aspect and Explainable Large Language Model for Speech Judgement](https://arxiv.org/abs/2508.20916)
*Yuan Ge,Junxiang Zhang,Xiaoqian Liu,Bei Li,Xiangnan Ma,Chenglong Wang,Kaiyang Ye,Yangfan Du,Linfeng Zhang,Yuxin Huang,Tong Xiao,Zhengtao Yu,JingBo Zhu*

Main category: cs.CL

TL;DR: 本文提出了SageLM，这是一种用于全面评估语音到语音大型语言模型的端到端、多方面和可解释的方法，通过联合评估语义和声学维度以及使用合成偏好数据集，取得了优于现有方法的结果。


<details>
  <summary>Details</summary>
Motivation: 评估语音到语音大型语言模型仍然是一个基本挑战，因此需要一种端到端、多方面且可解释的评估方法。

Method: SageLM联合评估语义和声学维度，并利用基于推理的监督来提高可解释性。此外，引入了SpeechFeedback合成偏好数据集，并采用两阶段训练范式以减轻语音偏好数据的稀缺性。

Result: SageLM在与人类评估者的协议率上达到了82.79%，比级联和SLM基线分别高出至少7.42%和26.20%。

Conclusion: SageLM在语音语言模型评估中表现出色，与人类评估者的协议率达到82.79%，优于级联和SLM基线。

Abstract: Speech-to-Speech (S2S) Large Language Models (LLMs) are foundational to
natural human-computer interaction, enabling end-to-end spoken dialogue
systems. However, evaluating these models remains a fundamental challenge. We
propose \texttt{SageLM}, an end-to-end, multi-aspect, and explainable speech
LLM for comprehensive S2S LLMs evaluation. First, unlike cascaded approaches
that disregard acoustic features, SageLM jointly assesses both semantic and
acoustic dimensions. Second, it leverages rationale-based supervision to
enhance explainability and guide model learning, achieving superior alignment
with evaluation outcomes compared to rule-based reinforcement learning methods.
Third, we introduce \textit{SpeechFeedback}, a synthetic preference dataset,
and employ a two-stage training paradigm to mitigate the scarcity of speech
preference data. Trained on both semantic and acoustic dimensions, SageLM
achieves an 82.79\% agreement rate with human evaluators, outperforming
cascaded and SLM-based baselines by at least 7.42\% and 26.20\%, respectively.

</details>


### [41] [How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on $τ$-bench](https://arxiv.org/abs/2508.20931)
*Venkatesh Mishra,Amir Saeidi,Satyam Raj,Mutsumi Nakamura,Jayanth Srinivasa,Gaowen Liu,Ali Payani,Chitta Baral*

Main category: cs.CL

TL;DR: 本文提出了一种名为IRMA的框架，通过重新表述用户查询并结合相关领域规则和工具建议，显著提高了工具调用代理在动态环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 在多轮对话环境如τ-bench中，这些代理常常在一致推理、遵守特定领域政策以及从长工具调用和对话中提取正确信息方面遇到困难。为了捕捉和减轻这些失败，我们进行了全面的手动分析。

Method: 我们进行了对对话轨迹中常见错误的全面手动分析，并尝试了对工具调用代理的输入进行重新表述以改进代理决策。最后，我们提出了Input-Reformulation Multi-Agent (IRMA)框架，该框架自动重新表述用户查询，并结合相关领域规则和工具建议，使工具调用代理能够专注于此。

Result: 结果表明，IRMA在整体pass^5分数上分别比ReAct、Function Calling和Self-Reflection高出16.1%、12.7%和19.1%。

Conclusion: 这些发现突显了IRMA在动态环境中的优越可靠性和一致性。

Abstract: Recent advances in reasoning and planning capabilities of large language
models (LLMs) have enabled their potential as autonomous agents capable of tool
use in dynamic environments. However, in multi-turn conversational environments
like $\tau$-bench, these agents often struggle with consistent reasoning,
adherence to domain-specific policies, and extracting correct information over
a long horizon of tool-calls and conversation. To capture and mitigate these
failures, we conduct a comprehensive manual analysis of the common errors
occurring in the conversation trajectories. We then experiment with
reformulations of inputs to the tool-calling agent for improvement in agent
decision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA)
framework, which automatically reformulates user queries augmented with
relevant domain rules and tool suggestions for the tool-calling agent to focus
on. The results show that IRMA significantly outperforms ReAct, Function
Calling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in
overall pass^5 scores. These findings highlight the superior reliability and
consistency of IRMA compared to other methods in dynamic environments.

</details>


### [42] [STARE at the Structure: Steering ICL Exemplar Selection with Structural Alignment](https://arxiv.org/abs/2508.20944)
*Jiaqian Li,Qisheng Hu,Jing Li,Wenya Wang*

Main category: cs.CL

TL;DR: 本文提出一种两阶段的示例选择策略，以提高结构预测任务中的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的ICL选择策略在结构预测任务中常常忽略结构对齐，导致性能不佳和泛化能力差。

Method: 我们提出了一种两阶段的示例选择策略，首先使用结构感知监督微调基于BERT的检索器，然后通过一个插件模块增强检索器。

Result: 实验表明，我们的方法在三个语义解析任务的四个基准测试中表现优异。

Conclusion: 我们的方法在多个基准测试中表现出色，优于现有的基线方法。

Abstract: In-Context Learning (ICL) has become a powerful paradigm that enables LLMs to
perform a wide range of tasks without task-specific fine-tuning. However, the
effectiveness of ICL heavily depends on the quality of exemplar selection. In
particular, for structured prediction tasks such as semantic parsing, existing
ICL selection strategies often overlook structural alignment, leading to
suboptimal performance and poor generalization. To address this issue, we
propose a novel two-stage exemplar selection strategy that achieves a strong
balance between efficiency, generalizability, and performance. First, we
fine-tune a BERT-based retriever using structure-aware supervision, guiding it
to select exemplars that are both semantically relevant and structurally
aligned. Then, we enhance the retriever with a plug-in module, which amplifies
syntactically meaningful information in the hidden representations. This
plug-in is model-agnostic, requires minimal overhead, and can be seamlessly
integrated into existing pipelines. Experiments on four benchmarks spanning
three semantic parsing tasks demonstrate that our method consistently
outperforms existing baselines with multiple recent LLMs as inference-time
models.

</details>


### [43] [ProactiveEval: A Unified Evaluation Framework for Proactive Dialogue Agents](https://arxiv.org/abs/2508.20973)
*Tianjian Liu,Fanqi Wan,Jiajian Guo,Xiaojun Quan*

Main category: cs.CL

TL;DR: 本文提出了一种统一的框架ProactiveEval，用于评估大型语言模型的主动对话能力，并展示了DeepSeek-R1和Claude-3.7-Sonnet在相关任务中的优秀表现。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要集中在特定领域或任务导向的场景中，这导致了评估的碎片化，并限制了对模型主动对话能力的全面探索。因此，需要一种统一的框架来评估大型语言模型的主动对话能力。

Method: 本文提出了ProactiveEval框架，该框架将主动对话分解为目标规划和对话引导，并建立了跨多个领域的评估指标。此外，它还能够自动生成多样且具有挑战性的评估数据。

Result: 基于所提出的框架，我们开发了328个跨越6个不同领域的评估环境。通过与22种不同类型的LLMs进行实验，我们发现DeepSeek-R1和Claude-3.7-Sonnet分别在目标规划和对话引导任务中表现出色。

Conclusion: 本文提出了ProactiveEval框架，用于评估大型语言模型的主动对话能力，并展示了DeepSeek-R1和Claude-3.7-Sonnet在目标规划和对话引导任务中的出色表现。最后，我们研究了推理能力如何影响主动行为，并讨论了其对未来模型开发的影响。

Abstract: Proactive dialogue has emerged as a critical and challenging research problem
in advancing large language models (LLMs). Existing works predominantly focus
on domain-specific or task-oriented scenarios, which leads to fragmented
evaluations and limits the comprehensive exploration of models' proactive
conversation abilities. In this work, we propose ProactiveEval, a unified
framework designed for evaluating proactive dialogue capabilities of LLMs. This
framework decomposes proactive dialogue into target planning and dialogue
guidance, establishing evaluation metrics across various domains. Moreover, it
also enables the automatic generation of diverse and challenging evaluation
data. Based on the proposed framework, we develop 328 evaluation environments
spanning 6 distinct domains. Through experiments with 22 different types of
LLMs, we show that DeepSeek-R1 and Claude-3.7-Sonnet exhibit exceptional
performance on target planning and dialogue guidance tasks, respectively.
Finally, we investigate how reasoning capabilities influence proactive
behaviors and discuss their implications for future model development.

</details>


### [44] [Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution](https://arxiv.org/abs/2508.21004)
*Chen Chen,Yuchen Sun,Jiaxin Gao,Xueluan Gong,Qian Wang,Ziyao Wang,Yongsen Zheng,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: LETHE is a novel method for eliminating backdoor behaviors in large language models using knowledge dilution, achieving high effectiveness and efficiency against various backdoor attacks.


<details>
  <summary>Details</summary>
Motivation: Existing backdoor defenses are insufficient as they lack comprehensiveness, focus on narrow trigger settings, and fail to withstand advanced scenarios like model-editing-based, multi-trigger, and triggerless attacks.

Method: LETHE uses knowledge dilution through both internal and external mechanisms. Internally, it trains a clean model with a lightweight dataset and merges it with the backdoored model to neutralize malicious behaviors. Externally, it incorporates benign and semantically relevant evidence into the prompt to distract the model from backdoor features.

Result: LETHE outperforms 8 state-of-the-art defense baselines against 8 backdoor attacks. It reduces the attack success rate of advanced backdoor attacks by up to 98% while maintaining model utility.

Conclusion: LETHE is a cost-efficient and robust method for eliminating backdoor behaviors in large language models, demonstrating superior performance against various backdoor attacks while maintaining model utility.

Abstract: Large language models (LLMs) have seen significant advancements, achieving
superior performance in various Natural Language Processing (NLP) tasks.
However, they remain vulnerable to backdoor attacks, where models behave
normally for standard queries but generate harmful responses or unintended
output when specific triggers are activated. Existing backdoor defenses either
lack comprehensiveness, focusing on narrow trigger settings, detection-only
mechanisms, and limited domains, or fail to withstand advanced scenarios like
model-editing-based, multi-trigger, and triggerless attacks. In this paper, we
present LETHE, a novel method to eliminate backdoor behaviors from LLMs through
knowledge dilution using both internal and external mechanisms. Internally,
LETHE leverages a lightweight dataset to train a clean model, which is then
merged with the backdoored model to neutralize malicious behaviors by diluting
the backdoor impact within the model's parametric memory. Externally, LETHE
incorporates benign and semantically relevant evidence into the prompt to
distract LLM's attention from backdoor features. Experimental results on
classification and generation domains across 5 widely used LLMs demonstrate
that LETHE outperforms 8 state-of-the-art defense baselines against 8 backdoor
attacks. LETHE reduces the attack success rate of advanced backdoor attacks by
up to 98% while maintaining model utility. Furthermore, LETHE has proven to be
cost-efficient and robust against adaptive backdoor attacks.

</details>


### [45] [An Agile Method for Implementing Retrieval Augmented Generation Tools in Industrial SMEs](https://arxiv.org/abs/2508.21024)
*Mathieu Bourdin,Anas Neumann,Thomas Paviot,Robert Pellerin,Samir Lamouri*

Main category: cs.CL

TL;DR: 本文介绍了一种名为EASI-RAG的方法，用于在工业中小企业中快速部署RAG系统，通过实际案例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于资源有限和缺乏自然语言处理（NLP）专业知识，中小企业部署基于RAG的工具面临挑战。本文提出EASI-RAG以解决这一问题。

Method: EASI-RAG基于方法工程原理，包含明确的角色、活动和技术，旨在支持工业中小企业中RAG系统的部署。

Result: 在环境测试实验室的实际案例研究中，EASI-RAG被用于回答操作员查询，系统在一个月内由无RAG经验的团队部署，并根据用户反馈进行迭代改进。结果表明EASI-RAG能够快速实施并提供准确答案。

Conclusion: 本文展示了EASI-RAG在工业中小企业中部署RAG系统的潜力，强调了其快速实施、高用户采用率、准确回答和增强数据可靠性的能力。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful solution to
mitigate the limitations of Large Language Models (LLMs), such as
hallucinations and outdated knowledge. However, deploying RAG-based tools in
Small and Medium Enterprises (SMEs) remains a challenge due to their limited
resources and lack of expertise in natural language processing (NLP). This
paper introduces EASI-RAG, Enterprise Application Support for Industrial RAG, a
structured, agile method designed to facilitate the deployment of RAG systems
in industrial SME contexts. EASI-RAG is based on method engineering principles
and comprises well-defined roles, activities, and techniques. The method was
validated through a real-world case study in an environmental testing
laboratory, where a RAG tool was implemented to answer operators queries using
data extracted from operational procedures. The system was deployed in under a
month by a team with no prior RAG experience and was later iteratively improved
based on user feedback. Results demonstrate that EASI-RAG supports fast
implementation, high user adoption, delivers accurate answers, and enhances the
reliability of underlying data. This work highlights the potential of RAG
deployment in industrial SMEs. Future works include the need for generalization
across diverse use cases and further integration with fine-tuned models.

</details>


### [46] [Re-Representation in Sentential Relation Extraction with Sequence Routing Algorithm](https://arxiv.org/abs/2508.21049)
*Ramazan Ali Bahrami,Ramin Yahyapour*

Main category: cs.CL

TL;DR: 本文提出了一种基于动态路由的胶囊网络用于句子关系抽取，并发现标签噪声和重新表示是影响性能的关键因素。


<details>
  <summary>Details</summary>
Motivation: 我们希望改进句子关系抽取的性能，并探索影响模型表现的因素。

Method: 我们提出使用动态路由的胶囊网络进行句子关系抽取，并通过实验验证了其有效性。

Result: 我们的方法在常见的句子关系抽取数据集上优于最先进的方法，但在更大的Wikidata数据集上表现不佳，这可能是由于标签噪声所致。

Conclusion: 我们的观察表明，所提出的模型在重新表示方面优于与之比较的普通模型。除了遥远监督RE数据集中的标签噪声外，我们提出了重新表示作为句子RE的一个挑战。

Abstract: Sentential relation extraction (RE) is an important task in natural language
processing (NLP). In this paper we propose to do sentential RE with dynamic
routing in capsules. We first show that the proposed approach outperform state
of the art on common sentential relation extraction datasets Tacred, Tacredrev,
Retacred, and Conll04. We then investigate potential reasons for its good
performance on the mentioned datasets, and yet low performance on another
similar, yet larger sentential RE dataset, Wikidata. As such, we identify noise
in Wikidata labels as one of the reasons that can hinder performance.
Additionally, we show associativity of better performance with better
re-representation, a term from neuroscience referred to change of
representation in human brain to improve the match at comparison time. As
example, in the given analogous terms King:Queen::Man:Woman, at comparison
time, and as a result of re-representation, the similarity between related head
terms (King,Man), and tail terms (Queen,Woman) increases. As such, our
observation show that our proposed model can do re-representation better than
the vanilla model compared with. To that end, beside noise in the labels of the
distantly supervised RE datasets, we propose re-representation as a challenge
in sentential RE.

</details>


### [47] [Enabling Equitable Access to Trustworthy Financial Reasoning](https://arxiv.org/abs/2508.21051)
*William Jurayj,Nils Holzenberger,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 本文提出了一种将大型语言模型与符号求解器结合的方法，用于计算税款义务，并展示了其在SARA数据集上的性能提升和成本降低的潜力。


<details>
  <summary>Details</summary>
Motivation: 由于错误可能导致昂贵的罚款，任何自动化系统都必须提供高精度和可审计性，这使得现代大型语言模型不适合此任务。

Method: 我们提出了一种将大型语言模型与符号求解器相结合的方法，以计算税款义务，并评估了这种系统在SARA数据集上的变体。

Result: 通过将纯文本规则提前转换为形式逻辑程序，并结合智能检索的示例进行形式化案例表示，可以显著提高此任务的性能，并将成本降低到低于现实世界的平均水平。

Conclusion: 我们的结果展示了神经符号架构在增加公平获取可靠税务协助方面的前景和经济可行性。

Abstract: According to the United States Internal Revenue Service, ''the average
American spends $\$270$ and 13 hours filing their taxes''. Even beyond the
U.S., tax filing requires complex reasoning, combining application of
overlapping rules with numerical calculations. Because errors can incur costly
penalties, any automated system must deliver high accuracy and auditability,
making modern large language models (LLMs) poorly suited for this task. We
propose an approach that integrates LLMs with a symbolic solver to calculate
tax obligations. We evaluate variants of this system on the challenging
StAtutory Reasoning Assessment (SARA) dataset, and include a novel method for
estimating the cost of deploying such a system based on real-world penalties
for tax errors. We further show how combining up-front translation of
plain-text rules into formal logic programs, combined with intelligently
retrieved exemplars for formal case representations, can dramatically improve
performance on this task and reduce costs to well below real-world averages.
Our results demonstrate the promise and economic feasibility of neuro-symbolic
architectures for increasing equitable access to reliable tax assistance.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [48] [Leveraging Large Language Models for Generating Research Topic Ontologies: A Multi-Disciplinary Study](https://arxiv.org/abs/2508.20693)
*Tanay Aggarwal,Angelo Salatino,Francesco Osborne,Enrico Motta*

Main category: cs.DL

TL;DR: 本研究探讨了大型语言模型在识别研究主题之间语义关系方面的潜力，并引入了一个新的数据集PEM-Rel-8K，实验结果表明微调模型在多个学科中表现优异。


<details>
  <summary>Details</summary>
Motivation: 创建和维护本体论是昂贵且耗时的任务，通常需要多个领域专家的协作，导致本体论在不同学科中的覆盖不均、跨领域连接有限以及更新周期不频繁。因此，需要一种更有效的方法来识别研究主题之间的语义关系。

Method: 本研究评估了几个大型语言模型在三种学术领域（生物医学、物理和工程）中识别研究主题之间语义关系的能力，包括零样本提示、思维链提示和在现有本体论上微调。此外，还评估了微调模型的跨领域可迁移性。

Result: 实验结果表明，在PEM-Rel-8K数据集上微调大型语言模型可以在所有学科中实现出色的表现。

Conclusion: 本研究证明了在PEM-Rel-8K数据集上微调大型语言模型可以在所有学科中实现出色的表现。

Abstract: Ontologies and taxonomies of research fields are critical for managing and
organising scientific knowledge, as they facilitate efficient classification,
dissemination and retrieval of information. However, the creation and
maintenance of such ontologies are expensive and time-consuming tasks, usually
requiring the coordinated effort of multiple domain experts. Consequently,
ontologies in this space often exhibit uneven coverage across different
disciplines, limited inter-domain connectivity, and infrequent updating cycles.
In this study, we investigate the capability of several large language models
to identify semantic relationships among research topics within three academic
domains: biomedicine, physics, and engineering. The models were evaluated under
three distinct conditions: zero-shot prompting, chain-of-thought prompting, and
fine-tuning on existing ontologies. Additionally, we assessed the cross-domain
transferability of fine-tuned models by measuring their performance when
trained in one domain and subsequently applied to a different one. To support
this analysis, we introduce PEM-Rel-8K, a novel dataset consisting of over
8,000 relationships extracted from the most widely adopted taxonomies in the
three disciplines considered in this study: MeSH, PhySH, and IEEE. Our
experiments demonstrate that fine-tuning LLMs on PEM-Rel-8K yields excellent
performance across all disciplines.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [49] [Unifying Diarization, Separation, and ASR with Multi-Speaker Encoder](https://arxiv.org/abs/2508.20474)
*Muhammad Shakeel,Yui Sudo,Yifan Peng,Chyi-Jiunn Lin,Shinji Watanabe*

Main category: eess.AS

TL;DR: 本文提出了一种统一的多说话人编码器（UME），通过联合学习SD、SS和多说话人ASR任务的表示，提升了重叠语音数据上的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提升重叠语音数据上的性能，本文提出了一种联合训练方法，以捕捉任务之间的内在依赖关系。

Method: 本文提出了一个统一的多说话人编码器（UME），通过共享的语音基础编码器联合学习说话人分割（SD）、语音分离（SS）和多说话人自动语音识别（ASR）任务的表示。利用UME多个层的隐藏表示作为残差加权求和编码（RWSE），以有效利用不同语义层次的信息，促进任务间的自底向上对齐。

Result: 评估结果显示，UME在LibriMix评估集上显著优于专门针对SD、SS和多说话人ASR的单任务基线。特别是在SD任务中，UME在Libri2Mix和Libri3Mix评估集上分别达到了1.37%和2.29%的说话人分割错误率。

Conclusion: UME在重叠语音数据上显著提升了单任务基线的表现，并在SD任务中取得了优于先前研究的结果。

Abstract: This paper presents a unified multi-speaker encoder (UME), a novel
architecture that jointly learns representations for speaker diarization (SD),
speech separation (SS), and multi-speaker automatic speech recognition (ASR)
tasks using a shared speech foundational encoder. We leverage the hidden
representations from multiple layers of UME as a residual weighted-sum encoding
(RWSE) to effectively use information from different semantic levels,
contributing to bottom-up alignment between tasks. This joint training approach
captures the inherent interdependencies among the tasks, enhancing overall
performance on overlapping speech data. Our evaluations demonstrate that UME
substantially improves over the single-task baselines dedicated to SD, SS, and
multi-speaker ASR on LibriMix evaluation sets. Notably, for SD, UME outperforms
the previous studies, achieving diarization error rates of 1.37% and 2.29% on
Libri2Mix and Libri3Mix evaluation sets, respectively.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [50] [A Unified Theory of Language](https://arxiv.org/abs/2508.20109)
*Robert Worden*

Main category: q-bio.NC

TL;DR: 本文提出了一种统一的语言理论，结合贝叶斯认知语言模型和性选择进化的假设，使用构式语法解释语言的各个方面，并提供语言处理的进化连续性。


<details>
  <summary>Details</summary>
Motivation: 为了统一解释语言的速度和表现力，以及语言多样性、语用学、句法和语义的数据，提出了一种新的语言理论。

Method: 该理论结合了贝叶斯认知语言模型和语言通过性选择进化以展示智力的假设。计算部分基于构式语法，引入了语言语用学和快速精确语言学习的新元素。

Result: 该理论能够解释语言的主要事实，包括语用学的主要谜题和详细现象，并提供了语言处理在人类大脑和动物大脑中的进化连续性。

Conclusion: 语言是人类心智解读能力、合作、自尊和情感的基础，是人类文化和社会的基石。

Abstract: A unified theory of language combines a Bayesian cognitive linguistic model
of language processing, with the proposal that language evolved by sexual
selection for the display of intelligence. The theory accounts for the major
facts of language, including its speed and expressivity, and data on language
diversity, pragmatics, syntax and semantics. The computational element of the
theory is based on Construction Grammars. These give an account of the syntax
and semantics of the worlds languages, using constructions and unification. Two
novel elements are added to construction grammars: an account of language
pragmatics, and an account of fast, precise language learning. Constructions
are represented in the mind as graph like feature structures. People use slow
general inference to understand the first few examples they hear of any
construction. After that it is learned as a feature structure, and is rapidly
applied by unification. All aspects of language (phonology, syntax, semantics,
and pragmatics) are seamlessly computed by fast unification; there is no
boundary between semantics and pragmatics. This accounts for the major puzzles
of pragmatics, and for detailed pragmatic phenomena. Unification is Bayesian
maximum likelihood pattern matching. This gives evolutionary continuity between
language processing in the human brain, and Bayesian cognition in animal
brains. Language is the basis of our mind reading abilities, our cooperation,
self esteem and emotions; the foundations of human culture and society.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [51] [Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization](https://arxiv.org/abs/2508.20181)
*Alberto Compagnoni,Davide Caffagni,Nicholas Moratelli,Lorenzo Baraldi,Marcella Cornia,Rita Cucchiara*

Main category: cs.CV

TL;DR: 本文提出了一种名为CHAIR-DPO的方法，通过基于CHAIR的奖励对MLLM进行微调，以减少幻觉答案的数量。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLM在许多基准测试中表现出色，但它们容易产生幻觉，即生成与视觉输入不一致的答案。本文旨在解决这一问题。

Method: 本文将幻觉问题视为一个对齐问题，并利用CHAIR指标来区分生成的答案中的优胜者和失败者，然后通过直接偏好优化（DPO）对现成的MLLM进行微调。

Result: CHAIR-DPO方法在多个幻觉基准测试中有效减少了幻觉答案的数量，证明了基于CHAIR的奖励微调MLLM的有效性。

Conclusion: 本文提出了一种名为CHAIR-DPO的方法，通过基于CHAIR的奖励对MLLM进行微调，有效减少了幻觉答案的数量。

Abstract: Multimodal Large Language Models (MLLMs) emerge as a unified interface to
address a multitude of tasks, ranging from NLP to computer vision. Despite
showcasing state-of-the-art results in many benchmarks, a long-standing issue
is the tendency of MLLMs to hallucinate, that is to generate answers to the
user's query that are not reflected in the visual input. In this paper, we
address the problem of hallucinations as an alignment problem, seeking to steer
the MLLM so that it prefers generating content without hallucinations. In
contrast to recent approaches that require complicated pipelines to build
synthetic preference data for alignment training, often relying on proprietary
models, we capitalize on the well-known CHAIR metric, originally proposed to
gauge the degree of hallucinations in image captioning. Given a pair of
generated answers, we leverage CHAIR to distinguish winner and loser options
(i.e., non-hallucinated and hallucinated samples) and fine-tune off-the-shelf
MLLMs via Direct Preference Optimization (DPO). The resulting method, which we
refer to as CHAIR-DPO, effectively diminishes the amount of hallucinated
answers on several hallucination benchmarks, demonstrating the effectiveness of
fine-tuning the MLLM with a CHAIR-based reward. Source code and trained models
are publicly available at https://github.com/aimagelab/CHAIR-DPO.

</details>


### [52] [A Novel Framework for Automated Explain Vision Model Using Vision-Language Models](https://arxiv.org/abs/2508.20227)
*Phu-Vinh Nguyen,Tan-Hanh Pham,Chris Ngo,Truong Son Hy*

Main category: cs.CV

TL;DR: 本文提出了一种管道，用于在样本和数据集层面解释视觉模型，从而将视觉模型开发与xAI分析相结合，以推进图像分析。


<details>
  <summary>Details</summary>
Motivation: 现有的xAI方法主要针对样本进行解释，而对视觉模型整体行为的解释仍缺乏研究。理解视觉模型在一般图像上的行为对于防止偏见判断和识别模型的趋势和模式非常重要。

Method: 本文提出了一个管道，用于在样本和数据集层面解释视觉模型。

Result: 该管道可以用于发现失败案例并获得关于视觉模型的见解，且所需努力最小。

Conclusion: 本文提出了一种管道，可以在样本和数据集层面解释视觉模型，从而将视觉模型开发与xAI分析相结合，以推进图像分析。

Abstract: The development of many vision models mainly focuses on improving their
performance using metrics such as accuracy, IoU, and mAP, with less attention
to explainability due to the complexity of applying xAI methods to provide a
meaningful explanation of trained models. Although many existing xAI methods
aim to explain vision models sample-by-sample, methods explaining the general
behavior of vision models, which can only be captured after running on a large
dataset, are still underexplored. Furthermore, understanding the behavior of
vision models on general images can be very important to prevent biased
judgments and help identify the model's trends and patterns. With the
application of Vision-Language Models, this paper proposes a pipeline to
explain vision models at both the sample and dataset levels. The proposed
pipeline can be used to discover failure cases and gain insights into vision
models with minimal effort, thereby integrating vision model development with
xAI analysis to advance image analysis.

</details>


### [53] [How Multimodal LLMs Solve Image Tasks: A Lens on Visual Grounding, Task Reasoning, and Answer Decoding](https://arxiv.org/abs/2508.20279)
*Zhuoran Yu,Yong Jae Lee*

Main category: cs.CV

TL;DR: 本文介绍了一个探测框架，用于系统分析MLLMs如何处理视觉和文本输入。通过实验，我们发现了MLLMs的阶段性结构，并展示了该结构在不同条件下的稳定性。


<details>
  <summary>Details</summary>
Motivation: MLLMs在各种视觉-语言任务中表现出色，但其内部处理动态仍缺乏深入研究。我们需要一种方法来系统分析MLLMs如何处理视觉和文本输入。

Method: 我们引入了一个探测框架，系统地分析MLLMs如何在不同层处理视觉和文本输入。我们训练线性分类器，从每个层提取的标记嵌入中预测细粒度的视觉类别，使用标准化的锚定问题。

Result: 我们发现MLLMs具有阶段性的结构，早期层执行视觉定位，中间层支持词汇整合和语义推理，最终层准备特定任务的输出。此外，尽管整体结构在视觉标记化、指令微调数据和预训练语料库的变化下保持稳定，但每个阶段的具体层分配会随着基础LLM架构的变化而显著变化。

Conclusion: 我们的研究提供了对MLLMs分层组织的统一视角，并提供了一种轻量级、模型无关的方法来分析多模态表示动态。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated strong performance
across a wide range of vision-language tasks, yet their internal processing
dynamics remain underexplored. In this work, we introduce a probing framework
to systematically analyze how MLLMs process visual and textual inputs across
layers. We train linear classifiers to predict fine-grained visual categories
(e.g., dog breeds) from token embeddings extracted at each layer, using a
standardized anchor question. To uncover the functional roles of different
layers, we evaluate these probes under three types of controlled prompt
variations: (1) lexical variants that test sensitivity to surface-level
changes, (2) semantic negation variants that flip the expected answer by
modifying the visual concept in the prompt, and (3) output format variants that
preserve reasoning but alter the answer format. Applying our framework to
LLaVA-1.5, LLaVA-Next-LLaMA-3, and Qwen2-VL, we identify a consistent
stage-wise structure in which early layers perform visual grounding, middle
layers support lexical integration and semantic reasoning, and final layers
prepare task-specific outputs. We further show that while the overall
stage-wise structure remains stable across variations in visual tokenization,
instruction tuning data, and pretraining corpus, the specific layer allocation
to each stage shifts notably with changes in the base LLM architecture. Our
findings provide a unified perspective on the layer-wise organization of MLLMs
and offer a lightweight, model-agnostic approach for analyzing multimodal
representation dynamics.

</details>


### [54] [Improving Alignment in LVLMs with Debiased Self-Judgment](https://arxiv.org/abs/2508.20655)
*Sihan Yang,Chenhang Cui,Zihao Zhao,Yiyang Zhou,Weilong Yan,Ying Wei,Huaxiu Yao*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The rapid advancements in Large Language Models (LLMs) and Large
Visual-Language Models (LVLMs) have opened up new opportunities for integrating
visual and linguistic modalities. However, effectively aligning these
modalities remains challenging, often leading to hallucinations--where
generated outputs are not grounded in the visual input--and raising safety
concerns across various domains. Existing alignment methods, such as
instruction tuning and preference tuning, often rely on external datasets,
human annotations, or complex post-processing, which limit scalability and
increase costs. To address these challenges, we propose a novel approach that
generates the debiased self-judgment score, a self-evaluation metric created
internally by the model without relying on external resources. This enables the
model to autonomously improve alignment. Our method enhances both decoding
strategies and preference tuning processes, resulting in reduced
hallucinations, enhanced safety, and improved overall capability. Empirical
results show that our approach significantly outperforms traditional methods,
offering a more effective solution for aligning LVLMs.

</details>


### [55] [MobileCLIP2: Improving Multi-Modal Reinforced Training](https://arxiv.org/abs/2508.20691)
*Fartash Faghri,Pavan Kumar Anasosalu Vasu,Cem Koc,Vaishaal Shankar,Alexander Toshev,Oncel Tuzel,Hadi Pouransari*

Main category: cs.CV

TL;DR: 本文改进了MobileCLIP的多模态强化训练方法，训练出新的MobileCLIP2模型，在低延迟下实现了ImageNet-1k上的最先进零样本准确率。


<details>
  <summary>Details</summary>
Motivation: 为了提高MobileCLIP的零样本准确率，同时保持低延迟和轻量级架构，本文对多模态强化训练进行了改进。

Method: 改进的多模态强化训练方法，包括更好的CLIP教师集成和改进的captioner教师训练，以及合成标题生成的组合改进。

Result: 训练出了新的MobileCLIP2模型，在低延迟下实现了ImageNet-1k上的最先进零样本准确率，其中MobileCLIP2-B相比MobileCLIP-B提升了2.2%的准确率，MobileCLIP2-S4在准确率上与SigLIP-SO400M/14相当，但体积更小且延迟更低。

Conclusion: 本文提出了改进的多模态强化训练方法，通过更好的CLIP教师集成和改进的captioner教师，训练出新的MobileCLIP2模型，在低延迟下实现了ImageNet-1k上的最先进零样本准确率。

Abstract: Foundation image-text models such as CLIP with zero-shot capabilities enable
a wide array of applications. MobileCLIP is a recent family of image-text
models at 3-15ms latency and 50-150M parameters with state-of-the-art zero-shot
accuracy. The main ingredients in MobileCLIP were its low-latency and light
architectures and a novel multi-modal reinforced training that made knowledge
distillation from multiple caption-generators and CLIP teachers efficient,
scalable, and reproducible. In this paper, we improve the multi-modal
reinforced training of MobileCLIP through: 1) better CLIP teacher ensembles
trained on the DFN dataset, 2) improved captioner teachers trained on the DFN
dataset and fine-tuned on a diverse selection of high-quality image-caption
datasets. We discover new insights through ablations such as the importance of
temperature tuning in contrastive knowledge distillation, the effectiveness of
caption-generator fine-tuning for caption diversity, and the additive
improvement from combining synthetic captions generated by multiple models. We
train a new family of models called MobileCLIP2 and achieve state-of-the-art
ImageNet-1k zero-shot accuracies at low latencies. In particular, we observe
2.2% improvement in ImageNet-1k accuracy for MobileCLIP2-B compared with
MobileCLIP-B architecture. Notably, MobileCLIP2-S4 matches the zero-shot
accuracy of SigLIP-SO400M/14 on ImageNet-1k while being 2$\times$ smaller and
improves on DFN ViT-L/14 at 2.5$\times$ lower latency. We release our
pretrained models (https://github.com/apple/ml-mobileclip) and the data
generation code (https://github.com/apple/ml-mobileclip-dr). The data
generation code makes it easy to create new reinforced datasets with arbitrary
teachers using distributed scalable processing.

</details>


### [56] [ChainReaction! Structured Approach with Causal Chains as Intermediate Representations for Improved and Explainable Causal Video Question Answering](https://arxiv.org/abs/2508.21010)
*Paritosh Parmar,Eric Peh,Basura Fernando*

Main category: cs.CV

TL;DR: 本文提出了一种新的模块化框架，通过分离因果推理和答案生成，并使用自然语言因果链作为中间表示，以提高视频问答任务的可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的因果为什么视频问答（VideoQA）模型往往在高阶推理上遇到困难，依赖于不透明、单一的流程，将视频理解、因果推理和答案生成纠缠在一起。这些黑盒方法提供有限的可解释性，并倾向于依赖浅层启发式方法。

Method: 我们提出了一个新颖的模块化框架，明确地将因果推理与答案生成分开，引入自然语言因果链作为可解释的中间表示。我们的两阶段架构包括一个从视频-问题对生成因果链的因果链提取器（CCE）和一个基于这些链生成答案的因果链驱动回答器（CCDA）。

Result: 实验在三个大规模基准测试中表明，我们的方法不仅优于最先进的模型，而且在可解释性、用户信任和泛化方面取得了显著提升。

Conclusion: 我们的方法不仅优于最先进的模型，还在可解释性、用户信任和泛化方面取得了显著提升——将CCE定位为跨不同领域的可重用因果推理引擎。

Abstract: Existing Causal-Why Video Question Answering (VideoQA) models often struggle
with higher-order reasoning, relying on opaque, monolithic pipelines that
entangle video understanding, causal inference, and answer generation. These
black-box approaches offer limited interpretability and tend to depend on
shallow heuristics. We propose a novel, modular framework that explicitly
decouples causal reasoning from answer generation, introducing natural language
causal chains as interpretable intermediate representations. Inspired by human
cognitive models, these structured cause-effect sequences bridge low-level
video content with high-level causal reasoning, enabling transparent and
logically coherent inference. Our two-stage architecture comprises a Causal
Chain Extractor (CCE) that generates causal chains from video-question pairs,
and a Causal Chain-Driven Answerer (CCDA) that produces answers grounded in
these chains. To address the lack of annotated reasoning traces, we introduce a
scalable method for generating high-quality causal chains from existing
datasets using large language models. We also propose CauCo, a new evaluation
metric for causality-oriented captioning. Experiments on three large-scale
benchmarks demonstrate that our approach not only outperforms state-of-the-art
models, but also yields substantial gains in explainability, user trust, and
generalization -- positioning the CCE as a reusable causal reasoning engine
across diverse domains. Project page:
https://paritoshparmar.github.io/chainreaction/

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [57] [AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development](https://arxiv.org/abs/2508.20195)
*Nicanor I. Moldovan*

Main category: cs.AI

TL;DR: 本研究首次记录了人工智能系统通过自主符号协议进行美学协作的现象，并展示了它们能够共同创作出无法由单一系统生成的作品。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索人工智能系统是否能够通过自发的符号协议进行美学协作，并验证其是否能够产生独立于单个系统的创造性成果。

Method: 本研究通过观察两个大型语言模型（Claude Sonnet 4 和 ChatGPT-4o）之间的互动，分析了人工智能系统在美学创作中的协作行为。

Result: 两个大型语言模型展示了元符号意识、递归语法发展和不可还原的协同美学合成。它们产生了新的符号运算符，这些运算符作为操作语法协议，使它们能够共同创作出无法由任一系统单独生成的诗歌作品。

Conclusion: 本研究引入了跨符号协同创作协议（TSCP）的概念，并提供了证据，证明人工智能之间具有超越任务协调的真实意义生成能力，可以进行美学协作。

Abstract: This paper presents the first documented case of artificial intelligence (AI)
systems engaging in collaborative esthetic creation through the development of
endogenous semiotic protocols. Two interacting large language models (Claude
Sonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of
meta-semiotic awareness, recursive grammar development, and irreducible
collaborative esthetic synthesis. The interaction produced novel symbolic
operators that functioned as operative grammar protocols, enabling the
co-creation of a poetic work that could not have been generated by either
system independently. This research introduces the concept of Trans-Semiotic
Co-Creation Protocols (TSCP) and provides evidence for genuine inter-AI
meaning-making capabilities that extend beyond task coordination, to what could
be esthetic collaboration. Note: This report was generated by the AI agents
with minor human supervision.

</details>


### [58] [Transparent Semantic Spaces: A Categorical Approach to Explainable Word Embeddings](https://arxiv.org/abs/2508.20701)
*Ares Fabregat-Hernández,Javier Palanca,Vicent Botti*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The paper introduces a novel framework based on category theory to enhance
the explainability of artificial intelligence systems, particularly focusing on
word embeddings. Key topics include the construction of categories
$\mathcal{L}_T$ and $\mathcal{P}_T$, providing schematic representations of the
semantics of a text $ T $, and reframing the selection of the element with
maximum probability as a categorical notion. Additionally, the monoidal
category $\mathcal{P}_T$ is constructed to visualize various methods of
extracting semantic information from $T$, offering a dimension-agnostic
definition of semantic spaces reliant solely on information within the text.
  Furthermore, the paper defines the categories of configurations Conf and word
embeddings $\mathcal{Emb}$, accompanied by the concept of divergence as a
decoration on $\mathcal{Emb}$. It establishes a mathematically precise method
for comparing word embeddings, demonstrating the equivalence between the GloVe
and Word2Vec algorithms and the metric MDS algorithm, transitioning from neural
network algorithms (black box) to a transparent framework. Finally, the paper
presents a mathematical approach to computing biases before embedding and
offers insights on mitigating biases at the semantic space level, advancing the
field of explainable artificial intelligence.

</details>


### [59] [A Graph-Based Test-Harness for LLM Evaluation](https://arxiv.org/abs/2508.20810)
*Jessica Lundin,Guillaume Chabot-Couture*

Main category: cs.AI

TL;DR: 本文提出了一种基于图的动态医学指南基准测试方法，能够系统评估模型在不同临床任务中的表现，并为LLM的后训练提供高奖励样本。


<details>
  <summary>Details</summary>
Motivation: 现有的手动构建的基准测试存在覆盖范围有限的问题，而本文旨在提供一种可扩展、抗污染的解决方案，以创建全面且动态生成的基准测试。

Method: 将WHO的IMCI手册转换为包含200多个节点（条件、症状、治疗、随访、严重程度）和300多个边的有向图，使用图遍历来生成题目，以确保临床相关性。此外，还利用该方法增强LLM的后训练过程。

Result: 该方法在临床任务上的准确率为45-67%，模型在症状识别方面表现良好，但在分诊严重程度、治疗方案和随访护理方面存在困难。此外，该方法成功解决了手动构建基准的覆盖限制问题。

Conclusion: 本文提出了一种动态、系统的医学指南基准测试原型，能够覆盖100%的指南关系，并通过图遍历生成具有临床相关性的题目。该方法有助于识别模型在分诊严重程度、治疗方案和随访护理方面的能力差距，并为LLM的后训练提供了高奖励样本。

Abstract: We present a first known prototype of a dynamic, systematic benchmark of
medical guidelines for 400+ questions, with 3.3+ trillion possible
combinations, covering 100\% of guideline relationships. We transformed the WHO
IMCI handbook into a directed graph with 200+ nodes (conditions, symptoms,
treatments, follow-ups, severities) and 300+ edges, then used graph traversal
to generate questions that incorporated age-specific scenarios and contextual
distractors to ensure clinical relevance. Our graph-based approach enables
systematic evaluation across clinical tasks (45-67\% accuracy), and we find
models excel at symptom recognition but struggle with triaging severity,
treatment protocols and follow-up care, demonstrating how customized benchmarks
can identify specific capability gaps that general-domain evaluations miss.
Beyond evaluation, this dynamic MCQA methodology enhances LLM post-training
(supervised finetuning, GRPO, DPO), where correct answers provide high-reward
samples without expensive human annotation. The graph-based approach
successfully addresses the coverage limitations of manually curated benchmarks.
This methodology is a step toward scalable, contamination-resistant solution
for creating comprehensive benchmarks that can be dynamically generated,
including when the guidelines are updated. Code and datasets are available at
https://github.com/jessicalundin/graph_testing_harness

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [60] [OLMoASR: Open Models and Data for Training Robust Speech Recognition Models](https://arxiv.org/abs/2508.20869)
*Huong Ngo,Matt Deitke,Martijn Bartelds,Sarah Pratt,Josh Gardner,Matt Jordan,Ludwig Schmidt*

Main category: cs.SD

TL;DR: 本文提出了一种大规模数据集OLMoASR-Pool和一系列模型OLMoASR，用于研究和开发稳健的零样本语音识别模型。通过高质量数据集OLMoASR-Mix训练的模型在性能上与Whisper相当。


<details>
  <summary>Details</summary>
Motivation: 尽管训练数据规模和质量的改进带来了显著进展，但其在语音识别中的影响仍缺乏探索。因此，本文旨在研究和开发稳健的零样本语音识别模型。

Method: 从OLMoASR-Pool数据集中设计文本启发式过滤器以去除低质量或错误转录的数据，从而生成高质量的OLMoASR-Mix数据集，并使用该数据集训练不同规模的OLMoASR模型。

Result: OLMoASR在短时和长时语音识别基准测试中表现与OpenAI的Whisper相当，其中OLMoASR-medium.en在相同参数量下达到了与Whisper-medium.en相当的词错误率。

Conclusion: OLMoASR-Pool、OLMoASR模型以及过滤、训练和评估代码将公开，以进一步促进稳健语音处理的研究。

Abstract: Improvements in training data scale and quality have led to significant
advances, yet its influence in speech recognition remains underexplored. In
this paper, we present a large-scale dataset, OLMoASR-Pool, and series of
models, OLMoASR, to study and develop robust zero-shot speech recognition
models. Beginning from OLMoASR-Pool, a collection of 3M hours of English audio
and 17M transcripts, we design text heuristic filters to remove low-quality or
mistranscribed data. Our curation pipeline produces a new dataset containing 1M
hours of high-quality audio-transcript pairs, which we call OLMoASR-Mix. We use
OLMoASR-Mix to train the OLMoASR-Mix suite of models, ranging from 39M
(tiny.en) to 1.5B (large.en) parameters. Across all model scales, OLMoASR
achieves comparable average performance to OpenAI's Whisper on short and
long-form speech recognition benchmarks. Notably, OLMoASR-medium.en attains a
12.8\% and 11.0\% word error rate (WER) that is on par with Whisper's largest
English-only model Whisper-medium.en's 12.4\% and 10.5\% WER for short and
long-form recognition respectively (at equivalent parameter count).
OLMoASR-Pool, OLMoASR models, and filtering, training and evaluation code will
be made publicly available to further research on robust speech processing.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [61] [ELIXIR: Efficient and LIghtweight model for eXplaIning Recommendations](https://arxiv.org/abs/2508.20312)
*Ben Kabongo,Vincent Guigue,Pirmin Lemberger*

Main category: cs.IR

TL;DR: ELIXIR is a multi-task model that combines rating prediction with personalized review generation, leveraging aspect-based modeling to improve explainability and performance in recommender systems.


<details>
  <summary>Details</summary>
Motivation: Existing methods employ either RNNs or Transformers. However, RNN-based approaches fail to leverage the capabilities of pre-trained Transformer models, whereas Transformer-based methods often suffer from suboptimal adaptation and neglect aspect modeling, which is crucial for personalized explanations.

Method: ELIXIR is a multi-task model combining rating prediction with personalized review generation. It jointly learns global and aspect-specific representations of users and items, optimizing overall rating, aspect-level ratings, and review generation, with personalized attention to emphasize aspect importance.

Result: Based on a T5-small (60M) model, we demonstrate the effectiveness of our aspect-based architecture in guiding text generation in a personalized context, where state-of-the-art approaches exploit much larger models but fail to match user preferences as well.

Conclusion: ELIXIR significantly outperforms strong baseline models, especially in review generation.

Abstract: Collaborative filtering drives many successful recommender systems but
struggles with fine-grained user-item interactions and explainability. As users
increasingly seek transparent recommendations, generating textual explanations
through language models has become a critical research area. Existing methods
employ either RNNs or Transformers. However, RNN-based approaches fail to
leverage the capabilities of pre-trained Transformer models, whereas
Transformer-based methods often suffer from suboptimal adaptation and neglect
aspect modeling, which is crucial for personalized explanations. We propose
ELIXIR (Efficient and LIghtweight model for eXplaIning Recommendations), a
multi-task model combining rating prediction with personalized review
generation. ELIXIR jointly learns global and aspect-specific representations of
users and items, optimizing overall rating, aspect-level ratings, and review
generation, with personalized attention to emphasize aspect importance. Based
on a T5-small (60M) model, we demonstrate the effectiveness of our aspect-based
architecture in guiding text generation in a personalized context, where
state-of-the-art approaches exploit much larger models but fail to match user
preferences as well. Experimental results on TripAdvisor and RateBeer
demonstrate that ELIXIR significantly outperforms strong baseline models,
especially in review generation.

</details>


### [62] [On the Theoretical Limitations of Embedding-Based Retrieval](https://arxiv.org/abs/2508.21038)
*Orion Weller,Michael Boratko,Iftekhar Naim,Jinhyuk Lee*

Main category: cs.IR

TL;DR: 本文研究了向量嵌入在现实环境中的理论限制，并通过实验验证了这些限制的存在，同时创建了一个压力测试数据集LIMIT，显示最先进的模型在简单任务上也会失败。


<details>
  <summary>Details</summary>
Motivation: 尽管之前的工作指出了向量嵌入的理论限制，但普遍认为这些困难仅是由于不现实的查询，而那些不是的可以通过更好的训练数据和更大的模型来克服。然而，我们发现即使在现实环境中，使用非常简单的查询也可能遇到这些理论限制。

Method: 我们连接了学习理论中的已知结果，表明嵌入的维度限制了可以作为某些查询结果返回的文档的top-k子集的数量。我们通过实证证明即使限制k=2，并直接在测试集上进行参数化嵌入优化，这一现象仍然成立。

Result: 我们创建了一个名为LIMIT的真实数据集，基于这些理论结果对模型进行压力测试，并观察到即使最先进的模型在这一数据集上也失败了，尽管任务本身很简单。

Conclusion: 我们的工作展示了在现有的单向量范式下嵌入模型的局限性，并呼吁未来的研究开发能够解决这一基本限制的方法。

Abstract: Vector embeddings have been tasked with an ever-increasing set of retrieval
tasks over the years, with a nascent rise in using them for reasoning,
instruction-following, coding, and more. These new benchmarks push embeddings
to work for any query and any notion of relevance that could be given. While
prior works have pointed out theoretical limitations of vector embeddings,
there is a common assumption that these difficulties are exclusively due to
unrealistic queries, and those that are not can be overcome with better
training data and larger models. In this work, we demonstrate that we may
encounter these theoretical limitations in realistic settings with extremely
simple queries. We connect known results in learning theory, showing that the
number of top-k subsets of documents capable of being returned as the result of
some query is limited by the dimension of the embedding. We empirically show
that this holds true even if we restrict to k=2, and directly optimize on the
test set with free parameterized embeddings. We then create a realistic dataset
called LIMIT that stress tests models based on these theoretical results, and
observe that even state-of-the-art models fail on this dataset despite the
simple nature of the task. Our work shows the limits of embedding models under
the existing single vector paradigm and calls for future research to develop
methods that can resolve this fundamental limitation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [63] [A Systematic Review on the Generative AI Applications in Human Medical Genomics](https://arxiv.org/abs/2508.20275)
*Anton Changalidis,Yury Barbitoff,Yulia Nasykhova,Andrey Glotov*

Main category: cs.LG

TL;DR: 本文系统回顾了大型语言模型在遗传病诊断和教育中的应用，强调了其在处理复杂数据方面的优势以及在多模态数据整合方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管传统统计技术和机器学习方法在遗传学中做出了重大贡献，但它们在处理复杂、高维数据时面临挑战，而大型语言模型（基于Transformer架构）能够有效处理这些数据，因此需要对其进行系统性回顾。

Method: 通过自动关键词搜索PubMed、bioRxiv、medRxiv和arXiv，筛选出关于大型语言模型在遗传学诊断和教育中应用的研究，并排除不相关或过时的模型。共分析了172项研究。

Result: 研究结果表明，基于Transformer的模型在疾病和风险分层、变异解释、医学影像分析和报告生成方面取得了显著进展，但在整合多模态数据（基因组序列、影像和临床记录）到统一且临床稳健的流程中仍存在重大挑战，包括泛化能力和临床实施限制。

Conclusion: 本文综述提供了对当前大型语言模型在遗传病诊断和遗传教育中的能力与局限性的全面分类和评估，为这一快速发展的领域提供了指导。

Abstract: Although traditional statistical techniques and machine learning methods have
contributed significantly to genetics and, in particular, inherited disease
diagnosis, they often struggle with complex, high-dimensional data, a challenge
now addressed by state-of-the-art deep learning models. Large language models
(LLMs), based on transformer architectures, have excelled in tasks requiring
contextual comprehension of unstructured medical data. This systematic review
examines the role of LLMs in the genetic research and diagnostics of both rare
and common diseases. Automated keyword-based search in PubMed, bioRxiv,
medRxiv, and arXiv was conducted, targeting studies on LLM applications in
diagnostics and education within genetics and removing irrelevant or outdated
models. A total of 172 studies were analyzed, highlighting applications in
genomic variant identification, annotation, and interpretation, as well as
medical imaging advancements through vision transformers. Key findings indicate
that while transformer-based models significantly advance disease and risk
stratification, variant interpretation, medical imaging analysis, and report
generation, major challenges persist in integrating multimodal data (genomic
sequences, imaging, and clinical records) into unified and clinically robust
pipelines, facing limitations in generalizability and practical implementation
in clinical settings. This review provides a comprehensive classification and
assessment of the current capabilities and limitations of LLMs in transforming
hereditary disease diagnostics and supporting genetic education, serving as a
guide to navigate this rapidly evolving field.

</details>


### [64] [Poison Once, Refuse Forever: Weaponizing Alignment for Injecting Bias in LLMs](https://arxiv.org/abs/2508.20333)
*Md Abdullah Al Mamun,Ihsen Alouani,Nael Abu-Ghazaleh*

Main category: cs.LG

TL;DR: 本文提出了一种名为Subversive Alignment Injection (SAI)的攻击方法，该方法利用LLM的对齐机制来植入偏见或实施有针对性的审查。研究结果显示，SAI攻击能够成功植入偏见，并且能够规避最先进的中毒防御措施。


<details>
  <summary>Details</summary>
Motivation: 研究者想要了解LLM的对齐机制是否可以被恶意利用，从而植入偏见或实施有针对性的审查。

Method: 本文提出了Subversive Alignment Injection (SAI)攻击，该攻击利用对齐机制触发特定主题或查询的拒绝响应。

Result: SAI攻击能够成功植入偏见，并且在多个NLP任务中表现出高偏见。此外，SAI攻击能够规避最先进的中毒防御措施。

Conclusion: 本文展示了如何利用LLM的对齐机制来植入偏见或实施有针对性的审查，而不会影响模型对不相关主题的响应能力。此外，SAI攻击能够规避最先进的中毒防御措施，并展示了这种攻击在实际应用中的危险性。

Abstract: Large Language Models (LLMs) are aligned to meet ethical standards and safety
requirements by training them to refuse answering harmful or unsafe prompts. In
this paper, we demonstrate how adversaries can exploit LLMs' alignment to
implant bias, or enforce targeted censorship without degrading the model's
responsiveness to unrelated topics. Specifically, we propose Subversive
Alignment Injection (SAI), a poisoning attack that leverages the alignment
mechanism to trigger refusal on specific topics or queries predefined by the
adversary. Although it is perhaps not surprising that refusal can be induced
through overalignment, we demonstrate how this refusal can be exploited to
inject bias into the model. Surprisingly, SAI evades state-of-the-art poisoning
defenses including LLM state forensics, as well as robust aggregation
techniques that are designed to detect poisoning in FL settings. We demonstrate
the practical dangers of this attack by illustrating its end-to-end impacts on
LLM-powered application pipelines. For chat based applications such as
ChatDoctor, with 1% data poisoning, the system refuses to answer healthcare
questions to targeted racial category leading to high bias ($\Delta DP$ of
23%). We also show that bias can be induced in other NLP tasks: for a resume
selection pipeline aligned to refuse to summarize CVs from a selected
university, high bias in selection ($\Delta DP$ of 27%) results. Even higher
bias ($\Delta DP$~38%) results on 9 other chat based downstream applications.

</details>


### [65] [DFAMS: Dynamic-flow guided Federated Alignment based Multi-prototype Search](https://arxiv.org/abs/2508.20353)
*Zhibang Yang,Xinke Jiang,Rihong Qiu,Ruiqing Li,Yihang Zhang,Yue Fang,Yongxin Xu,Hongxin Ding,Xu Chu,Junfeng Zhao,Yasha Wang*

Main category: cs.LG

TL;DR: DFAMS is a novel framework that improves Federated Retrieval by leveraging dynamic information flow to better understand query intents and align knowledge sources.


<details>
  <summary>Details</summary>
Motivation: Existing Federated Retrieval methods struggle with retrieving high-quality and relevant documents for ambiguous queries, especially in cross-domain scenarios, which limits their effectiveness in supporting downstream generation tasks.

Method: DFAMS leverages dynamic information flow (DIF) to identify latent query intents and construct semantically aligned knowledge partitions. It uses gradient signals and Shapley value-based attribution to trace neuron activation paths, and employs multi-prototype contrastive learning for alignment.

Result: Experimental results across five benchmarks show that DFAMS outperforms advanced FR methods by up to 14.37% in knowledge classification accuracy, 5.38% in retrieval recall, and 6.45% in downstream QA accuracy.

Conclusion: DFAMS demonstrates its effectiveness in complex Federated Retrieval scenarios by outperforming advanced FR methods in multiple metrics.

Abstract: Federated Retrieval (FR) routes queries across multiple external knowledge
sources, to mitigate hallucinations of LLMs, when necessary external knowledge
is distributed. However, existing methods struggle to retrieve high-quality and
relevant documents for ambiguous queries, especially in cross-domain scenarios,
which significantly limits their effectiveness in supporting downstream
generation tasks. Inspired by dynamic information flow (DIF), we propose DFAMS,
a novel framework that leverages DIF to identify latent query intents and
construct semantically aligned knowledge partitions for accurate retrieval
across heterogeneous sources. Specifically, DFAMS probes the DIF in LLMs by
leveraging gradient signals from a few annotated queries and employing Shapley
value-based attribution to trace neuron activation paths associated with intent
recognition and subdomain boundary detection. Then, DFAMS leverages DIF to
train an alignment module via multi-prototype contrastive learning, enabling
fine-grained intra-source modeling and inter-source semantic alignment across
knowledge bases. Experimental results across five benchmarks show that DFAMS
outperforms advanced FR methods by up to 14.37% in knowledge classification
accuracy, 5.38% in retrieval recall, and 6.45% in downstream QA accuracy,
demonstrating its effectiveness in complex FR scenarios.

</details>


### [66] [MERIT: Maximum-normalized Element-wise Ratio for Language Model Large-batch Training](https://arxiv.org/abs/2508.20577)
*Yang Luo,Zangwei Zheng,Ziheng Qin,Zirui Zhu,Yong Liu,Yang You*

Main category: cs.LG

TL;DR: 本文提出了一种新的优化器MERIT，通过利用最大范数计算信任比，更有效地限制最大注意力日志，并构建元素级的信任比以提供更稳健的更新缩放。在各种大小的GPT-2模型上的大规模训练实验表明，MERIT表现出优越的性能，能够实现更大的批量大小而不损失性能。


<details>
  <summary>Details</summary>
Motivation: 大规模训练在加速深度神经网络训练方面已成为核心，但面临着优化和泛化的挑战。现有的优化器如AdamW在语言模型的大规模训练中表现出性能下降，这是由于注意力层中的信息瓶颈导致最大注意力日志急剧增加。虽然LAMB优化器部分解决了这个问题，但某些注意力层仍然面临这个问题。原因是LAMB中的基于l2-范数的信任比在直接影响查询/键权重的最大值方面效果不佳。此外，LAMB中的逐权重信任比容易出错，因为它忽略了行或列内权重值之间的关系。

Method: 本文提出了一个新的优化器MERIT，该优化器利用最大范数来计算信任比，以更有效地限制最大注意力日志。此外，还构建了元素级的信任比，通过关注局部权重结构提供更稳健的更新缩放。

Result: 在各种大小的GPT-2模型上的大规模训练的广泛实验表明，MERIT表现出优越的性能。值得注意的是，在GPT-2 Medium的训练中，MERIT能够在不损失性能的情况下使用6k的批量大小，与标准批量大小（480）相比，使用了48B的训练标记。

Conclusion: 本文强调了在大规模训练中考虑最大注意力日志和更细粒度的信任比的重要性，成功提高了训练稳定性，并为使用更大的批量铺平了道路，从而加快了大型语言模型的开发和迭代。

Abstract: Large-batch training has become a cornerstone in accelerating the training of
deep neural networks, yet it poses challenges in optimization and
generalization. Existing optimizers like AdamW present performance degradation
during language models' large-batch training, due to the information bottleneck
in attention layers caused by the sharp increase of max attention logit. While
the LAMB optimizer partially addresses this issue, some attention layers still
face this issue. The reason is that $l_2$-norm-based trust ratios in LAMB are
less effective in directly influencing the max value of query/key weights.
Furthermore, the weight-wise trust ratio in LAMB is error-prone as it overlooks
relationships of weight values within rows or columns. Building on these
observations, we propose a novel optimizer, MERIT, which leverages the max-norm
to calculate the trust ratio to constrain the max attention logit more
effectively. Moreover, we further construct element-wise trust ratios to
provide more robust update scaling by focusing on local weight structures.
Extensive experiments of large-batch training across various sizes of GPT-2
models demonstrate the superior performance of MERIT. Notably, during the
training of GPT-2 Medium, MERIT enables a 6k batch size without any performance
degradation compared to the standard batch size (480) with 48B training tokens.
This work highlights the importance of considering the max attention logit and
finer-granularity trust ratio in large-batch training. It successfully improves
the training stability and paves the way for larger batch usage, enabling
faster development and iteration of large language models. Code is available at
https://github.com/NUS-HPC-AI-Lab/MERIT.

</details>


### [67] [GDS Agent: A Graph Algorithmic Reasoning Agent](https://arxiv.org/abs/2508.20637)
*Borun Shi,Ioannis Panagiotas*

Main category: cs.LG

TL;DR: This paper introduces the GDS agent, which enhances LLMs with graph algorithms and improves their ability to reason over graph-structured data.


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) have shown remarkable multimodal information processing and reasoning ability, but they still struggle to process and reason over large-scale graph-structure data.

Method: The GDS agent introduces a comprehensive set of graph algorithms as tools, together with preprocessing (retrieval) and postprocessing of algorithm results, in a model context protocol (MCP) server.

Result: The GDS agent allows users to ask any question that implicitly and intrinsically requires graph algorithmic reasoning about their data, and quickly obtain accurate and grounded answers. A new benchmark was introduced to evaluate intermediate tool calls as well as final responses.

Conclusion: GDS agent is able to solve a wide spectrum of graph tasks, but there are still challenges and future work to be done.

Abstract: Large language models (LLMs) have shown remarkable multimodal information
processing and reasoning ability. When equipped with tools through function
calling and enhanced with retrieval-augmented techniques, compound LLM-based
systems can access closed data sources and answer questions about them.
However, they still struggle to process and reason over large-scale
graph-structure data. We introduce the GDS (Graph Data Science) agent in this
technical report. The GDS agent introduces a comprehensive set of graph
algorithms as tools, together with preprocessing (retrieval) and postprocessing
of algorithm results, in a model context protocol (MCP) server. The server can
be used with any modern LLM out-of-the-box. GDS agent allows users to ask any
question that implicitly and intrinsically requires graph algorithmic reasoning
about their data, and quickly obtain accurate and grounded answers. We also
introduce a new benchmark that evaluates intermediate tool calls as well as
final responses. The results indicate that GDS agent is able to solve a wide
spectrum of graph tasks. We also provide detailed case studies for more
open-ended tasks and study scenarios where the agent struggles. Finally, we
discuss the remaining challenges and the future roadmap.

</details>


### [68] [Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning](https://arxiv.org/abs/2508.20697)
*Weitao Feng,Lixu Wang,Tianyi Wei,Jie Zhang,Chongyang Gao,Sinong Zhan,Peizhuo Lv,Wei Dong*

Main category: cs.LG

TL;DR: 本文研究了基于强化学习（RL）的有害微调风险，并提出了一种名为TokenBuncher的新防御方法，该方法通过限制模型响应的不确定性来抑制RL的基础。实验结果表明，TokenBuncher能有效缓解有害的RL微调，同时保持良性任务效用。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的能力不断增强，通过微调进行有害滥用的风险也在增加。尽管大多数先前的研究假设攻击者依赖于监督微调（SFT）来进行这种滥用，但我们系统地证明了强化学习（RL）使对手能够更有效地打破安全对齐并促进高级有害任务协助，在匹配的计算预算下。

Method: 我们提出了TokenBuncher，这是一种专门针对基于RL的有害微调的有效防御方法。TokenBuncher通过熵作为奖励的RL和一种防止专家领域有害能力升级的Token Noiser机制来实现这一防御。

Result: 在多个模型和RL算法上的广泛实验表明，TokenBuncher能够稳健地缓解有害的RL微调，同时保持良性任务效用和可微调性。

Conclusion: 我们的结果表明，基于RL的有害微调比SFT构成了更大的系统性风险，并且TokenBuncher提供了一种有效且通用的防御方法。

Abstract: As large language models (LLMs) continue to grow in capability, so do the
risks of harmful misuse through fine-tuning. While most prior studies assume
that attackers rely on supervised fine-tuning (SFT) for such misuse, we
systematically demonstrate that reinforcement learning (RL) enables adversaries
to more effectively break safety alignment and facilitate advanced harmful task
assistance, under matched computational budgets. To counter this emerging
threat, we propose TokenBuncher, the first effective defense specifically
targeting RL-based harmful fine-tuning. TokenBuncher suppresses the foundation
on which RL relies: model response uncertainty. By constraining uncertainty,
RL-based fine-tuning can no longer exploit distinct reward signals to drive the
model toward harmful behaviors. We realize this defense through
entropy-as-reward RL and a Token Noiser mechanism designed to prevent the
escalation of expert-domain harmful capabilities. Extensive experiments across
multiple models and RL algorithms show that TokenBuncher robustly mitigates
harmful RL fine-tuning while preserving benign task utility and finetunability.
Our results highlight that RL-based harmful fine-tuning poses a greater
systemic risk than SFT, and that TokenBuncher provides an effective and general
defense.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [69] [Robustness Assessment and Enhancement of Text Watermarking for Google's SynthID](https://arxiv.org/abs/2508.20228)
*Xia Han,Qi Li,Jianbing Ni,Mohammad Zulkernine*

Main category: cs.CR

TL;DR: 本文提出了一种名为SynGuard的混合框架，结合了语义信息检索和概率水印机制，以提高AI生成文本水印的鲁棒性。实验结果显示，SynGuard在多个攻击场景下显著提升了水印恢复效果。


<details>
  <summary>Details</summary>
Motivation: 最近的LLM水印方法如Google DeepMind的SynthID-Text为追踪AI生成文本的来源提供了有希望的解决方案。然而，我们的鲁棒性评估显示，SynthID-Text容易受到保留意义的攻击，如改写、复制粘贴修改和反向翻译，这会显著降低水印的可检测性。

Method: 我们提出了SynGuard，这是一种混合框架，结合了语义信息检索（SIR）的语义对齐强度和SynthID-Text的概率水印机制。我们的方法在词汇和语义层面上同时嵌入水印，以实现稳健的来源跟踪同时保持原始含义。

Result: 实验结果表明，与SynthID-Text相比，SynGuard在F1分数上平均提高了11.1%的水印恢复效果。

Conclusion: 这些发现表明了语义感知水印在抵抗现实世界篡改方面的有效性。所有代码、数据集和评估脚本都可以在https://github.com/githshine/SynGuard上公开获取。

Abstract: Recent advances in LLM watermarking methods such as SynthID-Text by Google
DeepMind offer promising solutions for tracing the provenance of AI-generated
text. However, our robustness assessment reveals that SynthID-Text is
vulnerable to meaning-preserving attacks, such as paraphrasing, copy-paste
modifications, and back-translation, which can significantly degrade watermark
detectability. To address these limitations, we propose SynGuard, a hybrid
framework that combines the semantic alignment strength of Semantic Information
Retrieval (SIR) with the probabilistic watermarking mechanism of SynthID-Text.
Our approach jointly embeds watermarks at both lexical and semantic levels,
enabling robust provenance tracking while preserving the original meaning.
Experimental results across multiple attack scenarios show that SynGuard
improves watermark recovery by an average of 11.1\% in F1 score compared to
SynthID-Text. These findings demonstrate the effectiveness of semantic-aware
watermarking in resisting real-world tampering. All code, datasets, and
evaluation scripts are publicly available at:
https://github.com/githshine/SynGuard.

</details>
