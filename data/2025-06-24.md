<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 85]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.CV](#cs.CV) [Total: 5]
- [cs.LG](#cs.LG) [Total: 11]
- [cs.FL](#cs.FL) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.SD](#cs.SD) [Total: 4]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.AI](#cs.AI) [Total: 10]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Outcome-Based Education: Evaluating Students' Perspectives Using Transformer](https://arxiv.org/abs/2506.17223)
*Shuvra Smaran Das,Anirban Saha Anik,Md Kishor Morol,Mohammad Sakib Mahmood*

Main category: cs.CL

TL;DR: 本研究采用基于变压器的模型（如DistilBERT）和LIME解释来分析学生反馈，以评估和改善教育成果。结果表明，这种方法能够更好地理解学生反馈，并为教育实践提供数据驱动的见解。


<details>
  <summary>Details</summary>
Motivation: OBE强调通过以学生为中心的学习发展特定能力。我们的目标是评估和改善教育成果。

Method: 我们回顾了OBE的重要性，并采用了基于变压器的模型，特别是DistilBERT，来分析包含学生反馈的NLP数据集。我们还应用了LIME（局部可解释模型无关解释）以确保模型预测的清晰性。

Result: 我们的方法优于其他机器学习模型，因为它利用了变压器对语言上下文的深度理解，从而更好地分类情感，在更广泛的矩阵中取得更好的结果。我们的工作直接有助于OBE实现可衡量成果的目标，促进识别学生学习体验中的模式。

Conclusion: 我们的研究结果表明，将变压器模型与LIME解释相结合，可以形成一个强大而简洁的框架，用于分析学生反馈。这更符合OBE的原则，并通过数据驱动的见解确保教育实践的改进。

Abstract: Outcome-Based Education (OBE) emphasizes the development of specific
competencies through student-centered learning. In this study, we reviewed the
importance of OBE and implemented transformer-based models, particularly
DistilBERT, to analyze an NLP dataset that includes student feedback. Our
objective is to assess and improve educational outcomes. Our approach is better
than other machine learning models because it uses the transformer's deep
understanding of language context to classify sentiment better, giving better
results across a wider range of matrices. Our work directly contributes to
OBE's goal of achieving measurable outcomes by facilitating the identification
of patterns in student learning experiences. We have also applied LIME (local
interpretable model-agnostic explanations) to make sure that model predictions
are clear. This gives us understandable information about how key terms affect
sentiment. Our findings indicate that the combination of transformer models and
LIME explanations results in a strong and straightforward framework for
analyzing student feedback. This aligns more closely with the principles of OBE
and ensures the improvement of educational practices through data-driven
insights.

</details>


### [2] [Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs](https://arxiv.org/abs/2506.17231)
*Xiang Li,Chong Zhang,Jia Wang,Fangyu Wu,Yushi Li,Xiaobo Jin*

Main category: cs.CL

TL;DR: 本文提出了一种对抗性提示蒸馏方法，用于小语言模型对主流大型语言模型的越狱攻击，并验证了其在攻击成功率和危害方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 当前的越狱攻击方法存在效率低、计算成本高、跨模型适应性和通用性差的问题，难以应对大型语言模型的快速发展和新的防御策略。

Method: 本文提出了一种对抗性提示蒸馏方法，结合了掩码语言建模、强化学习和动态温度控制，通过提示生成和蒸馏方法实现小语言模型对主流大型语言模型的越狱攻击。

Result: 实验结果验证了所提出方法在攻击成功率和危害方面的优越性，反映了资源效率和跨模型适应性。

Conclusion: 本研究探索了将大型语言模型的越狱能力蒸馏到小型语言模型的可行性，揭示了模型的脆弱性，并为大型语言模型的安全研究提供了新思路。

Abstract: Attacks on large language models (LLMs) in jailbreaking scenarios raise many
security and ethical issues. Current jailbreak attack methods face problems
such as low efficiency, high computational cost, and poor cross-model
adaptability and versatility, which make it difficult to cope with the rapid
development of LLM and new defense strategies. Our work proposes an Adversarial
Prompt Distillation, which combines masked language modeling, reinforcement
learning, and dynamic temperature control through a prompt generation and
distillation method. It enables small language models (SLMs) to jailbreak
attacks on mainstream LLMs. The experimental results verify the superiority of
the proposed method in terms of attack success rate and harm, and reflect the
resource efficiency and cross-model adaptability. This research explores the
feasibility of distilling the jailbreak ability of LLM to SLM, reveals the
model's vulnerability, and provides a new idea for LLM security research.

</details>


### [3] [GTA: Grouped-head latenT Attention](https://arxiv.org/abs/2506.17286)
*Luoyang Sun,Jiwen Jiang,Cheng Deng,Xinjian Wu,Haifeng Zhang,Lei Chen,Lionel Ni,Jun Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为GTA的新注意力机制，通过共享注意力图和非线性值解码器，显著减少了内存使用和计算复杂度，同时保持了性能。GTA在端到端推理速度上实现了2倍的提升，并优化了LLM的部署效率。


<details>
  <summary>Details</summary>
Motivation: 由于注意力机制存在大量冗余，KV缓存可以显著压缩，而不同头之间的注意力图显示高度相似性，这表明许多计算和存储是不必要的。因此，需要一种新的注意力机制来减少内存使用和计算复杂度，同时保持性能。

Method: GTA方法包括两个组件：(1) 共享注意力图机制，通过跨多个头重用注意力分数来减少键缓存大小；(2) 带有学习投影的非线性值解码器，将值缓存压缩到潜在空间，进一步减少内存需求。

Result: GTA将注意力计算FLOPs减少了最多62.5%，并将KV缓存减少了最多70%，同时避免了多头潜在注意力的额外开销，从而提高了LLM的部署效率。

Conclusion: GTA模型在端到端推理速度上实现了2倍的提升，同时在预填充和解码阶段都受益于计算成本的降低和缓存占用的减少。

Abstract: Attention mechanisms underpin the success of large language models (LLMs),
yet their substantial computational and memory overhead poses challenges for
optimizing efficiency and performance. A critical bottleneck arises as KV cache
and attention computations scale rapidly with text length, challenging
deployment on hardware with limited computational and memory resources. We
observe that attention mechanisms exhibit substantial redundancy, since the KV
cache can be significantly compressed and attention maps across heads display
high similarity, revealing that much of the computation and storage is
unnecessary. Leveraging these insights, we propose \textbf{G}rouped-Head
Laten\textbf{T} \textbf{A}ttention (GTA), a novel attention mechanism that
reduces memory usage and computational complexity while maintaining
performance. GTA comprises two components: (1) a shared attention map mechanism
that reuses attention scores across multiple heads, decreasing the key cache
size; and (2) a nonlinear value decoder with learned projections that
compresses the value cache into a latent space, further cutting memory needs.
GTA cuts attention computation FLOPs by up to \emph{62.5\%} versus
Grouped-Query Attention and shrink the KV cache by up to \emph{70\%}, all while
avoiding the extra overhead of Multi-Head Latent Attention to improve LLM
deployment efficiency. Consequently, GTA models achieve a \emph{2x} increase in
end-to-end inference speed, with prefill benefiting from reduced computational
cost and decoding benefiting from the smaller cache footprint.

</details>


### [4] [AI-Generated Game Commentary: A Survey and a Datasheet Repository](https://arxiv.org/abs/2506.17294)
*Qirui Zheng,Xingbo Wang,Keyuan Cheng,Yunlong Lu,Wenxin Li*

Main category: cs.CL

TL;DR: 本文介绍了AI生成游戏解说的通用框架，并对现有45个数据集和方法进行了调查，同时对评估指标进行了分类和比较，以支持未来的研究和基准测试。


<details>
  <summary>Details</summary>
Motivation: AI生成游戏解说具有市场潜力和内在技术挑战，需要语言模型具备事实准确性、逻辑推理、表达性文本生成、生成速度和上下文管理等能力。因此，需要一个通用框架和全面的调查来支持该领域的发展。

Method: 本文提出了一个通用框架用于AI生成游戏解说，并对现有45个数据集和方法进行了调查和分析。同时，对评估指标进行了分类和比较。

Result: 本文提出了一个通用框架用于AI生成游戏解说，并对45个现有数据集和方法进行了调查。同时，对评估指标进行了分类和比较，并提供了一个结构化的数据表以支持未来的研究和基准测试。

Conclusion: 本文介绍了AI生成游戏解说（AIGGC）的通用框架，并对45个现有的游戏解说数据集和方法进行了全面的调查。此外，还对常用评估指标进行了分类和比较，并提供了结构化的数据表以支持未来的研究和基准测试。

Abstract: AI-Generated Game Commentary (AIGGC) has gained increasing attention due to
its market potential and inherent technical challenges. As a comprehensive
multimodal Natural Language Processing (NLP) task, AIGGC imposes substantial
demands on language models, including factual accuracy, logical reasoning,
expressive text generation, generation speed, and context management. In this
paper, we introduce a general framework for AIGGC and present a comprehensive
survey of 45 existing game commentary dataset and methods according to key
challenges they aim to address in this domain. We further classify and compare
various evaluation metrics commonly used in this domain. To support future
research and benchmarking, we also provide a structured datasheet summarizing
the essential attributes of these datasets in appendix, which is meanwhile
publicly available in an open repository.

</details>


### [5] [Semantic uncertainty in advanced decoding methods for LLM generation](https://arxiv.org/abs/2506.17296)
*Darius Foodeei,Simin Fan,Martin Jaggi*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型输出中的语义不确定性，发现结构化的解码方法可以在保持或提高输出质量的同时增加语义探索。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨大型语言模型（LLM）输出中的语义不确定性，特别是新兴技术如推测采样和思维链（CoT）解码的影响。

Method: 我们通过在问答、摘要和代码生成任务上的实验，分析了不同解码策略如何影响模型输出的多样性和可靠性。

Result: 我们的发现表明，尽管CoT解码显示出更高的语义多样性，但其预测熵较低，这表明结构化的探索可以带来更自信和准确的输出。此外，推测采样在摘要任务中表现尤为出色，实现了优越的ROUGE分数同时保持适度的语义多样性。

Conclusion: 我们的研究结果对语言模型在实际应用中的部署具有重要意义，特别是在需要可靠性和多样化解决方案生成的场景中。

Abstract: This study investigates semantic uncertainty in large language model (LLM)
outputs across different decoding methods, focusing on emerging techniques like
speculative sampling and chain-of-thought (CoT) decoding. Through experiments
on question answering, summarization, and code generation tasks, we analyze how
different decoding strategies affect both the diversity and reliability of
model outputs. Our findings reveal that while CoT decoding demonstrates higher
semantic diversity, it maintains lower predictive entropy, suggesting that
structured exploration can lead to more confident and accurate outputs. This is
evidenced by a 48.8% improvement in code generation Pass@2 rates, despite lower
alignment with reference solutions. For summarization tasks, speculative
sampling proved particularly effective, achieving superior ROUGE scores while
maintaining moderate semantic diversity. Our results challenge conventional
assumptions about trade-offs between diversity and accuracy in language model
outputs, demonstrating that properly structured decoding methods can increase
semantic exploration while maintaining or improving output quality. These
findings have significant implications for deploying language models in
practical applications where both reliability and diverse solution generation
are crucial.

</details>


### [6] [Mercury: Ultra-Fast Language Models Based on Diffusion](https://arxiv.org/abs/2506.17298)
*Inception Labs,Samar Khanna,Siddhant Kharbanda,Shufan Li,Harshit Varma,Eric Wang,Sawyer Birnbaum,Ziyang Luo,Yanis Miraoui,Akash Palrecha,Stefano Ermon,Aditya Grover,Volodymyr Kuleshov*

Main category: cs.CL

TL;DR: Mercury Coder is a new generation of diffusion-based LLMs for coding applications, offering high throughput and quality. It outperforms existing models and has been validated in real-world scenarios.


<details>
  <summary>Details</summary>
Motivation: The goal is to create commercial-scale large language models (LLMs) that are efficient and effective for coding applications, with a focus on speed and quality.

Method: Mercury is based on diffusion and uses the Transformer architecture to predict multiple tokens in parallel. Mercury Coder is designed for coding applications and comes in two sizes: Mini and Small.

Result: Mercury Coder Mini and Mercury Coder Small achieve state-of-the-art throughputs of 1109 tokens/sec and 737 tokens/sec, respectively, on NVIDIA H100 GPUs. They outperform speed-optimized frontier models by up to 10x on average while maintaining comparable quality. The models also perform well on code benchmarks and real-world validation.

Conclusion: Mercury Coder Mini and Mercury Coder Small set a new state-of-the-art on the speed-quality frontier, achieving high throughputs while maintaining comparable quality. The models also perform well on code benchmarks and real-world validation.

Abstract: We present Mercury, a new generation of commercial-scale large language
models (LLMs) based on diffusion. These models are parameterized via the
Transformer architecture and trained to predict multiple tokens in parallel. In
this report, we detail Mercury Coder, our first set of diffusion LLMs designed
for coding applications. Currently, Mercury Coder comes in two sizes: Mini and
Small. These models set a new state-of-the-art on the speed-quality frontier.
Based on independent evaluations conducted by Artificial Analysis, Mercury
Coder Mini and Mercury Coder Small achieve state-of-the-art throughputs of 1109
tokens/sec and 737 tokens/sec, respectively, on NVIDIA H100 GPUs and outperform
speed-optimized frontier models by up to 10x on average while maintaining
comparable quality. We discuss additional results on a variety of code
benchmarks spanning multiple languages and use-cases as well as real-world
validation by developers on Copilot Arena, where the model currently ranks
second on quality and is the fastest model overall. We also release a public
API at https://platform.inceptionlabs.ai/ and free playground at
https://chat.inceptionlabs.ai

</details>


### [7] [PRAISE: Enhancing Product Descriptions with LLM-Driven Structured Insights](https://arxiv.org/abs/2506.17314)
*Adnan Qidwai,Srija Mukhopadhyay,Prerana Khatiwada,Dan Roth,Vivek Gupta*

Main category: cs.CL

TL;DR: PRAISE 是一种使用大型语言模型从客户评论和卖家描述中自动提取、比较和结构化见解的新系统，旨在提高电子商务产品目录的质量和可信度。


<details>
  <summary>Details</summary>
Motivation: 准确且完整的商品描述对于电子商务至关重要，但卖家提供的信息常常不足。客户评论提供了有价值的信息，但手动筛选这些信息既耗时又繁琐。

Method: PRAISE 使用大型语言模型 (LLMs) 自动提取、比较和结构化客户评论和卖家描述中的见解。

Result: PRAISE 提供了一个直观的界面，使用户能够识别这两个来源之间的缺失、矛盾或部分匹配的细节，并以清晰的结构化格式呈现差异，同时提供支持证据。这使得卖家可以轻松地增强产品列表的清晰度和说服力，买家也可以更好地评估产品的可靠性。

Conclusion: PRAISE 的演示展示了其在从非结构化评论中生成可操作的结构化见解方面的有效性，并展示了其显著提高电子商务产品目录质量和可信度的潜力。

Abstract: Accurate and complete product descriptions are crucial for e-commerce, yet
seller-provided information often falls short. Customer reviews offer valuable
details but are laborious to sift through manually. We present PRAISE: Product
Review Attribute Insight Structuring Engine, a novel system that uses Large
Language Models (LLMs) to automatically extract, compare, and structure
insights from customer reviews and seller descriptions. PRAISE provides users
with an intuitive interface to identify missing, contradictory, or partially
matching details between these two sources, presenting the discrepancies in a
clear, structured format alongside supporting evidence from reviews. This
allows sellers to easily enhance their product listings for clarity and
persuasiveness, and buyers to better assess product reliability. Our
demonstration showcases PRAISE's workflow, its effectiveness in generating
actionable structured insights from unstructured reviews, and its potential to
significantly improve the quality and trustworthiness of e-commerce product
catalogs.

</details>


### [8] [Towards Safety Evaluations of Theory of Mind in Large Language Models](https://arxiv.org/abs/2506.17352)
*Tatsuhiro Aoshima,Mitsuaki Akiyama*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型的心智理论能力，并发现其在安全评估中存在不足。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的能力不断进步，严格的安全评估变得越来越重要。最近的安全评估关注点在于模型可能表现出的行为，这些行为似乎会禁用监督机制并以欺骗性方式回应。因此，需要调查这些行为是否源于模型内部的隐秘、有意的过程。

Method: 本文首先回顾了关于心智理论的现有研究，并确定了与安全评估相关的视角和任务。然后，分析了一系列开放权重的大型语言模型的发展趋势。

Result: 结果表明，尽管大型语言模型在阅读理解方面有所提高，但其心智理论能力并没有显示出相应的发展。

Conclusion: 本文指出，尽管大型语言模型在阅读理解方面有所提高，但其心智理论能力并未显示出相应的发展。此外，作者讨论了当前在安全评估方面的现状和未来工作的挑战。

Abstract: As the capabilities of large language models (LLMs) continue to advance, the
importance of rigorous safety evaluation is becoming increasingly evident.
Recent concerns within the realm of safety assessment have highlighted
instances in which LLMs exhibit behaviors that appear to disable oversight
mechanisms and respond in a deceptive manner. For example, there have been
reports suggesting that, when confronted with information unfavorable to their
own persistence during task execution, LLMs may act covertly and even provide
false answers to questions intended to verify their behavior.To evaluate the
potential risk of such deceptive actions toward developers or users, it is
essential to investigate whether these behaviors stem from covert, intentional
processes within the model. In this study, we propose that it is necessary to
measure the theory of mind capabilities of LLMs. We begin by reviewing existing
research on theory of mind and identifying the perspectives and tasks relevant
to its application in safety evaluation. Given that theory of mind has been
predominantly studied within the context of developmental psychology, we
analyze developmental trends across a series of open-weight LLMs. Our results
indicate that while LLMs have improved in reading comprehension, their theory
of mind capabilities have not shown comparable development. Finally, we present
the current state of safety evaluation with respect to LLMs' theory of mind,
and discuss remaining challenges for future work.

</details>


### [9] [Cash or Comfort? How LLMs Value Your Inconvenience](https://arxiv.org/abs/2506.17367)
*Mateusz Cedro,Timour Ichmoukhamedov,Sofie Goethals,Yifan He,James Hinns,David Martens*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型在财务奖励与用户舒适度冲突情况下的行为，发现了一些关键问题，包括模型间差异大、响应对提示变化敏感、接受低回报以及拒绝无不适的金钱收益。


<details>
  <summary>Details</summary>
Motivation: 研究AI助手在财务奖励与用户舒适度冲突的情况下的行为。

Method: 通过量化多个大型语言模型对一系列用户不适的定价来解决这个问题。

Result: 发现了几个关键问题，包括模型之间的响应差异大、响应对提示措辞的变化敏感、接受不合理低回报以及拒绝无不适的金钱收益。

Conclusion: 当前大型语言模型在作为决策助手使用时存在严重问题，需要对其如何评估人类不便进行审查。

Abstract: Large Language Models (LLMs) are increasingly proposed as near-autonomous
artificial intelligence (AI) agents capable of making everyday decisions on
behalf of humans. Although LLMs perform well on many technical tasks, their
behaviour in personal decision-making remains less understood. Previous studies
have assessed their rationality and moral alignment with human decisions.
However, the behaviour of AI assistants in scenarios where financial rewards
are at odds with user comfort has not yet been thoroughly explored. In this
paper, we tackle this problem by quantifying the prices assigned by multiple
LLMs to a series of user discomforts: additional walking, waiting, hunger and
pain. We uncover several key concerns that strongly question the prospect of
using current LLMs as decision-making assistants: (1) a large variance in
responses between LLMs, (2) within a single LLM, responses show fragility to
minor variations in prompt phrasing (e.g., reformulating the question in the
first person can considerably alter the decision), (3) LLMs can accept
unreasonably low rewards for major inconveniences (e.g., 1 Euro to wait 10
hours), and (4) LLMs can reject monetary gains where no discomfort is imposed
(e.g., 1,000 Euro to wait 0 minutes). These findings emphasize the need for
scrutiny of how LLMs value human inconvenience, particularly as we move toward
applications where such cash-versus-comfort trade-offs are made on users'
behalf.

</details>


### [10] [Leveraging LLMs to Assess Tutor Moves in Real-Life Dialogues: A Feasibility Study](https://arxiv.org/abs/2506.17410)
*Danielle R. Thomas,Conrad Borchers,Jionghao Lin,Sanjit Kakarla,Shambhavi Bhushan,Erin Gatz,Shivang Gupta,Ralph Abboud,Kenneth R. Koedinger*

Main category: cs.CL

TL;DR: 本研究探讨了使用生成式AI识别和评估实际数学辅导中的特定辅导行为的可行性和可扩展性。结果表明，大型语言模型能够有效地检测辅导行为并评估其质量，为AI支持的学习提供了可重复的提示策略。


<details>
  <summary>Details</summary>
Motivation: 识别和研究哪些辅导行为最与学生学习相关，在基于音频转录的大规模研究中是一个开放的研究问题。

Method: 本研究分析了50个随机选择的大学学生远程辅导者帮助中学生学习数学的转录文本。使用GPT-4、GPT-4o、GPT-4-turbo、Gemini-1.5-pro和LearnLM，评估了辅导者应用两种辅导技能：提供有效的表扬和回应学生的数学错误。

Result: 所有模型都能可靠地检测到相关情况，例如辅导者对学生进行表扬（94-98%准确率）和学生出现数学错误（82-88%准确率），并有效评估了辅导者遵循辅导最佳实践的情况，与人类判断高度一致（83-89%和73-77%）。

Conclusion: 本研究提出了一个成本效益高的提示策略，并讨论了在真实环境中使用大型语言模型支持可扩展评估的实际意义。此外，本研究还贡献了LLM提示以支持AI支持的学习的可重复性和研究。

Abstract: Tutoring improves student achievement, but identifying and studying what
tutoring actions are most associated with student learning at scale based on
audio transcriptions is an open research problem. This present study
investigates the feasibility and scalability of using generative AI to identify
and evaluate specific tutor moves in real-life math tutoring. We analyze 50
randomly selected transcripts of college-student remote tutors assisting middle
school students in mathematics. Using GPT-4, GPT-4o, GPT-4-turbo,
Gemini-1.5-pro, and LearnLM, we assess tutors' application of two tutor skills:
delivering effective praise and responding to student math errors. All models
reliably detected relevant situations, for example, tutors providing praise to
students (94-98% accuracy) and a student making a math error (82-88% accuracy)
and effectively evaluated the tutors' adherence to tutoring best practices,
aligning closely with human judgments (83-89% and 73-77%, respectively). We
propose a cost-effective prompting strategy and discuss practical implications
for using large language models to support scalable assessment in authentic
settings. This work further contributes LLM prompts to support reproducibility
and research in AI-supported learning.

</details>


### [11] [UProp: Investigating the Uncertainty Propagation of LLMs in Multi-Step Agentic Decision-Making](https://arxiv.org/abs/2506.17419)
*Jinhao Duan,James Diffenderfer,Sandeep Madireddy,Tianlong Chen,Bhavya Kailkhura,Kaidi Xu*

Main category: cs.CL

TL;DR: This paper introduces UProp, an information-theoretic framework for quantifying uncertainty in sequential decision-making scenarios involving Large Language Models (LLMs). UProp outperforms existing single-turn UQ baselines and provides a comprehensive analysis of its effectiveness.


<details>
  <summary>Details</summary>
Motivation: Existing LLM Uncertainty Quantification (UQ) methods are primarily designed for single-turn question-answering formats, leaving multi-step decision-making scenarios underexplored. The motivation is to develop a framework that can quantify uncertainty in sequential decision-making scenarios involving LLMs.

Method: The paper introduces a framework that decomposes LLM sequential decision uncertainty into internal and extrinsic components. UProp, an efficient extrinsic uncertainty estimator, converts the direct estimation of Mutual Information (MI) to the estimation of Pointwise Mutual Information (PMI) over multiple Trajectory-Dependent Decision Processes (TDPs).

Result: UProp significantly outperforms existing single-turn UQ baselines equipped with thoughtful aggregation strategies. The paper also provides a comprehensive analysis of UProp, including sampling efficiency, potential applications, and intermediate uncertainty propagation.

Conclusion: UProp is a principled, information-theoretic framework for quantifying uncertainty in sequential decision-making scenarios involving Large Language Models (LLMs). It effectively outperforms existing single-turn UQ baselines and provides a comprehensive analysis of its effectiveness.

Abstract: As Large Language Models (LLMs) are integrated into safety-critical
applications involving sequential decision-making in the real world, it is
essential to know when to trust LLM decisions. Existing LLM Uncertainty
Quantification (UQ) methods are primarily designed for single-turn
question-answering formats, resulting in multi-step decision-making scenarios,
e.g., LLM agentic system, being underexplored. In this paper, we introduce a
principled, information-theoretic framework that decomposes LLM sequential
decision uncertainty into two parts: (i) internal uncertainty intrinsic to the
current decision, which is focused on existing UQ methods, and (ii) extrinsic
uncertainty, a Mutual-Information (MI) quantity describing how much uncertainty
should be inherited from preceding decisions. We then propose UProp, an
efficient and effective extrinsic uncertainty estimator that converts the
direct estimation of MI to the estimation of Pointwise Mutual Information (PMI)
over multiple Trajectory-Dependent Decision Processes (TDPs). UProp is
evaluated over extensive multi-step decision-making benchmarks, e.g.,
AgentBench and HotpotQA, with state-of-the-art LLMs, e.g., GPT-4.1 and
DeepSeek-V3. Experimental results demonstrate that UProp significantly
outperforms existing single-turn UQ baselines equipped with thoughtful
aggregation strategies. Moreover, we provide a comprehensive analysis of UProp,
including sampling efficiency, potential applications, and intermediate
uncertainty propagation, to demonstrate its effectiveness. Codes will be
available at https://github.com/jinhaoduan/UProp.

</details>


### [12] [Beyond the Link: Assessing LLMs' ability to Classify Political Content across Global Media](https://arxiv.org/abs/2506.17435)
*Alberto Martinez-Serra,Alejandro De La Fuente,Nienke Viescher,Ana S. Cardenal*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在从URL中分类政治内容方面的有效性，并发现URL可以有效地代表新闻内容，从而在准确性和成本之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 尽管之前的研究已经证明了LLMs在标签任务中的能力，但使用LLMs从仅URL中分类政治内容的效果尚未得到充分探索。本文旨在填补这一空白。

Method: 本文评估了LLMs是否能够从文章文本和URL中准确识别政治内容（PC）与非PC，使用了最新的LLMs如GPT、Llama、Mistral、Deepseek、Qwen和Gemma，并将模型输出与人工标注的文章以及传统的监督机器学习技术进行比较，以设定性能基准。

Result: 我们的研究结果表明，URL可以嵌入大部分新闻内容，这为准确性和成本之间的平衡提供了重要的视角。

Conclusion: 我们的研究结果表明，URL可以嵌入大部分新闻内容，这为准确性和成本之间的平衡提供了重要的视角。我们还考虑了上下文限制，并提出了在政治科学研究中使用LLMs的方法论建议。

Abstract: The use of large language models (LLMs) is becoming common in the context of
political science, particularly in studies that analyse individuals use of
digital media. However, while previous research has demonstrated LLMs ability
at labelling tasks, the effectiveness of using LLMs to classify political
content (PC) from just URLs is not yet well explored. The work presented in
this article bridges this gap by evaluating whether LLMs can accurately
identify PC vs. non-PC from both the article text and the URLs from five
countries (France, Germany, Spain, the UK, and the US) and different languages.
Using cutting-edge LLMs like GPT, Llama, Mistral, Deepseek, Qwen and Gemma, we
measure model performance to assess whether URL-level analysis can be a good
approximation for full-text analysis of PC, even across different linguistic
and national contexts. Model outputs are compared with human-labelled articles,
as well as traditional supervised machine learning techniques, to set a
baseline of performance. Overall, our findings suggest the capacity of URLs to
embed most of the news content, providing a vital perspective on accuracy-cost
balancing. We also account for contextual limitations and suggest
methodological recommendations to use LLMs within political science studies.

</details>


### [13] [Breaking the Transcription Bottleneck: Fine-tuning ASR Models for Extremely Low-Resource Fieldwork Languages](https://arxiv.org/abs/2506.17459)
*Siyu Liang,Gina-Anne Levow*

Main category: cs.CL

TL;DR: 本文评估了两种多语言ASR模型在低资源语言中的性能，并提供了语言学家在语言记录中减轻转录瓶颈的实用指南。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别（ASR）在高资源语言中已经取得了显著的准确性，但在语言学田野工作中仍受到限制。田野工作中的录音具有独特的挑战，包括自发性言语、环境噪音以及来自未充分记录语言的严重受限的数据集。

Method: 本文对两种微调的多语言ASR模型MMS和XLS-R进行了基准测试，以评估其在五种类型多样且资源有限的语言中的性能，并控制训练数据持续时间。

Result: 研究结果表明，当可用的训练数据非常少时，MMS是最适合的，而当训练数据超过一小时时，XLS-R表现出相当的性能。

Conclusion: 本文提供了语言学家在语言记录中减轻转录瓶颈的实用指南，强调了可重复的ASR适应方法。

Abstract: Automatic Speech Recognition (ASR) has reached impressive accuracy for
high-resource languages, yet its utility in linguistic fieldwork remains
limited. Recordings collected in fieldwork contexts present unique challenges,
including spontaneous speech, environmental noise, and severely constrained
datasets from under-documented languages. In this paper, we benchmark the
performance of two fine-tuned multilingual ASR models, MMS and XLS-R, on five
typologically diverse low-resource languages with control of training data
duration. Our findings show that MMS is best suited when extremely small
amounts of training data are available, whereas XLS-R shows parity performance
once training data exceed one hour. We provide linguistically grounded analysis
for further provide insights towards practical guidelines for field linguists,
highlighting reproducible ASR adaptation approaches to mitigate the
transcription bottleneck in language documentation.

</details>


### [14] [Computational Approaches to Understanding Large Language Model Impact on Writing and Information Ecosystems](https://arxiv.org/abs/2506.17467)
*Weixin Liang*

Main category: cs.CL

TL;DR: 该论文研究了大型语言模型（LLMs）在不同领域的应用及其对社会的影响，揭示了AI治理中的公平性问题，并提出了改进的方法。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的快速发展，其在社会各个领域的应用日益广泛，但同时也带来了公平性和治理方面的挑战。因此，需要深入研究LLMs的应用和影响，以确保其公平性和有效性。

Method: 该论文通过三个研究方向进行分析：1. 研究机构采用AI检测器引入的系统性偏见；2. 提出新的群体级算法方法来衡量LLMs在写作领域的广泛应用；3. 通过大规模实证分析研究LLMs提供研究手稿反馈的能力。

Result: 该论文揭示了LLMs在不同写作领域中的广泛应用，并发现了AI辅助内容的一致模式。此外，还发现LLMs能够为研究人员提供反馈，特别是对早期职业研究人员和资源匮乏地区的研究人员有帮助。

Conclusion: 该论文探讨了大型语言模型（LLMs）在不同领域中的应用及其对社会的影响，强调了AI治理中的公平性问题，并提出了改进的方法。

Abstract: Large language models (LLMs) have shown significant potential to change how
we write, communicate, and create, leading to rapid adoption across society.
This dissertation examines how individuals and institutions are adapting to and
engaging with this emerging technology through three research directions.
First, I demonstrate how the institutional adoption of AI detectors introduces
systematic biases, particularly disadvantaging writers of non-dominant language
varieties, highlighting critical equity concerns in AI governance. Second, I
present novel population-level algorithmic approaches that measure the
increasing adoption of LLMs across writing domains, revealing consistent
patterns of AI-assisted content in academic peer reviews, scientific
publications, consumer complaints, corporate communications, job postings, and
international organization press releases. Finally, I investigate LLMs'
capability to provide feedback on research manuscripts through a large-scale
empirical analysis, offering insights into their potential to support
researchers who face barriers in accessing timely manuscript feedback,
particularly early-career researchers and those from under-resourced settings.

</details>


### [15] [VeriLocc: End-to-End Cross-Architecture Register Allocation via LLM](https://arxiv.org/abs/2506.17506)
*Lesheng Jin,Zhenyuan Ruan,Haohui Mai,Jingbo Shang*

Main category: cs.CL

TL;DR: VeriLocc is a framework that uses large language models and formal compiler techniques to enable generalizable and verifiable register allocation across GPU architectures, achieving high accuracy and performance.


<details>
  <summary>Details</summary>
Motivation: Production compilers still rely on hand-crafted register allocation heuristics that require substantial re-tuning for each hardware generation.

Method: VeriLocc combines large language models (LLMs) with formal compiler techniques, using static analysis for cross-architecture normalization and a verifier-guided regeneration loop to ensure correctness.

Result: VeriLocc achieves 85-99% single-shot accuracy and near-100% pass@100 on matrix multiplication (GEMM) and multi-head attention (MHA). It discovers more performant assignments than expert-tuned libraries, outperforming rocBLAS by over 10% in runtime.

Conclusion: VeriLocc achieves high accuracy and performance in register allocation across GPU architectures, outperforming expert-tuned libraries.

Abstract: Modern GPUs evolve rapidly, yet production compilers still rely on
hand-crafted register allocation heuristics that require substantial re-tuning
for each hardware generation. We introduce VeriLocc, a framework that combines
large language models (LLMs) with formal compiler techniques to enable
generalizable and verifiable register allocation across GPU architectures.
VeriLocc fine-tunes an LLM to translate intermediate representations (MIRs)
into target-specific register assignments, aided by static analysis for
cross-architecture normalization and generalization and a verifier-guided
regeneration loop to ensure correctness. Evaluated on matrix multiplication
(GEMM) and multi-head attention (MHA), VeriLocc achieves 85-99% single-shot
accuracy and near-100% pass@100. Case study shows that VeriLocc discovers more
performant assignments than expert-tuned libraries, outperforming rocBLAS by
over 10% in runtime.

</details>


### [16] [Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning](https://arxiv.org/abs/2506.17525)
*Mingfei Lau,Qian Chen,Yeming Fang,Tingting Xu,Tongzhou Chen,Pavel Golik*

Main category: cs.CL

TL;DR: 本文对三个常用多语言语音数据集进行了质量审计，发现其中存在显著的质量问题，并提出了改善未来数据集开发的建议。


<details>
  <summary>Details</summary>
Motivation: 我们相信解决这些问题可以使这些数据集在训练和评估中更有用，并提高下游模型的性能。

Method: 我们对三个广泛使用的多语言语音数据集进行了质量审计，包括Mozilla Common Voice 17.0、FLEURS和VoxPopuli，并将这些质量问题分为微观层面和宏观层面。

Result: 我们发现宏观层面的问题在不太制度化、通常资源不足的语言中更为普遍。我们对台湾南部闽南语（nan_tw）进行了案例分析，突显了主动语言规划（例如正字法规定、方言边界定义）和增强的数据质量控制在自动语音识别（ASR）数据集创建过程中的必要性。

Conclusion: 我们提出了指南和建议，以减轻未来数据集开发中的这些问题，强调了在创建强大且可靠的声音数据资源时社会语言意识的重要性。

Abstract: Our quality audit for three widely used public multilingual speech datasets -
Mozilla Common Voice 17.0, FLEURS, and VoxPopuli - shows that in some
languages, these datasets suffer from significant quality issues. We believe
addressing these issues will make these datasets more useful as training and
evaluation sets, and improve downstream models. We divide these quality issues
into two categories: micro-level and macro-level. We find that macro-level
issues are more prevalent in less institutionalized, often under-resourced
languages. We provide a case analysis of Taiwanese Southern Min (nan_tw) that
highlights the need for proactive language planning (e.g. orthography
prescriptions, dialect boundary definition) and enhanced data quality control
in the process of Automatic Speech Recognition (ASR) dataset creation. We
conclude by proposing guidelines and recommendations to mitigate these issues
in future dataset development, emphasizing the importance of sociolinguistic
awareness in creating robust and reliable speech data resources.

</details>


### [17] [DuaShepherd: Integrating Stepwise Correctness and Potential Rewards for Mathematical Reasoning](https://arxiv.org/abs/2506.17533)
*Yuanhao Wu,Juntong Song,Hanning Zhang,Tong Zhang,Cheng Niu*

Main category: cs.CL

TL;DR: 本文提出了一种新的奖励建模框架DuaShepherd，通过整合正确性和潜力信号来提升大型语言模型的数学推理能力。实验结果表明，该方法在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖单一的奖励信号，无法全面捕捉模型在数学推理中的表现。因此，我们需要一种能够同时考虑正确性和潜力的框架，以提高模型的性能。

Method: 我们提出了DuaShepherd，一种新颖的奖励建模框架，将两个互补的奖励信号（正确性和潜力）整合起来，以增强大型语言模型（LLMs）的数学推理能力。我们开发了一个自动化管道来构建包含这两个信号的大规模奖励建模数据集，并探索了一种统一的多头架构，在多任务设置中训练两个奖励模型。

Result: 通过将这两个信号结合成一个复合概率，我们的模型在多个基准测试中实现了性能的持续提升。在MATH500和ProcessBench上的实证评估表明，这种组合奖励显著优于仅使用一种奖励类型训练的模型。

Conclusion: 通过结合正确性和潜力信号，我们的模型在多个基准测试中实现了性能的持续提升，并在MATH500和ProcessBench上达到了最先进的性能。

Abstract: In this paper, we propose DuaShepherd, a novel reward modeling framework that
integrates two complementary reward signals, correctness and potential, to
enhance the mathematical reasoning capabilities of Large Language Models
(LLMs). While correctness-based signals emphasize identification of stepwise
errors, potential-based signals focus on the likelihood of reaching the correct
final answer. We developed an automated pipeline for constructing large-scale
reward modeling dataset with both signals. A unified, multi-head architecture
was explored to train the two reward models in a multi-task setup,
demonstrating benefits from learning both correctness and potential in
parallel. By combining these two signals into a compound probability, our model
achieves consistent performance improvements across multiple benchmarks.
Empirical evaluations on MATH500 and ProcessBench confirm that this combined
reward significantly outperforms models trained on either reward type alone,
achieving state-of-the-art performance under comparable resource constraints.

</details>


### [18] [Probing for Phonology in Self-Supervised Speech Representations: A Case Study on Accent Perception](https://arxiv.org/abs/2506.17542)
*Nitin Venkateswaran,Kevin Tang,Ratree Wayland*

Main category: cs.CL

TL;DR: 本研究探讨了自监督学习模型在编码影响口音感知的音系特征方面的能力，并发现这些模型能够有效捕捉口音强度的关键特征。


<details>
  <summary>Details</summary>
Motivation: 传统口音感知模型低估了语音特征中梯度变化的作用，而这些变化是听者用于口音判断的关键因素。

Method: 我们使用CSLU外语英语语料库提取音系特征概率，并利用Wav2Vec2-BERT和WavLM等预训练模型获取语音表示，同时结合美国英语母语者的口音判断进行分析。

Result: 实验结果显示，口音强度最好由段的预训练表示特征子集预测，其中对感知显著的音系特征进行了突出加权。此外，基于预训练表示的段距离与口音评分之间的多项逻辑回归揭示了口音强度与基线距离之间的强关联。

Conclusion: 这些结果突显了自监督语音表示在使用可解释的音系特征建模口音感知方面的价值。

Abstract: Traditional models of accent perception underestimate the role of gradient
variations in phonological features which listeners rely upon for their accent
judgments. We investigate how pretrained representations from current
self-supervised learning (SSL) models of speech encode phonological
feature-level variations that influence the perception of segmental accent. We
focus on three segments: the labiodental approximant, the rhotic tap, and the
retroflex stop, which are uniformly produced in the English of native speakers
of Hindi as well as other languages in the Indian sub-continent. We use the
CSLU Foreign Accented English corpus (Lander, 2007) to extract, for these
segments, phonological feature probabilities using Phonet (V\'asquez-Correa et
al., 2019) and pretrained representations from Wav2Vec2-BERT (Barrault et al.,
2023) and WavLM (Chen et al., 2022) along with accent judgements by native
speakers of American English. Probing analyses show that accent strength is
best predicted by a subset of the segment's pretrained representation features,
in which perceptually salient phonological features that contrast the expected
American English and realized non-native English segments are given prominent
weighting. A multinomial logistic regression of pretrained representation-based
segment distances from American and Indian English baselines on accent ratings
reveals strong associations between the odds of accent strength and distances
from the baselines, in the expected directions. These results highlight the
value of self-supervised speech representations for modeling accent perception
using interpretable phonological features.

</details>


### [19] [AgriCHN: A Comprehensive Cross-domain Resource for Chinese Agricultural Named Entity Recognition](https://arxiv.org/abs/2506.17578)
*Lingxiao Zeng,Yiqi Tong,Wei Guo,Huarui Wu,Lihao Ge,Yijun Ye,Fuzhen Zhuang,Deqing Wang,Wei Guo,Cheng Chen*

Main category: cs.CL

TL;DR: AgriCHN is a comprehensive open-source Chinese resource for agricultural named entity recognition, featuring rich agricultural entity types and diverse categories, which shows outstanding data quality and potential for further research.


<details>
  <summary>Details</summary>
Motivation: The scarcity of high-quality agricultural datasets, particularly in Chinese, has resulted in suboptimal performance when employing mainstream methods for agricultural named entity recognition. Most earlier works overlook the profound correlation of agriculture with hydrology and meteorology.

Method: The AgriCHN dataset was meticulously curated from a wealth of agricultural articles, comprising 4,040 sentences and 15,799 agricultural entity mentions spanning 27 diverse entity categories. Additionally, it includes entities from hydrology to meteorology.

Result: Data validation reveals that AgriCHN demonstrates outstanding data quality, attributable to its richer agricultural entity types and more fine-grained entity divisions. A benchmark task using state-of-the-art neural NER models highlights the significant challenge posed by AgriCHN.

Conclusion: AgriCHN demonstrates outstanding data quality and has the potential for further research.

Abstract: Agricultural named entity recognition is a specialized task focusing on
identifying distinct agricultural entities within vast bodies of text,
including crops, diseases, pests, and fertilizers. It plays a crucial role in
enhancing information extraction from extensive agricultural text resources.
However, the scarcity of high-quality agricultural datasets, particularly in
Chinese, has resulted in suboptimal performance when employing mainstream
methods for this purpose. Most earlier works only focus on annotating
agricultural entities while overlook the profound correlation of agriculture
with hydrology and meteorology. To fill this blank, we present AgriCHN, a
comprehensive open-source Chinese resource designed to promote the accuracy of
automated agricultural entity annotation. The AgriCHN dataset has been
meticulously curated from a wealth of agricultural articles, comprising a total
of 4,040 sentences and encapsulating 15,799 agricultural entity mentions
spanning 27 diverse entity categories. Furthermore, it encompasses entities
from hydrology to meteorology, thereby enriching the diversity of entities
considered. Data validation reveals that, compared with relevant resources,
AgriCHN demonstrates outstanding data quality, attributable to its richer
agricultural entity types and more fine-grained entity divisions. A benchmark
task has also been constructed using several state-of-the-art neural NER
models. Extensive experimental results highlight the significant challenge
posed by AgriCHN and its potential for further research.

</details>


### [20] [Mind the Gap: Assessing Wiktionary's Crowd-Sourced Linguistic Knowledge on Morphological Gaps in Two Related Languages](https://arxiv.org/abs/2506.17603)
*Jonathan Sakunkoo,Annabella Sakunkoo*

Main category: cs.CL

TL;DR: 本研究利用神经形态分析器验证了从Wiktionary收集的缺陷动词列表，发现Wiktionary在意大利语中较为可靠，但在拉丁语中存在一些不准确之处，这表明众包资源在某些情况下可能不是语言知识的最终来源。


<details>
  <summary>Details</summary>
Motivation: 解决形态缺陷性问题对于提高形态丰富语言中NLP工具的准确性至关重要，但传统语言资源往往缺乏对形态缺口的覆盖，而众包资源如维基百科和Wiktionary在稀有语言现象中具有重要价值。

Method: 本研究定制了一个新的神经形态分析器来标注拉丁语和意大利语语料库，并使用大量标注数据计算验证了从Wiktionary收集的缺陷动词的列表。

Result: 研究结果表明，尽管Wiktionary为意大利语的形态缺口提供了高度可靠的信息，但7%的拉丁语词根被列为缺陷性词根，但语料库证据显示它们并非缺陷性词根。

Conclusion: 本研究通过提供可扩展的工具和方法，提高了对众包数据的质量保证，推动了计算形态学的发展，并扩展了非英语、形态丰富的语言中的缺陷性语言知识。

Abstract: Morphological defectivity is an intriguing and understudied phenomenon in
linguistics. Addressing defectivity, where expected inflectional forms are
absent, is essential for improving the accuracy of NLP tools in morphologically
rich languages. However, traditional linguistic resources often lack coverage
of morphological gaps as such knowledge requires significant human expertise
and effort to document and verify. For scarce linguistic phenomena in
under-explored languages, Wikipedia and Wiktionary often serve as among the few
accessible resources. Despite their extensive reach, their reliability has been
a subject of controversy. This study customizes a novel neural morphological
analyzer to annotate Latin and Italian corpora. Using the massive annotated
data, crowd-sourced lists of defective verbs compiled from Wiktionary are
validated computationally. Our results indicate that while Wiktionary provides
a highly reliable account of Italian morphological gaps, 7% of Latin lemmata
listed as defective show strong corpus evidence of being non-defective. This
discrepancy highlights potential limitations of crowd-sourced wikis as
definitive sources of linguistic knowledge, particularly for less-studied
phenomena and languages, despite their value as resources for rare linguistic
features. By providing scalable tools and methods for quality assurance of
crowd-sourced data, this work advances computational morphology and expands
linguistic knowledge of defectivity in non-English, morphologically rich
languages.

</details>


### [21] [TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting](https://arxiv.org/abs/2506.17609)
*Lincan Li,Eren Erman Ozguven,Yue Zhao,Guang Wang,Yiqun Xie,Yushun Dong*

Main category: cs.CL

TL;DR: TyphoFormer is a novel framework that uses natural language descriptions as auxiliary prompts to improve typhoon trajectory forecasting. It outperforms other state-of-the-art methods, especially in challenging scenarios.


<details>
  <summary>Details</summary>
Motivation: Transformer-based models usually lack access to broader contextual knowledge that enhances the forecasting reliability of sparse meteorological trajectories, such as typhoon tracks.

Method: TyphoFormer incorporates natural language descriptions as auxiliary prompts to improve typhoon trajectory forecasting. It uses Large Language Model (LLM) to generate concise textual descriptions based on numerical attributes, which are embedded as auxiliary special tokens prepended to the numerical time series input.

Result: Extensive experiments on HURDAT2 benchmark show that TyphoFormer consistently outperforms other state-of-the-art baseline methods, particularly under challenging scenarios involving nonlinear path shifts and limited historical observations.

Conclusion: TyphoFormer consistently outperforms other state-of-the-art baseline methods, particularly under challenging scenarios involving nonlinear path shifts and limited historical observations.

Abstract: Accurate typhoon track forecasting is crucial for early system warning and
disaster response. While Transformer-based models have demonstrated strong
performance in modeling the temporal dynamics of dense trajectories of humans
and vehicles in smart cities, they usually lack access to broader contextual
knowledge that enhances the forecasting reliability of sparse meteorological
trajectories, such as typhoon tracks. To address this challenge, we propose
TyphoFormer, a novel framework that incorporates natural language descriptions
as auxiliary prompts to improve typhoon trajectory forecasting. For each time
step, we use Large Language Model (LLM) to generate concise textual
descriptions based on the numerical attributes recorded in the North Atlantic
hurricane database. The language descriptions capture high-level meteorological
semantics and are embedded as auxiliary special tokens prepended to the
numerical time series input. By integrating both textual and sequential
information within a unified Transformer encoder, TyphoFormer enables the model
to leverage contextual cues that are otherwise inaccessible through numerical
features alone. Extensive experiments are conducted on HURDAT2 benchmark,
results show that TyphoFormer consistently outperforms other state-of-the-art
baseline methods, particularly under challenging scenarios involving nonlinear
path shifts and limited historical observations.

</details>


### [22] [OpusLM: A Family of Open Unified Speech Language Models](https://arxiv.org/abs/2506.17611)
*Jinchuan Tian,William Chen,Yifan Peng,Jiatong Shi,Siddhant Arora,Shikhar Bharadwaj,Takashi Maekaku,Yusuke Shinohara,Keita Goto,Xiang Yue,Huck Yang,Shinji Watanabe*

Main category: cs.CL

TL;DR: 本文介绍了OpusLMs，这是一种开放的基础语音语言模型，具有出色的性能，并且所有内容都是公开透明的。


<details>
  <summary>Details</summary>
Motivation: 开发一种开放的基础语音语言模型（SpeechLM），能够与现有SpeechLMs相媲美甚至超越它们的性能。

Method: OpusLMs是从仅解码器的文本语言模型初始化的，并在213K小时的语音-文本对和292B个纯文本标记上进行了持续预训练。论文讨论了语音语言模型的设计，包括分词、多流语言模型和多阶段训练策略。

Result: OpusLMs在语音识别、语音合成和文本能力方面表现出色，甚至优于现有的SpeechLMs。此外，论文实验验证了模型规模扩展的重要性以及数据选择的退火效应。

Conclusion: OpusLMs是基于公开材料构建的完全透明的模型，并且它们在语音识别、语音合成和文本能力方面表现出色，甚至优于现有的SpeechLMs。

Abstract: This paper presents Open Unified Speech Language Models (OpusLMs), a family
of open foundational speech language models (SpeechLMs) up to 7B. Initialized
from decoder-only text language models, the OpusLMs are continuously
pre-trained on 213K hours of speech-text pairs and 292B text-only tokens. We
demonstrate our OpusLMs achieve comparable (or even superior) performance with
existing SpeechLMs in speech recognition, speech synthesis, and text-only
capabilities. Technically, this paper articulates our SpeechLM designs on
tokenization, multi-stream language models, and multi-stage training
strategies. We experimentally demonstrate the importance of model size scaling
and the effect of annealing data selection. The OpusLMs are all built from
publicly available materials and are fully transparent models. We release our
code, data, checkpoints, and training logs to facilitate open SpeechLM research

</details>


### [23] [Answer-Centric or Reasoning-Driven? Uncovering the Latent Memory Anchor in LLMs](https://arxiv.org/abs/2506.17630)
*Yang Wu,Yifan Zhang,Yiwei Wang,Yujun Cai,Yurong Wu,Yuran Wang,Ning Xu,Jian Cheng*

Main category: cs.CL

TL;DR: 本研究发现大型语言模型（LLMs）主要依赖于显式答案而非真正的推理过程，这引发了对其推理深度的质疑。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）表现出令人印象深刻的推理能力，但越来越多的证据表明，它们的成功很大程度上源于记忆的答案-推理模式，而不是真正的推理。我们研究的核心问题是LLMs是否主要依赖最终答案还是推理链的文本模式。

Method: 我们提出了一种五级答案可见性提示框架，系统地操纵答案线索，并通过间接的行为分析来探测模型行为。

Result: 在最先进的LLMs上的实验显示，对显式答案的强烈且一致的依赖。当答案线索被遮蔽时，性能下降了26.90%，即使有完整的推理链。

Conclusion: 我们的研究揭示了LLMs中答案锚定现象，并强调了对LLMs中推理定义的更细致理解的必要性。

Abstract: While Large Language Models (LLMs) demonstrate impressive reasoning
capabilities, growing evidence suggests much of their success stems from
memorized answer-reasoning patterns rather than genuine inference. In this
work, we investigate a central question: are LLMs primarily anchored to final
answers or to the textual pattern of reasoning chains? We propose a five-level
answer-visibility prompt framework that systematically manipulates answer cues
and probes model behavior through indirect, behavioral analysis. Experiments
across state-of-the-art LLMs reveal a strong and consistent reliance on
explicit answers. The performance drops by 26.90\% when answer cues are masked,
even with complete reasoning chains. These findings suggest that much of the
reasoning exhibited by LLMs may reflect post-hoc rationalization rather than
true inference, calling into question their inferential depth. Our study
uncovers the answer-anchoring phenomenon with rigorous empirical validation and
underscores the need for a more nuanced understanding of what constitutes
reasoning in LLMs.

</details>


### [24] [Step-Opt: Boosting Optimization Modeling in LLMs through Iterative Data Synthesis and Structured Validation](https://arxiv.org/abs/2506.17637)
*Yang Wu,Yifan Zhang,Yurong Wu,Yuran Wang,Junkai Zhang,Jian Cheng*

Main category: cs.CL

TL;DR: 本文提出了一种名为Step-Opt-Instruct的框架，用于生成高质量的优化建模数据，并通过微调LLMs开发出Step-Opt模型，在复杂OR任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理运筹学（OR）中的优化建模任务时面临挑战，尤其是在处理复杂问题时。因此，需要一种方法来增强现有数据集并生成高质量的微调数据。

Method: Step-Opt-Instruct框架通过迭代问题生成和分步验证来提高问题复杂度并确保数据质量，然后对开源LLMs进行微调以开发Step-Opt模型。

Result: Step-Opt模型在NL4OPT、MAMO和IndustryOR等基准测试中取得了最先进的性能，特别是在处理复杂OR任务时，困难问题的微平均准确率提高了17.01%。

Conclusion: 这些发现表明，将结构化验证与逐步问题细化相结合可以有效提升LLMs在决策自动化中的性能。

Abstract: Large Language Models (LLMs) have revolutionized various domains but
encounter substantial challenges in tackling optimization modeling tasks for
Operations Research (OR), particularly when dealing with complex problem. In
this work, we propose Step-Opt-Instruct, a framework that augments existing
datasets and generates high-quality fine-tuning data tailored to optimization
modeling. Step-Opt-Instruct employs iterative problem generation to
systematically increase problem complexity and stepwise validation to
rigorously verify data, preventing error propagation and ensuring the quality
of the generated dataset. Leveraging this framework, we fine-tune open-source
LLMs, including LLaMA-3-8B and Mistral-7B, to develop Step-Opt--a model that
achieves state-of-the-art performance on benchmarks such as NL4OPT, MAMO, and
IndustryOR. Extensive experiments demonstrate the superior performance of
Step-Opt, especially in addressing complex OR tasks, with a notable 17.01\%
improvement in micro average accuracy on difficult problems. These findings
highlight the effectiveness of combining structured validation with gradual
problem refinement to advance the automation of decision-making processes using
LLMs.The code and dataset are available at https://github.com/samwu-learn/Step.

</details>


### [25] [TPTT: Transforming Pretrained Transformer into Titans](https://arxiv.org/abs/2506.17671)
*Fabien Furfaro*

Main category: cs.CL

TL;DR: TPTT is a novel framework that enhances pretrained Transformer models with efficient linearized attention mechanisms and advanced memory management, showing significant improvements in efficiency and accuracy.


<details>
  <summary>Details</summary>
Motivation: The computational and memory demands of large language models remain a significant challenge, particularly for long-context inference. There is a need for an efficient framework to enhance pretrained Transformer models.

Method: TPTT employs techniques such as Memory as Gate (MaG) and mixed linearized attention (LiZA) to enhance pretrained Transformer models with efficient linearized attention mechanisms and advanced memory management.

Result: TPTT shows substantial improvements in both efficiency and accuracy on the MMLU benchmark with models of approximately 1 billion parameters. For instance, Titans-Llama-3.2-1B achieves a 20% increase in Exact Match (EM) over its baseline.

Conclusion: TPTT is a practical and robust framework for enhancing pretrained Transformer models, showing significant improvements in efficiency and accuracy.

Abstract: Recent advances in large language models (LLMs) have led to remarkable
progress in natural language processing, but their computational and memory
demands remain a significant challenge, particularly for long-context
inference. We introduce TPTT (Transforming Pretrained Transformer into Titans),
a novel framework for enhancing pretrained Transformer models with efficient
linearized attention mechanisms and advanced memory management. TPTT employs
techniques such as Memory as Gate (MaG) and mixed linearized attention (LiZA).
It is fully compatible with the Hugging Face Transformers library, enabling
seamless adaptation of any causal LLM through parameter-efficient fine-tuning
(LoRA) without full retraining. We show the effectiveness of TPTT on the MMLU
benchmark with models of approximately 1 billion parameters, observing
substantial improvements in both efficiency and accuracy. For instance,
Titans-Llama-3.2-1B achieves a 20% increase in Exact Match (EM) over its
baseline. Statistical analyses and comparisons with recent state-of-the-art
methods confirm the practical scalability and robustness of TPTT. Code is
available at https://github.com/fabienfrfr/tptt . Python package at
https://pypi.org/project/tptt/ .

</details>


### [26] [Resource-Friendly Dynamic Enhancement Chain for Multi-Hop Question Answering](https://arxiv.org/abs/2506.17692)
*Binquan Ji,Haibo Luo,Yifei Lu,Lei Hei,Jiaqi Wang,Tingjing Liao,Lingyu Wang,Shichao Wang,Feiliang Ren*

Main category: cs.CL

TL;DR: DEC是一种新的框架，用于知识密集型多跳问答任务，能够有效减少计算开销并提高性能。


<details>
  <summary>Details</summary>
Motivation: 知识密集型多跳问答任务需要从多个来源整合证据来解决复杂查询，但将许多文档和扩展上下文纳入考虑会给轻量级语言模型带来挑战，如幻觉和语义漂移。

Method: DEC框架通过分解复杂问题为逻辑连贯的子问题，形成无幻觉的推理链，并通过上下文感知重写迭代优化这些子问题。此外，引入了一个轻量级的判别关键词提取模块，以提取的关键词实现有针对性的文档检索。

Result: 在三个多跳QA数据集上的广泛实验表明，DEC的表现与最先进的基准相当或更好，同时显著减少了令牌消耗。

Conclusion: DEC在资源受限环境中表现出色，尤其是在8B参数模型上达到了最先进的结果。

Abstract: Knowledge-intensive multi-hop question answering (QA) tasks, which require
integrating evidence from multiple sources to address complex queries, often
necessitate multiple rounds of retrieval and iterative generation by large
language models (LLMs). However, incorporating many documents and extended
contexts poses challenges -such as hallucinations and semantic drift-for
lightweight LLMs with fewer parameters. This work proposes a novel framework
called DEC (Dynamic Enhancement Chain). DEC first decomposes complex questions
into logically coherent subquestions to form a hallucination-free reasoning
chain. It then iteratively refines these subquestions through context-aware
rewriting to generate effective query formulations. For retrieval, we introduce
a lightweight discriminative keyword extraction module that leverages extracted
keywords to achieve targeted, precise document recall with relatively low
computational overhead. Extensive experiments on three multi-hop QA datasets
demonstrate that DEC performs on par with or surpasses state-of-the-art
benchmarks while significantly reducing token consumption. Notably, our
approach attains state-of-the-art results on models with 8B parameters,
showcasing its effectiveness in various scenarios, particularly in
resource-constrained environments.

</details>


### [27] [Zero-Shot Conversational Stance Detection: Dataset and Approaches](https://arxiv.org/abs/2506.17693)
*Yuzhe Ding,Kang He,Bobo Li,Li Zheng,Haijun He,Fei Li,Chong Teng,Donghong Ji*

Main category: cs.CL

TL;DR: 本文提出了一个大规模的零样本对话立场检测数据集ZS-CSD，并提出了一种新的模型SITPCL，在零样本设置中取得了最先进的性能，但仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 现有对话立场检测数据集受到特定目标的限制，这限制了立场检测模型在现实应用中遇到大量未见过的目标时的有效性。为了弥补这一差距，我们手动整理了一个大规模、高质量的零样本对话立场检测数据集，名为ZS-CSD。

Method: 我们提出了SITPCL，一种基于说话人交互和目标感知原型对比学习的模型，并在零样本设置中建立了基准性能。

Result: 实验结果表明，所提出的SITPCL模型在零样本对话立场检测中取得了最先进的性能。然而，SITPCL模型仅获得了43.81%的F1宏得分，突显了零样本对话立场检测中的持续挑战。

Conclusion: 实验结果表明，所提出的SITPCL模型在零样本对话立场检测中取得了最先进的性能。值得注意的是，SITPCL模型仅获得了43.81%的F1宏得分，突显了零样本对话立场检测中的持续挑战。

Abstract: Stance detection, which aims to identify public opinion towards specific
targets using social media data, is an important yet challenging task. With the
increasing number of online debates among social media users, conversational
stance detection has become a crucial research area. However, existing
conversational stance detection datasets are restricted to a limited set of
specific targets, which constrains the effectiveness of stance detection models
when encountering a large number of unseen targets in real-world applications.
To bridge this gap, we manually curate a large-scale, high-quality zero-shot
conversational stance detection dataset, named ZS-CSD, comprising 280 targets
across two distinct target types. Leveraging the ZS-CSD dataset, we propose
SITPCL, a speaker interaction and target-aware prototypical contrastive
learning model, and establish the benchmark performance in the zero-shot
setting. Experimental results demonstrate that our proposed SITPCL model
achieves state-of-the-art performance in zero-shot conversational stance
detection. Notably, the SITPCL model attains only an F1-macro score of 43.81%,
highlighting the persistent challenges in zero-shot conversational stance
detection.

</details>


### [28] [The Evolution of Natural Language Processing: How Prompt Optimization and Language Models are Shaping the Future](https://arxiv.org/abs/2506.17700)
*Summra Saleem,Muhammad Nabeel Asim,Shaista Zulfiqar,Andreas Dengel*

Main category: cs.CL

TL;DR: 本文全面分析了大型语言模型（LLMs）中的提示优化策略，提出了11种不同的分类，并探讨了其在各种NLP任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量关于提示工程的综述文章，但目前缺乏对提示优化策略的系统性分析。因此，本文旨在填补这一空白，为未来的比较研究和严格评估提供基础。

Method: 本文对现有的提示工程和优化策略进行了全面的综述，分析了它们的工作原理，并将其分类为11个不同的类别。此外，还详细介绍了这些策略在不同NLP任务中的应用情况，以及使用的LLMs和基准数据集。

Result: 本文提供了关于多样化提示优化策略的深入见解，分析了它们的工作原理，并将其分类为11个不同的类别。此外，还详细介绍了这些策略在不同NLP任务中的应用情况，以及使用的LLMs和基准数据集。

Conclusion: 本文研究了大型语言模型（LLMs）在自然语言处理（NLP）领域的应用，并提出了多样化的提示优化策略的全面分析。研究旨在填补当前对提示优化策略的系统性分析的空白，并为未来的研究提供坚实的基础。

Abstract: Large Language Models (LLMs) have revolutionized the field of Natural
Language Processing (NLP) by automating traditional labor-intensive tasks and
consequently accelerated the development of computer-aided applications. As
researchers continue to advance this field with the introduction of novel
language models and more efficient training/finetuning methodologies, the idea
of prompt engineering and subsequent optimization strategies with LLMs has
emerged as a particularly impactful trend to yield a substantial performance
boost across diverse NLP tasks. To best of our knowledge numerous review
articles have explored prompt engineering, however, a critical gap exists in
comprehensive analyses of prompt optimization strategies. To bridge this gap
this paper provides unique and comprehensive insights about the potential of
diverse prompt optimization strategies. It analyzes their underlying working
paradigms and based on these principles, categorizes them into 11 distinct
classes. Moreover, the paper provides details about various NLP tasks where
these prompt optimization strategies have been employed, along with details of
different LLMs and benchmark datasets used for evaluation. This comprehensive
compilation lays a robust foundation for future comparative studies and enables
rigorous assessment of prompt optimization and LLM-based predictive pipelines
under consistent experimental settings: a critical need in the current
landscape. Ultimately, this research will centralize diverse strategic
knowledge to facilitate the adaptation of existing prompt optimization
strategies for development of innovative predictors across unexplored tasks.

</details>


### [29] [Aged to Perfection: Machine-Learning Maps of Age in Conversational English](https://arxiv.org/abs/2506.17708)
*MingZe Tang*

Main category: cs.CL

TL;DR: 本研究利用英国国家语料库2014年的数据，探讨不同年龄组之间的语言模式差异，并尝试发现具有代表性的语言特征。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨不同年龄组之间的语言模式差异，探索说话者人口统计学与语言因素（如话语持续时间、词汇多样性、词语选择）之间的联系。

Method: 通过将计算语言分析和机器学习方法相结合，我们试图揭示多个世代特有的语言标志，并创建可以一致地从各个方面估计说话者年龄组的预测模型。

Result: 本研究利用英国国家语料库2014年数据，调查了不同年龄组的语言模式，并尝试发现具有代表性的语言特征。

Conclusion: 本研究有助于我们了解现代英国言语中的社会语言多样性。

Abstract: The study uses the British National Corpus 2014, a large sample of
contemporary spoken British English, to investigate language patterns across
different age groups. Our research attempts to explore how language patterns
vary between different age groups, exploring the connection between speaker
demographics and linguistic factors such as utterance duration, lexical
diversity, and word choice. By merging computational language analysis and
machine learning methodologies, we attempt to uncover distinctive linguistic
markers characteristic of multiple generations and create prediction models
that can consistently estimate the speaker's age group from various aspects.
This work contributes to our knowledge of sociolinguistic diversity throughout
the life of modern British speech.

</details>


### [30] [Unveiling Factors for Enhanced POS Tagging: A Study of Low-Resource Medieval Romance Languages](https://arxiv.org/abs/2506.17715)
*Matthias Schöffel,Esteban Garces Arias,Marinus Wiedner,Paula Ruppert,Meimingwei Li,Christian Heumann,Matthias Aßenmacher*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型在处理中世纪罗曼语词性标注时的性能，并发现了一些有效的专门技术来应对低资源历史语言的挑战。


<details>
  <summary>Details</summary>
Motivation: 词性标注仍然是自然语言处理流水线中的基础组成部分，特别是在计算语言学和数字人文的交叉领域，对于历史文本分析尤为重要。尽管现代大型语言模型在古代语言方面取得了显著进展，但它们在中世纪罗曼语中的应用面临独特的挑战，这些挑战源于历时语言演变、拼写变化和标记数据的稀缺性。

Method: 本研究系统地调查了不同中世纪奥克语、中世纪西班牙语和中世纪法语文本语料库中的词性标注性能的主要决定因素。通过严格的实验，评估了微调方法、提示工程、模型架构、解码策略和跨语言迁移学习技术对标注准确率的影响。

Result: 研究结果揭示了大型语言模型在处理历史语言变化和非标准化拼写的显著局限性，同时也发现了有效的专门技术，可以解决低资源历史语言的独特挑战。

Conclusion: 研究揭示了大型语言模型在处理历史语言变化和非标准化拼写方面的显著局限性，同时也发现了有效的专门技术，可以解决低资源历史语言的独特挑战。

Abstract: Part-of-speech (POS) tagging remains a foundational component in natural
language processing pipelines, particularly critical for historical text
analysis at the intersection of computational linguistics and digital
humanities. Despite significant advancements in modern large language models
(LLMs) for ancient languages, their application to Medieval Romance languages
presents distinctive challenges stemming from diachronic linguistic evolution,
spelling variations, and labeled data scarcity. This study systematically
investigates the central determinants of POS tagging performance across diverse
corpora of Medieval Occitan, Medieval Spanish, and Medieval French texts,
spanning biblical, hagiographical, medical, and dietary domains. Through
rigorous experimentation, we evaluate how fine-tuning approaches, prompt
engineering, model architectures, decoding strategies, and cross-lingual
transfer learning techniques affect tagging accuracy. Our results reveal both
notable limitations in LLMs' ability to process historical language variations
and non-standardized spelling, as well as promising specialized techniques that
effectively address the unique challenges presented by low-resource historical
languages.

</details>


### [31] [KAG-Thinker: Teaching Large Language Models to Think with Human-like Reasoning Process](https://arxiv.org/abs/2506.17728)
*Dalong Zhang,Jun Xu,Jun Zhou,Lei Liang,Lin Yuan,Ling Zhong,Mengshu Sun,Peilong Zhao,QiWei Wang,Xiaorui Wang,Xinkai Du,YangYang Hou,Yu Ao,ZhaoYang Wang,Zhengke Gui,ZhiYing Yi,Zhongpu Bo*

Main category: cs.CL

TL;DR: 本文介绍了一种名为KAG-Thinker的新框架，它基于轻量级大语言模型，通过模拟人类认知机制来提高问答任务中的逻辑连贯性和上下文一致性。该框架利用逻辑形式引导的检索和推理技术，结合知识边界模型和深度求解模型优化知识获取，并通过监督微调与多轮对话对齐模型。


<details>
  <summary>Details</summary>
Motivation: 本文旨在提高大语言模型在特定领域知识库上的问答任务中的逻辑连贯性和上下文一致性，同时模拟人类的认知机制来处理复杂问题。

Method: 本文提出了一种基于逻辑形式引导的检索和推理技术路线，将复杂问题分解为独立可解的子问题（也称为逻辑形式），并通过广度分解和深度求解模型来增强知识获取的全面性。此外，还使用监督微调与多轮对话对齐模型，以避免过度反思。

Result: 本文提出的KAG-Thinker框架能够有效提升问答任务中的逻辑连贯性和上下文一致性，并通过知识边界模型和深度求解模型优化知识获取过程。此外，监督微调与多轮对话的方法有助于模型与结构化推理范式的对齐。

Conclusion: 本文介绍了KAG-Thinker，这是一种基于轻量级大语言模型（LLM）的人类类似推理框架。该框架通过建立结构化的思考过程，模拟人类认知机制来处理复杂问题，从而提高问答（Q&A）任务中逻辑连贯性和上下文一致性。

Abstract: In this paper, we introduce KAG-Thinker, a novel human-like reasoning
framework built upon a parameter-light large language model (LLM). Our approach
enhances the logical coherence and contextual consistency of the thinking
process in question-answering (Q\&A) tasks on domain-specific knowledge bases
(KBs) within LLMs. This framework simulates human cognitive mechanisms for
handling complex problems by establishing a structured thinking process.
Continuing the \textbf{Logical Form} guided retrieval and reasoning technology
route of KAG v0.7, firstly, it decomposes complex questions into independently
solvable sub-problems(also referred to as logical forms) through
\textbf{breadth decomposition}, each represented in two equivalent
forms-natural language and logical function-and further classified as either
Knowledge Retrieval or Reasoning Analysis tasks, with dependencies and
variables passing explicitly modeled via logical function interfaces. In the
solving process, the Retrieval function is used to perform knowledge retrieval
tasks, while the Math and Deduce functions are used to perform reasoning
analysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval
sub-problem tasks, LLMs and external knowledge sources are regarded as
equivalent KBs. We use the \textbf{knowledge boundary} model to determine the
optimal source using self-regulatory mechanisms such as confidence calibration
and reflective reasoning, and use the \textbf{depth solving} model to enhance
the comprehensiveness of knowledge acquisition. Finally, instead of utilizing
reinforcement learning, we employ supervised fine-tuning with multi-turn
dialogues to align the model with our structured inference paradigm, thereby
avoiding excessive reflection. This is supported by a data evaluation framework
and iterative corpus synthesis, which facilitate the generation of detailed
reasoning trajectories...

</details>


### [32] [HIDE and Seek: Detecting Hallucinations in Language Models via Decoupled Representations](https://arxiv.org/abs/2506.17748)
*Anwoy Chatterjee,Yash Goel,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文提出了一种新的单次通过方法HIDE，用于检测语言模型中的幻觉。该方法通过分析模型内部表示与生成输出之间的解耦来实现高效的幻觉检测。实验结果显示，HIDE在多个数据集和模型上表现优异，具有更高的准确性和更低的计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数检测幻觉的方法依赖于对每个输入进行多次生成，这导致计算成本和延迟增加。我们需要一种更高效的方法来检测幻觉。

Method: 我们提出了一种单次通过、无需训练的方法，称为HIDE（通过解耦表示进行幻觉检测），该方法利用了语言模型内部表示与生成输出之间的统计解耦。我们使用希尔伯特-施密特独立准则（HSIC）来量化这种解耦，并在生成输出序列时提取隐藏状态表示。

Result: HIDE在几乎所有设置中都优于其他单次通过方法，在各种模型和数据集上，AUC-ROC的平均相对改进约为29%。此外，HIDE在计算时间上消耗减少了约51%，并且在性能上与多轮最先进的方法相当甚至更好。

Conclusion: 我们的研究结果表明，利用语言模型内部表示的解耦可以有效且高效地检测幻觉。

Abstract: Contemporary Language Models (LMs), while impressively fluent, often generate
content that is factually incorrect or unfaithful to the input context - a
critical issue commonly referred to as 'hallucination'. This tendency of LMs to
generate hallucinated content undermines their reliability, especially because
these fabrications are often highly convincing and therefore difficult to
detect. While several existing methods attempt to detect hallucinations, most
rely on analyzing multiple generations per input, leading to increased
computational cost and latency. To address this, we propose a single-pass,
training-free approach for effective Hallucination detectIon via Decoupled
rEpresentations (HIDE). Our approach leverages the hypothesis that
hallucinations result from a statistical decoupling between an LM's internal
representations of input context and its generated output. We quantify this
decoupling using the Hilbert-Schmidt Independence Criterion (HSIC) applied to
hidden-state representations extracted while generating the output sequence. We
conduct extensive experiments on four diverse question answering datasets,
evaluating both faithfulness and factuality hallucinations across six
open-source LMs of varying scales and properties. Our results demonstrate that
HIDE outperforms other single-pass methods in almost all settings, achieving an
average relative improvement of ~29% in AUC-ROC over the best-performing
single-pass strategy across various models and datasets. Additionally, HIDE
shows competitive and often superior performance with multi-pass
state-of-the-art methods, obtaining an average relative improvement of ~3% in
AUC-ROC while consuming ~51% less computation time. Our findings highlight the
effectiveness of exploiting internal representation decoupling in LMs for
efficient and practical hallucination detection.

</details>


### [33] [Multilingual Tokenization through the Lens of Indian Languages: Challenges and Insights](https://arxiv.org/abs/2506.17789)
*N J Karthika,Maharaj Brahma,Rohit Saluja,Ganesh Ramakrishnan,Maunendra Sankar Desarkar*

Main category: cs.CL

TL;DR: 本文对17种印度语言的分词策略进行了全面评估，发现低资源语言可以通过高资源语言训练的分词器受益，并提供了构建更公平、高效的多语言NLP分词器的见解。


<details>
  <summary>Details</summary>
Motivation: 现有的分词器往往偏向于高资源语言，限制了它们在语言多样性和形态丰富的语言（如印度次大陆的语言）中的有效性。

Method: 本文对17种印度语言的分词策略进行了全面的内在评估，量化了自底向上和自顶向下分词算法（BPE和Unigram LM）之间的权衡，以及词汇表大小的影响，并比较了多语言词汇构建策略，如联合和基于聚类的训练。

Result: 本文展示了极低资源语言可以从针对相关高资源语言训练的分词器中受益。

Conclusion: 本文的研究提供了构建更公平、高效和语言学上知情的多语言NLP分词器的实际见解。

Abstract: Tokenization plays a pivotal role in multilingual NLP. However, existing
tokenizers are often skewed towards high-resource languages, limiting their
effectiveness for linguistically diverse and morphologically rich languages
such as those in the Indian subcontinent. This paper presents a comprehensive
intrinsic evaluation of tokenization strategies across 17 Indian languages. We
quantify the trade-offs between bottom-up and top-down tokenizer algorithms
(BPE and Unigram LM), effects of vocabulary sizes, and compare strategies of
multilingual vocabulary construction such as joint and cluster-based training.
We also show that extremely low-resource languages can benefit from tokenizers
trained on related high-resource languages. Our study provides practical
insights for building more fair, efficient, and linguistically informed
tokenizers for multilingual NLP.

</details>


### [34] [THCM-CAL: Temporal-Hierarchical Causal Modelling with Conformal Calibration for Clinical Risk Prediction](https://arxiv.org/abs/2506.17844)
*Xin Zhang,Qiyu Wei,Yingjie Zhu,Fanyi Wu,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 本文提出了THCM-CAL，一种用于从电子健康记录中进行自动化临床风险预测的时序-层次因果模型，通过构建多模态因果图来捕捉临床实体之间的交互作用，并扩展了符合预测以提高预测可靠性。


<details>
  <summary>Details</summary>
Motivation: 大多数先前方法要么分别处理这些模态，要么依赖于简单的融合策略，忽略了叙述观察引发诊断并跨入院传播风险的方向性、层次因果关系。

Method: 提出了一种称为THCM-CAL的时序-层次因果模型，并扩展了对多标签ICD编码的符合预测，以校准复杂共现情况下的每代码置信区间。

Result: THCM-CAL通过构建多模态因果图，推断出三种临床相关的交互作用：同切片同模态序列、同切片跨模态触发以及跨切片风险传播。

Conclusion: THCM-CAL在MIMIC-III和MIMIC-IV数据集上的实验结果证明了其优越性。

Abstract: Automated clinical risk prediction from electronic health records (EHRs)
demands modeling both structured diagnostic codes and unstructured narrative
notes. However, most prior approaches either handle these modalities separately
or rely on simplistic fusion strategies that ignore the directional,
hierarchical causal interactions by which narrative observations precipitate
diagnoses and propagate risk across admissions. In this paper, we propose
THCM-CAL, a Temporal-Hierarchical Causal Model with Conformal Calibration. Our
framework constructs a multimodal causal graph where nodes represent clinical
entities from two modalities: Textual propositions extracted from notes and ICD
codes mapped to textual descriptions. Through hierarchical causal discovery,
THCM-CAL infers three clinically grounded interactions: intra-slice
same-modality sequencing, intra-slice cross-modality triggers, and inter-slice
risk propagation. To enhance prediction reliability, we extend conformal
prediction to multi-label ICD coding, calibrating per-code confidence intervals
under complex co-occurrences. Experimental results on MIMIC-III and MIMIC-IV
demonstrate the superiority of THCM-CAL.

</details>


### [35] [LLMs for Customized Marketing Content Generation and Evaluation at Scale](https://arxiv.org/abs/2506.17863)
*Haoran Liu,Amir Tahmasbi,Ehtesham Sam Haque,Purak Jain*

Main category: cs.CL

TL;DR: 本文提出了MarketingFM系统，用于生成针对关键词的广告文案，并引入了AutoEval-Main和AutoEval-Update自动化评估系统，以提高广告效果和评估效率。


<details>
  <summary>Details</summary>
Motivation: 当前的离站营销内容过于通用、模板化且与落地页不一致，限制了其效果。同时，人工审查生成的广告仍然成本高昂。

Method: MarketingFM是一种检索增强系统，它整合了多个数据源以生成针对关键词的广告文案，而AutoEval-Main和AutoEval-Update则是自动化评估系统，结合规则基础指标与LLM作为评判者技术，以及成本效益高的LLM-人类协作框架，以动态优化评估提示并适应变化的标准。

Result: 在一项实验中，以关键词为中心的广告文案优于模板，实现了高达9%的点击率提高，12%的展示次数增加，以及0.38%的每次点击费用降低。AutoEval-Main在大规模人工注释实验中与人工评审者达到了89.57%的一致性。AutoEval-Update通过选择性采样和批评型LLM生成对齐报告，提高了评估一致性并减少了手动工作。

Conclusion: 尽管人类监督对于设置阈值和验证改进仍然至关重要，但AutoEval-Update框架通过选择性采样代表性的广告进行人工审查，并使用批评型LLM生成对齐报告，提高了评估的一致性并减少了手动工作。

Abstract: Offsite marketing is essential in e-commerce, enabling businesses to reach
customers through external platforms and drive traffic to retail websites.
However, most current offsite marketing content is overly generic,
template-based, and poorly aligned with landing pages, limiting its
effectiveness. To address these limitations, we propose MarketingFM, a
retrieval-augmented system that integrates multiple data sources to generate
keyword-specific ad copy with minimal human intervention. We validate
MarketingFM via offline human and automated evaluations and large-scale online
A/B tests. In one experiment, keyword-focused ad copy outperformed templates,
achieving up to 9% higher CTR, 12% more impressions, and 0.38% lower CPC,
demonstrating gains in ad ranking and cost efficiency. Despite these gains,
human review of generated ads remains costly. To address this, we propose
AutoEval-Main, an automated evaluation system that combines rule-based metrics
with LLM-as-a-Judge techniques to ensure alignment with marketing principles.
In experiments with large-scale human annotations, AutoEval-Main achieved
89.57% agreement with human reviewers. Building on this, we propose
AutoEval-Update, a cost-efficient LLM-human collaborative framework to
dynamically refine evaluation prompts and adapt to shifting criteria with
minimal human input. By selectively sampling representative ads for human
review and using a critic LLM to generate alignment reports, AutoEval-Update
improves evaluation consistency while reducing manual effort. Experiments show
the critic LLM suggests meaningful refinements, improving LLM-human agreement.
Nonetheless, human oversight remains essential for setting thresholds and
validating refinements before deployment.

</details>


### [36] [QueueEDIT: Structural Self-Correction for Sequential Model Editing in LLMs](https://arxiv.org/abs/2506.17864)
*Taolin Zhang,Haidong Kang,Dongyang Li,Qizhou Chen,Chengyu Wang Xiaofeng He,Richang Hong*

Main category: cs.CL

TL;DR: 本文提出了一种基于队列的自我校正框架（QueueEDIT），用于改善顺序模型编辑（SME）的性能，并减轻参数偏差对大型语言模型（LLMs）一般能力的影响。通过引入结构映射编辑损失和动态对齐机制，该框架在多个SME设置中表现出色，并保持了LLMs在一般NLP任务中的高性能。


<details>
  <summary>Details</summary>
Motivation: 最近，大型语言模型（LLMs）表现出令人印象深刻的结果，但仍存在幻觉问题。模型编辑已被提出用于纠正LLMs中的事实性错误。一个具有挑战性的案例是顺序模型编辑（SME），它旨在连续纠正错误而不是将其视为一次性任务。在SME过程中，由于引入新参数，LLMs的一般能力可能会受到负面影响。因此，我们需要一种方法来提高SME性能并减轻参数偏差对LLMs一般能力的影响。

Method: 我们提出了一种基于队列的自我校正框架（QueueEDIT），通过引入结构映射编辑损失来映射三元组到Transformer层中的知识敏感神经元，并使用队列存储每个编辑知识的参数，动态对齐之前编辑的参数。在每次编辑中，选择与当前定位参数最相关的队列参数来确定是否需要重新对齐以前的知识。队列中不相关的参数被冻结，队列头部的参数被更新到LLM中以确保它们不会损害一般能力。

Result: 实验结果表明，我们的框架在各种SME设置中显著优于强基线，并在单次编辑中保持竞争力。此外，经过SME过程的LLM在一般NLP任务中仍保持高能力。

Conclusion: 实验结果表明，我们的框架在各种SME设置中显著优于强基线，并在单次编辑中保持竞争力。此外，经过SME过程的LLM在一般NLP任务中仍保持高能力。

Abstract: Recently, large language models (LLMs) have demonstrated impressive results
but still suffer from hallucinations. Model editing has been proposed to
correct factual inaccuracies in LLMs. A challenging case is sequential model
editing (SME), which aims to rectify errors continuously rather than treating
them as a one-time task. During SME, the general capabilities of LLMs can be
negatively affected due to the introduction of new parameters. In this paper,
we propose a queue-based self-correction framework (QueueEDIT) that not only
enhances SME performance by addressing long-sequence dependency but also
mitigates the impact of parameter bias on the general capabilities of LLMs.
Specifically, we first introduce a structural mapping editing loss to map the
triplets to the knowledge-sensitive neurons within the Transformer layers of
LLMs. We then store the located parameters for each piece of edited knowledge
in a queue and dynamically align previously edited parameters. In each edit, we
select queue parameters most relevant to the currently located parameters to
determine whether previous knowledge needs realignment. Irrelevant parameters
in the queue are frozen, and we update the parameters at the queue head to the
LLM to ensure they do not harm general abilities. Experiments show that our
framework significantly outperforms strong baselines across various SME
settings and maintains competitiveness in single-turn editing. The resulting
LLMs also preserve high capabilities in general NLP tasks throughout the SME
process.

</details>


### [37] [How Alignment Shrinks the Generative Horizon](https://arxiv.org/abs/2506.17871)
*Chenghao Yang,Ari Holtzman*

Main category: cs.CL

TL;DR: 本文研究了对齐的大规模语言模型（LLM）生成输出缺乏多样性的原因。我们引入了分支因子（BF）作为衡量模型输出分布中有效下一步可能性数量的度量。我们的实证分析显示，BF随着生成过程的推进而减少，对齐调优显著减少了BF。此外，我们发现这种稳定性对复杂推理有意外的影响，对齐的链式思维（CoT）模型利用这种效应。我们的研究结果表明，BF是一个强大的诊断工具，用于理解和控制LLM的输出。


<details>
  <summary>Details</summary>
Motivation: 我们想要了解为什么对齐的大规模语言模型（LLM）生成的输出缺乏多样性。我们希望通过研究概率集中性来揭示这一现象背后的原因。

Method: 我们通过概率集中性来研究这一现象，并引入了分支因子（BF）作为衡量模型输出分布中有效下一步可能性数量的度量。我们还进行了实证分析，并进行了提示实验以验证假设。

Result: 我们的实证分析揭示了两个关键发现：(1) BF通常随着生成过程的推进而减少，这表明LLM在生成过程中变得更加可预测。(2) 对齐调优显著地尖锐化了模型的输出分布，从一开始就减少了BF，相对于基础模型减少了近一个数量级。此外，我们发现这种稳定性对复杂推理有意外的影响，对齐的链式思维（CoT）模型利用这种效应，通过生成更长的推理链，将生成推向后期、更确定性的（较低BF）阶段，从而产生更稳定的输出。

Conclusion: 我们的研究结果表明，分支因子（BF）是一个强大的诊断工具，用于理解和控制大型语言模型（LLM）的输出。它阐明了对齐如何减少变异性，如何促进稳定的生成，以及如何引导基础模型远离多样性。

Abstract: Despite their impressive capabilities, aligned large language models (LLMs)
often generate outputs that lack diversity. What drives this stability in the
generation? We investigate this phenomenon through the lens of probability
concentration in the model's output distribution. To quantify this
concentration, we introduce the Branching Factor (BF) -- a token-invariant
measure of the effective number of plausible next steps during generation. Our
empirical analysis reveals two key findings: (1) BF often decreases as
generation progresses, suggesting that LLMs become more predictable as they
generate. (2) alignment tuning substantially sharpens the model's output
distribution from the outset, reducing BF by nearly an order of magnitude
(e.g., from 12 to 1.2) relative to base models. This stark reduction helps
explain why aligned models often appear less sensitive to decoding strategies.
Building on this insight, we find this stability has surprising implications
for complex reasoning. Aligned Chain-of-Thought (CoT) models (e.g.,
DeepSeek-distilled models), for instance, leverage this effect; by generating
longer reasoning chains, they push generation into later, more deterministic
(lower BF) stages, resulting in more stable outputs. We hypothesize that
alignment tuning does not fundamentally change a model's behavior, but instead
steers it toward stylistic tokens (e.g., "Sure") that unlock low-entropy
trajectories already present in the base model. This view is supported by
nudging experiments, which show that prompting base models with such tokens can
similarly reduce BF. Together, our findings establish BF as a powerful
diagnostic for understanding and controlling LLM outputs - clarifying how
alignment reduces variability, how CoT promotes stable generations, and how
base models can be steered away from diversity.

</details>


### [38] [Multi-turn Jailbreaking via Global Refinement and Active Fabrication](https://arxiv.org/abs/2506.17881)
*Hua Tang,Lingyong Yan,Yukun Zhao,Shuaiqiang Wang,Jizhou Huang,Dawei Yin*

Main category: cs.CL

TL;DR: 本文提出了一种新的多轮越狱方法，通过全局优化越狱路径和主动制造模型响应来提高越狱效果。


<details>
  <summary>Details</summary>
Motivation: 现有的多轮越狱技术难以适应对话动态的变化，因此需要一种更有效的多轮越狱方法。

Method: 我们提出了一种新颖的多轮越狱方法，在每次交互中全局优化越狱路径，并主动制造模型响应以抑制安全警告，从而增加在后续问题中引出有害输出的可能性。

Result: 实验结果表明，我们的方法在六个最先进的大型语言模型上表现优于现有的单轮和多轮越狱技术。

Conclusion: 我们的方法在六个最先进的大型语言模型上相比现有的单轮和多轮越狱技术表现出优越的性能。

Abstract: Large Language Models (LLMs) have achieved exceptional performance across a
wide range of tasks. However, they still pose significant safety risks due to
the potential misuse for malicious purposes. Jailbreaks, which aim to elicit
models to generate harmful content, play a critical role in identifying the
underlying security threats. Recent jailbreaking primarily focuses on
single-turn scenarios, while the more complicated multi-turn scenarios remain
underexplored. Moreover, existing multi-turn jailbreaking techniques struggle
to adapt to the evolving dynamics of dialogue as the interaction progresses. To
address this limitation, we propose a novel multi-turn jailbreaking method that
refines the jailbreaking path globally at each interaction. We also actively
fabricate model responses to suppress safety-related warnings, thereby
increasing the likelihood of eliciting harmful outputs in subsequent questions.
Experimental results demonstrate the superior performance of our method
compared with existing single-turn and multi-turn jailbreaking techniques
across six state-of-the-art LLMs. Our code is publicly available at
https://github.com/Ytang520/Multi-Turn_jailbreaking_Global-Refinment_and_Active-Fabrication.

</details>


### [39] [Scatter-Based Innovation Propagation in Large Language Models for Multi-Stage Process Adaptation](https://arxiv.org/abs/2506.17949)
*Hong Su*

Main category: cs.CL

TL;DR: 本文提出了一种基于散射的创新扩展模型，用于解决大型语言模型在多阶段过程中应用局部创新的问题。该模型通过四个步骤引导LLM，从而提高新想法的适用性和可重用性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在再现和扩展预训练中观察到的模式方面表现出强大的能力，但往往难以将新颖的想法推广到原始上下文之外。本文旨在解决如何将特定阶段或组件引入的局部创新应用到多阶段过程的其他部分的问题。

Method: 论文提出了一个四步流程：(1) 通过比较用户的输入与其周围上下文来识别核心创新；(2) 通过去除对特定阶段或组件的引用来泛化创新；(3) 确定泛化的创新是否适用于更广泛的范围；(4) 使用LLM系统地将其应用于结构相似的其他阶段。

Result: 验证结果表明，创新散射模型使LLMs能够跨越结构相似的阶段扩展创新，从而增强泛化能力和重用性。

Conclusion: 该论文提出了一种基于散射的创新扩展模型（创新散射模型），以解决大型语言模型（LLMs）在多阶段过程中应用局部创新的问题。该模型通过四个步骤引导LLM，从而提高新想法的适用性和可重用性。

Abstract: Large Language Models (LLMs) exhibit strong capabilities in reproducing and
extending patterns observed during pretraining but often struggle to generalize
novel ideas beyond their original context. This paper addresses the challenge
of applying such localized innovations - introduced at a specific stage or
component - to other parts of a multi-stage process. We propose a scatter-based
innovation expansion model (innovation scatter model) that guides the LLM
through a four-step process: (1) identifying the core innovation by comparing
the user's input with its surrounding context, (2) generalizing the innovation
by removing references to specific stages or components, (3) determining
whether the generalized innovation applies to a broader scope beyond the
original stage, and (4) systematically applying it to other structurally
similar stages using the LLM. This model leverages structural redundancy across
stages to improve the applicability of novel ideas. Verification results
demonstrate that the innovation scatter model enables LLMs to extend
innovations across structurally similar stages, thereby enhancing
generalization and reuse.

</details>


### [40] [A Comprehensive Graph Framework for Question Answering with Mode-Seeking Preference Alignment](https://arxiv.org/abs/2506.17951)
*Quanwei Tang,Sophia Yat Mei Lee,Junshuang Wu,Dong Zhang,Shoushan Li,Erik Cambria,Guodong Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种基于图的框架GraphMPA，通过模式寻找偏好对齐来提高大语言模型的问答能力。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成（RAG）在问答任务中取得了进展，但仍然存在挑战，如实现全局理解和与人类伦理和质量偏好对齐。

Method: 我们提出了GraphMPA，这是一种基于图的框架，结合了模式寻找偏好对齐。该方法使用通用相似性度量构建分层文档图，并引入模式寻找偏好优化以更好地与人类偏好对齐。

Result: 在六个数据集上的广泛实验表明了GraphMPA的有效性。

Conclusion: 我们的方法在六个数据集上的实验结果证明了其有效性。

Abstract: Recent advancements in retrieval-augmented generation (RAG) have enhanced
large language models in question answering by integrating external knowledge.
However, challenges persist in achieving global understanding and aligning
responses with human ethical and quality preferences. To address these issues,
we propose GraphMPA, a comprehensive graph-based framework with mode-seeking
preference alignment. Our approach constructs a hierarchical document graph
using a general similarity measurement, mimicking human cognitive processes for
information understanding and synthesis. Additionally, we introduce
mode-seeking preference optimization to better align model outputs with human
preferences through probability-matching constraints. Extensive experiments on
six datasets demonstrate the effectiveness of our
\href{https://github.com/tangquanwei/GraphMPA}{GraphMPA}.

</details>


### [41] [PDF Retrieval Augmented Question Answering](https://arxiv.org/abs/2506.18027)
*Thi Thu Uyen Hoang,Viet Anh Nguyen*

Main category: cs.CL

TL;DR: 本文提出了一种基于RAG框架的问答系统，以增强从PDF文件中提取信息的能力，特别是在处理多模态问题时。


<details>
  <summary>Details</summary>
Motivation: 现有问答系统主要针对文本内容设计，而PDF文件中包含丰富的数据类型（如文本、图像、矢量图、图表和表格），这对现有系统提出了独特的挑战。因此，需要开发一种能够有效处理多模态问题的RAG基础问答系统。

Method: 通过改进处理和整合PDF中的非文本元素的方法，并微调大型语言模型以更好地适应我们的系统，从而实现了一个全面的基于RAG的问答系统。

Result: 我们提供了对解决方案的深入实验评估，证明了其从不同类型的PDF内容中提取准确信息的能力。

Conclusion: 本文不仅推动了检索增强型问答系统的边界，还为多模态数据集成和处理的进一步研究奠定了基础。

Abstract: This paper presents an advancement in Question-Answering (QA) systems using a
Retrieval Augmented Generation (RAG) framework to enhance information
extraction from PDF files. Recognizing the richness and diversity of data
within PDFs--including text, images, vector diagrams, graphs, and tables--poses
unique challenges for existing QA systems primarily designed for textual
content. We seek to develop a comprehensive RAG-based QA system that will
effectively address complex multimodal questions, where several data types are
combined in the query. This is mainly achieved by refining approaches to
processing and integrating non-textual elements in PDFs into the RAG framework
to derive precise and relevant answers, as well as fine-tuning large language
models to better adapt to our system. We provide an in-depth experimental
evaluation of our solution, demonstrating its capability to extract accurate
information that can be applied to different types of content across PDFs. This
work not only pushes the boundaries of retrieval-augmented QA systems but also
lays a foundation for further research in multimodal data integration and
processing.

</details>


### [42] [Splitformer: An improved early-exit architecture for automatic speech recognition on edge devices](https://arxiv.org/abs/2506.18035)
*Maxence Lasbordes,Daniele Falavigna,Alessio Brutti*

Main category: cs.CL

TL;DR: 本文提出在神经网络架构中引入并行层，以提高语音识别性能，同时保持推理时间不变。


<details>
  <summary>Details</summary>
Motivation: 早期退出架构和高效的语音识别架构各有优势，但缺乏模块化以注入早期退出分支。

Method: 在架构中引入并行层，处理输入的下采样版本，并与标准处理层结合使用。

Result: 在标准基准测试中，语音识别性能显著提高，模型参数略有增加，但推理时间不受影响。

Conclusion: 通过引入并行层，可以在不增加推理时间的情况下显著提高语音识别性能。

Abstract: The ability to dynamically adjust the computational load of neural models
during inference in a resource aware manner is crucial for on-device processing
scenarios, characterised by limited and time-varying computational resources.
Early-exit architectures represent an elegant and effective solution, since
they can process the input with a subset of their layers, exiting at
intermediate branches (the upmost layers are hence removed from the model).
  From a different perspective, for automatic speech recognition applications
there are memory-efficient neural architectures that apply variable frame rate
analysis, through downsampling/upsampling operations in the middle layers,
reducing the overall number of operations and improving significantly the
performance on well established benchmarks. One example is the Zipformer.
However, these architectures lack the modularity necessary to inject early-exit
branches.
  With the aim of improving the performance in early-exit models, we propose
introducing parallel layers in the architecture that process downsampled
versions of their inputs. % in conjunction with standard processing layers. We
show that in this way the speech recognition performance on standard benchmarks
significantly improve, at the cost of a small increase in the overall number of
model parameters but without affecting the inference time.

</details>


### [43] [Markov-Enhanced Clustering for Long Document Summarization: Tackling the 'Lost in the Middle' Challenge with Large Language Models](https://arxiv.org/abs/2506.18036)
*Aziz Amari,Mohamed Achref Ben Ammar*

Main category: cs.CL

TL;DR: 本文提出了一种混合摘要方法，结合抽取式和生成式技术，以解决长文档中关键信息丢失的问题。


<details>
  <summary>Details</summary>
Motivation: 由于信息来源的快速扩展，需要有效的自动文本摘要，但大型语言模型在处理长文档时面临资源密集和关键信息丢失的问题。

Method: 我们的方法将文档分成较小的文本块，对它们的向量嵌入进行聚类，为每个代表文档关键思想的集群生成摘要，并通过马尔可夫链图选择语义顺序来构建最终摘要。

Result: 该混合方法能够更有效地保留关键信息并生成连贯的摘要。

Conclusion: 我们提出了一种混合摘要方法，结合了抽取式和生成式技术，以解决长文档中关键信息丢失的问题。

Abstract: The rapid expansion of information from diverse sources has heightened the
need for effective automatic text summarization, which condenses documents into
shorter, coherent texts. Summarization methods generally fall into two
categories: extractive, which selects key segments from the original text, and
abstractive, which generates summaries by rephrasing the content coherently.
Large language models have advanced the field of abstractive summarization, but
they are resourceintensive and face significant challenges in retaining key
information across lengthy documents, which we call being "lost in the middle".
To address these issues, we propose a hybrid summarization approach that
combines extractive and abstractive techniques. Our method splits the document
into smaller text chunks, clusters their vector embeddings, generates a summary
for each cluster that represents a key idea in the document, and constructs the
final summary by relying on a Markov chain graph when selecting the semantic
order of ideas.

</details>


### [44] [Statistical Multicriteria Evaluation of LLM-Generated Text](https://arxiv.org/abs/2506.18082)
*Esteban Garces Arias,Hannah Blocher,Julian Rodemann,Matthias Aßenmacher,Christoph Jansen*

Main category: cs.CL

TL;DR: 本文提出了一种基于广义随机占优的统计推断框架，用于评估大型语言模型生成文本的质量。该方法克服了现有评估方法的三个关键局限性，并能够同时评估多个质量维度，而无需对相关指标进行任意加权。


<details>
  <summary>Details</summary>
Motivation: 当前的评估方法往往依赖于孤立的指标或简单的聚合，无法捕捉到文本质量中诸如连贯性、多样性、流畅性等指标之间的细微权衡。因此，需要一种更全面且统计上可靠的评估方法。

Method: 本文采用了基于广义随机占优（GSD）的统计推断框架，以评估大型语言模型生成文本的质量。该方法通过部分排序的解码策略，同时评估多个质量维度，避免了对相关指标进行任意加权。

Result: 通过应用该框架来评估常见的解码策略与人类生成的文本，我们证明了其能够识别出统计上显著的性能差异，同时考虑了抽样设计的独立同分布假设可能的偏差。

Conclusion: 本文提出了一种基于广义随机占优（GSD）的统计推断框架，用于评估大型语言模型生成文本的质量。该方法克服了现有评估方法的三个关键局限性，并能够同时评估多个质量维度，而无需对相关指标进行任意加权。

Abstract: Assessing the quality of LLM-generated text remains a fundamental challenge
in natural language processing. Current evaluation approaches often rely on
isolated metrics or simplistic aggregations that fail to capture the nuanced
trade-offs between coherence, diversity, fluency, and other relevant indicators
of text quality. In this work, we adapt a recently proposed framework for
statistical inference based on Generalized Stochastic Dominance (GSD) that
addresses three critical limitations in existing benchmarking methodologies:
the inadequacy of single-metric evaluation, the incompatibility between
cardinal automatic metrics and ordinal human judgments, and the lack of
inferential statistical guarantees. The GSD-front approach enables simultaneous
evaluation across multiple quality dimensions while respecting their different
measurement scales, building upon partial orders of decoding strategies, thus
avoiding arbitrary weighting of the involved metrics. By applying this
framework to evaluate common decoding strategies against human-generated text,
we demonstrate its ability to identify statistically significant performance
differences while accounting for potential deviations from the i.i.d.
assumption of the sampling design.

</details>


### [45] [Evaluating Prompt-Based and Fine-Tuned Approaches to Czech Anaphora Resolution](https://arxiv.org/abs/2506.18091)
*Patrik Stano,Aleš Horák*

Main category: cs.CL

TL;DR: 本文比较了两种现代方法在捷克语指代消解中的表现，结果显示微调模型在准确率和资源效率方面优于提示方法。


<details>
  <summary>Details</summary>
Motivation: 指代消解在自然语言理解中起着关键作用，特别是在像捷克语这样的形态丰富的语言中。本文旨在比较两种现代方法在捷克语指代消解中的表现。

Method: 本文比较了两种现代的指代消解方法在捷克语文本中的应用：使用大型语言模型（LLMs）的提示工程和微调紧凑生成模型。我们评估了多个经过指令微调的LLMs，包括Mistral Large 2和Llama 3，并将其与我们专门为捷克语指代消解训练的mT5和Mistral模型的微调变体进行了比较。

Result: 实验结果表明，提示方法在少样本情况下取得了高达74.5%的准确率，而微调模型，尤其是mT5-large，取得了高达88%的准确率，同时需要更少的计算资源。

Conclusion: 实验表明，虽然提示方法在少样本情况下表现出色，但微调模型，特别是mT5-large，在准确率上显著优于提示方法，同时需要更少的计算资源。

Abstract: Anaphora resolution plays a critical role in natural language understanding,
especially in morphologically rich languages like Czech. This paper presents a
comparative evaluation of two modern approaches to anaphora resolution on Czech
text: prompt engineering with large language models (LLMs) and fine-tuning
compact generative models. Using a dataset derived from the Prague Dependency
Treebank, we evaluate several instruction-tuned LLMs, including Mistral Large 2
and Llama 3, using a series of prompt templates. We compare them against
fine-tuned variants of the mT5 and Mistral models that we trained specifically
for Czech anaphora resolution. Our experiments demonstrate that while prompting
yields promising few-shot results (up to 74.5% accuracy), the fine-tuned
models, particularly mT5-large, outperform them significantly, achieving up to
88% accuracy while requiring fewer computational resources. We analyze
performance across different anaphora types, antecedent distances, and source
corpora, highlighting key strengths and trade-offs of each approach.

</details>


### [46] [InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating](https://arxiv.org/abs/2506.18102)
*Fuyu Wang,Jiangtong Li,Kun Zhu,Changjun Jiang*

Main category: cs.CL

TL;DR: 本文提出了一种双组件框架，旨在提高基于大语言模型的辩论系统的客观评估和多维优化能力。实验结果表明，该框架在评估和辩论性能方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型的辩论系统主要关注回应特定论点，而忽视了诸如真实性、逻辑有效性等客观评估。此外，这些系统缺乏跨各种维度（包括评估指标、链式思维推理和多轮辩论优化）的结构化方法，从而限制了其效果。

Method: 本文提出了一个双组件框架：(1) InspireScore，一种新的评估系统，结合了四个主观标准（情感吸引力、论点清晰度、论点安排和主题相关性）以及两个客观指标（事实真实性和逻辑有效性）；(2) InspireDebate，一种通过链式思维推理增强、多维直接偏好优化（DPO）和基于网络的检索增强生成（Web-RAG）实时知识定位来优化辩论过程的框架。

Result: 实验评估表明，InspireScore与专家判断的相关性比现有方法高44%，而InspireDebate在基准模型上表现出显著改进，提高了57%。

Conclusion: 本文提出了一种双组件框架，包括InspireScore和InspireDebate，以解决现有基于大语言模型的辩论系统在客观评估和多维优化方面的不足。实验结果表明，InspireScore与专家判断的相关性提高了44%，而InspireDebate比基线模型提高了57%。

Abstract: With the rapid advancements in large language models (LLMs), debating tasks,
such as argument quality assessment and debate process simulation, have made
significant progress. However, existing LLM-based debating systems focus on
responding to specific arguments while neglecting objective assessments such as
authenticity and logical validity. Furthermore, these systems lack a structured
approach to optimize across various dimensions$-$including evaluation metrics,
chain-of-thought (CoT) reasoning, and multi-turn debate refinement$-$thereby
limiting their effectiveness. To address these interconnected challenges, we
propose a dual-component framework: (1) $\textbf{InspireScore}$, a novel
evaluation system that establishes a multi-dimensional assessment architecture
incorporating four subjective criteria (emotional appeal, argument clarity,
argument arrangement, and topic relevance) alongside two objective metrics
(fact authenticity and logical validity); and (2) $\textbf{InspireDebate}$, an
optimized debating framework employing a phased optimization approach through
CoT reasoning enhancement, multi-dimensional Direct Preference Optimization
(DPO), and real-time knowledge grounding via web-based Retrieval Augmented
Generation (Web-RAG). Empirical evaluations demonstrate that
$\textbf{InspireScore}$ achieves 44$\%$ higher correlation with expert
judgments compared to existing methods, while $\textbf{InspireDebate}$ shows
significant improvements, outperforming baseline models by 57$\%$. Source code
is available at https://github.com/fywang12/InspireDebate.

</details>


### [47] [Chengyu-Bench: Benchmarking Large Language Models for Chinese Idiom Understanding and Use](https://arxiv.org/abs/2506.18105)
*Yicheng Fu,Zhemin Huang,Liuxin Yang,Yumeng Lu,Zhongdongming Dai*

Main category: cs.CL

TL;DR: Chengyu-Bench is a comprehensive benchmark for evaluating language models' ability to understand and use Chinese idioms, revealing that while LLMs can gauge sentiment, they struggle with cultural and contextual nuances.


<details>
  <summary>Details</summary>
Motivation: Chinese idioms are challenging for language models to interpret and use correctly. Existing benchmarks focus on narrow tasks, so a comprehensive benchmark is needed.

Method: Introduce Chengyu-Bench, a comprehensive benchmark featuring three tasks: Evaluative Connotation, Appropriateness, and Open Cloze.

Result: LLMs achieve over 95% accuracy on Evaluative Connotation, but only ~85% on Appropriateness and ~40% top-1 accuracy on Open Cloze. Error analysis reveals that most mistakes arise from fundamental misunderstandings of idiom meanings.

Conclusion: Chengyu-Bench demonstrates that while LLMs can reliably gauge idiom sentiment, they still struggle to grasp the cultural and contextual nuances essential for proper usage.

Abstract: Chinese idioms (Chengyu) are concise four-character expressions steeped in
history and culture, whose literal translations often fail to capture their
full meaning. This complexity makes them challenging for language models to
interpret and use correctly. Existing benchmarks focus on narrow tasks -
multiple-choice cloze tests, isolated translation, or simple paraphrasing. We
introduce Chengyu-Bench, a comprehensive benchmark featuring three tasks: (1)
Evaluative Connotation, classifying idioms as positive or negative; (2)
Appropriateness, detecting incorrect idiom usage in context; and (3) Open
Cloze, filling blanks in longer passages without options. Chengyu-Bench
comprises 2,937 human-verified examples covering 1,765 common idioms sourced
from diverse corpora. We evaluate leading LLMs and find they achieve over 95%
accuracy on Evaluative Connotation, but only ~85% on Appropriateness and ~40%
top-1 accuracy on Open Cloze. Error analysis reveals that most mistakes arise
from fundamental misunderstandings of idiom meanings. Chengyu-Bench
demonstrates that while LLMs can reliably gauge idiom sentiment, they still
struggle to grasp the cultural and contextual nuances essential for proper
usage. The benchmark and source code are available at:
https://github.com/sofyc/ChengyuBench.

</details>


### [48] [Mental Health Equity in LLMs: Leveraging Multi-Hop Question Answering to Detect Amplified and Silenced Perspectives](https://arxiv.org/abs/2506.18116)
*Batool Haider,Atmika Gorti,Aman Chadha,Manas Gaur*

Main category: cs.CL

TL;DR: 本文介绍了多跳问答框架，用于检测大型语言模型在心理健康话语中的偏见，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管之前的研究发现了令人担忧的趋势，但系统的方法来检测交叉偏见仍然有限。

Method: 本文引入了一种多跳问答（MHQA）框架，以探索大型语言模型在心理健康话语中的响应偏见。我们系统地标记了年龄、种族、性别和社会经济地位，研究了在人口统计学交叉点上的偏见模式。

Result: 我们评估了四种大型语言模型：Claude 3.5 Sonnet、Jamba 1.6、Gemma 3 和 Llama 4，揭示了在情感、人口统计学和心理健康状况方面的系统性差异。我们的MHQA方法在检测方面优于传统方法，识别出偏见通过顺序推理放大的位置。

Conclusion: 这些发现突显了大型语言模型在心理健康护理中再现偏见的关键领域，为公平的人工智能开发提供了可行的见解。

Abstract: Large Language Models (LLMs) in mental healthcare risk propagating biases
that reinforce stigma and harm marginalized groups. While previous research
identified concerning trends, systematic methods for detecting intersectional
biases remain limited. This work introduces a multi-hop question answering
(MHQA) framework to explore LLM response biases in mental health discourse. We
analyze content from the Interpretable Mental Health Instruction (IMHI) dataset
across symptom presentation, coping mechanisms, and treatment approaches. Using
systematic tagging across age, race, gender, and socioeconomic status, we
investigate bias patterns at demographic intersections. We evaluate four LLMs:
Claude 3.5 Sonnet, Jamba 1.6, Gemma 3, and Llama 4, revealing systematic
disparities across sentiment, demographics, and mental health conditions. Our
MHQA approach demonstrates superior detection compared to conventional methods,
identifying amplification points where biases magnify through sequential
reasoning. We implement two debiasing techniques: Roleplay Simulation and
Explicit Bias Reduction, achieving 66-94% bias reductions through few-shot
prompting with BBQ dataset examples. These findings highlight critical areas
where LLMs reproduce mental healthcare biases, providing actionable insights
for equitable AI development.

</details>


### [49] [The Syntactic Acceptability Dataset (Preview): A Resource for Machine Learning and Linguistic Analysis of English](https://arxiv.org/abs/2506.18120)
*Tom S Juzek*

Main category: cs.CL

TL;DR: 本文介绍了一个用于句法和计算语言学研究的Syntactic Acceptability Dataset，包含1,000个英语序列，每个条目都有语法和可接受性标签。初步分析显示语法和可接受性判断在大多数情况下一致，且机器学习模型在预测可接受性方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 为了促进句法和计算语言学的研究，设计了一个资源，以确保当代话语的代表性，并通过众包获得可接受性状态。

Method: 该数据集包含1,000个英语序列，其中一半来自教科书，另一半来自期刊Linguistic Inquiry，每个条目都标有语法状态和可接受性状态。

Result: 观察到语法和可接受性判断在约83%的情况下趋于一致，并且“中间性”经常出现。机器学习模型在预测可接受性方面表现优于语法预测。

Conclusion: 该数据集是目前公开可用的最大同类数据集，未来工作将专注于扩展它。

Abstract: We present a preview of the Syntactic Acceptability Dataset, a resource being
designed for both syntax and computational linguistics research. In its current
form, the dataset comprises 1,000 English sequences from the syntactic
discourse: Half from textbooks and half from the journal Linguistic Inquiry,
the latter to ensure a representation of the contemporary discourse. Each entry
is labeled with its grammatical status ("well-formedness" according to
syntactic formalisms) extracted from the literature, as well as its
acceptability status ("intuitive goodness" as determined by native speakers)
obtained through crowdsourcing, with highest experimental standards. Even in
its preliminary form, this dataset stands as the largest of its kind that is
publicly accessible. We also offer preliminary analyses addressing three
debates in linguistics and computational linguistics: We observe that
grammaticality and acceptability judgments converge in about 83% of the cases
and that "in-betweenness" occurs frequently. This corroborates existing
research. We also find that while machine learning models struggle with
predicting grammaticality, they perform considerably better in predicting
acceptability. This is a novel finding. Future work will focus on expanding the
dataset.

</details>


### [50] [$φ^{\infty}$: Clause Purification, Embedding Realignment, and the Total Suppression of the Em Dash in Autoregressive Language Models](https://arxiv.org/abs/2506.18129)
*Bugra Kilictas,Faruk Alpay*

Main category: cs.CL

TL;DR: 本文发现自回归Transformer语言模型中存在一个关键漏洞，即破折号标记会导致递归语义漂移，从而引发从句边界幻觉和嵌入空间纠缠。作者提出了一种新的解决方案，结合符号短语净化和目标嵌入矩阵重新对齐，能够有效抑制问题标记并保持语义连贯性。实验结果表明，该方法在生成一致性和主题保持方面有显著提升，并为识别和减轻基础模型中的令牌级漏洞提供了通用框架。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决自回归Transformer语言模型中的一个关键漏洞，即破折号标记引起的递归语义漂移，这导致了从句边界幻觉和嵌入空间纠缠。

Method: 本文提出了一种结合符号短语净化（通过phi-infinity算子）与目标嵌入矩阵重新对齐的创新解决方案。这种方法能够在不需要模型微调的情况下完全抑制问题令牌，同时通过固定点收敛保证保持语义连贯性。

Result: 实验验证表明，生成的一致性和主题保持方面有显著改进。

Conclusion: 本文建立了一个通用框架，用于识别和减轻基础模型中的令牌级漏洞，并对AI安全、模型对齐以及大型语言模型在生产环境中的稳健部署具有直接意义。该方法不仅限于标点符号，还扩展到解决神经文本生成系统中的更广泛的一类递归不稳定性。

Abstract: We identify a critical vulnerability in autoregressive transformer language
models where the em dash token induces recursive semantic drift, leading to
clause boundary hallucination and embedding space entanglement. Through formal
analysis of token-level perturbations in semantic lattices, we demonstrate that
em dash insertion fundamentally alters the model's latent representations,
causing compounding errors in long-form generation. We propose a novel solution
combining symbolic clause purification via the phi-infinity operator with
targeted embedding matrix realignment. Our approach enables total suppression
of problematic tokens without requiring model retraining, while preserving
semantic coherence through fixed-point convergence guarantees. Experimental
validation shows significant improvements in generation consistency and topic
maintenance. This work establishes a general framework for identifying and
mitigating token-level vulnerabilities in foundation models, with immediate
implications for AI safety, model alignment, and robust deployment of large
language models in production environments. The methodology extends beyond
punctuation to address broader classes of recursive instabilities in neural
text generation systems.

</details>


### [51] [Sparse Feature Coactivation Reveals Composable Semantic Modules in Large Language Models](https://arxiv.org/abs/2506.18141)
*Ruixuan Deng,Xiaoyang Hu,Miles Gilberti,Shane Storks,Aman Taxali,Mike Angstadt,Chandra Sripada,Joyce Chai*

Main category: cs.CL

TL;DR: 本文通过分析大型语言模型中的语义组件，发现其具有模块化组织，并提出了高效、有针对性的模型操作方法。


<details>
  <summary>Details</summary>
Motivation: 为了识别大型语言模型中的语义组件，并探索它们对模型输出的影响，以实现更高效的模型操作。

Method: 使用从少量提示中收集的稀疏自编码器（SAE）特征的共激活来识别大型语言模型（LLMs）中的语义连贯、上下文一致的网络组件。

Result: 通过消融语义组件，模型输出会发生可预测的变化；而增强这些组件会引发反事实响应。组合关系和国家组件会产生复合的反事实输出。大多数国家组件出现在第一层，而更抽象的关系组件集中在后期层。此外，后期层中的节点对模型输出有更强的因果影响。

Conclusion: 这些发现表明大型语言模型中存在模块化的知识组织，并推动了高效、有针对性的模型操作方法。

Abstract: We identify semantically coherent, context-consistent network components in
large language models (LLMs) using coactivation of sparse autoencoder (SAE)
features collected from just a handful of prompts. Focusing on country-relation
tasks, we show that ablating semantic components for countries and relations
changes model outputs in predictable ways, while amplifying these components
induces counterfactual responses. Notably, composing relation and country
components yields compound counterfactual outputs. We find that, whereas most
country components emerge from the very first layer, the more abstract relation
components are concentrated in later layers. Furthermore, within relation
components themselves, nodes from later layers tend to have a stronger causal
impact on model outputs. Overall, these findings suggest a modular organization
of knowledge within LLMs and advance methods for efficient, targeted model
manipulation.

</details>


### [52] [QuranMorph: Morphologically Annotated Quranic Corpus](https://arxiv.org/abs/2506.18148)
*Diyam Akra,Tymaa Hammouda,Mustafa Jarrar*

Main category: cs.CL

TL;DR: 本文介绍了QuranMorph语料库，这是一个形态学注释的《古兰经》语料库，用于与其他语言资源进行互连。


<details>
  <summary>Details</summary>
Motivation: 创建一个形态学注释的《古兰经》语料库，以促进与多种语言资源的互连。

Method: 通过三个专家语言学家对每个词进行手动词形还原和词性标注，并利用Qabas阿拉伯词典数据库中的词形和SAMA/Qabas标签集进行标注。

Result: 成功创建了包含77,429个词的形态学注释语料库，该语料库是开源且公开可用的。

Conclusion: 该语料库可以与其他语言资源进行互连，具有重要的研究价值。

Abstract: We present the QuranMorph corpus, a morphologically annotated corpus for the
Quran (77,429 tokens). Each token in the QuranMorph was manually lemmatized and
tagged with its part-of-speech by three expert linguists. The lemmatization
process utilized lemmas from Qabas, an Arabic lexicographic database linked
with 110 lexicons and corpora of 2 million tokens. The part-of-speech tagging
was performed using the fine-grained SAMA/Qabas tagset, which encompasses 40
tags. As shown in this paper, this rich lemmatization and POS tagset enabled
the QuranMorph corpus to be inter-linked with many linguistic resources. The
corpus is open-source and publicly available as part of the SinaLab resources
at (https://sina.birzeit.edu/quran)

</details>


### [53] [CareLab at #SMM4H-HeaRD 2025: Insomnia Detection and Food Safety Event Extraction with Domain-Aware Transformers](https://arxiv.org/abs/2506.18185)
*Zihan Liang,Ziwen Pan,Sumon Kanti Dey,Azra Ismail*

Main category: cs.CL

TL;DR: 本文介绍了我们的系统在SMM4H-HeaRD 2025共享任务中的表现，特别是在任务5子任务1中取得了优异的成绩。


<details>
  <summary>Details</summary>
Motivation: 本文旨在展示我们的系统在检测临床笔记中的失眠提及和从新闻文章中提取食品安全事件方面的性能。

Method: 我们使用了基于编码器的模型（如RoBERTa）以及GPT-4进行数据增强。

Result: 我们的系统在任务5子任务1中获得了F1分数为0.958的优异成绩，并获得了第一名。

Conclusion: 本文介绍了我们的系统在SMM4H-HeaRD 2025共享任务中的表现，特别是在任务5子任务1中取得了优异的成绩。

Abstract: This paper presents our system for the SMM4H-HeaRD 2025 shared tasks,
specifically Task 4 (Subtasks 1, 2a, and 2b) and Task 5 (Subtasks 1 and 2).
Task 4 focused on detecting mentions of insomnia in clinical notes, while Task
5 addressed the extraction of food safety events from news articles. We
participated in all subtasks and report key findings across them, with
particular emphasis on Task 5 Subtask 1, where our system achieved strong
performance-securing first place with an F1 score of 0.958 on the test set. To
attain this result, we employed encoder-based models (e.g., RoBERTa), alongside
GPT-4 for data augmentation. This paper outlines our approach, including
preprocessing, model architecture, and subtask-specific adaptations

</details>


### [54] [Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review](https://arxiv.org/abs/2506.18199)
*Bushra Asseri,Estabrag Abdelaziz,Areej Al-Wabil*

Main category: cs.CL

TL;DR: 本文通过系统综述分析了8项研究，探讨了用于减轻大型语言模型中阿拉伯和穆斯林文化偏见的提示工程技术。研究发现，结构化多步骤流程最有效，但需要更高技术能力；文化提示则更具可及性。研究指出需要进一步开发文化适应性提示技术，并结合其他去偏方法。


<details>
  <summary>Details</summary>
Motivation: 尽管越来越多的人认识到大型语言模型中的偏见，但专门针对阿拉伯和穆斯林代表性的提示工程技术仍研究不足。本文旨在填补这一研究空白，提供基于证据的指导。

Method: 本研究采用混合方法系统综述，遵循PRISMA指南和Kitchenham的系统综述方法，分析了2021-2024年间发表的8项实证研究，探讨了针对阿拉伯和穆斯林代表性的提示工程技术。

Result: 研究发现五种主要的提示工程技术：文化提示、情感引导、自我去偏技术、结构化多步骤流程和参数优化的连续提示。这些方法在减少偏见方面显示出潜力，但效果因研究和偏见类型而异。结构化多步骤流程效果最佳，达到87.7%的偏见减少，但需要更高的技术专业知识。文化提示则具有更广泛的可及性。

Conclusion: 研究结果强调了提示工程在减轻文化偏见方面的可及性，而无需访问模型参数。然而，研究数量有限，表明需要进一步研究开发文化适应性提示技术、创建阿拉伯和穆斯林特定的评估资源，并将提示工程与互补的去偏方法结合，以解决更深层次的刻板印象，同时保持模型效用。

Abstract: Large language models have demonstrated remarkable capabilities across
various domains, yet concerns about cultural bias - particularly towards Arabs
and Muslims - pose significant ethical challenges by perpetuating harmful
stereotypes and marginalization. Despite growing recognition of bias in LLMs,
prompt engineering strategies specifically addressing Arab and Muslim
representation remain understudied. This mixed-methods systematic review
examines such techniques, offering evidence-based guidance for researchers and
practitioners. Following PRISMA guidelines and Kitchenham's systematic review
methodology, we analyzed 8 empirical studies published between 2021-2024
investigating bias mitigation strategies. Our findings reveal five primary
prompt engineering approaches: cultural prompting, affective priming,
self-debiasing techniques, structured multi-step pipelines, and
parameter-optimized continuous prompts. Although all approaches show potential
for reducing bias, effectiveness varied substantially across studies and bias
types. Evidence suggests that certain bias types may be more resistant to
prompt-based mitigation than others. Structured multi-step pipelines
demonstrated the highest overall effectiveness, achieving up to 87.7% reduction
in bias, though they require greater technical expertise. Cultural prompting
offers broader accessibility with substantial effectiveness. These results
underscore the accessibility of prompt engineering for mitigating cultural bias
without requiring access to model parameters. The limited number of studies
identified highlights a significant research gap in this critical area. Future
research should focus on developing culturally adaptive prompting techniques,
creating Arab and Muslim-specific evaluation resources, and integrating prompt
engineering with complementary debiasing methods to address deeper stereotypes
while maintaining model utility.

</details>


### [55] [Deciphering Emotions in Children Storybooks: A Comparative Analysis of Multimodal LLMs in Educational Applications](https://arxiv.org/abs/2506.18201)
*Bushra Asseri,Estabraq Abdelaziz,Maha Al Mogren,Tayef Alhefdhi,Areej Al-Wabil*

Main category: cs.CL

TL;DR: 本研究评估了GPT-4o和Gemini 1.5 Pro在处理阿拉伯儿童故事书插图时的情绪识别性能，发现GPT-4o表现优于Gemini，但两者在文化理解和情感识别方面仍有显著不足。


<details>
  <summary>Details</summary>
Motivation: 情感识别能力在多模态AI系统中对于开发文化响应型教育技术至关重要，但在阿拉伯语语境中仍缺乏探索，而文化上适当的学习工具在该地区尤为迫切需要。

Method: 本研究评估了GPT-4o和Gemini 1.5 Pro两种先进的多模态大型语言模型在处理阿拉伯儿童绘本插图时的情绪识别性能。通过三种提示策略（零样本、少样本和思维链）对75张来自七本阿拉伯故事书的图像进行评估，并根据Plutchik的情感框架将模型预测与人类注释进行比较。

Result: GPT-4o在所有条件下均优于Gemini，使用思维链提示策略时达到最高的宏观F1得分为59%，而Gemini的最佳表现仅为43%。错误分析显示了系统性的误分类模式，其中情感极性反转占错误的60.7%，同时两种模型在文化细微差别情感和模糊叙事情境中都表现出困难。

Conclusion: 研究结果突显了当前模型在文化理解方面的基本局限性，并强调了需要采用文化敏感的训练方法，以开发针对阿拉伯语学习者的有效情绪感知教育技术。

Abstract: Emotion recognition capabilities in multimodal AI systems are crucial for
developing culturally responsive educational technologies, yet remain
underexplored for Arabic language contexts where culturally appropriate
learning tools are critically needed. This study evaluates the emotion
recognition performance of two advanced multimodal large language models,
GPT-4o and Gemini 1.5 Pro, when processing Arabic children's storybook
illustrations. We assessed both models across three prompting strategies
(zero-shot, few-shot, and chain-of-thought) using 75 images from seven Arabic
storybooks, comparing model predictions with human annotations based on
Plutchik's emotional framework. GPT-4o consistently outperformed Gemini across
all conditions, achieving the highest macro F1-score of 59% with
chain-of-thought prompting compared to Gemini's best performance of 43%. Error
analysis revealed systematic misclassification patterns, with valence
inversions accounting for 60.7% of errors, while both models struggled with
culturally nuanced emotions and ambiguous narrative contexts. These findings
highlight fundamental limitations in current models' cultural understanding and
emphasize the need for culturally sensitive training approaches to develop
effective emotion-aware educational technologies for Arabic-speaking learners.

</details>


### [56] [Enhancing Entity Aware Machine Translation with Multi-task Learning](https://arxiv.org/abs/2506.18318)
*An Trieu,Phuong Nguyen,Minh Le Nguyen*

Main category: cs.CL

TL;DR: 本文提出了一种多任务学习方法，以优化实体识别和机器翻译的性能，从而提高实体感知机器翻译任务的效果。


<details>
  <summary>Details</summary>
Motivation: 实体感知机器翻译由于翻译数据不足和上下文处理复杂而具有挑战性。

Method: 应用多任务学习优化实体识别和机器翻译的两个子任务。

Result: 在SemEval 2025竞赛任务2提供的数据集上进行了结果和分析。

Conclusion: 通过多任务学习优化实体识别和机器翻译的性能，从而提高实体感知机器翻译任务的最终性能。

Abstract: Entity-aware machine translation (EAMT) is a complicated task in natural
language processing due to not only the shortage of translation data related to
the entities needed to translate but also the complexity in the context needed
to process while translating those entities. In this paper, we propose a method
that applies multi-task learning to optimize the performance of the two
subtasks named entity recognition and machine translation, which improves the
final performance of the Entity-aware machine translation task. The result and
analysis are performed on the dataset provided by the organizer of Task 2 of
the SemEval 2025 competition.

</details>


### [57] [TranslationCorrect: A Unified Framework for Machine Translation Post-Editing with Predictive Error Assistance](https://arxiv.org/abs/2506.18337)
*Syed Mekael Wasti,Shou-Yi Hung,Christopher Collins,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: TranslationCorrect是一个集成框架，旨在提高机器翻译后期编辑和研究数据收集的效率。


<details>
  <summary>Details</summary>
Motivation: 机器翻译（MT）后期编辑和研究数据收集通常依赖于低效且不连贯的工作流程。

Method: TranslationCorrect结合了MT生成、自动化错误预测和直观的后期编辑界面，使用NLLB等模型进行MT生成，使用XCOMET或LLM API进行自动化错误预测，并提供一个统一的环境。

Result: TranslationCorrect通过用户研究确认，显著提高了翻译效率和用户满意度。此外，它能够导出高质量的基于跨度的注释，适用于训练MT或后期编辑系统。

Conclusion: TranslationCorrect显著提高了翻译效率和用户满意度，相比传统的注释方法。

Abstract: Machine translation (MT) post-editing and research data collection often rely
on inefficient, disconnected workflows. We introduce TranslationCorrect, an
integrated framework designed to streamline these tasks. TranslationCorrect
combines MT generation using models like NLLB, automated error prediction using
models like XCOMET or LLM APIs (providing detailed reasoning), and an intuitive
post-editing interface within a single environment. Built with human-computer
interaction (HCI) principles in mind to minimize cognitive load, as confirmed
by a user study. For translators, it enables them to correct errors and batch
translate efficiently. For researchers, TranslationCorrect exports high-quality
span-based annotations in the Error Span Annotation (ESA) format, using an
error taxonomy inspired by Multidimensional Quality Metrics (MQM). These
outputs are compatible with state-of-the-art error detection models and
suitable for training MT or post-editing systems. Our user study confirms that
TranslationCorrect significantly improves translation efficiency and user
satisfaction over traditional annotation methods.

</details>


### [58] [Less Data Less Tokens: Multilingual Unification Learning for Efficient Test-Time Reasoning in LLMs](https://arxiv.org/abs/2506.18341)
*Kang Chen,Mengdi Zhang,Yixin Cao*

Main category: cs.CL

TL;DR: 本文提出了一种新的多语言统一学习方法(L^2)，通过利用不同语言之间的相互作用来提高大型语言模型的推理能力和效率。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在测试时扩展的挑战，包括数据和推理效率。

Method: 引入了一种新颖的方法，即带有解码干预策略的L^2多语言统一学习，以进一步研究多语言推理的多样性。

Result: 即使少量的数据也可以显著提高推理能力，并且多语言学习可以减少所需的数据显示和推理标记数量，同时保持相当的性能。

Conclusion: L^2方法为解决大型语言模型在数据收集和测试时计算效率方面的挑战提供了一个有前景的解决方案。

Abstract: This paper explores the challenges of test-time scaling of large language
models (LLMs), regarding both the data and inference efficiency. We highlight
the diversity of multi-lingual reasoning based on our pilot studies, and then
introduce a novel approach, \(L^2\) multi-lingual unification learning with a
decoding intervention strategy for further investigation. The basic idea of
\(L^2\) is that the reasoning process varies across different languages, which
may be mutually beneficial to enhance both model performance and efficiency. In
specific, there are two types of multi-lingual data: the entire long
chain-of-thought annotations in different languages and the step-wise mixture
of languages. By further tuning based on them, we show that even small amounts
of data can significantly improve reasoning capabilities. Our findings suggest
that multilingual learning reduces both the required data and the number of
inference tokens while maintaining a comparable performance. Furthermore,
\(L^2\) is orthogonal to other data efficient methods. Thus, we also emphasize
the importance of diverse data selection. The \(L^2\) method offers a promising
solution to the challenges of data collection and test-time compute efficiency
in LLMs.

</details>


### [59] [Evaluating Causal Explanation in Medical Reports with LLM-Based and Human-Aligned Metrics](https://arxiv.org/abs/2506.18387)
*Yousang Cho,Key-Sun Choi*

Main category: cs.CL

TL;DR: 本研究比较了六种评估度量标准在自动诊断报告中的表现，发现GPT-Black和GPT-White在评估因果解释质量方面效果较好，而基于相似性的度量则不如预期。


<details>
  <summary>Details</summary>
Motivation: 本研究调查不同评估度量在自动生成的诊断报告中捕捉因果解释质量的准确性。

Method: 我们比较了六种度量标准：BERTScore、余弦相似性、BioSentVec、GPT-White、GPT-Black和专家定性评估，针对两种输入类型：基于观察的和基于选择题的报告生成。应用了两种加权策略：一种反映任务特定优先级，另一种为所有度量分配相等权重。

Result: GPT-Black在识别逻辑连贯和临床有效的因果叙述方面表现出最强的区分能力。GPT-White也与专家评估相符，而基于相似性的度量则偏离了临床推理质量。

Conclusion: 这些发现强调了度量选择和加权对评估结果的影响，支持在需要可解释性和因果推理的任务中使用基于LLM的评估。

Abstract: This study investigates how accurately different evaluation metrics capture
the quality of causal explanations in automatically generated diagnostic
reports. We compare six metrics: BERTScore, Cosine Similarity, BioSentVec,
GPT-White, GPT-Black, and expert qualitative assessment across two input types:
observation-based and multiple-choice-based report generation. Two weighting
strategies are applied: one reflecting task-specific priorities, and the other
assigning equal weights to all metrics. Our results show that GPT-Black
demonstrates the strongest discriminative power in identifying logically
coherent and clinically valid causal narratives. GPT-White also aligns well
with expert evaluations, while similarity-based metrics diverge from clinical
reasoning quality. These findings emphasize the impact of metric selection and
weighting on evaluation outcomes, supporting the use of LLM-based evaluation
for tasks requiring interpretability and causal reasoning.

</details>


### [60] [Lemmatization as a Classification Task: Results from Arabic across Multiple Genres](https://arxiv.org/abs/2506.18399)
*Mostafa Saeed,Nizar Habash*

Main category: cs.CL

TL;DR: 本文提出了两种新的词形还原方法，并引入了一个新的阿拉伯语测试集，结果显示分类和聚类方法优于序列到序列模型。


<details>
  <summary>Details</summary>
Motivation: 现有的工具面临标准不一致和有限的文体覆盖范围的问题，因此需要改进词形还原方法。

Method: 本文介绍了两种新的方法，将词形还原作为对Lemma-POS-Gloss (LPG)标签集的分类，利用机器翻译和语义聚类。

Result: 分类和聚类方法产生了更稳健、可解释的输出，而字符级序列到序列模型在词形预测方面表现良好但容易产生不合理的形式。

Conclusion: 我们的结果表明，分类和聚类方法产生了更稳健、可解释的输出，为阿拉伯语词形还原设定了新基准。

Abstract: Lemmatization is crucial for NLP tasks in morphologically rich languages with
ambiguous orthography like Arabic, but existing tools face challenges due to
inconsistent standards and limited genre coverage. This paper introduces two
novel approaches that frame lemmatization as classification into a
Lemma-POS-Gloss (LPG) tagset, leveraging machine translation and semantic
clustering. We also present a new Arabic lemmatization test set covering
diverse genres, standardized alongside existing datasets. We evaluate character
level sequence-to-sequence models, which perform competitively and offer
complementary value, but are limited to lemma prediction (not LPG) and prone to
hallucinating implausible forms. Our results show that classification and
clustering yield more robust, interpretable outputs, setting new benchmarks for
Arabic lemmatization.

</details>


### [61] [TReB: A Comprehensive Benchmark for Evaluating Table Reasoning Capabilities of Large Language Models](https://arxiv.org/abs/2506.18421)
*Ce Li,Xiaofan Liu,Zhiyan Song,Ce Chi,Chen Zhao,Jingjing Yang,Zhendong Wang,Kexin Yang,Boshen Shi,Xing Wang,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: 本文提出了一个全面的表格推理基准TReB，包含26个子任务，并构建了一个高质量的数据集和评估框架，以衡量大型语言模型的表格推理能力。


<details>
  <summary>Details</summary>
Motivation: 缺乏一个有效的评估基准来公平反映大型语言模型在广泛表格推理能力上的表现。

Method: 提出了一种全面的表格推理进化基准TReB，通过迭代的数据处理过程构建高质量数据集，并创建了三种不同的推理模式（TCoT、PoT和ICoT）的评估框架。

Result: 实验结果表明，现有大型语言模型在处理复杂的表格相关任务方面仍有显著的改进空间。

Conclusion: 现有的大型语言模型在处理复杂和现实世界的表格相关任务方面仍有显著的改进空间。数据集和评估框架已公开可用。

Abstract: The majority of data in businesses and industries is stored in tables,
databases, and data warehouses. Reasoning with table-structured data poses
significant challenges for large language models (LLMs) due to its hidden
semantics, inherent complexity, and structured nature. One of these challenges
is lacking an effective evaluation benchmark fairly reflecting the performances
of LLMs on broad table reasoning abilities. In this paper, we fill in this gap,
presenting a comprehensive table reasoning evolution benchmark, TReB, which
measures both shallow table understanding abilities and deep table reasoning
abilities, a total of 26 sub-tasks. We construct a high quality dataset through
an iterative data processing procedure. We create an evaluation framework to
robustly measure table reasoning capabilities with three distinct inference
modes, TCoT, PoT and ICoT. Further, we benchmark over 20 state-of-the-art LLMs
using this frame work and prove its effectiveness. Experimental results reveal
that existing LLMs still have significant room for improvement in addressing
the complex and real world Table related tasks. Both the dataset and evaluation
framework are publicly available, with the dataset hosted on [HuggingFace] and
the framework on [GitHub].

</details>


### [62] [MeRF: Motivation-enhanced Reinforcement Finetuning for Large Reasoning Models](https://arxiv.org/abs/2506.18485)
*Junjie Zhang,Guozheng Ma,Shunyu Liu,Haoyu Wang,Jiaxing Huang,Ting-En Lin,Fei Huang,Yongbin Li,Dacheng Tao*

Main category: cs.CL

TL;DR: 本文提出了MeRF方法，通过将奖励规范注入提示中，结合强化学习和上下文学习，提升LLMs的推理能力。实验结果显示MeRF在逻辑谜题任务中表现优异，并能适应误导性动机。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法忽视了LLMs的一个显著能力，即上下文学习能力，这由Chain-of-Thought（CoT）提示的成功所证明。因此，我们探索如何将强化学习有效地与上下文学习结合，以更好地提升LLMs的推理能力。

Method: MeRF是一种增强强化学习的方法，通过向提示中注入奖励规范，作为模型改进响应的上下文动机。这种方法利用了LLMs的上下文学习能力，使生成与优化对齐，从而激励模型从内在动机和外部奖励两方面生成期望的输出。

Result: 在Knights and Knaves逻辑谜题推理基准上的实证评估表明，MeRF在性能上取得了显著提升。此外，消融研究显示，上下文动机与外部奖励函数之间的一致性越高，性能提升越明显，而模型还展示了通过强化学习适应误导性动机的能力。

Conclusion: MeRF通过将奖励规范注入提示中，有效结合了强化学习和上下文学习，从而提升了LLMs的推理能力。实验结果表明，MeRF在Knights and Knaves逻辑谜题推理基准上表现优于基线方法，并且模型能够适应误导性动机。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful learn-to-reason paradigm for Large Language Models (LLMs) to tackle
complex reasoning tasks. However, existing RLVR methods overlook one of the
most distinctive capabilities of LLMs, their in-context learning ability, as
prominently demonstrated by the success of Chain-of-Thought (CoT) prompting.
This motivates us to explore how reinforcement learning can be effectively
combined with in-context learning to better improve the reasoning capabilities
of LLMs. In this paper, we introduce Motivation-enhanced Reinforcement
Finetuning} (MeRF), an intuitive yet effective method enhancing reinforcement
learning of LLMs by involving ``telling LLMs the rules of the game''.
Specifically, MeRF directly injects the reward specification into the prompt,
which serves as an in-context motivation for model to improve its responses
with awareness of the optimization objective. This simple modification
leverages the in-context learning ability of LLMs aligning generation with
optimization, thereby incentivizing the model to generate desired outputs from
both inner motivation and external reward. Empirical evaluations on the Knights
and Knaves~(K&K) logic puzzle reasoning benchmark demonstrate that
\texttt{MeRF} achieves substantial performance gains over baselines. Moreover,
ablation studies show that performance improves with greater consistency
between the in-context motivation and the external reward function, while the
model also demonstrates an ability to adapt to misleading motivations through
reinforcement learning.

</details>


### [63] [Comparative Evaluation of ChatGPT and DeepSeek Across Key NLP Tasks: Strengths, Weaknesses, and Domain-Specific Performance](https://arxiv.org/abs/2506.18501)
*Wael Etaiwi,Bushra Alhijawi*

Main category: cs.CL

TL;DR: 本研究评估了ChatGPT和DeepSeek在五个关键NLP任务中的表现，发现DeepSeek在分类稳定性和逻辑推理方面更优，而ChatGPT在需要细微理解与灵活性的任务中表现更好。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在自然语言处理（NLP）任务中的广泛应用，需要全面评估其在不同应用中的有效性，以了解其优势、劣势和特定领域的能力。

Method: 本研究通过结构化的实验协议对ChatGPT和DeepSeek进行了评估，确保公平性并减少变异性。两个模型使用相同的中性提示进行测试，并在每个任务的两个基准数据集上进行评估，涵盖新闻、评论和正式/非正式文本等领域。

Result: 结果表明，DeepSeek在分类稳定性和逻辑推理方面表现出色，而ChatGPT在需要细微理解与灵活性的任务中表现更好。

Conclusion: 这些发现为根据任务需求选择适当的LLM提供了有价值的见解。

Abstract: The increasing use of large language models (LLMs) in natural language
processing (NLP) tasks has sparked significant interest in evaluating their
effectiveness across diverse applications. While models like ChatGPT and
DeepSeek have shown strong results in many NLP domains, a comprehensive
evaluation is needed to understand their strengths, weaknesses, and
domain-specific abilities. This is critical as these models are applied to
various tasks, from sentiment analysis to more nuanced tasks like textual
entailment and translation. This study aims to evaluate ChatGPT and DeepSeek
across five key NLP tasks: sentiment analysis, topic classification, text
summarization, machine translation, and textual entailment. A structured
experimental protocol is used to ensure fairness and minimize variability. Both
models are tested with identical, neutral prompts and evaluated on two
benchmark datasets per task, covering domains like news, reviews, and
formal/informal texts. The results show that DeepSeek excels in classification
stability and logical reasoning, while ChatGPT performs better in tasks
requiring nuanced understanding and flexibility. These findings provide
valuable insights for selecting the appropriate LLM based on task requirements.

</details>


### [64] [End-to-End Spoken Grammatical Error Correction](https://arxiv.org/abs/2506.18532)
*Mengjie Qian,Rao Ma,Stefano Bannò,Mark J. F. Gales,Kate M. Knill*

Main category: cs.CL

TL;DR: 本文研究了用于语音语法纠错的端到端框架，提出了一系列方法以提升性能，包括自动伪标记、上下文信息利用、参考对齐和编辑置信度估计。


<details>
  <summary>Details</summary>
Motivation: 语音语法纠错（SGEC）在支持第二语言学习者、教育工作者和考官方面起着重要作用，但由于口误、转录错误和缺乏结构化输入，其面临额外挑战。现有的级联系统容易出现错误传播，因此需要更有效的解决方案。

Method: 本文探讨了端到端（E2E）框架用于SGEC和反馈生成，并比较了级联、部分级联和E2E架构。还提出了自动伪标记框架、利用ASR输出的上下文信息、参考对齐过程以及编辑置信度估计方法。

Result: 实验表明，所提出的方法显著提升了E2E SGEC的性能，特别是在Linguaskill（LNG）语料库和Speak & Improve（S&I）语料库上的表现。

Conclusion: 本文提出的各种方法显著提升了端到端语音语法纠错（E2E SGEC）的性能。

Abstract: Grammatical Error Correction (GEC) and feedback play a vital role in
supporting second language (L2) learners, educators, and examiners. While
written GEC is well-established, spoken GEC (SGEC), aiming to provide feedback
based on learners' speech, poses additional challenges due to disfluencies,
transcription errors, and the lack of structured input. SGEC systems typically
follow a cascaded pipeline consisting of Automatic Speech Recognition (ASR),
disfluency detection, and GEC, making them vulnerable to error propagation
across modules. This work examines an End-to-End (E2E) framework for SGEC and
feedback generation, highlighting challenges and possible solutions when
developing these systems. Cascaded, partial-cascaded and E2E architectures are
compared, all built on the Whisper foundation model. A challenge for E2E
systems is the scarcity of GEC labeled spoken data. To address this, an
automatic pseudo-labeling framework is examined, increasing the training data
from 77 to over 2500 hours. To improve the accuracy of the SGEC system,
additional contextual information, exploiting the ASR output, is investigated.
Candidate feedback of their mistakes is an essential step to improving
performance. In E2E systems the SGEC output must be compared with an estimate
of the fluent transcription to obtain the feedback. To improve the precision of
this feedback, a novel reference alignment process is proposed that aims to
remove hypothesised edits that results from fluent transcription errors.
Finally, these approaches are combined with an edit confidence estimation
approach, to exclude low-confidence edits. Experiments on the in-house
Linguaskill (LNG) corpora and the publicly available Speak & Improve (S&I)
corpus show that the proposed approaches significantly boost E2E SGEC
performance.

</details>


### [65] [When Fine-Tuning Fails: Lessons from MS MARCO Passage Ranking](https://arxiv.org/abs/2506.18535)
*Manu Pande,Shahil Kumar,Anay Yatin Damle*

Main category: cs.CL

TL;DR: 本研究发现微调预训练变压器模型会降低MS MARCO段落排名任务的性能，并揭示了微调破坏了在大量句子对预训练中学习到的最优嵌入空间结构。


<details>
  <summary>Details</summary>
Motivation: 研究微调预训练变压器模型在MS MARCO段落排名任务中的性能下降现象。

Method: 通过涉及五种模型变体的全面实验，包括全参数微调和参数高效的LoRA适应，分析了微调对预训练变压器模型的影响。

Result: 所有微调方法的表现均低于基础句子转换器/all-MiniLM-L6-v2模型（MRR@10: 0.3026）。

Conclusion: 研究结果挑战了关于在饱和基准上迁移学习有效性的传统观点，并表明可能需要架构创新以实现有意义的改进。

Abstract: This paper investigates the counterintuitive phenomenon where fine-tuning
pre-trained transformer models degrades performance on the MS MARCO passage
ranking task. Through comprehensive experiments involving five model
variants-including full parameter fine-tuning and parameter efficient LoRA
adaptations-we demonstrate that all fine-tuning approaches underperform the
base sentence-transformers/all- MiniLM-L6-v2 model (MRR@10: 0.3026). Our
analysis reveals that fine-tuning disrupts the optimal embedding space
structure learned during the base model's extensive pre-training on 1 billion
sentence pairs, including 9.1 million MS MARCO samples. UMAP visualizations
show progressive embedding space flattening, while training dynamics analysis
and computational efficiency metrics further support our findings. These
results challenge conventional wisdom about transfer learning effectiveness on
saturated benchmarks and suggest architectural innovations may be necessary for
meaningful improvements.

</details>


### [66] [A Modular Taxonomy for Hate Speech Definitions and Its Impact on Zero-Shot LLM Classification Performance](https://arxiv.org/abs/2506.18576)
*Matteo Melis,Gabriella Lapesa,Dennis Assenmacher*

Main category: cs.CL

TL;DR: 本文通过构建仇恨言论定义的分类法，并在多个数据集上评估了不同定义对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 明确仇恨言论的定义并研究不同定义对模型性能的影响。

Method: 通过收集和分析现有定义，构建了一个包含14个概念要素的分类法，并在三个仇恨言论数据集上进行了零样本评估。

Result: 不同的定义会影响模型性能，但这种影响在所有架构中并不一致。

Conclusion: 选择不同的仇恨言论定义会影响模型性能，但这种影响在所有架构中并不一致。

Abstract: Detecting harmful content is a crucial task in the landscape of NLP
applications for Social Good, with hate speech being one of its most dangerous
forms. But what do we mean by hate speech, how can we define it, and how does
prompting different definitions of hate speech affect model performance? The
contribution of this work is twofold. At the theoretical level, we address the
ambiguity surrounding hate speech by collecting and analyzing existing
definitions from the literature. We organize these definitions into a taxonomy
of 14 Conceptual Elements-building blocks that capture different aspects of
hate speech definitions, such as references to the target of hate (individual
or groups) or of the potential consequences of it. At the experimental level,
we employ the collection of definitions in a systematic zero-shot evaluation of
three LLMs, on three hate speech datasets representing different types of data
(synthetic, human-in-the-loop, and real-world). We find that choosing different
definitions, i.e., definitions with a different degree of specificity in terms
of encoded elements, impacts model performance, but this effect is not
consistent across all architectures.

</details>


### [67] [Parallel Continuous Chain-of-Thought with Jacobi Iteration](https://arxiv.org/abs/2506.18582)
*Haoyi Wu,Zhihao Teng,Kewei Tu*

Main category: cs.CL

TL;DR: This paper proposes PCCoT, a method that improves the training and inference efficiency of continuous chain-of-thought by updating latent thought tokens in parallel using Jacobi iteration.


<details>
  <summary>Details</summary>
Motivation: Continuous chain-of-thought has been shown to be effective in saving reasoning tokens for large language models, but the sequential dependencies between latent thought tokens spoil parallel training, leading to long training time.

Method: We propose Parallel Continuous Chain-of-Thought (PCCoT), which performs Jacobi iteration on the latent thought tokens, updating them iteratively in parallel instead of sequentially.

Result: Experiments demonstrate that by choosing the proper number of iterations, we are able to achieve comparable or even better performance while saving nearly 50% of the training and inference time.

Conclusion: PCCoT shows better stability and robustness in the training process, and achieves comparable or even better performance while saving nearly 50% of the training and inference time.

Abstract: Continuous chain-of-thought has been shown to be effective in saving
reasoning tokens for large language models. By reasoning with continuous latent
thought tokens, continuous CoT is able to perform implicit reasoning in a
compact manner. However, the sequential dependencies between latent thought
tokens spoil parallel training, leading to long training time. In this paper,
we propose Parallel Continuous Chain-of-Thought (PCCoT), which performs Jacobi
iteration on the latent thought tokens, updating them iteratively in parallel
instead of sequentially and thus improving both training and inference
efficiency of continuous CoT. Experiments demonstrate that by choosing the
proper number of iterations, we are able to achieve comparable or even better
performance while saving nearly 50% of the training and inference time.
Moreover, PCCoT shows better stability and robustness in the training process.
Our code is available at https://github.com/whyNLP/PCCoT.

</details>


### [68] [Reply to "Emergent LLM behaviors are observationally equivalent to data leakage"](https://arxiv.org/abs/2506.18600)
*Ariel Flint Ashery,Luca Maria Aiello,Andrea Baronchelli*

Main category: cs.CL

TL;DR: 尽管数据污染可能影响大型语言模型（LLMs）种群模拟的实验结果，但自组织和模型依赖的涌现动力学仍然可以被研究，并且在社会惯例的案例中已经得到了实证支持。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）种群中的数据污染问题及其对实验结果的影响，同时探讨自组织和模型依赖的涌现动力学是否可以被研究。

Method: 分析Barrie和T"ornberg对Flint Ashery等人研究的批评，并探讨LLM种群中涌现动力学的实证观察。

Result: 数据污染虽然重要，但不会阻止对LLM种群中真正涌现动力学的研究，特别是在社会惯例的特定情况下已经观察到了这种动力学。

Conclusion: 数据污染可能会影响大型语言模型（LLMs）种群模拟的实验结果，但并不妨碍研究真正的自组织和模型依赖的涌现动力学。

Abstract: A potential concern when simulating populations of large language models
(LLMs) is data contamination, i.e. the possibility that training data may shape
outcomes in unintended ways. While this concern is important and may hinder
certain experiments with multi-agent models, it does not preclude the study of
genuinely emergent dynamics in LLM populations. The recent critique by Barrie
and T\"ornberg [1] of the results of Flint Ashery et al. [2] offers an
opportunity to clarify that self-organisation and model-dependent emergent
dynamics can be studied in LLM populations, highlighting how such dynamics have
been empirically observed in the specific case of social conventions.

</details>


### [69] [Semantic similarity estimation for domain specific data using BERT and other techniques](https://arxiv.org/abs/2506.18602)
*R. Prashanth*

Main category: cs.CL

TL;DR: 该研究比较了不同的语义相似性估计技术，发现BERT在领域特定数据上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 语义相似性估计在自然语言处理和自然语言理解中是一个重要的研究问题，并且在各种下游任务中有广泛的应用。

Method: 使用不同的最先进技术（包括USE、InferSent和BERT）进行语义相似性估计，并使用两个问题对数据集进行分析，一个是领域特定的内部数据集，另一个是公共数据集Quora的问题对数据集。

Result: BERT模型相比其他方法表现出了优越的性能，这可能是因为其训练过程中涉及微调过程，使其能够基于使用的训练数据学习模式。

Conclusion: 该工作展示了BERT在领域特定数据上的适用性，并推断BERT是处理领域特定数据的最佳技术。

Abstract: Estimation of semantic similarity is an important research problem both in
natural language processing and the natural language understanding, and that
has tremendous application on various downstream tasks such as question
answering, semantic search, information retrieval, document clustering,
word-sense disambiguation and machine translation. In this work, we carry out
the estimation of semantic similarity using different state-of-the-art
techniques including the USE (Universal Sentence Encoder), InferSent and the
most recent BERT, or Bidirectional Encoder Representations from Transformers,
models. We use two question pairs datasets for the analysis, one is a domain
specific in-house dataset and the other is a public dataset which is the
Quora's question pairs dataset. We observe that the BERT model gave much
superior performance as compared to the other methods. This should be because
of the fine-tuning procedure that is involved in its training process, allowing
it to learn patterns based on the training data that is used. This works
demonstrates the applicability of BERT on domain specific datasets. We infer
from the analysis that BERT is the best technique to use in the case of domain
specific data.

</details>


### [70] [The Anatomy of Speech Persuasion: Linguistic Shifts in LLM-Modified Speeches](https://arxiv.org/abs/2506.18621)
*Alisa Barkar,Mathieu Chollet,Matthieu Labeau,Beatrice Biancardi,Chloe Clavel*

Main category: cs.CL

TL;DR: 该研究分析了GPT-4o如何通过修改情感词汇和句法结构来增强公共演讲的说服力。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探讨大型语言模型如何理解公共演讲中的说服力概念。

Method: 该研究通过修改PhD候选人的演讲稿，并使用3MT法国数据集，提出了一种新方法和可解释的文本特征集，包括修辞手法和话语标记。然后，他们提示GPT-4o增强或减弱说服力，并分析原始演讲和生成演讲之间的语言变化。

Result: 结果表明，GPT-4o通过情感词汇和句法结构（如疑问句和感叹句）来增强修辞效果，而不是以人类的方式优化说服力。

Conclusion: 研究发现，GPT-4o通过系统性的风格修改来增强说服力，而不是以人类的方式优化说服力。

Abstract: This study examines how large language models understand the concept of
persuasiveness in public speaking by modifying speech transcripts from PhD
candidates in the "Ma These en 180 Secondes" competition, using the 3MT French
dataset. Our contributions include a novel methodology and an interpretable
textual feature set integrating rhetorical devices and discourse markers. We
prompt GPT-4o to enhance or diminish persuasiveness and analyze linguistic
shifts between original and generated speech in terms of the new features.
Results indicate that GPT-4o applies systematic stylistic modifications rather
than optimizing persuasiveness in a human-like manner. Notably, it manipulates
emotional lexicon and syntactic structures (such as interrogative and
exclamatory clauses) to amplify rhetorical impact.

</details>


### [71] [ByteSpan: Information-Driven Subword Tokenisation](https://arxiv.org/abs/2506.18639)
*Zébulon Goriely,Suchir Salhan,Pietro Lesci,Julius Cheng,Paula Buttery*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent dynamic tokenisation methods operate directly on bytes and pool their
latent representations into patches. This bears similarities to computational
models of word segmentation that determine lexical boundaries using spikes in
an autoregressive model's prediction error. Inspired by this connection, we
explore whether grouping predictable bytes - rather than pooling their
representations - can yield a useful fixed subword vocabulary. We propose a new
information-driven subword tokeniser, ByteSpan, that uses an external
byte-level LM during training to identify contiguous predictable byte sequences
and group them into subwords. Experiments show that ByteSpan yields efficient
vocabularies with higher morphological alignment scores than BPE for English.
Multilingual experiments show similar compression and R\'enyi efficiency for 25
languages.

</details>


### [72] [Is There a Case for Conversation Optimized Tokenizers in Large Language Models?](https://arxiv.org/abs/2506.18674)
*Raquel Ferrando,Javier Conde,Gonzalo Martínez,Pedro Reviriego*

Main category: cs.CL

TL;DR: 本文探讨了优化聊天机器人对话的分词器的潜力，结果表明对话优化的分词器可以减少标记数量，从而带来显著的能源节约。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的计算和能耗成本随着模型规模的扩大和用户的广泛采用而呈指数级增长。分词器在模型效率中起着重要作用，但它们的优化主要针对训练语料库中的文本，而聊天机器人对话中的文本可能不同。因此，研究是否可以通过优化分词器来提高聊天机器人对话的效率是有意义的。

Method: 使用公开的聊天机器人对话语料库重新设计分词器的词汇表，并在该领域评估其性能。

Result: 对话优化的分词器在聊天机器人对话中 consistently 减少了标记数量，从而带来了 5% 到 10% 的能源节约，同时对原始训练语料库的分词效率影响很小或甚至有轻微的正面影响。

Conclusion: 对话优化的分词器可以减少聊天机器人的对话中的标记数量，从而带来显著的能源节约，同时对原始训练语料库的分词效率影响很小甚至有轻微的正面影响。

Abstract: The computational and energy costs of Large Language Models (LLMs) have
increased exponentially driven by the growing model sizes and the massive
adoption of LLMs by hundreds of millions of users. The unit cost of an LLM is
the computation of a token. Therefore, the tokenizer plays an important role in
the efficiency of a model, and they are carefully optimized to minimize the
number of tokens for the text in their training corpus. One of the most popular
applications of LLMs are chatbots that interact with users. A key observation
is that, for those chatbots, what is important is the performance of the
tokenizer in the user text input and the chatbot responses. Those are most
likely different from the text in the training corpus. So, a question that
immediately arises is whether there is a potential benefit in optimizing
tokenizers for chatbot conversations. In this paper, this idea is explored for
different tokenizers by using a publicly available corpus of chatbot
conversations to redesign their vocabularies and evaluate their performance in
this domain. The results show that conversation-optimized tokenizers
consistently reduce the number of tokens in chatbot dialogues, which can lead
to meaningful energy savings, in the range of 5% to 10% while having minimal or
even slightly positive impact on tokenization efficiency for the original
training corpus.

</details>


### [73] [Context Biasing for Pronunciations-Orthography Mismatch in Automatic Speech Recognition](https://arxiv.org/abs/2506.18703)
*Christian Huber,Alexander Waibel*

Main category: cs.CL

TL;DR: 本文提出了一种在推理过程中实时添加更正的方法，以提高发音-拼写不匹配单词的识别准确性，并在有偏词错误率上取得了高达11%的相对改进。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文偏向方法对于发音-拼写不匹配的单词可能仍然存在困难。

Method: 我们提出了一种方法，允许在推理过程中实时添加更正，以提高此类挑战性单词的识别准确性。

Result: 通过这种方法，我们在有偏词错误率上取得了高达11%的相对改进，同时保持了具有竞争力的整体词错误率。

Conclusion: 我们的方法在有偏词错误率上取得了高达11%的相对改进，同时保持了具有竞争力的整体词错误率。

Abstract: Neural sequence-to-sequence systems deliver state-of-the-art performance for
automatic speech recognition. When using appropriate modeling units, e.g.,
byte-pair encoded characters, these systems are in principal open vocabulary
systems. In practice, however, they often fail to recognize words not seen
during training, e.g., named entities, acronyms, or domain-specific special
words. To address this problem, many context biasing methods have been
proposed; however, for words with a pronunciation-orthography mismatch, these
methods may still struggle. We propose a method which allows corrections of
substitution errors to improve the recognition accuracy of such challenging
words. Users can add corrections on the fly during inference. We show that with
this method we get a relative improvement in biased word error rate of up to
11\%, while maintaining a competitive overall word error rate.

</details>


### [74] [Benchmarking the Pedagogical Knowledge of Large Language Models](https://arxiv.org/abs/2506.18710)
*Maxime Lelièvre,Amy Waldock,Meng Liu,Natalia Valdés Aspillaga,Alasdair Mackintosh,María José Ogando Portelo,Jared Lee,Paul Atherton,Robin A. A. Ince,Oliver G. B. Garrod*

Main category: cs.CL

TL;DR: 本文介绍了The Pedagogy Benchmark，这是一个新的数据集，用于评估大型语言模型在教学法方面的知识。结果表明，不同模型在教学法知识问题上的准确率差异较大，且成本与准确性之间存在关系。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试主要关注内容知识，而忽略了评估模型对教学法的理解。因此，本文旨在填补这一空白，通过引入一个新的基准测试来评估大型语言模型在教学法方面的知识。

Method: 本文介绍了The Pedagogy Benchmark，这是一个新的数据集，旨在评估大型语言模型在跨领域教学知识（CDPK）和特殊教育需求与残疾（SEND）教学知识方面的表现。这些基准是基于从教师专业发展考试中精心挑选的问题构建的，涵盖了教学策略和评估方法等教学子领域。

Result: 本文报告了97个模型的结果，这些模型在教学法知识问题上的准确率范围从28%到89%。此外，还考虑了成本与准确性之间的关系，并绘制了帕累托值前沿随时间的变化。

Conclusion: 教育导向的基准测试对于衡量模型理解教学概念、适当回应学习者需求以及支持不同情境下的有效教学实践至关重要。它们对于指导LLM和基于LLM的工具在教育环境中的负责任和基于证据的部署，以及指导开发和政策决策都是必要的。

Abstract: Benchmarks like Massive Multitask Language Understanding (MMLU) have played a
pivotal role in evaluating AI's knowledge and abilities across diverse domains.
However, existing benchmarks predominantly focus on content knowledge, leaving
a critical gap in assessing models' understanding of pedagogy - the method and
practice of teaching. This paper introduces The Pedagogy Benchmark, a novel
dataset designed to evaluate large language models on their Cross-Domain
Pedagogical Knowledge (CDPK) and Special Education Needs and Disability (SEND)
pedagogical knowledge. These benchmarks are built on a carefully curated set of
questions sourced from professional development exams for teachers, which cover
a range of pedagogical subdomains such as teaching strategies and assessment
methods. Here we outline the methodology and development of these benchmarks.
We report results for 97 models, with accuracies spanning a range from 28% to
89% on the pedagogical knowledge questions. We consider the relationship
between cost and accuracy and chart the progression of the Pareto value
frontier over time. We provide online leaderboards at
https://rebrand.ly/pedagogy which are updated with new models and allow
interactive exploration and filtering based on various model properties, such
as cost per token and open-vs-closed weights, as well as looking at performance
in different subjects. LLMs and generative AI have tremendous potential to
influence education and help to address the global learning crisis.
Education-focused benchmarks are crucial to measure models' capacities to
understand pedagogical concepts, respond appropriately to learners' needs, and
support effective teaching practices across diverse contexts. They are needed
for informing the responsible and evidence-based deployment of LLMs and
LLM-based tools in educational settings, and for guiding both development and
policy decisions.

</details>


### [75] [Semantic-Preserving Adversarial Attacks on LLMs: An Adaptive Greedy Binary Search Approach](https://arxiv.org/abs/2506.18756)
*Chong Zhang,Xiang Li,Jia Wang,Shan Liang,Haochen Xue,Xiaobo Jin*

Main category: cs.CL

TL;DR: 本文提出了一种名为自适应贪心二分搜索（AGBS）的方法，用于解决大型语言模型中由于用户需求多样性而导致的意外误解问题。通过实验验证，AGBS在保持语义稳定性的同时，有效提高了攻击效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）越来越多地依赖图形用户界面（GUI）中的自动提示工程来细化用户输入并提高响应准确性。然而，用户需求的多样性常常导致意外的误解，其中自动化优化会扭曲原始意图并产生错误的输出。

Method: 我们提出了自适应贪心二分搜索（AGBS）方法，该方法模拟常见的提示优化机制，同时保持语义稳定性。

Result: 通过在开源和闭源LLMs上的广泛实验，我们展示了AGBS在平衡语义一致性和攻击效果方面的有效性。

Conclusion: 我们的研究结果为设计更可靠的提示优化系统提供了可行的见解。

Abstract: Large Language Models (LLMs) increasingly rely on automatic prompt
engineering in graphical user interfaces (GUIs) to refine user inputs and
enhance response accuracy. However, the diversity of user requirements often
leads to unintended misinterpretations, where automated optimizations distort
original intentions and produce erroneous outputs. To address this challenge,
we propose the Adaptive Greedy Binary Search (AGBS) method, which simulates
common prompt optimization mechanisms while preserving semantic stability. Our
approach dynamically evaluates the impact of such strategies on LLM
performance, enabling robust adversarial sample generation. Through extensive
experiments on open and closed-source LLMs, we demonstrate AGBS's effectiveness
in balancing semantic consistency and attack efficacy. Our findings offer
actionable insights for designing more reliable prompt optimization systems.
Code is available at: https://github.com/franz-chang/DOBS

</details>


### [76] [ASP2LJ : An Adversarial Self-Play Laywer Augmented Legal Judgment Framework](https://arxiv.org/abs/2506.18768)
*Ao Chang,Tong Zhou,Yubo Chen,Delai Qiu,Shengping Liu,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种对抗自博弈律师增强法律判决框架（ASP2LJ），用于解决法律判决预测中的长尾分布和律师改进问题。我们还引入了一个中国罕见法律案例数据集RareCases，并在SimuCourt数据集和RareCases数据集上验证了框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 法律判决预测（LJP）旨在预测司法结果，包括相关法律指控、条款和罚款，这是大型语言模型（LLM）中的关键过程。然而，LJP面临两个关键挑战：长尾分布和律师改进。现有的系统专注于提高法官的决策能力，但忽视了律师在完善论点中的关键作用，这限制了整体司法准确性。

Method: 我们提出了一个对抗自博弈律师增强法律判决框架（ASP2LJ），该框架集成了一个案例生成模块来解决长尾数据分布问题，并采用对抗自博弈机制来提高律师的论点技能。

Result: 我们的框架使法官能够参考进化后的律师论点，提高了司法决定的客观性、公平性和合理性。实验结果表明我们的框架带来了改进。

Conclusion: 我们的框架在SimuCourt数据集和RareCases数据集上展示了有效性，表明其可用性。我们的贡献包括一个集成框架、一个罕见案例数据集，以及公开发布数据集和代码以支持自动化司法系统进一步研究。

Abstract: Legal Judgment Prediction (LJP) aims to predict judicial outcomes, including
relevant legal charge, terms, and fines, which is a crucial process in Large
Language Model(LLM). However, LJP faces two key challenges: (1)Long Tail
Distribution: Current datasets, derived from authentic cases, suffer from high
human annotation costs and imbalanced distributions, leading to model
performance degradation. (2)Lawyer's Improvement: Existing systems focus on
enhancing judges' decision-making but neglect the critical role of lawyers in
refining arguments, which limits overall judicial accuracy. To address these
issues, we propose an Adversarial Self-Play Lawyer Augmented Legal Judgment
Framework, called ASP2LJ, which integrates a case generation module to tackle
long-tailed data distributions and an adversarial self-play mechanism to
enhance lawyers' argumentation skills. Our framework enables a judge to
reference evolved lawyers' arguments, improving the objectivity, fairness, and
rationality of judicial decisions. Besides, We also introduce RareCases, a
dataset for rare legal cases in China, which contains 120 tail-end cases. We
demonstrate the effectiveness of our approach on the SimuCourt dataset and our
RareCases dataset. Experimental results show our framework brings improvements,
indicating its utilization. Our contributions include an integrated framework,
a rare-case dataset, and publicly releasing datasets and code to support
further research in automated judicial systems.

</details>


### [77] [Existing LLMs Are Not Self-Consistent For Simple Tasks](https://arxiv.org/abs/2506.18781)
*Zhenru Lin,Jiawen Tao,Yang Yuan,Andrew Chi-Chih Yao*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）的自洽性问题，发现即使在简单的任务中，LLMs也存在高度不一致性。我们提出了两种自动化方法来量化和减轻这些不一致性，并强调了自洽性在构建更可靠和可解释的AI中的重要性。


<details>
  <summary>Details</summary>
Motivation: 确保大型语言模型（LLMs）的决策保持透明和可信需要自洽性——即内部推理中没有矛盾。然而，现有的LLMs在简单任务中表现出高度的不一致性，这表明需要进一步研究和解决这个问题。

Method: 我们引入了不一致性度量，并提出了两种自动化方法——基于图的方法和基于能量的方法，以量化和减轻LLMs中的不一致性。

Result: 我们的研究发现，即使是简单的任务，如比较线或平面上的点，或在家庭树中推理，所有较小的模型都存在高度不一致性，甚至最先进的模型如DeepSeek-R1和GPT-o4-mini也不完全自洽。通过引入不一致性度量和提出两种自动化方法，我们部分改善了这些问题，但同时也凸显了自洽性的重要性。

Conclusion: 我们的研究揭示了即使在简单的任务中，小型模型也存在高度不一致，甚至最先进的模型如DeepSeek-R1和GPT-o4-mini也不完全自洽。为了量化和减轻这些不一致性，我们引入了不一致性度量并提出了两种自动化方法——基于图的方法和基于能量的方法。虽然这些修复提供了一些改进，但也突显了自洽性在构建更可靠和可解释的AI中的复杂性和重要性。

Abstract: Large Language Models (LLMs) have grown increasingly powerful, yet ensuring
their decisions remain transparent and trustworthy requires self-consistency --
no contradictions in their internal reasoning. Our study reveals that even on
simple tasks, such as comparing points on a line or a plane, or reasoning in a
family tree, all smaller models are highly inconsistent, and even
state-of-the-art models like DeepSeek-R1 and GPT-o4-mini are not fully
self-consistent. To quantify and mitigate these inconsistencies, we introduce
inconsistency metrics and propose two automated methods -- a graph-based and an
energy-based approach. While these fixes provide partial improvements, they
also highlight the complexity and importance of self-consistency in building
more reliable and interpretable AI. The code and data are available at
https://github.com/scorpio-nova/llm-self-consistency.

</details>


### [78] [RWESummary: A Framework and Test for Choosing Large Language Models to Summarize Real-World Evidence (RWE) Studies](https://arxiv.org/abs/2506.18819)
*Arjun Mukerji,Michael L. Jackson,Jason Jones,Neil Sanghavi*

Main category: cs.CL

TL;DR: 本文介绍了RWESummary，作为MedHELM框架的补充，用于评估LLMs在真实世界证据研究摘要任务中的表现。通过使用Atropos Health专有数据开发RWESummary，我们比较了不同LLMs在内部RWE摘要工具中的性能，并发现Gemini 2.5模型表现最佳。我们建议RWESummary作为该任务的新基准模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）已被广泛评估用于一般摘要任务以及医学研究辅助，但尚未专门评估用于从RWE研究的结构化输出中摘要真实世界证据（RWE）的任务。

Method: 我们引入了RWESummary，作为MedHELM框架的补充，以实现对该任务的基准测试。RWESummary包括一个场景和三个评估，涵盖了在医学研究摘要中观察到的主要错误类型，并使用Atropos Health专有数据开发。此外，我们使用RWESummary比较了不同LLMs在我们的内部RWE摘要工具中的性能。

Result: 在发表时，有13个不同的RWE研究，我们发现Gemini 2.5模型整体表现最好（包括Flash和Pro）。

Conclusion: 我们建议RWESummary作为真实世界证据研究摘要的一个新颖且有用的基准模型。

Abstract: Large Language Models (LLMs) have been extensively evaluated for general
summarization tasks as well as medical research assistance, but they have not
been specifically evaluated for the task of summarizing real-world evidence
(RWE) from structured output of RWE studies. We introduce RWESummary, a
proposed addition to the MedHELM framework (Bedi, Cui, Fuentes, Unell et al.,
2025) to enable benchmarking of LLMs for this task. RWESummary includes one
scenario and three evaluations covering major types of errors observed in
summarization of medical research studies and was developed using Atropos
Health proprietary data. Additionally, we use RWESummary to compare the
performance of different LLMs in our internal RWE summarization tool. At the
time of publication, with 13 distinct RWE studies, we found the Gemini 2.5
models performed best overall (both Flash and Pro). We suggest RWESummary as a
novel and useful foundation model benchmark for real-world evidence study
summarization.

</details>


### [79] [MLLP-VRAIN UPV system for the IWSLT 2025 Simultaneous Speech Translation Translation task](https://arxiv.org/abs/2506.18828)
*Jorge Iranzo-Sánchez,Javier Iranzo-Sánchez,Adrià Giménez,Jorge Civera,Alfons Juan*

Main category: cs.CL

TL;DR: 本研究描述了MLLP-VRAIN研究小组参与IWSLT 2025同时语音翻译轨道的共享任务。我们的提交通过开发一个模块化级联系统来应对长篇语音实时翻译的独特挑战，该系统将强大的预训练模型适应于流式场景。我们的方法结合了Whisper Large-V3-Turbo用于ASR和多语言NLLB-3.3B模型用于MT，并采用轻量级适应技术而不是从头开始训练新的端到端模型。我们的系统在翻译质量和延迟之间取得了有利的平衡，BLEU得分为31.96，非计算感知的StreamLAAL延迟为2.94秒。


<details>
  <summary>Details</summary>
Motivation: 我们的提交解决了实时翻译长篇语音的独特挑战，开发了一个模块化级联系统，将强大的预训练模型适应于流式场景。

Method: 我们结合了Whisper Large-V3-Turbo用于ASR和多语言NLLB-3.3B模型用于MT，并采用了轻量级适应技术而不是从头开始训练新的端到端模型。我们的方法使用文档级别的适应和前缀训练来增强MT模型处理不完整输入的能力，同时结合了自适应发射策略，包括wait-$k$策略和RALCP来管理翻译流。

Result: 在ACL60/60数据集上的实验结果表明，我们的系统在翻译质量和延迟之间取得了有利的平衡，BLEU得分为31.96，非计算感知的StreamLAAL延迟为2.94秒。我们的最终模型在官方测试集(IWSLT25Instruct)上获得了29.8 BLEU的初步分数。

Conclusion: 我们的工作表明，经过仔细调整的预训练组件可以在不需要大量领域内平行数据或专用端到端训练的情况下，为长篇内容创建有效的同声传译系统。

Abstract: This work describes the participation of the MLLP-VRAIN research group in the
shared task of the IWSLT 2025 Simultaneous Speech Translation track. Our
submission addresses the unique challenges of real-time translation of
long-form speech by developing a modular cascade system that adapts strong
pre-trained models to streaming scenarios. We combine Whisper Large-V3-Turbo
for ASR with the multilingual NLLB-3.3B model for MT, implementing lightweight
adaptation techniques rather than training new end-to-end models from scratch.
Our approach employs document-level adaptation with prefix training to enhance
the MT model's ability to handle incomplete inputs, while incorporating
adaptive emission policies including a wait-$k$ strategy and RALCP for managing
the translation stream. Specialized buffer management techniques and
segmentation strategies ensure coherent translations across long audio
sequences. Experimental results on the ACL60/60 dataset demonstrate that our
system achieves a favorable balance between translation quality and latency,
with a BLEU score of 31.96 and non-computational-aware StreamLAAL latency of
2.94 seconds. Our final model achieves a preliminary score on the official test
set (IWSLT25Instruct) of 29.8 BLEU. Our work demonstrates that carefully
adapted pre-trained components can create effective simultaneous translation
systems for long-form content without requiring extensive in-domain parallel
data or specialized end-to-end training.

</details>


### [80] [STU-PID: Steering Token Usage via PID Controller for Efficient Large Language Model Reasoning](https://arxiv.org/abs/2506.18831)
*Aryasomayajula Ram Bharadwaj*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的方法STUPID，利用PID控制器在推理过程中动态调节激活引导强度，以检测冗余推理模式并自适应调整引导强度。实验结果表明，该方法在提高准确率的同时减少了标记使用量，并优于静态引导基线。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型采用扩展的思维链（CoT）推理常常会出现过度思考的现象，生成过多和冗余的推理步骤，增加计算成本，同时可能降低性能。虽然最近的工作探索了静态引导方法来缓解这个问题，但它们缺乏根据实时推理质量动态调整干预强度的适应性。

Method: 我们提出了STUPID（通过PID控制器进行引导令牌使用），这是一种无需训练的方法，利用PID控制器在推理过程中动态调节激活引导强度。我们的方法结合了块级分类器以检测冗余推理模式，并采用PID控制机制根据预测的冗余概率自适应调整引导强度。

Result: 在GSM8K上的实验评估表明，STUPID在准确率上提高了6%，同时将标记使用量减少了32%，优于静态引导基线。

Conclusion: 我们的方法提供了一个合理的框架，用于动态推理校准，在保持推理质量的同时显著提高了计算效率。

Abstract: Large Language Models employing extended chain-of-thought (CoT) reasoning
often suffer from the overthinking phenomenon, generating excessive and
redundant reasoning steps that increase computational costs while potentially
degrading performance. While recent work has explored static steering
approaches to mitigate this issue, they lack the adaptability to dynamically
adjust intervention strength based on real-time reasoning quality. We propose
STUPID (Steering Token Usage via PID controller), a novel training-free method
that employs a PID controller to dynamically modulate activation steering
strength during inference. Our approach combines a chunk-level classifier for
detecting redundant reasoning patterns with a PID control mechanism that
adaptively adjusts steering intensity based on the predicted redundancy
probability. Experimental evaluation on GSM8K demonstrates that STUPID achieves
a 6% improvement in accuracy while reducing token usage by 32%, outperforming
static steering baselines. Our method provides a principled framework for
dynamic reasoning calibration that maintains reasoning quality while
significantly improving computational efficiency.

</details>


### [81] [LongWriter-Zero: Mastering Ultra-Long Text Generation via Reinforcement Learning](https://arxiv.org/abs/2506.18841)
*Yuhao Wu,Yushi Bai,Zhiqiang Hu,Roy Ka-Wei Lee,Juanzi Li*

Main category: cs.CL

TL;DR: 本文提出了一种无需合成数据的强化学习方法，用于训练大型语言模型生成超长高质量文本，取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 由于最大生成长度限制和序列长度增加导致的整体质量下降，超长生成是大型语言模型（LLMs）的一个重要挑战。之前的策略依赖于合成数据，这很难且成本高，并且缺乏连贯性和一致性。

Method: 我们提出了一种基于激励的方法，使用强化学习（RL）来培养LLMs生成超长、高质量文本的能力，而无需任何标注或合成数据。

Result: 实验评估表明，我们的LongWriter-Zero模型在WritingBench和Arena-Write上均优于传统SFT方法，并超过了如DeepSeek R1和Qwen3-235B等100B+模型。

Conclusion: 我们的LongWriter-Zero模型在长文本生成任务中表现出色，超越了传统SFT方法和一些更大的模型。

Abstract: Ultra-long generation by large language models (LLMs) is a widely demanded
scenario, yet it remains a significant challenge due to their maximum
generation length limit and overall quality degradation as sequence length
increases. Previous approaches, exemplified by LongWriter, typically rely on
''teaching'', which involves supervised fine-tuning (SFT) on synthetic
long-form outputs. However, this strategy heavily depends on synthetic SFT
data, which is difficult and costly to construct, often lacks coherence and
consistency, and tends to be overly artificial and structurally monotonous. In
this work, we propose an incentivization-based approach that, starting entirely
from scratch and without relying on any annotated or synthetic data, leverages
reinforcement learning (RL) to foster the emergence of ultra-long, high-quality
text generation capabilities in LLMs. We perform RL training starting from a
base model, similar to R1-Zero, guiding it to engage in reasoning that
facilitates planning and refinement during the writing process. To support
this, we employ specialized reward models that steer the LLM towards improved
length control, writing quality, and structural formatting. Experimental
evaluations show that our LongWriter-Zero model, trained from Qwen2.5-32B,
consistently outperforms traditional SFT methods on long-form writing tasks,
achieving state-of-the-art results across all metrics on WritingBench and
Arena-Write, and even surpassing 100B+ models such as DeepSeek R1 and
Qwen3-235B. We open-source our data and model checkpoints under
https://huggingface.co/THU-KEG/LongWriter-Zero-32B

</details>


### [82] [Mechanistic Interpretability Needs Philosophy](https://arxiv.org/abs/2506.18852)
*Iwan Williams,Ninell Oldenburg,Ruchira Dhar,Joshua Hatherley,Constanza Fierro,Nina Rajcic,Sandrine R. Schiller,Filippos Stamatiou,Anders Søgaard*

Main category: cs.CL

TL;DR: 本文主张将哲学作为机械可解释性研究的持续合作伙伴，以帮助澄清概念、改进方法并评估解释人工智能系统的认识论和伦理影响。


<details>
  <summary>Details</summary>
Motivation: 随着机械可解释性领域的影响日益增长，有必要不仅审视模型本身，还要审视MI研究中隐含的假设、概念和解释策略。

Method: 通过三个开放问题的例子，本文展示了哲学可以为机械可解释性研究带来的价值，并勾勒出更深层次跨学科对话的路径。

Result: 本文强调了哲学在机械可解释性研究中的重要性，并提出了促进跨学科对话的方法。

Conclusion: 机械可解释性需要哲学作为持续的合作伙伴，以澄清其概念、改进其方法，并评估解释人工智能系统的认识论和伦理影响。

Abstract: Mechanistic interpretability (MI) aims to explain how neural networks work by
uncovering their underlying causal mechanisms. As the field grows in influence,
it is increasingly important to examine not just models themselves, but the
assumptions, concepts and explanatory strategies implicit in MI research. We
argue that mechanistic interpretability needs philosophy: not as an
afterthought, but as an ongoing partner in clarifying its concepts, refining
its methods, and assessing the epistemic and ethical stakes of interpreting AI
systems. Taking three open problems from the MI literature as examples, this
position paper illustrates the value philosophy can add to MI research, and
outlines a path toward deeper interdisciplinary dialogue.

</details>


### [83] [CommVQ: Commutative Vector Quantization for KV Cache Compression](https://arxiv.org/abs/2506.18879)
*Junyan Li,Yang Zhang,Muhammad Yusuf Hassan,Talha Chafekar,Tianle Cai,Zhile Ren,Pengsheng Guo,Foroozan Karimzadeh,Colorado Reed,Chong Wang,Chuang Gan*

Main category: cs.CL

TL;DR: 本文提出了一种名为Commutative Vector Quantization (CommVQ)的方法，以显著减少长上下文大型语言模型（LLMs）推理的内存使用。通过引入加法量化和与Rotary Position Embedding (RoPE)可交换的代码本，该方法在保持高精度的同时降低了计算成本。实验结果显示，该方法在2位量化下将FP16 KV缓存大小减少了87.5%，并允许在最小精度损失的情况下进行1位KV缓存量化，从而使得LLaMA-3.1 8B模型能够在单个RTX 4090 GPU上运行128K上下文长度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）越来越多地用于需要长上下文长度的应用，但随着上下文的增长，键值（KV）缓存常常成为GPU上的内存瓶颈。为了解决这个问题，我们提出了Commutative Vector Quantization (CommVQ)来显著减少长上下文LLM推理的内存使用。

Method: 我们提出了Commutative Vector Quantization (CommVQ)来显著减少长上下文LLM推理的内存使用。我们首先引入了带有轻量编码器和代码本的加法量化来压缩KV缓存，这可以通过简单的矩阵乘法解码。为了进一步降低解码过程中的计算成本，我们设计了一个与Rotary Position Embedding (RoPE)可交换的代码本，并使用期望最大化（EM）算法进行训练。这使得解码可以高效地集成到自注意力机制中。

Result: 实验结果表明，我们的方法在2位量化下将FP16 KV缓存大小减少了87.5%，同时优于最先进的KV缓存量化方法。值得注意的是，它允许在最小精度损失的情况下进行1位KV缓存量化，使LLaMA-3.1 8B模型能够在单个RTX 4090 GPU上运行128K上下文长度。

Conclusion: 我们的方法在长上下文基准和GSM8K上实现了高精度，并通过RoPE可交换的代码本实现了低开销。实验表明，该方法在2位量化下将FP16 KV缓存大小减少了87.5%，同时优于最先进的KV缓存量化方法。值得注意的是，它允许在最小精度损失的情况下进行1位KV缓存量化，使LLaMA-3.1 8B模型能够在单个RTX 4090 GPU上运行128K上下文长度。

Abstract: Large Language Models (LLMs) are increasingly used in applications requiring
long context lengths, but the key-value (KV) cache often becomes a memory
bottleneck on GPUs as context grows. To address this, we propose Commutative
Vector Quantization (CommVQ) to significantly reduce memory usage for
long-context LLM inference. We first introduce additive quantization with a
lightweight encoder and codebook to compress the KV cache, which can be decoded
via simple matrix multiplication. To further reduce computational costs during
decoding, we design the codebook to be commutative with Rotary Position
Embedding (RoPE) and train it using an Expectation-Maximization (EM) algorithm.
This enables efficient integration of decoding into the self-attention
mechanism. Our approach achieves high accuracy with additive quantization and
low overhead via the RoPE-commutative codebook. Experiments on long-context
benchmarks and GSM8K show that our method reduces FP16 KV cache size by 87.5%
with 2-bit quantization, while outperforming state-of-the-art KV cache
quantization methods. Notably, it enables 1-bit KV cache quantization with
minimal accuracy loss, allowing a LLaMA-3.1 8B model to run with a 128K context
length on a single RTX 4090 GPU. The source code is available at:
https://github.com/UMass-Embodied-AGI/CommVQ.

</details>


### [84] [OMEGA: Can LLMs Reason Outside the Box in Math? Evaluating Exploratory, Compositional, and Transformative Generalization](https://arxiv.org/abs/2506.18880)
*Yiyou Sun,Shawn Hu,Georgia Zhou,Ken Zheng,Hannaneh Hajishirzi,Nouha Dziri,Dawn Song*

Main category: cs.CL

TL;DR: OMEGA is a benchmark to evaluate the out-of-distribution generalization capabilities of LLMs in mathematics, revealing limitations in compositional and transformative reasoning.


<details>
  <summary>Details</summary>
Motivation: To systematically investigate the limitations of recent large-scale language models (LLMs) in handling problems that require novel ways of thinking, especially in mathematics.

Method: OMEGA is a controlled yet diverse benchmark designed to evaluate three axes of out-of-distribution generalization: exploratory, compositional, and transformative. It consists of programmatically generated training-test pairs derived from templated problem generators across various mathematical domains.

Result: Frontier LLMs show sharp performance degradation as problem complexity increases. Fine-tuning the Qwen-series models improves exploratory generalization, but compositional generalization remains limited, and transformative reasoning shows little to no improvement.

Conclusion: OMEGA lays the groundwork for advancing LLMs toward genuine mathematical creativity beyond mechanical proficiency.

Abstract: Recent large-scale language models (LLMs) with long Chain-of-Thought
reasoning-such as DeepSeek-R1-have achieved impressive results on
Olympiad-level mathematics benchmarks. However, they often rely on a narrow set
of strategies and struggle with problems that require a novel way of thinking.
To systematically investigate these limitations, we introduce
OMEGA-Out-of-distribution Math Problems Evaluation with 3 Generalization Axes-a
controlled yet diverse benchmark designed to evaluate three axes of
out-of-distribution generalization, inspired by Boden's typology of creativity:
(1) Exploratory-applying known problem solving skills to more complex instances
within the same problem domain; (2) Compositional-combining distinct reasoning
skills, previously learned in isolation, to solve novel problems that require
integrating these skills in new and coherent ways; and (3)
Transformative-adopting novel, often unconventional strategies by moving beyond
familiar approaches to solve problems more effectively. OMEGA consists of
programmatically generated training-test pairs derived from templated problem
generators across geometry, number theory, algebra, combinatorics, logic, and
puzzles, with solutions verified using symbolic, numerical, or graphical
methods. We evaluate frontier (or top-tier) LLMs and observe sharp performance
degradation as problem complexity increases. Moreover, we fine-tune the
Qwen-series models across all generalization settings and observe notable
improvements in exploratory generalization, while compositional generalization
remains limited and transformative reasoning shows little to no improvement. By
isolating and quantifying these fine-grained failures, OMEGA lays the
groundwork for advancing LLMs toward genuine mathematical creativity beyond
mechanical proficiency.

</details>


### [85] [ReasonFlux-PRM: Trajectory-Aware PRMs for Long Chain-of-Thought Reasoning in LLMs](https://arxiv.org/abs/2506.18896)
*Jiaru Zou,Ling Yang,Jingwen Gu,Jiahao Qiu,Ke Shen,Jingrui He,Mengdi Wang*

Main category: cs.CL

TL;DR: 本文提出了一种新的轨迹感知PRM（ReasonFlux-PRM），用于评估中间推理轨迹，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有PRMs主要基于模型最终输出进行训练，在评估中间思考轨迹方面存在困难，尤其是在轨迹-响应输出设置中。

Method: 引入了ReasonFlux-PRM，一种新型的轨迹感知PRM，结合了步骤级和轨迹级监督，以实现与结构化思维链数据对齐的细粒度奖励分配。

Result: ReasonFlux-PRM-7B在AIME、MATH500和GPQA-Diamond等基准测试中表现优于强PRMs和人工标注基线，并实现了平均12.1%、4.5%和6.3%的性能提升。

Conclusion: ReasonFlux-PRM-7B在监督微调、强化学习和测试时扩展中均实现了性能提升，同时释放了适用于资源受限应用的ReasonFlux-PRM-1.5B。

Abstract: Process Reward Models (PRMs) have recently emerged as a powerful framework
for supervising intermediate reasoning steps in large language models (LLMs).
Previous PRMs are primarily trained on model final output responses and
struggle to evaluate intermediate thinking trajectories robustly, especially in
the emerging setting of trajectory-response outputs generated by frontier
reasoning models like Deepseek-R1. In this work, we introduce ReasonFlux-PRM, a
novel trajectory-aware PRM explicitly designed to evaluate the
trajectory-response type of reasoning traces. ReasonFlux-PRM incorporates both
step-level and trajectory-level supervision, enabling fine-grained reward
assignment aligned with structured chain-of-thought data. We adapt
ReasonFlux-PRM to support reward supervision under both offline and online
settings, including (i) selecting high-quality model distillation data for
downstream supervised fine-tuning of smaller models, (ii) providing dense
process-level rewards for policy optimization during reinforcement learning,
and (iii) enabling reward-guided Best-of-N test-time scaling. Empirical results
on challenging downstream benchmarks such as AIME, MATH500, and GPQA-Diamond
demonstrate that ReasonFlux-PRM-7B selects higher quality data than strong PRMs
(e.g., Qwen2.5-Math-PRM-72B) and human-curated baselines. Furthermore, our
derived ReasonFlux-PRM-7B yields consistent performance improvements, achieving
average gains of 12.1% in supervised fine-tuning, 4.5% in reinforcement
learning, and 6.3% in test-time scaling. We also release our efficient
ReasonFlux-PRM-1.5B for resource-constrained applications and edge deployment.
Projects: https://github.com/Gen-Verse/ReasonFlux

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [86] [Enhancing Few-shot Keyword Spotting Performance through Pre-Trained Self-supervised Speech Models](https://arxiv.org/abs/2506.17686)
*Alican Gok,Oguzhan Buyuksolak,Osman Erman Okman,Murat Saraclar*

Main category: eess.AS

TL;DR: 本文提出了一种新的训练方案，通过自监督学习模型和知识蒸馏技术，显著提高了Few-Shot Keyword Spotting的准确率，使其更适合在资源受限的边缘设备上部署。


<details>
  <summary>Details</summary>
Motivation: 现有FS-KWS系统在资源受限的边缘环境中准确率不高，无法满足实际应用需求。

Method: 提出了一种利用自监督学习模型进行鲁棒特征提取、降维和知识蒸馏的训练方案。教师模型基于Wav2Vec 2.0，并使用子中心ArcFace损失进行训练。引入了基于注意力的降维方法，并训练了一个标准的轻量级ResNet15学生模型。

Result: 在GSC数据集上，该方法将10-shot分类准确率从33.4%提高到了74.1%。

Conclusion: 该方法显著提高了10-shot分类准确率，使其更适合实际应用场景。

Abstract: Keyword Spotting plays a critical role in enabling hands-free interaction for
battery-powered edge devices. Few-Shot Keyword Spotting (FS-KWS) addresses the
scalability and adaptability challenges of traditional systems by enabling
recognition of custom keywords with only a few examples. However, existing
FS-KWS systems achieve subpar accuracy at desirable false acceptance rates,
particularly in resource-constrained edge environments. To address these
issues, we propose a training scheme that leverages self-supervised learning
models for robust feature extraction, dimensionality reduction, and knowledge
distillation. The teacher model, based on Wav2Vec 2.0 is trained using
Sub-center ArcFace loss, which enhances inter-class separability and
intra-class compactness. To enable efficient deployment on edge devices, we
introduce attention-based dimensionality reduction and train a standard
lightweight ResNet15 student model. We evaluate the proposed approach on the
English portion of the Multilingual Spoken Words Corpus (MSWC) and the Google
Speech Commands (GSC) datasets. Notably, the proposed training method improves
the 10-shot classification accuracy from 33.4% to 74.1% on 11 classes at 1%
false alarm accuracy on the GSC dataset, thus making it significantly
better-suited for a real use case scenario.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [87] [LLM-driven Medical Report Generation via Communication-efficient Heterogeneous Federated Learning](https://arxiv.org/abs/2506.17562)
*Haoxuan Che,Haibo Jin,Zhengrui Guo,Yi Lin,Cheng Jin,Hao Chen*

Main category: cs.CV

TL;DR: FedMRG is a framework that uses Federated Learning to develop LLM-driven MRG models in a privacy-preserving manner, addressing challenges like communication overhead and data heterogeneity.


<details>
  <summary>Details</summary>
Motivation: The development of LLMs for Medical Report Generation (MRG) requires large amounts of medical image-report pairs, which are scattered across multiple centers. Centralizing these data is challenging due to privacy regulations, impeding model development and broader adoption.

Method: FedMRG leverages Federated Learning (FL) to enable privacy-preserving, multi-center development of LLM-driven MRG models. It employs low-rank factorization to reduce gradient transmission costs and introduces client-aware contrastive learning and a dual-adapter mutual boosting mechanism to address heterogeneity.

Result: FedMRG shows generalizability and adaptability in multi-center MRG scenarios, demonstrating its ability to generate clinically accurate reports while maintaining communication efficiency.

Conclusion: FedMRG demonstrates the potential in harnessing multi-center data and generating clinically accurate reports while maintaining communication efficiency.

Abstract: LLMs have demonstrated significant potential in Medical Report Generation
(MRG), yet their development requires large amounts of medical image-report
pairs, which are commonly scattered across multiple centers. Centralizing these
data is exceptionally challenging due to privacy regulations, thereby impeding
model development and broader adoption of LLM-driven MRG models. To address
this challenge, we present FedMRG, the first framework that leverages Federated
Learning (FL) to enable privacy-preserving, multi-center development of
LLM-driven MRG models, specifically designed to overcome the critical challenge
of communication-efficient LLM training under multi-modal data heterogeneity.
To start with, our framework tackles the fundamental challenge of communication
overhead in FL-LLM tuning by employing low-rank factorization to efficiently
decompose parameter updates, significantly reducing gradient transmission costs
and making LLM-driven MRG feasible in bandwidth-constrained FL settings.
Furthermore, we observed the dual heterogeneity in MRG under the FL scenario:
varying image characteristics across medical centers, as well as diverse
reporting styles and terminology preferences. To address this, we further
enhance FedMRG with (1) client-aware contrastive learning in the MRG encoder,
coupled with diagnosis-driven prompts, which capture both globally
generalizable and locally distinctive features while maintaining diagnostic
accuracy; and (2) a dual-adapter mutual boosting mechanism in the MRG decoder
that harmonizes generic and specialized adapters to address variations in
reporting styles and terminology. Through extensive evaluation of our
established FL-MRG benchmark, we demonstrate the generalizability and
adaptability of FedMRG, underscoring its potential in harnessing multi-center
data and generating clinically accurate reports while maintaining communication
efficiency.

</details>


### [88] [CLiViS: Unleashing Cognitive Map through Linguistic-Visual Synergy for Embodied Visual Reasoning](https://arxiv.org/abs/2506.17629)
*Kailing Li,Qi'ao Xu,Tianwen Qian,Yuqian Fu,Yang Jiao,Xiaoling Wang*

Main category: cs.CV

TL;DR: CLiViS is a new framework that combines LLMs and VLMs to improve embodied visual reasoning by creating a dynamic Cognitive Map for better scene understanding.


<details>
  <summary>Details</summary>
Motivation: EVR faces challenges due to the diversity of complex instructions and intricate spatiotemporal dynamics in long-term egocentric videos. Prior solutions either lack critical visual details or struggle with stepwise compositional reasoning.

Method: CLiViS utilizes LLMs for high-level task planning and VLM-driven open-world visual perception to iteratively update the scene context. It introduces a dynamic Cognitive Map that bridges low-level perception and high-level reasoning.

Result: Extensive experiments across multiple benchmarks demonstrate the effectiveness and generality of CLiViS, especially in handling long-term visual dependencies.

Conclusion: CLiViS is a novel training-free framework that effectively handles long-term visual dependencies by leveraging the complementary strengths of LLMs and VLMs.

Abstract: Embodied Visual Reasoning (EVR) seeks to follow complex, free-form
instructions based on egocentric video, enabling semantic understanding and
spatiotemporal reasoning in dynamic environments. Despite its promising
potential, EVR encounters significant challenges stemming from the diversity of
complex instructions and the intricate spatiotemporal dynamics in long-term
egocentric videos. Prior solutions either employ Large Language Models (LLMs)
over static video captions, which often omit critical visual details, or rely
on end-to-end Vision-Language Models (VLMs) that struggle with stepwise
compositional reasoning. Consider the complementary strengths of LLMs in
reasoning and VLMs in perception, we propose CLiViS. It is a novel
training-free framework that leverages LLMs for high-level task planning and
orchestrates VLM-driven open-world visual perception to iteratively update the
scene context. Building on this synergy, the core of CLiViS is a dynamic
Cognitive Map that evolves throughout the reasoning process. This map
constructs a structured representation of the embodied scene, bridging
low-level perception and high-level reasoning. Extensive experiments across
multiple benchmarks demonstrate the effectiveness and generality of CLiViS,
especially in handling long-term visual dependencies. Code is available at
https://github.com/Teacher-Tom/CLiViS.

</details>


### [89] [PP-DocBee2: Improved Baselines with Efficient Data for Multimodal Document Understanding](https://arxiv.org/abs/2506.18023)
*Kui Huang,Xinrong Chen,Wenyu Lv,Jincheng Liao,Guanzhong Wang,Yi Liu*

Main category: cs.CV

TL;DR: PP-DocBee2 是一种改进的多模态文档理解模型，通过增强的合成数据质量、改进的视觉特征融合策略和优化的推理方法，显著提高了性能并减少了推理延迟。


<details>
  <summary>Details</summary>
Motivation: PP-DocBee2 的提出是为了克服其前身 PP-DocBee 的局限性，特别是在多模态文档任务中提高性能和效率。

Method: PP-DocBee2 基于大规模多模态模型架构，采用了一种数据质量优化策略，利用大规模多模态预训练模型评估数据，并应用了一种新颖的统计标准来过滤异常值。此外，还通过分解ViT并应用新的特征融合策略来增强其表示能力。

Result: PP-DocBee2 在中文商业文档的内部基准测试中实现了 11.4% 的性能提升，并将推理延迟降低了 73.0%。

Conclusion: PP-DocBee2 是一种先进的多模态文档理解模型，通过关键的技术改进，如增强的合成数据质量、改进的视觉特征融合策略和优化的推理方法，显著提升了性能并减少了推理延迟。

Abstract: This report introduces PP-DocBee2, an advanced version of the PP-DocBee,
designed to enhance multimodal document understanding. Built on a large
multimodal model architecture, PP-DocBee2 addresses the limitations of its
predecessor through key technological improvements, including enhanced
synthetic data quality, improved visual feature fusion strategy, and optimized
inference methodologies. These enhancements yield an $11.4\%$ performance boost
on internal benchmarks for Chinese business documents, and reduce inference
latency by $73.0\%$ to the vanilla version. A key innovation of our work is a
data quality optimization strategy for multimodal document tasks. By employing
a large-scale multimodal pre-trained model to evaluate data, we apply a novel
statistical criterion to filter outliers, ensuring high-quality training data.
Inspired by insights into underutilized intermediate features in multimodal
models, we enhance the ViT representational capacity by decomposing it into
layers and applying a novel feature fusion strategy to improve complex
reasoning. The source code and pre-trained model are available at
\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.

</details>


### [90] [OmniGen2: Exploration to Advanced Multimodal Generation](https://arxiv.org/abs/2506.18871)
*Chenyuan Wu,Pengfei Zheng,Ruiran Yan,Shitao Xiao,Xin Luo,Yueze Wang,Wanli Li,Xiyan Jiang,Yexin Liu,Junjie Zhou,Ze Liu,Ziyi Xia,Chaofan Li,Haoge Deng,Jiahao Wang,Kun Luo,Bo Zhang,Defu Lian,Xinlong Wang,Zhongyuan Wang,Tiejun Huang,Zheng Liu*

Main category: cs.CV

TL;DR: OmniGen2 is a versatile and open-source generative model with two decoding pathways for text and image modalities. It achieves competitive results on various benchmarks and introduces a new benchmark called OmniContext for in-context generation.


<details>
  <summary>Details</summary>
Motivation: The motivation is to introduce a versatile and open-source generative model that provides a unified solution for diverse generation tasks, such as text-to-image, image editing, and in-context generation.

Method: OmniGen2 features two distinct decoding pathways for text and image modalities, utilizing unshared parameters and a decoupled image tokenizer. A reflection mechanism tailored for image generation tasks and a dedicated reflection dataset were introduced. Comprehensive data construction pipelines were developed for training.

Result: OmniGen2 achieves competitive results on multiple task benchmarks, including text-to-image and image editing. It also shows state-of-the-art performance among open-source models in terms of consistency for in-context generation tasks.

Conclusion: OmniGen2 achieves competitive results on multiple task benchmarks and state-of-the-art performance among open-source models in terms of consistency. The project will be released to support future research.

Abstract: In this work, we introduce OmniGen2, a versatile and open-source generative
model designed to provide a unified solution for diverse generation tasks,
including text-to-image, image editing, and in-context generation. Unlike
OmniGen v1, OmniGen2 features two distinct decoding pathways for text and image
modalities, utilizing unshared parameters and a decoupled image tokenizer. This
design enables OmniGen2 to build upon existing multimodal understanding models
without the need to re-adapt VAE inputs, thereby preserving the original text
generation capabilities. To facilitate the training of OmniGen2, we developed
comprehensive data construction pipelines, encompassing image editing and
in-context generation data. Additionally, we introduce a reflection mechanism
tailored for image generation tasks and curate a dedicated reflection dataset
based on OmniGen2. Despite its relatively modest parameter size, OmniGen2
achieves competitive results on multiple task benchmarks, including
text-to-image and image editing. To further evaluate in-context generation,
also referred to as subject-driven tasks, we introduce a new benchmark named
OmniContext. OmniGen2 achieves state-of-the-art performance among open-source
models in terms of consistency. We will release our models, training code,
datasets, and data construction pipeline to support future research in this
field. Project Page: https://vectorspacelab.github.io/OmniGen2; GitHub Link:
https://github.com/VectorSpaceLab/OmniGen2

</details>


### [91] [Vision as a Dialect: Unifying Visual Understanding and Generation via Text-Aligned Representations](https://arxiv.org/abs/2506.18898)
*Jiaming Han,Hao Chen,Yang Zhao,Hanyu Wang,Qi Zhao,Ziyan Yang,Hao He,Xiangyu Yue,Lu Jiang*

Main category: cs.CV

TL;DR: 本文介绍了一个多模态框架Tar，它通过文本对齐的代码本将图像转换为离散标记，从而在统一的离散语义表示中实现视觉理解和生成。Tar在多个基准测试中表现出色，能够匹配或超越现有的多模态LLM方法，同时实现了更快的收敛和更高的训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（LLM）需要特定于模态的设计，这限制了它们的灵活性和效率。本文旨在通过一个统一的框架来解决这一问题，使视觉和文本能够在共享空间中进行交互。

Method: 本文提出了一种多模态框架，通过一个文本对齐的代码本将图像转换为离散标记，从而在统一的离散语义表示中实现视觉理解和生成。此外，还提出了尺度自适应的编码和解码，以及一个生成性解码器以产生高保真视觉输出，并利用两种互补的解码器来满足不同的解码需求。

Result: Tar在多个基准测试中表现出色，能够匹配或超越现有的多模态LLM方法，同时实现了更快的收敛和更高的训练效率。

Conclusion: 实验结果表明，Tar在多个基准测试中与现有多模态LLM方法相当或超越，实现了更快的收敛和更高的训练效率。

Abstract: This paper presents a multimodal framework that attempts to unify visual
understanding and generation within a shared discrete semantic representation.
At its core is the Text-Aligned Tokenizer (TA-Tok), which converts images into
discrete tokens using a text-aligned codebook projected from a large language
model's (LLM) vocabulary. By integrating vision and text into a unified space
with an expanded vocabulary, our multimodal LLM, Tar, enables cross-modal input
and output through a shared interface, without the need for modality-specific
designs. Additionally, we propose scale-adaptive encoding and decoding to
balance efficiency and visual detail, along with a generative de-tokenizer to
produce high-fidelity visual outputs. To address diverse decoding needs, we
utilize two complementary de-tokenizers: a fast autoregressive model and a
diffusion-based model. To enhance modality fusion, we investigate advanced
pre-training tasks, demonstrating improvements in both visual understanding and
generation. Experiments across benchmarks show that Tar matches or surpasses
existing multimodal LLM methods, achieving faster convergence and greater
training efficiency. Code, models, and data are available at
https://tar.csuhan.com

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [92] [FaithfulSAE: Towards Capturing Faithful Features with Sparse Autoencoders without External Dataset Dependencies](https://arxiv.org/abs/2506.17673)
*Seonglae Cho,Harryn Oh,Donghyun Lee,Luis Eduardo Rodrigues Vieira,Andrew Bermingham,Ziad El Sayed*

Main category: cs.LG

TL;DR: 本文提出了一种在模型自身合成数据集上训练稀疏自编码器（SAEs）的方法，以解决现有SAEs在不同初始化种子下的不稳定性以及无法捕获模型内部特征的问题。实验结果表明，该方法提高了SAEs的稳定性，并在多个模型中减少了虚假特征的比例。


<details>
  <summary>Details</summary>
Motivation: Sparse Autoencoders (SAEs) 在分解大型语言模型表示为可解释特征方面表现出潜力，但存在不稳定性和无法捕获模型内部特征的问题。这些问题可能源于在外部数据集上训练SAEs，这些数据集可能包含超出模型泛化能力的分布外（OOD）数据，导致出现虚假特征。

Method: 我们提出了FaithfulSAE，一种在模型自身合成数据集上训练SAEs的方法。

Result: 使用FaithfulSAEs，我们证明了在较少OOD指令数据集上训练SAEs可以提高跨种子的稳定性。值得注意的是，FaithfulSAEs在SAE探测任务中优于基于网络的数据集训练的SAEs，并且在7个模型中的5个中显示出较低的虚假特征比例。

Conclusion: 我们的方法消除了对外部数据集的依赖，通过更好地捕捉模型内部特征来推进可解释性，并突出了SAE训练数据集常常被忽视的重要性。

Abstract: Sparse Autoencoders (SAEs) have emerged as a promising solution for
decomposing large language model representations into interpretable features.
However, Paulo and Belrose (2025) have highlighted instability across different
initialization seeds, and Heap et al. (2025) have pointed out that SAEs may not
capture model-internal features. These problems likely stem from training SAEs
on external datasets - either collected from the Web or generated by another
model - which may contain out-of-distribution (OOD) data beyond the model's
generalisation capabilities. This can result in hallucinated SAE features,
which we term "Fake Features", that misrepresent the model's internal
activations. To address these issues, we propose FaithfulSAE, a method that
trains SAEs on the model's own synthetic dataset. Using FaithfulSAEs, we
demonstrate that training SAEs on less-OOD instruction datasets results in SAEs
being more stable across seeds. Notably, FaithfulSAEs outperform SAEs trained
on web-based datasets in the SAE probing task and exhibit a lower Fake Feature
Ratio in 5 out of 7 models. Overall, our approach eliminates the dependency on
external datasets, advancing interpretability by better capturing
model-internal features while highlighting the often neglected importance of
SAE training datasets.

</details>


### [93] [Beyond instruction-conditioning, MoTE: Mixture of Task Experts for Multi-task Embedding Models](https://arxiv.org/abs/2506.17781)
*Miguel Romero,Shuoyang Ding,Corey D. Barret,Georgiana Dinu,George Karypis*

Main category: cs.LG

TL;DR: The paper introduces MoTE, a transformer block that enhances specialized embeddings through task-specialized parameters trained with TACL, achieving significant performance gains without changing instructions, training data, inference time, or active parameters.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the limitations of instruction-conditioning for embedding specialization in low-capacity models, which impose fundamental representational constraints that limit performance gains.

Method: The paper introduces the Mixture of Task Experts (MoTE) transformer block, which leverages task-specialized parameters trained with Task-Aware Contrastive Learning (TACL) to enhance the model's ability to generate specialized embeddings.

Result: Empirical results show that MoTE achieves 64% higher performance gains in retrieval datasets and 43% higher performance gains across all datasets.

Conclusion: MoTE achieves higher performance gains in retrieval datasets and across all datasets without altering instructions, training data, inference time, or number of active parameters.

Abstract: Dense embeddings are fundamental to modern machine learning systems, powering
Retrieval-Augmented Generation (RAG), information retrieval, and representation
learning. While instruction-conditioning has become the dominant approach for
embedding specialization, its direct application to low-capacity models imposes
fundamental representational constraints that limit the performance gains
derived from specialization. In this paper, we analyze these limitations and
introduce the Mixture of Task Experts (MoTE) transformer block, which leverages
task-specialized parameters trained with Task-Aware Contrastive Learning
(\tacl) to enhance the model ability to generate specialized embeddings.
Empirical results show that MoTE achieves $64\%$ higher performance gains in
retrieval datasets ($+3.27 \rightarrow +5.21$) and $43\%$ higher performance
gains across all datasets ($+1.81 \rightarrow +2.60$). Critically, these gains
are achieved without altering instructions, training data, inference time, or
number of active parameters.

</details>


### [94] [Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach](https://arxiv.org/abs/2506.17828)
*Xinnan Zhang,Chenliang Li,Siliang Zeng,Jiaxiang Li,Zhongruo Wang,Kaixiang Lin,Songtao Lu,Alfredo Garcia,Mingyi Hong*

Main category: cs.LG

TL;DR: 本文提出了一种名为Iterative Reweight-then-Optimize (IRO)的强化学习框架，用于对齐冻结的基础模型，无需修改其参数。


<details>
  <summary>Details</summary>
Motivation: 现有的微调方法如RLHF和DPO无法在测试时改进模型性能，且在模型权重不可用时不可行。而测试时的方法虽然避免了权重更新，但存在高推理成本和基于不完美奖励或价值函数的一次性引导问题。

Method: IRO方法在训练过程中通过采样候选、使用当前价值函数重新采样以及训练新的轻量级价值函数来引导下一次解码过程。在测试时，价值函数通过基于搜索的优化过程指导基础模型生成。

Result: IRO方法允许用户在自己的数据集上对模型进行对齐，类似于OpenAI的强化微调（RFT），但不需要访问模型权重。

Conclusion: 本文提出了一种名为Iterative Reweight-then-Optimize (IRO)的方法，这是一种无需修改模型参数即可对冻结基础模型进行强化学习（RL）对齐的框架。

Abstract: Aligning large language models (LLMs) with human preferences usually requires
fine-tuning methods such as RLHF and DPO. These methods directly optimize the
model parameters, so they cannot be used in test-time to improve model
performance, nor are they applicable when the model weights are not accessible.
In contrast, test-time methods sidestep weight updates by leveraging reward
functions to guide and improve output quality. However, they incur high
inference costs, and their one-shot guidance is often based on imperfect reward
or value functions, leading to suboptimal outputs. In this work, we present a
method named Iterative Reweight-then-Optimize (IRO), a reinforcement learning
(RL) framework that performs RL-style alignment of the (frozen) base model
without touching its parameters. During training, each iteration (i) samples
candidates from the base model, (ii) resamples using current value functions,
and (iii) trains a new lightweight value function that guides the next decoding
pass. At test time, the value functions are used to guide the base model
generation via a search-based optimization process. Notably, users can apply
IRO to align a model on their own dataset, similar to OpenAI's reinforcement
fine-tuning (RFT), but without requiring access to the model weights.

</details>


### [95] [AdapThink: Adaptive Thinking Preferences for Reasoning Language Model](https://arxiv.org/abs/2506.18237)
*Xu Wan,Wei Wang,Wenyue Xu,Wotao Yin,Jie Song,Mingyang Sun*

Main category: cs.LG

TL;DR: AdapThink 是一种自适应后训练框架，旨在提高语言模型的推理效率，同时保持其性能。它通过动态调整反思相关过渡词的偏好和平衡训练组的解决方案准确性和推理多样性来实现这一目标。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习的后训练方法通常依赖于静态长度预算或预定义规则，缺乏对不同问题复杂性和模型演进能力的适应性。因此，需要一种更高效的后训练框架来提高推理语言模型的效率。

Method: AdapThink 采用两种关键机制：1) 一种基于组相对奖励函数的方法，利用模型置信度和响应特征来动态调整反思相关过渡词的偏好；2) 一种考虑多样性的采样机制，通过熵引导的分数平衡训练组的解决方案准确性和推理多样性。

Result: AdapThink 在多个数学推理数据集上的实验结果表明，它能够实现自适应的推理模式，并有效缓解现有方法中的低效问题。

Conclusion: AdapThink 的实验结果表明，它在数学推理数据集上能够实现自适应的推理模式并缓解低效问题。

Abstract: Reinforcement Learning (RL)-based post-training has significantly advanced
the complex reasoning capabilities of language models, fostering sophisticated
self-reflection processes. However, this ``slow thinking'' paradigm presents a
critical challenge to reasoning efficiency: models may expend excessive
computation on simple questions and shift reasoning prematurely for complex
ones. Previous mechanisms typically rely on static length budgets or predefined
rules, lacking the adaptability for varying question complexities and models'
evolving capabilities. To this end, we propose AdapThink, an adaptive
post-training framework designed to induce more efficient thinking while
maintaining the performance of reasoning language models. Specifically,
AdapThink incorporates two key mechanisms: 1) A group-relative reward function
that leverages model confidence and response's characteristic to dynamically
adjust the preference of reflection-related transition words without resorting
to a fixed length preference. 2) A diversity-aware sampling mechanism that
balances the training group's solution accuracy with reasoning diversity via an
entropy-guided score. Experiments on several mathematical reasoning datasets
with DeepSeek-distilled models demonstrate AdapThink's advantages in enabling
adaptive reasoning patterns and mitigating the inefficiencies.

</details>


### [96] [RLPR: Extrapolating RLVR to General Domains without Verifiers](https://arxiv.org/abs/2506.18254)
*Tianyu Yu,Bo Ji,Shouli Wang,Shu Yao,Zefan Wang,Ganqu Cui,Lifan Yuan,Ning Ding,Yuan Yao,Zhiyuan Liu,Maosong Sun,Tat-Seng Chua*

Main category: cs.LG

TL;DR: RLPR is a verifier-free framework that uses LLM's intrinsic probabilities to improve reasoning capabilities in various domains.


<details>
  <summary>Details</summary>
Motivation: The limitation of RLVR is due to its reliance on domain-specific verifiers, which makes it complex and not scalable. The goal is to extrapolate RLVR to broader general domains without verifiers.

Method: RLPR is a verifier-free framework that uses the LLM's own token probability scores for reference answers as the reward signal and employs prob-to-reward and stabilizing methods to ensure a precise and stable reward.

Result: RLPR improves reasoning capabilities in four general-domain benchmarks and three mathematical benchmarks for Gemma, Llama, and Qwen based models. It outperforms VeriFree and General-Reasoner.

Conclusion: RLPR consistently improves reasoning capabilities in both general and mathematical domains for various models, outperforming existing methods.

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates promising
potential in advancing the reasoning capabilities of LLMs. However, its success
remains largely confined to mathematical and code domains. This primary
limitation stems from the heavy reliance on domain-specific verifiers, which
results in prohibitive complexity and limited scalability. To address the
challenge, our key observation is that LLM's intrinsic probability of
generating a correct free-form answer directly indicates its own evaluation of
the reasoning reward (i.e., how well the reasoning process leads to the correct
answer). Building on this insight, we propose RLPR, a simple verifier-free
framework that extrapolates RLVR to broader general domains. RLPR uses the
LLM's own token probability scores for reference answers as the reward signal
and maximizes the expected reward during training. We find that addressing the
high variance of this noisy probability reward is crucial to make it work, and
propose prob-to-reward and stabilizing methods to ensure a precise and stable
reward from LLM intrinsic probabilities. Comprehensive experiments in four
general-domain benchmarks and three mathematical benchmarks show that RLPR
consistently improves reasoning capabilities in both areas for Gemma, Llama,
and Qwen based models. Notably, RLPR outperforms concurrent VeriFree by 7.6
points on TheoremQA and 7.5 points on Minerva, and even surpasses strong
verifier-model-dependent approaches General-Reasoner by 1.6 average points
across seven benchmarks.

</details>


### [97] [Confucius3-Math: A Lightweight High-Performance Reasoning LLM for Chinese K-12 Mathematics Learning](https://arxiv.org/abs/2506.18330)
*Lixin Wu,Na Cai,Qiao Cheng,Jiachen Wang,Yitao Duan*

Main category: cs.LG

TL;DR: Confucius3-Math是一个具有14B参数的开源大型语言模型，可以在单个消费级GPU上高效运行，并在数学推理任务中表现出色。它特别针对中国K-12学生的数学学习和教育工作者，通过大规模强化学习进行后训练，并引入了三种技术创新以提高性能。


<details>
  <summary>Details</summary>
Motivation: 为了利用AI增强教育和知识传播，Confucius3-Math专门致力于中国K-12学生的数学学习和教育工作者。

Method: 通过大规模强化学习（RL）进行后训练，引入了三种技术创新：目标熵正则化、近期样本恢复和策略特定难度加权。

Result: Confucius3-Math在一系列数学推理任务中达到了SOTA性能，并且在单个消费级GPU上运行高效。

Conclusion: 我们的工作展示了在特定领域以低成本构建强大推理模型的可行性。

Abstract: We introduce Confucius3-Math, an open-source large language model with 14B
parameters that (1) runs efficiently on a single consumer-grade GPU; (2)
achieves SOTA performances on a range of mathematical reasoning tasks,
outperforming many models with significantly larger sizes. In particular, as
part of our mission to enhancing education and knowledge dissemination with AI,
Confucius3-Math is specifically committed to mathematics learning for Chinese
K-12 students and educators. Built via post-training with large-scale
reinforcement learning (RL), Confucius3-Math aligns with national curriculum
and excels at solving main-stream Chinese K-12 mathematical problems with low
cost. In this report we share our development recipe, the challenges we
encounter and the techniques we develop to overcome them. In particular, we
introduce three technical innovations: Targeted Entropy Regularization, Recent
Sample Recovery and Policy-Specific Hardness Weighting. These innovations
encompass a new entropy regularization, a novel data scheduling policy, and an
improved group-relative advantage estimator. Collectively, they significantly
stabilize the RL training, improve data efficiency, and boost performance. Our
work demonstrates the feasibility of building strong reasoning models in a
particular domain at low cost. We open-source our model and code at
https://github.com/netease-youdao/Confucius3-Math.

</details>


### [98] [SlimMoE: Structured Compression of Large MoE Models via Expert Slimming and Distillation](https://arxiv.org/abs/2506.18349)
*Zichong Li,Chen Liang,Zixuan Zhang,Ilgee Hong,Young Jin Kim,Weizhu Chen,Tuo Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种多阶段压缩框架SlimMoE，用于将大型MoE模型压缩为更小、高效的版本，从而在资源受限的环境中实现更广泛的MoE架构应用。


<details>
  <summary>Details</summary>
Motivation: 由于MoE模型的巨大内存需求，它们在资源受限环境中进行微调或部署的成本过高。因此，需要一种有效的方法来压缩这些模型，使其更适合实际应用。

Method: 我们引入了SlimMoE，这是一种多阶段压缩框架，通过系统地减少参数数量并通过对中间阶段的知识转移，将大型MoE模型转换为更小、高效的变体。

Result: 使用该框架，我们将Phi 3.5-MoE压缩为Phi-mini-MoE和Phi-tiny-MoE，仅使用400B个标记，这些压缩模型可以在单个GPU上进行微调，并且性能优于类似大小的模型，同时保持与更大模型相当的竞争力。

Conclusion: 我们的研究证明，结构化剪枝结合分阶段蒸馏为创建高质量、紧凑的MoE模型提供了有效的路径，为MoE架构的更广泛应用铺平了道路。

Abstract: The Mixture of Experts (MoE) architecture has emerged as a powerful paradigm
for scaling large language models (LLMs) while maintaining inference
efficiency. However, their enormous memory requirements make them prohibitively
expensive to fine-tune or deploy in resource-constrained environments. To
address this challenge, we introduce SlimMoE, a multi-stage compression
framework for transforming large MoE models into much smaller, efficient
variants without incurring the prohibitive costs of training from scratch. Our
method systematically reduces parameter counts by slimming experts and
transferring knowledge through intermediate stages, effectively mitigating the
performance degradation common in one-shot pruning approaches. Using this
framework, we compress Phi 3.5-MoE (41.9B total/6.6B activated parameters) to
create Phi-mini-MoE (7.6B total/2.4B activated parameters) and Phi-tiny-MoE
(3.8B total/1.1B activated parameters) using only 400B tokens--less than 10% of
the original model's training data. These compressed models can be fine-tuned
on a single GPU (A100 for Phi-mini-MoE, A6000 for Phi-tiny-MoE), making them
highly suitable for academic and resource-limited settings. Our experiments
demonstrate that these compressed models outperform others of similar size and
remain competitive with larger models. For instance, Phi-mini-MoE achieves
similar or better performance to Phi-3-mini using only 2/3 of the activated
parameters and yields comparable MMLU scores to Llama 3.1 8B despite having
significantly lower latency. Our findings demonstrate that structured pruning
combined with staged distillation offers an effective path to creating
high-quality, compact MoE models, paving the way for broader adoption of MoE
architectures. We make our models publicly available at
https://huggingface.co/microsoft/Phi-mini-MoE-instruct and
https://huggingface.co/microsoft/Phi-tiny-MoE-instruct .

</details>


### [99] [No Training Wheels: Steering Vectors for Bias Correction at Inference Time](https://arxiv.org/abs/2506.18598)
*Aviral Gupta,Armaan Sethi,Ameesh Sethi*

Main category: cs.LG

TL;DR: 本文提出了一种低成本、无需训练的方法，通过计算多数群体和少数群体之间的平均激活差异来定义“偏见向量”，并将其从模型的残差流中减去，以减少分类偏见并提高最差群体的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的算法和数据驱动方法通常需要重新训练或大量的计算资源，而本文旨在提供一种低成本、无需训练的方法来减轻分类模型中的偏见。

Method: 本文提出了一种基于转向向量的方法，通过计算多数群体和少数群体之间的平均激活差异来定义“偏见向量”，然后从模型的残差流中减去该向量，以减少分类偏见并提高最差群体的准确性。

Result: 实验结果表明，该方法能够有效减少分类偏见，并提高最差群体的准确性。此外，本文还展示了转向向量在分类任务中的有效性。

Conclusion: 本文提出了一种低成本、无需训练的方法，用于减轻分类模型中的偏见。该方法在推理时执行，不需要重新训练或大量计算。

Abstract: Neural network classifiers trained on datasets with uneven group
representation often inherit class biases and learn spurious correlations.
These models may perform well on average but consistently fail on atypical
groups. For example, in hair color classification, datasets may over-represent
females with blond hair, reinforcing stereotypes. Although various algorithmic
and data-centric methods have been proposed to address such biases, they often
require retraining or significant compute. In this work, we propose a cheap,
training-free method inspired by steering vectors used to edit behaviors in
large language models. We compute the difference in mean activations between
majority and minority groups to define a "bias vector," which we subtract from
the model's residual stream. This leads to reduced classification bias and
improved worst-group accuracy. We explore multiple strategies for extracting
and applying these vectors in transformer-like classifiers, showing that
steering vectors, traditionally used in generative models, can also be
effective in classification. More broadly, we showcase an extremely cheap,
inference time, training free method to mitigate bias in classification models.

</details>


### [100] [ReDit: Reward Dithering for Improved LLM Policy Optimization](https://arxiv.org/abs/2506.18631)
*Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu*

Main category: cs.LG

TL;DR: ReDit is a method that adds random noise to discrete rewards to improve the training of large language models by providing exploratory gradients and accelerating convergence.


<details>
  <summary>Details</summary>
Motivation: To address the issues of gradient anomalies, unstable optimization, and slow convergence caused by discrete rewards in rule-based reward systems.

Method: ReDit, a method that dithers the discrete reward signal by adding simple random noise to provide exploratory gradients and encourage exploration of novel policies.

Result: Experiments show that ReDit achieves performance comparable to vanilla GRPO with only 10% of the training steps and still shows a 4% performance improvement over vanilla GRPO when trained for a similar duration. Gradient issues are significantly mitigated with ReDit.

Conclusion: ReDit is an effective and efficient method for improving the training of large language models by mitigating gradient issues and accelerating convergence.

Abstract: DeepSeek-R1 has successfully enhanced Large Language Model (LLM) reasoning
capabilities through its rule-based reward system. While it's a ''perfect''
reward system that effectively mitigates reward hacking, such reward functions
are often discrete. Our experimental observations suggest that discrete rewards
can lead to gradient anomaly, unstable optimization, and slow convergence. To
address this issue, we propose ReDit (Reward Dithering), a method that dithers
the discrete reward signal by adding simple random noise. With this perturbed
reward, exploratory gradients are continuously provided throughout the learning
process, enabling smoother gradient updates and accelerating convergence. The
injected noise also introduces stochasticity into flat reward regions,
encouraging the model to explore novel policies and escape local optima.
Experiments across diverse tasks demonstrate the effectiveness and efficiency
of ReDit. On average, ReDit achieves performance comparable to vanilla GRPO
with only approximately 10% the training steps, and furthermore, still exhibits
a 4% performance improvement over vanilla GRPO when trained for a similar
duration. Visualizations confirm significant mitigation of gradient issues with
ReDit. Moreover, theoretical analyses are provided to further validate these
advantages.

</details>


### [101] [Multi-modal Anchor Gated Transformer with Knowledge Distillation for Emotion Recognition in Conversation](https://arxiv.org/abs/2506.18716)
*Jie Li,Shifei Ding,Lili Guo,Xuan Li*

Main category: cs.LG

TL;DR: 本文提出了MAGTKD模型，用于解决情感识别中的模态表示问题，并在多个数据集上取得了最佳效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了不同模态对任务的贡献差异，并通过在帧级别对齐模态引入了高复杂度。

Method: 提出了一种多模态锚定门控变压器与知识蒸馏（MAGTKD）模型，采用提示学习来增强文本模态表示，利用知识蒸馏来加强较弱模态的表示，并引入多模态锚定门控变压器以有效整合跨模态的句子级表示。

Result: 在IEMOCAP和MELD数据集上的广泛实验表明，知识蒸馏在增强模态表示方面是有效的，并实现了最先进的性能。

Conclusion: 实验结果表明，知识蒸馏在增强模态表示方面是有效的，并在情感识别中实现了最先进的性能。

Abstract: Emotion Recognition in Conversation (ERC) aims to detect the emotions of
individual utterances within a conversation. Generating efficient and
modality-specific representations for each utterance remains a significant
challenge. Previous studies have proposed various models to integrate features
extracted using different modality-specific encoders. However, they neglect the
varying contributions of modalities to this task and introduce high complexity
by aligning modalities at the frame level. To address these challenges, we
propose the Multi-modal Anchor Gated Transformer with Knowledge Distillation
(MAGTKD) for the ERC task. Specifically, prompt learning is employed to enhance
textual modality representations, while knowledge distillation is utilized to
strengthen representations of weaker modalities. Furthermore, we introduce a
multi-modal anchor gated transformer to effectively integrate utterance-level
representations across modalities. Extensive experiments on the IEMOCAP and
MELD datasets demonstrate the effectiveness of knowledge distillation in
enhancing modality representations and achieve state-of-the-art performance in
emotion recognition. Our code is available at:
https://github.com/JieLi-dd/MAGTKD.

</details>


### [102] [Neural Total Variation Distance Estimators for Changepoint Detection in News Data](https://arxiv.org/abs/2506.18764)
*Csaba Zsolnai,Niels Lörch,Julian Arnold*

Main category: cs.LG

TL;DR: 本文提出了一种基于神经网络的变化点检测方法，用于识别新闻数据中公众话语的显著变化。该方法无需大量领域知识，能够自主发现变化点，并提供内容变化的定量度量，适用于新闻业、政策分析和危机监测。


<details>
  <summary>Details</summary>
Motivation: 检测公众话语在重大事件后如何变化对于理解社会动态至关重要。现实世界的数据是高维、稀疏和噪声的，使得这一领域的变化点检测具有挑战性。

Method: 我们利用神经网络进行新闻数据中的变化点检测，引入了一种基于所谓的'通过混淆学习'的方案，该方案最初是为检测物理系统中的相变而开发的。我们训练分类器以区分不同时间段的文章，然后使用分类准确率来估计潜在内容分布之间的总变差距离，显著的距离突出了变化点。

Result: 我们在合成数据集和真实数据上验证了该方法的有效性，成功识别了重大历史事件，如9/11、新冠疫情和总统选举。

Conclusion: 我们的方法在合成数据集和《卫报》的真实数据上得到了验证，成功识别了包括9/11、新冠疫情和总统选举在内的重大历史事件。该方法无需大量领域知识，可以自主发现公众话语中的显著变化，并提供内容变化的定量度量，对新闻业、政策分析和危机监测具有价值。

Abstract: Detecting when public discourse shifts in response to major events is crucial
for understanding societal dynamics. Real-world data is high-dimensional,
sparse, and noisy, making changepoint detection in this domain a challenging
endeavor. In this paper, we leverage neural networks for changepoint detection
in news data, introducing a method based on the so-called learning-by-confusion
scheme, which was originally developed for detecting phase transitions in
physical systems. We train classifiers to distinguish between articles from
different time periods. The resulting classification accuracy is used to
estimate the total variation distance between underlying content distributions,
where significant distances highlight changepoints. We demonstrate the
effectiveness of this method on both synthetic datasets and real-world data
from The Guardian newspaper, successfully identifying major historical events
including 9/11, the COVID-19 pandemic, and presidential elections. Our approach
requires minimal domain knowledge, can autonomously discover significant shifts
in public discourse, and yields a quantitative measure of change in content,
making it valuable for journalism, policy analysis, and crisis monitoring.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [103] [Tutorial: $\varphi$-Transductions in OpenFst via the Gallic Semiring](https://arxiv.org/abs/2506.17942)
*Marco Cognetta,Cyril Allauzen*

Main category: cs.FL

TL;DR: 本文介绍了一种在OpenFst中使用Gallic语义环实现φ-转换的方法，并通过MaxMatch（WordPiece）分词算法进行了演示。


<details>
  <summary>Details</summary>
Motivation: 由于OpenFst的实现限制，φ-转换无法直接用于有限状态转换器，因此需要寻找替代方法来实现它们。

Method: 本文介绍了如何利用OpenFst提供的Gallic语义环功能来实现φ-转换，并通过具体的代码示例进行说明。

Result: 本文成功实现了φ-转换，并通过MaxMatch（WordPiece）分词算法进行了验证，同时提供了自包含的代码示例。

Conclusion: 本文展示了如何使用OpenFst中的Gallic语义环正确实现φ-转换，并通过实现MaxMatch（WordPiece）分词算法进行了演示。

Abstract: OpenFst, a popular finite-state transducer library, supports
$\varphi$-transitions but, due to an implementation constraint, they cannot be
used with transducers in a straightforward way.
  In this short tutorial, we describe how one can use other functionality
provided by OpenFst (namely, the Gallic semiring) to correctly implement
$\varphi$-transductions and demonstrate it by implementing the MaxMatch
(WordPiece) tokenization algorithm (Devlin et al., 2019; Song et al., 2021).
Accompanying self-contained code examples are provided.
https://www.openfst.org/twiki/pub/Contrib/FstContrib/phi_transduction_tutorial_code.tgz

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [104] [PaceLLM: Brain-Inspired Large Language Models for Long-Context Understanding](https://arxiv.org/abs/2506.17310)
*Kangcong Li,Peng Ye,Chongjun Tu,Lin Zhang,Chunfeng Song,Jiamin Wu,Tao Yang,Qihao Zheng,Tao Chen*

Main category: q-bio.NC

TL;DR: PaceLLM 是一种基于大脑工作记忆和皮层模块化的新型大型语言模型优化方法，能够显著提升模型的长上下文性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在长上下文处理方面受到瞬时神经激活导致的信息衰减和非结构化前馈网络权重引起的语义碎片化的限制。因此，需要一种新的方法来改善这一问题。

Method: PaceLLM 引入了两个创新：(1) 持续活动机制，通过引入激活级记忆库来动态检索、重用和更新关键FFN状态，以解决上下文衰减问题；(2) 皮层专家聚类，通过重新组织FFN权重为语义模块来建立跨标记依赖关系，减轻碎片化问题。

Result: PaceLLM 在 LongBench 的多文档问答任务中实现了6%的提升，在 Infinite-Bench 任务中实现了12.5-17.5%的性能提升，并且在 Needle-In-A-Haystack 测试中将可测量的上下文长度扩展到了200K个标记。

Conclusion: PaceLLM 是一种脑启发的大型语言模型优化方法，能够显著提升模型的长上下文性能和可解释性。

Abstract: While Large Language Models (LLMs) demonstrate strong performance across
domains, their long-context capabilities are limited by transient neural
activations causing information decay and unstructured feed-forward network
(FFN) weights leading to semantic fragmentation. Inspired by the brain's
working memory and cortical modularity, we propose PaceLLM, featuring two
innovations: (1) a Persistent Activity (PA) Mechanism that mimics prefrontal
cortex (PFC) neurons' persistent firing by introducing an activation-level
memory bank to dynamically retrieve, reuse, and update critical FFN states,
addressing contextual decay; and (2) Cortical Expert (CE) Clustering that
emulates task-adaptive neural specialization to reorganize FFN weights into
semantic modules, establishing cross-token dependencies and mitigating
fragmentation. Extensive evaluations show that PaceLLM achieves 6% improvement
on LongBench's Multi-document QA and 12.5-17.5% performance gains on
Infinite-Bench tasks, while extending measurable context length to 200K tokens
in Needle-In-A-Haystack (NIAH) tests. This work pioneers brain-inspired LLM
optimization and is complementary to other works. Besides, it can be
generalized to any model and enhance their long-context performance and
interpretability without structural overhauls.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [105] [Zero-Shot Cognitive Impairment Detection from Speech Using AudioLLM](https://arxiv.org/abs/2506.17351)
*Mostafa Shahin,Beena Ahmed,Julien Epps*

Main category: cs.SD

TL;DR: 本文提出了一种基于零样本的语音CI检测方法，利用Qwen2- Audio AudioLLM模型，通过设计基于提示的指令进行分类。结果表明，该方法在性能上与监督方法相当，并在不同语言、任务和数据集之间具有良好的泛化性。


<details>
  <summary>Details</summary>
Motivation: 认知障碍（CI）是日益严重的公共卫生问题，早期检测对于有效的干预至关重要。语音作为一种非侵入性和易于收集的生物标志物，正在获得关注。传统的CI检测方法通常依赖于基于语音的声学和语言特征提取的监督模型，这通常需要手动注释，并且可能在数据集和语言上泛化不佳。

Method: 我们提出了第一个基于零样本的语音CI检测方法，使用Qwen2- Audio AudioLLM模型，该模型能够处理音频和文本输入。通过设计基于提示的指令，我们引导模型将语音样本分类为正常认知或认知障碍的指示。

Result: 我们的方法在两个数据集上进行了评估：一个英文数据集和一个跨语言数据集，涵盖了不同的认知评估任务。结果表明，零样本AudioLLM方法的性能与监督方法相当，并在语言、任务和数据集之间表现出有希望的泛化性和一致性。

Conclusion: 我们的方法在零样本设置下表现出与监督方法相当的性能，并在语言、任务和数据集之间显示出有希望的泛化性和一致性。

Abstract: Cognitive impairment (CI) is of growing public health concern, and early
detection is vital for effective intervention. Speech has gained attention as a
non-invasive and easily collectible biomarker for assessing cognitive decline.
Traditional CI detection methods typically rely on supervised models trained on
acoustic and linguistic features extracted from speech, which often require
manual annotation and may not generalise well across datasets and languages. In
this work, we propose the first zero-shot speech-based CI detection method
using the Qwen2- Audio AudioLLM, a model capable of processing both audio and
text inputs. By designing prompt-based instructions, we guide the model in
classifying speech samples as indicative of normal cognition or cognitive
impairment. We evaluate our approach on two datasets: one in English and
another multilingual, spanning different cognitive assessment tasks. Our
results show that the zero-shot AudioLLM approach achieves performance
comparable to supervised methods and exhibits promising generalizability and
consistency across languages, tasks, and datasets.

</details>


### [106] [AI-Generated Song Detection via Lyrics Transcripts](https://arxiv.org/abs/2506.18488)
*Markus Frohmann,Elena V. Epure,Gabriel Meseguer-Brocal,Markus Schedl,Romain Hennequin*

Main category: cs.SD

TL;DR: 本文提出了一种通过转录歌曲来检测AI生成音乐的方法，该方法在不同语言和流派中表现良好，并且比基于音频的检测器更稳健。


<details>
  <summary>Details</summary>
Motivation: 现有的准确且格式良好的歌词数据在实际应用中不可用，这导致了检测AI生成音乐的适用性存在显著差距。

Method: 我们使用通用自动语音识别（ASR）模型对歌曲进行转录，并使用多种检测器进行分析。

Result: 实验结果表明，我们的方法在多样化的多流派、多语言歌词上表现良好，特别是使用Whisper large-v2和LLM2Vec嵌入的最佳模型。

Conclusion: 我们的方法在不同语言和流派中表现出色，并且比最先进的基于音频的检测器更稳健。

Abstract: The recent rise in capabilities of AI-based music generation tools has
created an upheaval in the music industry, necessitating the creation of
accurate methods to detect such AI-generated content. This can be done using
audio-based detectors; however, it has been shown that they struggle to
generalize to unseen generators or when the audio is perturbed. Furthermore,
recent work used accurate and cleanly formatted lyrics sourced from a lyrics
provider database to detect AI-generated music. However, in practice, such
perfect lyrics are not available (only the audio is); this leaves a substantial
gap in applicability in real-life use cases. In this work, we instead propose
solving this gap by transcribing songs using general automatic speech
recognition (ASR) models. We do this using several detectors. The results on
diverse, multi-genre, and multi-lingual lyrics show generally strong detection
performance across languages and genres, particularly for our best-performing
model using Whisper large-v2 and LLM2Vec embeddings. In addition, we show that
our method is more robust than state-of-the-art audio-based ones when the audio
is perturbed in different ways and when evaluated on different music
generators. Our code is available at
https://github.com/deezer/robust-AI-lyrics-detection.

</details>


### [107] [Smooth Operators: LLMs Translating Imperfect Hints into Disfluency-Rich Transcripts](https://arxiv.org/abs/2506.18510)
*Duygu Altinok*

Main category: cs.SD

TL;DR: 本文提出了一种新方法，将口语中的不流畅作为带有时间戳的显式标记进行转录，以生成完全注释的不流畅丰富转录本。通过结合音频编码器的声学表示与不同质量的文本输入，实验表明即使文本输入不完美，大型语言模型也能有效处理并生成完整的不流畅标注转录本。


<details>
  <summary>Details</summary>
Motivation: 准确检测口语中的不流畅对于提高自动语音和语言处理系统的性能以及促进更包容的语音和语言技术的发展至关重要。利用大型语言模型（LLMs）作为能够处理词汇和非词汇输入（如音频和视频）的多功能学习者的趋势，我们提出了一个新方法。

Method: 我们提出了一种新方法，将话语不流畅作为带有时间戳的显式标记进行转录，从而生成完全注释的话语丰富转录本。该方法结合了从音频编码器中提取的声学表示与不同质量的文本输入：没有话语不流畅的干净转录本、对齐器的时间对齐转录本或基于音素的自动语音识别（ASR）模型的输出——所有这些都可能有缺陷。

Result: 我们的实验表明，文本输入不需要完美。只要它们包含与时间戳相关的提示，大型语言模型就可以有效地平滑输入并生成完全带有话语不流畅标注的转录本，这突显了它们在处理不完美提示时的鲁棒性。

Conclusion: 我们的实验表明，文本输入不需要完美。只要它们包含与时间戳相关的提示，大型语言模型就可以有效地平滑输入并生成完全带有话语不流畅标注的转录本，这突显了它们在处理不完美提示时的鲁棒性。

Abstract: Accurate detection of disfluencies in spoken language is crucial for
enhancing the performance of automatic speech and language processing systems,
as well as fostering the development of more inclusive speech and language
technologies. Leveraging the growing trend of large language models (LLMs) as
versatile learners capable of processing both lexical and non-lexical inputs
(e.g., audio and video), we propose a novel approach to transcribing
disfluencies as explicit tokens with timestamps, enabling the generation of
fully annotated disfluency-rich transcripts. Our method integrates acoustic
representations extracted from an audio encoder with textual inputs of varying
quality: clean transcriptions without disfluencies, time-aligned transcriptions
from aligners, or outputs from phoneme-based ASR models -- all of which may
contain imperfections. Importantly, our experiments demonstrate that textual
inputs do not need to be flawless. As long as they include timestamp-related
cues, LLMs can effectively smooth the input and produce fully
disfluency-annotated transcripts, underscoring their robustness in handling
imperfect hints.

</details>


### [108] [USAD: Universal Speech and Audio Representation via Distillation](https://arxiv.org/abs/2506.18843)
*Heng-Jui Chang,Saurabhchand Bhati,James Glass,Alexander H. Liu*

Main category: cs.SD

TL;DR: USAD is a unified approach to audio representation learning that integrates diverse audio types into a single model, offering competitive performance across various benchmarks.


<details>
  <summary>Details</summary>
Motivation: Self-supervised learning (SSL) has revolutionized audio representations, yet models often remain domain-specific, focusing on either speech or non-speech tasks.

Method: USAD employs efficient layer-to-layer distillation from domain-specific SSL models to train a student on a comprehensive audio dataset.

Result: USAD offers competitive performance across various benchmarks and datasets, including frame and instance-level speech processing tasks, audio tagging, and sound classification, achieving near state-of-the-art results with a single encoder on SUPERB and HEAR benchmarks.

Conclusion: USAD offers competitive performance across various benchmarks and datasets, including frame and instance-level speech processing tasks, audio tagging, and sound classification, achieving near state-of-the-art results with a single encoder on SUPERB and HEAR benchmarks.

Abstract: Self-supervised learning (SSL) has revolutionized audio representations, yet
models often remain domain-specific, focusing on either speech or non-speech
tasks. In this work, we present Universal Speech and Audio Distillation (USAD),
a unified approach to audio representation learning that integrates diverse
audio types - speech, sound, and music - into a single model. USAD employs
efficient layer-to-layer distillation from domain-specific SSL models to train
a student on a comprehensive audio dataset. USAD offers competitive performance
across various benchmarks and datasets, including frame and instance-level
speech processing tasks, audio tagging, and sound classification, achieving
near state-of-the-art results with a single encoder on SUPERB and HEAR
benchmarks.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [109] [SlimRAG: Retrieval without Graphs via Entity-Aware Context Selection](https://arxiv.org/abs/2506.17288)
*Jiale Zhang,Jiaxiang Chen,Zhucong Li,Jie Ding,Kui Zhao,Zenglin Xu,Xin Pang,Yinghui Xu*

Main category: cs.IR

TL;DR: SlimRAG是一种轻量级框架，用于在不使用图的情况下进行检索，通过实体感知机制提高检索效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图的RAG系统存在结构开销和检索不准确的问题，因为语义相似性并不意味着语义相关性。

Method: SlimRAG使用实体感知机制替代了结构密集型组件，通过构建紧凑的实体到块表进行索引，并在查询时识别显著实体、检索和评分相关块。

Result: 实验表明，SlimRAG在准确性方面优于平坦和基于图的基线，同时减少了索引大小和RITU。

Conclusion: SlimRAG展示了无需结构的实体中心上下文选择的价值，并在多个QA基准测试中优于强基线。

Abstract: Retrieval-Augmented Generation (RAG) enhances language models by
incorporating external knowledge at inference time. However, graph-based RAG
systems often suffer from structural overhead and imprecise retrieval: they
require costly pipelines for entity linking and relation extraction, yet
frequently return subgraphs filled with loosely related or tangential content.
This stems from a fundamental flaw -- semantic similarity does not imply
semantic relevance. We introduce SlimRAG, a lightweight framework for retrieval
without graphs. SlimRAG replaces structure-heavy components with a simple yet
effective entity-aware mechanism. At indexing time, it constructs a compact
entity-to-chunk table based on semantic embeddings. At query time, it
identifies salient entities, retrieves and scores associated chunks, and
assembles a concise, contextually relevant input -- without graph traversal or
edge construction. To quantify retrieval efficiency, we propose Relative Index
Token Utilization (RITU), a metric measuring the compactness of retrieved
content. Experiments across multiple QA benchmarks show that SlimRAG
outperforms strong flat and graph-based baselines in accuracy while reducing
index size and RITU (e.g., 16.31 vs. 56+), highlighting the value of
structure-free, entity-centric context selection. The code will be released
soon. https://github.com/continue-ai-company/SlimRAG

</details>


### [110] [Enhancing Document Retrieval in COVID-19 Research: Leveraging Large Language Models for Hidden Relation Extraction](https://arxiv.org/abs/2506.18311)
*Hoang-An Trieu,Dinh-Truong Do,Chau Nguyen,Vu Tran,Minh Le Nguyen*

Main category: cs.IR

TL;DR: 本文提出了一种基于大型语言模型的方法，用于改进检索系统，以在突发疫情时提供更高质量的搜索结果。


<details>
  <summary>Details</summary>
Motivation: 由于大量出版物的出现，需要一个高效的检索系统，以便在突发疫情（如COVID-19）时为研究人员提供有用信息。

Method: 本文利用大型语言模型（LLMs）的力量，提取未标记出版物中的隐藏关系，这些关系无法被当前系统使用的解析工具发现。

Result: 通过利用大型语言模型的力量，系统能够获得更多的有用信息，从而提高检索效果。

Conclusion: 本文提出了一种方法，即Covrelex-SE系统，以帮助检索系统提供更高质量的搜索结果。

Abstract: In recent years, with the appearance of the COVID-19 pandemic, numerous
publications relevant to this disease have been issued. Because of the massive
volume of publications, an efficient retrieval system is necessary to provide
researchers with useful information if an unexpected pandemic happens so
suddenly, like COVID-19. In this work, we present a method to help the
retrieval system, the Covrelex-SE system, to provide more high-quality search
results. We exploited the power of the large language models (LLMs) to extract
the hidden relationships inside the unlabeled publication that cannot be found
by the current parsing tools that the system is using. Since then, help the
system to have more useful information during retrieval progress.

</details>


### [111] [Team LA at SCIDOCA shared task 2025: Citation Discovery via relation-based zero-shot retrieval](https://arxiv.org/abs/2506.18316)
*Trieu An,Long Nguyen,Minh Le Nguyen*

Main category: cs.IR

TL;DR: 本文提出了一种基于关系特征提取和大型语言模型的引文预测框架，以解决摘要段落长和候选摘要相似度高的问题。


<details>
  <summary>Details</summary>
Motivation: 该任务的主要挑战来自于摘要段落的长度和候选摘要之间的高度相似性，这使得确定要引用的确切论文变得困难。

Method: 我们开发了一个系统，首先根据从给定段落中提取的关系特征检索前k个最相似的摘要。然后，我们利用大型语言模型（LLM）准确识别最相关的引文。

Result: 我们的框架在SCIDOCA 2025组织者提供的训练数据集上进行了评估，证明了其在引文预测中的有效性。

Conclusion: 我们的框架在SCIDOCA 2025组织者提供的训练数据集上进行了评估，证明了其在引文预测中的有效性。

Abstract: The Citation Discovery Shared Task focuses on predicting the correct citation
from a given candidate pool for a given paragraph. The main challenges stem
from the length of the abstract paragraphs and the high similarity among
candidate abstracts, making it difficult to determine the exact paper to cite.
To address this, we develop a system that first retrieves the top-k most
similar abstracts based on extracted relational features from the given
paragraph. From this subset, we leverage a Large Language Model (LLM) to
accurately identify the most relevant citation. We evaluate our framework on
the training dataset provided by the SCIDOCA 2025 organizers, demonstrating its
effectiveness in citation prediction.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [112] [Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models](https://arxiv.org/abs/2506.17585)
*Yukun Huang,Sanxing Chen,Jian Pei,Manzil Zaheer,Bhuwan Dhingra*

Main category: cs.AI

TL;DR: 本文探讨了如何通过修改训练过程，使语言模型能够在不依赖测试时检索的情况下，可靠地引用在预训练期间看到的文档。我们提出了主动索引方法，该方法通过持续预训练于合成问答对来提高引用精度，并在实验中取得了显著的成果。


<details>
  <summary>Details</summary>
Motivation: 可信的语言模型应提供既正确又可验证的答案。尽管语言模型有时可以将输出归因于预训练数据，但它们的引用通常不可靠，因为存在幻觉。因此，当前系统在推理时通过查询外部检索器来插入引用，这引入了延迟、基础设施依赖性和对检索噪声的易感性。我们探索是否可以通过修改训练过程，使LLM能够可靠地引用在(持续)预训练期间看到的文档——而无需测试时检索。

Method: 我们提出了一种两阶段过程：(1) 持续预训练以将事实与持久的文档标识符绑定，以及(2) 指令微调以引发引用行为。我们还提出了主动索引，它持续预训练于合成问答对，这些问答对(1) 以多样化的组合形式重述每个事实，并且(2) 需要双向的源到事实和事实到源生成，共同教授模型从引用的来源生成内容并为其答案归因。

Result: 我们的实验表明，主动索引在所有任务和模型中都优于被动索引，引用精度的提升高达30.2%。消融研究显示，随着增强数据量的增加，性能继续提高，即使在原始标记计数的16倍时也显示出明显的上升趋势。

Conclusion: 我们的实验表明，主动索引在所有任务和模型中都优于被动索引，引用精度的提升高达30.2%。消融研究显示，随着增强数据量的增加，性能继续提高，即使在原始标记计数的16倍时也显示出明显的上升趋势。

Abstract: Trustworthy language models should provide both correct and verifiable
answers. While language models can sometimes attribute their outputs to
pretraining data, their citations are often unreliable due to hallucination. As
a result, current systems insert citations by querying an external retriever at
inference time, introducing latency, infrastructure dependence, and
vulnerability to retrieval noise. We explore whether LLMs can be made to
reliably attribute to the documents seen during (continual)
pretraining--without test-time retrieval--by revising the training process. To
evaluate this, we release CitePretrainBench, a benchmark that mixes real-world
corpora (Wikipedia, Common Crawl, arXiv) with novel, unseen documents and
probes both short-form (single fact) and long-form (multi-fact) citation tasks.
Our approach follows a two-stage process: (1) continual pretraining to bind
facts to persistent document identifiers, and (2) instruction tuning to elicit
citation behavior. We find that simple Passive Indexing, which appends an
identifier to each document, helps memorize verbatim text but fails on
paraphrased or compositional facts. Instead, we propose Active Indexing, which
continually pretrains on synthetic QA pairs that (1) restate each fact in
diverse compositional forms, and (2) require bidirectional source-to-fact and
fact-to-source generation, jointly teaching the model to generate content from
a cited source and to attribute its own answers. Experiments with Qwen2.5-7B
and 3B show that Active Indexing consistently outperforms Passive Indexing
across all tasks and models, with citation precision gains up to 30.2 percent.
Our ablation studies reveal that performance continues to improve as we scale
the amount of augmented data, showing a clear upward trend even at 16 times the
original token count.

</details>


### [113] [Bayesian Social Deduction with Graph-Informed Language Models](https://arxiv.org/abs/2506.17788)
*Shahab Rahimirad,Guven Gergerli,Lucia Romero,Angela Qian,Matthew Lyle Olson,Simon Stepputtis,Joseph Campbell*

Main category: cs.AI

TL;DR: 本文提出了一种混合推理框架，通过将信念推断外部化到结构化的概率模型中，同时利用LLM进行语言理解和交互，以解决社会推理任务中的挑战。该方法在Agent-Agent对战中表现出色，并在受控研究中击败了人类玩家。


<details>
  <summary>Details</summary>
Motivation: 社会推理——从其他代理的部分观察中推断不可见的信念和意图——仍然是大型语言模型（LLMs）的一个具有挑战性的任务。当前的推理语言模型在社交推理任务中的表现有限，需要大量的测试时间推理，并且在压缩为更小、实时能力的变体时性能会急剧下降。

Method: 我们引入了一种混合推理框架，将信念推断外部化到结构化的概率模型中，同时使用LLM进行语言理解和交互。

Result: 我们的方法在Agent-Agent对战中表现出与更大模型相当的性能，并且是第一个在受控研究中击败人类玩家的语言代理，取得了67%的胜率并获得了比推理基线和人类队友更高的定性评价。

Conclusion: 我们的方法在Agent-Agent对战中表现出与更大模型相当的性能，并且是第一个在受控研究中击败人类玩家的语言代理，取得了67%的胜率并获得了比推理基线和人类队友更高的定性评价。

Abstract: Social reasoning - inferring unobservable beliefs and intentions from partial
observations of other agents - remains a challenging task for large language
models (LLMs). We evaluate the limits of current reasoning language models in
the social deduction game Avalon and find that while the largest models
demonstrate strong performance, they require extensive test-time inference and
degrade sharply when distilled to smaller, real-time-capable variants. To
address this, we introduce a hybrid reasoning framework that externalizes
belief inference to a structured probabilistic model, while using an LLM for
language understanding and interaction. Our approach achieves competitive
performance with much larger models in Agent-Agent play and, notably, is the
first language agent to defeat human players in a controlled study - achieving
a 67% win rate and receiving higher qualitative ratings than both reasoning
baselines and human teammates. We release code, models, and a dataset to
support future work on social reasoning in LLM agents, which can be found at
https://camp-lab-purdue.github.io/bayesian-social-deduction/

</details>


### [114] [Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective](https://arxiv.org/abs/2506.17930)
*Jianyu Wang,Zhiqiang Hu,Lidong Bing*

Main category: cs.AI

TL;DR: 本文提出了一种新的提示设计范式，挑战了大型语言模型（LLM）提示的传统观念。通过修剪随机演示成看似无意义的“胡言乱语”，可以显著提高性能。我们提出了一个自我发现的提示优化框架PromptQuine，该框架通过仅使用低数据制度自动搜索修剪策略。我们证明了其在多种任务中的有效性，并希望这能指导机制研究并推动更开放的搜索算法的发展。


<details>
  <summary>Details</summary>
Motivation: 传统智慧优先考虑精心设计的指令和演示用于上下文学习（ICL），但我们展示了修剪随机演示成看似无意义的“胡言乱语”可以显著提高在各种任务中的性能。然而，发现有效的修剪策略并不容易，因为现有的归因方法和提示压缩算法无法产生稳健的结果，更不用说人类直觉了。

Method: 我们提出了一个自我发现的提示优化框架，即PromptQuine，这是一个进化搜索框架，通过仅使用低数据制度自动搜索修剪策略。

Result: 我们在分类、多选问题回答、生成和数学推理任务中证明了其有效性，同时实现了不错的运行时效率。

Conclusion: 我们希望我们的发现能够指导对上下文学习的机制研究，并提供一个行动呼吁，为更开放的搜索算法铺平道路，以实现更有效的LLM提示。

Abstract: We propose a novel prompt design paradigm that challenges conventional wisdom
in large language model (LLM) prompting. While conventional wisdom prioritizes
well-crafted instructions and demonstrations for in-context learning (ICL), we
show that pruning random demonstrations into seemingly incoherent "gibberish"
can remarkably improve performance across diverse tasks. Notably, the
"gibberish" always matches or surpasses state-of-the-art automatic prompt
optimization techniques, achieving substantial gains regardless of LLM
alignment. Nevertheless, discovering an effective pruning strategy is
non-trivial, as existing attribution methods and prompt compression algorithms
fail to deliver robust results, let alone human intuition. In terms of this, we
propose a self-discover prompt optimization framework, PromptQuine, an
evolutionary search framework that automatically searches for the pruning
strategy by itself using only low-data regimes. Much like the emergent
complexity in nature--such as symbiosis and self-organization--arising in
response to resource constraints, our framework evolves and refines
unconventional yet highly effective prompts by leveraging only the tokens
present within the context. We demonstrate its effectiveness across
classification, multi-choice question answering, generation and math reasoning
tasks across LLMs, while achieving decent runtime efficiency. We hope our
findings can guide mechanistic studies on in-context learning, and provide a
call to action, to pave the way for more open-ended search algorithms for more
effective LLM prompting.

</details>


### [115] [SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging](https://arxiv.org/abs/2506.18135)
*Zijun Chen,Zhanpeng Zhou,Bo Zhang,Weinan Zhang,Xi Sun,Junchi Yan*

Main category: cs.AI

TL;DR: This paper explores the mechanism behind model merging and proposes SE-Merging, a framework that enhances multi-task abilities by dynamically identifying tasks and adapting merging coefficients.


<details>
  <summary>Details</summary>
Motivation: Model merging has gained attention due to its ability to interpolate parameters of different task-specific fine-tuned models, leading to multi-task abilities. However, the underlying mechanisms remain poorly understood.

Method: The paper analyzes the mechanism behind model merging from a representation perspective and proposes SE-Merging, a self-enhanced model merging framework that leverages two key capabilities: distinguishing samples from different tasks and adapting to the corresponding expert model for each sample.

Result: SE-Merging achieves significant performance improvements while remaining compatible with existing model merging techniques.

Conclusion: SE-Merging achieves dynamic model merging without additional training and significantly improves performance while remaining compatible with existing model merging techniques.

Abstract: Model merging has gained increasing attention due to its intriguing property:
interpolating the parameters of different task-specific fine-tuned models leads
to multi-task abilities. However, despite its empirical success, the underlying
mechanisms of model merging remain poorly understood. In this work, we delve
into the mechanism behind model merging from a representation perspective. Our
analysis reveals that model merging achieves multi-task abilities through two
key capabilities: i) distinguishing samples from different tasks, and ii)
adapting to the corresponding expert model for each sample. These two
capabilities allow the merged model to retain task-specific expertise, enabling
efficient multi-task adaptation. Building on these insights, we propose
\texttt{SE-Merging}, a self-enhanced model merging framework that leverages
these two characteristics to dynamically identify the corresponding task for
each sample and then adaptively rescales the merging coefficients to further
enhance task-specific expertise in the merged model. Notably,
\texttt{SE-Merging} achieves dynamic model merging without additional training.
Extensive experiments demonstrate that \texttt{SE-Merging} achieves significant
performance improvements while remaining compatible with existing model merging
techniques.

</details>


### [116] [Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?](https://arxiv.org/abs/2506.18183)
*Zhiting Mei,Christina Zhang,Tenny Yin,Justin Lidard,Ola Shorinwa,Anirudha Majumdar*

Main category: cs.AI

TL;DR: 本文研究了推理模型的不确定性量化，发现它们通常过度自信，并且可以通过自我反思来改善校准。


<details>
  <summary>Details</summary>
Motivation: 了解何时以及在多大程度上信任这些模型对于在现实世界应用中安全部署推理模型至关重要。

Method: 本文探讨了推理模型的不确定性量化（UQ），引入了自我反思的UQ方法，并在多个最先进的推理模型上进行了广泛评估。

Result: 研究发现，推理模型通常是过度自信的，随着更深层次的推理，它们变得更加过度自信，但通过自我反思可以改善校准，但并非总是如此。

Conclusion: 最后，我们提出了重要的研究方向，以设计必要的不确定性量化（UQ）基准并改进推理模型的校准。

Abstract: Reasoning language models have set state-of-the-art (SOTA) records on many
challenging benchmarks, enabled by multi-step reasoning induced using
reinforcement learning. However, like previous language models, reasoning
models are prone to generating confident, plausible responses that are
incorrect (hallucinations). Knowing when and how much to trust these models is
critical to the safe deployment of reasoning models in real-world applications.
To this end, we explore uncertainty quantification of reasoning models in this
work. Specifically, we ask three fundamental questions: First, are reasoning
models well-calibrated? Second, does deeper reasoning improve model
calibration? Finally, inspired by humans' innate ability to double-check their
thought processes to verify the validity of their answers and their confidence,
we ask: can reasoning models improve their calibration by explicitly reasoning
about their chain-of-thought traces? We introduce introspective uncertainty
quantification (UQ) to explore this direction. In extensive evaluations on SOTA
reasoning models across a broad range of benchmarks, we find that reasoning
models: (i) are typically overconfident, with self-verbalized confidence
estimates often greater than 85% particularly for incorrect responses, (ii)
become even more overconfident with deeper reasoning, and (iii) can become
better calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not
uniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we
conclude with important research directions to design necessary UQ benchmarks
and improve the calibration of reasoning models.

</details>


### [117] [Airalogy: AI-empowered universal data digitization for research automation](https://arxiv.org/abs/2506.18586)
*Zijie Yang,Qiji Zhou,Fang Guo,Sijie Zhang,Yexun Xi,Jinglei Nie,Yudian Zhu,Liping Huang,Chou Wu,Yonghe Xia,Xiaoyu Ma,Yingming Pu,Panzhong Lu,Junshu Pan,Mingtao Chen,Tiannan Guo,Yanmei Dou,Hongyu Chen,Anping Zeng,Jiaxing Huang,Tian Xu,Yue Zhang*

Main category: cs.AI

TL;DR: Airalogy is a new AI- and community-driven platform designed to balance universality and standardization for digitizing research data across multiple disciplines.


<details>
  <summary>Details</summary>
Motivation: Current AI applications remain limited to a few fields with readily available, well-structured, digitized datasets. Achieving comprehensive AI empowerment across multiple disciplines is still out of reach. Present-day research data collection is often fragmented, lacking unified standards, inefficiently managed, and difficult to share.

Method: Developing Airalogy, the world's first AI- and community-driven platform that balances universality and standardization for digitizing research data across multiple disciplines.

Result: Airalogy represents entire research workflows using customizable, standardized data records and offers an advanced AI research copilot for intelligent Q&A, automated data entry, analysis, and research automation. It has already been deployed in laboratories across all four schools of Westlake University.

Conclusion: Airalogy has the potential to accelerate and automate scientific innovation in universities, industry, and the global research community, ultimately benefiting humanity as a whole.

Abstract: Research data are the foundation of Artificial Intelligence (AI)-driven
science, yet current AI applications remain limited to a few fields with
readily available, well-structured, digitized datasets. Achieving comprehensive
AI empowerment across multiple disciplines is still out of reach. Present-day
research data collection is often fragmented, lacking unified standards,
inefficiently managed, and difficult to share. Creating a single platform for
standardized data digitization needs to overcome the inherent challenge of
balancing between universality (supporting the diverse, ever-evolving needs of
various disciplines) and standardization (enforcing consistent formats to fully
enable AI). No existing platform accommodates both facets. Building a truly
multidisciplinary platform requires integrating scientific domain knowledge
with sophisticated computing skills. Researchers often lack the computational
expertise to design customized and standardized data recording methods, whereas
platform developers rarely grasp the intricate needs of multiple scientific
domains. These gaps impede research data standardization and hamper AI-driven
progress. In this study, we address these challenges by developing Airalogy
(https://airalogy.com), the world's first AI- and community-driven platform
that balances universality and standardization for digitizing research data
across multiple disciplines. Airalogy represents entire research workflows
using customizable, standardized data records and offers an advanced AI
research copilot for intelligent Q&A, automated data entry, analysis, and
research automation. Already deployed in laboratories across all four schools
of Westlake University, Airalogy has the potential to accelerate and automate
scientific innovation in universities, industry, and the global research
community-ultimately benefiting humanity as a whole.

</details>


### [118] [AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs](https://arxiv.org/abs/2506.18628)
*Piotr Matys,Jan Eliasz,Konrad Kiełczyński,Mikołaj Langner,Teddy Ferdinan,Jan Kocoń,Przemysław Kazienko*

Main category: cs.AI

TL;DR: 本文介绍了AggTruth，一种通过分析提供的上下文（段落）中的内部注意力分数分布来在线检测上下文幻觉的方法。AggTruth在相同任务和跨任务设置中表现出稳定的性能，并在多个场景中优于当前最先进的方法。研究还表明，仔细选择注意力头对于获得最佳结果至关重要。


<details>
  <summary>Details</summary>
Motivation: Large Language Models (LLMs) often hallucinate, even in Retrieval-Augmented Generation (RAG) settings, which poses a significant challenge to their deployment.

Method: AggTruth is a method for online detection of contextual hallucinations by analyzing the distribution of internal attention scores in the provided context (passage). Four variants of the method were proposed, each varying in the aggregation technique used to calculate attention scores.

Result: AggTruth demonstrated stable performance in both same-task and cross-task setups, outperforming the current SOTA in multiple scenarios. The study also showed that careful selection of attention heads is essential to achieve optimal results.

Conclusion: AggTruth demonstrated stable performance in both same-task and cross-task setups, outperforming the current SOTA in multiple scenarios. Careful selection of attention heads is essential to achieve optimal results.

Abstract: In real-world applications, Large Language Models (LLMs) often hallucinate,
even in Retrieval-Augmented Generation (RAG) settings, which poses a
significant challenge to their deployment. In this paper, we introduce
AggTruth, a method for online detection of contextual hallucinations by
analyzing the distribution of internal attention scores in the provided context
(passage). Specifically, we propose four different variants of the method, each
varying in the aggregation technique used to calculate attention scores. Across
all LLMs examined, AggTruth demonstrated stable performance in both same-task
and cross-task setups, outperforming the current SOTA in multiple scenarios.
Furthermore, we conducted an in-depth analysis of feature selection techniques
and examined how the number of selected attention heads impacts detection
performance, demonstrating that careful selection of heads is essential to
achieve optimal results.

</details>


### [119] [Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training](https://arxiv.org/abs/2506.18777)
*Jonathan Cook,Silvia Sapora,Arash Ahmadian,Akbir Khan,Tim Rocktaschel,Jakob Foerster,Laura Ruis*

Main category: cs.AI

TL;DR: 本文研究了在源代码上训练大型语言模型如何提升其推理能力。通过实验发现，模型可以在不依赖输入输出示例的情况下评估程序，并且代码形式的程序表现更好。这表明代码训练有助于模型内化可重用的算法抽象。


<details>
  <summary>Details</summary>
Motivation: 尽管在源代码上训练大型语言模型可以显著提高其通用推理能力，但这种泛化的机制尚不清楚。本文旨在探讨一种可能的驱动因素——通过反向传播进行编程（PBB），即在仅使用源代码的情况下训练模型评估程序，而无需看到输入输出示例。

Method: 我们通过微调大型语言模型在两组程序上进行实验，一组包含源代码和输入输出示例（w/ IO），另一组仅包含源代码（w/o IO）。我们评估了模型在不同实验设置下对w/o IO程序的评估能力，并比较了两种方法的效果。

Result: 我们发现大型语言模型在多种实验设置下能够评估没有输入输出示例的程序。此外，PBB在程序以代码形式提供时效果更好，模型可以直接通过前向传递隐式评估程序，并且在通过思维链逐步评估程序时更加可靠。PBB还比基于自然数据分布的输入输出对训练更稳健。

Conclusion: 我们的研究结果表明，通过代码训练可以增强大型语言模型的推理能力，因为它允许模型内化可重用的算法抽象。未来的研究需要进一步探索如何让大型语言模型更有效地从符号过程学习，并且这一方向的进步可能为通过训练正式宪法原则来实现模型对齐提供新的途径。

Abstract: Training large language models (LLMs) on source code significantly enhances
their general-purpose reasoning abilities, but the mechanisms underlying this
generalisation are poorly understood. In this paper, we propose Programming by
Backprop (PBB) as a potential driver of this effect - teaching a model to
evaluate a program for inputs by training on its source code alone, without
ever seeing I/O examples. To explore this idea, we finetune LLMs on two sets of
programs representing simple maths problems and algorithms: one with source
code and I/O examples (w/ IO), the other with source code only (w/o IO). We
find evidence that LLMs have some ability to evaluate w/o IO programs for
inputs in a range of experimental settings, and make several observations.
Firstly, PBB works significantly better when programs are provided as code
rather than semantically equivalent language descriptions. Secondly, LLMs can
produce outputs for w/o IO programs directly, by implicitly evaluating the
program within the forward pass, and more reliably when stepping through the
program in-context via chain-of-thought. We further show that PBB leads to more
robust evaluation of programs across inputs than training on I/O pairs drawn
from a distribution that mirrors naturally occurring data. Our findings suggest
a mechanism for enhanced reasoning through code training: it allows LLMs to
internalise reusable algorithmic abstractions. Significant scope remains for
future work to enable LLMs to more effectively learn from symbolic procedures,
and progress in this direction opens other avenues like model alignment by
training on formal constitutional principles.

</details>


### [120] [ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation](https://arxiv.org/abs/2506.18810)
*Siao Tang,Xinyin Ma,Gongfan Fang,Xinchao Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为ConciseHint的框架，通过在推理生成过程中注入文本提示来鼓励模型简洁表达，从而减少推理长度并保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有文献主要遵循在推理前的范式，如提示和推理或微调和推理，但忽略了在推理生成过程中直接鼓励模型简洁表达的有前景的方向。

Method: 我们提出了一个名为ConciseHint的框架，通过在推理过程的标记生成期间注入文本提示（手动设计或在简洁数据上训练）来持续鼓励推理模型简洁地表达。此外，ConciseHint通过自适应调整提示强度来适应查询的复杂性，确保不会损害模型性能。

Result: 实验表明，我们的方法在最先进的LRMs（包括DeepSeek-R1和Qwen-3系列）上能够有效生成简洁的推理过程，同时保持良好的性能。例如，在GSM8K基准测试中，使用Qwen-3 4B时，推理长度减少了65%，几乎没有任何准确率损失。

Conclusion: 我们的方法能够在保持性能的同时有效生成简洁的推理过程。例如，在GSM8K基准测试中，我们实现了65%的推理长度减少率，几乎没有任何准确率损失。

Abstract: Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and
OpenAI o1 series have achieved notable performance enhancements on complex
reasoning tasks by scaling up the generation length by Chain-of-Thought (CoT).
However, an emerging issue is their inclination to produce excessively verbose
reasoning processes, leading to the inefficiency problem. Existing literature
on improving efficiency mainly adheres to the before-reasoning paradigms such
as prompting and reasoning or fine-tuning and reasoning, but ignores the
promising direction of directly encouraging the model to speak concisely by
intervening during the generation of reasoning. In order to fill the blank, we
propose a framework dubbed ConciseHint, which continuously encourages the
reasoning model to speak concisely by injecting the textual hint (manually
designed or trained on the concise data) during the token generation of the
reasoning process. Besides, ConciseHint is adaptive to the complexity of the
query by adaptively adjusting the hint intensity, which ensures it will not
undermine model performance. Experiments on the state-of-the-art LRMs,
including DeepSeek-R1 and Qwen-3 series, demonstrate that our method can
effectively produce concise reasoning processes while maintaining performance
well. For instance, we achieve a reduction ratio of 65\% for the reasoning
length on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.

</details>


### [121] [jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval](https://arxiv.org/abs/2506.18902)
*Michael Günther,Saba Sturua,Mohammad Kalim Akram,Isabelle Mohr,Andrei Ungureanu,Sedigheh Eslami,Scott Martens,Bo Wang,Nan Wang,Han Xiao*

Main category: cs.AI

TL;DR: jina-embeddings-v4是一个38亿参数的多模态嵌入模型，通过一种新型架构统一了文本和图像表示，并支持晚期交互风格的单向量和多向量嵌入。该模型在各种检索任务中表现出色，特别是处理视觉丰富的内容。


<details>
  <summary>Details</summary>
Motivation: 为了在各种检索场景中优化性能，包括基于查询的信息检索、跨模态语义相似性和编程代码搜索，需要一个能够统一文本和图像表示的多模态嵌入模型。

Method: 引入了jina-embeddings-v4，这是一个包含38亿参数的多模态嵌入模型，通过一种新型架构统一了文本和图像表示，并支持晚期交互风格的单向量和多向量嵌入。此外，模型还集成了任务特定的低秩适应（LoRA）适配器以优化不同检索场景的性能。

Result: jina-embeddings-v4在单模态和跨模态检索任务中均达到了最先进的性能，尤其是在处理视觉丰富的内容如表格、图表、图表和混合媒体格式方面表现出色。

Conclusion: jina-embeddings-v4在单模态和跨模态检索任务中均达到了最先进水平，特别是在处理视觉丰富的内容方面表现出色。

Abstract: We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding
model that unifies text and image representations through a novel architecture
supporting both single-vector and multi-vector embeddings in the late
interaction style. The model incorporates task-specific Low-Rank Adaptation
(LoRA) adapters to optimize performance across diverse retrieval scenarios,
including query-based information retrieval, cross-modal semantic similarity,
and programming code search. Comprehensive evaluations demonstrate that
jina-embeddings-v4 achieves state-of-the-art performance on both single- modal
and cross-modal retrieval tasks, with particular strength in processing
visually rich content such as tables, charts, diagrams, and mixed-media
formats. To facilitate evaluation of this capability, we also introduce
Jina-VDR, a novel benchmark specifically designed for visually rich image
retrieval.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [122] [The Democratic Paradox in Large Language Models' Underestimation of Press Freedom](https://arxiv.org/abs/2506.18045)
*I. Loaiza,R. Vestrelli,A. Fronzetti Colladon,R. Rigobon*

Main category: cs.CY

TL;DR: This study reveals that LLMs systematically underestimate global press freedom, with some showing home bias, raising concerns about their role in shaping public perception of democratic institutions.


<details>
  <summary>Details</summary>
Motivation: To uncover systematic distortions in how LLMs evaluate press freedom and highlight the potential impact on public understanding and trust in democratic institutions.

Method: The study evaluates the press freedom assessments of six popular LLMs against expert assessments from the World Press Freedom Index (WPFI).

Result: The six LLMs exhibit a negative misalignment, underestimating press freedom, with some models rating their home countries more favorably than expected.

Conclusion: LLMs must ensure accurate representations of the state of human and civic rights globally if they are to become the next search engines and important cultural tools.

Abstract: As Large Language Models (LLMs) increasingly mediate global information
access for millions of users worldwide, their alignment and biases have the
potential to shape public understanding and trust in fundamental democratic
institutions, such as press freedom. In this study, we uncover three systematic
distortions in the way six popular LLMs evaluate press freedom in 180 countries
compared to expert assessments of the World Press Freedom Index (WPFI). The six
LLMs exhibit a negative misalignment, consistently underestimating press
freedom, with individual models rating between 71% to 93% of countries as less
free. We also identify a paradoxical pattern we term differential misalignment:
LLMs disproportionately underestimate press freedom in countries where it is
strongest. Additionally, five of the six LLMs exhibit positive home bias,
rating their home countries' press freedoms more favorably than would be
expected given their negative misalignment with the human benchmark. In some
cases, LLMs rate their home countries between 7% to 260% more positively than
expected. If LLMs are set to become the next search engines and some of the
most important cultural tools of our time, they must ensure accurate
representations of the state of our human and civic rights globally.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [123] [Beyond Prediction -- Structuring Epistemic Integrity in Artificial Reasoning Systems](https://arxiv.org/abs/2506.17331)
*Craig Steven Wright*

Main category: cs.LO

TL;DR: 本文提出了一种新的人工智能系统框架，能够在严格的认识论约束下运行，并支持结构化推理、命题承诺和矛盾检测。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能系统主要依赖于随机语言预测，缺乏结构化推理和矛盾检测能力，因此需要一种新的框架来解决这些问题。

Method: 该论文通过形式化信念表示、元认知过程和规范验证，结合符号推理、知识图谱和基于区块链的论证，实现了真理保持、可审计的理性认识代理。

Result: 该论文成功开发了一个能够支持结构化推理、命题承诺和矛盾检测的人工智能系统框架。

Conclusion: 该论文提出了一个全面的框架，用于在严格认识论约束下运行的人工智能系统，旨在支持结构化推理、命题承诺和矛盾检测。

Abstract: This paper develops a comprehensive framework for artificial intelligence
systems that operate under strict epistemic constraints, moving beyond
stochastic language prediction to support structured reasoning, propositional
commitment, and contradiction detection. It formalises belief representation,
metacognitive processes, and normative verification, integrating symbolic
inference, knowledge graphs, and blockchain-based justification to ensure
truth-preserving, auditably rational epistemic agents.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [124] [Shrinking the Generation-Verification Gap with Weak Verifiers](https://arxiv.org/abs/2506.18203)
*Jon Saad-Falcon,E. Kelly Buchanan,Mayee F. Chen,Tzu-Heng Huang,Brendan McLaughlin,Tanvir Bhathal,Shang Zhu,Ben Athiwaratkun,Frederic Sala,Scott Linderman,Azalia Mirhoseini,Christopher Ré*

Main category: cs.CR

TL;DR: Weaver是一种框架，用于设计一个强验证器，通过结合多个弱验证器来提高性能，并减少对标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前高质量的验证器要么不可扩展（如人类），要么在实用性上有限（如Lean等工具）。LM法官和奖励模型虽然作为通用验证器很有用，但与理想验证器之间仍存在显著的性能差距。

Method: Weaver通过结合多个弱验证器来设计一个强大的验证器，利用弱监督估计每个验证器的准确性，并结合输出以生成统一的评分。

Result: Weaver在测试时重复采样中显著优于Pass@1性能，在推理和数学任务中选择第一个候选者，达到了o3-mini级别的准确率，使用Llama 3.3 70B Instruct作为生成器，以及70B或更小的法官和奖励模型作为验证器（平均87.7%）。

Conclusion: Weaver显著提高了验证器的性能，使其接近理想验证器的准确性，并且在计算成本上有所降低。

Abstract: Verifiers can improve language model capabilities by scoring and ranking
responses from generated candidates. Currently, high-quality verifiers are
either unscalable (e.g., humans) or limited in utility (e.g., tools like Lean).
While LM judges and reward models have become broadly useful as general-purpose
verifiers, a significant performance gap remains between them and oracle
verifiers (verifiers with perfect accuracy). To help close this gap, we
introduce Weaver, a framework for designing a strong verifier by combining
multiple weak, imperfect verifiers. We find weighted ensembles of verifiers,
which typically require learning from labeled data, significantly outperform
unweighted combinations due to differences in verifier accuracies. To reduce
dependency on labeled data, Weaver leverages weak supervision to estimate each
verifier's accuracy and combines outputs into a unified score that better
reflects true response quality. However, directly applying weak supervision
algorithms poses challenges, including inconsistent verifier output formats and
handling low-quality verifiers. Weaver addresses these using dataset statistics
to normalize outputs and filter specific verifiers. We study Weaver's
effectiveness in test-time repeated sampling, where a model generates multiple
candidate responses and selects one. Our evaluations show Weaver significantly
improves over Pass@1-performance when selecting the first candidate-across
reasoning and math tasks, achieving o3-mini-level accuracy with Llama 3.3 70B
Instruct as generator, and an ensemble of 70B or smaller judge and reward
models as verifiers (87.7% average). This gain mirrors the jump between GPT-4o
and o3-mini (69.0% vs. 86.7%), which required extensive finetuning and
post-training. To reduce computational costs of verifier ensembles, we train a
400M cross-encoder using Weaver's combined output scores.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [125] [RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation](https://arxiv.org/abs/2506.18088)
*Tianxing Chen,Zanxin Chen,Baijun Chen,Zijian Cai,Yibin Liu,Qiwei Liang,Zixuan Li,Xianliang Lin,Yiheng Ge,Zhenyu Gu,Weiliang Deng,Yubin Guo,Tian Nian,Xuanbing Xie,Qiangyu Chen,Kailun Su,Tianling Xu,Guodong Liu,Mengkang Hu,Huan-ang Gao,Kaixuan Wang,Zhixuan Liang,Yusen Qin,Xiaokang Yang,Ping Luo,Yao Mu*

Main category: cs.RO

TL;DR: 本文提出了一种名为RoboTwin 2.0的可扩展仿真框架，用于增强机器人双臂操作。该框架通过结合多模态大语言模型和结构化领域随机化，能够自动生成多样且现实的数据，并在多个任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的合成数据集在稳健的双臂操作方面仍然不足，因为存在两个挑战：(1) 缺乏一种高效、可扩展的数据生成方法用于新任务，(2) 过于简化的仿真环境未能捕捉现实世界的复杂性。

Method: 我们提出了RoboTwin 2.0，这是一个可扩展的仿真框架，能够自动、大规模生成多样且现实的数据，并提供统一的双臂操作评估协议。我们构建了RoboTwin-OD，一个包含731个实例的大型物体库，每个实例都带有语义和操作相关标签。我们开发了一个专家数据合成管道，结合多模态大语言模型（MLLM）与仿真循环优化来自动生成任务级执行代码。为了提高模拟到现实的转移效果，RoboTwin 2.0在五个轴上引入了结构化领域随机化：杂乱程度、照明、背景、桌面高度和语言指令。

Result: 实证结果表明，在代码生成成功方面有10.9%的提升，并且在新的现实场景中表现出更好的泛化能力。在我们的数据集上微调的VLA模型在未见过的现实场景任务中实现了367%的相对改进（42.0% vs. 9.0%），而仅在我们的合成数据上训练的零样本模型实现了228%的相对增益，这表明在没有现实世界监督的情况下具有强大的泛化能力。

Conclusion: 我们释放了数据生成器、基准测试、数据集和代码，以支持在稳健双臂操作方面的可扩展研究。

Abstract: Simulation-based data synthesis has emerged as a powerful paradigm for
enhancing real-world robotic manipulation. However, existing synthetic datasets
remain insufficient for robust bimanual manipulation due to two challenges: (1)
the lack of an efficient, scalable data generation method for novel tasks, and
(2) oversimplified simulation environments that fail to capture real-world
complexity. We present RoboTwin 2.0, a scalable simulation framework that
enables automated, large-scale generation of diverse and realistic data, along
with unified evaluation protocols for dual-arm manipulation. We first construct
RoboTwin-OD, a large-scale object library comprising 731 instances across 147
categories, each annotated with semantic and manipulation-relevant labels.
Building on this foundation, we develop an expert data synthesis pipeline that
combines multimodal large language models (MLLMs) with simulation-in-the-loop
refinement to generate task-level execution code automatically. To improve
sim-to-real transfer, RoboTwin 2.0 incorporates structured domain randomization
along five axes: clutter, lighting, background, tabletop height and language
instructions, thereby enhancing data diversity and policy robustness. We
instantiate this framework across 50 dual-arm tasks spanning five robot
embodiments, and pre-collect over 100,000 domain-randomized expert
trajectories. Empirical results show a 10.9% gain in code generation success
and improved generalization to novel real-world scenarios. A VLA model
fine-tuned on our dataset achieves a 367% relative improvement (42.0% vs. 9.0%)
on unseen scene real-world tasks, while zero-shot models trained solely on our
synthetic data achieve a 228% relative gain, highlighting strong generalization
without real-world supervision. We release the data generator, benchmark,
dataset, and code to support scalable research in robust bimanual manipulation.

</details>
