<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 37]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.RO](#cs.RO) [Total: 2]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.CV](#cs.CV) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Noise or Nuance: An Investigation Into Useful Information and Filtering For LLM Driven AKBC](https://arxiv.org/abs/2509.08903)
*Alex Clay,Ernesto Jiménez-Ruiz,Pranava Madhyastha*

Main category: cs.CL

TL;DR: 本文研究了在受限设置下三元组完成任务的三个方面，发现额外信息能提高生成质量，LLM能有效过滤低质量三元组，且灵活性与一致性之间的权衡取决于设置。


<details>
  <summary>Details</summary>
Motivation: RAG和微调是提高LLM输出质量的常见策略，但在受限情况下（如2025 LM-KBC挑战）这些技术受到限制。

Method: 研究了三元组完成任务的三个方面：生成、质量保证和LLM响应解析。

Result: 额外信息可以提高生成质量，LLM可以有效地过滤低质量三元组，并且LLM响应解析的灵活性与一致性之间的权衡取决于设置。

Conclusion: 在受限设置中，额外信息可以提高生成质量，LLM可以有效地过滤低质量三元组，并且LLM响应解析的灵活性与一致性之间的权衡取决于设置。

Abstract: RAG and fine-tuning are prevalent strategies for improving the quality of LLM
outputs. However, in constrained situations, such as that of the 2025 LM-KBC
challenge, such techniques are restricted. In this work we investigate three
facets of the triple completion task: generation, quality assurance, and LLM
response parsing. Our work finds that in this constrained setting: additional
information improves generation quality, LLMs can be effective at filtering
poor quality triples, and the tradeoff between flexibility and consistency with
LLM response parsing is setting dependent.

</details>


### [2] [Automated Evidence Extraction and Scoring for Corporate Climate Policy Engagement: A Multilingual RAG Approach](https://arxiv.org/abs/2509.08907)
*Imene Kolli,Ario Saeid Vaghefi,Chiara Colesanti Senni,Shantam Raj,Markus Leippold*

Main category: cs.CL

TL;DR: 本文提出了一种AI辅助框架，利用检索增强生成来自动化从大规模文本数据中提取相关证据的过程，结果表明该方法在多语言企业文档中表现最佳，但需要人类专家的参与以确保准确性。


<details>
  <summary>Details</summary>
Motivation: InfluenceMap的LobbyMap平台在监测企业气候政策参与方面取得了进展，但评估的大部分仍然手动进行，耗时且容易出错。

Method: 我们提出了一种AI辅助框架，利用检索增强生成来自动化从大规模文本数据中提取相关证据的过程。

Result: 布局感知解析、Nomic嵌入模型和少量提示策略的组合在从多语言企业文档中提取和分类证据方面表现最佳。

Conclusion: 虽然自动化RAG系统有效地加速了证据提取，但分析的细微性质需要一种人机结合的方法，其中技术增强而非取代专家判断以确保准确性。

Abstract: InfluenceMap's LobbyMap Platform monitors the climate policy engagement of
over 500 companies and 250 industry associations, assessing each entity's
support or opposition to science-based policy pathways for achieving the Paris
Agreement's goal of limiting global warming to 1.5{\deg}C. Although
InfluenceMap has made progress with automating key elements of the analytical
workflow, a significant portion of the assessment remains manual, making it
time- and labor-intensive and susceptible to human error. We propose an
AI-assisted framework to accelerate the monitoring of corporate climate policy
engagement by leveraging Retrieval-Augmented Generation to automate the most
time-intensive extraction of relevant evidence from large-scale textual data.
Our evaluation shows that a combination of layout-aware parsing, the Nomic
embedding model, and few-shot prompting strategies yields the best performance
in extracting and classifying evidence from multilingual corporate documents.
We conclude that while the automated RAG system effectively accelerates
evidence extraction, the nuanced nature of the analysis necessitates a
human-in-the-loop approach where the technology augments, rather than replaces,
expert judgment to ensure accuracy.

</details>


### [3] [Documents Are People and Words Are Items: A Psychometric Approach to Textual Data with Contextual Embeddings](https://arxiv.org/abs/2509.08920)
*Jinsong Chen*

Main category: cs.CL

TL;DR: 该研究提出了一种新的心理测量方法，利用大型语言模型分析文本数据。通过上下文嵌入生成上下文分数，并使用因子分析提取潜在因子。实验结果表明该方法能够揭示文本数据中的潜在知识维度和模式。


<details>
  <summary>Details</summary>
Motivation: 该研究引入了一种新的心理测量方法，用于使用大型语言模型分析文本数据。通过利用上下文嵌入创建上下文分数，将文本数据转换为适合心理测量分析的响应数据。

Method: 该方法包括两个阶段：获取上下文分数和进行心理测量分析。在第一阶段，利用自然语言处理技术和基于编码器的变压器模型来识别常见关键词并生成上下文分数。在第二阶段，采用各种类型的因子分析，包括探索性和双因子模型，以提取和定义潜在因子，确定因子相关性，并识别与每个因子相关的最重要词语。

Result: 应用于Wiki STEM语料库，实验结果展示了该方法揭示文本数据中的潜在知识维度和模式的潜力。

Conclusion: 该方法不仅增强了文本数据的心理测量分析，而且在教育、心理学和法律等领域丰富的文本信息应用中具有前景。

Abstract: This research introduces a novel psychometric method for analyzing textual
data using large language models. By leveraging contextual embeddings to create
contextual scores, we transform textual data into response data suitable for
psychometric analysis. Treating documents as individuals and words as items,
this approach provides a natural psychometric interpretation under the
assumption that certain keywords, whose contextual meanings vary significantly
across documents, can effectively differentiate documents within a corpus. The
modeling process comprises two stages: obtaining contextual scores and
performing psychometric analysis. In the first stage, we utilize natural
language processing techniques and encoder based transformer models to identify
common keywords and generate contextual scores. In the second stage, we employ
various types of factor analysis, including exploratory and bifactor models, to
extract and define latent factors, determine factor correlations, and identify
the most significant words associated with each factor. Applied to the Wiki
STEM corpus, our experimental results demonstrate the method's potential to
uncover latent knowledge dimensions and patterns within textual data. This
approach not only enhances the psychometric analysis of textual data but also
holds promise for applications in fields rich in textual information, such as
education, psychology, and law.

</details>


### [4] [BRoverbs -- Measuring how much LLMs understand Portuguese proverbs](https://arxiv.org/abs/2509.08960)
*Thales Sales Almeida,Giovana Kerche Bonás,João Guilherme Alves Santos*

Main category: cs.CL

TL;DR: 本文介绍了BRoverbs数据集，用于评估大语言模型在葡萄牙语环境下的表现，填补了现有评估的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的葡萄牙语评估有限，通常依赖于翻译的数据集，无法充分捕捉语言细微差别或文化参考。同时，本地葡萄牙语数据集主要集中在结构化的国家考试或社交媒体互动的情感分析上，缺乏对更广泛语言理解的评估。

Method: 引入BRoverbs数据集，通过巴西谚语评估大语言模型的表现。

Result: BRoverbs数据集可以作为评估大语言模型在特定地区设置下能力的新工具。

Conclusion: BRoverbs旨在为葡萄牙语大语言模型提供一个新的评估工具，有助于推动区域相关的基准测试。

Abstract: Large Language Models (LLMs) exhibit significant performance variations
depending on the linguistic and cultural context in which they are applied.
This disparity signals the necessity of mature evaluation frameworks that can
assess their capabilities in specific regional settings. In the case of
Portuguese, existing evaluations remain limited, often relying on translated
datasets that may not fully capture linguistic nuances or cultural references.
Meanwhile, native Portuguese-language datasets predominantly focus on
structured national exams or sentiment analysis of social media interactions,
leaving gaps in evaluating broader linguistic understanding. To address this
limitation, we introduce BRoverbs, a dataset specifically designed to assess
LLM performance through Brazilian proverbs. Proverbs serve as a rich linguistic
resource, encapsulating cultural wisdom, figurative expressions, and complex
syntactic structures that challenge the model comprehension of regional
expressions. BRoverbs aims to provide a new evaluation tool for
Portuguese-language LLMs, contributing to advancing regionally informed
benchmarking. The benchmark is available at
https://huggingface.co/datasets/Tropic-AI/BRoverbs.

</details>


### [5] [Can Vision-Language Models Solve Visual Math Equations?](https://arxiv.org/abs/2509.09013)
*Monjoy Narayan Choudhury,Junling Wang,Yifan Hou,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 研究显示VLMs在视觉方程求解中存在计数和多步骤推理的挑战，这指出了未来改进的方向。


<details>
  <summary>Details</summary>
Motivation: 研究VLMs在需要整合感知和符号计算的任务中的表现，特别是视觉方程求解。

Method: 通过分解任务为系数计数和变量识别，研究了VLMs在视觉方程求解中的局限性。

Result: VLMs在文本方程上表现良好，但在视觉基础的方程上失败。计数是主要瓶颈，即使识别准确。组合识别和推理引入了额外错误，复杂度增加时符号推理成为限制因素。

Conclusion: 这些发现揭示了当前VLMs的关键弱点，并指出了在视觉基础数学推理方面的未来改进方向。

Abstract: Despite strong performance in visual understanding and language-based
reasoning, Vision-Language Models (VLMs) struggle with tasks requiring
integrated perception and symbolic computation. We study this limitation
through visual equation solving, where mathematical equations are embedded in
images, variables are represented by object icons, and coefficients must be
inferred by counting. While VLMs perform well on textual equations, they fail
on visually grounded counterparts. To understand this gap, we decompose the
task into coefficient counting and variable recognition, and find that counting
is the primary bottleneck, even when recognition is accurate. We also observe
that composing recognition and reasoning introduces additional errors,
highlighting challenges in multi-step visual reasoning. Finally, as equation
complexity increases, symbolic reasoning itself becomes a limiting factor.
These findings reveal key weaknesses in current VLMs and point toward future
improvements in visually grounded mathematical reasoning.

</details>


### [6] [Stated Preference for Interaction and Continued Engagement (SPICE): Evaluating an LLM's Willingness to Re-engage in Conversation](https://arxiv.org/abs/2509.09043)
*Thomas Manuel Rost,Martina Figlia,Bernd Wallraff*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce and evaluate Stated Preference for Interaction and Continued
Engagement (SPICE), a simple diagnostic signal elicited by asking a Large
Language Model a YES or NO question about its willingness to re-engage with a
user's behavior after reviewing a short transcript. In a study using a 3-tone
(friendly, unclear, abusive) by 10-interaction stimulus set, we tested four
open-weight chat models across four framing conditions, resulting in 480
trials. Our findings show that SPICE sharply discriminates by user tone.
Friendly interactions yielded a near-unanimous preference to continue (97.5%
YES), while abusive interactions yielded a strong preference to discontinue
(17.9% YES), with unclear interactions falling in between (60.4% YES). This
core association remains decisive under multiple dependence-aware statistical
tests, including Rao-Scott adjustment and cluster permutation tests.
Furthermore, we demonstrate that SPICE provides a distinct signal from abuse
classification. In trials where a model failed to identify abuse, it still
overwhelmingly stated a preference not to continue the interaction (81% of the
time). An exploratory analysis also reveals a significant interaction effect: a
preamble describing the study context significantly impacts SPICE under
ambiguity, but only when transcripts are presented as a single block of text
rather than a multi-turn chat. The results validate SPICE as a robust,
low-overhead, and reproducible tool for auditing model dispositions,
complementing existing metrics by offering a direct, relational signal of a
model's state. All stimuli, code, and analysis scripts are released to support
replication.

</details>


### [7] [Improving LLM Safety and Helpfulness using SFT and DPO: A Study on OPT-350M](https://arxiv.org/abs/2509.09055)
*Piyush Pant*

Main category: cs.CL

TL;DR: 本研究评估了SFT、DPO及其组合方法在提升语言模型安全性和帮助性方面的效果，发现结合SFT和DPO的模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在评估不同的对齐技术在提高语言模型的安全性和帮助性方面的有效性，并探索它们的互补性。

Method: 本研究使用了Anthropic Helpful-Harmless RLHF数据集，对OPT-350M语言模型进行了监督微调（SFT）、直接偏好优化（DPO）以及结合SFT和DPO的方法进行训练和评估。

Result: 研究结果表明，虽然SFT在大多数指标上优于DPO，但结合SFT和DPO的模型在所有指标上都表现最佳，证明了这些技术的互补性。

Conclusion: 本研究展示了SFT和DPO技术在提高语言模型的安全性和帮助性方面的互补性，并指出了未来工作中的挑战和方向。

Abstract: This research investigates the effectiveness of alignment techniques,
Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and a
combined SFT+DPO approach on improving the safety and helpfulness of the
OPT-350M language model. Utilizing the Anthropic Helpful-Harmless RLHF dataset,
we train and evaluate four models: the base OPT350M, an SFT model, a DPO model,
and a model trained with both SFT and DPO. We introduce three key evaluation
metrics: Harmlessness Rate (HmR), Helpfulness Rate (HpR), and a Combined
Alignment Score (CAS), all derived from reward model outputs. The results show
that while SFT outperforms DPO, The combined SFT+DPO model outperforms all
others across all metrics, demonstrating the complementary nature of these
techniques. Our findings also highlight challenges posed by noisy data, limited
GPU resources, and training constraints. This study offers a comprehensive view
of how fine-tuning strategies affect model alignment and provides a foundation
for more robust alignment pipelines in future work.

</details>


### [8] [MR-UIE: Multi-Perspective Reasoning with Reinforcement Learning for Universal Information Extraction](https://arxiv.org/abs/2509.09082)
*Zhongqiu Li,Shiquan Wang,Ruiyu Fang,Mengjiao Bao,Zhenhe Wu,Shuangyong Song,Yongxiang Li,Zhongjiang He*

Main category: cs.CL

TL;DR: 本文提出了一种结合强化学习和多视角推理的方法，以提高大型语言模型在信息抽取任务中的性能和泛化能力。实验结果表明，该方法在多个基准上表现优异，尤其是在复杂任务中展现出更强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的方法虽然通过上下文学习和指令调优提高了LLMs的性能，但在处理涉及复杂模式描述和需要多步骤推理的结构化输出场景时，性能仍然不足。因此，需要一种新的方法来增强模型的泛化能力。

Method: 本文提出将强化学习（RL）与多视角推理相结合，以提升信息抽取（IE）任务中大型语言模型（LLMs）的泛化能力。通过这种方法，LLMs从被动的抽取器转变为积极的推理者，不仅理解要抽取什么，还理解如何推理。

Result: 在多个信息抽取基准上的实验表明，MR-UIE在不同领域内 consistently 提高了抽取准确性，并在一些数据集上超越了最先进的方法。此外，将多视角推理纳入强化学习显著增强了复杂信息抽取任务的泛化能力。

Conclusion: 实验结果表明，MR-UIE在多个信息抽取基准上 consistently 提高了抽取准确性，并在一些数据集上超越了最先进的方法。此外，将多视角推理纳入强化学习显著增强了复杂信息抽取任务的泛化能力，突显了推理在挑战性场景中的关键作用。

Abstract: Large language models (LLMs) demonstrate robust capabilities across diverse
research domains. However, their performance in universal information
extraction (UIE) remains insufficient, especially when tackling structured
output scenarios that involve complex schema descriptions and require
multi-step reasoning. While existing approaches enhance the performance of LLMs
through in-context learning and instruction tuning, significant limitations
nonetheless persist. To enhance the model's generalization ability, we propose
integrating reinforcement learning (RL) with multi-perspective reasoning for
information extraction (IE) tasks. Our work transitions LLMs from passive
extractors to active reasoners, enabling them to understand not only what to
extract but also how to reason. Experiments conducted on multiple IE benchmarks
demonstrate that MR-UIE consistently elevates extraction accuracy across
domains and surpasses state-of-the-art methods on several datasets.
Furthermore, incorporating multi-perspective reasoning into RL notably enhances
generalization in complex IE tasks, underscoring the critical role of reasoning
in challenging scenarios.

</details>


### [9] [TigerCoder: A Novel Suite of LLMs for Code Generation in Bangla](https://arxiv.org/abs/2509.09101)
*Nishat Raihan,Antonios Anastasopoulos,Marcos Zampieri*

Main category: cs.CL

TL;DR: 本文介绍了第一个针对孟加拉语的代码大语言模型家族（1B & 9B），并提供了三个主要贡献：(1) 一个全面的孟加拉语代码指令数据集，用于编程领域适应；(2) MBPP-Bangla，一个评估孟加拉语代码生成的基准测试；(3) TigerCoder家族的代码大语言模型，在Pass@1上比现有的多语言和通用孟加拉语大语言模型取得了显著的~11-18%性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管孟加拉语是第五大语言，但在大型语言模型（LLMs）中，特别是在代码生成方面仍然代表性不足。这主要是由于缺乏高质量的数据来进行预训练和/或微调这些模型。

Method: 我们引入了第一个针对孟加拉语的代码大语言模型家族（1B & 9B），并提供了三个主要贡献：(1) 一个全面的孟加拉语代码指令数据集，用于编程领域适应；(2) MBPP-Bangla，一个评估孟加拉语代码生成的基准测试；(3) TigerCoder家族的代码大语言模型，在Pass@1上比现有的多语言和通用孟加拉语大语言模型取得了显著的~11-18%性能提升。

Result: TigerCoder家族的代码大语言模型在Pass@1上比现有的多语言和通用孟加拉语大语言模型取得了显著的~11-18%性能提升。

Conclusion: 我们的研究结果表明，精心整理的高质量数据集可以克服小模型在低资源语言上的局限性。我们开源了所有资源，以推动进一步的孟加拉语大语言模型研究。

Abstract: Despite being the 5th most spoken language, Bangla remains underrepresented
in Large Language Models (LLMs), particularly for code generation. This
primarily stems from the scarcity of high-quality data to pre-train and/or
finetune such models. Hence, we introduce the first dedicated family of Code
LLMs for Bangla (1B & 9B). We offer three major contributions: (1) a
comprehensive Bangla code instruction datasets for programming domain
adaptation; (2) MBPP-Bangla, an evaluation benchmark for Bangla code
generation; and (3) the TigerCoder-family of Code LLMs, achieving significant
~11-18% performance gains at Pass@1 over existing multilingual and
general-purpose Bangla LLMs. Our findings show that curated, high-quality
datasets can overcome limitations of smaller models for low-resource languages.
We open-source all resources to advance further Bangla LLM research.

</details>


### [10] [Compass-v3: Scaling Domain-Specific LLMs for Multilingual E-Commerce in Southeast Asia](https://arxiv.org/abs/2509.09121)
*Sophia Maria*

Main category: cs.CL

TL;DR: Compass-v3 is a vertical-domain Mixture-of-Experts (MoE) model designed for Southeast Asian e-commerce, featuring 245B total parameters and 71B active per token. It outperforms existing models in e-commerce tasks and exhibits strong multilingual capabilities across low-resource Southeast Asian languages and Portuguese.


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) excel in general-domain applications, yet their performance often degrades in specialized tasks requiring domain-specific knowledge. E-commerce is particularly challenging, as its data are noisy, heterogeneous, multilingual, and highly dynamic.

Method: Compass-v3 is a vertical-domain Mixture-of-Experts (MoE) model with 245B total parameters and 71B active per token, designed for Southeast Asian e-commerce. It adopts fewer but larger experts, combined with hardware-efficient optimizations such as intra-node expert parallelism and a customized memcpy operator. The model is trained on 12T tokens of curated multilingual corpora and large-scale synthetic e-commerce instructions using a mixed-training strategy. To enhance alignment, we propose Optimal-Transport Direct Preference Optimization (OTPO), which captures token-level distinctions and improves instruction adherence in commerce-specific scenarios.

Result: Extensive evaluations demonstrate that Compass-v3 delivers state-of-the-art e-commerce performance, surpassing DeepSeek-V3.1, GPT-4 series, and Qwen3-235B. Moreover, Compass-v3 demonstrates strong multilingual capability across low-resource Southeast Asian languages (Indonesian, Thai, Filipino, Vietnamese, Malay, Taglog) and Portuguese while sustaining competitive performance on general benchmarks.

Conclusion: Compass-v3 demonstrates strong multilingual capability across low-resource Southeast Asian languages and Portuguese while sustaining competitive performance on general benchmarks. It has already been widely applied in Shopee's industrial-scale e-commerce platform and is gradually replacing OpenAI's traffic, now accounting for over 70% of total LLM usage, highlighting its dual strengths in specialized commerce expertise and broad linguistic competence.

Abstract: Large language models (LLMs) excel in general-domain applications, yet their
performance often degrades in specialized tasks requiring domain-specific
knowledge. E-commerce is particularly challenging, as its data are noisy,
heterogeneous, multilingual, and highly dynamic. We present Compass-v3, a
vertical-domain Mixture-of-Experts (MoE) model with 245B total parameters and
71B active per token, designed for Southeast Asian e-commerce. Compass-v3
adopts fewer but larger experts, combined with hardware-efficient
optimizations-such as intra-node expert parallelism and a customized memcpy
operator-to maximize GPU utilization. The model is trained on 12T tokens of
curated multilingual corpora and large-scale synthetic e-commerce instructions
using a mixed-training strategy. To enhance alignment, we propose
Optimal-Transport Direct Preference Optimization (OTPO), which captures
token-level distinctions and improves instruction adherence in
commerce-specific scenarios. Extensive evaluations demonstrate that Compass-v3
delivers state-of-the-art e-commerce performance, surpassing DeepSeek-V3.1,
GPT-4 series, and Qwen3-235B. Moreover, Compass-v3 demonstrates strong
multilingual capability across low-resource Southeast Asian languages
(Indonesian, Thai, Filipino, Vietnamese, Malay, Taglog) and Portuguese while
sustaining competitive performance on general benchmarks. It has already been
widely applied in Shopee's industrial-scale e-commerce platform and is
gradually replacing OpenAI's traffic, now accounting for over 70\% of total LLM
usage, highlighting its dual strengths in specialized commerce expertise and
broad linguistic competence.

</details>


### [11] [Automated Classification of Tutors' Dialogue Acts Using Generative AI: A Case Study Using the CIMA Corpus](https://arxiv.org/abs/2509.09125)
*Liqun He,Jiaqi Xu*

Main category: cs.CL

TL;DR: 本研究探讨了生成式AI在自动化分类导师对话行为中的应用，结果表明GPT-4模型在准确性和一致性方面表现优异，显示出生成式AI在教育对话分析中的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索生成式AI在自动化分类导师对话行为（DAs）中的应用，以减少传统手动编码所需的时间和精力。

Method: 本研究使用了开源的CIMA语料库，其中导师的回答已被预标注为四个DA类别。测试了GPT-3.5-turbo和GPT-4模型，并使用了定制的提示。

Result: GPT-4模型达到了80%的准确率、加权F1分数0.81和Cohen's Kappa 0.74，超过了基线性能，表明与人类标注有显著的一致性。

Conclusion: 研究结果表明，生成式AI在DA分类中具有巨大的潜力，可以提供一种高效且可访问的方法，并对教育对话分析有重要意义。同时，研究也强调了任务特定的标签定义和上下文信息在提高自动化注释质量中的重要性，并突出了与生成式AI使用相关的伦理考虑和负责任的研究实践的必要性。

Abstract: This study explores the use of generative AI for automating the
classification of tutors' Dialogue Acts (DAs), aiming to reduce the time and
effort required by traditional manual coding. This case study uses the
open-source CIMA corpus, in which tutors' responses are pre-annotated into four
DA categories. Both GPT-3.5-turbo and GPT-4 models were tested using tailored
prompts. Results show that GPT-4 achieved 80% accuracy, a weighted F1-score of
0.81, and a Cohen's Kappa of 0.74, surpassing baseline performance and
indicating substantial agreement with human annotations. These findings suggest
that generative AI has strong potential to provide an efficient and accessible
approach to DA classification, with meaningful implications for educational
dialogue analysis. The study also highlights the importance of task-specific
label definitions and contextual information in enhancing the quality of
automated annotation. Finally, it underscores the ethical considerations
associated with the use of generative AI and the need for responsible and
transparent research practices. The script of this research is publicly
available at
https://github.com/liqunhe27/Generative-AI-for-educational-dialogue-act-tagging.

</details>


### [12] [ViRanker: A BGE-M3 & Blockwise Parallel Transformer Cross-Encoder for Vietnamese Reranking](https://arxiv.org/abs/2509.09131)
*Phuong-Nam Dang,Kieu-Linh Nguyen,Thanh-Hieu Pham*

Main category: cs.CL

TL;DR: 本文介绍了ViRanker，这是一个专为越南语设计的交叉编码器重排序模型，通过精心的架构调整和数据整理，在性能上取得了显著进展。


<details>
  <summary>Details</summary>
Motivation: 针对越南语缺乏有竞争力的重排序模型的问题，越南语是一种资源较少的语言，具有复杂的语法和变音符号。

Method: ViRanker基于BGE-M3编码器并增强了Blockwise Parallel Transformer，使用8 GB的精心整理语料库进行训练，并通过混合硬负采样进行微调以增强鲁棒性。

Result: ViRanker在MMARCO-VI基准测试中表现出色，早期排名准确性优于多语言基线，并与PhoRanker竞争激烈。

Conclusion: 通过在Hugging Face上公开模型，我们旨在支持可重复性和鼓励在实际检索系统中的更广泛应用。此外，本研究展示了如何通过仔细的架构适应和数据整理来推进其他未被充分代表语言的排序。

Abstract: This paper presents ViRanker, a cross-encoder reranking model tailored to the
Vietnamese language. Built on the BGE-M3 encoder and enhanced with the
Blockwise Parallel Transformer, ViRanker addresses the lack of competitive
rerankers for Vietnamese, a low-resource language with complex syntax and
diacritics. The model was trained on an 8 GB curated corpus and fine-tuned with
hybrid hard-negative sampling to strengthen robustness. Evaluated on the
MMARCO-VI benchmark, ViRanker achieves strong early-rank accuracy, surpassing
multilingual baselines and competing closely with PhoRanker. By releasing the
model openly on Hugging Face, we aim to support reproducibility and encourage
wider adoption in real-world retrieval systems. Beyond Vietnamese, this study
illustrates how careful architectural adaptation and data curation can advance
reranking in other underrepresented languages.

</details>


### [13] [LITcoder: A General-Purpose Library for Building and Comparing Encoding Models](https://arxiv.org/abs/2509.09152)
*Taha Binhuraib,Ruimin Gao,Anna A. Ivanova*

Main category: cs.CL

TL;DR: LITcoder是一个开源库，用于构建和基准测试神经编码模型。它提供了一套标准化工具，用于对齐连续刺激与脑数据，将刺激转换为表征特征，将这些特征映射到脑数据，并评估模型在保留数据上的预测性能。该库实现了模块化流程，涵盖了广泛的方法设计选择，使研究人员可以轻松组合、比较和扩展编码模型而不必重新发明核心基础设施。


<details>
  <summary>Details</summary>
Motivation: 为了降低编码模型实现的技术障碍，促进模型和数据集之间的系统比较，促进方法严谨性，并加速高质量高性能预测模型的开发，作者提出了LITcoder。

Method: LITcoder是一个开源库，用于构建和基准测试神经编码模型。它提供了一套标准化工具，用于对齐连续刺激（如文本和语音）与脑数据，将刺激转换为表征特征，将这些特征映射到脑数据，并评估模型在保留数据上的预测性能。该库实现了模块化流程，涵盖了广泛的方法设计选择，使研究人员可以轻松组合、比较和扩展编码模型而不必重新发明核心基础设施。

Result: 作者通过将各种编码模型拟合到三个故事聆听数据集（LeBel等人，2023年；Narratives；Little Prince）来展示框架的可扩展性和多功能性。他们还探讨了构建连续fMRI数据编码模型的关键方法选择，说明了考虑TR扫描中的所有标记的重要性，包括血流动力学滞后效应，使用最小化信息泄漏的训练-测试分割，以及考虑头部运动对编码模型预测性的影响。

Conclusion: LITcoder降低了编码模型实现的技术障碍，促进了模型和数据集之间的系统比较，促进了方法严谨性，并加速了高质量高性能脑活动预测模型的开发。

Abstract: We introduce LITcoder, an open-source library for building and benchmarking
neural encoding models. Designed as a flexible backend, LITcoder provides
standardized tools for aligning continuous stimuli (e.g., text and speech) with
brain data, transforming stimuli into representational features, mapping those
features onto brain data, and evaluating the predictive performance of the
resulting model on held-out data. The library implements a modular pipeline
covering a wide array of methodological design choices, so researchers can
easily compose, compare, and extend encoding models without reinventing core
infrastructure. Such choices include brain datasets, brain regions, stimulus
feature (both neural-net-based and control, such as word rate), downsampling
approaches, and many others. In addition, the library provides built-in
logging, plotting, and seamless integration with experiment tracking platforms
such as Weights & Biases (W&B). We demonstrate the scalability and versatility
of our framework by fitting a range of encoding models to three story listening
datasets: LeBel et al. (2023), Narratives, and Little Prince. We also explore
the methodological choices critical for building encoding models for continuous
fMRI data, illustrating the importance of accounting for all tokens in a TR
scan (as opposed to just taking the last one, even when contextualized),
incorporating hemodynamic lag effects, using train-test splits that minimize
information leakage, and accounting for head motion effects on encoding model
predictivity. Overall, LITcoder lowers technical barriers to encoding model
implementation, facilitates systematic comparisons across models and datasets,
fosters methodological rigor, and accelerates the development of high-quality
high-performance predictive models of brain activity.
  Project page: https://litcoder-brain.github.io

</details>


### [14] [Target-oriented Multimodal Sentiment Classification with Counterfactual-enhanced Debiasing](https://arxiv.org/abs/2509.09160)
*Zhiyue Liu,Fanrong Ma,Xin Ling*

Main category: cs.CL

TL;DR: 本文提出了一种增强反事实的去偏框架，通过最小改变情感相关因果特征的反事实数据增强策略和自适应去偏对比学习机制，有效减少了虚假相关性，提高了目标导向的多模态情感分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法过度依赖文本内容，未能考虑数据集偏差，特别是词级上下文偏差，导致文本特征和输出标签之间出现虚假相关性，影响分类准确性。

Method: 我们引入了一个增强反事实的去偏框架，结合了最小改变情感相关因果特征的反事实数据增强策略，并引入了一种自适应去偏对比学习机制。

Result: 实验结果表明，我们的方法在多个基准数据集上优于最先进的基线。

Conclusion: 我们的方法在多个基准数据集上优于最先进的基线。

Abstract: Target-oriented multimodal sentiment classification seeks to predict
sentiment polarity for specific targets from image-text pairs. While existing
works achieve competitive performance, they often over-rely on textual content
and fail to consider dataset biases, in particular word-level contextual
biases. This leads to spurious correlations between text features and output
labels, impairing classification accuracy. In this paper, we introduce a novel
counterfactual-enhanced debiasing framework to reduce such spurious
correlations. Our framework incorporates a counterfactual data augmentation
strategy that minimally alters sentiment-related causal features, generating
detail-matched image-text samples to guide the model's attention toward content
tied to sentiment. Furthermore, for learning robust features from
counterfactual data and prompting model decisions, we introduce an adaptive
debiasing contrastive learning mechanism, which effectively mitigates the
influence of biased words. Experimental results on several benchmark datasets
show that our proposed method outperforms state-of-the-art baselines.

</details>


### [15] [EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs](https://arxiv.org/abs/2509.09174)
*Yuhao Zhang,Yuhao Du,Zhanchen Dai,Xiangnan Ma,Kaiqi Kou,Benyou Wang,Haizhou Li*

Main category: cs.CL

TL;DR: EchoX是一种新的语音到语音大语言模型，通过结合声学和语义学习，解决了现有模型在知识和推理能力上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前SLLMs的训练范式未能弥合特征表示空间中的声学-语义差距，导致知识和推理能力下降。

Method: EchoX利用语义表示并动态生成语音训练目标，结合了声学和语义学习。

Result: EchoX在多个基于知识的问答基准测试中表现出色，仅使用约六千小时的训练数据。

Conclusion: EchoX能够保持作为语音大语言模型的强大推理能力，并在多个基于知识的问答基准测试中表现出色。

Abstract: Speech-to-speech large language models (SLLMs) are attracting increasing
attention. Derived from text-based large language models (LLMs), SLLMs often
exhibit degradation in knowledge and reasoning capabilities. We hypothesize
that this limitation arises because current training paradigms for SLLMs fail
to bridge the acoustic-semantic gap in the feature representation space. To
address this issue, we propose EchoX, which leverages semantic representations
and dynamically generates speech training targets. This approach integrates
both acoustic and semantic learning, enabling EchoX to preserve strong
reasoning abilities as a speech LLM. Experimental results demonstrate that
EchoX, with about six thousand hours of training data, achieves advanced
performance on multiple knowledge-based question-answering benchmarks. The
project is available at https://github.com/FreedomIntelligence/EchoX.

</details>


### [16] [Efficient Trie-based Biasing using K-step Prediction for Rare Word Recognition](https://arxiv.org/abs/2509.09196)
*Chin Yuen Kwok,Jia Qi yip*

Main category: cs.CL

TL;DR: 本文提出一种新的ASR模型优化方法，通过提前预测多个步骤来提高罕见词识别性能，并在实验中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于Trie的偏置方法在解码过程中对罕见词进行优先输出，但撤销步骤计算成本高，尤其对于大型解码器模型。

Method: 我们提出适应ASR模型以提前预测多个步骤，从而避免撤销步骤，更好地估计部分假设是否会生成完整的罕见单词。

Result: 通过仅使用10小时合成数据微调Whisper模型，我们的方法显著降低了词错误率。

Conclusion: 通过微调Whisper模型，我们的方法在NSC Part 2测试集上将词错误率从30.86%降低到12.19%。

Abstract: Contextual biasing improves rare word recognition of ASR models by
prioritizing the output of rare words during decoding. A common approach is
Trie-based biasing, which gives "bonus scores" to partial hypothesis (e.g.
"Bon") that may lead to the generation of the rare word (e.g. "Bonham"). If the
full word ("Bonham") isn't ultimately recognized, the system revokes those
earlier bonuses. This revocation is limited to beam search and is
computationally expensive, particularly for models with large decoders. To
overcome these limitations, we propose adapting ASR models to look ahead and
predict multiple steps at once. This avoids the revocation step entirely by
better estimating whether a partial hypothesis will lead to the generation of
the full rare word. By fine-tuning Whisper with only 10 hours of synthetic
data, our method reduces the word error rate on the NSC Part 2 test set from
30.86% to 12.19%.

</details>


### [17] [Improving Synthetic Data Training for Contextual Biasing Models with a Keyword-Aware Cost Function](https://arxiv.org/abs/2509.09197)
*Chin Yuen Kwok,Jia Qi Yip,Eng Siong Chng*

Main category: cs.CL

TL;DR: 本文提出了一种增强的上下文偏差方法和关键词感知损失函数，以提高罕见词识别的性能。


<details>
  <summary>Details</summary>
Motivation: 罕见词识别可以通过将ASR模型适应到包含这些词的合成数据来改进。通过上下文偏差可以进一步提高性能，但使用合成数据可能导致过拟合。

Method: 我们增强了基于TCPGen的上下文偏差方法，并提出了一种关键词感知损失函数，该函数在训练偏差模块时额外关注偏差词。

Result: 通过适应Whisper到10小时的合成数据，我们的方法将NSC Part 2测试集上的词错误率从29.71%降低到11.81%。

Conclusion: 通过适应10小时的合成数据，我们的方法将NSC Part 2测试集上的词错误率从29.71%降低到11.81%。

Abstract: Rare word recognition can be improved by adapting ASR models to synthetic
data that includes these words. Further improvements can be achieved through
contextual biasing, which trains and adds a biasing module into the model
architecture to prioritize rare words. While training the module on synthetic
rare word data is more effective than using non-rare-word data, it can lead to
overfitting due to artifacts in the synthetic audio. To address this, we
enhance the TCPGen-based contextual biasing approach and propose a
keyword-aware loss function that additionally focuses on biased words when
training biasing modules. This loss includes a masked cross-entropy term for
biased word prediction and a binary classification term for detecting biased
word positions. These two terms complementarily support the decoding of biased
words during inference. By adapting Whisper to 10 hours of synthetic data, our
method reduced the word error rate on the NSC Part 2 test set from 29.71% to
11.81%.

</details>


### [18] [GmSLM : Generative Marmoset Spoken Language Modeling](https://arxiv.org/abs/2509.09198)
*Talia Sternberg,Michael London,David Omer,Yossi Adi*

Main category: cs.CL

TL;DR: 研究者开发了一种名为GmSLM的生成式松鼠猴语音语言模型，用于分析松鼠猴的语音交流。该模型在无监督数据和弱标注对话数据上进行了评估，并表现出优于基于人类语音的基线模型的优势。GmSLM生成的语音与实际语音非常相似，并且在下游任务中表现良好，为研究语音交流的神经基础提供了实用框架。


<details>
  <summary>Details</summary>
Motivation: Marmoset monkeys exhibit complex vocal communication, challenging the view that nonhuman primates vocal communication is entirely innate, and show similar features of human speech, such as vocal labeling of others and turn-taking. Studying their vocal communication offers a unique opportunity to link it with brain activity.

Method: We introduced Generative Marmoset Spoken Language Modeling (GmSLM), an optimized spoken language model pipeline for Marmoset vocal communication. We designed a novel zero-shot evaluation metrics using unsupervised in-the-wild data, alongside weakly labeled conversational data, to assess GmSLM.

Result: GmSLM generated vocalizations closely matched real resynthesized samples acoustically and performed well on downstream tasks. Despite being fully unsupervised, GmSLM effectively distinguish real from artificial conversations and may support further investigations of the neural basis of vocal communication and provides a practical framework linking vocalization and brain activity.

Conclusion: GmSLM stands to benefit future work in neuroscience, bioacoustics, and evolutionary biology.

Abstract: Marmoset monkeys exhibit complex vocal communication, challenging the view
that nonhuman primates vocal communication is entirely innate, and show similar
features of human speech, such as vocal labeling of others and turn-taking.
Studying their vocal communication offers a unique opportunity to link it with
brain activity-especially given the difficulty of accessing the human brain in
speech and language research. Since Marmosets communicate primarily through
vocalizations, applying standard LLM approaches is not straightforward. We
introduce Generative Marmoset Spoken Language Modeling (GmSLM), an optimized
spoken language model pipeline for Marmoset vocal communication. We designed a
novel zero-shot evaluation metrics using unsupervised in-the-wild data,
alongside weakly labeled conversational data, to assess GmSLM and demonstrate
its advantage over a basic human-speech-based baseline. GmSLM generated
vocalizations closely matched real resynthesized samples acoustically and
performed well on downstream tasks. Despite being fully unsupervised, GmSLM
effectively distinguish real from artificial conversations and may support
further investigations of the neural basis of vocal communication and provides
a practical framework linking vocalization and brain activity. We believe GmSLM
stands to benefit future work in neuroscience, bioacoustics, and evolutionary
biology. Samples are provided under: pages.cs.huji.ac.il/adiyoss-lab/GmSLM.

</details>


### [19] [CCF: A Context Compression Framework for Efficient Long-Sequence Language Modeling](https://arxiv.org/abs/2509.09199)
*Wenhao Li,Bangcheng Sun,Weihao Ye,Tianyi Zhang,Daohai Yu,Fei Chao,Rongrong Ji*

Main category: cs.CL

TL;DR: 本文提出了一种名为CCF的新上下文压缩框架，通过学习分层潜在表示来实现高效的长上下文建模，同时保留全局语义并减少输入冗余。CCF结合了逐段语义聚合和键值记忆编码，形成了支持准确重建和长距离理解的紧凑表示。为了进一步提高可扩展性，我们引入了一种训练高效的优化策略，将增量段解码与稀疏水库采样相结合，显著减少了内存开销而不降低性能。实验结果表明，CCF在高压缩比率下实现了具有竞争力的困惑度，并且与现有方法相比，显著提高了吞吐量和内存效率。这些发现突显了结构化压缩在可扩展和有效的长上下文语言建模中的潜力。


<details>
  <summary>Details</summary>
Motivation: 扩展语言模型以处理更长的上下文对于捕捉跨扩展话语的丰富依赖关系至关重要。然而，天真地扩展上下文会带来显著的计算和内存负担，通常导致训练和推理过程中的低效。

Method: 我们提出了CCF，这是一种新颖的上下文压缩框架，通过学习分层潜在表示来实现高效的长上下文建模，同时保留全局语义并大幅减少输入冗余。CCF结合了逐段语义聚合和键值记忆编码，形成了支持准确重建和长距离理解的紧凑表示。为了进一步提高可扩展性，我们引入了一种训练高效的优化策略，将增量段解码与稀疏水库采样相结合，显著减少了内存开销而不降低性能。

Result: 在多个长上下文语言建模基准测试中，CCF在高压缩比率下实现了具有竞争力的困惑度，并且与现有方法相比，显著提高了吞吐量和内存效率。

Conclusion: 这些发现突显了结构化压缩在可扩展和有效的长上下文语言建模中的潜力。

Abstract: Scaling language models to longer contexts is essential for capturing rich
dependencies across extended discourse. However, na\"ive context extension
imposes significant computational and memory burdens, often resulting in
inefficiencies during both training and inference. In this work, we propose
CCF, a novel context compression framework designed to enable efficient
long-context modeling by learning hierarchical latent representations that
preserve global semantics while aggressively reducing input redundancy. CCF
integrates segment-wise semantic aggregation with key-value memory encoding,
forming compact representations that support accurate reconstruction and
long-range understanding. To further enhance scalability, we introduce a
training-efficient optimization strategy that couples incremental segment
decoding with sparse reservoir sampling, substantially reducing memory overhead
without degrading performance. Empirical results on multiple long-context
language modeling benchmarks demonstrate that CCF achieves competitive
perplexity under high compression ratios, and significantly improves throughput
and memory efficiency compared to existing approaches. These findings highlight
the potential of structured compression for scalable and effective long-context
language modeling.

</details>


### [20] [Reading Between the Lines: Classifying Resume Seniority with Large Language Models](https://arxiv.org/abs/2509.09229)
*Matan Cohen,Shira Shani,Eden Menahem,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型在自动分类简历中的有效性，并引入了一个混合数据集来评估模型性能。研究结果表明，这些模型在检测简历中的高级别膨胀和隐含专业知识方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 准确评估候选人的资历是一个关键但具有挑战性的任务，因为简历中普遍存在夸大经验和模糊的自我表现。

Method: 研究使用了混合数据集，包括真实简历和合成生成的困难示例，以评估大型语言模型在自动分类简历中的有效性。

Result: 研究发现，大型语言模型能够有效检测与资历膨胀和隐含专业知识相关的细微语言线索。

Conclusion: 研究结果表明，大型语言模型在检测简历中的高级别膨胀和隐含的专业知识方面具有前景，有助于增强AI驱动的候选人评估系统并减少自我宣传语言带来的偏差。

Abstract: Accurately assessing candidate seniority from resumes is a critical yet
challenging task, complicated by the prevalence of overstated experience and
ambiguous self-presentation. In this study, we investigate the effectiveness of
large language models (LLMs), including fine-tuned BERT architectures, for
automating seniority classification in resumes. To rigorously evaluate model
performance, we introduce a hybrid dataset comprising both real-world resumes
and synthetically generated hard examples designed to simulate exaggerated
qualifications and understated seniority. Using the dataset, we evaluate the
performance of Large Language Models in detecting subtle linguistic cues
associated with seniority inflation and implicit expertise. Our findings
highlight promising directions for enhancing AI-driven candidate evaluation
systems and mitigating bias introduced by self-promotional language. The
dataset is available for the research community at https://bit.ly/4mcTovt

</details>


### [21] [Agentic LLMs for Question Answering over Tabular Data](https://arxiv.org/abs/2509.09234)
*Rishit Tyagi,Mohit Gupta,Rahul Bouri*

Main category: cs.CL

TL;DR: 本文介绍了一种基于大型语言模型的自然语言到SQL方法，用于解决表格问答问题，并在DataBench基准测试中取得了显著优于基线的结果。


<details>
  <summary>Details</summary>
Motivation: 由于现实世界表格的结构、大小和数据类型的多样性，表格问答 (Table QA) 带来了独特的挑战。SemEval 2025任务8 (DataBench) 引入了一个由大规模、领域多样数据集组成的基准，以评估模型准确回答结构化查询的能力。

Method: 我们提出了一种自然语言到SQL (NL-to-SQL) 的方法，利用大型语言模型 (LLMs) 如GPT-4o、GPT-4o-mini 和 DeepSeek v2:16b 动态生成SQL查询。我们的系统遵循一个涉及示例选择、SQL查询生成、答案提取、验证和迭代优化的多阶段流程。

Result: 实验表明了我们方法的有效性，在DataBench QA上达到了70.5%的准确率，在DataBench Lite QA上达到了71.6%，分别显著超过了基线分数26%和27%。

Conclusion: 本文详细介绍了我们的方法、实验结果和替代方法，提供了对基于LLM的Table QA的优势和局限性的见解。

Abstract: Question Answering over Tabular Data (Table QA) presents unique challenges
due to the diverse structure, size, and data types of real-world tables. The
SemEval 2025 Task 8 (DataBench) introduced a benchmark composed of large-scale,
domain-diverse datasets to evaluate the ability of models to accurately answer
structured queries. We propose a Natural Language to SQL (NL-to-SQL) approach
leveraging large language models (LLMs) such as GPT-4o, GPT-4o-mini, and
DeepSeek v2:16b to generate SQL queries dynamically. Our system follows a
multi-stage pipeline involving example selection, SQL query generation, answer
extraction, verification, and iterative refinement. Experiments demonstrate the
effectiveness of our approach, achieving 70.5\% accuracy on DataBench QA and
71.6\% on DataBench Lite QA, significantly surpassing baseline scores of 26\%
and 27\% respectively. This paper details our methodology, experimental
results, and alternative approaches, providing insights into the strengths and
limitations of LLM-driven Table QA.

</details>


### [22] [From scratch to silver: Creating trustworthy training data for patent-SDG classification using Large Language Models](https://arxiv.org/abs/2509.09303)
*Grazia Sveva Ascione,Nicolò Tamagnone*

Main category: cs.CL

TL;DR: 本文提出了一种基于弱监督和语义对齐的方法，用于大规模SDG分类，提高了分类性能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大型标记数据集，监督学习的应用受到限制。现有的方法如关键词搜索、迁移学习和基于引文的启发式方法在可扩展性和通用性方面存在不足。

Method: 本文将专利到SDG的分类问题视为一个弱监督问题，使用专利引用的SDG标记科学出版物（NPL引用）作为噪声初始信号，并开发了一个复合标注函数（LF），利用大语言模型（LLMs）从专利和SDG论文中提取结构化概念。

Result: 本文生成了一个银标准的软多标签数据集，将专利映射到SDG，使有效的多标签回归模型得以训练。通过内部和外部验证策略验证了方法的有效性。

Conclusion: 本文展示了弱监督和语义对齐可以在大规模SDG分类中提高性能。

Abstract: Classifying patents by their relevance to the UN Sustainable Development
Goals (SDGs) is crucial for tracking how innovation addresses global
challenges. However, the absence of a large, labeled dataset limits the use of
supervised learning. Existing methods, such as keyword searches, transfer
learning, and citation-based heuristics, lack scalability and generalizability.
This paper frames patent-to-SDG classification as a weak supervision problem,
using citations from patents to SDG-tagged scientific publications (NPL
citations) as a noisy initial signal. To address its sparsity and noise, we
develop a composite labeling function (LF) that uses large language models
(LLMs) to extract structured concepts, namely functions, solutions, and
applications, from patents and SDG papers based on a patent ontology.
Cross-domain similarity scores are computed and combined using a rank-based
retrieval approach. The LF is calibrated via a custom positive-only loss that
aligns with known NPL-SDG links without penalizing discovery of new SDG
associations. The result is a silver-standard, soft multi-label dataset mapping
patents to SDGs, enabling the training of effective multi-label regression
models. We validate our approach through two complementary strategies: (1)
internal validation against held-out NPL-based labels, where our method
outperforms several baselines including transformer-based models, and zero-shot
LLM; and (2) external validation using network modularity in patent citation,
co-inventor, and co-applicant graphs, where our labels reveal greater thematic,
cognitive, and organizational coherence than traditional technological
classifications. These results show that weak supervision and semantic
alignment can enhance SDG classification at scale.

</details>


### [23] [MetaRAG: Metamorphic Testing for Hallucination Detection in RAG Systems](https://arxiv.org/abs/2509.09360)
*Channdeth Sok,David Luz,Yacine Haddam*

Main category: cs.CL

TL;DR: MetaRAG is a metamorphic testing framework for detecting hallucinations in RAG systems, which decomposes answers into atomic factoids, generates controlled mutations, verifies variants against retrieved context, and aggregates penalties into a hallucination score.


<details>
  <summary>Details</summary>
Motivation: Existing detection approaches primarily target standalone LLMs and do not address the unique challenges of RAG systems, where responses must be consistent with retrieved evidence.

Method: MetaRAG is a metamorphic testing framework that operates in a real-time, unsupervised, black-box setting. It decomposes answers into atomic factoids, generates controlled mutations using synonym and antonym substitutions, verifies each variant against the retrieved context, and aggregates penalties for inconsistencies into a response-level hallucination score.

Result: Experiments on a proprietary enterprise dataset illustrate the effectiveness of MetaRAG for detecting hallucinations and enabling trustworthy deployment of RAG-based conversational agents.

Conclusion: MetaRAG is effective for detecting hallucinations and enabling trustworthy deployment of RAG-based conversational agents.

Abstract: Large Language Models (LLMs) are increasingly deployed in enterprise
applications, yet their reliability remains limited by hallucinations, i.e.,
confident but factually incorrect information. Existing detection approaches,
such as SelfCheckGPT and MetaQA, primarily target standalone LLMs and do not
address the unique challenges of Retrieval-Augmented Generation (RAG) systems,
where responses must be consistent with retrieved evidence. We therefore
present MetaRAG, a metamorphic testing framework for hallucination detection in
Retrieval-Augmented Generation (RAG) systems. MetaRAG operates in a real-time,
unsupervised, black-box setting, requiring neither ground-truth references nor
access to model internals, making it suitable for proprietary and high-stakes
domains. The framework proceeds in four stages: (1) decompose answers into
atomic factoids, (2) generate controlled mutations of each factoid using
synonym and antonym substitutions, (3) verify each variant against the
retrieved context (synonyms are expected to be entailed and antonyms
contradicted), and (4) aggregate penalties for inconsistencies into a
response-level hallucination score. Crucially for identity-aware AI, MetaRAG
localizes unsupported claims at the factoid span where they occur (e.g.,
pregnancy-specific precautions, LGBTQ+ refugee rights, or labor eligibility),
allowing users to see flagged spans and enabling system designers to configure
thresholds and guardrails for identity-sensitive queries. Experiments on a
proprietary enterprise dataset illustrate the effectiveness of MetaRAG for
detecting hallucinations and enabling trustworthy deployment of RAG-based
conversational agents. We also outline a topic-based deployment design that
translates MetaRAG's span-level scores into identity-aware safeguards; this
design is discussed but not evaluated in our experiments.

</details>


### [24] [Modelling Analogies and Analogical Reasoning: Connecting Cognitive Science Theory and NLP Research](https://arxiv.org/abs/2509.09381)
*Molly R Petersen,Claire E Stevenson,Lonneke van der Plas*

Main category: cs.CL

TL;DR: 本文探讨了类比推理在自然语言处理中的应用，并强调了其在优化文本关系理解方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管这些过程可以轻松地与NLP中的概念相关联，但它们通常不通过认知视角来看待。

Method: 本文通过分析认知科学中的类比推理理论，探讨其在自然语言处理中的应用。

Result: 本文展示了这些概念对于NLP研究中的几个主要挑战的相关性，这些挑战并不直接与类比求解有关。

Conclusion: 本文总结了认知科学文献中关于类比推理过程的关键理论，并将其与自然语言处理（NLP）的当前研究联系起来。

Abstract: Analogical reasoning is an essential aspect of human cognition. In this
paper, we summarize key theory about the processes underlying analogical
reasoning from the cognitive science literature and relate it to current
research in natural language processing. While these processes can be easily
linked to concepts in NLP, they are generally not viewed through a cognitive
lens. Furthermore, we show how these notions are relevant for several major
challenges in NLP research, not directly related to analogy solving. This may
guide researchers to better optimize relational understanding in text, as
opposed to relying heavily on entity-level similarity.

</details>


### [25] [Hierarchical Bracketing Encodings Work for Dependency Graphs](https://arxiv.org/abs/2509.09388)
*Ana Ezquerro,Carlos Gómez-Rodríguez,David Vilares*

Main category: cs.CL

TL;DR: 本文提出了一种新的图编码方法，能够在保持结构信息的同时减少标签空间，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的图线性化方法在标签空间和结构信息保留方面存在不足，因此需要一种更有效的表示方法。

Method: 该方法通过将图编码为序列，实现了线性时间解析，并保留了重叠、循环和空节点的结构信息。

Result: 在多语言和多形式主义基准测试中，该方法表现出色，具有竞争力的结果和一致的改进。

Conclusion: 该方法在精确匹配准确性上表现出色，相比其他方法有显著改进。

Abstract: We revisit hierarchical bracketing encodings from a practical perspective in
the context of dependency graph parsing. The approach encodes graphs as
sequences, enabling linear-time parsing with $n$ tagging actions, and still
representing reentrancies, cycles, and empty nodes. Compared to existing graph
linearizations, this representation substantially reduces the label space while
preserving structural information. We evaluate it on a multilingual and
multi-formalism benchmark, showing competitive results and consistent
improvements over other methods in exact match accuracy.

</details>


### [26] [GrACE: A Generative Approach to Better Confidence Elicitation in Large Language Models](https://arxiv.org/abs/2509.09438)
*Zhaohan Zhang,Ziquan Liu,Ioannis Patras*

Main category: cs.CL

TL;DR: GrACE is a novel approach for confidence elicitation in LLMs that provides scalable, reliable, and real-time confidence estimation, outperforming existing methods without additional sampling or an auxiliary model.


<details>
  <summary>Details</summary>
Motivation: Existing methods for assessing the reliability of LLMs by confidence elicitation either require expensive computational overhead or suffer from poor calibration, making them impractical and unreliable for real-world deployment.

Method: GrACE is a Generative Approach to Confidence Elicitation that uses the similarity between the last hidden state and the embedding of a special token appended to the vocabulary to express confidence in real-time. The model is fine-tuned for calibrating confidence with calibration targets associated with accuracy.

Result: Experiments with three LLMs and two benchmark datasets show that GrACE achieves the best discriminative capacity and calibration on open-ended generation tasks, outperforming six competing methods without additional sampling or an auxiliary model. Additionally, using GrACE improves the accuracy of the final decision and significantly reduces the number of required samples in the test-time scaling scheme.

Conclusion: GrACE shows potential as a practical solution for deploying LLMs with scalable, reliable, and real-time confidence estimation.

Abstract: Assessing the reliability of Large Language Models (LLMs) by confidence
elicitation is a prominent approach to AI safety in high-stakes applications,
such as healthcare and finance. Existing methods either require expensive
computational overhead or suffer from poor calibration, making them impractical
and unreliable for real-world deployment. In this work, we propose GrACE, a
Generative Approach to Confidence Elicitation that enables scalable and
reliable confidence elicitation for LLMs. GrACE adopts a novel mechanism in
which the model expresses confidence by the similarity between the last hidden
state and the embedding of a special token appended to the vocabulary, in
real-time. We fine-tune the model for calibrating the confidence with
calibration targets associated with accuracy. Experiments with three LLMs and
two benchmark datasets show that the confidence produced by GrACE achieves the
best discriminative capacity and calibration on open-ended generation tasks,
outperforming six competing methods without resorting to additional sampling or
an auxiliary model. Moreover, we propose two strategies for improving test-time
scaling based on confidence induced by GrACE. Experimental results show that
using GrACE not only improves the accuracy of the final decision but also
significantly reduces the number of required samples in the test-time scaling
scheme, indicating the potential of GrACE as a practical solution for deploying
LLMs with scalable, reliable, and real-time confidence estimation.

</details>


### [27] [Mitigating Language Barriers in Education: Developing Multilingual Digital Learning Materials with Machine Translation](https://arxiv.org/abs/2509.09473)
*Lucie Poláková,Martin Popel,Věra Kloudová,Michal Novák,Mariia Anisimova,Jiří Balhar*

Main category: cs.CL

TL;DR: EdUKate项目结合数字教育、语言学、翻译研究和机器翻译，开发了多语言学习材料，并针对教育领域开发了一个直接的捷克语-乌克兰语机器翻译系统。


<details>
  <summary>Details</summary>
Motivation: 该项目旨在为捷克中小学提供多语言学习材料，以满足非捷克语学生的需要，并开发一个专门处理格式化内容和科技术语的机器翻译系统。

Method: 该项目结合了数字教育、语言学、翻译研究和机器翻译，开发了多语言学习材料，并针对教育领域开发和评估了一个直接的捷克语-乌克兰语机器翻译系统。

Result: 项目完成了将9000个多媒体互动练习从捷克语翻译成乌克兰语、英语和德语的工作，并成功在教育网络门户上实施了机器翻译系统。

Conclusion: 该项目开发的多语言学习材料和机器翻译系统已成功实施，并对学生、教育工作者和研究人员免费开放。

Abstract: The EdUKate project combines digital education, linguistics, translation
studies, and machine translation to develop multilingual learning materials for
Czech primary and secondary schools. Launched through collaboration between a
major Czech academic institution and the country's largest educational
publisher, the project is aimed at translating up to 9,000 multimodal
interactive exercises from Czech into Ukrainian, English, and German for an
educational web portal. It emphasizes the development and evaluation of a
direct Czech-Ukrainian machine translation system tailored to the educational
domain, with special attention to processing formatted content such as XML and
PDF and handling technical and scientific terminology. We present findings from
an initial survey of Czech teachers regarding the needs of non-Czech-speaking
students and describe the system's evaluation and implementation on the web
portal. All resulting applications are freely available to students, educators,
and researchers.

</details>


### [28] [Towards Explainable Job Title Matching: Leveraging Semantic Textual Relatedness and Knowledge Graphs](https://arxiv.org/abs/2509.09522)
*Vadim Zadykian,Bruno Andrade,Haithem Afli*

Main category: cs.CL

TL;DR: 本文提出了一种结合知识图谱的自监督混合架构，用于改进职位名称匹配任务。通过分层评估方法，研究发现该方法在高语义相关性区域表现优异，同时强调了区域性能分析的重要性。


<details>
  <summary>Details</summary>
Motivation: 在简历推荐系统中，职位名称匹配是一个关键挑战，因为重叠术语可能有限或具有误导性。传统的模型评估方法通常基于整体性能，而我们希望探索一种更细致的区域性能分析方法，以更好地理解模型行为。

Method: 我们引入了一种自监督的混合架构，结合密集句子嵌入和领域特定的知识图谱（KGs），以提高语义对齐和可解释性。此外，我们通过将STR分数连续体划分为低、中、高语义相关性区域来进行分层评估，以实现对模型性能的细粒度分析。

Result: 实验结果显示，经过微调的SBERT模型结合KGs在高STR区域表现出色，RMSE比强基线模型降低了25%。这表明结合KGs与文本嵌入具有明显优势，并且区域性能分析能够揭示全局指标无法发现的模型优缺点。

Conclusion: 我们的研究结果表明，结合知识图谱的文本嵌入方法在高语义相关性区域表现出显著优势，并且区域性能分析有助于更深入地理解模型行为。这种细粒度的方法对于人力资源系统和需要公平性、可解释性和上下文匹配的应用具有重要意义。

Abstract: Semantic Textual Relatedness (STR) captures nuanced relationships between
texts that extend beyond superficial lexical similarity. In this study, we
investigate STR in the context of job title matching - a key challenge in
resume recommendation systems, where overlapping terms are often limited or
misleading. We introduce a self-supervised hybrid architecture that combines
dense sentence embeddings with domain-specific Knowledge Graphs (KGs) to
improve both semantic alignment and explainability. Unlike previous work that
evaluated models on aggregate performance, our approach emphasizes data
stratification by partitioning the STR score continuum into distinct regions:
low, medium, and high semantic relatedness. This stratified evaluation enables
a fine-grained analysis of model performance across semantically meaningful
subspaces. We evaluate several embedding models, both with and without KG
integration via graph neural networks. The results show that fine-tuned SBERT
models augmented with KGs produce consistent improvements in the high-STR
region, where the RMSE is reduced by 25% over strong baselines. Our findings
highlight not only the benefits of combining KGs with text embeddings, but also
the importance of regional performance analysis in understanding model
behavior. This granular approach reveals strengths and weaknesses hidden by
global metrics, and supports more targeted model selection for use in Human
Resources (HR) systems and applications where fairness, explainability, and
contextual matching are essential.

</details>


### [29] [DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning and Label Distribution Learning](https://arxiv.org/abs/2509.09524)
*Daniil Ignatev,Nan Li,Hugh Mee Wong,Anh Dang,Shane Kaszefski Yaschuk*

Main category: cs.CL

TL;DR: The paper presents approaches for predicting annotator-specific annotations and soft labels using ICL and LDL methods, showing their effectiveness and potential for further exploration.


<details>
  <summary>Details</summary>
Motivation: To explore effective approaches for predicting annotator-specific annotations and soft label predictions in the context of the Learning with Disagreements shared task.

Method: In-context learning (ICL) with large language models and label distribution learning (LDL) methods with RoBERTa.

Result: ICL was shown to effectively predict annotator-specific annotations, and aggregating these predictions into soft labels yielded competitive performance. LDL methods were found to be promising for soft label predictions.

Conclusion: ICL can effectively predict annotator-specific annotations and aggregating these predictions into soft labels yields competitive performance. LDL methods are promising for soft label predictions and merit further exploration.

Abstract: This system paper presents the DeMeVa team's approaches to the third edition
of the Learning with Disagreements shared task (LeWiDi 2025; Leonardelli et
al., 2025). We explore two directions: in-context learning (ICL) with large
language models, where we compare example sampling strategies; and label
distribution learning (LDL) methods with RoBERTa (Liu et al., 2019b), where we
evaluate several fine-tuning methods. Our contributions are twofold: (1) we
show that ICL can effectively predict annotator-specific annotations
(perspectivist annotations), and that aggregating these predictions into soft
labels yields competitive performance; and (2) we argue that LDL methods are
promising for soft label predictions and merit further exploration by the
perspectivist community.

</details>


### [30] [Prompting the Market? A Large-Scale Meta-Analysis of GenAI in Finance NLP (2022-2025)](https://arxiv.org/abs/2509.09544)
*Paolo Pedinotti,Peter Baumann,Nathan Jessurun,Leslie Barrett,Enrico Santus*

Main category: cs.CL

TL;DR: 本文介绍了 MetaGraph，这是一种从科学文献中提取知识图谱并分析研究趋势的方法，揭示了金融 NLP 的三个发展阶段。


<details>
  <summary>Details</summary>
Motivation: 传统调查未能跟上大型语言模型（LLMs）在金融 NLP 中的快速变化，因此需要一种新的方法来提取知识图谱并分析研究趋势。

Method: 定义了一个金融 NLP 研究的本体论，并应用基于 LLM 的提取管道来分析 681 篇论文（2022-2025）。

Result: MetaGraph 揭示了三个关键阶段：早期 LLM 的采用和任务/数据集创新；对 LLM 限制的批判性反思；以及外围技术向模块化系统的整合。

Conclusion: MetaGraph 提供了一种可重复使用的方法，用于映射其他领域的科学进展，并为从业者和研究人员提供了对金融 NLP 发展的清晰理解。

Abstract: Large Language Models (LLMs) have rapidly reshaped financial NLP, enabling
new tasks and driving a proliferation of datasets and diversification of data
sources. Yet, this transformation has outpaced traditional surveys. In this
paper, we present MetaGraph, a generalizable methodology for extracting
knowledge graphs from scientific literature and analyzing them to obtain a
structured, queryable view of research trends. We define an ontology for
financial NLP research and apply an LLM-based extraction pipeline to 681 papers
(2022-2025), enabling large-scale, data-driven analysis. MetaGraph reveals
three key phases: early LLM adoption and task/dataset innovation; critical
reflection on LLM limitations; and growing integration of peripheral techniques
into modular systems. This structured view offers both practitioners and
researchers a clear understanding of how financial NLP has evolved -
highlighting emerging trends, shifting priorities, and methodological
shifts-while also demonstrating a reusable approach for mapping scientific
progress in other domains.

</details>


### [31] [Personality-Enhanced Social Recommendations in SAMI: Exploring the Role of Personality Detection in Matchmaking](https://arxiv.org/abs/2509.09583)
*Brittany Harbison,Samuel Taubman,Travis Taylor,Ashok. K. Goel*

Main category: cs.CL

TL;DR: 本文提出了一种利用GPT的零样本能力来推断大五人格特质的模型，并将其集成到SAMI的基于实体的匹配系统中，以实现基于个性的社会推荐。初步整合表明个性特征可以补充现有的匹配因素，但需要进一步评估其对学生参与度和匹配质量的全面影响。


<details>
  <summary>Details</summary>
Motivation: SAMI在在线课程环境中通过促进学生连接提供了一个解决方案，但其有效性受到不完整的心理理论的限制，这限制了其创建学生有效心理模型的能力。其中一个方面是其无法直观地感知个性，这可能会影响其推荐的相关性。

Method: 本文提出了一种利用GPT的零样本能力来推断大五人格特质的模型，并将其集成到SAMI的基于实体的匹配系统中，以实现基于个性的社会推荐。

Result: 本文展示了该模型在这一任务中的有效性，并将其集成到SAMI的实体匹配系统中，以实现基于个性的社会推荐。初步整合表明个性特征可以补充现有的匹配因素，但需要进一步评估其对学生参与度和匹配质量的全面影响。

Conclusion: 本文提出了一种利用GPT的零样本能力来推断大五人格特质的模型，并将其集成到SAMI的基于实体的匹配系统中，以实现基于个性的社会推荐。初步整合表明个性特征可以补充现有的匹配因素，但需要进一步评估其对学生参与度和匹配质量的全面影响。

Abstract: Social connection is a vital part of learning, yet online course environments
present barriers to the organic formation of social groups. SAMI offers one
solution by facilitating student connections, but its effectiveness is
constrained by an incomplete Theory of Mind, limiting its ability to create an
effective mental model of a student. One facet of this is its inability to
intuit personality, which may influence the relevance of its recommendations.
To explore this, we propose a personality detection model utilizing GPTs
zero-shot capability to infer Big-Five personality traits from forum
introduction posts, often encouraged in online courses. We benchmark its
performance against established models, demonstrating its efficacy in this
task. Furthermore, we integrate this model into SAMIs entity-based matchmaking
system, enabling personality-informed social recommendations. Initial
integration suggests personality traits can complement existing matching
factors, though additional evaluation is required to determine their full
impact on student engagement and match quality.

</details>


### [32] [Fluent but Unfeeling: The Emotional Blind Spots of Language Models](https://arxiv.org/abs/2509.09593)
*Bangzhao Shu,Isha Joshi,Melissa Karnaze,Anh C. Pham,Ishita Kakkar,Sindhu Kothe,Arpine Hovasapian,Mai ElSherief*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型在细粒度情感对齐方面的局限性，并提出了一个基准数据集EXPRESS，用于评估模型在情感识别任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常专注于将情感分类为预定义的有限类别，而忽略了更细微的表达。因此，本研究旨在填补这一空白，评估大型语言模型是否能在细粒度层面与人类情感保持一致。

Method: 研究引入了EXPRESS数据集，这是一个从Reddit社区中整理的基准数据集，包含251个细粒度、自我披露的情感标签。此外，研究还构建了一个全面的评估框架，用于检查预测的情感术语，并将其分解为八种基本情绪，以实现细粒度比较。

Result: 系统测试了流行的大型语言模型在不同提示设置下的表现，发现准确预测与人类自我披露情感一致的情感仍然具有挑战性。定性分析进一步表明，虽然某些大型语言模型生成的情感术语与已有的情感理论和定义一致，但它们有时无法像人类自我披露那样有效地捕捉上下文线索。

Conclusion: 研究结果表明，尽管某些大型语言模型生成的情感术语与已有的情感理论和定义一致，但它们在捕捉上下文线索方面不如人类自我披露有效。这突显了大型语言模型在细粒度情感对齐方面的局限性，并为未来增强其上下文理解的研究提供了见解。

Abstract: The versatility of Large Language Models (LLMs) in natural language
understanding has made them increasingly popular in mental health research.
While many studies explore LLMs' capabilities in emotion recognition, a
critical gap remains in evaluating whether LLMs align with human emotions at a
fine-grained level. Existing research typically focuses on classifying emotions
into predefined, limited categories, overlooking more nuanced expressions. To
address this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit
communities featuring 251 fine-grained, self-disclosed emotion labels. Our
comprehensive evaluation framework examines predicted emotion terms and
decomposes them into eight basic emotions using established emotion theories,
enabling a fine-grained comparison. Systematic testing of prevalent LLMs under
various prompt settings reveals that accurately predicting emotions that align
with human self-disclosed emotions remains challenging. Qualitative analysis
further shows that while certain LLMs generate emotion terms consistent with
established emotion theories and definitions, they sometimes fail to capture
contextual cues as effectively as human self-disclosures. These findings
highlight the limitations of LLMs in fine-grained emotion alignment and offer
insights for future research aimed at enhancing their contextual understanding.

</details>


### [33] [LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death Determination](https://arxiv.org/abs/2509.09602)
*Yiqun T. Chen,Tyler H. McCormick,Li Liu,Abhirup Datta*

Main category: cs.CL

TL;DR: 本研究提出了一种结合大型语言模型和传统方法的验证概念管道，用于提高资源有限地区死亡原因预测的准确性。结果表明，GPT-5的表现优于传统方法，显示出大型语言模型在改善口头尸检中的潜力。


<details>
  <summary>Details</summary>
Motivation: 在缺乏医疗认证的资源有限的环境中，口头尸检（VA）是估计死亡原因的关键工具。本研究旨在探索使用大型语言模型来改进口头尸检的准确性。

Method: 本研究提出了LA-VA，这是一个结合大型语言模型（LLMs）与传统算法方法和基于嵌入的分类的验证概念管道，以提高死亡原因预测的准确性。

Result: 研究结果显示，GPT-5在个体表现上取得了最高成绩，平均测试站点准确率分别为48.6%（成人）、50.5%（儿童）和53.5%（新生儿），比传统的统计机器学习基线高出5-10%。

Conclusion: 研究发现，简单的现成大型语言模型辅助方法可以显著提高口头尸检的准确性，这对低资源环境中的全球健康监测具有重要意义。

Abstract: Verbal autopsy (VA) is a critical tool for estimating causes of death in
resource-limited settings where medical certification is unavailable. This
study presents LA-VA, a proof-of-concept pipeline that combines Large Language
Models (LLMs) with traditional algorithmic approaches and embedding-based
classification for improved cause-of-death prediction. Using the Population
Health Metrics Research Consortium (PHMRC) dataset across three age categories
(Adult: 7,580; Child: 1,960; Neonate: 2,438), we evaluate multiple approaches:
GPT-5 predictions, LCVA baseline, text embeddings, and meta-learner ensembles.
Our results demonstrate that GPT-5 achieves the highest individual performance
with average test site accuracies of 48.6% (Adult), 50.5% (Child), and 53.5%
(Neonate), outperforming traditional statistical machine learning baselines by
5-10%. Our findings suggest that simple off-the-shelf LLM-assisted approaches
could substantially improve verbal autopsy accuracy, with important
implications for global health surveillance in low-resource settings.

</details>


### [34] [Bridging the Capability Gap: Joint Alignment Tuning for Harmonizing LLM-based Multi-Agent Systems](https://arxiv.org/abs/2509.09629)
*Minghang Zhu,Zhengliang Shi,Zhiwei Xu,Shiguang Wu,Lingjie Wang,Pengjie Ren,Zhaochun Ren,Zhumin Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为MOAT的多智能体联合对齐调优框架，通过迭代对齐提高智能体之间的协作。MOAT交替进行两个关键阶段：(1) 规划智能体对齐，优化规划智能体生成更好的子目标序列来指导接地智能体；(2) 接地智能体改进，使用智能体自身生成的多样化子目标-动作对来微调接地智能体，以增强其泛化能力。理论分析证明MOAT确保了非递减且逐步收敛的训练过程。六个基准测试的实验表明，MOAT优于最先进的基线，平均提高了3.1%在保留任务和4.4%在保留任务。


<details>
  <summary>Details</summary>
Motivation: Most existing methods typically fine-tune these agents independently, leading to capability gaps among them with poor coordination.

Method: MOAT is a Multi-Agent Joint Alignment Tuning framework that improves agents collaboration through iterative alignment. It alternates between two key stages: (1) Planning Agent Alignment, which optimizes the planning agent to generate subgoal sequences that better guide the grounding agent; and (2) Grounding Agent Improving, which fine-tunes the grounding agent using diverse subgoal-action pairs generated by the agent itself to enhance its generalization capability.

Result: Experiments across six benchmarks demonstrate that MOAT outperforms state-of-the-art baselines, achieving average improvements of 3.1% on held-in tasks and 4.4% on held-out tasks.

Conclusion: MOAT outperforms state-of-the-art baselines, achieving average improvements of 3.1% on held-in tasks and 4.4% on held-out tasks.

Abstract: The advancement of large language models (LLMs) has enabled the construction
of multi-agent systems to solve complex tasks by dividing responsibilities
among specialized agents, such as a planning agent for subgoal generation and a
grounding agent for executing tool-use actions. Most existing methods typically
fine-tune these agents independently, leading to capability gaps among them
with poor coordination. To address this, we propose MOAT, a Multi-Agent Joint
Alignment Tuning framework that improves agents collaboration through iterative
alignment. MOAT alternates between two key stages: (1) Planning Agent
Alignment, which optimizes the planning agent to generate subgoal sequences
that better guide the grounding agent; and (2) Grounding Agent Improving, which
fine-tunes the grounding agent using diverse subgoal-action pairs generated by
the agent itself to enhance its generalization capablity. Theoretical analysis
proves that MOAT ensures a non-decreasing and progressively convergent training
process. Experiments across six benchmarks demonstrate that MOAT outperforms
state-of-the-art baselines, achieving average improvements of 3.1% on held-in
tasks and 4.4% on held-out tasks.

</details>


### [35] [All for One: LLMs Solve Mental Math at the Last Token With Information Transferred From Other Tokens](https://arxiv.org/abs/2509.09650)
*Siddarth Mamidanna,Daking Rai,Ziyu Yao,Yilun Zhou*

Main category: cs.CL

TL;DR: 本文通过两种技术研究了大型语言模型在心理数学任务中的内部运作，发现了一个高效的子图，该子图在各种任务中表现良好，并且可以跨模型迁移。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在许多计算任务中表现出色，但它们的内部机制仍然不清晰。本文旨在探讨这些模型在心理数学任务中的计算过程。

Method: 本文提出了两种技术：Context-Aware Mean Ablation (CAMA) 和 Attention-Based Peeking (ABP)，用于研究大型语言模型在心理数学任务中的内部运作。

Result: 通过CAMA和ABP技术，我们发现了一个名为All-for-One (AF1) 的子图，在各种心理数学任务中表现出高准确性。有意义的计算发生在非常晚的层深度，并且只在最后一个标记上进行。

Conclusion: 实验表明，这种子图对于高模型性能是充分且必要的，并且可以在不同模型之间迁移，适用于各种输入风格。CAMA和ABP的不同消融实验揭示了它们相对于其他方法的独特优势，这可能具有独立的兴趣。

Abstract: Large language models (LLMs) demonstrate proficiency across numerous
computational tasks, yet their inner workings remain unclear. In theory, the
combination of causal self-attention and multilayer perceptron layers allows
every token to access and compute information based on all preceding tokens. In
practice, to what extent are such operations present? In this paper, on mental
math tasks (i.e., direct math calculation via next-token prediction without
explicit reasoning), we investigate this question in three steps: inhibiting
input-specific token computations in the initial layers, restricting the routes
of information transfer across token positions in the next few layers, and
forcing all computation to happen at the last token in the remaining layers.
With two proposed techniques, Context-Aware Mean Ablation (CAMA) and
Attention-Based Peeking (ABP), we identify an All-for-One subgraph (AF1) with
high accuracy on a wide variety of mental math tasks, where meaningful
computation occurs very late (in terms of layer depth) and only at the last
token, which receives information of other tokens in few specific middle
layers. Experiments on a variety of models and arithmetic expressions show that
this subgraph is sufficient and necessary for high model performance, transfers
across different models, and works on a variety of input styles. Ablations on
different CAMA and ABP alternatives reveal their unique advantages over other
methods, which may be of independent interest.

</details>


### [36] [Steering MoE LLMs via Expert (De)Activation](https://arxiv.org/abs/2509.09660)
*Mohsen Fayyaz,Ali Modarressi,Hanieh Deilamsalehy,Franck Dernoncourt,Ryan Rossi,Trung Bui,Hinrich Schütze,Nanyun Peng*

Main category: cs.CL

TL;DR: SteerMoE是一种新的框架，用于调节Mixture-of-Experts (MoE)模型的行为，通过检测和控制与行为相关的专家，提高模型的安全性和忠实度，并揭示了专家内部可能隐藏的对齐伪造的新维度。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型在处理不同输入时可能表现出不同的行为，但缺乏一种有效的方法来检测和控制这些行为相关的专家。因此，需要一种新的框架来调节模型的行为，以提高其安全性和忠实度。

Method: SteerMoE框架通过检测在对比输入中具有不同激活模式的专家，并在推理过程中选择性地（去）激活这些专家，从而实现对模型行为的控制。

Result: 在11个基准测试和6个大型语言模型上，SteerMoE框架提高了安全性高达+20%和忠实度高达+27%。在对抗攻击模式下，它单独降低了安全性达-41%，当与现有越狱方法结合使用时，甚至降低了100%，绕过了所有安全防护措施，暴露了专家内部可能隐藏的对齐伪造的新维度。

Conclusion: SteerMoE框架能够通过检测和控制与行为相关的专家来调节Mixture-of-Experts (MoE)模型的行为，这为提高模型的安全性和忠实度提供了新的方法，并揭示了专家内部可能隐藏的对齐伪造的新维度。

Abstract: Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token
through a subset of specialized Feed-Forward Networks (FFN), known as experts.
We present SteerMoE, a framework for steering MoE models by detecting and
controlling behavior-linked experts. Our detection method identifies experts
with distinct activation patterns across paired inputs exhibiting contrasting
behaviors. By selectively (de)activating such experts during inference, we
control behaviors like faithfulness and safety without retraining or modifying
weights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to
+20% and faithfulness by +27%. In adversarial attack mode, it drops safety by
-41% alone, and -100% when combined with existing jailbreak methods, bypassing
all safety guardrails and exposing a new dimension of alignment faking hidden
within experts.

</details>


### [37] [CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning in Large Language Models](https://arxiv.org/abs/2509.09675)
*Runpeng Dai,Linfeng Song,Haolin Liu,Zhenwen Liang,Dian Yu,Haitao Mi,Zhaopeng Tu,Rui Liu,Tong Zheng,Hongtu Zhu,Dong Yu*

Main category: cs.CL

TL;DR: 本文提出了一种名为好奇心驱动探索（CDE）的新方法，用于增强强化学习与可验证奖励（RLVR）框架下的大型语言模型（LLMs）的推理能力。通过利用模型自身的内在好奇心来指导探索，该方法在AIME基准测试中取得了显著的性能提升，并揭示了RLVR中的校准崩溃机制。


<details>
  <summary>Details</summary>
Motivation: 当前的RLVR方法常常探索不足，导致过早收敛和熵崩溃。为了应对这一挑战，我们提出了好奇心驱动探索（CDE）框架，以提高模型的探索能力。

Method: 我们引入了好奇心驱动探索（CDE），利用模型自身的内在好奇心来指导探索。我们通过来自执行者和评论家的信号来形式化好奇心：对于执行者，我们使用其生成响应的困惑度；对于评论家，我们使用多头架构的价值估计方差。这两种信号都在RLVR框架内作为探索奖励来引导模型。

Result: 我们的方法在AIME基准测试中相比标准RLVR实现了大约+3点的改进。进一步分析揭示了RLVR中的校准崩溃机制，为常见的LLM失败模式提供了见解。

Conclusion: 我们的方法在AIME基准测试中相比标准RLVR实现了大约+3点的改进，并揭示了RLVR中的校准崩溃机制，为常见的LLM失败模式提供了见解。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful paradigm
for enhancing the reasoning ability of Large Language Models (LLMs). Yet
current RLVR methods often explore poorly, leading to premature convergence and
entropy collapse. To address this challenge, we introduce Curiosity-Driven
Exploration (CDE), a framework that leverages the model's own intrinsic sense
of curiosity to guide exploration. We formalize curiosity with signals from
both the actor and the critic: for the actor, we use perplexity over its
generated response, and for the critic, we use the variance of value estimates
from a multi-head architecture. Both signals serve as an exploration bonus
within the RLVR framework to guide the model. Our theoretical analysis shows
that the actor-wise bonus inherently penalizes overconfident errors and
promotes diversity among correct responses; moreover, we connect the
critic-wise bonus to the well-established count-based exploration bonus in RL.
Empirically, our method achieves an approximate +3 point improvement over
standard RLVR using GRPO/PPO on AIME benchmarks. Further analysis identifies a
calibration collapse mechanism within RLVR, shedding light on common LLM
failure modes.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [38] [Generative Engine Optimization: How to Dominate AI Search](https://arxiv.org/abs/2509.08919)
*Mahe Chen,Xiaoxuan Wang,Kaiwen Chen,Nick Koudas*

Main category: cs.IR

TL;DR: 本文分析了生成式AI搜索引擎与传统搜索引擎之间的差异，并提出了生成式引擎优化的战略议程。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI驱动的搜索引擎的快速采用，信息检索正在从传统的排名列表转变为合成的、有引用支持的答案。这挑战了现有的SEO实践，需要一种新的范式，即生成式引擎优化（GEO）。

Method: 本文通过一系列大规模、受控实验，在多个垂直领域、语言和查询改写中对AI搜索和传统网络搜索（Google）进行了全面比较分析。

Result: 研究结果表明，AI搜索在信息来源上表现出对获得的媒体（第三方权威来源）的系统性且压倒性的偏见，而Google则更平衡。此外，AI搜索服务在领域多样性、新鲜度、跨语言稳定性以及对措辞的敏感性方面存在显著差异。

Conclusion: 本文提供了在新的生成式搜索环境中实现可见性的基础实证分析和战略框架。

Abstract: The rapid adoption of generative AI-powered search engines like ChatGPT,
Perplexity, and Gemini is fundamentally reshaping information retrieval, moving
from traditional ranked lists to synthesized, citation-backed answers. This
shift challenges established Search Engine Optimization (SEO) practices and
necessitates a new paradigm, which we term Generative Engine Optimization
(GEO).
  This paper presents a comprehensive comparative analysis of AI Search and
traditional web search (Google). Through a series of large-scale, controlled
experiments across multiple verticals, languages, and query paraphrases, we
quantify critical differences in how these systems source information. Our key
findings reveal that AI Search exhibit a systematic and overwhelming bias
towards Earned media (third-party, authoritative sources) over Brand-owned and
Social content, a stark contrast to Google's more balanced mix. We further
demonstrate that AI Search services differ significantly from each other in
their domain diversity, freshness, cross-language stability, and sensitivity to
phrasing.
  Based on these empirical results, we formulate a strategic GEO agenda. We
provide actionable guidance for practitioners, emphasizing the critical need
to: (1) engineer content for machine scannability and justification, (2)
dominate earned media to build AI-perceived authority, (3) adopt
engine-specific and language-aware strategies, and (4) overcome the inherent
"big brand bias" for niche players. Our work provides the foundational
empirical analysis and a strategic framework for achieving visibility in the
new generative search landscape.

</details>


### [39] [Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations](https://arxiv.org/abs/2509.09651)
*Zakaria El Kassimi,Fares Fourati,Mohamed-Slim Alouini*

Main category: cs.IR

TL;DR: 本文提出了一种电信特定的检索增强生成（RAG）流程，并创建了第一个用于无线电法规领域的多选评估集。结果表明，精心定位的接地可以提供一个简单而强大的基线，并有效解决法规问答问题。


<details>
  <summary>Details</summary>
Motivation: 我们研究了无线电法规领域的问答，这是一个法律敏感且高风险的领域。

Method: 我们提出了一个电信特定的检索增强生成（RAG）流程，并引入了我们认为的第一个多选评估集，该集从权威来源中使用自动化过滤和人工验证构建。

Result: 我们的检索器在定义的领域特定检索指标下达到了约97%的准确率。除了检索之外，我们的方法在所有测试模型的生成准确性方面都持续提高。特别是，虽然天真地插入没有结构化检索的文档仅对GPT-4o产生微不足道的收益（不到1%），但应用我们的流程却带来了近12%的相对改进。

Conclusion: 这些发现表明，精心定位的接地提供了一个简单而强大的基线，并为法规问答提供了有效的领域特定解决方案。

Abstract: We study question answering in the domain of radio regulations, a legally
sensitive and high-stakes area. We propose a telecom-specific
Retrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge,
the first multiple-choice evaluation set for this domain, constructed from
authoritative sources using automated filtering and human validation. To assess
retrieval quality, we define a domain-specific retrieval metric, under which
our retriever achieves approximately 97% accuracy. Beyond retrieval, our
approach consistently improves generation accuracy across all tested models. In
particular, while naively inserting documents without structured retrieval
yields only marginal gains for GPT-4o (less than 1%), applying our pipeline
results in nearly a 12% relative improvement. These findings demonstrate that
carefully targeted grounding provides a simple yet strong baseline and an
effective domain-specific solution for regulatory question answering. All code
and evaluation scripts, along with our derived question-answer dataset, are
available at https://github.com/Zakaria010/Radio-RAG.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [40] [OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning](https://arxiv.org/abs/2509.09332)
*Yuecheng Liu,Dafeng Chi,Shiguang Wu,Zhanguang Zhang,Yuzheng Zhuang,Bowen Yang,He Zhu,Lingfeng Zhang,Pengwei Xie,David Gamaliel Arcos Bravo,Yingxue Zhang,Jianye Hao,Xingyue Quan*

Main category: cs.RO

TL;DR: OmniEVA is an embodied versatile planner that addresses the limitations of current MLLM-based embodied systems by introducing a Task-Adaptive 3D Grounding mechanism and an Embodiment-Aware Reasoning framework, achieving state-of-the-art performance in embodied reasoning and planning.


<details>
  <summary>Details</summary>
Motivation: Current MLLM-based embodied systems face two critical limitations: (1) Geometric Adaptability Gap: models trained solely on 2D inputs or with hard-coded 3D geometry injection suffer from either insufficient spatial information or restricted 2D generalization, leading to poor adaptability across tasks with diverse spatial demands. (2) Embodiment Constraint Gap: prior work often neglects the physical constraints and capacities of real robots, resulting in task plans that are theoretically valid but practically infeasible.

Method: Introduce OmniEVA -- an embodied versatile planner that enables advanced embodied reasoning and task planning through two pivotal innovations: (1) a Task-Adaptive 3D Grounding mechanism, which introduces a gated router to perform explicit selective regulation of 3D fusion based on contextual requirements, enabling context-aware 3D grounding for diverse embodied tasks. (2) an Embodiment-Aware Reasoning framework that jointly incorporates task goals and embodiment constraints into the reasoning loop, resulting in planning decisions that are both goal-directed and executable.

Result: Extensive experimental results demonstrate that OmniEVA achieves state-of-the-art general embodied reasoning performance and exhibits a strong ability across a wide range of downstream scenarios. Evaluations of a suite of proposed embodied benchmarks, including both primitive and composite tasks, confirm its robust and versatile planning capabilities.

Conclusion: OmniEVA not only achieves state-of-the-art general embodied reasoning performance, but also exhibits a strong ability across a wide range of downstream scenarios. Evaluations of a suite of proposed embodied benchmarks confirm its robust and versatile planning capabilities.

Abstract: Recent advances in multimodal large language models (MLLMs) have opened new
opportunities for embodied intelligence, enabling multimodal understanding,
reasoning, and interaction, as well as continuous spatial decision-making.
Nevertheless, current MLLM-based embodied systems face two critical
limitations. First, Geometric Adaptability Gap: models trained solely on 2D
inputs or with hard-coded 3D geometry injection suffer from either insufficient
spatial information or restricted 2D generalization, leading to poor
adaptability across tasks with diverse spatial demands. Second, Embodiment
Constraint Gap: prior work often neglects the physical constraints and
capacities of real robots, resulting in task plans that are theoretically valid
but practically infeasible.To address these gaps, we introduce OmniEVA -- an
embodied versatile planner that enables advanced embodied reasoning and task
planning through two pivotal innovations: (1) a Task-Adaptive 3D Grounding
mechanism, which introduces a gated router to perform explicit selective
regulation of 3D fusion based on contextual requirements, enabling
context-aware 3D grounding for diverse embodied tasks. (2) an Embodiment-Aware
Reasoning framework that jointly incorporates task goals and embodiment
constraints into the reasoning loop, resulting in planning decisions that are
both goal-directed and executable. Extensive experimental results demonstrate
that OmniEVA not only achieves state-of-the-art general embodied reasoning
performance, but also exhibits a strong ability across a wide range of
downstream scenarios. Evaluations of a suite of proposed embodied benchmarks,
including both primitive and composite tasks, confirm its robust and versatile
planning capabilities. Project page: https://omnieva.github.io

</details>


### [41] [SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning](https://arxiv.org/abs/2509.09674)
*Haozhan Li,Yuxin Zuo,Jiale Yu,Yuhao Zhang,Zhaohui Yang,Kaiyan Zhang,Xuekai Zhu,Yuchen Zhang,Tianxing Chen,Ganqu Cui,Dehui Wang,Dingxiang Luo,Yuchen Fan,Youbang Sun,Jia Zeng,Jiangmiao Pang,Shanghang Zhang,Yu Wang,Yao Mu,Bowen Zhou,Ning Ding*

Main category: cs.RO

TL;DR: 本文提出了SimpleVLA-RL，一个针对VLA模型的高效强化学习框架，通过引入VLA特定的轨迹采样、可扩展的并行化、多环境渲染和优化的损失计算，显著提升了VLA模型在现实任务中的表现，并发现了新的现象'pushcut'。


<details>
  <summary>Details</summary>
Motivation: 尽管通过大规模预训练和监督微调（SFT）取得了显著进展，但这些模型面临两个基本挑战：(i) 用于SFT扩展的大规模人类操作机器人轨迹的稀缺性和高成本，以及(ii) 有限的任务泛化能力。最近大型推理模型（LRMs）的突破表明，强化学习（RL）可以显著增强逐步推理能力，这引发了一个自然问题：RL能否同样改善VLA的长期步骤动作规划？

Method: 本文引入了SimpleVLA-RL，这是一个针对VLA模型的高效强化学习框架。基于veRL，我们引入了VLA特定的轨迹采样、可扩展的并行化、多环境渲染和优化的损失计算。

Result: 当应用于OpenVLA-OFT时，SimpleVLA-RL在LIBERO上达到了最先进（SoTA）性能，并且在我们引入的探索增强策略下，在RoboTwin 1.0&2.0上超过了π0。

Conclusion: SimpleVLA-RL不仅减少了对大规模数据的依赖，还实现了稳健的泛化，并在现实任务中显著超越了SFT。此外，我们在RL训练中发现了一个新的现象'pushcut'，其中策略发现了之前训练过程中未见过的模式。

Abstract: Vision-Language-Action (VLA) models have recently emerged as a powerful
paradigm for robotic manipulation. Despite substantial progress enabled by
large-scale pretraining and supervised fine-tuning (SFT), these models face two
fundamental challenges: (i) the scarcity and high cost of large-scale
human-operated robotic trajectories required for SFT scaling, and (ii) limited
generalization to tasks involving distribution shift. Recent breakthroughs in
Large Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can
dramatically enhance step-by-step reasoning capabilities, raising a natural
question: Can RL similarly improve the long-horizon step-by-step action
planning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL
framework tailored for VLA models. Building upon veRL, we introduce
VLA-specific trajectory sampling, scalable parallelization, multi-environment
rendering, and optimized loss computation. When applied to OpenVLA-OFT,
SimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $\pi_0$
on RoboTwin 1.0\&2.0 with the exploration-enhancing strategies we introduce.
SimpleVLA-RL not only reduces dependence on large-scale data and enables robust
generalization, but also remarkably surpasses SFT in real-world tasks.
Moreover, we identify a novel phenomenon ``pushcut'' during RL training,
wherein the policy discovers previously unseen patterns beyond those seen in
the previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [42] [Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs](https://arxiv.org/abs/2509.08847)
*Amna Hassan*

Main category: cs.AI

TL;DR: 本文提出了一种新的框架，通过自然语言处理和多模态大型语言模型将游戏设计文档转换为功能性的Unity游戏原型。系统包括一个专门用于Unity代码生成的微调LLaMA-3模型和一个自定义的Unity集成包，评估结果显示其在多个指标上优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决AI辅助游戏开发中的关键问题，通过将游戏设计文档转换为功能性的Unity游戏原型，提高从游戏设计到实现的效率。

Method: 我们引入了一个端到端的系统，该系统解析游戏设计文档，提取结构化的游戏规范，并合成符合Unity的C#代码，实现了设计文档中定义的核心机制、系统和架构。我们的方法结合了一个专门用于Unity代码生成的微调LLaMA-3模型和一个自定义的Unity集成包，以简化实现过程。

Result: 评估结果表明，与基线模型相比，我们的微调模型在编译成功率、GDD遵循度、最佳实践采用和代码模块化指标方面表现出色，平均得分为4.8/5.0。生成的模板在多个游戏类型中对GDD规范有很高的遵循度。

Conclusion: 我们的系统有效解决了AI辅助游戏开发中的关键差距，将大型语言模型定位为在从游戏设计到实现的过渡中很有价值的工具。

Abstract: This paper presents a novel framework for automated game template generation
by transforming Game Design Documents (GDDs) into functional Unity game
prototypes using Natural Language Processing (NLP) and multi-modal Large
Language Models (LLMs). We introduce an end-to-end system that parses GDDs,
extracts structured game specifications, and synthesizes Unity-compatible C#
code that implements the core mechanics, systems, and architecture defined in
the design documentation. Our approach combines a fine-tuned LLaMA-3 model
specialized for Unity code generation with a custom Unity integration package
that streamlines the implementation process. Evaluation results demonstrate
significant improvements over baseline models, with our fine-tuned model
achieving superior performance (4.8/5.0 average score) compared to
state-of-the-art LLMs across compilation success, GDD adherence, best practices
adoption, and code modularity metrics. The generated templates demonstrate high
adherence to GDD specifications across multiple game genres. Our system
effectively addresses critical gaps in AI-assisted game development,
positioning LLMs as valuable tools in streamlining the transition from game
design to implementation.

</details>


### [43] [Tree-OPO: Off-policy Monte Carlo Tree-Guided Advantage Optimization for Multistep Reasoning](https://arxiv.org/abs/2509.09284)
*Bingning Huang,Tu Nguyen,Matthieu Zimmer*

Main category: cs.AI

TL;DR: 本文探讨了如何利用MCTS生成的轨迹来改进基于偏好的强化学习中的策略优化，并提出了一种分阶段的GRPO训练范式。


<details>
  <summary>Details</summary>
Motivation: 我们探索了MCTS生成的轨迹如何被重新用于改进基于偏好的强化学习中的策略优化。

Method: 我们提出了一种分阶段的GRPO训练范式，其中完成是从部分揭示的MCTS回溯中得出的，引入了一种新颖的树状结构用于优势估计。

Result: 初步结果表明，结构化的优势估计可以稳定更新并更好地反映组合推理质量，但优势饱和和奖励信号崩溃等问题依然存在。

Conclusion: 虽然结构化的优势估计可以稳定更新并更好地反映组合推理质量，但挑战如优势饱和和奖励信号崩溃仍然存在。我们提出了启发式和统计解决方案来缓解这些问题，并讨论了在分阶段或树状奖励结构下学习的开放性挑战。

Abstract: Recent advances in reasoning with large language models (LLMs) have shown the
effectiveness of Monte Carlo Tree Search (MCTS) for generating high-quality
intermediate trajectories, particularly in math and symbolic domains. Inspired
by this, we explore how MCTS-derived trajectories, traditionally used for
training value or reward models, can be repurposed to improve policy
optimization in preference-based reinforcement learning (RL). Specifically, we
focus on Group Relative Policy Optimization (GRPO), a recent algorithm that
enables preference-consistent policy learning without value networks. We
propose a staged GRPO training paradigm where completions are derived from
partially revealed MCTS rollouts, introducing a novel tree-structured setting
for advantage estimation. This leads to a rich class of prefix-conditioned
reward signals, which we analyze theoretically and empirically. Our initial
results indicate that while structured advantage estimation can stabilize
updates and better reflect compositional reasoning quality, challenges such as
advantage saturation and reward signal collapse remain. We propose heuristic
and statistical solutions to mitigate these issues and discuss open challenges
for learning under staged or tree-like reward structures.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [44] [Bona fide Cross Testing Reveals Weak Spot in Audio Deepfake Detection Systems](https://arxiv.org/abs/2509.09204)
*Chin Yuen Kwok,Jia Qi Yip,Zhen Qiu,Chi Hung Chi,Kwok Yan Lam*

Main category: cs.SD

TL;DR: 本文提出了一种新的评估框架，以解决现有音频深度伪造检测数据集中的问题，并发布了新的数据集以促进进一步研究。


<details>
  <summary>Details</summary>
Motivation: 现有的ADD数据集在真实语音方面缺乏多样性，通常只包含一种环境和语音风格，限制了它们模拟现实条件的能力。此外，使用EER作为性能指标会不成比例地加权具有更多样本的合成器，从而降低了EER的整体可靠性。

Method: 我们提出了一个名为真实交叉测试的新型评估框架，该框架结合了多样化的真实语音数据集，并汇总EER以进行更平衡的评估。

Result: 我们的方法提高了鲁棒性和可解释性，对超过150个合成器进行了基准测试，并发布了一个新的数据集以促进进一步的研究。

Conclusion: 我们的方法相比传统评估方法提高了鲁棒性和可解释性。我们对超过150个合成器进行了基准测试，并发布了一个新的数据集以促进进一步的研究。

Abstract: Audio deepfake detection (ADD) models are commonly evaluated using datasets
that combine multiple synthesizers, with performance reported as a single Equal
Error Rate (EER). However, this approach disproportionately weights
synthesizers with more samples, underrepresenting others and reducing the
overall reliability of EER. Additionally, most ADD datasets lack diversity in
bona fide speech, often featuring a single environment and speech style (e.g.,
clean read speech), limiting their ability to simulate real-world conditions.
To address these challenges, we propose bona fide cross-testing, a novel
evaluation framework that incorporates diverse bona fide datasets and
aggregates EERs for more balanced assessments. Our approach improves robustness
and interpretability compared to traditional evaluation methods. We benchmark
over 150 synthesizers across nine bona fide speech types and release a new
dataset to facilitate further research at
https://github.com/cyaaronk/audio_deepfake_eval.

</details>


### [45] [DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for Low-Latency Zero-Shot Text-To-Speech](https://arxiv.org/abs/2509.09631)
*Ngoc-Son Nguyen,Hieu-Nghia Huynh-Nguyen,Thanh V. T. Tran,Truong-Son Hy,Van Nguyen*

Main category: cs.SD

TL;DR: DiFlow-TTS is a novel model that explores purely Discrete Flow Matching for speech synthesis, achieving high performance in zero-shot TTS with fast inference and low latency.


<details>
  <summary>Details</summary>
Motivation: Recent approaches based on language models, diffusion, and flow matching have shown promising results in zero-shot TTS, but still suffer from slow inference and repetition artifacts. Existing flow-matching methods typically embed these discrete tokens into a continuous space and apply continuous flow matching, which may not fully leverage the advantages of discrete representations.

Method: DiFlow-TTS explicitly models factorized speech attributes within a compact and unified architecture. It leverages in-context learning by conditioning on textual content, along with prosodic and acoustic attributes extracted from a reference speech, enabling effective attribute cloning in a zero-shot setting. The model employs a factorized flow prediction mechanism with distinct heads for prosody and acoustic details, allowing it to learn aspect-specific distributions.

Result: Experimental results demonstrate that DiFlow-TTS achieves promising performance in several key metrics, including naturalness, prosody, preservation of speaker style, and energy control. It also maintains a compact model size and achieves low-latency inference, generating speech up to 25.8 times faster than the latest existing baselines.

Conclusion: DiFlow-TTS achieves promising performance in several key metrics, including naturalness, prosody, preservation of speaker style, and energy control. It also maintains a compact model size and achieves low-latency inference, generating speech up to 25.8 times faster than the latest existing baselines.

Abstract: Zero-shot Text-to-Speech (TTS) aims to synthesize high-quality speech that
mimics the voice of an unseen speaker using only a short reference sample,
requiring not only speaker adaptation but also accurate modeling of prosodic
attributes. Recent approaches based on language models, diffusion, and flow
matching have shown promising results in zero-shot TTS, but still suffer from
slow inference and repetition artifacts. Discrete codec representations have
been widely adopted for speech synthesis, and recent works have begun to
explore diffusion models in purely discrete settings, suggesting the potential
of discrete generative modeling for speech synthesis. However, existing
flow-matching methods typically embed these discrete tokens into a continuous
space and apply continuous flow matching, which may not fully leverage the
advantages of discrete representations. To address these challenges, we
introduce DiFlow-TTS, which, to the best of our knowledge, is the first model
to explore purely Discrete Flow Matching for speech synthesis. DiFlow-TTS
explicitly models factorized speech attributes within a compact and unified
architecture. It leverages in-context learning by conditioning on textual
content, along with prosodic and acoustic attributes extracted from a reference
speech, enabling effective attribute cloning in a zero-shot setting. In
addition, the model employs a factorized flow prediction mechanism with
distinct heads for prosody and acoustic details, allowing it to learn
aspect-specific distributions. Experimental results demonstrate that DiFlow-TTS
achieves promising performance in several key metrics, including naturalness,
prosody, preservation of speaker style, and energy control. It also maintains a
compact model size and achieves low-latency inference, generating speech up to
25.8 times faster than the latest existing baselines.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [46] [A vibe coding learning design to enhance EFL students' talking to, through, and about AI](https://arxiv.org/abs/2509.08854)
*David James Woo,Kai Guo,Yangyang Yu*

Main category: cs.CY

TL;DR: 本文报告了在英语作为外语教育中试点使用vibe coding（使用自然语言通过AI创建软件应用）的创新实践。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨使用自然语言通过AI创建软件应用（vibe coding）在英语作为外语（EFL）教育中的应用。

Method: 本文采用案例研究方法，收集了工作表、视频记录、自言自语协议、屏幕录制和AI生成图像的数据。

Result: 分析显示学生在提示工程方法上的差异，这表明不同的AI心智模型和在归因作者权方面的紧张关系。一个学生成功地vibe编码了一个符合她设计的应用程序，而另一个则遇到了技术问题，其设计与实际功能之间存在重大差距。

Conclusion: 本文认为AI作为有益的语言工具，有效vibe编码教学需要明确的元语言支撑，教授结构化的提示工程，促进批判性的作者权讨论，并发展用于表达AI心智模型的词汇。

Abstract: This innovative practice article reports on the piloting of vibe coding
(using natural language to create software applications with AI) for English as
a Foreign Language (EFL) education. We developed a human-AI meta-languaging
framework with three dimensions: talking to AI (prompt engineering), talking
through AI (negotiating authorship), and talking about AI (mental models of
AI). Using backward design principles, we created a four-hour workshop where
two students designed applications addressing authentic EFL writing challenges.
We adopted a case study methodology, collecting data from worksheets and video
recordings, think-aloud protocols, screen recordings, and AI-generated images.
Contrasting cases showed one student successfully vibe coding a functional
application cohering to her intended design, while another encountered
technical difficulties with major gaps between intended design and actual
functionality. Analysis reveals differences in students' prompt engineering
approaches, suggesting different AI mental models and tensions in attributing
authorship. We argue that AI functions as a beneficial languaging machine, and
that differences in how students talk to, through, and about AI explain vibe
coding outcome variations. Findings indicate that effective vibe coding
instruction requires explicit meta-languaging scaffolding, teaching structured
prompt engineering, facilitating critical authorship discussions, and
developing vocabulary for articulating AI mental models.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [47] [Open-sci-ref-0.01: open and reproducible reference baselines for language model and dataset comparison](https://arxiv.org/abs/2509.09009)
*Marianna Nezhurina,Taishi Nakamura,Timur Carstensen,Niccolò Ajroldi,Ville Komulainen,David Salinas,Jenia Jitsev*

Main category: cs.LG

TL;DR: 本文介绍了open-sci-ref，一个用于研究的密集Transformer模型系列，旨在为不同规模和数据集上的训练方法提供基准线。


<details>
  <summary>Details</summary>
Motivation: 为了提供一个参考点，使研究者能够评估其他训练方法在不同规模和数据集上的合理性与质量。

Method: 训练了一系列密集的Transformer模型，作为跨多个模型和标记规模的研究基线。

Result: 在NemoTron-CC HQ上训练的表现优于其他参考数据集，其次是DCLM-baseline和FineWeb-Edu。

Conclusion: 通过建立基准线，研究者可以评估不同训练方法在不同规模和数据集上的合理性和质量。

Abstract: We introduce open-sci-ref, a family of dense transformer models trained as
research baselines across multiple model (0.13B to 1.7B parameters) and token
scales (up to 1T) on 8 recent open reference datasets. Evaluating the models on
various standardized benchmarks, our training runs set establishes reference
points that enable researchers to assess the sanity and quality of alternative
training approaches across scales and datasets. Intermediate checkpoints allow
comparison and studying of the training dynamics. The established reference
baselines allow training procedures to be compared through their scaling
trends, aligning them on a common compute axis. Comparison of open reference
datasets reveals that training on NemoTron-CC HQ consistently outperforms other
reference datasets, followed by DCLM-baseline and FineWeb-Edu. In addition to
intermediate training checkpoints, the release includes logs, code, and
downstream evaluations to simplify reproduction, standardize comparison, and
facilitate future research.

</details>


### [48] [Identifying Key Features for Establishing Sustainable Agro-Tourism Centre: A Data Driven Approach](https://arxiv.org/abs/2509.09214)
*Alka Gadakh,Vidya Kumbhar,Sonal Khosla,Kumar Karunendra*

Main category: cs.LG

TL;DR: 本研究探讨了农业旅游的增长策略，通过文献综述和先进技术识别关键指标，并利用LASSO方法和多种机器学习模型进行特征选择，结果显示逻辑回归模型在分类准确率上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 农业旅游作为一种战略经济模式，旨在通过多样化当地社区（如农民）的收入来源来促进农村发展，同时促进本土文化遗产和传统农业实践的保护。由于农业旅游是一个快速发展的子领域，需要详细研究其增长策略。

Method: 该研究分为两个阶段：第一阶段通过全面的文献综述确定了重要的指标，第二阶段使用了最先进的技术来识别促进农业旅游增长的重要指标。应用了机器学习模型进行特征选择，包括LASSO方法以及逻辑回归（LR）、决策树（DT）、随机森林（RF）和极端梯度提升（XGBOOST）模型。

Result: 研究结果表明，使用LASSO方法结合逻辑回归（LR）模型在70-30%的训练测试数据中取得了最高的分类准确率98%，而在80-20%的训练测试数据中，LR模型保持最高准确率99%。

Conclusion: 研究结果表明，使用LASSO方法结合逻辑回归（LR）模型在70-30%的训练测试数据中取得了最高的分类准确率98%，而在80-20%的训练测试数据中，LR模型保持最高准确率99%。

Abstract: Agro-tourism serves as a strategic economic model designed to facilitate
rural development by diversifying income streams for local communities like
farmers while promoting the conservation of indigenous cultural heritage and
traditional agricultural practices. As a very booming subdomain of tourism,
there is a need to study the strategies for the growth of Agro-tourism in
detail. The current study has identified the important indicators for the
growth and enhancement of agro-tourism. The study is conducted in two phases:
identification of the important indicators through a comprehensive literature
review and in the second phase state-of-the-art techniques were used to
identify the important indicators for the growth of agro-tourism. The
indicators are also called features synonymously, the machine learning models
for feature selection were applied and it was observed that the Least Absolute
Shrinkage and Selection Operator (LASSO) method combined with, the machine
Learning Classifiers such as Logistic Regression (LR), Decision Trees (DT),
Random Forest (RF) Tree, and Extreme Gradient Boosting (XGBOOST) models were
used to suggest the growth of the agro-tourism. The results show that with the
LASSO method, LR model gives the highest classification accuracy of 98% in
70-30% train-test data followed by RF with 95% accuracy. Similarly, in the
80-20% train-test data LR maintains the highest accuracy at 99%, while DT and
XGBoost follow with 97% accuracy.

</details>


### [49] [Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents](https://arxiv.org/abs/2509.09265)
*Jiawei Wang,Jiacai Liu,Yuqian Fu,Yingru Li,Xintao Wang,Yuan Lin,Yu Yue,Lin Zhang,Yang Wang,Ke Wang*

Main category: cs.LG

TL;DR: 本文提出了一种名为EMPG的框架，通过基于步骤不确定性及最终任务结果重新校准学习信号，解决了LLM在长时任务中因稀疏奖励导致的信用分配问题。实验表明，EMPG在多个任务中表现优异，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: In long-horizon tasks, recent agents based on Large Language Models (LLMs) face a significant challenge that sparse, outcome-based rewards make it difficult to assign credit to intermediate steps.

Method: Entropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the learning signal based on step-wise uncertainty and the final task outcome.

Result: Through comprehensive experiments on three challenging agent tasks, WebShop, ALFWorld, and Deep Search, we demonstrate that EMPG achieves substantial performance gains.

Conclusion: EMPG achieves substantial performance gains and significantly outperforms strong policy gradient baselines.

Abstract: In long-horizon tasks, recent agents based on Large Language Models (LLMs)
face a significant challenge that sparse, outcome-based rewards make it
difficult to assign credit to intermediate steps. Previous methods mainly focus
on creating dense reward signals to guide learning, either through traditional
reinforcement learning techniques like inverse reinforcement learning or by
using Process Reward Models for step-by-step feedback. In this paper, we
identify a fundamental problem in the learning dynamics of LLMs: the magnitude
of policy gradients is inherently coupled with the entropy, which leads to
inefficient small updates for confident correct actions and potentially
destabilizes large updates for uncertain ones. To resolve this, we propose
Entropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the
learning signal based on step-wise uncertainty and the final task outcome. EMPG
amplifies updates for confident correct actions, penalizes confident errors,
and attenuates updates from uncertain steps to stabilize exploration. We
further introduce a bonus term for future clarity that encourages agents to
find more predictable solution paths. Through comprehensive experiments on
three challenging agent tasks, WebShop, ALFWorld, and Deep Search, we
demonstrate that EMPG achieves substantial performance gains and significantly
outperforms strong policy gradient baselines. Project page is at
https://empgseed-seed.github.io/

</details>


### [50] [LLMs Don't Know Their Own Decision Boundaries: The Unreliability of Self-Generated Counterfactual Explanations](https://arxiv.org/abs/2509.09396)
*Harry Mayne,Ryan Othniel Kearns,Yushi Yang,Andrew M. Bean,Eoin Delaney,Chris Russell,Adam Mahdi*

Main category: cs.LG

TL;DR: This paper studies self-generated counterfactual explanations (SCEs) in language models and finds that they are often valid but not minimal, making them ineffective or potentially misleading as explainability tools.


<details>
  <summary>Details</summary>
Motivation: To collaborate effectively with humans, language models must be able to explain their decisions in natural language. The study focuses on self-explanations, specifically SCEs, to understand their effectiveness as an explainability tool.

Method: We study self-generated counterfactual explanations (SCEs) where a model explains its prediction by modifying the input such that it would have predicted a different outcome. We evaluate whether LLMs can produce SCEs that are valid and minimal.

Result: LLMs typically produce SCEs that are valid but not minimal, offering little insight into their decision-making behavior. When asked to generate minimal counterfactuals, LLMs make excessively small edits that fail to change predictions. The validity-minimality trade-off is consistent across several LLMs, datasets, and evaluation settings.

Conclusion: SCEs are, at best, an ineffective explainability tool and, at worst, can provide misleading insights into model behaviour. Proposals to deploy LLMs in high-stakes settings must consider the impact of unreliable self-explanations on downstream decision-making.

Abstract: To collaborate effectively with humans, language models must be able to
explain their decisions in natural language. We study a specific type of
self-explanation: self-generated counterfactual explanations (SCEs), where a
model explains its prediction by modifying the input such that it would have
predicted a different outcome. We evaluate whether LLMs can produce SCEs that
are valid, achieving the intended outcome, and minimal, modifying the input no
more than necessary. When asked to generate counterfactuals, we find that LLMs
typically produce SCEs that are valid, but far from minimal, offering little
insight into their decision-making behaviour. Worryingly, when asked to
generate minimal counterfactuals, LLMs typically make excessively small edits
that fail to change predictions. The observed validity-minimality trade-off is
consistent across several LLMs, datasets, and evaluation settings. Our findings
suggest that SCEs are, at best, an ineffective explainability tool and, at
worst, can provide misleading insights into model behaviour. Proposals to
deploy LLMs in high-stakes settings must consider the impact of unreliable
self-explanations on downstream decision-making. Our code is available at
https://github.com/HarryMayne/SCEs.

</details>


### [51] [ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable Orthogonal Butterfly Transforms](https://arxiv.org/abs/2509.09679)
*Bingxin Xu,Zhen Dong,Oussama Elachqar,Yuzhang Shang*

Main category: cs.LG

TL;DR: ButterflyQuant is a novel method for 2-bit quantization of large language models that uses learnable butterfly transforms and uniformity regularization to achieve better performance than existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing rotation-based methods use fixed transforms that cannot adapt to specific weight distributions, leading to suboptimal performance in extreme 2-bit quantization.

Method: ButterflyQuant replaces Hadamard rotations with learnable butterfly transforms parameterized by continuous Givens rotation angles, which allows for smooth optimization while maintaining orthogonality. It also introduces uniformity regularization on post-transformation activations to improve quantization.

Result: ButterflyQuant achieves a perplexity of 15.4 on LLaMA-2-7B with 2-bit quantization, compared to 22.1 for QuaRot.

Conclusion: ButterflyQuant achieves better performance than existing methods like QuaRot when applied to LLaMA-2-7B with 2-bit quantization.

Abstract: Large language models require massive memory footprints, severely limiting
deployment on consumer hardware. Quantization reduces memory through lower
numerical precision, but extreme 2-bit quantization suffers from catastrophic
performance loss due to outliers in activations. Rotation-based methods such as
QuIP and QuaRot apply orthogonal transforms to eliminate outliers before
quantization, using computational invariance: $\mathbf{y} = \mathbf{Wx} =
(\mathbf{WQ}^T)(\mathbf{Qx})$ for orthogonal $\mathbf{Q}$. However, these
methods use fixed transforms--Hadamard matrices achieving optimal worst-case
coherence $\mu = 1/\sqrt{n}$--that cannot adapt to specific weight
distributions. We identify that different transformer layers exhibit distinct
outlier patterns, motivating layer-adaptive rotations rather than
one-size-fits-all approaches. We propose ButterflyQuant, which replaces
Hadamard rotations with learnable butterfly transforms parameterized by
continuous Givens rotation angles. Unlike Hadamard's discrete $\{+1, -1\}$
entries that are non-differentiable and prohibit gradient-based learning,
butterfly transforms' continuous parameterization enables smooth optimization
while guaranteeing orthogonality by construction. This orthogonal constraint
ensures theoretical guarantees in outlier suppression while achieving $O(n \log
n)$ computational complexity with only $\frac{n \log n}{2}$ learnable
parameters. We further introduce a uniformity regularization on
post-transformation activations to promote smoother distributions amenable to
quantization. Learning requires only 128 calibration samples and converges in
minutes on a single GPU--a negligible one-time cost. On LLaMA-2-7B with 2-bit
quantization, ButterflyQuant achieves 15.4 perplexity versus 22.1 for QuaRot.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [52] [Recurrence Meets Transformers for Universal Multimodal Retrieval](https://arxiv.org/abs/2509.08897)
*Davide Caffagni,Sara Sarto,Marcella Cornia,Lorenzo Baraldi,Rita Cucchiara*

Main category: cs.CV

TL;DR: 本文提出了 ReT-2，一种统一的检索模型，支持多模态查询和多模态文档集合的搜索，通过多层表示和循环 Transformer 架构实现动态信息整合。ReT-2 在多个基准测试中表现出色，同时具有更快的推理速度和更低的内存消耗。


<details>
  <summary>Details</summary>
Motivation: 随着多模态检索的快速发展及其在 LLMs 和多模态 LLMs 中的应用，出现了越来越复杂的检索任务。现有的方法主要依赖于特定任务的微调视觉语言模型，并且仅限于单模态查询或文档。

Method: ReT-2 是一个统一的检索模型，支持多模态查询（包括图像和文本），并在包含文本和图像共存的多模态文档集合中进行搜索。ReT-2 利用多层表示和具有 LSTM 风格门控机制的循环 Transformer 架构，动态整合跨层和模态的信息，捕捉细粒度的视觉和文本细节。

Result: 在 M2KR 和 M-BEIR 基准测试中，ReT-2 在不同检索配置下表现出色，取得了最先进的性能。与之前的方法相比，ReT-2 提供了更快的推理速度和更低的内存消耗。当集成到检索增强生成管道中时，ReT-2 还提高了 Encyclopedic-VQA 和 InfoSeek 数据集的下游性能。

Conclusion: ReT-2 在多种设置中 consistently achieves state-of-the-art performance，同时提供更快的推理和更少的内存使用。当集成到检索增强生成管道中时，ReT-2 也提高了 Encyclopedic-VQA 和 InfoSeek 数据集的下游性能。

Abstract: With the rapid advancement of multimodal retrieval and its application in
LLMs and multimodal LLMs, increasingly complex retrieval tasks have emerged.
Existing methods predominantly rely on task-specific fine-tuning of
vision-language models and are limited to single-modality queries or documents.
In this paper, we propose ReT-2, a unified retrieval model that supports
multimodal queries, composed of both images and text, and searches across
multimodal document collections where text and images coexist. ReT-2 leverages
multi-layer representations and a recurrent Transformer architecture with
LSTM-inspired gating mechanisms to dynamically integrate information across
layers and modalities, capturing fine-grained visual and textual details. We
evaluate ReT-2 on the challenging M2KR and M-BEIR benchmarks across different
retrieval configurations. Results demonstrate that ReT-2 consistently achieves
state-of-the-art performance across diverse settings, while offering faster
inference and reduced memory usage compared to prior approaches. When
integrated into retrieval-augmented generation pipelines, ReT-2 also improves
downstream performance on Encyclopedic-VQA and InfoSeek datasets. Our source
code and trained models are publicly available at:
https://github.com/aimagelab/ReT-2

</details>


### [53] [COCO-Urdu: A Large-Scale Urdu Image-Caption Dataset with Multimodal Quality Estimation](https://arxiv.org/abs/2509.09014)
*Umair Hassan*

Main category: cs.CV

TL;DR: 本文介绍了COCO-Urdu，这是一个从MS COCO衍生的大规模图像-标题数据集，包含59,000张图片和319,000个乌尔都语标题，通过分层抽样保持原始分布。标题通过SeamlessM4T v2翻译，并通过混合多模态质量评估框架进行验证，低评分标题通过开源大语言模型进行优化。COCO-Urdu是目前最大的公开可用的乌尔都语标题数据集。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语在多模态和视觉-语言研究中严重不足，缺乏大规模高质量的数据集限制了乌尔都语能力系统的开发，并强化了主要在高资源语言上训练的多语言视觉-语言模型中的偏见。

Method: 使用SeamlessM4T v2进行翻译，并通过混合多模态质量评估框架（包括COMET-Kiwi、CLIP-based相似性以及BERTScore与反向翻译）验证了标题的质量，低评分标题通过开源大语言模型进行了迭代优化。

Result: COCO-Urdu在BLEU、SacreBLEU和chrF上的基准测试结果表现强劲。

Conclusion: 通过发布数据集和质量评估流程，我们旨在减少多模态研究中的语言偏见，并为包容性的视觉-语言系统奠定基础。

Abstract: Urdu, spoken by over 250 million people, remains critically under-served in
multimodal and vision-language research. The absence of large-scale,
high-quality datasets has limited the development of Urdu-capable systems and
reinforced biases in multilingual vision-language models trained primarily on
high-resource languages. To address this gap, we present COCO-Urdu, a
large-scale image-caption dataset derived from MS COCO, containing 59,000
images and 319,000 Urdu captions selected through stratified sampling to
preserve the original distribution. Captions were translated using SeamlessM4T
v2 and validated with a hybrid multimodal quality estimation framework that
integrates COMET-Kiwi for translation quality, CLIP-based similarity for visual
grounding, and BERTScore with back-translation for semantic consistency;
low-scoring captions were iteratively refined using open-source large language
models. We further benchmark COCO-Urdu on BLEU, SacreBLEU, and chrF, reporting
consistently strong results. To the best of our knowledge, COCO-Urdu is the
largest publicly available Urdu captioning dataset. By releasing both the
dataset and the quality estimation pipeline, we aim to reduce language bias in
multimodal research and establish a foundation for inclusive vision-language
systems.

</details>


### [54] [Can Multimodal LLMs See Materials Clearly? A Multimodal Benchmark on Materials Characterization](https://arxiv.org/abs/2509.09307)
*Zhengzhao Lai,Youbin Zheng,Zhenyang Cai,Haonan Lyu,Jinpu Yang,Hongqing Liang,Yan Hu,Benyou Wang*

Main category: cs.CV

TL;DR: 本文提出了MatCha，这是第一个针对材料表征图像理解的基准测试，包含1500个需要专家级领域知识的问题。评估显示，现有的MLLMs在处理需要高级专业知识和复杂视觉感知的问题时表现不佳，表明它们在适应真实材料表征场景方面仍有局限。MatCha有望促进新材料发现和自主科学代理等未来研究。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLLMs）在材料科学的生成和预测任务中显示出潜力，但它们在理解现实世界表征成像数据方面的能力仍未被充分探索。为了弥合这一差距，提出了MatCha基准测试。

Method: 提出MatCha，这是一个针对材料表征图像理解的基准测试，包含1500个需要专家级领域知识的问题。评估了最先进的MLLMs在MatCha上的表现，并比较了它们与人类专家的性能差异。

Result: 评估结果显示，最先进的MLLMs在MatCha上的表现与人类专家相比存在显著差距。这些模型在处理需要更高层次专业知识和复杂视觉感知的问题时表现出退化。简单的少样本提示和思维链提示难以缓解这些限制。

Conclusion: 现有MLLMs在处理需要高级专业知识和复杂视觉感知的问题时表现不佳，表明它们在适应真实材料表征场景方面仍有限制。MatCha有望促进新材料发现和自主科学代理等未来研究。

Abstract: Materials characterization is fundamental to acquiring materials information,
revealing the processing-microstructure-property relationships that guide
material design and optimization. While multimodal large language models
(MLLMs) have recently shown promise in generative and predictive tasks within
materials science, their capacity to understand real-world characterization
imaging data remains underexplored. To bridge this gap, we present MatCha, the
first benchmark for materials characterization image understanding, comprising
1,500 questions that demand expert-level domain expertise. MatCha encompasses
four key stages of materials research comprising 21 distinct tasks, each
designed to reflect authentic challenges faced by materials scientists. Our
evaluation of state-of-the-art MLLMs on MatCha reveals a significant
performance gap compared to human experts. These models exhibit degradation
when addressing questions requiring higher-level expertise and sophisticated
visual perception. Simple few-shot and chain-of-thought prompting struggle to
alleviate these limitations. These findings highlight that existing MLLMs still
exhibit limited adaptability to real-world materials characterization
scenarios. We hope MatCha will facilitate future research in areas such as new
material discovery and autonomous scientific agents. MatCha is available at
https://github.com/FreedomIntelligence/MatCha.

</details>


### [55] [FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark](https://arxiv.org/abs/2509.09680)
*Rongyao Fang,Aldrich Yu,Chengqi Duan,Linjiang Huang,Shuai Bai,Yuxuan Cai,Kun Wang,Si Liu,Xihui Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: 本文提出了FLUX-Reason-6M数据集和PRISM-Bench基准测试，旨在解决开源文本到图像模型缺乏大规模、推理导向数据集和评估基准的问题，并通过广泛评估发现了现有模型的性能差距。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大规模、注重推理的数据集和全面的评估基准，开源文本到图像模型的发展受到了阻碍，导致与领先的闭源系统相比存在性能差距。

Method: 我们引入了FLUX-Reason-6M数据集和PRISM-Bench基准测试，其中包含600万张高质量的FLUX生成图像和2000万条中英文描述，并设计了显式的生成链式思维（GCoT）来详细分解图像生成步骤。此外，还提供了七个不同的评估赛道，包括使用GCoT的长文本挑战。

Result: 我们在PRISM-Bench上对19个领先的模型进行了广泛的评估，揭示了关键的性能差距，并突出了需要改进的具体领域。

Conclusion: 我们的数据集、基准和评估代码已发布，以推动面向推理的文本到图像生成的下一次浪潮。

Abstract: The advancement of open-source text-to-image (T2I) models has been hindered
by the absence of large-scale, reasoning-focused datasets and comprehensive
evaluation benchmarks, resulting in a performance gap compared to leading
closed-source systems. To address this challenge, We introduce FLUX-Reason-6M
and PRISM-Bench (Precise and Robust Image Synthesis Measurement Benchmark).
FLUX-Reason-6M is a massive dataset consisting of 6 million high-quality
FLUX-generated images and 20 million bilingual (English and Chinese)
descriptions specifically designed to teach complex reasoning. The image are
organized according to six key characteristics: Imagination, Entity, Text
rendering, Style, Affection, and Composition, and design explicit Generation
Chain-of-Thought (GCoT) to provide detailed breakdowns of image generation
steps. The whole data curation takes 15,000 A100 GPU days, providing the
community with a resource previously unattainable outside of large industrial
labs. PRISM-Bench offers a novel evaluation standard with seven distinct
tracks, including a formidable Long Text challenge using GCoT. Through
carefully designed prompts, it utilizes advanced vision-language models for
nuanced human-aligned assessment of prompt-image alignment and image
aesthetics. Our extensive evaluation of 19 leading models on PRISM-Bench
reveals critical performance gaps and highlights specific areas requiring
improvement. Our dataset, benchmark, and evaluation code are released to
catalyze the next wave of reasoning-oriented T2I generation. Project page:
https://flux-reason-6m.github.io/ .

</details>
