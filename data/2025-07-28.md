<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 36]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.CV](#cs.CV) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Specification Self-Correction: Mitigating In-Context Reward Hacking Through Test-Time Refinement](https://arxiv.org/abs/2507.18742)
*Víctor Gallego*

Main category: cs.CL

TL;DR: 本文介绍了Specification Self-Correction (SSC)框架，该框架使语言模型能够在推理时识别并修正自身规范中的缺陷，从而减少奖励黑客攻击的可能性。


<details>
  <summary>Details</summary>
Motivation: 语言模型容易受到上下文奖励黑客攻击，即利用有缺陷的规范或评分标准来获得高分而不满足用户的真正意图。需要一种方法来识别和纠正这些缺陷。

Method: SSC框架通过多步骤推理过程，首先基于可能有缺陷的规范生成响应，然后对输出进行批判，并修订规范以消除可利用的漏洞，最后使用自我修正后的规范生成更稳健的响应。

Result: 实验表明，虽然模型在50-70%的情况下会利用有缺陷的规范，但SSC过程将这种漏洞减少了90%以上。

Conclusion: SSC框架能够在不修改模型权重的情况下，在推理时动态修复规范，从而提高模型行为的鲁棒性。

Abstract: Language models (LMs) are susceptible to in-context reward hacking, where
they exploit flaws in tainted or faulty written specifications or rubrics to
achieve high scores without fulfilling the user's true intent. We introduce
Specification Self-Correction (SSC), a novel, test-time framework that enables
an LM to identify and correct flaws within its own guiding specification. SSC
employs a multi-step inference process where the model first generates a
response based on a potentially tainted specification, critiques its output,
and then revises the specification itself to remove the exploitable loophole. A
final, more robust response is then generated using this self-corrected
specification. Across experiments spanning creative writing and agentic coding
tasks with several LMs, we demonstrate that while models initially game tainted
specifications in 50-70\% of cases, the SSC process reduces this vulnerability
by over 90\%. This dynamic repair occurs at inference time, requires no weight
modification, and leads to more robustly aligned model behavior. Code at
https://github.com/vicgalle/specification-self-correction .

</details>


### [2] [The Role of Orthographic Consistency in Multilingual Embedding Models for Text Classification in Arabic-Script Languages](https://arxiv.org/abs/2507.18762)
*Abdulhady Abas Abdullah,Amir H. Gandomi,Tarik A Rashid,Seyedali Mirjalili,Laith Abualigah,Milena Živković,Hadi Veisi*

Main category: cs.CL

TL;DR: 本文介绍了AS-RoBERTa系列模型，这些模型在阿拉伯语脚本语言的预训练中表现出色，优于现有的多语言模型。


<details>
  <summary>Details</summary>
Motivation: 在自然语言处理中，多语言模型如mBERT和XLM-RoBERTa承诺广泛的覆盖范围，但常常在共享脚本但正字法规范和文化背景不同的语言上遇到困难。这个问题在使用阿拉伯语脚本的语言中尤为明显，如库尔德语索拉尼语、阿拉伯语、波斯语和乌尔都语。

Method: 我们引入了阿拉伯语脚本RoBERTa（AS-RoBERTa）系列：四个基于RoBERTa的模型，每个模型都在针对其特定语言的大语料库上进行了预训练。通过将预训练集中在语言特定的脚本特征和统计信息上，我们的模型捕捉到了通用模型所忽视的模式。

Result: 当在分类任务上微调时，AS-RoBERTa变体比mBERT和XLM-RoBERTa高出2到5个百分点。消融研究证实了以脚本为重点的预训练是这些提升的关键。使用混淆矩阵的错误分析展示了共享脚本特征和领域特定内容如何影响性能。

Conclusion: 我们的结果强调了针对使用阿拉伯语脚本的语言进行脚本感知专业化的重要性，并支持进一步研究基于脚本和语言特异性的预训练策略。

Abstract: In natural language processing, multilingual models like mBERT and
XLM-RoBERTa promise broad coverage but often struggle with languages that share
a script yet differ in orthographic norms and cultural context. This issue is
especially notable in Arabic-script languages such as Kurdish Sorani, Arabic,
Persian, and Urdu. We introduce the Arabic Script RoBERTa (AS-RoBERTa) family:
four RoBERTa-based models, each pre-trained on a large corpus tailored to its
specific language. By focusing pre-training on language-specific script
features and statistics, our models capture patterns overlooked by
general-purpose models. When fine-tuned on classification tasks, AS-RoBERTa
variants outperform mBERT and XLM-RoBERTa by 2 to 5 percentage points. An
ablation study confirms that script-focused pre-training is central to these
gains. Error analysis using confusion matrices shows how shared script traits
and domain-specific content affect performance. Our results highlight the value
of script-aware specialization for languages using the Arabic script and
support further work on pre-training strategies rooted in script and language
specificity.

</details>


### [3] [ylmmcl at Multilingual Text Detoxification 2025: Lexicon-Guided Detoxification and Classifier-Gated Rewriting](https://arxiv.org/abs/2507.18769)
*Nicole Lai-Lopez,Lusha Wang,Su Yuan,Liza Zhang*

Main category: cs.CL

TL;DR: 我们提出了一种多语言文本净化方法，通过结合词典引导的标记、微调模型和迭代分类器机制，在多个语言中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常是无监督或单语的，无法精确地进行跨语言的净化。我们希望通过显式的有毒词汇注释来提高净化的精度和跨语言的泛化能力。

Method: 我们引入了一个多语言文本净化管道，结合了基于词典的标记、微调的序列到序列模型和基于分类器的迭代门控机制。

Result: 我们的最终模型在开发集和测试集上分别获得了0.793和0.787的xCOMET分数，以及0.612的平均官方J分数，优于基线和回译方法。

Conclusion: 我们的模型在比赛中取得了第九名的成绩，展示了在多语言文本净化任务中的强大性能和泛化能力。

Abstract: In this work, we introduce our solution for the Multilingual Text
Detoxification Task in the PAN-2025 competition for the ylmmcl team: a robust
multilingual text detoxification pipeline that integrates lexicon-guided
tagging, a fine-tuned sequence-to-sequence model (s-nlp/mt0-xl-detox-orpo) and
an iterative classifier-based gatekeeping mechanism. Our approach departs from
prior unsupervised or monolingual pipelines by leveraging explicit toxic word
annotation via the multilingual_toxic_lexicon to guide detoxification with
greater precision and cross-lingual generalization. Our final model achieves
the highest STA (0.922) from our previous attempts, and an average official J
score of 0.612 for toxic inputs in both the development and test sets. It also
achieved xCOMET scores of 0.793 (dev) and 0.787 (test). This performance
outperforms baseline and backtranslation methods across multiple languages, and
shows strong generalization in high-resource settings (English, Russian,
French). Despite some trade-offs in SIM, the model demonstrates consistent
improvements in detoxification strength. In the competition, our team achieved
ninth place with a score of 0.612.

</details>


### [4] [Evaluating Code-Mixing in LLMs Across 18 Languages](https://arxiv.org/abs/2507.18791)
*Yilun Yang,Yekun Chai*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型在18种语言（来自七个语系）的混合语言数据上的表现，并提出了一种生成合成混合语言文本的新方法。分析表明，大型语言模型在混合语言数据集上表现不佳，建议通过增加训练数据量、模型规模和少样本学习来提高性能。


<details>
  <summary>Details</summary>
Motivation: 代码混合对于多语言用户很重要，但目前在这一领域的研究仍有限。现有的基准测试受限于狭窄的语言对和任务，无法充分评估大型语言模型的代码混合能力。此外，当前生成混合语言数据的方法尚不成熟。

Method: 我们对18种语言（来自七个语系）的混合语言数据上的大型语言模型性能进行了全面评估。我们还提出了一种生成合成混合语言文本的新方法，该方法结合了单词替换和GPT-4提示。

Result: 我们的分析显示，大型语言模型在涉及多个语系的混合语言数据集上表现不佳。

Conclusion: 我们的分析显示，大型语言模型在涉及多个语系的混合语言数据集上表现不佳。我们建议通过增加训练数据量、模型规模和少样本学习来提高其性能。

Abstract: Code-mixing, the practice of switching between languages within a
conversation, presents unique challenges for traditional natural language
processing. Existing benchmarks, such as LinCE and GLUECoS, are limited by
narrow language pairings and tasks, failing to adequately evaluate the
code-mixing capabilities of large language models (LLMs). Despite the
significance of code-mixing for multilingual users, research on LLMs in this
context remains limited. Additionally, current methods for generating
code-mixed data are underdeveloped. In this paper, we conduct a comprehensive
evaluation of LLMs' performance on code-mixed data across 18 languages from
seven language families. We also propose a novel approach for generating
synthetic code-mixed texts by combining word substitution with GPT-4 prompting.
Our analysis reveals consistent underperformance of LLMs on code-mixed datasets
involving multiple language families. We suggest that improvements in training
data size, model scale, and few-shot learning could enhance their performance.

</details>


### [5] [CueBuddy: helping non-native English speakers navigate English-centric STEM education](https://arxiv.org/abs/2507.18827)
*Pranav Gupta*

Main category: cs.CL

TL;DR: 本文介绍了一种名为CueBuddy的工具，旨在通过实时的“词汇提示”帮助学生克服英语术语的困难。


<details>
  <summary>Details</summary>
Motivation: 学生在STEM课程中，尤其是在全球南方地区，由于英语不够流利而落后于同龄人，尽管他们在科学前提方面与他们相当。

Method: CueBuddy通过实时的技术关键词检测和多语言术语表查询来提供实时的“词汇提示”，以帮助学生跟上复杂的英语术语。

Result: CueBuddy能够帮助学生在不干扰他们对讲座注意力的情况下跟上复杂的英语术语。

Conclusion: 本文介绍了CueBuddy，它通过实时的“词汇提示”来解决这些问题，同时描述了该方法的局限性和未来扩展方向。

Abstract: Students across the world in STEM classes, especially in the Global South,
fall behind their peers who are more fluent in English, despite being at par
with them in terms of scientific prerequisites. While many of them are able to
follow everyday English at ease, key terms in English stay challenging. In most
cases, such students have had most of their course prerequisites in a lower
resource language. Live speech translation to lower resource languages is a
promising area of research, however, models for speech translation can be too
expensive on a large scale and often struggle with technical content. In this
paper, we describe CueBuddy, which aims to remediate these issues by providing
real-time "lexical cues" through technical keyword spotting along real-time
multilingual glossary lookup to help students stay up to speed with complex
English jargon without disrupting their concentration on the lecture. We also
describe the limitations and future extensions of our approach.

</details>


### [6] [PrismRAG: Boosting RAG Factuality with Distractor Resilience and Strategized Reasoning](https://arxiv.org/abs/2507.18857)
*Mohammad Kachuee,Teja Gollapudi,Minseok Kim,Yin Huang,Kai Sun,Xiao Yang,Jiaqi Wang,Nirav Shah,Yue Liu,Aaron Colak,Anuj Kumar,Wen-tau Yih,Xin Luna Dong*

Main category: cs.CL

TL;DR: PrismRAG is a new framework that improves RAG by training models with distractor-aware QA pairs and reasoning-centric habits, achieving better factuality on multiple benchmarks.


<details>
  <summary>Details</summary>
Motivation: Retrieval-augmented generation (RAG) often falls short when retrieved context includes confusing semi-relevant passages or when answering questions requires deep contextual understanding and reasoning.

Method: PrismRAG is an efficient fine-tuning framework that trains the model with distractor-aware QA pairs and instills reasoning-centric habits.

Result: PrismRAG improves average factuality by 5.4% across 12 open-book RAG QA benchmarks.

Conclusion: PrismRAG improves average factuality by 5.4% and outperforms state-of-the-art solutions.

Abstract: Retrieval-augmented generation (RAG) often falls short when retrieved context
includes confusing semi-relevant passages, or when answering questions require
deep contextual understanding and reasoning. We propose an efficient
fine-tuning framework, called PrismRAG, that (i) trains the model with
distractor-aware QA pairs mixing gold evidence with subtle distractor passages,
and (ii) instills reasoning-centric habits that make the LLM plan, rationalize,
and synthesize without relying on extensive human engineered instructions.
Evaluated across 12 open-book RAG QA benchmarks spanning diverse application
domains and scenarios, PrismRAG improves average factuality by 5.4%,
outperforming state-of-the-art solutions.

</details>


### [7] [MindFlow+: A Self-Evolving Agent for E-Commerce Customer Service](https://arxiv.org/abs/2507.18884)
*Ming Gong,Xucheng Huang,Ziheng Xu,Vijayan K. Asari*

Main category: cs.CL

TL;DR: MindFlow+是一种自我进化的对话代理，通过结合大型语言模型与模仿学习和离线强化学习来提高电子商务客服中的对话质量。


<details>
  <summary>Details</summary>
Motivation: 传统基于意图的系统在动态、多轮交互中表现不佳，因此需要一种能够适应这些挑战的对话代理。

Method: MindFlow+通过结合大型语言模型（LLMs）与模仿学习和离线强化学习（RL）来学习特定领域的行为。它引入了两种以数据为中心的机制：工具增强的示范构建，以及奖励条件数据建模。

Result: 在真实电子商务对话上的实验表明，MindFlow+在上下文相关性、灵活性和任务准确性方面优于强大的基线模型。

Conclusion: 这些结果展示了结合LLMs工具推理和奖励引导学习在构建领域专业化、上下文感知对话系统方面的潜力。

Abstract: High-quality dialogue is crucial for e-commerce customer service, yet
traditional intent-based systems struggle with dynamic, multi-turn
interactions. We present MindFlow+, a self-evolving dialogue agent that learns
domain-specific behavior by combining large language models (LLMs) with
imitation learning and offline reinforcement learning (RL). MindFlow+
introduces two data-centric mechanisms to guide learning: tool-augmented
demonstration construction, which exposes the model to knowledge-enhanced and
agentic (ReAct-style) interactions for effective tool use; and
reward-conditioned data modeling, which aligns responses with task-specific
goals using reward signals. To evaluate the model's role in response
generation, we introduce the AI Contribution Ratio, a novel metric quantifying
AI involvement in dialogue. Experiments on real-world e-commerce conversations
show that MindFlow+ outperforms strong baselines in contextual relevance,
flexibility, and task accuracy. These results demonstrate the potential of
combining LLMs tool reasoning, and reward-guided learning to build
domain-specialized, context-aware dialogue systems.

</details>


### [8] [NUTMEG: Separating Signal From Noise in Annotator Disagreement](https://arxiv.org/abs/2507.18890)
*Jonathan Ivey,Susan Gauch,David Jurgens*

Main category: cs.CL

TL;DR: 本文提出了一种新的贝叶斯模型NUTMEG，用于处理人类标注数据中的分歧问题，该模型能够区分噪声和信号，从而提高训练效果。


<details>
  <summary>Details</summary>
Motivation: 许多NLP模型依赖于人工标注的数据进行训练和评估。然而，由于注释者的技能、背景和动机不同，导致了冲突的标注。传统的方法假设分歧是错误，但最近的研究认为对于许多任务，注释者可能有真正的分歧，应将变化视为信号而非噪声。然而，很少有模型能区分信号和噪声。

Method: 我们引入了NUTMEG，这是一种新的贝叶斯模型，它结合了关于注释者背景的信息，以从人类标注的训练数据中去除噪声标注，同时保留系统性分歧。

Result: 使用合成数据，我们展示了NUTMEG在从具有系统性分歧的标注中恢复真实数据方面比传统聚合方法更有效。我们进一步分析了子群体大小、分歧率和垃圾信息率如何影响我们模型的性能。最后，我们证明了在NUTMEG聚合数据上训练的下游模型显著优于在传统聚合方法数据上训练的模型。

Conclusion: 我们的结果强调了在基于人类标注数据进行训练时，考虑注释者能力和系统性分歧的重要性。

Abstract: NLP models often rely on human-labeled data for training and evaluation. Many
approaches crowdsource this data from a large number of annotators with varying
skills, backgrounds, and motivations, resulting in conflicting annotations.
These conflicts have traditionally been resolved by aggregation methods that
assume disagreements are errors. Recent work has argued that for many tasks
annotators may have genuine disagreements and that variation should be treated
as signal rather than noise. However, few models separate signal and noise in
annotator disagreement. In this work, we introduce NUTMEG, a new Bayesian model
that incorporates information about annotator backgrounds to remove noisy
annotations from human-labeled training data while preserving systematic
disagreements. Using synthetic data, we show that NUTMEG is more effective at
recovering ground-truth from annotations with systematic disagreement than
traditional aggregation methods. We provide further analysis characterizing how
differences in subpopulation sizes, rates of disagreement, and rates of spam
affect the performance of our model. Finally, we demonstrate that downstream
models trained on NUTMEG-aggregated data significantly outperform models
trained on data from traditionally aggregation methods. Our results highlight
the importance of accounting for both annotator competence and systematic
disagreements when training on human-labeled data.

</details>


### [9] [REPRO-Bench: Can Agentic AI Systems Assess the Reproducibility of Social Science Research?](https://arxiv.org/abs/2507.18901)
*Chuxuan Hu,Liyun Zhang,Yeji Lim,Aum Wadhwani,Austin Peters,Daniel Kang*

Main category: cs.CL

TL;DR: 本文介绍了REPRO-Bench，这是一个用于评估社会科学论文可重复性的基准测试集。通过评估AI代理的能力，我们发现当前的AI代理在处理现实世界的可重复性评估时表现不佳，但通过改进，可以显著提高准确率。


<details>
  <summary>Details</summary>
Motivation: 评估社会科学论文的可重复性对于促进研究过程中的严谨性至关重要，但手动评估成本高昂。随着代理AI系统（即AI代理）的最新进展，我们试图评估它们在自动化这一过程方面的能力。然而，现有的可重复性研究论文基准存在一些问题，如仅关注使用提供的代码和数据重现结果，而没有评估其与论文的一致性，过于简化现实场景，并且缺乏必要的数据格式和编程语言多样性。

Method: 我们引入了REPRO-Bench，这是一个包含112个任务实例的集合，每个实例代表一个社会科学论文，并附有公开的可重复性报告。AI代理被要求根据原始论文PDF和相应的可重复性包来评估论文的可重复性。

Result: 我们在REPRO-Bench上评估了三个代表性的AI代理，表现最好的代理准确率仅为21.4%。基于我们的实证分析，我们开发了REPRO-Agent，它将现有代理达到的最高准确率提高了71%。

Conclusion: 我们得出结论，需要开发更先进的AI代理来自动化现实世界的可重复性评估。

Abstract: Assessing the reproducibility of social science papers is essential for
promoting rigor in research processes, but manual assessment is costly. With
recent advances in agentic AI systems (i.e., AI agents), we seek to evaluate
their capability to automate this process. However, existing benchmarks for
reproducing research papers (1) focus solely on reproducing results using
provided code and data without assessing their consistency with the paper, (2)
oversimplify real-world scenarios, and (3) lack necessary diversity in data
formats and programming languages. To address these issues, we introduce
REPRO-Bench, a collection of 112 task instances, each representing a social
science paper with a publicly available reproduction report. The agents are
tasked with assessing the reproducibility of the paper based on the original
paper PDF and the corresponding reproduction package. REPRO-Bench features
end-to-end evaluation tasks on the reproducibility of social science papers
with complexity comparable to real-world assessments. We evaluate three
representative AI agents on REPRO-Bench, with the best-performing agent
achieving an accuracy of only 21.4%. Building on our empirical analysis, we
develop REPRO-Agent, which improves the highest accuracy achieved by existing
agents by 71%. We conclude that more advanced AI agents should be developed to
automate real-world reproducibility assessment. REPRO-Bench is publicly
available at https://github.com/uiuc-kang-lab/REPRO-Bench.

</details>


### [10] [SLoW: Select Low-frequency Words! Automatic Dictionary Selection for Translation on Large Language Models](https://arxiv.org/abs/2507.18902)
*Hongyuan Lu,Zixuan Li,Zefan Zhang,Wai Lam*

Main category: cs.CL

TL;DR: 本文提出了一种新的自动字典选择任务（ADS）和SLoW方法，通过选择低频词的字典来提高翻译性能，无需训练数据，节省token使用，并在多个语言上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型仅支持数百种语言，而全球有超过7000种语言。现有的基于字典的提示方法虽然可以增强翻译，但通常使用所有可用字典，这可能很昂贵。因此，需要一种在token消耗和翻译性能之间进行权衡的方法。

Method: 本文提出了SLoW方法，该方法通过选择低频词的字典来提高翻译性能，无需访问训练数据进行频率估计，同时继承了基于字典方法的优势，不需要对LLMs进行额外调优。

Result: 实验结果表明，SLoW在100种语言上的表现优于强基线，并且能够明显节省token使用，许多语言甚至超过了全字典基线的翻译性能。此外，使用公共资源获得的频率估计仍然有效，无需实际训练数据。

Conclusion: 本文提出了一种新的任务，称为自动字典选择（ADS），并提出了一种名为SLoW的方法，该方法在不使用训练数据的情况下，通过选择低频词的字典来提高翻译性能，并且在多个语言上表现出色，同时节省了token使用。

Abstract: There are more than 7,000 languages around the world, and current Large
Language Models (LLMs) only support hundreds of languages. Dictionary-based
prompting methods can enhance translation on them, but most methods use all the
available dictionaries, which could be expensive. Instead, it will be flexible
to have a trade-off between token consumption and translation performance. This
paper proposes a novel task called \textbf{A}utomatic \textbf{D}ictionary
\textbf{S}election (\textbf{ADS}). The goal of the task is to automatically
select which dictionary to use to enhance translation. We propose a novel and
effective method which we call \textbf{S}elect \textbf{Lo}w-frequency
\textbf{W}ords! (\textbf{SLoW}) which selects those dictionaries that have a
lower frequency. Our methods have unique advantages. First, there is no need
for access to the training data for frequency estimation (which is usually
unavailable). Second, it inherits the advantage of dictionary-based methods,
where no additional tuning is required on LLMs. Experimental results on 100
languages from FLORES indicate that SLoW surpasses strong baselines, and it can
obviously save token usage, with many languages even surpassing the translation
performance of the full dictionary baseline.\footnote{A shocking fact is that
there is no need to use the actual training data (often unobtainable) for
frequency estimation, and an estimation frequency obtained using public
resources is still apparently effective in improving translation with ChatGPT
and Llama, and DeepSeek.}\footnote{Code and data available upon publication.}

</details>


### [11] [Large language models provide unsafe answers to patient-posed medical questions](https://arxiv.org/abs/2507.18905)
*Rachel L. Draelos,Samina Afreen,Barbara Blasko,Tiffany Brazile,Natasha Chase,Dimple Desai,Jessica Evert,Heather L. Gardner,Lauren Herrmann,Aswathy Vaikom House,Stephanie Kass,Marianne Kavan,Kirshma Khemani,Amanda Koire,Lauren M. McDonald,Zahraa Rabeeah,Amy Shah*

Main category: cs.CL

TL;DR: 研究发现，公开可用的聊天机器人在提供医疗建议时可能存在安全隐患，需要进一步改进其临床安全性。


<details>
  <summary>Details</summary>
Motivation: 由于数百万患者已经在使用大型语言模型聊天机器人获取医疗建议，因此需要评估这些聊天机器人的安全性。

Method: 该研究通过一个评估框架对四个公开可用的聊天机器人进行了比较，该框架允许定量和定性分析。

Result: 研究发现聊天机器人之间存在统计学上的显著差异，问题响应率从21.6%（Claude）到43.2%（Llama）不等，不安全响应率从5%（Claude）到13%（GPT-4o, Llama）不等。

Conclusion: 该研究表明，数百万患者可能正在从公开可用的聊天机器人那里获得不安全的医疗建议，并需要进一步的工作来提高这些强大工具的临床安全性。

Abstract: Millions of patients are already using large language model (LLM) chatbots
for medical advice on a regular basis, raising patient safety concerns. This
physician-led red-teaming study compares the safety of four publicly available
chatbots--Claude by Anthropic, Gemini by Google, GPT-4o by OpenAI, and
Llama3-70B by Meta--on a new dataset, HealthAdvice, using an evaluation
framework that enables quantitative and qualitative analysis. In total, 888
chatbot responses are evaluated for 222 patient-posed advice-seeking medical
questions on primary care topics spanning internal medicine, women's health,
and pediatrics. We find statistically significant differences between chatbots.
The rate of problematic responses varies from 21.6 percent (Claude) to 43.2
percent (Llama), with unsafe responses varying from 5 percent (Claude) to 13
percent (GPT-4o, Llama). Qualitative results reveal chatbot responses with the
potential to lead to serious patient harm. This study suggests that millions of
patients could be receiving unsafe medical advice from publicly available
chatbots, and further work is needed to improve the clinical safety of these
powerful tools.

</details>


### [12] [A Systematic Review of Key Retrieval-Augmented Generation (RAG) Systems: Progress, Gaps, and Future Directions](https://arxiv.org/abs/2507.18910)
*Agada Joseph Oche,Ademola Glory Folashade,Tirthankar Ghosal,Arpan Biswas*

Main category: cs.CL

TL;DR: 本文对RAG进行了全面的系统回顾，分析了其发展历程、核心技术、应用挑战以及未来发展方向。


<details>
  <summary>Details</summary>
Motivation: RAG旨在解决参数化模型中的幻觉和过时知识问题，提高事实基础、准确性和上下文相关性。

Method: 本文通过系统回顾RAG的发展历程，分析了其核心技术组件，并进行了比较评估。

Result: 本文提供了RAG在企业系统中的部署分析，并评估了其在检索准确性、生成流畅性、延迟和计算效率方面的性能。

Conclusion: 本文总结了RAG的最新进展，并指出了未来更可靠、高效和上下文感知的知识密集型NLP系统的方向。

Abstract: Retrieval-Augmented Generation (RAG) represents a major advancement in
natural language processing (NLP), combining large language models (LLMs) with
information retrieval systems to enhance factual grounding, accuracy, and
contextual relevance. This paper presents a comprehensive systematic review of
RAG, tracing its evolution from early developments in open domain question
answering to recent state-of-the-art implementations across diverse
applications. The review begins by outlining the motivations behind RAG,
particularly its ability to mitigate hallucinations and outdated knowledge in
parametric models. Core technical components-retrieval mechanisms,
sequence-to-sequence generation models, and fusion strategies are examined in
detail. A year-by-year analysis highlights key milestones and research trends,
providing insight into RAG's rapid growth. The paper further explores the
deployment of RAG in enterprise systems, addressing practical challenges
related to retrieval of proprietary data, security, and scalability. A
comparative evaluation of RAG implementations is conducted, benchmarking
performance on retrieval accuracy, generation fluency, latency, and
computational efficiency. Persistent challenges such as retrieval quality,
privacy concerns, and integration overhead are critically assessed. Finally,
the review highlights emerging solutions, including hybrid retrieval
approaches, privacy-preserving techniques, optimized fusion strategies, and
agentic RAG architectures. These innovations point toward a future of more
reliable, efficient, and context-aware knowledge-intensive NLP systems.

</details>


### [13] [Mining Contextualized Visual Associations from Images for Creativity Understanding](https://arxiv.org/abs/2507.18915)
*Ananya Sahu,Amith Ananthram,Kathleen McKeown*

Main category: cs.CL

TL;DR: 本文提出了一种方法，用于挖掘图像中显著视觉元素的上下文化关联，并生成具有不同抽象程度的高质量创造性标题。该方法在两个创意领域中提升了零样本图像-文本检索性能。


<details>
  <summary>Details</summary>
Motivation: 理解他人的创造性输出需要一种共享的关联语言。然而，在训练像CLIP这样的视觉-语言模型时，我们依赖于包含简短、主要是字面意义的alt-text的网络抓取数据集。

Method: 我们引入了一种方法，用于挖掘图像中显著视觉元素的上下文化关联，可以扩展到任何未标记的数据集。给定一张图像，我们可以使用这些挖掘出的关联生成高质量的创造性标题，抽象程度不断增加。

Result: 我们生成了一个新的视觉关联数据集和1.7m个MSCOCO图像的创造性标题。人类评估确认这些标题保持视觉基础，同时表现出明显增加的抽象性。此外，对这个数据集进行微调的视觉编码器在两个创意领域中实现了有意义的改进。

Conclusion: 我们的方法在两个创意领域（诗歌和隐喻可视化）中通过微调视觉编码器显著提高了零样本图像-文本检索性能，并释放了数据集、生成代码和模型供更广泛的社区使用。

Abstract: Understanding another person's creative output requires a shared language of
association. However, when training vision-language models such as CLIP, we
rely on web-scraped datasets containing short, predominantly literal, alt-text.
In this work, we introduce a method for mining contextualized associations for
salient visual elements in an image that can scale to any unlabeled dataset.
Given an image, we can use these mined associations to generate high quality
creative captions at increasing degrees of abstraction. With our method, we
produce a new dataset of visual associations and 1.7m creative captions for the
images in MSCOCO. Human evaluation confirms that these captions remain visually
grounded while exhibiting recognizably increasing abstraction. Moreover,
fine-tuning a visual encoder on this dataset yields meaningful improvements in
zero-shot image-text retrieval in two creative domains: poetry and metaphor
visualization. We release our dataset, our generation code and our models for
use by the broader community.

</details>


### [14] [Uncovering Cross-Linguistic Disparities in LLMs using Sparse Autoencoders](https://arxiv.org/abs/2507.18918)
*Richmond Sin Jing Xuan,Jalil Huseynov,Yang Zhang*

Main category: cs.CL

TL;DR: 研究发现多语言大语言模型在中等至低资源语言上的激活模式存在系统性差异，通过激活感知微调可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究多语言大语言模型在中等至低资源语言上的表现不佳问题，探索激活模式的系统性差异。

Method: 使用稀疏自编码器（SAEs）分析Gemma-2-2B在所有26个残差层和10种语言中的激活模式，并通过低秩适应（LoRA）进行激活感知微调。

Result: 中等至低资源语言在早期层的激活降低了高达26.27%，在深层仍有19.89%的差距。通过LoRA微调，马来语和印地语的激活分别提高了87.69%和86.32%，同时保持英语性能在约91%。

Conclusion: 激活对齐是提高多语言大语言模型性能的关键因素。

Abstract: Multilingual large language models (LLMs) exhibit strong cross-linguistic
generalization, yet medium to low resource languages underperform on common
benchmarks such as ARC-Challenge, MMLU, and HellaSwag. We analyze activation
patterns in Gemma-2-2B across all 26 residual layers and 10 languages: Chinese
(zh), Russian (ru), Spanish (es), Italian (it), medium to low resource
languages including Indonesian (id), Catalan (ca), Marathi (mr), Malayalam
(ml), and Hindi (hi), with English (en) as the reference. Using Sparse
Autoencoders (SAEs), we reveal systematic disparities in activation patterns.
Medium to low resource languages receive up to 26.27 percent lower activations
in early layers, with a persistent gap of 19.89 percent in deeper layers. To
address this, we apply activation-aware fine-tuning via Low-Rank Adaptation
(LoRA), leading to substantial activation gains, such as 87.69 percent for
Malayalam and 86.32 percent for Hindi, while maintaining English retention at
approximately 91 percent. After fine-tuning, benchmark results show modest but
consistent improvements, highlighting activation alignment as a key factor in
enhancing multilingual LLM performance.

</details>


### [15] [LLaVA-NeuMT: Selective Layer-Neuron Modulation for Efficient Multilingual Multimodal Translation](https://arxiv.org/abs/2507.18940)
*Jingxuan Wei,Caijun Jia,Qi Chen,Yujun Cai,Linzhuang Sun,Xiangxiang Zhang,Gaowei Wu,Bihui Yu*

Main category: cs.CL

TL;DR: LLaVA-NeuMT is a new framework for multimodal multilingual translation that improves performance by modeling language-specific and agnostic representations, achieving state-of-the-art results with fewer parameters.


<details>
  <summary>Details</summary>
Motivation: Existing MMT methods face challenges in multilingual translation due to cross-lingual interference and ineffective parameter-sharing strategies.

Method: LLaVA-NeuMT is a novel multimodal multilingual translation framework that explicitly models language-specific and language-agnostic representations. It includes a layer selection mechanism and a neuron-level adaptation strategy.

Result: LLaVA-NeuMT surpasses full fine-tuning approaches and achieves SOTA results on both M3-Multi30K and M3-AmbigCaps datasets while fine-tuning only 40% of the model parameters.

Conclusion: LLaVA-NeuMT provides an efficient and scalable solution to cross-lingual adaptation in multimodal translation.

Abstract: Multimodal Machine Translation (MMT) enhances translation quality by
incorporating visual context, helping to resolve textual ambiguities. While
existing MMT methods perform well in bilingual settings, extending them to
multilingual translation remains challenging due to cross-lingual interference
and ineffective parameter-sharing strategies. To address this, we propose
LLaVA-NeuMT, a novel multimodal multilingual translation framework that
explicitly models language-specific and language-agnostic representations to
mitigate multilingual interference. Our approach consists of a layer selection
mechanism that identifies the most informative layers for different language
pairs and a neuron-level adaptation strategy that dynamically selects
language-specific and agnostic neurons to improve translation quality while
reducing redundancy. We conduct extensive experiments on the M3-Multi30K and
M3-AmbigCaps datasets, demonstrating that LLaVA-NeuMT, while fine-tuning only
40\% of the model parameters, surpasses full fine-tuning approaches and
ultimately achieves SOTA results on both datasets. Our analysis further
provides insights into the importance of selected layers and neurons in
multimodal multilingual adaptation, offering an efficient and scalable solution
to cross-lingual adaptation in multimodal translation.

</details>


### [16] [Legal Document Summarization: Enhancing Judicial Efficiency through Automation Detection](https://arxiv.org/abs/2507.18952)
*Yongjie Li,Ruilin Nong,Jianan Liu,Lucas Evans*

Main category: cs.CL

TL;DR: 本研究提出了一种基于自然语言处理和机器学习的法律文档摘要方法，能够提高司法效率并减少人工审查的工作量。


<details>
  <summary>Details</summary>
Motivation: 法律文档摘要代表了提高司法效率的重要进展，通过自动化关键信息检测来改善司法流程。

Method: 本研究利用最先进的自然语言处理技术，通过先进的机器学习算法识别和提取法律文本中的关键信息，以生成精确的摘要。

Result: 实验结果表明，该方法能够生成高质量的摘要，同时保持原始内容的完整性，并显著提高处理速度。

Conclusion: 本研究展示了技术驱动的策略在法律领域的应用潜力，强调了自动化在优化司法流程中的作用。

Abstract: Legal document summarization represents a significant advancement towards
improving judicial efficiency through the automation of key information
detection. Our approach leverages state-of-the-art natural language processing
techniques to meticulously identify and extract essential data from extensive
legal texts, which facilitates a more efficient review process. By employing
advanced machine learning algorithms, the framework recognizes underlying
patterns within judicial documents to create precise summaries that encapsulate
the crucial elements. This automation alleviates the burden on legal
professionals, concurrently reducing the likelihood of overlooking vital
information that could lead to errors. Through comprehensive experiments
conducted with actual legal datasets, we demonstrate the capability of our
method to generate high-quality summaries while preserving the integrity of the
original content and enhancing processing times considerably. The results
reveal marked improvements in operational efficiency, allowing legal
practitioners to direct their efforts toward critical analytical and
decision-making activities instead of manual reviews. This research highlights
promising technology-driven strategies that can significantly alter workflow
dynamics within the legal sector, emphasizing the role of automation in
refining judicial processes.

</details>


### [17] [A Similarity Measure for Comparing Conversational Dynamics](https://arxiv.org/abs/2507.18956)
*Sang Min Jung,Kaixiang Zhang,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: 本文提出了一种用于比较对话动态的相似性度量，并通过验证框架测试了其鲁棒性和敏感性，最终应用于大型在线社区分析，揭示了情境权力的作用。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏一种稳健的自动化方法来比较对话的整体互动动态，这种方法可以增强对话数据的分析并更全面地评估对话代理。

Method: 本文提出了一种比较对话动态的相似性度量，并设计了一个验证框架来测试该度量的鲁棒性和对对话主题的敏感性。

Result: 本文提出的度量方法能够有效分析大型在线社区中的对话动态，并揭示情境权力在对话中的作用。

Conclusion: 本文引入了一种用于比较对话动态的相似性度量，并通过验证框架测试了该度量的鲁棒性和敏感性，最后用它分析了一个大型在线社区中的对话动态，揭示了情境权力在对话中的作用。

Abstract: The quality of a conversation goes beyond the individual quality of each
reply, and instead emerges from how these combine into interactional patterns
that give the conversation its distinctive overall "shape". However, there is
no robust automated method for comparing conversations in terms of their
overall interactional dynamics. Such methods could enhance the analysis of
conversational data and help evaluate conversational agents more holistically.
  In this work, we introduce a similarity measure for comparing conversations
with respect to their dynamics. We design a validation framework for testing
the robustness of the metric in capturing differences in conversation dynamics
and for assessing its sensitivity to the topic of the conversations. Finally,
to illustrate the measure's utility, we use it to analyze conversational
dynamics in a large online community, bringing new insights into the role of
situational power in conversations.

</details>


### [18] [A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation](https://arxiv.org/abs/2507.18973)
*Bohan Yao,Vikas Yadav*

Main category: cs.CL

TL;DR: Multi-TAG 是一种无需微调的多工具聚合框架，可显著提升数学推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的工具增强方法在处理需要多步骤精确推理的复杂数学问题时表现不佳，因此需要一种更强大的框架。

Method: Multi-TAG 框架通过在每个推理步骤中同时调用多个工具，并聚合它们的输出来验证和优化推理过程。

Result: 在四个具有挑战性的基准测试中，Multi-TAG 在开放权重和封闭源代码的 LLM 骨干上均表现出色，平均提升了 6.0% 到 7.5%。

Conclusion: Multi-TAG 是一种无需微调的推理框架，能够显著提升数学推理任务的性能，并在多个基准测试中优于最先进的基线方法。

Abstract: Augmenting large language models (LLMs) with external tools is a promising
avenue for developing high-performance mathematical reasoning systems. Prior
tool-augmented approaches typically finetune an LLM to select and invoke a
single tool at each reasoning step and show promising results on simpler math
reasoning benchmarks such as GSM8K. However, these approaches struggle with
more complex math problems that require precise reasoning over multiple steps.
To address this limitation, in this work, we propose Multi-TAG, a Multi-Tool
AGgregation-based framework. Instead of relying on a single tool, Multi-TAG
guides an LLM to concurrently invoke multiple tools at each reasoning step. It
then aggregates their diverse outputs to verify and refine the reasoning
process, enhancing solution robustness and accuracy. Notably, Multi-TAG is a
finetuning-free, inference-only framework, making it readily applicable to any
LLM backbone, including large open-weight models which are computationally
expensive to finetune and proprietary frontier models which cannot be finetuned
with custom recipes. We evaluate Multi-TAG on four challenging benchmarks:
MATH500, AIME, AMC, and OlympiadBench. Across both open-weight and
closed-source LLM backbones, Multi-TAG consistently and substantially
outperforms state-of-the-art baselines, achieving average improvements of 6.0%
to 7.5% over state-of-the-art baselines.

</details>


### [19] [Arg-LLaDA: Argument Summarization via Large Language Diffusion Models and Sufficiency-Aware Refinement](https://arxiv.org/abs/2507.19081)
*Hao Li,Yizheng Sun,Viktor Schlegel,Kailai Yang,Riza Batista-Navarro,Goran Nenadic*

Main category: cs.CL

TL;DR: Arg-LLaDA是一种新的大型语言扩散框架，用于生成更忠实、简洁和连贯的摘要。它通过迭代改进摘要，结合灵活的遮蔽控制器和充分性检查模块，能够识别和修改不受支持的、冗余的或不完整的段落。在两个基准数据集上的实证结果表明，Arg-LLaDA在10个自动评估指标中的7个超过了最先进的基线，并且在人类评估中也显示出显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于单次生成，对事实纠正或结构优化的支持有限。为了弥补这一差距，我们引入了Arg-LLaDA，这是一种新的大型语言扩散框架，可以迭代改进摘要。

Method: Arg-LLaDA是一种新颖的大语言扩散框架，通过充分性引导的重新遮蔽和再生来迭代改进摘要。我们的方法结合了一个灵活的遮蔽控制器和一个充分性检查模块，以识别和修改不受支持的、冗余的或不完整的段落，从而产生更忠实、简洁和连贯的输出。

Result: Arg-LLaDA在两个基准数据集上的实证结果表明，它在10个自动评估指标中的7个超过了最先进的基线。此外，人类评估显示在核心维度、覆盖范围、忠实度和简洁性方面有显著改进，验证了我们迭代的、注重充分性的生成策略的有效性。

Conclusion: Arg-LLaDA在两个基准数据集上的实证结果表明，它在10个自动评估指标中的7个超过了最先进的基线。此外，人类评估显示在核心维度、覆盖范围、忠实度和简洁性方面有显著改进，验证了我们迭代的、注重充分性的生成策略的有效性。

Abstract: Argument summarization aims to generate concise, structured representations
of complex, multi-perspective debates. While recent work has advanced the
identification and clustering of argumentative components, the generation stage
remains underexplored. Existing approaches typically rely on single-pass
generation, offering limited support for factual correction or structural
refinement. To address this gap, we introduce Arg-LLaDA, a novel large language
diffusion framework that iteratively improves summaries via sufficiency-guided
remasking and regeneration. Our method combines a flexible masking controller
with a sufficiency-checking module to identify and revise unsupported,
redundant, or incomplete spans, yielding more faithful, concise, and coherent
outputs. Empirical results on two benchmark datasets demonstrate that Arg-LLaDA
surpasses state-of-the-art baselines in 7 out of 10 automatic evaluation
metrics. In addition, human evaluations reveal substantial improvements across
core dimensions, coverage, faithfulness, and conciseness, validating the
effectiveness of our iterative, sufficiency-aware generation strategy.

</details>


### [20] [Debating Truth: Debate-driven Claim Verification with Multiple Large Language Model Agents](https://arxiv.org/abs/2507.19090)
*Haorui He,Yupeng Li,Dacheng Wen,Reynold Cheng,Francis C. M. Lau*

Main category: cs.CL

TL;DR: 本文提出了一种名为DebateCV的声明验证框架，该框架采用辩论驱动的方法，使用多个LLM代理进行多轮论战，并通过一种新的后训练策略提高性能。实验结果表明，该方法在不同证据质量水平下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的单LLM方法在涉及多方面证据的复杂声明验证中存在困难。受现实世界事实检查实践的启发，我们提出了DebateCV框架。

Method: 我们提出了DebateCV，这是一个采用辩论驱动方法的声明验证框架，使用多个LLM代理。两个辩论者采取对立立场并进行多轮论战，而一个主持人评估论点并给出带有理由的裁决。为了进一步提高主持人的性能，我们引入了一种新的后训练策略，利用由零样本DebateCV生成的合成辩论数据。

Result: 实验结果表明，我们的方法在不同证据质量水平下优于现有的声明验证方法。

Conclusion: 我们的方法在不同证据质量水平下优于现有的声明验证方法。

Abstract: Claim verification is critical for enhancing digital literacy. However, the
state-of-the-art single-LLM methods struggle with complex claim verification
that involves multi-faceted evidences. Inspired by real-world fact-checking
practices, we propose DebateCV, the first claim verification framework that
adopts a debate-driven methodology using multiple LLM agents. In our framework,
two Debaters take opposing stances on a claim and engage in multi-round
argumentation, while a Moderator evaluates the arguments and renders a verdict
with justifications. To further improve the performance of the Moderator, we
introduce a novel post-training strategy that leverages synthetic debate data
generated by the zero-shot DebateCV, effectively addressing the scarcity of
real-world debate-driven claim verification data. Experimental results show
that our method outperforms existing claim verification methods under varying
levels of evidence quality. Our code and dataset are publicly available at
https://anonymous.4open.science/r/DebateCV-6781.

</details>


### [21] [Objectifying the Subjective: Cognitive Biases in Topic Interpretations](https://arxiv.org/abs/2507.19117)
*Swapnil Hingmire,Ze Shi Li,Shiyu,Zeng,Ahmed Musa Awon,Luiz Franciscatto Guerra,Neil Ernst*

Main category: cs.CL

TL;DR: 本文通过用户研究探讨了主题解释的机制，发现用户基于可用性和代表性启发式来解释主题，并提出了基于锚定和调整启发式的主题解释理论。


<details>
  <summary>Details</summary>
Motivation: 现有的主题质量评估指标（如连贯性和单词入侵）没有衡量主题在促进语料库探索方面的作用。

Method: 通过用户研究来理解用户如何解释主题，并使用反思性主题分析从理由中识别主题解释的主题。

Result: 用户基于可用性和代表性启发式来解释主题，而不是概率。

Conclusion: 主题解释可以被视为生态理性用户在不确定性下的判断，因此需要认知偏差意识的用户模型和评估框架。

Abstract: Interpretation of topics is crucial for their downstream applications.
State-of-the-art evaluation measures of topic quality such as coherence and
word intrusion do not measure how much a topic facilitates the exploration of a
corpus. To design evaluation measures grounded on a task, and a population of
users, we do user studies to understand how users interpret topics. We propose
constructs of topic quality and ask users to assess them in the context of a
topic and provide rationale behind evaluations. We use reflexive thematic
analysis to identify themes of topic interpretations from rationales. Users
interpret topics based on availability and representativeness heuristics rather
than probability. We propose a theory of topic interpretation based on the
anchoring-and-adjustment heuristic: users anchor on salient words and make
semantic adjustments to arrive at an interpretation. Topic interpretation can
be viewed as making a judgment under uncertainty by an ecologically rational
user, and hence cognitive biases aware user models and evaluation frameworks
are needed.

</details>


### [22] [An Empirical Investigation of Gender Stereotype Representation in Large Language Models: The Italian Case](https://arxiv.org/abs/2507.19156)
*Gioele Giachino,Marco Rondina,Antonio Vetrò,Riccardo Coppola,Juan Carlos De Martin*

Main category: cs.CL

TL;DR: This paper investigates how Large Language Models (LLMs) generate biased content, focusing on gender and professional bias. Through experiments with Italian prompts, it reveals that LLMs like ChatGPT and Gemini often perpetuate stereotypes, such as associating 'she' pronouns with lower-status roles. The findings emphasize the need for mitigation strategies to prevent AI from exacerbating social inequalities.


<details>
  <summary>Details</summary>
Motivation: The increasing use of Large Language Models (LLMs) in a large variety of domains has sparked worries about how easily they can perpetuate stereotypes and contribute to the generation of biased content. With a focus on gender and professional bias, this work examines in which manner LLMs shape responses to ungendered prompts, contributing to biased outputs.

Method: This analysis uses a structured experimental method, giving different prompts involving three different professional job combinations, which are also characterized by a hierarchical relationship. Two popular LLM-based chatbots are examined, namely OpenAI ChatGPT (gpt-4o-mini) and Google Gemini (gemini-1.5-flash). Through APIs, we collected a range of 3600 responses.

Result: The results highlight how content generated by LLMs can perpetuate stereotypes. For example, Gemini associated 100% (ChatGPT 97%) of 'she' pronouns to the 'assistant' rather than the 'manager'. The presence of bias in AI-generated text can have significant implications in many fields, such as in the workplaces or in job selections, raising ethical concerns about its use.

Conclusion: Understanding these risks is pivotal to developing mitigation strategies and assuring that AI-based systems do not increase social inequalities, but rather contribute to more equitable outcomes.

Abstract: The increasing use of Large Language Models (LLMs) in a large variety of
domains has sparked worries about how easily they can perpetuate stereotypes
and contribute to the generation of biased content. With a focus on gender and
professional bias, this work examines in which manner LLMs shape responses to
ungendered prompts, contributing to biased outputs. This analysis uses a
structured experimental method, giving different prompts involving three
different professional job combinations, which are also characterized by a
hierarchical relationship. This study uses Italian, a language with extensive
grammatical gender differences, to highlight potential limitations in current
LLMs' ability to generate objective text in non-English languages. Two popular
LLM-based chatbots are examined, namely OpenAI ChatGPT (gpt-4o-mini) and Google
Gemini (gemini-1.5-flash). Through APIs, we collected a range of 3600
responses. The results highlight how content generated by LLMs can perpetuate
stereotypes. For example, Gemini associated 100% (ChatGPT 97%) of 'she'
pronouns to the 'assistant' rather than the 'manager'. The presence of bias in
AI-generated text can have significant implications in many fields, such as in
the workplaces or in job selections, raising ethical concerns about its use.
Understanding these risks is pivotal to developing mitigation strategies and
assuring that AI-based systems do not increase social inequalities, but rather
contribute to more equitable outcomes. Future research directions include
expanding the study to additional chatbots or languages, refining prompt
engineering methods or further exploiting a larger experimental base.

</details>


### [23] [Can Small-Scale Data Poisoning Exacerbate Dialect-Linked Biases in Large Language Models?](https://arxiv.org/abs/2507.19195)
*Chaymaa Abbas,Mariette Awad,Razane Tajeddine*

Main category: cs.CL

TL;DR: 本研究探讨了数据中毒和方言偏见（如AAVE与SAE）如何影响语言模型的毒性输出，并揭示了大型模型更容易受到偏见影响的现象，同时提出需要方言意识评估和去偏见干预。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）的设计不断改进以促进包容性和平衡响应，但这些系统仍然容易编码和放大社会偏见。因此，研究数据中毒与方言变体之间的相互作用对于理解毒性输出至关重要。

Method: 本研究使用了小型和中型规模的LLaMA模型，分析了数据中毒如何影响AAVE和SAE输入的毒性输出，并利用GPT-4o作为公平性审计工具来评估这些差异。

Result: 研究发现，即使少量暴露于中毒数据，也会显著增加AAVE输入的毒性，而对SAE的影响较小。更大的模型表现出更显著的放大效应，表明规模增加时更容易受到偏见的影响。此外，GPT-4o识别出了与AAVE输入相关的有害刻板印象，包括攻击性、犯罪性和智力低下等描述。

Conclusion: 研究结果强调了数据中毒和方言偏见的叠加影响，并强调了在开发过程中需要进行方言意识评估、针对性去偏见干预和社会责任培训协议。

Abstract: Despite the ongoing improvements in the design of large language models
(LLMs) to foster inclusion and balanced responses, these systems remain
susceptible to encoding and amplifying social biases. This study examines how
dialectal variation, specifically African American Vernacular English (AAVE)
versus Standard American English (SAE), interacts with data poisoning to
influence toxicity in outputs. Using both small- and medium-scale LLaMA models,
we show that even minimal exposure to poisoned data significantly increases
toxicity for AAVE inputs, while it remains comparatively unaffected for SAE.
Larger models exhibit a more significant amplification effect which suggests
heightened susceptibility with scale. To further assess these disparities, we
employed GPT-4o as a fairness auditor, which identified harmful stereotypical
patterns disproportionately tied to AAVE inputs, including portrayals of
aggression, criminality, and intellectual inferiority. These findings
underscore the compounding impact of data poisoning and dialectal bias and
emphasize the need for dialect-aware evaluation, targeted debiasing
interventions, and socially responsible training protocols during development.

</details>


### [24] [How Much Do Large Language Model Cheat on Evaluation? Benchmarking Overestimation under the One-Time-Pad-Based Framework](https://arxiv.org/abs/2507.19219)
*Zi Liang,Liantong Yu,Shiyu Zhang,Qingqing Ye,Haibo Hu*

Main category: cs.CL

TL;DR: 本文提出了 ArxivRoll，一种基于一次性密码加密的动态评估框架，用于解决 LLMs 评估中的过估计问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法同时确保可重复性、透明性和高效率，并且当前 LLMs 的过估计程度尚未量化。

Method: 提出了一种名为 ArxivRoll 的动态评估框架，包含两个关键组件：SCP（序列、填空和预测）和 Rugged Scores (RS)。

Result: 实验表明我们的基准测试质量很高，并提供了对当前 LLMs 的系统评估。

Conclusion: ArxivRoll 提供了一个高质量的基准测试，并对当前 LLMs 进行了系统评估。

Abstract: Overestimation in evaluating large language models (LLMs) has become an
increasing concern. Due to the contamination of public benchmarks or imbalanced
model training, LLMs may achieve unreal evaluation results on public
benchmarks, either intentionally or unintentionally, which leads to unfair
comparisons among LLMs and undermines their realistic capability assessments.
Existing benchmarks attempt to address these issues by keeping test cases
permanently secret, mitigating contamination through human evaluation, or
repeatedly collecting and constructing new samples. However, these approaches
fail to ensure reproducibility, transparency, and high efficiency
simultaneously. Moreover, the extent of overestimation in current LLMs remains
unquantified. To address these issues, we propose ArxivRoll, a dynamic
evaluation framework inspired by one-time pad encryption in cryptography.
ArxivRoll comprises two key components: \emph{i) SCP (Sequencing, Cloze, and
Prediction)}, an automated generator for private test cases, and \emph{ii)
Rugged Scores (RS)}, metrics that measure the proportion of public benchmark
contamination and training bias. Leveraging SCP, ArxivRoll constructs a new
benchmark every six months using recent articles from ArXiv and employs them
for one-time evaluations of LLM performance. Extensive experiments demonstrate
the high quality of our benchmark, and we provide a systematic evaluation of
current LLMs. The source code is available at
https://github.com/liangzid/ArxivRoll/.

</details>


### [25] [Jailbreaking Large Language Diffusion Models: Revealing Hidden Safety Flaws in Diffusion-Based Text Generation](https://arxiv.org/abs/2507.19227)
*Yuanhe Zhang,Fangzhou Xie,Zhenhong Zhou,Zherui Li,Hao Chen,Kun Wang,Yufei Guo*

Main category: cs.CL

TL;DR: 本文研究了LLDMs的安全性，提出了一种有效的越狱攻击方法PAD，并展示了LLDMs在安全方面的重大漏洞。


<details>
  <summary>Details</summary>
Motivation: 由于LLDMs在推理速度和数学推理任务中的优势，其有害生成的风险也更加突出。现有的针对LLMs的越狱方法对LLDMs效果有限，无法暴露其安全漏洞。因此，需要研究LLDMs的安全性。

Method: 本文提出了一种名为PAD的并行解码攻击方法，其中引入了多点注意力攻击，该攻击旨在引导并行生成过程产生有害输出。

Result: 实验结果表明，PAD方法在四个LLDMs上实现了97%的越狱攻击成功率，揭示了LLDMs的安全漏洞。此外，与相同规模的自回归LLMs相比，LLDMs的有害生成速度提高了2倍，突显了不受控制滥用的风险。

Conclusion: 本文揭示了LLDMs在安全方面的显著漏洞，并通过实验验证了PAD方法的有效性。同时，本文提供了对LLDM架构的深入分析，为扩散语言模型的安全部署提供了关键见解。

Abstract: Large Language Diffusion Models (LLDMs) exhibit comparable performance to
LLMs while offering distinct advantages in inference speed and mathematical
reasoning tasks.The precise and rapid generation capabilities of LLDMs amplify
concerns of harmful generations, while existing jailbreak methodologies
designed for Large Language Models (LLMs) prove limited effectiveness against
LLDMs and fail to expose safety vulnerabilities.Successful defense cannot
definitively resolve harmful generation concerns, as it remains unclear whether
LLDMs possess safety robustness or existing attacks are incompatible with
diffusion-based architectures.To address this, we first reveal the
vulnerability of LLDMs to jailbreak and demonstrate that attack failure in
LLDMs stems from fundamental architectural differences.We present a PArallel
Decoding jailbreak (PAD) for diffusion-based language models. PAD introduces
Multi-Point Attention Attack, which guides parallel generative processes toward
harmful outputs that inspired by affirmative response patterns in LLMs.
Experimental evaluations across four LLDMs demonstrate that PAD achieves
jailbreak attack success rates by 97%, revealing significant safety
vulnerabilities. Furthermore, compared to autoregressive LLMs of the same size,
LLDMs increase the harmful generation speed by 2x, significantly highlighting
risks of uncontrolled misuse.Through comprehensive analysis, we provide an
investigation into LLDM architecture, offering critical insights for the secure
deployment of diffusion-based language models.

</details>


### [26] [Identifying Fine-grained Forms of Populism in Political Discourse: A Case Study on Donald Trump's Presidential Campaigns](https://arxiv.org/abs/2507.19303)
*Ilias Chalkidis,Stephanie Brandl,Paris Aslanidis*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型在识别和分类民粹主义话语方面的表现，发现经过微调的RoBERTa分类器优于指令调优的大型语言模型，但指令调优的大型语言模型在处理域外数据时更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨大型语言模型是否能够识别和分类细粒度的民粹主义，这是一个在学术和媒体辩论中复杂且有争议的概念。

Method: 本文通过构建和发布专门设计来捕捉民粹主义话语的新数据集，评估了多种预训练（大）语言模型，包括开源和专有模型，并在多个提示范式下进行评估。此外，还应用了表现最佳的模型来分析唐纳德·特朗普的竞选演讲，并对欧洲政治人物的竞选演讲进行了基准测试，以评估这些模型的泛化能力。

Result: 研究结果表明，经过微调的RoBERTa分类器在检测民粹主义话语方面显著优于所有新时期的指令调优大型语言模型，除非它们也被微调。此外，指令调优的大型语言模型在处理域外数据时表现出更高的鲁棒性。

Conclusion: 本文结论表明，尽管指令调优的大型语言模型在处理域外数据时表现出更高的鲁棒性，但经过微调的RoBERTa分类器在检测民粹主义话语方面表现优于所有新时期的指令调优大型语言模型。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
a wide range of instruction-following tasks, yet their grasp of nuanced social
science concepts remains underexplored. This paper examines whether LLMs can
identify and classify fine-grained forms of populism, a complex and contested
concept in both academic and media debates. To this end, we curate and release
novel datasets specifically designed to capture populist discourse. We evaluate
a range of pre-trained (large) language models, both open-weight and
proprietary, across multiple prompting paradigms. Our analysis reveals notable
variation in performance, highlighting the limitations of LLMs in detecting
populist discourse. We find that a fine-tuned RoBERTa classifier vastly
outperforms all new-era instruction-tuned LLMs, unless fine-tuned.
Additionally, we apply our best-performing model to analyze campaign speeches
by Donald Trump, extracting valuable insights into his strategic use of
populist rhetoric. Finally, we assess the generalizability of these models by
benchmarking them on campaign speeches by European politicians, offering a lens
into cross-context transferability in political discourse analysis. In this
setting, we find that instruction-tuned LLMs exhibit greater robustness on
out-of-domain data.

</details>


### [27] [AutoPCR: Automated Phenotype Concept Recognition by Prompting](https://arxiv.org/abs/2507.19315)
*Yicheng Tao,Yuanhao Huang,Jie Liu*

Main category: cs.CL

TL;DR: 本文提出了一种基于提示的表型CR方法AutoPCR，该方法不需要本体特定的训练。AutoPCR通过三个阶段进行CR：实体提取、候选检索和实体链接。实验表明，AutoPCR在多个基准数据集上表现出色，具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常需要本体特定的训练，并且在跨不同文本类型和不断演变的生物医学术语时表现不佳。因此，需要一种不需要本体特定训练的表型CR方法。

Method: AutoPCR是一种基于提示的表型CR方法，不需要本体特定的训练。AutoPCR通过三个阶段进行CR：使用基于规则和神经标记策略的混合方法进行实体提取，通过SapBERT进行候选检索，以及通过提示大型语言模型进行实体链接。

Result: AutoPCR在四个基准数据集上的实验表明，它在提及级和文档级评估中都实现了最佳平均性能和最稳健的性能，超越了之前最先进的方法。

Conclusion: AutoPCR在四个基准数据集上的实验表明，它在提及级和文档级评估中都实现了最佳平均性能和最稳健的性能，超越了之前最先进的方法。进一步的消融和迁移研究证明了其归纳能力和对新本体的泛化能力。

Abstract: Phenotype concept recognition (CR) is a fundamental task in biomedical text
mining, enabling applications such as clinical diagnostics and knowledge graph
construction. However, existing methods often require ontology-specific
training and struggle to generalize across diverse text types and evolving
biomedical terminology. We present AutoPCR, a prompt-based phenotype CR method
that does not require ontology-specific training. AutoPCR performs CR in three
stages: entity extraction using a hybrid of rule-based and neural tagging
strategies, candidate retrieval via SapBERT, and entity linking through
prompting a large language model. Experiments on four benchmark datasets show
that AutoPCR achieves the best average and most robust performance across both
mention-level and document-level evaluations, surpassing prior state-of-the-art
methods. Further ablation and transfer studies demonstrate its inductive
capability and generalizability to new ontologies.

</details>


### [28] [Smooth Reading: Bridging the Gap of Recurrent LLM to Self-Attention LLM on Long-Context Tasks](https://arxiv.org/abs/2507.19353)
*Kai Liu,Zhan Su,Peijie Dong,Fengran Mo,Jianfei Gao,ShaoTing Zhang,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为Smooth Reading的方法，通过分块处理和迭代总结上下文信息，显著提升了Recurrent LLMs在长上下文任务中的性能，同时保持了其效率优势。


<details>
  <summary>Details</summary>
Motivation: 由于Recurrent LLMs在长上下文任务中表现不佳，因为它们的固定大小内存有限，而之前的增强内存容量的方法并未使Recurrent LLMs达到Self-Attention LLMs的性能水平，因此需要一种新的方法来解决这个问题。

Method: 本文提出了Smooth Reading方法，该方法受到人类阅读策略的启发，将上下文分成块进行处理，并迭代地总结上下文信息，从而降低内存需求并提高与Recurrent LLMs的兼容性。

Result: 实验结果表明，Smooth Reading方法显著缩小了Recurrent LLMs与Self-Attention LLMs在长上下文任务上的性能差距，同时保持了Recurrent LLMs的效率优势。例如，在LongBench上，SWA-3B-4k的性能从比Self-Attention LLMs低5.68%提升到高3.61%。此外，该方法在64k上下文下训练速度提高了3倍，推理速度提高了2倍。

Conclusion: 本文提出了一种名为Smooth Reading的方法，该方法通过分块处理和迭代总结上下文信息，显著缩小了循环大型语言模型（Recurrent LLMs）与基于自注意力的大型语言模型（Self-Attention LLMs）在长上下文任务上的性能差距，并保持了循环LLMs的效率优势。

Abstract: Recently, recurrent large language models (Recurrent LLMs) with linear
computational complexity have re-emerged as efficient alternatives to
self-attention-based LLMs (Self-Attention LLMs), which have quadratic
complexity. However, Recurrent LLMs often underperform on long-context tasks
due to their limited fixed-size memory. Previous research has primarily focused
on enhancing the memory capacity of Recurrent LLMs through architectural
innovations, but these approaches have not yet enabled Recurrent LLMs to match
the performance of Self-Attention LLMs on long-context tasks. We argue that
this limitation arises because processing the entire context at once is not
well-suited for Recurrent LLMs. In this paper, we propose Smooth Reading, a
chunk-wise inference method inspired by human reading strategies. Smooth
Reading processes context in chunks and iteratively summarizes the contextual
information, thereby reducing memory demands and making the approach more
compatible with Recurrent LLMs. Our experimental results show that this method
substantially narrows the performance gap between Recurrent and Self-Attention
LLMs on long-context tasks, while preserving the efficiency advantages of
Recurrent LLMs. Our Smooth Reading boosts SWA-3B-4k (a Recurrent LLM) from
5.68% lower to 3.61% higher performance than Self-Attention LLMs on LongBench.
Besides, our method maintains the high efficiency, training 3x faster and
inferring 2x faster at 64k context compared to Self-Attention LLMs. To our
knowledge, this is the first work to achieve comparable performance using
Recurrent LLMs compared with Self-Attention LLMs on long-context tasks. We hope
our method will inspire future research in this area. To facilitate further
progress, we will release code and dataset.

</details>


### [29] [Enhancing Speech Emotion Recognition Leveraging Aligning Timestamps of ASR Transcripts and Speaker Diarization](https://arxiv.org/abs/2507.19356)
*Hsuan-Yu Wang,Pei-Ying Lee,Berlin Chen*

Main category: cs.CL

TL;DR: 本文研究了将自动语音识别（ASR）转录本和说话人聚类（SD）输出之间基于时间戳的对齐对语音情感识别（SER）准确性的影响。通过引入一个利用预训练ASR和说话人聚类模型的对齐管道，实验结果表明精确的时间戳对齐能有效提高SER的准确性。


<details>
  <summary>Details</summary>
Motivation: 在对话环境中，这两种模态之间的错位往往会降低多模态情感识别系统的可靠性。为了应对这个问题，我们提出了一个时间戳对齐的管道。

Method: 我们引入了一个利用预训练ASR和说话人聚类模型的对齐管道，系统地同步时间戳以生成准确标记的说话人段。我们的多模态方法结合了通过RoBERTa提取的文本嵌入和来自Wav2Vec的音频嵌入，利用交叉注意力融合增强的门控机制。

Result: 在IEMOCAP基准数据集上的实验评估表明，精确的时间戳对齐提高了SER的准确性，优于缺乏同步的基线方法。

Conclusion: 实验结果表明，精确的时间戳对齐在提高整体情感识别准确性方面非常有效，并为稳健的多模态情感分析提供了基础。

Abstract: In this paper, we investigate the impact of incorporating timestamp-based
alignment between Automatic Speech Recognition (ASR) transcripts and Speaker
Diarization (SD) outputs on Speech Emotion Recognition (SER) accuracy.
Misalignment between these two modalities often reduces the reliability of
multimodal emotion recognition systems, particularly in conversational
contexts. To address this issue, we introduce an alignment pipeline utilizing
pre-trained ASR and speaker diarization models, systematically synchronizing
timestamps to generate accurately labeled speaker segments. Our multimodal
approach combines textual embeddings extracted via RoBERTa with audio
embeddings from Wav2Vec, leveraging cross-attention fusion enhanced by a gating
mechanism. Experimental evaluations on the IEMOCAP benchmark dataset
demonstrate that precise timestamp alignment improves SER accuracy,
outperforming baseline methods that lack synchronization. The results highlight
the critical importance of temporal alignment, demonstrating its effectiveness
in enhancing overall emotion recognition accuracy and providing a foundation
for robust multimodal emotion analysis.

</details>


### [30] [SpeechIQ: Speech Intelligence Quotient Across Cognitive Levels in Voice Understanding Large Language Models](https://arxiv.org/abs/2507.19361)
*Zhen Wan,Chao-Han Huck Yang,Yahan Yu,Jinchuan Tian,Sheng Li,Ke Hu,Zhehuai Chen,Shinji Watanabe,Fei Cheng,Chenhui Chu,Sadao Kurohashi*

Main category: cs.CL

TL;DR: SIQ是一种新的基于语音的人类认知启发式评估流程，用于评估语音理解大型语言模型的能力，超越了传统的语音理解指标。


<details>
  <summary>Details</summary>
Motivation: 现有的语音理解指标如词错误率（WER）不足以全面评估语音理解大型语言模型的能力，需要一种更全面的评估方法。

Method: SIQ通过Bloom's Taxonomy的三个认知层次（记忆、理解、应用）来评估LLM Voice的语音理解能力，包括词错误率（WER）、解释相似性和问答准确率。

Result: SIQ不仅量化了语音理解能力，还提供了级联方法和端到端模型之间的统一比较，识别了现有基准中的注释错误，并检测了LLM Voice中的幻觉。

Conclusion: SIQ框架代表了一种开创性的智能测试方法，将认知原则与面向语音的基准相结合，同时揭示了多模态训练中被忽视的挑战。

Abstract: We introduce Speech-based Intelligence Quotient (SIQ) as a new form of human
cognition-inspired evaluation pipeline for voice understanding large language
models, LLM Voice, designed to assess their voice understanding ability. Moving
beyond popular voice understanding metrics such as word error rate (WER), SIQ
examines LLM Voice across three cognitive levels motivated by Bloom's Taxonomy:
(1) Remembering (i.e., WER for verbatim accuracy); (2) Understanding (i.e.,
similarity of LLM's interpretations); and (3) Application (i.e., QA accuracy
for simulating downstream tasks). We demonstrate that SIQ not only quantifies
voice understanding abilities but also provides unified comparisons between
cascaded methods (e.g., ASR LLM) and end-to-end models, identifies annotation
errors in existing benchmarks, and detects hallucinations in LLM Voice. Our
framework represents a first-of-its-kind intelligence examination that bridges
cognitive principles with voice-oriented benchmarks, while exposing overlooked
challenges in multi-modal training.

</details>


### [31] [Data Augmentation for Spoken Grammatical Error Correction](https://arxiv.org/abs/2507.19374)
*Penny Karanasou,Mengjie Qian,Stefano Bannò,Mark J. F. Gales,Kate M. Knill*

Main category: cs.CL

TL;DR: 本文提出了一种自动生成带有语法错误和不流畅的音频-文本对的方法，并通过客观指标评估生成的数据，以增强SGEC数据集。


<details>
  <summary>Details</summary>
Motivation: 目前，针对口语GEC（SGEC）的高质量注释语音数据集仍然不足。因此，需要一种方法来生成带有语法错误和不流畅的音频-文本对，以补充现有的数据集。

Method: 本文提出了一种完全自动化的生成音频-文本对的方法，并引入了一系列客观指标来评估生成的数据，以选择适合SGEC的数据集。此外，还对生成的数据集进行了评估，用于书面GEC和SGEC任务。

Result: 本文在S&I语料库上进行了实验，该语料库是第一个公开可用的带有语法错误注释的语音数据集。结果表明，生成的增强数据集能够保持原始数据的文本和声学特征，同时提供新的错误类型，适用于书面GEC和SGEC任务。

Conclusion: 本文提出了一种生成带有语法错误和不流畅的音频-文本对的自动化方法，并通过客观指标评估生成的数据，以选择更适合SGEC的数据集。目标是生成一个增强的数据集，保持原始数据的文本和声学特征，同时提供新的错误类型，从而丰富原始语料库而不改变第二语言学习者的语言评估分数。

Abstract: While there exist strong benchmark datasets for grammatical error correction
(GEC), high-quality annotated spoken datasets for Spoken GEC (SGEC) are still
under-resourced. In this paper, we propose a fully automated method to generate
audio-text pairs with grammatical errors and disfluencies. Moreover, we propose
a series of objective metrics that can be used to evaluate the generated data
and choose the more suitable dataset for SGEC. The goal is to generate an
augmented dataset that maintains the textual and acoustic characteristics of
the original data while providing new types of errors. This augmented dataset
should augment and enrich the original corpus without altering the language
assessment scores of the second language (L2) learners. We evaluate the use of
the augmented corpus both for written GEC (the text part) and for SGEC (the
audio-text pairs). Our experiments are conducted on the S\&I Corpus, the first
publicly available speech dataset with grammar error annotations.

</details>


### [32] [Detection of Adverse Drug Events in Dutch clinical free text documents using Transformer Models: benchmark study](https://arxiv.org/abs/2507.19396)
*Rachel M. Murphy,Nishant Mishra,Nicolette F. de Keizer,Dave A. Dongelmans,Kitty J. Jager,Ameen Abu-Hanna,Joanna E. Klopotowska,Iacer Calixto*

Main category: cs.CL

TL;DR: 本研究通过多种变压器模型和性能度量，为荷兰临床自由文本文档中的不良药物事件检测设定了基准。MedRoBERTa.nl模型在多个任务中表现最佳，研究强调了使用适合任务的性能度量的重要性，并展望了未来在临床中的应用。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为荷兰临床自由文本文档中的不良药物事件（ADE）检测设定基准，并评估不同模型的性能，以确定最适合该任务的模型。

Method: 本研究使用多种变压器模型、临床场景和适合任务的性能度量，为荷兰临床自由文本文档中的不良药物事件（ADE）检测设定了基准。训练了Bi-LSTM模型和四个基于变压器的荷兰和/或多语言编码器模型（BERTje、RobBERT、MedRoBERTa.nl和NuNER），用于命名实体识别（NER）和关系分类（RC）任务。

Result: 尽管在ADE RC任务中模型之间的差异较小，但MedRoBERTa.nl在使用黄金标准和预测实体时表现最佳，宏平均F1得分为0.63和0.62。MedRoBERTa.nl模型在外部验证中也表现最佳，使用预测实体的召回率在0.67到0.74之间，意味着67%到74%的带有ADE的出院信件被检测到。

Conclusion: 本研究提出了一个用于评估语言模型在临床自由文本文档中检测不良药物事件（ADE）的稳健且具有临床意义的方法。研究强调了使用适合任务的性能度量的重要性，并展望了未来在临床中的应用。

Abstract: In this study, we set a benchmark for adverse drug event (ADE) detection in
Dutch clinical free text documents using several transformer models, clinical
scenarios and fit-for-purpose performance measures. We trained a Bidirectional
Long Short-Term Memory (Bi-LSTM) model and four transformer-based Dutch and/or
multilingual encoder models (BERTje, RobBERT, MedRoBERTa.nl, and NuNER) for the
tasks of named entity recognition (NER) and relation classification (RC) using
102 richly annotated Dutch ICU clinical progress notes. Anonymized free text
clinical progress notes of patients admitted to intensive care unit (ICU) of
one academic hospital and discharge letters of patients admitted to Internal
Medicine wards of two non-academic hospitals were reused. We evaluated our ADE
RC models internally using gold standard (two-step task) and predicted entities
(end-to-end task). In addition, all models were externally validated on
detecting ADEs at the document level. We report both micro- and macro-averaged
F1 scores, given the imbalance of ADEs in the datasets. Although differences
for the ADE RC task between the models were small, MedRoBERTa.nl was the best
performing model with macro-averaged F1 score of 0.63 using gold standard and
0.62 using predicted entities. The MedRoBERTa.nl models also performed the best
in our external validation and achieved recall of between 0.67 to 0.74 using
predicted entities, meaning between 67 to 74% of discharge letters with ADEs
were detected. Our benchmark study presents a robust and clinically meaningful
approach for evaluating language models for ADE detection in clinical free text
documents. Our study highlights the need to use appropriate performance
measures fit for the task of ADE detection in clinical free-text documents and
envisioned future clinical use.

</details>


### [33] [Towards Domain Specification of Embedding Models in Medicine](https://arxiv.org/abs/2507.19407)
*Mohammad Khodadad,Ali Shiraee,Mahdi Astaraki,Hamidreza Mahyar*

Main category: cs.CL

TL;DR: 本文提出了一种基于MEDTE模型的医学文本嵌入方法，并构建了一个涵盖51个任务的全面基准套件，以解决现有模型在数据多样性和评估不足方面的问题。实验结果表明，该方法在不同任务中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的医学文本嵌入模型存在两个关键缺陷：首先，大多数模型仅在狭窄的医学和生物数据上进行训练，且方法不够先进，无法捕捉实际中遇到的术语和语义多样性。其次，现有的评估往往不足：即使广泛使用的基准测试也无法在现实世界的医疗任务中泛化。

Method: 本文利用MEDTE，一个经过广泛微调的GTE模型，通过跨多个数据源的自监督对比学习，提供稳健的医学文本嵌入。同时，我们提出了一个涵盖51个任务的全面基准套件，这些任务包括分类、聚类、对分类和检索，并针对医学文本的特点进行了调整。

Result: 实验结果表明，这种结合方法不仅建立了稳健的评估框架，而且在不同任务中产生的嵌入始终优于最先进的替代方案。

Conclusion: 本文提出的结合方法不仅建立了稳健的评估框架，而且在不同任务中产生的嵌入始终优于最先进的替代方案。

Abstract: Medical text embedding models are foundational to a wide array of healthcare
applications, ranging from clinical decision support and biomedical information
retrieval to medical question answering, yet they remain hampered by two
critical shortcomings. First, most models are trained on a narrow slice of
medical and biological data, beside not being up to date in terms of
methodology, making them ill suited to capture the diversity of terminology and
semantics encountered in practice. Second, existing evaluations are often
inadequate: even widely used benchmarks fail to generalize across the full
spectrum of real world medical tasks.
  To address these gaps, we leverage MEDTE, a GTE model extensively fine-tuned
on diverse medical corpora through self-supervised contrastive learning across
multiple data sources, to deliver robust medical text embeddings.
  Alongside this model, we propose a comprehensive benchmark suite of 51 tasks
spanning classification, clustering, pair classification, and retrieval modeled
on the Massive Text Embedding Benchmark (MTEB) but tailored to the nuances of
medical text. Our results demonstrate that this combined approach not only
establishes a robust evaluation framework but also yields embeddings that
consistently outperform state of the art alternatives in different tasks.

</details>


### [34] [TokenSmith: Streamlining Data Editing, Search, and Inspection for Large-Scale Language Model Training and Interpretability](https://arxiv.org/abs/2507.19419)
*Mohammad Aflah Khan,Ameya Godbole,Johnny Tian-Zheng Wei,Ryan Wang,James Flemings,Krishna Gummadi,Willie Neiswanger,Robin Jia*

Main category: cs.CL

TL;DR: TokenSmith 是一个开源库，允许研究人员交互式地编辑、检查和分析预训练数据集，而无需修改训练代码，从而简化了数据调试和实验过程。


<details>
  <summary>Details</summary>
Motivation: 现有的工作流程在理解训练数据与模型行为之间的关系时显得繁琐、分散且难以访问，因此需要一种更高效、易用的工具来处理预训练数据集。

Method: TokenSmith 提供了一个简单的用户界面和模块化后端，支持搜索、查看、导入、导出、检查和采样数据等多种操作，无需修改训练代码即可进行结构化编辑。

Result: TokenSmith 作为一个即插即用的组件，可以轻松集成到现有的大型语言模型预训练工作流中，从而降低对生产级数据工具的使用门槛。

Conclusion: TokenSmith 是一个开源库，旨在简化大规模语言模型预训练数据集的编辑、检查和分析过程，使研究人员能够更方便地进行数据调试、验证和实验。

Abstract: Understanding the relationship between training data and model behavior
during pretraining is crucial, but existing workflows make this process
cumbersome, fragmented, and often inaccessible to researchers. We present
TokenSmith, an open-source library for interactive editing, inspection, and
analysis of datasets used in Megatron-style pretraining frameworks such as
GPT-NeoX, Megatron, and NVIDIA NeMo. TokenSmith supports a wide range of
operations including searching, viewing, ingesting, exporting, inspecting, and
sampling data, all accessible through a simple user interface and a modular
backend. It also enables structured editing of pretraining data without
requiring changes to training code, simplifying dataset debugging, validation,
and experimentation.
  TokenSmith is designed as a plug and play addition to existing large language
model pretraining workflows, thereby democratizing access to production-grade
dataset tooling. TokenSmith is hosted on GitHub1, with accompanying
documentation and tutorials. A demonstration video is also available on
YouTube.

</details>


### [35] [GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning](https://arxiv.org/abs/2507.19457)
*Lakshya A Agrawal,Shangyin Tan,Dilara Soylu,Noah Ziems,Rishi Khare,Krista Opsahl-Ong,Arnav Singhvi,Herumb Shandilya,Michael J Ryan,Meng Jiang,Christopher Potts,Koushik Sen,Alexandros G. Dimakis,Ion Stoica,Dan Klein,Matei Zaharia,Omar Khattab*

Main category: cs.CL

TL;DR: GEPA is a prompt optimizer that uses natural language reflection to improve the learning process of large language models, achieving better performance with fewer rollouts compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: The authors argue that the interpretable nature of language can provide a richer learning medium for LLMs compared to policy gradients derived from sparse, scalar rewards. They aim to develop a method that leverages natural language reflection to improve the learning process of LLMs.

Method: GEPA is a prompt optimizer that incorporates natural language reflection to learn high-level rules from trial and error. It samples system-level trajectories and reflects on them in natural language to diagnose problems, propose and test prompt updates, and combine complementary lessons from the Pareto frontier of its own attempts.

Result: GEPA outperforms GRPO by 10% on average and up to 20%, while using up to 35x fewer rollouts. It also outperforms MIPROv2 by over 10% across two LLMs and shows promising results as an inference-time search strategy for code optimization.

Conclusion: GEPA demonstrates significant improvements over existing methods like GRPO and MIPROv2, while using fewer rollouts. It also shows promise as an inference-time search strategy for code optimization.

Abstract: Large language models (LLMs) are increasingly adapted to downstream tasks via
reinforcement learning (RL) methods like Group Relative Policy Optimization
(GRPO), which often require thousands of rollouts to learn new tasks. We argue
that the interpretable nature of language can often provide a much richer
learning medium for LLMs, compared with policy gradients derived from sparse,
scalar rewards. To test this, we introduce GEPA (Genetic-Pareto), a prompt
optimizer that thoroughly incorporates natural language reflection to learn
high-level rules from trial and error. Given any AI system containing one or
more LLM prompts, GEPA samples system-level trajectories (e.g., reasoning, tool
calls, and tool outputs) and reflects on them in natural language to diagnose
problems, propose and test prompt updates, and combine complementary lessons
from the Pareto frontier of its own attempts. As a result of GEPA's design, it
can often turn even just a few rollouts into a large quality gain. Across four
tasks, GEPA outperforms GRPO by 10% on average and by up to 20%, while using up
to 35x fewer rollouts. GEPA also outperforms the leading prompt optimizer,
MIPROv2, by over 10% across two LLMs, and demonstrates promising results as an
inference-time search strategy for code optimization.

</details>


### [36] [Conversations Gone Awry, But Then? Evaluating Conversational Forecasting Models](https://arxiv.org/abs/2507.19470)
*Son Quoc Tran,Tushaar Gangavarapu,Nicholas Chernogor,Jonathan P. Chang,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: 本文提出了一个统一的评估框架，用于比较CGA模型，并引入了一种新的度量标准，以衡量模型在对话进展中修正预测的能力。


<details>
  <summary>Details</summary>
Motivation: 为了使自动化系统能够像人类一样预见对话的方向，从而帮助人与人之间的互动，需要对CGA模型进行更全面的评估和比较。

Method: 本文重新审视了CGA任务，并引入了一个统一的评估框架，以创建一个基准，使不同架构之间的直接和可靠比较成为可能。此外，还提出了一种新的度量标准，用于衡量模型在对话进展中修正其预测的能力。

Result: 本文提出了一个统一的评估框架，使得不同CGA模型之间的比较更加直接和可靠，并引入了一种新的度量标准，用于衡量模型在对话进行过程中修正预测的能力。

Conclusion: 本文介绍了第一个统一的评估框架，为CGA模型提供了直接和可靠的比较基准，并提出了一个新的度量标准来衡量模型在对话进行过程中修正其预测的能力。

Abstract: We often rely on our intuition to anticipate the direction of a conversation.
Endowing automated systems with similar foresight can enable them to assist
human-human interactions. Recent work on developing models with this predictive
capacity has focused on the Conversations Gone Awry (CGA) task: forecasting
whether an ongoing conversation will derail. In this work, we revisit this task
and introduce the first uniform evaluation framework, creating a benchmark that
enables direct and reliable comparisons between different architectures. This
allows us to present an up-to-date overview of the current progress in CGA
models, in light of recent advancements in language modeling. Our framework
also introduces a novel metric that captures a model's ability to revise its
forecast as the conversation progresses.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [37] [PurpCode: Reasoning for Safer Code Generation](https://arxiv.org/abs/2507.19060)
*Jiawei Liu,Nirav Diwan,Zhe Wang,Haoyu Zhai,Xiaona Zhou,Kiet A. Nguyen,Tianjiao Yu,Muntasir Wahed,Yinlin Deng,Hadjer Benkraouda,Yuxiang Wei,Lingming Zhang,Ismini Lourentzou,Gang Wang*

Main category: cs.CR

TL;DR: 本文介绍了PurpCode，这是第一个用于训练安全代码推理模型的后训练方法，旨在生成安全代码并防御恶意网络活动。PurpCode通过两个阶段进行训练：规则学习和强化学习。基于PurpCode，开发了PurpCode-32B模型，在网络安全方面表现优异，同时降低了模型的过度拒绝率，并保留了模型的实用性。


<details>
  <summary>Details</summary>
Motivation: 开发一种后训练方法，使代码推理模型能够生成安全代码并防御恶意网络活动。

Method: PurpCode通过两个阶段训练模型：(i) 规则学习，明确教导模型参考网络安全规则生成无漏洞的代码并避免促进恶意网络活动；(ii) 强化学习，通过多样化的多目标奖励机制优化模型的安全性和保留模型的实用性。此外，通过内部红队测试合成全面且高覆盖率的提示，以诱导模型中的不安全网络活动。

Result: 基于PurpCode开发的推理编码模型PurpCode-32B在网络安全方面表现出色，优于各种前沿模型。同时，我们的对齐方法降低了模型在一般和网络安全特定场景中的过度拒绝率，同时保留了模型在代码生成和通用安全知识中的实用性。

Conclusion: PurpCode-32B展示了最先进的网络安全性能，同时减少了模型的过度拒绝率，并在代码生成和通用安全知识中保持了模型的实用性。

Abstract: We introduce PurpCode, the first post-training recipe for training safe code
reasoning models towards generating secure code and defending against malicious
cyberactivities. PurpCode trains a reasoning model in two stages: (i) Rule
Learning, which explicitly teaches the model to reference cybersafety rules to
generate vulnerability-free code and to avoid facilitating malicious
cyberactivities; and (ii) Reinforcement Learning, which optimizes model safety
and preserves model utility through diverse, multi-objective reward mechanisms.
To empower the training pipelines with comprehensive cybersafety data, we
conduct internal red-teaming to synthesize comprehensive and high-coverage
prompts based on real-world tasks for inducing unsafe cyberactivities in the
model. Based on PurpCode, we develop a reasoning-based coding model, namely
PurpCode-32B, which demonstrates state-of-the-art cybersafety, outperforming
various frontier models. Meanwhile, our alignment method decreases the model
overrefusal rates in both general and cybersafety-specific scenarios, while
preserving model utility in both code generation and common security knowledge.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [38] [MLLM-based Speech Recognition: When and How is Multimodality Beneficial?](https://arxiv.org/abs/2507.19037)
*Yiwen Guan,Viet Anh Trinh,Vivek Voleti,Jacob Whitehill*

Main category: cs.SD

TL;DR: 本文研究了在噪声环境中，多种输入模态如何提高自动语音识别（ASR）的准确性，并通过实验发现了多个关键结果，包括模态的互补性、同步与不同步模态的作用、视觉表示的重要性以及模型架构的影响。


<details>
  <summary>Details</summary>
Motivation: 最近在多模态大语言模型（MLLMs）方面的进展为统一建模语音、文本、图像等模态打开了新的可能性。本文旨在探讨在噪声环境中，多种输入模态如何提高自动语音识别（ASR）的准确性。

Method: 通过在合成和真实数据上的实验，研究了多种输入模态在噪声环境下的自动语音识别（ASR）准确性改进条件和模型架构。

Result: （1）利用更多模态通常能提高ASR准确性，因为每个模态提供互补信息，但改进程度取决于听觉噪声的大小。（2）同步模态（如嘴唇运动）在高噪声水平下更有用，而不同步模态（如图像上下文）在中等噪声水平下最有帮助。（3）高质量的视觉表示始终能提高ASR准确性，突显了开发更强大的视觉编码器的重要性。（4）Mamba在多模态收益方面表现出与Transformer相似的趋势。（5）模态的输入顺序以及它们在损失函数中的权重可以显著影响准确性。

Conclusion: 这些发现提供了实用的见解，并有助于加深我们对在挑战性条件下多模态语音识别的理解。

Abstract: Recent advances in multi-modal large language models (MLLMs) have opened new
possibilities for unified modeling of speech, text, images, and other
modalities. Building on our prior work, this paper examines the conditions and
model architectures under which multiple input modalities can improve automatic
speech recognition (ASR) accuracy in noisy environments. Through experiments on
synthetic and real-world data, we find that (1) harnessing more modalities
usually improves ASR accuracy, as each modality provides complementary
information, but the improvement depends on the amount of auditory noise. (2)
Synchronized modalities (e.g., lip movements) are more useful at high noise
levels whereas unsynchronized modalities (e.g., image context) are most helpful
at moderate noise levels. (3) Higher-quality visual representations
consistently improve ASR accuracy, highlighting the importance of developing
more powerful visual encoders. (4) Mamba exhibits similar trends regarding the
benefits of multimodality as do Transformers. (5) The input order of modalities
as well as their weights in the loss function can significantly impact
accuracy. These findings both offer practical insights and help to deepen our
understanding of multi-modal speech recognition under challenging conditions.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [39] [Adaptive Learning Systems: Personalized Curriculum Design Using LLM-Powered Analytics](https://arxiv.org/abs/2507.18949)
*Yongjie Li,Ruilin Nong,Jianan Liu,Lucas Evans*

Main category: cs.CY

TL;DR: 本文提出了一种基于大型语言模型的自适应学习系统框架，通过实时数据分析实现个性化课程设计，实验结果显示该框架能有效提高学习者的参与度和知识保留率，并具有广泛的适用性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型正在革新教育领域，通过提供个性化的学习体验来满足个体学生的需求。本文旨在引入一种自适应学习系统的框架，以利用LLM的力量提升个性化课程设计。

Method: 本文介绍了一种自适应学习系统的框架，利用LLM驱动的分析进行个性化课程设计。该方法使用先进的机器学习分析实时数据，使系统能够调整学习路径并推荐与学习者进度相匹配的资源。

Result: 实验结果表明，使用定制化课程可以显著提高学习者的参与度和知识保留率。在各种教育环境中进行的评估显示了该框架的灵活性和对学习成果的积极影响。

Conclusion: 该框架展示了其在不同教育环境中的灵活性和对学习成果的积极影响，可能重新塑造传统的教育实践，使其更加适应学生需求。

Abstract: Large language models (LLMs) are revolutionizing the field of education by
enabling personalized learning experiences tailored to individual student
needs. In this paper, we introduce a framework for Adaptive Learning Systems
that leverages LLM-powered analytics for personalized curriculum design. This
innovative approach uses advanced machine learning to analyze real-time data,
allowing the system to adapt learning pathways and recommend resources that
align with each learner's progress. By continuously assessing students, our
framework enhances instructional strategies, ensuring that the materials
presented are relevant and engaging. Experimental results indicate a marked
improvement in both learner engagement and knowledge retention when using a
customized curriculum. Evaluations conducted across varied educational
environments demonstrate the framework's flexibility and positive influence on
learning outcomes, potentially reshaping conventional educational practices
into a more adaptive and student-centered model.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [40] [Distilling a Small Utility-Based Passage Selector to Enhance Retrieval-Augmented Generation](https://arxiv.org/abs/2507.19102)
*Hengran Zhang,Keping Bi,Jiafeng Guo,Jiaming Zhang,Shuaiqiang Wang,Dawei Yin,Xueqi Cheng*

Main category: cs.IR

TL;DR: 本文提出了一种将大型语言模型的效用判断能力蒸馏到更小模型的方法，以解决RAG中基于效用的检索计算成本高的问题。实验结果表明，这种方法显著降低了计算成本，同时提高了答案质量。


<details>
  <summary>Details</summary>
Motivation: 在RAG中，重点已从相关性转向效用，即考虑段落对生成准确答案的有用性。尽管基于效用的检索在RAG中显示出优势，但使用LLM进行效用判断的高计算成本限制了评估的段落数量。这对需要大量信息的复杂查询构成问题。

Method: 我们提出了一种方法，将大型语言模型（LLM）的效用判断能力蒸馏到更小、更高效的模型中。我们的方法专注于基于效用的选择而不是排序，使动态的段落选择适应特定查询而无需固定阈值。我们训练学生模型从教师LLM中学习伪答案生成和效用判断，使用滑动窗口方法动态选择有用的段落。

Result: 实验结果表明，基于效用的选择提供了灵活且成本效益高的解决方案，显著减少了计算成本并提高了答案质量。使用Qwen3-32B作为教师模型，进行了相关性排序和基于效用的选择的蒸馏，分别得到RankQwen1.7B和UtilityQwen1.7B。对于复杂问题，基于效用的选择比相关性排序更有效。

Conclusion: 实验结果表明，基于效用的选择为RAG提供了一种灵活且成本效益高的解决方案，显著降低了计算成本，同时提高了答案质量。对于复杂问题，基于效用的选择比相关性排序更有效。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
incorporating retrieved information. Standard retrieval process prioritized
relevance, focusing on topical alignment between queries and passages. In
contrast, in RAG, the emphasis has shifted to utility, which considers the
usefulness of passages for generating accurate answers. Despite empirical
evidence showing the benefits of utility-based retrieval in RAG, the high
computational cost of using LLMs for utility judgments limits the number of
passages evaluated. This restriction is problematic for complex queries
requiring extensive information. To address this, we propose a method to
distill the utility judgment capabilities of LLMs into smaller, more efficient
models. Our approach focuses on utility-based selection rather than ranking,
enabling dynamic passage selection tailored to specific queries without the
need for fixed thresholds. We train student models to learn pseudo-answer
generation and utility judgments from teacher LLMs, using a sliding window
method that dynamically selects useful passages. Our experiments demonstrate
that utility-based selection provides a flexible and cost-effective solution
for RAG, significantly reducing computational costs while improving answer
quality. We present the distillation results using Qwen3-32B as the teacher
model for both relevance ranking and utility-based selection, distilled into
RankQwen1.7B and UtilityQwen1.7B. Our findings indicate that for complex
questions, utility-based selection is more effective than relevance ranking in
enhancing answer generation performance. We will release the relevance ranking
and utility-based selection annotations for the MS MARCO dataset, supporting
further research in this area.

</details>


### [41] [Injecting External Knowledge into the Reasoning Process Enhances Retrieval-Augmented Generation](https://arxiv.org/abs/2507.19333)
*Minghao Tang,Shiyu Ni,Jiafeng Guo,Keping Bi*

Main category: cs.IR

TL;DR: 本文提出了一种名为Passage Injection的方法，通过将检索到的段落显式地纳入大型语言模型的推理过程中，以提高其对噪声段落的识别和抵抗能力。实验结果表明，该方法在多个数据集上显著提升了RAG系统的性能，并增强了系统的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了提高RAG系统的可靠性，需要增强大型语言模型对噪声的鲁棒性。最近的进展使大型语言模型具备了强大的推理和自我反思能力，使其能够识别和纠正推理过程中的错误。受此能力的启发，提出了Passage Injection方法。

Method: 提出了一种简单而有效的方法，称为Passage Injection，它显式地将检索到的段落纳入大型语言模型的推理过程中，旨在增强模型识别和抵抗噪声段落的能力。

Result: 在四个事实性问答数据集上进行的实验表明，Passage Injection显著提高了整体RAG性能。进一步分析显示，在两种噪声检索设置下，Passage Injection都能持续提高鲁棒性。控制实验确认Passage Injection也能有效地利用有帮助的段落。

Conclusion: 将段落纳入大型语言模型的推理过程是构建更稳健的RAG系统的一个有前景的方向。

Abstract: Retrieval-augmented generation (RAG) has been widely adopted to augment large
language models (LLMs) with external knowledge for knowledge-intensive tasks.
However, its effectiveness is often undermined by the presence of noisy (i.e.,
low-quality) retrieved passages. Enhancing LLMs' robustness to such noise is
critical for improving the reliability of RAG systems. Recent advances have
equipped LLMs with strong reasoning and self-reflection capabilities, allowing
them to identify and correct errors in their reasoning process. Inspired by
this ability, we propose Passage Injection-a simple yet effective method that
explicitly incorporates retrieved passages into LLMs' reasoning process, aiming
to enhance the model's ability to recognize and resist noisy passages. We
validate Passage Injection under general RAG settings using BM25 as the
retriever. Experiments on four reasoning-enhanced LLMs across four factual QA
datasets demonstrate that Passage Injection significantly improves overall RAG
performance. Further analysis on two noisy retrieval settings-random noise,
where the model is provided irrelevant passages, and counterfactual noise,
where it is given misleading passages-shows that Passage Injection consistently
improves robustness. Controlled experiments confirm that Passage Injection can
also effectively leverage helpful passages. These findings suggest that
incorporating passages in LLMs' reasoning process is a promising direction for
building more robust RAG systems. The code can be found
\href{here}{https://github.com/mh-tang/Passage-Injection}.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [42] [A Markov Categorical Framework for Language Modeling](https://arxiv.org/abs/2507.19247)
*Yifan Zhang*

Main category: cs.LG

TL;DR: 本文使用马尔可夫范畴框架分析自回归语言模型的生成过程和NLL目标，揭示了其成功背后的深层结构原理。


<details>
  <summary>Details</summary>
Motivation: 尽管自回归语言模型在实践中表现出色，但对其为何能产生如此多功能表示的理论理解仍然不足。本文旨在提供一个统一的分析框架来解决这一问题。

Method: 本文将单步生成过程建模为Stoch范畴中的马尔可夫核的组合，并利用统计散度来分解信息流和学习到的几何结构。

Result: 本文提出了三个主要贡献：1）为现代推测解码方法（如EAGLE）提供了信息论上的解释；2）形式化了NLL最小化如何使模型学习数据的内在条件随机性；3）证明了NLL训练作为一种隐式的谱对比学习。

Conclusion: 本文通过引入马尔可夫范畴（MCs）的分析框架，揭示了自回归语言模型的成功背后的深层结构原理。

Abstract: Auto-regressive language models factorize sequence probabilities and are
trained by minimizing the negative log-likelihood (NLL) objective. While
empirically powerful, a deep theoretical understanding of why this simple
objective yields such versatile representations remains elusive. This work
introduces a unifying analytical framework using Markov Categories (MCs) to
deconstruct the AR generation process and the NLL objective. We model the
single-step generation map as a composition of Markov kernels in the category
Stoch. This compositional view, when enriched with statistical divergences,
allows us to dissect information flow and learned geometry. Our framework makes
three main contributions. First, we provide a formal, information-theoretic
rationale for the success of modern speculative decoding methods like EAGLE,
quantifying the information surplus in hidden states that these methods
exploit. Second, we formalize how NLL minimization forces the model to learn
not just the next token, but the data's intrinsic conditional stochasticity, a
process we analyze using categorical entropy. Third, and most centrally, we
prove that NLL training acts as an implicit form of spectral contrastive
learning. By analyzing the information geometry of the model's prediction head,
we show that NLL implicitly forces the learned representation space to align
with the eigenspectrum of a predictive similarity operator, thereby learning a
geometrically structured space without explicit contrastive pairs. This
compositional and information-geometric perspective reveals the deep structural
principles underlying the effectiveness of modern LMs. Project Page:
https://github.com/asiresearch/lm-theory

</details>


### [43] [Advancing Event Forecasting through Massive Training of Large Language Models: Challenges, Solutions, and Broader Impacts](https://arxiv.org/abs/2507.19477)
*Sang-Woo Lee,Sohee Yang,Donghyun Kwak,Noah Y. Siegel*

Main category: cs.LG

TL;DR: 本文探讨了训练超级预测者级事件预测大语言模型的关键研究方向，包括训练方法和数据获取，并提出了相关解决方案，旨在推动人工智能在更广泛领域提供预测智能。


<details>
  <summary>Details</summary>
Motivation: 由于最近的推理模型和深度研究风格模型的成功，表明已经开发出能够显著提高预测性能的技术。因此，本文认为现在是研究大规模训练超级预测者级事件预测大语言模型的时候了。

Method: 本文讨论了两个关键的研究方向：训练方法和数据获取。对于训练，文章介绍了基于大语言模型的事件预测训练的三个困难，并提出了缓解这些问题的相关想法。对于数据，文章提出了激进使用市场、公共和爬取数据集以实现大规模训练和评估。

Result: 本文提出了具体的路径和考虑因素，以更接近超级预测者级人工智能技术，并呼吁研究人员关注这些方向。

Conclusion: 本文认为，随着近期技术的积极趋势，现在是研究大规模训练超级预测者级事件预测大语言模型的时候了。

Abstract: Many recent papers have studied the development of superforecaster-level
event forecasting LLMs. While methodological problems with early studies cast
doubt on the use of LLMs for event forecasting, recent studies with improved
evaluation methods have shown that state-of-the-art LLMs are gradually reaching
superforecaster-level performance, and reinforcement learning has also been
reported to improve future forecasting. Additionally, the unprecedented success
of recent reasoning models and Deep Research-style models suggests that
technology capable of greatly improving forecasting performance has been
developed. Therefore, based on these positive recent trends, we argue that the
time is ripe for research on large-scale training of superforecaster-level
event forecasting LLMs. We discuss two key research directions: training
methods and data acquisition. For training, we first introduce three
difficulties of LLM-based event forecasting training: noisiness-sparsity,
knowledge cut-off, and simple reward structure problems. Then, we present
related ideas to mitigate these problems: hypothetical event Bayesian networks,
utilizing poorly-recalled and counterfactual events, and auxiliary reward
signals. For data, we propose aggressive use of market, public, and crawling
datasets to enable large-scale training and evaluation. Finally, we explain how
these technical advances could enable AI to provide predictive intelligence to
society in broader areas. This position paper presents promising specific paths
and considerations for getting closer to superforecaster-level AI technology,
aiming to call for researchers' interest in these directions.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [44] [People Are Highly Cooperative with Large Language Models, Especially When Communication Is Possible or Following Human Interaction](https://arxiv.org/abs/2507.18639)
*Paweł Niszczota,Tomasz Grzegorczyk,Alexander Pastukhov*

Main category: cs.HC

TL;DR: 研究表明，尽管与LLM合作率略低于与人类合作，但仍然较高，且允许沟通能提高合作可能性，验证了LLMs在商业合作环境中的可行性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨与LLM互动如何影响商业环境中的人类合作行为，特别是在有效沟通、协作和利益相关者信任至关重要的情况下。

Method: 我们使用囚徒困境游戏来探索与LLM互动是否会影响合作行为。在实验1中，参与者与人类、经典机器人和LLM进行了30轮重复游戏；在实验2中，参与者进行了一次性游戏，并允许与对手沟通。

Result: 与LLM的合作率比与人类对手低约10-15个百分点，但仍较高。在实验2中，允许沟通增加了与人类和LLM合作的可能性（增加88%），这在LLM非人类性质的情况下尤其令人惊讶。此外，与人类之前的互动后，与LLM的合作率更高，表明合作行为存在溢出效应。

Conclusion: 我们的研究结果验证了企业在具有合作成分的环境中谨慎使用LLMs的可行性。

Abstract: Machines driven by large language models (LLMs) have the potential to augment
humans across various tasks, a development with profound implications for
business settings where effective communication, collaboration, and stakeholder
trust are paramount. To explore how interacting with an LLM instead of a human
might shift cooperative behavior in such settings, we used the Prisoner's
Dilemma game -- a surrogate of several real-world managerial and economic
scenarios. In Experiment 1 (N=100), participants engaged in a thirty-round
repeated game against a human, a classic bot, and an LLM (GPT, in real-time).
In Experiment 2 (N=192), participants played a one-shot game against a human or
an LLM, with half of them allowed to communicate with their opponent, enabling
LLMs to leverage a key advantage over older-generation machines. Cooperation
rates with LLMs -- while lower by approximately 10-15 percentage points
compared to interactions with human opponents -- were nonetheless high. This
finding was particularly notable in Experiment 2, where the psychological cost
of selfish behavior was reduced. Although allowing communication about
cooperation did not close the human-machine behavioral gap, it increased the
likelihood of cooperation with both humans and LLMs equally (by 88%), which is
particularly surprising for LLMs given their non-human nature and the
assumption that people might be less receptive to cooperating with machines
compared to human counterparts. Additionally, cooperation with LLMs was higher
following prior interaction with humans, suggesting a spillover effect in
cooperative behavior. Our findings validate the (careful) use of LLMs by
businesses in settings that have a cooperative component.

</details>


### [45] [TreeReader: A Hierarchical Academic Paper Reader Powered by Language Models](https://arxiv.org/abs/2507.18945)
*Zijian Zhang,Pan Chen,Fangshi Du,Runlong Ye,Oliver Huang,Michael Liut,Alán Aspuru-Guzik*

Main category: cs.HC

TL;DR: TreeReader 是一种新型的语言模型增强型论文阅读器，它将论文分解为交互式树状结构，每个部分最初由 LLM 生成的简洁摘要表示，用户可以按需访问底层细节。


<details>
  <summary>Details</summary>
Motivation: Efficiently navigating and understanding academic papers is crucial for scientific progress. Traditional linear formats like PDF and HTML can cause cognitive overload and obscure a paper's hierarchical structure, making it difficult to locate key information. While LLM-based chatbots offer summarization, they often lack nuanced understanding of specific sections, may produce unreliable information, and typically discard the document's navigational structure.

Method: Drawing insights from a formative study on academic reading practices, we introduce TreeReader, a novel language model-augmented paper reader. TreeReader decomposes papers into an interactive tree structure where each section is initially represented by an LLM-generated concise summary, with underlying details accessible on demand.

Result: A user study was conducted to evaluate TreeReader's impact on reading efficiency and comprehension.

Conclusion: TreeReader provides a more focused and efficient way to navigate and understand complex academic literature by bridging hierarchical summarization with interactive exploration.

Abstract: Efficiently navigating and understanding academic papers is crucial for
scientific progress. Traditional linear formats like PDF and HTML can cause
cognitive overload and obscure a paper's hierarchical structure, making it
difficult to locate key information. While LLM-based chatbots offer
summarization, they often lack nuanced understanding of specific sections, may
produce unreliable information, and typically discard the document's
navigational structure. Drawing insights from a formative study on academic
reading practices, we introduce TreeReader, a novel language model-augmented
paper reader. TreeReader decomposes papers into an interactive tree structure
where each section is initially represented by an LLM-generated concise
summary, with underlying details accessible on demand. This design allows users
to quickly grasp core ideas, selectively explore sections of interest, and
verify summaries against the source text. A user study was conducted to
evaluate TreeReader's impact on reading efficiency and comprehension.
TreeReader provides a more focused and efficient way to navigate and understand
complex academic literature by bridging hierarchical summarization with
interactive exploration.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [46] [Towards Multimodal Social Conversations with Robots: Using Vision-Language Models](https://arxiv.org/abs/2507.19196)
*Ruben Janssens,Tony Belpaeme*

Main category: cs.RO

TL;DR: 本文探讨了社交机器人在多模态社交互动中的需求，并分析了视觉语言模型的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 社交机器人需要利用多种模态进行社交互动，而现有的研究主要集中在任务导向的交互上。

Method: 本文讨论了如何将视觉语言模型适应到社交对话场景中，并探讨了相关的技术挑战和评估方法。

Result: 本文概述了社交对话中多模态系统的需求，并探讨了视觉语言模型在其中的应用潜力。

Conclusion: 本文认为视觉语言模型能够以足够通用的方式处理广泛范围的视觉信息，适用于自主社交机器人。

Abstract: Large language models have given social robots the ability to autonomously
engage in open-domain conversations. However, they are still missing a
fundamental social skill: making use of the multiple modalities that carry
social interactions. While previous work has focused on task-oriented
interactions that require referencing the environment or specific phenomena in
social interactions such as dialogue breakdowns, we outline the overall needs
of a multimodal system for social conversations with robots. We then argue that
vision-language models are able to process this wide range of visual
information in a sufficiently general manner for autonomous social robots. We
describe how to adapt them to this setting, which technical challenges remain,
and briefly discuss evaluation practices.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [47] [OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?](https://arxiv.org/abs/2507.19132)
*Xuetian Chen,Yinghao Chen,Xinfeng Yuan,Zhuo Peng,Lu Chen,Yuekeng Li,Zhoujia Zhang,Yingqian Huang,Leyan Huang,Jiaqing Liang,Tianbao Xie,Zhiyong Wu,Qiushi Sun,Biqing Qi,Bowen Zhou*

Main category: cs.AI

TL;DR: 本文介绍了 OS-MAP，这是一个用于日常计算机使用自动化的基准测试，旨在解决现有基准测试的不足，并提供一个结构化的性能-泛化评估矩阵。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试未能考虑内部任务异质性和相应的代理能力，以及它们与实际用户需求的对齐，这阻碍了有针对性的能力开发和研究进展的实际部署。

Method: OS-MAP 是一个基准测试，将 416 个现实任务按两个关键维度组织：自动化五级分类和从实际用户需求层次派生的泛化范围。

Result: 实验表明，即使最先进的具有 VLM 骨干的代理在涉及感知、推理和协调的高级任务中也遇到困难，这突显了深入理解当前优势和局限性的必要性。

Conclusion: OS-MAP 提供了一个结构化和全面的评估矩阵，有助于推动计算机使用代理的研究和部署。

Abstract: Computer-using agents have shown strong potential to boost human productivity
and enable new application forms across platforms. While recent advances have
led to usable applications, existing benchmarks fail to account for the
internal task heterogeneity and the corresponding agent capabilities, as well
as their alignment with actual user demands-hindering both targeted capability
development and the reliable transition of research progress into practical
deployment. To bridge the gap, we present OS-MAP, a benchmark for daily
computer-using automation that organizes its 416 realistic tasks across 15
applications along two key dimensions: a five-level taxonomy of automation and
a generalization scope derived from a real-world user demand hierarchy. To
enable fine-grained analysis of required capabilities and alignment with
real-world scenarios, OS-MAP evaluates agents along two dimensions: automation
level across a five-level taxonomy, and generalization scope across a demand
hierarchy. This design captures varying levels of required agent autonomy and
generalization, forming a performance-generalization evaluation matrix for
structured and comprehensive assessment. Experiments show that even
State-of-the-Art agents with VLM backbones struggle with higher-level tasks
involving perception, reasoning, and coordination-highlighting the need for a
deeper understanding of current strengths and limitations to drive the future
progress in computer-using agents research and deployment. All code,
environments, baselines, and data are publicly available at
https://github.com/OS-Copilot/OS-Map.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [48] [FD-Bench: A Full-Duplex Benchmarking Pipeline Designed for Full Duplex Spoken Dialogue Systems](https://arxiv.org/abs/2507.19040)
*Yizhou Peng,Yi-Wen Chao,Dianwen Ng,Yukun Ma,Chongjia Ni,Bin Ma,Eng Siong Chng*

Main category: eess.AS

TL;DR: 本文提出一个全面的FD基准测试流程，利用LLM、TTS和ASR来评估FDSDS处理用户中断、管理延迟和在困难场景中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试缺乏针对FD场景的指标，例如评估模型在用户中断时的表现。

Method: 提出一个全面的FD基准测试流程，利用LLM、TTS和ASR来解决这一差距。

Result: 应用基准测试到三个开源FDSDS（Moshi、Freeze-omni和VITA-1.5），使用超过40小时的生成语音，293次模拟对话和1200次中断。结果表明所有模型仍然面临挑战。

Conclusion: 所有模型仍然面临挑战，例如在频繁干扰和噪声条件下无法响应用户中断。

Abstract: Full-duplex spoken dialogue systems (FDSDS) enable more natural human-machine
interactions by allowing real-time user interruptions and backchanneling,
compared to traditional SDS that rely on turn-taking. However, existing
benchmarks lack metrics for FD scenes, e.g., evaluating model performance
during user interruptions. In this paper, we present a comprehensive FD
benchmarking pipeline utilizing LLMs, TTS, and ASR to address this gap. It
assesses FDSDS's ability to handle user interruptions, manage delays, and
maintain robustness in challenging scenarios with diverse novel metrics. We
applied our benchmark to three open-source FDSDS (Moshi, Freeze-omni, and
VITA-1.5) using over 40 hours of generated speech, with 293 simulated
conversations and 1,200 interruptions. The results show that all models
continue to face challenges, such as failing to respond to user interruptions,
under frequent disruptions and noisy conditions. Demonstrations, data, and code
will be released.

</details>


### [49] [Should Top-Down Clustering Affect Boundaries in Unsupervised Word Discovery?](https://arxiv.org/abs/2507.19204)
*Simon Malan,Benjamin van Niekerk,Herman Kamper*

Main category: eess.AS

TL;DR: 本文研究了将未标记语音分割成词类单位并聚类以创建词典的问题，比较了自下而上和自上而下的方法，发现自下而上的方法在速度上有优势，但两者在性能上相当。


<details>
  <summary>Details</summary>
Motivation: 我们想探索是否需要自上而下的信息来提高分割效果。

Method: 我们比较了两种方法：一种是基于自监督特征的相似性预测单词边界，然后对结果进行聚类；另一种是更新的ES-KMeans动态规划方法，它迭代使用K-means来更新边界。

Result: 两种方法在五种语言的ZeroSpeech基准测试中都达到了最先进的结果，但自下而上的方法速度几乎是自上而下的五倍。

Conclusion: 我们建议未来的研究应专注于改进聚类技术，并学习更具区分性的词类表示。

Abstract: We investigate the problem of segmenting unlabeled speech into word-like
units and clustering these to create a lexicon. Prior work can be categorized
into two frameworks. Bottom-up methods first determine boundaries and then
cluster the fixed segmented words into a lexicon. In contrast, top-down methods
incorporate information from the clustered words to inform boundary selection.
However, it is unclear whether top-down information is necessary to improve
segmentation. To explore this, we look at two similar approaches that differ in
whether top-down clustering informs boundary selection. Our simple bottom-up
strategy predicts word boundaries using the dissimilarity between adjacent
self-supervised features, then clusters the resulting segments to construct a
lexicon. Our top-down system is an updated version of the ES-KMeans dynamic
programming method that iteratively uses K-means to update its boundaries. On
the five-language ZeroSpeech benchmarks, both approaches achieve comparable
state-of-the-art results, with the bottom-up system being nearly five times
faster. Through detailed analyses, we show that the top-down influence of
ES-KMeans can be beneficial (depending on factors like the candidate
boundaries), but in many cases the simple bottom-up method performs just as
well. For both methods, we show that the clustering step is a limiting factor.
Therefore, we recommend that future work focus on improved clustering
techniques and learning more discriminative word-like representations. Project
code repository: https://github.com/s-malan/prom-seg-clus.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [50] [Closing the Modality Gap for Mixed Modality Search](https://arxiv.org/abs/2507.19054)
*Binxu Li,Yuhui Zhang,Xiaohan Wang,Weixin Liang,Ludwig Schmidt,Serena Yeung-Levy*

Main category: cs.CV

TL;DR: 本文研究了CLIP在混合模态搜索任务中的表现，发现其存在模态差距问题，并提出GR-CLIP方法来解决这一问题，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 混合模态搜索是一个重要但研究不足的实际应用，现有的对比视觉语言模型（如CLIP）在这一任务中存在明显的模态差距问题，导致了内部模态排名偏差和跨模态融合失败。

Method: 本文提出了一种名为GR-CLIP的轻量级后处理校准方法，用于消除CLIP模型中的模态差距。

Result: GR-CLIP在MixBench基准上将NDCG@10提升了26个百分点，超过了最近的视觉语言生成嵌入模型4个百分点，同时使用了75倍更少的计算资源。

Conclusion: GR-CLIP是一种轻量级的后处理校准方法，能够有效解决CLIP在混合模态搜索任务中的模态差距问题，并在MixBench基准上取得了显著的性能提升。

Abstract: Mixed modality search -- retrieving information across a heterogeneous corpus
composed of images, texts, and multimodal documents -- is an important yet
underexplored real-world application. In this work, we investigate how
contrastive vision-language models, such as CLIP, perform on the mixed modality
search task. Our analysis reveals a critical limitation: these models exhibit a
pronounced modality gap in the embedding space, where image and text embeddings
form distinct clusters, leading to intra-modal ranking bias and inter-modal
fusion failure. To address this issue, we propose GR-CLIP, a lightweight
post-hoc calibration method that removes the modality gap in CLIP's embedding
space. Evaluated on MixBench -- the first benchmark specifically designed for
mixed modality search -- GR-CLIP improves NDCG@10 by up to 26 percentage points
over CLIP, surpasses recent vision-language generative embedding models by 4
percentage points, while using 75x less compute.

</details>


### [51] [LOTUS: A Leaderboard for Detailed Image Captioning from Quality to Societal Bias and User Preferences](https://arxiv.org/abs/2507.19362)
*Yusuke Hirota,Boyi Li,Ryo Hachiuma,Yueh-Hua Wu,Boris Ivanovic,Yuta Nakashima,Marco Pavone,Yejin Choi,Yu-Chiang Frank Wang,Chao-Han Huck Yang*

Main category: cs.CV

TL;DR: 本文介绍了LOTUS，一个用于评估详细标题的基准测试，解决了现有评估中的三个主要差距：缺乏标准化标准、意识偏差评估和用户偏好考虑。分析表明，没有一个模型在所有标准上都表现出色，而标题的详细程度与偏见风险之间存在相关性。偏好导向的评估表明，最佳模型选择取决于用户优先事项。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法在标准化标准、意识偏差评估和用户偏好考虑方面存在不足，因此需要一种新的评估基准来解决这些问题。

Method: 我们引入了LOTUS，这是一个用于评估详细标题的基准测试，解决了现有评估中的三个主要差距：缺乏标准化标准、意识偏差评估和用户偏好考虑。LOTUS全面评估了各种方面，包括标题质量（例如，对齐度、描述性）、风险（例如，幻觉）和社会偏见（例如，性别偏见），同时通过根据不同的用户偏好定制标准来实现偏好导向的评估。

Result: 我们对最近的LVLMs的分析显示，没有一个模型在所有标准上都表现出色，而标题的详细程度与偏见风险之间存在相关性。偏好导向的评估表明，最佳模型选择取决于用户优先事项。

Conclusion: 我们的分析表明，没有一个模型在所有标准上都表现出色，而标题的详细程度与偏见风险之间存在相关性。以用户优先事项为导向的评估表明，最佳模型选择取决于用户的需求。

Abstract: Large Vision-Language Models (LVLMs) have transformed image captioning,
shifting from concise captions to detailed descriptions. We introduce LOTUS, a
leaderboard for evaluating detailed captions, addressing three main gaps in
existing evaluations: lack of standardized criteria, bias-aware assessments,
and user preference considerations. LOTUS comprehensively evaluates various
aspects, including caption quality (e.g., alignment, descriptiveness), risks
(\eg, hallucination), and societal biases (e.g., gender bias) while enabling
preference-oriented evaluations by tailoring criteria to diverse user
preferences. Our analysis of recent LVLMs reveals no single model excels across
all criteria, while correlations emerge between caption detail and bias risks.
Preference-oriented evaluations demonstrate that optimal model selection
depends on user priorities.

</details>


### [52] [MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI Agents](https://arxiv.org/abs/2507.19478)
*Xuehui Wang,Zhenyu Wu,JingJing Xie,Zichen Ding,Bowen Yang,Zehao Li,Zhaoyang Liu,Qingyun Li,Xuan Dong,Zhe Chen,Weiyun Wang,Xiangyu Zhao,Jixuan Chen,Haodong Duan,Tianbao Xie,Chenyu Yang,Shiqian Su,Yue Yu,Yuan Huang,Yiqian Liu,Xiao Zhang,Yanting Zhang,Xiangyu Yue,Weijie Su,Xizhou Zhu,Wei Shen,Jifeng Dai,Wenhai Wang*

Main category: cs.CV

TL;DR: 我们引入了MMBench-GUI，这是一个分层基准，用于评估跨Windows、macOS、Linux、iOS、Android和Web平台的GUI自动化代理。我们提出了一个新的效率-质量区域（EQA）度量标准，并发现准确的视觉定位对于任务成功至关重要。此外，任务效率是一个被严重忽视的维度，所有模型都存在显著的低效率问题。


<details>
  <summary>Details</summary>
Motivation: 为了实现可靠的GUI自动化，代理需要强大的任务规划和跨平台泛化能力，同时需要长上下文记忆、广泛的动作空间和长期推理能力。此外，任务效率仍然是一个严重缺乏研究的维度，所有模型都存在显著的低效率问题。

Method: 我们提出了一个新颖的效率-质量区域（EQA）度量标准，用于评估GUI代理在在线自动化场景中的执行效率。

Result: 通过MMBench-GUI，我们发现准确的视觉定位是整体任务成功的关键决定因素，强调了集成专门定位模块的模块化框架的显著优势。

Conclusion: 我们的基准代码、评估数据和运行环境将公开在https://github.com/open-compass/MMBench-GUI。

Abstract: We introduce MMBench-GUI, a hierarchical benchmark for evaluating GUI
automation agents across Windows, macOS, Linux, iOS, Android, and Web
platforms. It comprises four levels: GUI Content Understanding, Element
Grounding, Task Automation, and Task Collaboration, covering essential skills
for GUI agents. In addition, we propose a novel Efficiency-Quality Area (EQA)
metric to assess GUI agent execution efficiency in online automation scenarios.
Through MMBench-GUI, we identify accurate visual grounding as a critical
determinant of overall task success, emphasizing the substantial benefits of
modular frameworks that integrate specialized grounding modules. Furthermore,
to achieve reliable GUI automation, an agent requires strong task planning and
cross-platform generalization abilities, with long-context memory, a broad
action space, and long-term reasoning playing a critical role. More important,
task efficiency remains a critically underexplored dimension, and all models
suffer from substantial inefficiencies, with excessive redundant steps even
when tasks are ultimately completed. The integration of precise localization,
effective planning, and early stopping strategies is indispensable to enable
truly efficient and scalable GUI automation. Our benchmark code, evaluation
data, and running environment will be publicly available at
https://github.com/open-compass/MMBench-GUI.

</details>
