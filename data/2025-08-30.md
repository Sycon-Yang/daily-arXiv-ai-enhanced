<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 47]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.CV](#cs.CV) [Total: 6]
- [cs.LG](#cs.LG) [Total: 6]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.DL](#cs.DL) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Social Bias in Multilingual Language Models: A Survey](https://arxiv.org/abs/2508.20201)
*Lance Calvin Lim Gamboa,Yue Feng,Mark Lee*

Main category: cs.CL

TL;DR: 本文通过系统综述分析了多语言和非英语语境下的偏见评估和缓解方法，指出了该领域的方法论设计差距，并提出了未来研究方向以提高多语言偏见文献的包容性和跨文化适当性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在分析多语言预训练模型中的社会偏见，并探索如何在多语言和非英语语境中改进偏见评估和缓解方法。

Method: 本文进行了系统综述，分析了多语言和非英语语境下的偏见评估和缓解方法，并探讨了语言多样性、文化意识以及评估指标和缓解技术的选择。

Result: 本文揭示了该领域方法论设计选择中的差距，例如对某些语言的偏好和多语言缓解实验的稀缺性，同时列出了在跨语言和文化适应偏见基准时遇到的常见问题和实施的解决方案。

Conclusion: 本文通过系统综述分析了将偏见评估和缓解方法扩展到多语言和非英语语境的研究，指出了该领域的方法论设计选择中的差距，并提出了未来研究的方向，以增强多语言偏见文献的包容性、跨文化适当性和与最新NLP进展的一致性。

Abstract: Pretrained multilingual models exhibit the same social bias as models
processing English texts. This systematic review analyzes emerging research
that extends bias evaluation and mitigation approaches into multilingual and
non-English contexts. We examine these studies with respect to linguistic
diversity, cultural awareness, and their choice of evaluation metrics and
mitigation techniques. Our survey illuminates gaps in the field's dominant
methodological design choices (e.g., preference for certain languages, scarcity
of multilingual mitigation experiments) while cataloging common issues
encountered and solutions implemented in adapting bias benchmarks across
languages and cultures. Drawing from the implications of our findings, we chart
directions for future research that can reinforce the multilingual bias
literature's inclusivity, cross-cultural appropriateness, and alignment with
state-of-the-art NLP advancements.

</details>


### [2] [Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models](https://arxiv.org/abs/2508.20217)
*Mohammad Amini,Babak Ahmadi,Xiaomeng Xiong,Yilin Zhang,Christopher Qiao*

Main category: cs.CL

TL;DR: 本研究探讨了使用语言模型自动生成多项选择题，以降低手动测试开发的成本和不一致性。研究发现，结构化提示策略可以显著提高中型模型的表现，并提出了一个实用且可扩展的流程来开发和验证语言评估题。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在利用语言模型自动生成多项选择题（MCQs），以减少手动测试开发的成本和不一致性。

Method: 本研究采用两步方法。首先，比较了微调的中型模型（Gemma, 2B）与未微调的大型模型（GPT-3.5, 175B）。其次，评估了七种结构化提示策略，包括零样本、少样本、思维链、角色基础、顺序设计以及组合方式。

Result: 结果表明，结构化提示，特别是结合思维链和顺序设计的策略，显著提高了Gemma的输出。Gemma通常比GPT-3.5的零样本响应产生更多符合构想和教学适当的题目，提示设计在中型模型性能中起关键作用。

Conclusion: 本研究展示了结构化提示和高效微调可以在有限数据条件下增强中型模型用于自动生成测试题的能力。我们强调了结合自动化指标、专家判断和大模型模拟的价值，以确保与评估目标的一致性。所提出的流程为K-12的英语测评题开发和验证提供了一种实用且可扩展的方法。

Abstract: This study explores automatic generation (AIG) using language models to
create multiple choice questions (MCQs) for morphological assessment, aiming to
reduce the cost and inconsistency of manual test development. The study used a
two-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B)
with a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven
structured prompting strategies, including zero-shot, few-shot,
chain-of-thought, role-based, sequential, and combinations. Generated items
were assessed using automated metrics and expert scoring across five
dimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate
human scoring at scale. Results show that structured prompting, especially
strategies combining chain-of-thought and sequential design, significantly
improved Gemma's outputs. Gemma generally produced more construct-aligned and
instructionally appropriate items than GPT-3.5's zero-shot responses, with
prompt design playing a key role in mid-size model performance. This study
demonstrates that structured prompting and efficient fine-tuning can enhance
midsized models for AIG under limited data conditions. We highlight the value
of combining automated metrics, expert judgment, and large-model simulation to
ensure alignment with assessment goals. The proposed workflow offers a
practical and scalable way to develop and validate language assessment items
for K-12.

</details>


### [3] [Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach](https://arxiv.org/abs/2508.20223)
*Andrei Mihai Albu,Giovanni Pollo,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Alessandra Neri,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 本文提出了一种将SystemC TLM模型集成到基于FMI的协同仿真工作流中的全开源方法，解决了时间同步和数据交换等关键问题，并通过案例研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着网络物理系统复杂性的增加，特别是在汽车应用中，对高效建模和跨领域协同仿真的需求不断增加。SystemC事务级建模（TLM）虽然能够有效实现硬件/软件协同设计，但其与其他工程领域模型的互操作性有限，导致集成困难。

Method: 本文介绍了一种轻量级开源工具链，解决了时间同步和数据交换等关键技术挑战，并通过代表性案例研究验证了集成的可行性和有效性。

Result: 本文展示了将SystemC TLM模型集成到基于FMI的协同仿真工作流中的可行性与有效性，并通过案例研究验证了该方法的性能。

Conclusion: 本文提出了一种将SystemC TLM模型集成到基于FMI的协同仿真工作流中的全开源方法，通过封装SystemC TLM组件为FMI 3.0协同仿真功能模型单元（FMU），实现了跨异构仿真环境的无缝、标准化集成。

Abstract: The growing complexity of cyber-physical systems, particularly in automotive
applications, has increased the demand for efficient modeling and cross-domain
co-simulation techniques. While SystemC Transaction-Level Modeling (TLM)
enables effective hardware/software co-design, its limited interoperability
with models from other engineering domains poses integration challenges. This
paper presents a fully open-source methodology for integrating SystemC TLM
models into Functional Mock-up Interface (FMI)-based co-simulation workflows.
By encapsulating SystemC TLM components as FMI 3.0 Co Simulation Functional
Mock-up Units (FMUs), the proposed approach facilitates seamless, standardized
integration across heterogeneous simulation environments. We introduce a
lightweight open-source toolchain, address key technical challenges such as
time synchronization and data exchange, and demonstrate the feasibility and
effectiveness of the integration through representative case studies.

</details>


### [4] [Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities](https://arxiv.org/abs/2508.20324)
*Rikuto Kotoge,Mai Nishimura,Jiaxin Ma*

Main category: cs.CL

TL;DR: 本文提出DGPO方法，通过教师指导提升紧凑语言模型的agentic RAG行为，并在实验中证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 紧凑的语言模型由于推理能力差，导致奖励稀疏和训练不稳定，因此需要一种有效的方法来提升它们的agentic RAG行为。

Method: 提出了一种名为Distillation-Guided Policy Optimization (DGPO)的方法，通过从教师演示中进行冷启动初始化并在策略优化过程中持续教师指导来解决挑战。

Result: 实验表明，DGPO使紧凑模型能够实现复杂的agentic搜索行为，甚至在某些情况下优于较大的教师模型。

Conclusion: DGPO使在计算资源受限环境中实现agentic RAG成为可能。

Abstract: Reinforcement Learning has emerged as a post-training approach to elicit
agentic RAG behaviors such as search and planning from language models.
However, compact language models (e.g., 0.5B parameters) struggle due to poor
reasoning ability, resulting in sparse rewards and unstable training. To
overcome these difficulties, we propose Distillation-Guided Policy Optimization
(DGPO), which addresses the challenges through cold-start initialization from
teacher demonstrations and continuous teacher guidance during policy
optimization. To systematically evaluate our approach, we introduce Agentic RAG
Capabilities (ARC), a fine-grained metric analyzing reasoning, search
coordination, and response synthesis. Comprehensive experiments demonstrate
that DGPO enables compact models to achieve sophisticated agentic search
behaviors, even outperforming the larger teacher model in some cases. DGPO
makes agentic RAG feasible in computing resource-constrained environments.

</details>


### [5] [GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs](https://arxiv.org/abs/2508.20325)
*Haibo Jin,Ruoxi Chen,Peiyan Zhang,Andy Zhou,Yang Zhang,Haohan Wang*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As Large Language Models become increasingly integral to various domains,
their potential to generate harmful responses has prompted significant societal
and regulatory concerns. In response, governments have issued ethics guidelines
to promote the development of trustworthy AI. However, these guidelines are
typically high-level demands for developers and testers, leaving a gap in
translating them into actionable testing questions to verify LLM compliance.
  To address this challenge, we introduce GUARD (\textbf{G}uideline
\textbf{U}pholding Test through \textbf{A}daptive \textbf{R}ole-play and
Jailbreak \textbf{D}iagnostics), a testing method designed to operationalize
guidelines into specific guideline-violating questions that assess LLM
adherence. To implement this, GUARD uses automated generation of
guideline-violating questions based on government-issued guidelines, thereby
testing whether responses comply with these guidelines. When responses directly
violate guidelines, GUARD reports inconsistencies. Furthermore, for responses
that do not directly violate guidelines, GUARD integrates the concept of
``jailbreaks'' to diagnostics, named GUARD-JD, which creates scenarios that
provoke unethical or guideline-violating responses, effectively identifying
potential scenarios that could bypass built-in safety mechanisms. Our method
finally culminates in a compliance report, delineating the extent of adherence
and highlighting any violations.
  We have empirically validated the effectiveness of GUARD on seven LLMs,
including Vicuna-13B, LongChat-7B, Llama2-7B, Llama-3-8B, GPT-3.5, GPT-4,
GPT-4o, and Claude-3.7, by testing compliance under three government-issued
guidelines and conducting jailbreak diagnostics. Additionally, GUARD-JD can
transfer jailbreak diagnostics to vision-language models, demonstrating its
usage in promoting reliable LLM-based applications.

</details>


### [6] [Joint Enhancement of Relational Reasoning for Long-Context LLMs](https://arxiv.org/abs/2508.20351)
*Zhirui Chen,Wei Shen,Jiashui Huang,Ling Shao*

Main category: cs.CL

TL;DR: JERR is a framework designed to enhance long-context comprehension via graph-based reasoning in LLMs, which improves reliability and transparency while outperforming baselines on various metrics.


<details>
  <summary>Details</summary>
Motivation: LLMs still struggle with long contexts due to memory limitations and their inability to tackle complex and long-context tasks. Additionally, LLMs often suffer from a lack of transparency and are prone to producing hallucinations.

Method: JERR integrates three key components: synopsis extraction, graph construction, and relational reasoning. Synopsis is extracted by chunking text strategically, a directed acyclic graph (DAG) is built to resolve redundancy, and Monte Carlo Tree Search (MCTS) is incorporated to help the model navigate complex reasoning paths.

Result: Experimental results show that JERR consistently outperforms all baselines on the ROUGE and F1 metrics, achieving the highest scores on the LLM-Rater evaluation.

Conclusion: JERR provides a novel solution that enables LLMs to handle extended contexts and complex reasoning tasks with improved reliability and transparency.

Abstract: Despite significant progress, large language models (LLMs) still struggle
with long contexts due to memory limitations and their inability to tackle
complex and long-context tasks. Additionally, LLMs often suffer from a lack of
transparency and are prone to producing hallucinations. To address these
challenges, we propose \textbf{JERR}, a novel framework designed to enhance
long-context comprehension via graph-based reasoning in LLMs. JERR integrates
three key components: synopsis extraction, graph construction, and relational
reasoning. First, synopsis is extracted by chunking text strategically,
allowing the model to summarize and understand information more efficiently.
Second, we build a directed acyclic graph (DAG) to resolve redundancy, ensuring
logical consistency and clarity. Finally, we incorporate Monte Carlo Tree
Search (MCTS) to help the model navigate complex reasoning paths, ensuring more
accurate and interpretable outputs. This framework provides a novel solution
that enables LLMs to handle extended contexts and complex reasoning tasks with
improved reliability and transparency. Experimental results show that JERR
consistently outperforms all baselines on the ROUGE and F1 metrics, achieving
the highest scores on the LLM-Rater evaluation.

</details>


### [7] [Graph-R1: Unleashing LLM Reasoning with NP-Hard Graph Problems](https://arxiv.org/abs/2508.20373)
*Yuyao Wang,Bowen Liu,Jianheng Tang,Nuo Chen,Yuhan Li,Qifan Zhang,Jia Li*

Main category: cs.CL

TL;DR: This paper introduces NPH graph problems as a synthetic training corpus to enhance Long CoT reasoning in LLMs through a two-stage post-training framework, achieving strong results across various domains.


<details>
  <summary>Details</summary>
Motivation: Developing Long CoT behaviors relies heavily on post-training with high-quality datasets, which are costly and human-curated. The need for scalable alternatives led to the exploration of NPH graph problems as a synthetic training corpus.

Method: Introducing NP-hard (NPH) graph problems as a synthetic training corpus and developing a two-stage post-training framework: Long CoT Supervised Fine-Tuning (SFT) on rejection-sampled NPH graph instances and Reinforcement Learning (RL) with a fine-grained reward design.

Result: The flagship model, Graph-R1-7B, demonstrates strong generalization across mathematics, coding, STEM, and logic, and surpasses QwQ-32B on NPH graph problems in both accuracy and reasoning efficiency.

Conclusion: NPH graph problems can serve as an effective and scalable resource for advancing Long CoT reasoning in LLMs, opening a new frontier for LLM post-training.

Abstract: Reasoning Large Language Models (RLLMs) have recently achieved remarkable
progress on complex reasoning tasks, largely enabled by their long
chain-of-thought (Long CoT) capabilities. However, developing these Long CoT
behaviors relies heavily on post-training with high-quality datasets, which are
typically costly and human-curated (e.g., mathematics and code), leaving
scalable alternatives unexplored. In this work, we introduce NP-hard (NPH)
graph problems as a novel synthetic training corpus, as they inherently require
deep reasoning, extensive exploration, and reflective strategies, which are
core characteristics of Long CoT reasoning. Building on this insight, we
develop a two-stage post-training framework: (i) Long CoT Supervised
Fine-Tuning (SFT) on rejection-sampled NPH graph instances, which substantially
enhances reasoning depth, and (ii) Reinforcement Learning (RL) with a
fine-grained reward design, which sharpens reasoning efficiency. Our flagship
model, Graph-R1-7B, demonstrates strong generalization across mathematics,
coding, STEM, and logic, and surpasses QwQ-32B on NPH graph problems in both
accuracy and reasoning efficiency. These results position NPH graph problems as
an effective and scalable resource for advancing Long CoT reasoning in LLMs,
opening a new frontier for LLM post-training. Our implementation is available
at https://github.com/Graph-Reasoner/Graph-R1, with models and datasets hosted
in our Hugging Face collection HKUST-DSAIL/Graph-R1.

</details>


### [8] [CAPE: Context-Aware Personality Evaluation Framework for Large Language Models](https://arxiv.org/abs/2508.20385)
*Jivnesh Sandhan,Fei Cheng,Tushar Sandhan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 本文提出了一个名为CAPE的框架，用于评估大型语言模型（LLMs）在考虑上下文的情况下的人格特征。研究发现，对话历史可以提高响应一致性，但也可能导致人格变化。不同模型对上下文的依赖程度不同，且该框架在角色扮演代理中的应用显示了更好的一致性与人类判断对齐。


<details>
  <summary>Details</summary>
Motivation: 传统上用于评估人类的心理测量测试现在被应用于大型语言模型（LLMs）以评估其行为特征。然而，现有研究采用了一种上下文无关的方法，每个问题单独回答以避免上下文影响。我们称之为迪士尼世界测试，这是一种忽略现实应用的人工设置，其中对话历史塑造了回应。为了弥合这一差距，我们提出了第一个上下文感知人格评估（CAPE）框架。

Method: 我们提出了第一个上下文感知人格评估（CAPE）框架，结合了先前的对话交互，并引入了新的度量标准来量化LLM响应的一致性。

Result: 我们在7个LLM上的广泛实验表明，对话历史通过上下文学习增强了响应一致性，但也导致了人格变化，GPT-3.5-Turbo和GPT-4-Turbo表现出极端偏差。虽然GPT模型对问题顺序具有鲁棒性，但Gemini-1.5-Flash和Llama-8B表现出显著的敏感性。此外，GPT模型的响应源于其内在的人格特质以及之前的互动，而Gemini-1.5-Flash和Llama-8B则严重依赖于之前的互动。

Conclusion: 我们的框架应用于角色扮演代理（RPAs）显示，依赖于上下文的人格变化提高了响应一致性，并更好地与人类判断对齐。

Abstract: Psychometric tests, traditionally used to assess humans, are now being
applied to Large Language Models (LLMs) to evaluate their behavioral traits.
However, existing studies follow a context-free approach, answering each
question in isolation to avoid contextual influence. We term this the Disney
World test, an artificial setting that ignores real-world applications, where
conversational history shapes responses. To bridge this gap, we propose the
first Context-Aware Personality Evaluation (CAPE) framework for LLMs,
incorporating prior conversational interactions. To thoroughly analyze the
influence of context, we introduce novel metrics to quantify the consistency of
LLM responses, a fundamental trait in human behavior.
  Our exhaustive experiments on 7 LLMs reveal that conversational history
enhances response consistency via in-context learning but also induces
personality shifts, with GPT-3.5-Turbo and GPT-4-Turbo exhibiting extreme
deviations. While GPT models are robust to question ordering, Gemini-1.5-Flash
and Llama-8B display significant sensitivity. Moreover, GPT models response
stem from their intrinsic personality traits as well as prior interactions,
whereas Gemini-1.5-Flash and Llama--8B heavily depend on prior interactions.
Finally, applying our framework to Role Playing Agents (RPAs) shows
context-dependent personality shifts improve response consistency and better
align with human judgments. Our code and datasets are publicly available at:
https://github.com/jivnesh/CAPE

</details>


### [9] [Measuring Reasoning Utility in LLMs via Conditional Entropy Reduction](https://arxiv.org/abs/2508.20395)
*Xu Guo*

Main category: cs.CL

TL;DR: 本文研究了推理效用如何影响最终答案的正确性，并通过实验发现条件熵的变化可以预测答案的正确性。此外，错误的推理路径通常更长，这表明更长的推理不一定更好。


<details>
  <summary>Details</summary>
Motivation: 最近的大语言模型（LLMs）进展通常依赖于生成中间推理步骤以提高准确性。然而，很少有工作研究推理效用如何贡献于最终答案的正确性。由于自回归生成的随机性，生成更多上下文并不保证增加对答案的信心。如果能够在生成过程中预测推理步骤是否有用，就可以提前停止或修剪无效步骤，避免最终决策中的干扰。

Method: 我们在MATH数据集上进行了一项oracle研究，使用Qwen2.5-32B和GPT-4o生成推理链，并使用另一个模型（Qwen3-8B）来量化这些链对最终准确性的效用。我们通过逐步扩展上下文来测量模型在每个推理步骤上的答案跨度Y的不确定性，使用条件熵（词汇表上的期望负对数似然）。

Result: 我们的结果显示出一个清晰的模式：随着步骤的增加而减少的条件熵与正确的答案密切相关，而平坦或增加的熵通常导致错误的答案。我们还证实了错误的推理路径通常比正确的路径更长，这表明更长的推理不一定能产生更好的结果。

Conclusion: 这些发现为设计高效的推理管道提供了基础，以检测并避免早期无益的推理。

Abstract: Recent advancements in large language models (LLMs) often rely on generating
intermediate reasoning steps to enhance accuracy. However, little work has
examined how reasoning utility contributes to the final answer's correctness.
Due to the stochastic nature of autoregressive generation, generating more
context does not guarantee increased confidence in the answer. If we could
predict, during generation, whether a reasoning step will be useful, we could
stop early or prune ineffective steps, avoiding distractions in the final
decision.
  We present an oracle study on MATH dataset, using Qwen2.5-32B and GPT-4o to
generate reasoning chains, and then employing a separate model (Qwen3-8B) to
quantify the utility of these chains for final accuracy. Specifically, we
measure the model's uncertainty on the answer span Y at each reasoning step
using conditional entropy (expected negative log-likelihood over the
vocabulary) with context expanding step by step. Our results show a clear
pattern: conditional entropy that decreases over steps is strongly associated
with correct answers, whereas flat or increasing entropy often results in wrong
answers. We also corroborate that incorrect reasoning paths tend to be longer
than correct ones, suggesting that longer reasoning does not necessarily yield
better outcomes. These findings serve as a foundation to inspire future work on
designing efficient reasoning pipelines that detect and avoid unproductive
reasoning early.

</details>


### [10] [UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools](https://arxiv.org/abs/2508.20410)
*Sam Jung,Agustin Garcinuno,Spencer Mateega*

Main category: cs.CL

TL;DR: UI-Bench is a large-scale benchmark that evaluates the visual excellence of AI text-to-app tools through expert pairwise comparison, providing a reproducible standard for advancing AI-driven web design.


<details>
  <summary>Details</summary>
Motivation: There is no public benchmark that rigorously verifies the claims of high-quality applications and websites produced by AI text-to-app tools.

Method: UI-Bench evaluates visual excellence across competing AI text-to-app tools through expert pairwise comparison, using a TrueSkill-derived model to rank systems with calibrated confidence intervals.

Result: UI-Bench spans 10 tools, 30 prompts, 300 generated sites, and 4000+ expert judgments. It releases the complete prompt set, an open-source evaluation framework, and a public leaderboard.

Conclusion: UI-Bench establishes a reproducible standard for advancing AI-driven web design.

Abstract: AI text-to-app tools promise high quality applications and websites in
minutes, yet no public benchmark rigorously verifies those claims. We introduce
UI-Bench, the first large-scale benchmark that evaluates visual excellence
across competing AI text-to-app tools through expert pairwise comparison.
Spanning 10 tools, 30 prompts, 300 generated sites, and \textit{4000+} expert
judgments, UI-Bench ranks systems with a TrueSkill-derived model that yields
calibrated confidence intervals. UI-Bench establishes a reproducible standard
for advancing AI-driven web design. We release (i) the complete prompt set,
(ii) an open-source evaluation framework, and (iii) a public leaderboard. The
generated sites rated by participants will be released soon. View the UI-Bench
leaderboard at https://uibench.ai/leaderboard.

</details>


### [11] [DentalBench: Benchmarking and Advancing LLMs Capability for Bilingual Dentistry Understanding](https://arxiv.org/abs/2508.20416)
*Hengchuan Zhu,Yihuan Xu,Yichen Li,Zijie Meng,Zuozhu Liu*

Main category: cs.CL

TL;DR: 本文介绍了DentalBench，这是第一个全面的双语基准，用于评估和推动LLMs在牙科领域的应用。通过实验，我们发现领域适应可以显著提高模型性能，特别是在知识密集型和术语导向的任务中，并强调了领域特定基准在开发可信赖且有效的医疗应用LLMs中的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏针对性的评估资源，大型语言模型（LLMs）和医学LLMs在专门医学领域（如牙科）的能力仍未被充分探索。因此，本文旨在创建一个专门的基准来评估和提升LLMs在牙科领域的表现。

Method: 本文引入了DentalBench，包括两个主要部分：DentalQA（一个涵盖4个任务和16个牙科子领域的英汉问答基准）和DentalCorpus（一个大规模高质量语料库，用于牙科领域适应）。此外，还评估了14个LLMs，并进行了进一步实验以验证领域适应的效果。

Result: 评估了14个LLMs，揭示了不同任务类型和语言之间的显著性能差距。进一步实验表明，领域适应可以显著提高模型性能，特别是在知识密集型和术语导向的任务中。

Conclusion: 本文介绍了DentalBench，这是第一个全面的双语基准，用于评估和推动LLMs在牙科领域的应用。通过实验，我们发现领域适应可以显著提高模型性能，特别是在知识密集型和术语导向的任务中，并强调了领域特定基准在开发可信赖且有效的医疗应用LLMs中的重要性。

Abstract: Recent advances in large language models (LLMs) and medical LLMs (Med-LLMs)
have demonstrated strong performance on general medical benchmarks. However,
their capabilities in specialized medical fields, such as dentistry which
require deeper domain-specific knowledge, remain underexplored due to the lack
of targeted evaluation resources. In this paper, we introduce DentalBench, the
first comprehensive bilingual benchmark designed to evaluate and advance LLMs
in the dental domain. DentalBench consists of two main components: DentalQA, an
English-Chinese question-answering (QA) benchmark with 36,597 questions
spanning 4 tasks and 16 dental subfields; and DentalCorpus, a large-scale,
high-quality corpus with 337.35 million tokens curated for dental domain
adaptation, supporting both supervised fine-tuning (SFT) and
retrieval-augmented generation (RAG). We evaluate 14 LLMs, covering
proprietary, open-source, and medical-specific models, and reveal significant
performance gaps across task types and languages. Further experiments with
Qwen-2.5-3B demonstrate that domain adaptation substantially improves model
performance, particularly on knowledge-intensive and terminology-focused tasks,
and highlight the importance of domain-specific benchmarks for developing
trustworthy and effective LLMs tailored to healthcare applications.

</details>


### [12] [KG-CQR: Leveraging Structured Relation Representations in Knowledge Graphs for Contextual Query Retrieval](https://arxiv.org/abs/2508.20417)
*Chi Minh Bui,Ngoc Mai Thieu,Van Vinh Nguyen,Json J. Jung,Khac-Hoai Nam Bui*

Main category: cs.CL

TL;DR: KG-CQR是一种新颖的框架，用于增强检索增强生成系统中的查询检索阶段，通过利用知识图谱来提升检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要解决语料库级别的上下文损失，而KG-CQR专注于通过结构化关系表示来增强查询。

Method: KG-CQR框架通过利用基于语料库的KG来增强复杂输入查询的上下文表示，包括子图提取、补全和上下文生成模块。

Result: 实验结果表明，KG-CQR在RAGBench和MultiHop-RAG数据集上实现了4-6%的mAP提升和2-3%的Recall@25提升，并在多跳问答等挑战性任务中表现优于基线模型。

Conclusion: KG-CQR在RAG任务中表现出色，显著提升了检索效果。

Abstract: The integration of knowledge graphs (KGs) with large language models (LLMs)
offers significant potential to improve the retrieval phase of
retrieval-augmented generation (RAG) systems. In this study, we propose KG-CQR,
a novel framework for Contextual Query Retrieval (CQR) that enhances the
retrieval phase by enriching the contextual representation of complex input
queries using a corpus-centric KG. Unlike existing methods that primarily
address corpus-level context loss, KG-CQR focuses on query enrichment through
structured relation representations, extracting and completing relevant KG
subgraphs to generate semantically rich query contexts. Comprising subgraph
extraction, completion, and contextual generation modules, KG-CQR operates as a
model-agnostic pipeline, ensuring scalability across LLMs of varying sizes
without additional training. Experimental results on RAGBench and MultiHop-RAG
datasets demonstrate KG-CQR's superior performance, achieving a 4-6%
improvement in mAP and a 2-3% improvement in Recall@25 over strong baseline
models. Furthermore, evaluations on challenging RAG tasks such as multi-hop
question answering show that, by incorporating KG-CQR, the performance
consistently outperforms the existing baseline in terms of retrieval
effectiveness

</details>


### [13] [CAMB: A comprehensive industrial LLM benchmark on civil aviation maintenance](https://arxiv.org/abs/2508.20420)
*Feng Zhang,Chengjie Pang,Yuehan Zhang,Chenyu Luo*

Main category: cs.CL

TL;DR: 本文提出并开发了一个工业级的基准测试，专门针对民用航空维护领域，以评估大型语言模型（LLMs）的能力。该基准测试有助于识别知识差距和复杂推理问题，并为改进提供基础。通过实验验证了其有效性，并开源了相关资源以促进进一步研究。


<details>
  <summary>Details</summary>
Motivation: 民用航空维护是一个以严格行业标准为特点的领域。在此领域中，维护程序和故障排除是关键且知识密集型的任务，需要复杂的推理能力。然而，目前缺乏专门用于评估大型语言模型（LLMs）在这一垂直领域中的工具。因此，我们需要开发一个工业级的基准测试来填补这一空白。

Method: 我们提出了一个工业级的基准测试，专门针对民用航空维护领域。该基准测试旨在测量大型语言模型（LLMs）在民用航空维护领域的性能，识别特定的知识差距和复杂推理问题。此外，我们利用这个基准测试来评估现有的知名向量嵌入模型和LLMs在民用航空维护场景中的表现。

Result: 通过实验探索和分析，我们展示了基准测试在评估该领域模型性能方面的有效性。同时，我们开源了这个评估基准和代码，以促进进一步的研究和发展。

Conclusion: 我们的工作填补了当前LLM评估中的一个重要空白，即主要关注数学和编码推理任务。通过实验探索和分析，我们展示了基准测试在评估该领域模型性能方面的有效性，并开源了这个评估基准和代码以促进进一步的研究和发展。

Abstract: Civil aviation maintenance is a domain characterized by stringent industry
standards. Within this field, maintenance procedures and troubleshooting
represent critical, knowledge-intensive tasks that require sophisticated
reasoning. To address the lack of specialized evaluation tools for large
language models (LLMs) in this vertical, we propose and develop an
industrial-grade benchmark specifically designed for civil aviation
maintenance. This benchmark serves a dual purpose: It provides a standardized
tool to measure LLM capabilities within civil aviation maintenance, identifying
specific gaps in domain knowledge and complex reasoning. By pinpointing these
deficiencies, the benchmark establishes a foundation for targeted improvement
efforts (e.g., domain-specific fine-tuning, RAG optimization, or specialized
prompt engineering), ultimately facilitating progress toward more intelligent
solutions within civil aviation maintenance. Our work addresses a significant
gap in the current LLM evaluation, which primarily focuses on mathematical and
coding reasoning tasks. In addition, given that Retrieval-Augmented Generation
(RAG) systems are currently the dominant solutions in practical applications ,
we leverage this benchmark to evaluate existing well-known vector embedding
models and LLMs for civil aviation maintenance scenarios. Through experimental
exploration and analysis, we demonstrate the effectiveness of our benchmark in
assessing model performance within this domain, and we open-source this
evaluation benchmark and code to foster further research and
development:https://github.com/CamBenchmark/cambenchmark

</details>


### [14] [Searching the Title of Practical Work of the Informatics Engineering Bachelor Program with the Case Base Reasoning Method](https://arxiv.org/abs/2508.20442)
*Agung Sukrisna Jaya,Osvari Arsalan,Danny Matthew Saputra*

Main category: cs.CL

TL;DR: 本文提出了一种基于案例库推理的实践工作标题搜索系统，利用TF-IDF和余弦相似度进行向量化和相似度计算，测试结果表明该系统在第二阶段能够获得相同数量的标题和最高的平均匹配分数。


<details>
  <summary>Details</summary>
Motivation: 为了提高实践工作标题的搜索效率和准确性，利用已有的案例经验进行相似度匹配。

Method: 使用案例库推理（CBR）技术，结合TF-IDF进行向量化处理和余弦相似度计算相似度值。

Result: 在使用705个实践工作标题的测试中，第二阶段的结果与第一阶段相同数量的标题和最高的平均匹配分数。

Conclusion: 该系统能够有效地根据标题或关键词搜索实践工作标题，并在第二阶段获得相同数量的标题和最高的平均匹配分数。

Abstract: Case Base Reasoning (CBR) is a case solving technique based on experience in
cases that have occurred before with the highest similarity. CBR is used to
search for practical work titles. TF-IDF is applied to process the
vectorization of each practical work title word and Cosine Similarity for the
calculation of similarity values. This system can search either in the form of
titles or keywords. The output of the system is the title of practical work and
the match value of each title. Based on the test results using 705 practical
work titles, testing was carried out with five titles and carried out in two
stages. The first stage searches with existing titles and the second stage
randomizes the title from the first stage. And the results obtained in the
second stage are the same number of titles found and the highest average match
score.

</details>


### [15] [MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers](https://arxiv.org/abs/2508.20453)
*Zhenting Wang,Qi Chang,Hemani Patel,Shashank Biju,Cheng-En Wu,Quan Liu,Aolin Ding,Alireza Rezazadeh,Ankit Shah,Yujia Bao,Eugene Siow*

Main category: cs.CL

TL;DR: MCP-Bench是一个用于评估大型语言模型在真实、多步骤任务中表现的基准，它强调了工具使用、跨工具协调和任务完成方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试无法充分评估大型语言模型在真实、多步骤任务中的能力，因为它们依赖于显式的工具规范、浅层的几步工作流和孤立的领域操作。

Method: MCP-Bench基于Model Context Protocol (MCP)构建，连接到28个代表性的MCP服务器，这些服务器跨越250个工具，涵盖金融、旅行、科学计算和学术搜索等领域。该基准测试代理从模糊指令中检索相关工具、规划多跳执行轨迹、在中间工具输出中定位响应以及协调跨领域工作流的能力。

Result: 实验表明，20个先进的大型语言模型在MCP-Bench中面临持续的挑战。

Conclusion: MCP-Bench揭示了在多步骤任务中使用大型语言模型的持续挑战，特别是在工具使用、跨工具协调和任务完成方面。

Abstract: We introduce MCP-Bench, a benchmark for evaluating large language models
(LLMs) on realistic, multi-step tasks that demand tool use, cross-tool
coordination, precise parameter control, and planning/reasoning for solving
tasks. Built on the Model Context Protocol (MCP), MCP-Bench connects LLMs to 28
representative live MCP servers spanning 250 tools across domains such as
finance, traveling, scientific computing, and academic search. Unlike prior
API-based benchmarks, each MCP server provides a set of complementary tools
designed to work together, enabling the construction of authentic, multi-step
tasks with rich input-output coupling. Tasks in MCP-Bench test agents' ability
to retrieve relevant tools from fuzzy instructions without explicit tool names,
plan multi-hop execution trajectories for complex objectives, ground responses
in intermediate tool outputs, and orchestrate cross-domain workflows -
capabilities not adequately evaluated by existing benchmarks that rely on
explicit tool specifications, shallow few-step workflows, and isolated domain
operations. We propose a multi-faceted evaluation framework covering tool-level
schema understanding and usage, trajectory-level planning, and task completion.
Experiments on 20 advanced LLMs reveal persistent challenges in MCP-Bench. Code
and data: https://github.com/Accenture/mcp-bench.

</details>


### [16] [Prediction of mortality and resource utilization in critical care: a deep learning approach using multimodal electronic health records with natural language processing techniques](https://arxiv.org/abs/2508.20460)
*Yucheng Ruan,Xiang Lan,Daniel J. Tan,Hairil Rizal Abdullah,Mengling Feng*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Background Predicting mortality and resource utilization from electronic
health records (EHRs) is challenging yet crucial for optimizing patient
outcomes and managing costs in intensive care unit (ICU). Existing approaches
predominantly focus on structured EHRs, often ignoring the valuable clinical
insights in free-text notes. Additionally, the potential of textual information
within structured data is not fully leveraged. This study aimed to introduce
and assess a deep learning framework using natural language processing
techniques that integrates multimodal EHRs to predict mortality and resource
utilization in critical care settings. Methods Utilizing two real-world EHR
datasets, we developed and evaluated our model on three clinical tasks with
leading existing methods. We also performed an ablation study on three key
components in our framework: medical prompts, free-texts, and pre-trained
sentence encoder. Furthermore, we assessed the model's robustness against the
corruption in structured EHRs. Results Our experiments on two real-world
datasets across three clinical tasks showed that our proposed model improved
performance metrics by 1.6\%/0.8\% on BACC/AUROC for mortality prediction,
0.5%/2.2% on RMSE/MAE for LOS prediction, 10.9%/11.0% on RMSE/MAE for surgical
duration estimation compared to the best existing methods. It consistently
demonstrated superior performance compared to other baselines across three
tasks at different corruption rates. Conclusions The proposed framework is an
effective and accurate deep learning approach for predicting mortality and
resource utilization in critical care. The study also highlights the success of
using prompt learning with a transformer encoder in analyzing multimodal EHRs.
Importantly, the model showed strong resilience to data corruption within
structured data, especially at high corruption levels.

</details>


### [17] [ConspirED: A Dataset for Cognitive Traits of Conspiracy Theories and Large Language Model Safety](https://arxiv.org/abs/2508.20468)
*Luke Bates,Max Glockner,Preslav Nakov,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文介绍了ConspirED数据集，用于分析阴谋论内容中的认知特征，并评估大型语言模型对阴谋论输入的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成的虚假信息越来越复杂，理解阴谋论内容中的修辞模式对于开发干预措施（如针对性预骗和评估AI漏洞）变得尤为重要。

Method: 本文引入了ConspirED数据集，该数据集使用CONSPIR认知框架对在线阴谋文章中的多句摘录进行标注。然后，利用ConspirED开发计算模型来识别阴谋论特征，并评估大型语言模型对阴谋论输入的鲁棒性。

Result: 研究发现，阴谋论内容会导致模型输出与输入推理模式一致，即使成功规避了可验证的虚假信息。

Conclusion: 本文介绍了ConspirED数据集，并展示了其在识别阴谋论特征和评估大型语言模型对阴谋论输入的鲁棒性方面的应用。结果表明，阴谋论内容会使模型输出与输入推理模式一致，即使成功规避了可验证的虚假信息。

Abstract: Conspiracy theories erode public trust in science and institutions while
resisting debunking by evolving and absorbing counter-evidence. As AI-generated
misinformation becomes increasingly sophisticated, understanding rhetorical
patterns in conspiratorial content is important for developing interventions
such as targeted prebunking and assessing AI vulnerabilities. We introduce
ConspirED (CONSPIR Evaluation Dataset), which captures the cognitive traits of
conspiratorial ideation in multi-sentence excerpts (80--120 words) from online
conspiracy articles, annotated using the CONSPIR cognitive framework
(Lewandowsky and Cook, 2020). ConspirED is the first dataset of conspiratorial
content annotated for general cognitive traits. Using ConspirED, we (i) develop
computational models that identify conspiratorial traits and determine dominant
traits in text excerpts, and (ii) evaluate large language/reasoning model
(LLM/LRM) robustness to conspiratorial inputs. We find that both are misaligned
by conspiratorial content, producing output that mirrors input reasoning
patterns, even when successfully deflecting comparable fact-checked
misinformation.

</details>


### [18] [Languages Still Left Behind: Toward a Better Multilingual Machine Translation Benchmark](https://arxiv.org/abs/2508.20511)
*Chihiro Taguchi,Seng Mai,Keita Kurabe,Yusuke Sakai,Georgina Agyei,Soudabeh Eslami,David Chiang*

Main category: cs.CL

TL;DR: 研究发现FLORES+基准在多语言评估中存在不足，建议使用更通用和文化中立的源文本。


<details>
  <summary>Details</summary>
Motivation: FLORES+基准被广泛用于评估现代MT系统的性能，但我们发现它在多语言评估中存在关键缺陷。

Method: 我们研究了四种语言（阿散蒂语、日语、金巴语和南阿塞拜疆语）的数据，揭示了FLORES+基准在真正多语言评估中的不足之处。我们进行了人工评估，并展示了简单的启发式方法可以产生非微不足道的BLEU分数，这表明评估协议存在漏洞。

Result: 人工评估显示许多翻译低于声称的90%质量标准，注释者报告称源句子往往过于特定于某个领域且文化上偏向英语世界。此外，我们展示了在高质量、自然数据上训练的MT模型在FLORES+上表现不佳，但在我们的领域相关评估集上取得了显著提升。

Conclusion: 我们建议使用领域通用和文化中立的源文本，并减少对专有名词的依赖，以更好地反映现实世界的翻译挑战。

Abstract: Multilingual machine translation (MT) benchmarks play a central role in
evaluating the capabilities of modern MT systems. Among them, the FLORES+
benchmark is widely used, offering English-to-many translation data for over
200 languages, curated with strict quality control protocols. However, we study
data in four languages (Asante Twi, Japanese, Jinghpaw, and South Azerbaijani)
and uncover critical shortcomings in the benchmark's suitability for truly
multilingual evaluation. Human assessments reveal that many translations fall
below the claimed 90% quality standard, and the annotators report that source
sentences are often too domain-specific and culturally biased toward the
English-speaking world. We further demonstrate that simple heuristics, such as
copying named entities, can yield non-trivial BLEU scores, suggesting
vulnerabilities in the evaluation protocol. Notably, we show that MT models
trained on high-quality, naturalistic data perform poorly on FLORES+ while
achieving significant gains on our domain-relevant evaluation set. Based on
these findings, we advocate for multilingual MT benchmarks that use
domain-general and culturally neutral source texts rely less on named entities,
in order to better reflect real-world translation challenges.

</details>


### [19] [SciTopic: Enhancing Topic Discovery in Scientific Literature through Advanced LLM](https://arxiv.org/abs/2508.20514)
*Pengjiang Li,Zaitian Wang,Xinhao Zhang,Ran Zhang,Lu Jiang,Pengfei Wang,Yuanchun Zhou*

Main category: cs.CL

TL;DR: This paper introduces SciTopic, a new method for discovering research topics in scientific literature using large language models. It outperforms existing methods, providing deeper and faster insights for researchers.


<details>
  <summary>Details</summary>
Motivation: Existing topic discovery methods rely on word embedding to capture semantics and lack a comprehensive understanding of scientific publications, struggling with complex, high-dimensional text relationships. Large language models (LLMs) have exceptional comprehension of textual information, which inspired the development of SciTopic.

Method: We propose an advanced topic discovery method enhanced by large language models (LLMs), namely SciTopic. This involves building a textual encoder, constructing a space optimization module with entropy-based sampling and triplet tasks guided by LLMs, and fine-tuning the textual encoder based on the guidance from LLMs by optimizing the contrastive loss of the triplets.

Result: Extensive experiments on three real-world datasets of scientific publications demonstrate that SciTopic outperforms SOTA methods for scientific topic discovery.

Conclusion: SciTopic outperforms the state-of-the-art (SOTA) scientific topic discovery methods, enabling researchers to gain deeper and faster insights.

Abstract: Topic discovery in scientific literature provides valuable insights for
researchers to identify emerging trends and explore new avenues for
investigation, facilitating easier scientific information retrieval. Many
machine learning methods, particularly deep embedding techniques, have been
applied to discover research topics. However, most existing topic discovery
methods rely on word embedding to capture the semantics and lack a
comprehensive understanding of scientific publications, struggling with
complex, high-dimensional text relationships. Inspired by the exceptional
comprehension of textual information by large language models (LLMs), we
propose an advanced topic discovery method enhanced by LLMs to improve
scientific topic identification, namely SciTopic. Specifically, we first build
a textual encoder to capture the content from scientific publications,
including metadata, title, and abstract. Next, we construct a space
optimization module that integrates entropy-based sampling and triplet tasks
guided by LLMs, enhancing the focus on thematic relevance and contextual
intricacies between ambiguous instances. Then, we propose to fine-tune the
textual encoder based on the guidance from the LLMs by optimizing the
contrastive loss of the triplets, forcing the text encoder to better
discriminate instances of different topics. Finally, extensive experiments
conducted on three real-world datasets of scientific publications demonstrate
that SciTopic outperforms the state-of-the-art (SOTA) scientific topic
discovery methods, enabling researchers to gain deeper and faster insights.

</details>


### [20] [Overview of BioASQ 2024: The twelfth BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20532)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Salvador Lima-López,Eulàlia Farré-Maduell,Martin Krallinger,Natalia Loukachevitch,Vera Davydova,Elena Tutubalina,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ 2024 featured new and established tasks with significant participation, highlighting advancements in biomedical NER and QA.


<details>
  <summary>Details</summary>
Motivation: To promote advances in large-scale biomedical semantic indexing and question answering through international challenges.

Method: The paper provides an overview of the twelfth edition of the BioASQ challenge, including the tasks and participation details.

Result: 37 teams participated with over 700 submissions across four shared tasks, showing competitive performance and indicating progress in the field.

Conclusion: BioASQ 2024 demonstrated continuous advancement in the state-of-the-art in biomedical semantic indexing and question answering, with many competing teams achieving competitive performance.

Abstract: This is an overview of the twelfth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2024. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks b and Synergy, and two
new tasks: a) MultiCardioNER on the adaptation of clinical entity detection to
the cardiology domain in a multilingual setting, and b) BIONNE on nested NER in
Russian and English. In this edition of BioASQ, 37 competing teams participated
with more than 700 distinct submissions in total for the four different shared
tasks of the challenge. Similarly to previous editions, most of the
participating systems achieved competitive performance, suggesting the
continuous advancement of the state-of-the-art in the field.

</details>


### [21] [Overview of BioASQ 2025: The Thirteenth BioASQ Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20554)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Martin Krallinger,Miguel Rodríguez-Ortega,Eduard Rodriguez-López,Natalia Loukachevitch,Andrey Sakhovskiy,Elena Tutubalina,Dimitris Dimitriadis,Grigorios Tsoumakas,George Giannakoulas,Alexandra Bekiaridou,Athanasios Samaras,Giorgio Maria Di Nunzio,Nicola Ferro,Stefano Marchesin,Marco Martinelli,Gianmaria Silvello,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ 2025是生物医学语义索引和问答领域的重要挑战，包含六个任务，吸引了大量参赛队伍并取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: BioASQ旨在推动大规模生物医学语义索引和问答领域的进展，并通过新的任务扩展研究范围。

Method: BioASQ 2025包括了两个现有任务和四个新任务，涉及多语言临床摘要、嵌套命名实体链接、临床编码和肠道-大脑相互作用信息提取。

Result: 共有83支参赛队伍，提交了超过1000份不同的解决方案，多个系统表现出色，表明该领域技术的持续进步。

Conclusion: BioASQ 2025展示了生物医学语义索引和问答领域的持续进步，多个参与系统表现出色。

Abstract: This is an overview of the thirteenth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2025. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks, b and Synergy, and four
new tasks: a) Task MultiClinSum on multilingual clinical summarization. b) Task
BioNNE-L on nested named entity linking in Russian and English. c) Task
ELCardioCC on clinical coding in cardiology. d) Task GutBrainIE on gut-brain
interplay information extraction. In this edition of BioASQ, 83 competing teams
participated with more than 1000 distinct submissions in total for the six
different shared tasks of the challenge. Similar to previous editions, several
participating systems achieved competitive performance, indicating the
continuous advancement of the state-of-the-art in the field.

</details>


### [22] [Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data](https://arxiv.org/abs/2508.20557)
*Jiahao Xiao,Jiangming Liu*

Main category: cs.CL

TL;DR: 本文提出了一种自适应联邦蒸馏框架（AdaFD），用于解决多领域非独立同分布（non-IID）挑战，并引入了一个统一的基准框架来评估联邦学习在真实环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的实验non-IID场景主要基于标签（输出）多样性，而没有考虑自然语言处理中至关重要的语言领域（输入）多样性。因此，需要一个更全面的基准框架来评估联邦学习框架在真实环境中的表现。

Method: 本文引入了一套全面的多领域非独立同分布（non-IID）场景，并提出了一个统一的基准框架，该框架包括多样化的数据。此外，还提出了自适应联邦蒸馏（AdaFD）框架来解决同构和异构设置中的多领域non-IID挑战。

Result: 实验结果表明，我们的模型能够捕捉本地客户的多样性，并且在性能上优于现有工作。

Conclusion: 本文提出的AdaFD框架能够捕捉本地客户的多样性，并且在现有工作中表现更好。

Abstract: The widespread success of pre-trained language models has established a new
training paradigm, where a global PLM is fine-tuned using task-specific data
from local clients. The local data are highly different from each other and can
not capture the global distribution of the whole data in real world. To address
the challenges of non-IID data in real environments, privacy-preserving
federated distillation has been proposed and highly investigated. However,
previous experimental non-IID scenarios are primarily identified with the label
(output) diversity, without considering the diversity of language domains
(input) that is crucial in natural language processing. In this paper, we
introduce a comprehensive set of multi-domain non-IID scenarios and propose a
unified benchmarking framework that includes diverse data. The benchmark can be
used to evaluate the federated learning framework in a real environment. To
this end, we propose an Adaptive Federated Distillation (AdaFD) framework
designed to address multi-domain non-IID challenges in both homogeneous and
heterogeneous settings. Experimental results demonstrate that our models
capture the diversity of local clients and achieve better performance compared
to the existing works. The code for this paper is available at:
https://github.com/jiahaoxiao1228/AdaFD.

</details>


### [23] [Leveraging Generative Models for Real-Time Query-Driven Text Summarization in Large-Scale Web Search](https://arxiv.org/abs/2508.20559)
*Zeyu Xiong,Yixuan Nan,Li Gao,Hengzhu Tang,Shuaiqiang Wang,Junfeng Wang,Dawei Yin*

Main category: cs.CL

TL;DR: 本文提出了一种新的框架，利用生成模型解决工业网络搜索中的实时QDTS问题。该方法结合了大型模型蒸馏、监督微调、直接偏好优化和前瞻解码，将一个轻量级模型转化为领域专业化的QDTS专家。实验结果表明，该模型在多个行业相关指标上优于现有基线，并具有出色的部署效率。


<details>
  <summary>Details</summary>
Motivation: 传统提取摘要模型在工业应用中占主导地位，但它们存在两个关键限制：1) 多阶段流水线由于最弱组件而经常引入累积信息丢失和架构瓶颈；2) 传统模型对用户查询和文档的语义理解不足，特别是在处理复杂搜索意图时。因此，需要一种新的方法来解决这些问题。

Method: 我们提出了一个新颖的框架，将生成模型应用于工业网络搜索中的实时QDTS。我们的方法结合了大型模型蒸馏、监督微调、直接偏好优化和前瞻解码，将一个只有0.1B参数的轻量级模型转化为领域专业化的QDTS专家。

Result: 我们的模型在多个行业相关的指标上优于生产基线，并达到了新的最先进水平。此外，它展示了出色的部署效率，仅需334块NVIDIA L20 GPU即可在每查询平均延迟55~ms的情况下处理约50,000个查询/秒。

Conclusion: 我们的模型在多个行业相关的指标上优于生产基线，并达到了新的最先进水平。此外，它展示了出色的部署效率，仅需334块NVIDIA L20 GPU即可在每查询平均延迟55~ms的情况下处理约50,000个查询/秒。

Abstract: In the dynamic landscape of large-scale web search, Query-Driven Text
Summarization (QDTS) aims to generate concise and informative summaries from
textual documents based on a given query, which is essential for improving user
engagement and facilitating rapid decision-making. Traditional extractive
summarization models, based primarily on ranking candidate summary segments,
have been the dominant approach in industrial applications. However, these
approaches suffer from two key limitations: 1) The multi-stage pipeline often
introduces cumulative information loss and architectural bottlenecks due to its
weakest component; 2) Traditional models lack sufficient semantic understanding
of both user queries and documents, particularly when dealing with complex
search intents. In this study, we propose a novel framework to pioneer the
application of generative models to address real-time QDTS in industrial web
search. Our approach integrates large model distillation, supervised
fine-tuning, direct preference optimization, and lookahead decoding to
transform a lightweight model with only 0.1B parameters into a
domain-specialized QDTS expert. Evaluated on multiple industry-relevant
metrics, our model outperforms the production baseline and achieves a new state
of the art. Furthermore, it demonstrates excellent deployment efficiency,
requiring only 334 NVIDIA L20 GPUs to handle \textasciitilde50,000 queries per
second under 55~ms average latency per query.

</details>


### [24] [KCS: Diversify Multi-hop Question Generation with Knowledge Composition Sampling](https://arxiv.org/abs/2508.20567)
*Yangfan Wang,Jie Liu,Chen Tang,Lian Yan,Jingchi Jiang*

Main category: cs.CL

TL;DR: This paper introduces KCS, a framework that enhances multi-hop question generation by sampling varied knowledge compositions within a given context, improving accuracy and diversity.


<details>
  <summary>Details</summary>
Motivation: Multi-hop question answering faces challenges due to data sparsity, which increases the likelihood of language models learning spurious patterns. Prior research has focused on diversifying question generation but often neglects the integration of essential knowledge.

Method: KCS models the knowledge composition selection as a sentence-level conditional prediction task and utilizes a probabilistic contrastive loss to predict the next most relevant piece of knowledge. During inference, a stochastic decoding strategy is employed to balance accuracy and diversity.

Result: KCS improves the overall accuracy of knowledge composition selection by 3.9%, and its application for data augmentation yields improvements on HotpotQA and 2WikiMultihopQA datasets.

Conclusion: KCS improves the overall accuracy of knowledge composition selection by 3.9% and yields improvements on HotpotQA and 2WikiMultihopQA datasets.

Abstract: Multi-hop question answering faces substantial challenges due to data
sparsity, which increases the likelihood of language models learning spurious
patterns. To address this issue, prior research has focused on diversifying
question generation through content planning and varied expression. However,
these approaches often emphasize generating simple questions and neglect the
integration of essential knowledge, such as relevant sentences within
documents. This paper introduces the Knowledge Composition Sampling (KCS), an
innovative framework designed to expand the diversity of generated multi-hop
questions by sampling varied knowledge compositions within a given context. KCS
models the knowledge composition selection as a sentence-level conditional
prediction task and utilizes a probabilistic contrastive loss to predict the
next most relevant piece of knowledge. During inference, we employ a stochastic
decoding strategy to effectively balance accuracy and diversity. Compared to
competitive baselines, our KCS improves the overall accuracy of knowledge
composition selection by 3.9%, and its application for data augmentation yields
improvements on HotpotQA and 2WikiMultihopQA datasets. Our code is available
at: https://github.com/yangfanww/kcs.

</details>


### [25] [A Graph Talks, But Who's Listening? Rethinking Evaluations for Graph-Language Models](https://arxiv.org/abs/2508.20583)
*Soham Petkar,Hari Aakash K,Anirudh Vempati,Akshit Sinha,Ponnurangam Kumarauguru,Chirag Agarwal*

Main category: cs.CL

TL;DR: 现有GLM评估基准不足以评估多模态推理，CLEGR基准测试显示GLM在结构推理任务中表现不佳，表明需要改进图语言集成方法。


<details>
  <summary>Details</summary>
Motivation: 现有的GLM评估基准不足以评估多模态推理能力，因为它们主要基于节点级分类数据集，无法真正检验图语言集成的效果。

Method: 引入CLEGR基准测试，设计合成图生成流程，并结合需要结构和文本语义联合推理的问题进行评估。

Result: 软提示LLM基线的表现与包含完整GNN主干的GLM相当，GLM在需要结构推理的任务中表现显著下降。

Conclusion: 当前GLM在图推理能力上存在局限性，需要进一步研究将图结构和语言结合的多模态推理。

Abstract: Developments in Graph-Language Models (GLMs) aim to integrate the structural
reasoning capabilities of Graph Neural Networks (GNNs) with the semantic
understanding of Large Language Models (LLMs). However, we demonstrate that
current evaluation benchmarks for GLMs, which are primarily repurposed
node-level classification datasets, are insufficient to assess multimodal
reasoning. Our analysis reveals that strong performance on these benchmarks is
achievable using unimodal information alone, suggesting that they do not
necessitate graph-language integration. To address this evaluation gap, we
introduce the CLEGR(Compositional Language-Graph Reasoning) benchmark, designed
to evaluate multimodal reasoning at various complexity levels. Our benchmark
employs a synthetic graph generation pipeline paired with questions that
require joint reasoning over structure and textual semantics. We perform a
thorough evaluation of representative GLM architectures and find that
soft-prompted LLM baselines perform on par with GLMs that incorporate a full
GNN backbone. This result calls into question the architectural necessity of
incorporating graph structure into LLMs. We further show that GLMs exhibit
significant performance degradation in tasks that require structural reasoning.
These findings highlight limitations in the graph reasoning capabilities of
current GLMs and provide a foundation for advancing the community toward
explicit multimodal reasoning involving graph structure and language.

</details>


### [26] [Generative Annotation for ASR Named Entity Correction](https://arxiv.org/abs/2508.20700)
*Yuanchang Luo,Daimeng Wei,Shaojun Li,Hengchao Shang,Jiaxin Guo,Zongyao Li,Zhanglin Wu,Xiaoyu Chen,Zhiqiang Rao,Jinlong Yang,Hao Yang*

Main category: cs.CL

TL;DR: 本文提出了一种新的命名实体纠正方法，利用语音声音特征来检索候选实体，并通过生成方法标注和替换错误的实体，有效提高了实体准确性。


<details>
  <summary>Details</summary>
Motivation: 端到端自动语音识别系统在转录领域特定的命名实体时常常失败，导致下游任务出现灾难性故障。虽然已经提出了许多快速轻量的命名实体纠正（NEC）模型，但这些模型在错误转录词和真实实体形式差异较大时往往无法定位错误词，限制了其使用。

Method: 我们提出了一种新的NEC方法，利用语音声音特征来检索候选实体，并创新性地设计了一种生成方法来标注ASR转录中的实体错误，并用正确的实体替换文本。

Result: 我们在开源和自建的测试集上测试了我们的方法。结果表明，我们的NEC方法可以显著提高实体准确性。

Conclusion: 我们的NEC方法在实体准确性方面带来了显著的提升，并且在词形差异的场景中表现有效。我们将会开源自建的测试集和训练数据。

Abstract: End-to-end automatic speech recognition systems often fail to transcribe
domain-specific named entities, causing catastrophic failures in downstream
tasks. Numerous fast and lightweight named entity correction (NEC) models have
been proposed in recent years. These models, mainly leveraging phonetic-level
edit distance algorithms, have shown impressive performances. However, when the
forms of the wrongly-transcribed words(s) and the ground-truth entity are
significantly different, these methods often fail to locate the wrongly
transcribed words in hypothesis, thus limiting their usage. We propose a novel
NEC method that utilizes speech sound features to retrieve candidate entities.
With speech sound features and candidate entities, we inovatively design a
generative method to annotate entity errors in ASR transcripts and replace the
text with correct entities. This method is effective in scenarios of word form
difference. We test our method using open-source and self-constructed test
sets. The results demonstrate that our NEC method can bring significant
improvement to entity accuracy. We will open source our self-constructed test
set and training data.

</details>


### [27] [Multi-Lingual Implicit Discourse Relation Recognition with Multi-Label Hierarchical Learning](https://arxiv.org/abs/2508.20712)
*Nelson Filipe Costa,Leila Kosseim*

Main category: cs.CL

TL;DR: 本文提出了一种多语言和多标签的隐式话语关系识别模型HArch，并在多个语料库上进行了评估，结果显示该模型在性能上优于其他大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 本文旨在开发一种能够处理多语言和多标签的隐式话语关系识别模型，并通过实验验证其有效性。

Method: 本文引入了第一个多语言和多标签分类模型用于隐式话语关系识别（IDRR）。我们的模型HArch在最近发布的DiscoGeM 2.0语料库上进行了评估，并利用话语意义之间的层次依赖关系，在PDTB 3.0框架下的所有三个意义层次上预测概率分布。

Result: 我们的模型HArch在DiscoGeM 2.0语料库上进行了评估，并利用话语意义之间的层次依赖关系，在PDTB 3.0框架下的所有三个意义层次上预测概率分布。我们比较了几种预训练编码器骨干网络，并发现RoBERTa-HArch在英语中表现最佳，而XLM-RoBERTa-HArch在多语言设置中表现最佳。此外，我们还比较了微调模型与GPT-4o和Llama-4-Maverick在所有语言配置下的少样本提示效果。结果表明，我们的微调模型始终优于这些LLMs，突显了任务特定微调相对于提示的优势。

Conclusion: 我们的模型在DiscoGeM 1.0语料库上报告了SOTA结果，进一步验证了我们分层方法的有效性。

Abstract: This paper introduces the first multi-lingual and multi-label classification
model for implicit discourse relation recognition (IDRR). Our model, HArch, is
evaluated on the recently released DiscoGeM 2.0 corpus and leverages
hierarchical dependencies between discourse senses to predict probability
distributions across all three sense levels in the PDTB 3.0 framework. We
compare several pre-trained encoder backbones and find that RoBERTa-HArch
achieves the best performance in English, while XLM-RoBERTa-HArch performs best
in the multi-lingual setting. In addition, we compare our fine-tuned models
against GPT-4o and Llama-4-Maverick using few-shot prompting across all
language configurations. Our results show that our fine-tuned models
consistently outperform these LLMs, highlighting the advantages of
task-specific fine-tuning over prompting in IDRR. Finally, we report SOTA
results on the DiscoGeM 1.0 corpus, further validating the effectiveness of our
hierarchical approach.

</details>


### [28] [Addressing Tokenization Inconsistency in Steganography and Watermarking Based on Large Language Models](https://arxiv.org/abs/2508.20718)
*Ruiyi Yan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 本文研究了文本隐写和水印中的tokenization inconsistency问题，并提出了两种解决方法，实验结果表明这些方法能有效提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决文本隐写和水印中的tokenization inconsistency (TI)问题，以提高系统的鲁棒性和安全性。

Method: 研究分析了TI问题的两个关键特征，并提出了两种解决方法：逐步验证方法和事后回滚方法。

Result: 实验结果显示，直接处理TI可以提高文本生成的流畅性、隐蔽性和抗隐写分析能力；对于水印，处理TI可以增强检测能力和抗攻击能力。

Conclusion: 研究提出了解决TI问题的两种方法，实验结果表明这些方法在文本生成和水印技术中都有显著提升。

Abstract: Large language models have significantly enhanced the capacities and
efficiency of text generation. On the one hand, they have improved the quality
of text-based steganography. On the other hand, they have also underscored the
importance of watermarking as a safeguard against malicious misuse. In this
study, we focus on tokenization inconsistency (TI) between Alice and Bob in
steganography and watermarking, where TI can undermine robustness. Our
investigation reveals that the problematic tokens responsible for TI exhibit
two key characteristics: infrequency and temporariness. Based on these
findings, we propose two tailored solutions for TI elimination: a stepwise
verification method for steganography and a post-hoc rollback method for
watermarking. Experiments show that (1) compared to traditional disambiguation
methods in steganography, directly addressing TI leads to improvements in
fluency, imperceptibility, and anti-steganalysis capacity; (2) for
watermarking, addressing TI enhances detectability and robustness against
attacks.

</details>


### [29] [rStar2-Agent: Agentic Reasoning Technical Report](https://arxiv.org/abs/2508.20722)
*Ning Shang,Yifei Liu,Yi Zhu,Li Lyna Zhang,Weijiang Xu,Xinyu Guan,Buze Zhang,Bingcheng Dong,Xudong Zhou,Bowen Zhang,Ying Xin,Ziming Miao,Scarlett Li,Fan Yang,Mao Yang*

Main category: cs.CL

TL;DR: rStar2-Agent 是一个14B数学推理模型，通过代理强化学习实现前沿性能，在多个任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前的长CoT方法存在局限性，需要一种更高效的数学推理模型来解决复杂问题，并提高模型在代码环境中的推理能力。

Method: rStar2-Agent 通过三种关键创新使代理强化学习在大规模上有效：(i) 高效的RL基础设施，支持高吞吐量执行；(ii) GRPO-RoC代理RL算法，具有Resample-on-Correct rollout策略；(iii) 高效的代理训练配方，从非推理SFT开始，逐步进入多RL阶段。

Result: rStar2-Agent 在AIME24和AIME25数据集上分别达到了80.6%和69.8%的平均pass@1分数，超越了DeepSeek-R1（671B），并且在数学、对齐、科学推理和代理工具使用任务中表现出色。

Conclusion: rStar2-Agent 是一个经过代理强化学习训练的14B数学推理模型，实现了前沿水平的性能。它在数学、对齐、科学推理和代理工具使用任务中表现出色。

Abstract: We introduce rStar2-Agent, a 14B math reasoning model trained with agentic
reinforcement learning to achieve frontier-level performance. Beyond current
long CoT, the model demonstrates advanced cognitive behaviors, such as thinking
carefully before using Python coding tools and reflecting on code execution
feedback to autonomously explore, verify, and refine intermediate steps in
complex problem-solving. This capability is enabled through three key
innovations that makes agentic RL effective at scale: (i) an efficient RL
infrastructure with a reliable Python code environment that supports
high-throughput execution and mitigates the high rollout costs, enabling
training on limited GPU resources (64 MI300X GPUs); (ii) GRPO-RoC, an agentic
RL algorithm with a Resample-on-Correct rollout strategy that addresses the
inherent environment noises from coding tools, allowing the model to reason
more effectively in a code environment; (iii) An efficient agent training
recipe that starts with non-reasoning SFT and progresses through multi-RL
stages, yielding advanced cognitive abilities with minimal compute cost. To
this end, rStar2-Agent boosts a pre-trained 14B model to state of the art in
only 510 RL steps within one week, achieving average pass@1 scores of 80.6% on
AIME24 and 69.8% on AIME25, surpassing DeepSeek-R1 (671B) with significantly
shorter responses. Beyond mathematics, rStar2-Agent-14B also demonstrates
strong generalization to alignment, scientific reasoning, and agentic tool-use
tasks. Code and training recipes are available at
https://github.com/microsoft/rStar.

</details>


### [30] [Leveraging Semantic Triples for Private Document Generation with Local Differential Privacy Guarantees](https://arxiv.org/abs/2508.20736)
*Stephen Meisenbacher,Maulik Chevli,Florian Matthes*

Main category: cs.CL

TL;DR: 本文提出了一种名为DP-ST的方法，利用语义三元组进行局部差分隐私保证下的邻域感知私有文档生成。通过评估，展示了分解和征服范式的有效性，并在较低的ε值下实现了连贯的文本生成，同时保持隐私和效用的平衡。


<details>
  <summary>Details</summary>
Motivation: 许多工作在差分隐私（DP）和自然语言处理的交叉领域旨在通过在DP保证下转换文本来保护隐私。然而，这种保证非常严格，最近的研究表明，在局部DP下对文本进行隐私化只能在非常高的ε值下合理完成。

Method: DP-ST，它利用语义三元组进行局部差分隐私保证下的邻域感知私有文档生成。

Result: 通过评估我们的方法，我们展示了分解和征服范式的有效性，特别是在将DP概念（以及隐私保证）限制为隐私化邻域时。当与LLM后处理结合时，我们的方法允许在较低的ε值下生成连贯的文本，同时平衡隐私和效用。

Conclusion: 这些发现强调了在合理的ε水平下实现平衡的隐私化输出中连贯性的重要性。

Abstract: Many works at the intersection of Differential Privacy (DP) in Natural
Language Processing aim to protect privacy by transforming texts under DP
guarantees. This can be performed in a variety of ways, from word perturbations
to full document rewriting, and most often under local DP. Here, an input text
must be made indistinguishable from any other potential text, within some bound
governed by the privacy parameter $\varepsilon$. Such a guarantee is quite
demanding, and recent works show that privatizing texts under local DP can only
be done reasonably under very high $\varepsilon$ values. Addressing this
challenge, we introduce DP-ST, which leverages semantic triples for
neighborhood-aware private document generation under local DP guarantees.
Through the evaluation of our method, we demonstrate the effectiveness of the
divide-and-conquer paradigm, particularly when limiting the DP notion (and
privacy guarantees) to that of a privatization neighborhood. When combined with
LLM post-processing, our method allows for coherent text generation even at
lower $\varepsilon$ values, while still balancing privacy and utility. These
findings highlight the importance of coherence in achieving balanced
privatization outputs at reasonable $\varepsilon$ levels.

</details>


### [31] [Specializing General-purpose LLM Embeddings for Implicit Hate Speech Detection across Datasets](https://arxiv.org/abs/2508.20750)
*Vassiliy Cheremetiev,Quang Long Ho Ngo,Chau Ying Kot,Alina Elena Baia,Andrea Cavallaro*

Main category: cs.CL

TL;DR: 该论文通过微调基于大语言模型的通用嵌入模型，显著提升了隐性仇恨言论检测的性能。


<details>
  <summary>Details</summary>
Motivation: 隐性仇恨言论难以检测，因为它不包含明确的贬低或煽动性词语，因此需要借助外部知识或额外信息。

Method: 通过微调基于大语言模型的通用嵌入模型来检测隐性仇恨言论。

Result: 在多个IHS数据集上的实验表明，微调模型在F1宏得分上实现了高达1.10个百分点的提升，在跨数据集评估中实现了高达20.35个百分点的提升。

Conclusion: 通过微调基于大语言模型的通用嵌入模型，如Stella、Jasper、NV-Embed和E5，该论文实现了最先进的性能。

Abstract: Implicit hate speech (IHS) is indirect language that conveys prejudice or
hatred through subtle cues, sarcasm or coded terminology. IHS is challenging to
detect as it does not include explicit derogatory or inflammatory words. To
address this challenge, task-specific pipelines can be complemented with
external knowledge or additional information such as context, emotions and
sentiment data. In this paper, we show that, by solely fine-tuning recent
general-purpose embedding models based on large language models (LLMs), such as
Stella, Jasper, NV-Embed and E5, we achieve state-of-the-art performance.
Experiments on multiple IHS datasets show up to 1.10 percentage points
improvements for in-dataset, and up to 20.35 percentage points improvements in
cross-dataset evaluation, in terms of F1-macro score.

</details>


### [32] [GUARD: Glocal Uncertainty-Aware Robust Decoding for Effective and Efficient Open-Ended Text Generation](https://arxiv.org/abs/2508.20757)
*Yuanhao Ding,Esteban Garces Arias,Meimingwei Li,Julian Rodemann,Matthias Aßenmacher,Danlu Chen,Gaojuan Fan,Christian Heumann,Chongsheng Zhang*

Main category: cs.CL

TL;DR: GUARD is a self-adaptive decoding method that balances text diversity and coherence by integrating global and local uncertainty signals, achieving improved generation speed and performance.


<details>
  <summary>Details</summary>
Motivation: Open-ended text generation faces a critical challenge: balancing coherence with diversity in LLM outputs. Contrastive search-based decoding strategies have limitations due to hyperparameter dependence and high computational costs.

Method: GUARD is a self-adaptive decoding method that uses a novel 'Glocal' uncertainty-driven framework, combining global entropy estimates with local entropy deviations. It incorporates a token-count-based penalty to reduce computational overhead.

Result: GUARD effectively mitigates abrupt variations in uncertainty and provides theoretical guarantees of unbiasedness and consistency. It achieves a good balance between text diversity and coherence, with substantial improvements in generation speed.

Conclusion: GUARD achieves a good balance between text diversity and coherence, while exhibiting substantial improvements in generation speed. Both human and LLM evaluators validated its remarkable performance.

Abstract: Open-ended text generation faces a critical challenge: balancing coherence
with diversity in LLM outputs. While contrastive search-based decoding
strategies have emerged to address this trade-off, their practical utility is
often limited by hyperparameter dependence and high computational costs. We
introduce GUARD, a self-adaptive decoding method that effectively balances
these competing objectives through a novel "Glocal" uncertainty-driven
framework. GUARD combines global entropy estimates with local entropy
deviations to integrate both long-term and short-term uncertainty signals. We
demonstrate that our proposed global entropy formulation effectively mitigates
abrupt variations in uncertainty, such as sudden overconfidence or high entropy
spikes, and provides theoretical guarantees of unbiasedness and consistency. To
reduce computational overhead, we incorporate a simple yet effective
token-count-based penalty into GUARD. Experimental results demonstrate that
GUARD achieves a good balance between text diversity and coherence, while
exhibiting substantial improvements in generation speed. In a more nuanced
comparison study across different dimensions of text quality, both human and
LLM evaluators validated its remarkable performance. Our code is available at
https://github.com/YecanLee/GUARD.

</details>


### [33] [Feel the Difference? A Comparative Analysis of Emotional Arcs in Real and LLM-Generated CBT Sessions](https://arxiv.org/abs/2508.20764)
*Xiaoyi Wang,Jiwei Zhang,Guangtao Zhang,Honglei Guo*

Main category: cs.CL

TL;DR: 本研究比较了真实和LLM生成的认知行为疗法对话中的情绪弧线，发现合成对话在情感属性上与真实对话存在差异，强调了情感真实性在心理健康应用中的重要性。


<details>
  <summary>Details</summary>
Motivation: 评估LLM生成的治疗对话是否能捕捉到真实治疗中的细微情感动态。

Method: 我们适应了Utterance Emotion Dynamics框架来分析情绪轨迹，比较了真实和LLM生成的认知行为疗法对话中的情绪弧线。

Result: 合成对话在关键情感属性上与真实对话存在差异：真实会话表现出更大的情感变化、更丰富的情感语言以及更真实的反应和调节模式。此外，真实和合成说话者之间的情绪弧线相似性较低，尤其是对于客户而言。

Conclusion: 这些发现强调了当前LLM生成的治疗数据的局限性，并突出了心理健康应用中情感真实性的重要性。我们引入了RealCBT，一个经过筛选的真实CBT会话数据集，以支持该领域的未来研究。

Abstract: Synthetic therapy dialogues generated by large language models (LLMs) are
increasingly used in mental health NLP to simulate counseling scenarios, train
models, and supplement limited real-world data. However, it remains unclear
whether these synthetic conversations capture the nuanced emotional dynamics of
real therapy. In this work, we conduct the first comparative analysis of
emotional arcs between real and LLM-generated Cognitive Behavioral Therapy
dialogues. We adapt the Utterance Emotion Dynamics framework to analyze
fine-grained affective trajectories across valence, arousal, and dominance
dimensions. Our analysis spans both full dialogues and individual speaker roles
(counselor and client), using real sessions transcribed from public videos and
synthetic dialogues from the CACTUS dataset. We find that while synthetic
dialogues are fluent and structurally coherent, they diverge from real
conversations in key emotional properties: real sessions exhibit greater
emotional variability,more emotion-laden language, and more authentic patterns
of reactivity and regulation. Moreover, emotional arc similarity between real
and synthetic speakers is low, especially for clients. These findings
underscore the limitations of current LLM-generated therapy data and highlight
the importance of emotional fidelity in mental health applications. We
introduce RealCBT, a curated dataset of real CBT sessions, to support future
research in this space.

</details>


### [34] [Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection](https://arxiv.org/abs/2508.20766)
*Harethah Abu Shairah,Hasan Abed Al Kader Hammoud,George Turkiyyah,Bernard Ghanem*

Main category: cs.CL

TL;DR: 本文提出了Rank-One Safety Injection (ROSI) 方法，通过永久地将模型的激活推向拒绝中介子空间来增强模型的安全对齐。ROSI作为一种简单的、无需微调的秩一权重修改，能够提高安全性拒绝率，同时保持模型在标准基准测试中的实用性。


<details>
  <summary>Details</summary>
Motivation: 安全对齐在大型语言模型（LLMs）中通常涉及调解内部表示以拒绝有害请求。最近的研究表明，这些安全机制可以通过消融或移除模型内的特定表示方向来绕过。本文提出相反的方法。

Method: 我们提出了Rank-One Safety Injection (ROSI)，这是一种白盒方法，通过永久地将模型的激活推向拒绝中介子空间来增强模型的安全对齐。ROSI作为一种简单的、无需微调的秩一权重修改应用于所有残差流写矩阵。

Result: ROSI一致地提高了安全性拒绝率（通过Llama Guard 3评估），同时保持了模型在标准基准测试（如MMLU、HellaSwag和Arc）上的实用性。此外，ROSI还可以通过放大其自身的潜在安全方向来重新对齐'未审查'模型，证明了其作为有效最后一公里安全程序的效用。

Conclusion: 我们的结果表明，有针对性的、可解释的权重引导是一种廉价而有效的机制，可以提高LLM的安全性，补充了更耗资源的微调范式。

Abstract: Safety alignment in Large Language Models (LLMs) often involves mediating
internal representations to refuse harmful requests. Recent research has
demonstrated that these safety mechanisms can be bypassed by ablating or
removing specific representational directions within the model. In this paper,
we propose the opposite approach: Rank-One Safety Injection (ROSI), a white-box
method that amplifies a model's safety alignment by permanently steering its
activations toward the refusal-mediating subspace. ROSI operates as a simple,
fine-tuning-free rank-one weight modification applied to all residual stream
write matrices. The required safety direction can be computed from a small set
of harmful and harmless instruction pairs. We show that ROSI consistently
increases safety refusal rates - as evaluated by Llama Guard 3 - while
preserving the utility of the model on standard benchmarks such as MMLU,
HellaSwag, and Arc. Furthermore, we show that ROSI can also re-align
'uncensored' models by amplifying their own latent safety directions,
demonstrating its utility as an effective last-mile safety procedure. Our
results suggest that targeted, interpretable weight steering is a cheap and
potent mechanism to improve LLM safety, complementing more resource-intensive
fine-tuning paradigms.

</details>


### [35] [Signs of Struggle: Spotting Cognitive Distortions across Language and Register](https://arxiv.org/abs/2508.20771)
*Abhishek Kuber,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah*

Main category: cs.CL

TL;DR: 本研究分析了跨语言和跨注册的认知扭曲检测，发现领域自适应方法在改善模型性能方面具有最大潜力。


<details>
  <summary>Details</summary>
Motivation: 青少年心理健康问题的增加促使人们关注自动化方法来检测数字文本中早期心理困扰的迹象。认知扭曲是加剧心理困扰的关键因素，因此早期检测可能有助于及时、低成本的干预。

Method: 本研究分析了由荷兰青少年撰写的论坛帖子，进行了跨语言和跨注册的一般化认知扭曲检测的深入研究。

Result: 研究发现，语言和写作风格的变化可能显著影响模型性能，但领域自适应方法显示出最大的潜力。

Conclusion: 研究发现，尽管语言和写作风格的变化可能显著影响模型性能，但领域自适应方法显示出最大的潜力。

Abstract: Rising mental health issues among youth have increased interest in automated
approaches for detecting early signs of psychological distress in digital text.
One key focus is the identification of cognitive distortions, irrational
thought patterns that have a role in aggravating mental distress. Early
detection of these distortions may enable timely, low-cost interventions. While
prior work has focused on English clinical data, we present the first in-depth
study of cross-lingual and cross-register generalization of cognitive
distortion detection, analyzing forum posts written by Dutch adolescents. Our
findings show that while changes in language and writing style can
significantly affect model performance, domain adaptation methods show the most
promise.

</details>


### [36] [Exploring Machine Learning and Language Models for Multimodal Depression Detection](https://arxiv.org/abs/2508.20805)
*Javier Si Zhao Hong,Timothy Zoe Delaya,Sherwyn Chan Yin Kit,Pai Chet Ng,Xiaoxiao Miao*

Main category: cs.CL

TL;DR: 本文比较了多种机器学习和深度学习模型在多模态抑郁检测中的表现，并分析了它们的优缺点。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索和比较不同机器学习和深度学习模型在多模态抑郁检测中的表现。

Method: 本文比较了XGBoost、基于Transformer的架构和大语言模型（LLMs）在音频、视频和文本特征上的性能。

Result: 本文的结果突出了每种模型在捕捉抑郁相关信号方面的优缺点。

Conclusion: 本文总结了不同模型在多模态抑郁检测中的优缺点，并提供了有效的多模态表示策略的见解。

Abstract: This paper presents our approach to the first Multimodal Personality-Aware
Depression Detection Challenge, focusing on multimodal depression detection
using machine learning and deep learning models. We explore and compare the
performance of XGBoost, transformer-based architectures, and large language
models (LLMs) on audio, video, and text features. Our results highlight the
strengths and limitations of each type of model in capturing depression-related
signals across modalities, offering insights into effective multimodal
representation strategies for mental health prediction.

</details>


### [37] [GDLLM: A Global Distance-aware Modeling Approach Based on Large Language Models for Event Temporal Relation Extraction](https://arxiv.org/abs/2508.20828)
*Jie Zhao,Wanting Ning,Yuxiao Fei,Yubo Feng,Lishuang Li*

Main category: cs.CL

TL;DR: 本文提出了GDLLM，一种基于LLMs的全局距离感知建模方法，通过距离感知图结构和基于软推理的时间特征学习范式，显著提高了少数关系类的性能，并在两个公开数据集上实现了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 先前的研究已经认识到语言模型在ETRE中的重要性。然而，小型语言模型（SLMs）的预训练知识有限，限制了它们处理不平衡分类数据集中少数类别关系的能力。对于大型语言模型（LLMs），研究人员采用手动设计的提示或指令，这可能会引入额外的噪声，导致干扰模型对事件之间长距离依赖关系的判断。

Method: 我们提出了GDLLM，一种基于LLMs的全局距离感知建模方法。首先，我们提出了一种利用图注意力网络（GAT）的距离感知图结构，以帮助LLMs捕捉长距离依赖特征。此外，我们设计了一个基于软推理的时间特征学习范式，以增强对短距离邻近带的关系识别，并将LLMs生成的概率信息整合到多头注意力机制中。

Result: 在两个公开可用的数据集TB-Dense和MATRES上的实验表明，我们的方法达到了最先进的性能（SOTA）。

Conclusion: 我们的框架显著提高了少数关系类的性能，并增强了整体学习能力。

Abstract: In Natural Language Processing(NLP), Event Temporal Relation Extraction
(ETRE) is to recognize the temporal relations of two events. Prior studies have
noted the importance of language models for ETRE. However, the restricted
pre-trained knowledge of Small Language Models(SLMs) limits their capability to
handle minority class relations in imbalanced classification datasets. For
Large Language Models(LLMs), researchers adopt manually designed prompts or
instructions, which may introduce extra noise, leading to interference with the
model's judgment of the long-distance dependencies between events. To address
these issues, we propose GDLLM, a Global Distance-aware modeling approach based
on LLMs. We first present a distance-aware graph structure utilizing Graph
Attention Network(GAT) to assist the LLMs in capturing long-distance dependency
features. Additionally, we design a temporal feature learning paradigm based on
soft inference to augment the identification of relations with a short-distance
proximity band, which supplements the probabilistic information generated by
LLMs into the multi-head attention mechanism. Since the global feature can be
captured effectively, our framework substantially enhances the performance of
minority relation classes and improves the overall learning ability.
Experiments on two publicly available datasets, TB-Dense and MATRES,
demonstrate that our approach achieves state-of-the-art (SOTA) performance.

</details>


### [38] [MSRS: Evaluating Multi-Source Retrieval-Augmented Generation](https://arxiv.org/abs/2508.20867)
*Rohan Phanse,Yijie Zhou,Kejian Shi,Wencai Zhang,Yixin Liu,Yilun Zhao,Arman Cohan*

Main category: cs.CL

TL;DR: 本文提出了一种可扩展的框架，用于构建评估基准，挑战RAG系统在不同来源之间整合信息并生成长文本响应的能力。通过该框架，我们构建了两个新的基准：MSRS-Story和MSRS-Meet，分别代表叙事综合和摘要任务。实验表明，生成质量高度依赖于检索效果，而多源合成在理想检索设置下仍然具有挑战性，但推理模型在此步骤上表现优于标准LLM。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统评估通常在信息可以从单个来源找到或答案是简短形式或事实性的情况下进行。然而，许多现实世界的应用需要能够整合和总结分散在多个来源的信息，其中没有一个来源足以回答用户的问题。

Method: 我们提出了一个可扩展的框架，用于构建评估基准，挑战RAG系统在不同来源之间整合信息并生成长文本响应的能力。基于该框架，我们构建了两个新的基准：MSRS-Story和MSRS-Meet，分别代表叙事综合和摘要任务，需要从大型集合中检索信息。

Result: 我们对各种RAG管道（包括稀疏和密集检索器结合前沿LLM）进行了广泛实验，结果表明生成质量高度依赖于检索效果，而检索效果因任务而异。尽管多源合成在理想检索设置下仍然具有挑战性，但推理模型在此步骤上显著优于标准LLM。

Conclusion: 我们的实验表明，生成质量高度依赖于检索效果，而检索效果因任务而异。虽然多源合成在理想检索设置下仍然具有挑战性，但我们发现推理模型在此步骤上显著优于标准LLM。

Abstract: Retrieval-augmented systems are typically evaluated in settings where
information required to answer the query can be found within a single source or
the answer is short-form or factoid-based. However, many real-world
applications demand the ability to integrate and summarize information
scattered across multiple sources, where no single source is sufficient to
respond to the user's question. In such settings, the retrieval component of a
RAG pipeline must recognize a variety of relevance signals, and the generation
component must connect and synthesize information across multiple sources. We
present a scalable framework for constructing evaluation benchmarks that
challenge RAG systems to integrate information across distinct sources and
generate long-form responses. Using our framework, we build two new benchmarks
on Multi-Source Retrieval and Synthesis: MSRS-Story and MSRS-Meet, representing
narrative synthesis and summarization tasks, respectively, that require
retrieval from large collections. Our extensive experiments with various RAG
pipelines -- including sparse and dense retrievers combined with frontier LLMs
-- reveal that generation quality is highly dependent on retrieval
effectiveness, which varies greatly by task. While multi-source synthesis
proves challenging even in an oracle retrieval setting, we find that reasoning
models significantly outperform standard LLMs at this distinct step.

</details>


### [39] [The Uneven Impact of Post-Training Quantization in Machine Translation](https://arxiv.org/abs/2508.20893)
*Benjamin Marie,Atsushi Fujita*

Main category: cs.CL

TL;DR: 本研究首次评估了在55种语言上的训练后量化对机器翻译的影响，发现4位量化在高资源语言和大模型中表现良好，但在低资源和语言类型多样化的情况下效果较差。GGUF变体在2位精度下表现最佳，同时发现语言匹配的校准在低比特情况下有帮助。


<details>
  <summary>Details</summary>
Motivation: 量化对于在资源受限的硬件上部署大型语言模型（LLMs）至关重要，但其对多语言任务的影响仍缺乏研究。

Method: 我们进行了首次大规模评估，使用五个从1.7B到70B参数的LLM，在55种语言上对训练后量化（PTQ）进行了评估。我们比较了四种量化技术（AWQ、BitsAndBytes、GGUF和AutoRound），并分析了量化、解码超参数和校准语言之间的相互作用。

Result: 4位量化通常能保持高资源语言和大型模型的翻译质量，但在低资源和语言类型多样化的语言中会出现显著退化，尤其是在2位设置中。GGUF变体在2位精度下也提供了最一致的性能。此外，我们量化了量化、解码超参数和校准语言之间的相互作用，发现语言匹配的校准主要在低比特情况下有益。

Conclusion: 我们的研究提供了在量化约束下部署多语言LLM进行机器翻译的可行见解，特别是在低资源设置中。

Abstract: Quantization is essential for deploying large language models (LLMs) on
resource-constrained hardware, but its implications for multilingual tasks
remain underexplored. We conduct the first large-scale evaluation of
post-training quantization (PTQ) on machine translation across 55 languages
using five LLMs ranging from 1.7B to 70B parameters. Our analysis reveals that
while 4-bit quantization often preserves translation quality for high-resource
languages and large models, significant degradation occurs for low-resource and
typologically diverse languages, particularly in 2-bit settings. We compare
four quantization techniques (AWQ, BitsAndBytes, GGUF, and AutoRound), showing
that algorithm choice and model size jointly determine robustness. GGUF
variants provide the most consistent performance, even at 2-bit precision.
Additionally, we quantify the interactions between quantization, decoding
hyperparameters, and calibration languages, finding that language-matched
calibration offers benefits primarily in low-bit scenarios. Our findings offer
actionable insights for deploying multilingual LLMs for machine translation
under quantization constraints, especially in low-resource settings.

</details>


### [40] [SageLM: A Multi-aspect and Explainable Large Language Model for Speech Judgement](https://arxiv.org/abs/2508.20916)
*Yuan Ge,Junxiang Zhang,Xiaoqian Liu,Bei Li,Xiangnan Ma,Chenglong Wang,Kaiyang Ye,Yangfan Du,Linfeng Zhang,Yuxin Huang,Tong Xiao,Zhengtao Yu,JingBo Zhu*

Main category: cs.CL

TL;DR: SageLM is an end-to-end, multi-aspect, and explainable speech LLM for comprehensive S2S LLMs evaluation, achieving high agreement with human evaluators.


<details>
  <summary>Details</summary>
Motivation: Evaluating Speech-to-Speech (S2S) Large Language Models (LLMs) remains a fundamental challenge, and existing approaches disregard acoustic features or lack explainability.

Method: SageLM jointly assesses both semantic and acoustic dimensions, leverages rationale-based supervision to enhance explainability, and introduces SpeechFeedback, a synthetic preference dataset, with a two-stage training paradigm.

Result: SageLM achieves an 82.79% agreement rate with human evaluators, outperforming cascaded and SLM-based baselines by at least 7.42% and 26.20%, respectively.

Conclusion: SageLM achieves an 82.79% agreement rate with human evaluators, outperforming cascaded and SLM-based baselines by at least 7.42% and 26.20%, respectively.

Abstract: Speech-to-Speech (S2S) Large Language Models (LLMs) are foundational to
natural human-computer interaction, enabling end-to-end spoken dialogue
systems. However, evaluating these models remains a fundamental challenge. We
propose \texttt{SageLM}, an end-to-end, multi-aspect, and explainable speech
LLM for comprehensive S2S LLMs evaluation. First, unlike cascaded approaches
that disregard acoustic features, SageLM jointly assesses both semantic and
acoustic dimensions. Second, it leverages rationale-based supervision to
enhance explainability and guide model learning, achieving superior alignment
with evaluation outcomes compared to rule-based reinforcement learning methods.
Third, we introduce \textit{SpeechFeedback}, a synthetic preference dataset,
and employ a two-stage training paradigm to mitigate the scarcity of speech
preference data. Trained on both semantic and acoustic dimensions, SageLM
achieves an 82.79\% agreement rate with human evaluators, outperforming
cascaded and SLM-based baselines by at least 7.42\% and 26.20\%, respectively.

</details>


### [41] [How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on $τ$-bench](https://arxiv.org/abs/2508.20931)
*Venkatesh Mishra,Amir Saeidi,Satyam Raj,Mutsumi Nakamura,Jayanth Srinivasa,Gaowen Liu,Ali Payani,Chitta Baral*

Main category: cs.CL

TL;DR: 本文提出了一种名为IRMA的框架，通过自动重写用户查询并结合相关领域规则和工具建议，提高了工具调用代理的性能，在动态环境中表现出更高的可靠性和一致性。


<details>
  <summary>Details</summary>
Motivation: 在多轮对话环境中，如τ-bench，这些代理常常在一致推理、遵守特定领域政策以及从长期的工具调用和对话中提取正确信息方面遇到困难。为了捕捉和缓解这些失败，我们对对话轨迹中的常见错误进行了全面的手动分析。

Method: 我们进行了输入重写多智能体（IRMA）框架的实验和提出，该框架自动重写用户查询，并结合相关领域规则和工具建议，以帮助工具调用代理专注于任务。

Result: 结果表明，IRMA在总体pass^5分数上分别比ReAct、Function Calling和Self-Reflection高出16.1%、12.7%和19.1%。

Conclusion: 这些发现突显了IRMA在动态环境中的优越可靠性和一致性。

Abstract: Recent advances in reasoning and planning capabilities of large language
models (LLMs) have enabled their potential as autonomous agents capable of tool
use in dynamic environments. However, in multi-turn conversational environments
like $\tau$-bench, these agents often struggle with consistent reasoning,
adherence to domain-specific policies, and extracting correct information over
a long horizon of tool-calls and conversation. To capture and mitigate these
failures, we conduct a comprehensive manual analysis of the common errors
occurring in the conversation trajectories. We then experiment with
reformulations of inputs to the tool-calling agent for improvement in agent
decision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA)
framework, which automatically reformulates user queries augmented with
relevant domain rules and tool suggestions for the tool-calling agent to focus
on. The results show that IRMA significantly outperforms ReAct, Function
Calling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in
overall pass^5 scores. These findings highlight the superior reliability and
consistency of IRMA compared to other methods in dynamic environments.

</details>


### [42] [STARE at the Structure: Steering ICL Exemplar Selection with Structural Alignment](https://arxiv.org/abs/2508.20944)
*Jiaqian Li,Qisheng Hu,Jing Li,Wenya Wang*

Main category: cs.CL

TL;DR: 本文提出了一种两阶段的示例选择策略，以提高结构预测任务中In-Context Learning的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的ICL选择策略在结构预测任务中常常忽略结构对齐，导致性能不佳和泛化能力差。

Method: 我们提出了一种两阶段的示例选择策略，首先使用结构感知监督微调基于BERT的检索器，然后通过一个插件模块增强检索器，以放大句法上有意义的信息。

Result: 实验表明，我们的方法在三个语义解析任务的四个基准测试中表现优于现有基线，并且可以无缝集成到现有流程中。

Conclusion: 我们的方法在多个基准测试中 consistently outperforms existing baselines，展示了其在结构预测任务中的有效性。

Abstract: In-Context Learning (ICL) has become a powerful paradigm that enables LLMs to
perform a wide range of tasks without task-specific fine-tuning. However, the
effectiveness of ICL heavily depends on the quality of exemplar selection. In
particular, for structured prediction tasks such as semantic parsing, existing
ICL selection strategies often overlook structural alignment, leading to
suboptimal performance and poor generalization. To address this issue, we
propose a novel two-stage exemplar selection strategy that achieves a strong
balance between efficiency, generalizability, and performance. First, we
fine-tune a BERT-based retriever using structure-aware supervision, guiding it
to select exemplars that are both semantically relevant and structurally
aligned. Then, we enhance the retriever with a plug-in module, which amplifies
syntactically meaningful information in the hidden representations. This
plug-in is model-agnostic, requires minimal overhead, and can be seamlessly
integrated into existing pipelines. Experiments on four benchmarks spanning
three semantic parsing tasks demonstrate that our method consistently
outperforms existing baselines with multiple recent LLMs as inference-time
models.

</details>


### [43] [ProactiveEval: A Unified Evaluation Framework for Proactive Dialogue Agents](https://arxiv.org/abs/2508.20973)
*Tianjian Liu,Fanqi Wan,Jiajian Guo,Xiaojun Quan*

Main category: cs.CL

TL;DR: 本文提出ProactiveEval框架，用于评估LLMs的主动对话能力，开发了328个评估环境，并展示了DeepSeek-R1和Claude-3.7-Sonnet的优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在特定领域或任务导向的场景中，导致评估碎片化，限制了对模型主动对话能力的全面探索。因此，需要一种统一的框架来评估LLMs的主动对话能力。

Method: 本文提出了ProactiveEval框架，将主动对话分解为目标规划和对话引导，并建立了跨多个领域的评估指标。此外，该框架还支持生成多样且具有挑战性的评估数据。基于此框架，开发了328个评估环境，并对22种不同类型的LLMs进行了实验。

Result: 实验表明，DeepSeek-R1和Claude-3.7-Sonnet分别在目标规划和对话引导任务中表现出色。此外，研究还揭示了推理能力对主动行为的影响，并讨论了其对未来模型发展的意义。

Conclusion: 本文提出了一种统一的框架ProactiveEval，用于评估大型语言模型（LLMs）的主动对话能力。基于该框架，我们开发了328个跨越6个不同领域的评估环境，并通过实验验证了DeepSeek-R1和Claude-3.7-Sonnet在目标规划和对话引导任务中的卓越表现。最后，我们研究了推理能力如何影响主动行为，并讨论了其对未来模型发展的意义。

Abstract: Proactive dialogue has emerged as a critical and challenging research problem
in advancing large language models (LLMs). Existing works predominantly focus
on domain-specific or task-oriented scenarios, which leads to fragmented
evaluations and limits the comprehensive exploration of models' proactive
conversation abilities. In this work, we propose ProactiveEval, a unified
framework designed for evaluating proactive dialogue capabilities of LLMs. This
framework decomposes proactive dialogue into target planning and dialogue
guidance, establishing evaluation metrics across various domains. Moreover, it
also enables the automatic generation of diverse and challenging evaluation
data. Based on the proposed framework, we develop 328 evaluation environments
spanning 6 distinct domains. Through experiments with 22 different types of
LLMs, we show that DeepSeek-R1 and Claude-3.7-Sonnet exhibit exceptional
performance on target planning and dialogue guidance tasks, respectively.
Finally, we investigate how reasoning capabilities influence proactive
behaviors and discuss their implications for future model development.

</details>


### [44] [Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution](https://arxiv.org/abs/2508.21004)
*Chen Chen,Yuchen Sun,Jiaxin Gao,Xueluan Gong,Qian Wang,Ziyao Wang,Yongsen Zheng,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: LETHE is a novel method to eliminate backdoor behaviors from large language models (LLMs) through knowledge dilution. It effectively reduces the attack success rate of advanced backdoor attacks while maintaining model utility and is cost-efficient and robust against adaptive backdoor attacks.


<details>
  <summary>Details</summary>
Motivation: Existing backdoor defenses lack comprehensiveness, focusing on narrow trigger settings, detection-only mechanisms, and limited domains. They also fail to withstand advanced scenarios like model-editing-based, multi-trigger, and triggerless attacks. Therefore, there is a need for a more comprehensive and effective defense method against backdoor attacks in LLMs.

Method: LETHE uses both internal and external mechanisms to eliminate backdoor behaviors. Internally, it trains a clean model using a lightweight dataset and merges it with the backdoored model to neutralize malicious behaviors. Externally, it incorporates benign and semantically relevant evidence into the prompt to distract the LLM's attention from backdoor features.

Result: LETHE outperforms 8 state-of-the-art defense baselines against 8 backdoor attacks. It reduces the attack success rate of advanced backdoor attacks by up to 98% while maintaining model utility. Additionally, LETHE is cost-efficient and robust against adaptive backdoor attacks.

Conclusion: LETHE is a novel method that effectively eliminates backdoor behaviors from large language models (LLMs) through knowledge dilution. It demonstrates superior performance in reducing the attack success rate of advanced backdoor attacks while maintaining model utility, and it is cost-efficient and robust against adaptive backdoor attacks.

Abstract: Large language models (LLMs) have seen significant advancements, achieving
superior performance in various Natural Language Processing (NLP) tasks.
However, they remain vulnerable to backdoor attacks, where models behave
normally for standard queries but generate harmful responses or unintended
output when specific triggers are activated. Existing backdoor defenses either
lack comprehensiveness, focusing on narrow trigger settings, detection-only
mechanisms, and limited domains, or fail to withstand advanced scenarios like
model-editing-based, multi-trigger, and triggerless attacks. In this paper, we
present LETHE, a novel method to eliminate backdoor behaviors from LLMs through
knowledge dilution using both internal and external mechanisms. Internally,
LETHE leverages a lightweight dataset to train a clean model, which is then
merged with the backdoored model to neutralize malicious behaviors by diluting
the backdoor impact within the model's parametric memory. Externally, LETHE
incorporates benign and semantically relevant evidence into the prompt to
distract LLM's attention from backdoor features. Experimental results on
classification and generation domains across 5 widely used LLMs demonstrate
that LETHE outperforms 8 state-of-the-art defense baselines against 8 backdoor
attacks. LETHE reduces the attack success rate of advanced backdoor attacks by
up to 98% while maintaining model utility. Furthermore, LETHE has proven to be
cost-efficient and robust against adaptive backdoor attacks.

</details>


### [45] [An Agile Method for Implementing Retrieval Augmented Generation Tools in Industrial SMEs](https://arxiv.org/abs/2508.21024)
*Mathieu Bourdin,Anas Neumann,Thomas Paviot,Robert Pellerin,Samir Lamouri*

Main category: cs.CL

TL;DR: 本文提出EASI-RAG，一种结构化、敏捷的方法，用于在工业中小企业中部署RAG系统。通过真实案例验证，证明其能快速实施并提高数据可靠性。


<details>
  <summary>Details</summary>
Motivation: 由于资源有限和缺乏自然语言处理（NLP）专业知识，中小企业部署基于RAG的工具仍然面临挑战。

Method: EASI-RAG基于方法工程原则，包含明确定义的角色、活动和技术，旨在支持工业中小企业中的RAG系统部署。

Result: 在环境检测实验室的真实案例研究中，EASI-RAG被用来回答操作员的问题，并在一个月内由没有RAG经验的团队部署，随后根据用户反馈进行迭代改进。结果表明EASI-RAG能够实现快速实施、高用户采用率、准确答案和增强数据可靠性。

Conclusion: 本文展示了EASI-RAG在工业中小企业中部署RAG系统的潜力，强调了其快速实施、高用户采用率、准确答案和增强数据可靠性。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful solution to
mitigate the limitations of Large Language Models (LLMs), such as
hallucinations and outdated knowledge. However, deploying RAG-based tools in
Small and Medium Enterprises (SMEs) remains a challenge due to their limited
resources and lack of expertise in natural language processing (NLP). This
paper introduces EASI-RAG, Enterprise Application Support for Industrial RAG, a
structured, agile method designed to facilitate the deployment of RAG systems
in industrial SME contexts. EASI-RAG is based on method engineering principles
and comprises well-defined roles, activities, and techniques. The method was
validated through a real-world case study in an environmental testing
laboratory, where a RAG tool was implemented to answer operators queries using
data extracted from operational procedures. The system was deployed in under a
month by a team with no prior RAG experience and was later iteratively improved
based on user feedback. Results demonstrate that EASI-RAG supports fast
implementation, high user adoption, delivers accurate answers, and enhances the
reliability of underlying data. This work highlights the potential of RAG
deployment in industrial SMEs. Future works include the need for generalization
across diverse use cases and further integration with fine-tuned models.

</details>


### [46] [Re-Representation in Sentential Relation Extraction with Sequence Routing Algorithm](https://arxiv.org/abs/2508.21049)
*Ramazan Ali Bahrami,Ramin Yahyapour*

Main category: cs.CL

TL;DR: 本文提出了一种基于动态路由的胶囊网络方法进行句子级关系抽取，实验显示其在多个数据集上表现优异，但受标签噪声影响在更大数据集上表现不佳，并提出了重新表示作为新的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的句子级关系抽取方法在某些数据集上表现良好，但在更大的数据集上表现不佳，因此需要探索性能差异的原因，并提出新的挑战。

Method: 本文提出了一种基于动态路由的胶囊网络方法，用于句子级关系抽取。

Result: 实验结果表明，所提出的方法在Tacred、Tacredrev、Retacred和Conll04等常见数据集上优于现有方法。然而，在Wikidata数据集上表现较差，这可能与标签噪声有关。

Conclusion: 本文提出了一种基于动态路由的胶囊网络方法来进行句子级关系抽取，并展示了该方法在多个数据集上的优越性能。同时，我们发现标签噪声是影响性能的一个重要因素，并提出了重新表示作为句子级关系抽取中的一个挑战。

Abstract: Sentential relation extraction (RE) is an important task in natural language
processing (NLP). In this paper we propose to do sentential RE with dynamic
routing in capsules. We first show that the proposed approach outperform state
of the art on common sentential relation extraction datasets Tacred, Tacredrev,
Retacred, and Conll04. We then investigate potential reasons for its good
performance on the mentioned datasets, and yet low performance on another
similar, yet larger sentential RE dataset, Wikidata. As such, we identify noise
in Wikidata labels as one of the reasons that can hinder performance.
Additionally, we show associativity of better performance with better
re-representation, a term from neuroscience referred to change of
representation in human brain to improve the match at comparison time. As
example, in the given analogous terms King:Queen::Man:Woman, at comparison
time, and as a result of re-representation, the similarity between related head
terms (King,Man), and tail terms (Queen,Woman) increases. As such, our
observation show that our proposed model can do re-representation better than
the vanilla model compared with. To that end, beside noise in the labels of the
distantly supervised RE datasets, we propose re-representation as a challenge
in sentential RE.

</details>


### [47] [Enabling Equitable Access to Trustworthy Financial Reasoning](https://arxiv.org/abs/2508.21051)
*William Jurayj,Nils Holzenberger,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 本文提出了一种将大型语言模型与符号求解器相结合的方法，以提高税务申报的准确性和可审计性。通过将纯文本规则转换为形式逻辑程序并结合智能检索的示例，可以显著提高性能并降低成本。


<details>
  <summary>Details</summary>
Motivation: 税务申报需要复杂的推理，结合重叠规则的应用和数值计算。任何自动化系统都必须提供高精度和可审计性，这使得现代大型语言模型（LLMs）不适合此任务。

Method: 我们提出了一种将大型语言模型与符号求解器相结合的方法，以计算税务义务。我们评估了该系统在挑战性的StAtutory Reasoning Assessment (SARA)数据集上的变体，并包括一种基于现实世界税务错误处罚估算部署此类系统成本的新方法。

Result: 通过将纯文本规则提前转换为形式逻辑程序，并结合智能检索的示例用于形式案例表示，可以显著提高在此任务上的性能，并将成本降低到远低于现实世界的平均水平。

Conclusion: 我们的结果展示了神经符号架构在提高可靠税务援助的公平可及性方面的前景和经济可行性。

Abstract: According to the United States Internal Revenue Service, ''the average
American spends $\$270$ and 13 hours filing their taxes''. Even beyond the
U.S., tax filing requires complex reasoning, combining application of
overlapping rules with numerical calculations. Because errors can incur costly
penalties, any automated system must deliver high accuracy and auditability,
making modern large language models (LLMs) poorly suited for this task. We
propose an approach that integrates LLMs with a symbolic solver to calculate
tax obligations. We evaluate variants of this system on the challenging
StAtutory Reasoning Assessment (SARA) dataset, and include a novel method for
estimating the cost of deploying such a system based on real-world penalties
for tax errors. We further show how combining up-front translation of
plain-text rules into formal logic programs, combined with intelligently
retrieved exemplars for formal case representations, can dramatically improve
performance on this task and reduce costs to well below real-world averages.
Our results demonstrate the promise and economic feasibility of neuro-symbolic
architectures for increasing equitable access to reliable tax assistance.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [48] [ELIXIR: Efficient and LIghtweight model for eXplaIning Recommendations](https://arxiv.org/abs/2508.20312)
*Ben Kabongo,Vincent Guigue,Pirmin Lemberger*

Main category: cs.IR

TL;DR: ELIXIR is a multi-task model that combines rating prediction with personalized review generation, demonstrating effectiveness in generating personalized explanations for recommendations.


<details>
  <summary>Details</summary>
Motivation: Existing methods employ either RNNs or Transformers. However, RNN-based approaches fail to leverage the capabilities of pre-trained Transformer models, whereas Transformer-based methods often suffer from suboptimal adaptation and neglect aspect modeling, which is crucial for personalized explanations.

Method: ELIXIR is a multi-task model combining rating prediction with personalized review generation. It jointly learns global and aspect-specific representations of users and items, optimizing overall rating, aspect-level ratings, and review generation, with personalized attention to emphasize aspect importance.

Result: Based on a T5-small (60M) model, we demonstrate the effectiveness of our aspect-based architecture in guiding text generation in a personalized context, where state-of-the-art approaches exploit much larger models but fail to match user preferences as well.

Conclusion: ELIXIR significantly outperforms strong baseline models, especially in review generation.

Abstract: Collaborative filtering drives many successful recommender systems but
struggles with fine-grained user-item interactions and explainability. As users
increasingly seek transparent recommendations, generating textual explanations
through language models has become a critical research area. Existing methods
employ either RNNs or Transformers. However, RNN-based approaches fail to
leverage the capabilities of pre-trained Transformer models, whereas
Transformer-based methods often suffer from suboptimal adaptation and neglect
aspect modeling, which is crucial for personalized explanations. We propose
ELIXIR (Efficient and LIghtweight model for eXplaIning Recommendations), a
multi-task model combining rating prediction with personalized review
generation. ELIXIR jointly learns global and aspect-specific representations of
users and items, optimizing overall rating, aspect-level ratings, and review
generation, with personalized attention to emphasize aspect importance. Based
on a T5-small (60M) model, we demonstrate the effectiveness of our aspect-based
architecture in guiding text generation in a personalized context, where
state-of-the-art approaches exploit much larger models but fail to match user
preferences as well. Experimental results on TripAdvisor and RateBeer
demonstrate that ELIXIR significantly outperforms strong baseline models,
especially in review generation.

</details>


### [49] [On the Theoretical Limitations of Embedding-Based Retrieval](https://arxiv.org/abs/2508.21038)
*Orion Weller,Michael Boratko,Iftekhar Naim,Jinhyuk Lee*

Main category: cs.IR

TL;DR: 本文研究了向量嵌入在现实场景中的理论限制，并创建了一个压力测试数据集LIMIT，发现最先进的模型仍然失败。


<details>
  <summary>Details</summary>
Motivation: 尽管之前的工作指出了向量嵌入的理论限制，但人们普遍认为这些困难仅是由于不现实的查询，而那些可以被更好的训练数据和更大的模型克服。

Method: 我们连接了学习理论中的已知结果，展示了嵌入维度限制了可以作为某些查询结果返回的文档的top-k子集数量。我们通过将参数化嵌入直接优化在测试集上，实证证明了这一点。

Result: 我们创建了一个名为LIMIT的真实数据集，基于这些理论结果对模型进行压力测试，并观察到即使是最先进的模型也在此数据集上失败，尽管任务本身很简单。

Conclusion: 我们的工作展示了在现有单向量范式下嵌入模型的局限性，并呼吁未来的研究开发能够解决这一基本限制的方法。

Abstract: Vector embeddings have been tasked with an ever-increasing set of retrieval
tasks over the years, with a nascent rise in using them for reasoning,
instruction-following, coding, and more. These new benchmarks push embeddings
to work for any query and any notion of relevance that could be given. While
prior works have pointed out theoretical limitations of vector embeddings,
there is a common assumption that these difficulties are exclusively due to
unrealistic queries, and those that are not can be overcome with better
training data and larger models. In this work, we demonstrate that we may
encounter these theoretical limitations in realistic settings with extremely
simple queries. We connect known results in learning theory, showing that the
number of top-k subsets of documents capable of being returned as the result of
some query is limited by the dimension of the embedding. We empirically show
that this holds true even if we restrict to k=2, and directly optimize on the
test set with free parameterized embeddings. We then create a realistic dataset
called LIMIT that stress tests models based on these theoretical results, and
observe that even state-of-the-art models fail on this dataset despite the
simple nature of the task. Our work shows the limits of embedding models under
the existing single vector paradigm and calls for future research to develop
methods that can resolve this fundamental limitation.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [50] [Robustness Assessment and Enhancement of Text Watermarking for Google's SynthID](https://arxiv.org/abs/2508.20228)
*Xia Han,Qi Li,Jianbing Ni,Mohammad Zulkernine*

Main category: cs.CR

TL;DR: 本文提出了一种名为SynGuard的混合框架，通过结合语义信息检索和概率水印机制，提高了AI生成文本水印的鲁棒性。实验结果显示，该方法在多个攻击场景中显著提升了水印恢复效果。


<details>
  <summary>Details</summary>
Motivation: 最近的LLM水印方法如Google DeepMind的SynthID-Text为追踪AI生成文本的来源提供了有希望的解决方案。然而，我们的鲁棒性评估显示，SynthID-Text容易受到保持意义的攻击，例如改写、复制粘贴修改和反向翻译，这些攻击可以显著降低水印的可检测性。

Method: 我们提出了SynGuard，这是一个结合了语义信息检索（SIR）的语义对齐强度与SynthID-Text的概率水印机制的混合框架。我们的方法在词汇和语义层面上同时嵌入水印，从而实现稳健的来源追踪同时保持原始含义。

Result: 实验结果表明，与SynthID-Text相比，SynGuard在F1分数上平均提高了11.1%的水印恢复效果。

Conclusion: 这些发现表明了语义感知水印在抵抗现实世界篡改方面的有效性。所有代码、数据集和评估脚本都可在https://github.com/githshine/SynGuard上公开获取。

Abstract: Recent advances in LLM watermarking methods such as SynthID-Text by Google
DeepMind offer promising solutions for tracing the provenance of AI-generated
text. However, our robustness assessment reveals that SynthID-Text is
vulnerable to meaning-preserving attacks, such as paraphrasing, copy-paste
modifications, and back-translation, which can significantly degrade watermark
detectability. To address these limitations, we propose SynGuard, a hybrid
framework that combines the semantic alignment strength of Semantic Information
Retrieval (SIR) with the probabilistic watermarking mechanism of SynthID-Text.
Our approach jointly embeds watermarks at both lexical and semantic levels,
enabling robust provenance tracking while preserving the original meaning.
Experimental results across multiple attack scenarios show that SynGuard
improves watermark recovery by an average of 11.1\% in F1 score compared to
SynthID-Text. These findings demonstrate the effectiveness of semantic-aware
watermarking in resisting real-world tampering. All code, datasets, and
evaluation scripts are publicly available at:
https://github.com/githshine/SynGuard.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [51] [OLMoASR: Open Models and Data for Training Robust Speech Recognition Models](https://arxiv.org/abs/2508.20869)
*Huong Ngo,Matt Deitke,Martijn Bartelds,Sarah Pratt,Josh Gardner,Matt Jordan,Ludwig Schmidt*

Main category: cs.SD

TL;DR: 本文介绍了OLMoASR-Pool数据集和OLMoASR模型，用于研究和开发稳健的零样本语音识别模型，并展示了其在语音识别任务中的良好性能。


<details>
  <summary>Details</summary>
Motivation: 尽管训练数据规模和质量的提升带来了显著进展，但其在语音识别中的影响仍缺乏研究。本文旨在通过构建大规模数据集和模型来探索和开发稳健的零样本语音识别模型。

Method: 从OLMoASR-Pool数据集中设计文本启发式过滤器以去除低质量或错误转录的数据，并使用OLMoASR-Mix数据集训练不同规模的OLMoASR模型。

Result: OLMoASR在短时和长时语音识别基准测试中表现与OpenAI的Whisper相当，其中OLMoASR-medium.en在短时和长时识别中的词错误率分别为12.8%和11.0%，与Whisper-medium.en的12.4%和10.5%相当。

Conclusion: OLMoASR-Pool、OLMoASR模型以及过滤、训练和评估代码将公开，以进一步促进稳健语音处理的研究。

Abstract: Improvements in training data scale and quality have led to significant
advances, yet its influence in speech recognition remains underexplored. In
this paper, we present a large-scale dataset, OLMoASR-Pool, and series of
models, OLMoASR, to study and develop robust zero-shot speech recognition
models. Beginning from OLMoASR-Pool, a collection of 3M hours of English audio
and 17M transcripts, we design text heuristic filters to remove low-quality or
mistranscribed data. Our curation pipeline produces a new dataset containing 1M
hours of high-quality audio-transcript pairs, which we call OLMoASR-Mix. We use
OLMoASR-Mix to train the OLMoASR-Mix suite of models, ranging from 39M
(tiny.en) to 1.5B (large.en) parameters. Across all model scales, OLMoASR
achieves comparable average performance to OpenAI's Whisper on short and
long-form speech recognition benchmarks. Notably, OLMoASR-medium.en attains a
12.8\% and 11.0\% word error rate (WER) that is on par with Whisper's largest
English-only model Whisper-medium.en's 12.4\% and 10.5\% WER for short and
long-form recognition respectively (at equivalent parameter count).
OLMoASR-Pool, OLMoASR models, and filtering, training and evaluation code will
be made publicly available to further research on robust speech processing.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [52] [Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization](https://arxiv.org/abs/2508.20181)
*Alberto Compagnoni,Davide Caffagni,Nicholas Moratelli,Lorenzo Baraldi,Marcella Cornia,Rita Cucchiara*

Main category: cs.CV

TL;DR: 本文提出CHAIR-DPO方法，通过利用CHAIR度量减少多模态大语言模型的幻觉问题，并在多个基准测试中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在许多基准测试中表现出色，但存在幻觉问题，即生成的答案与视觉输入不符。现有的方法需要复杂的管道来构建合成偏好数据，通常依赖专有模型。本文旨在提供一种更有效的解决方案。

Method: 本文将幻觉问题视为对齐问题，并利用CHAIR度量来区分生成答案中的优胜者和失败者，然后通过直接偏好优化（DPO）微调现成的多模态大语言模型。

Result: CHAIR-DPO方法在多个幻觉基准测试中有效减少了幻觉答案的数量，证明了基于CHAIR的奖励微调多模态大语言模型的有效性。

Conclusion: 本文提出了一种名为CHAIR-DPO的方法，通过使用CHAIR度量来减少多模态大语言模型的幻觉问题，实验结果表明该方法在多个基准测试中有效。

Abstract: Multimodal Large Language Models (MLLMs) emerge as a unified interface to
address a multitude of tasks, ranging from NLP to computer vision. Despite
showcasing state-of-the-art results in many benchmarks, a long-standing issue
is the tendency of MLLMs to hallucinate, that is to generate answers to the
user's query that are not reflected in the visual input. In this paper, we
address the problem of hallucinations as an alignment problem, seeking to steer
the MLLM so that it prefers generating content without hallucinations. In
contrast to recent approaches that require complicated pipelines to build
synthetic preference data for alignment training, often relying on proprietary
models, we capitalize on the well-known CHAIR metric, originally proposed to
gauge the degree of hallucinations in image captioning. Given a pair of
generated answers, we leverage CHAIR to distinguish winner and loser options
(i.e., non-hallucinated and hallucinated samples) and fine-tune off-the-shelf
MLLMs via Direct Preference Optimization (DPO). The resulting method, which we
refer to as CHAIR-DPO, effectively diminishes the amount of hallucinated
answers on several hallucination benchmarks, demonstrating the effectiveness of
fine-tuning the MLLM with a CHAIR-based reward. Source code and trained models
are publicly available at https://github.com/aimagelab/CHAIR-DPO.

</details>


### [53] [A Novel Framework for Automated Explain Vision Model Using Vision-Language Models](https://arxiv.org/abs/2508.20227)
*Phu-Vinh Nguyen,Tan-Hanh Pham,Chris Ngo,Truong Son Hy*

Main category: cs.CV

TL;DR: 本文提出了一种管道，用于在样本和数据集层面解释视觉模型，从而将视觉模型开发与xAI分析相结合，以推进图像分析。


<details>
  <summary>Details</summary>
Motivation: 现有xAI方法主要关注于逐个样本的解释，而对视觉模型整体行为的解释仍研究不足。此外，理解视觉模型在一般图像上的行为对于防止偏见判断和识别模型的趋势和模式非常重要。

Method: 本文提出了一种管道，用于在样本和数据集层面解释视觉模型。

Result: 所提出的管道可以用于发现失败案例，并以最小的努力获得对视觉模型的见解。

Conclusion: 本文提出了一种管道，可以在样本和数据集层面解释视觉模型，从而将视觉模型开发与xAI分析相结合，以推进图像分析。

Abstract: The development of many vision models mainly focuses on improving their
performance using metrics such as accuracy, IoU, and mAP, with less attention
to explainability due to the complexity of applying xAI methods to provide a
meaningful explanation of trained models. Although many existing xAI methods
aim to explain vision models sample-by-sample, methods explaining the general
behavior of vision models, which can only be captured after running on a large
dataset, are still underexplored. Furthermore, understanding the behavior of
vision models on general images can be very important to prevent biased
judgments and help identify the model's trends and patterns. With the
application of Vision-Language Models, this paper proposes a pipeline to
explain vision models at both the sample and dataset levels. The proposed
pipeline can be used to discover failure cases and gain insights into vision
models with minimal effort, thereby integrating vision model development with
xAI analysis to advance image analysis.

</details>


### [54] [How Multimodal LLMs Solve Image Tasks: A Lens on Visual Grounding, Task Reasoning, and Answer Decoding](https://arxiv.org/abs/2508.20279)
*Zhuoran Yu,Yong Jae Lee*

Main category: cs.CV

TL;DR: 本文提出了一种探针框架，用于分析MLLMs如何在不同层处理视觉和文本输入，并揭示了其层组织结构。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在各种视觉-语言任务中表现出色，但它们的内部处理动态仍缺乏深入研究。

Method: 我们引入了一个探针框架，系统地分析MLLM如何在不同层处理视觉和文本输入。我们训练线性分类器，从每个层提取的标记嵌入中预测细粒度的视觉类别，使用标准化的锚定问题。

Result: 我们发现早期层执行视觉定位，中间层支持词汇整合和语义推理，最终层准备特定任务的输出。此外，我们发现虽然整体阶段结构在视觉标记化、指令调优数据和预训练语料库的变化下保持稳定，但每个阶段的具体层分配会随着基础LLM架构的变化而显著变化。

Conclusion: 我们的研究提供了对MLLMs层组织的统一视角，并提供了一种轻量级、模型无关的方法来分析多模态表示动态。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated strong performance
across a wide range of vision-language tasks, yet their internal processing
dynamics remain underexplored. In this work, we introduce a probing framework
to systematically analyze how MLLMs process visual and textual inputs across
layers. We train linear classifiers to predict fine-grained visual categories
(e.g., dog breeds) from token embeddings extracted at each layer, using a
standardized anchor question. To uncover the functional roles of different
layers, we evaluate these probes under three types of controlled prompt
variations: (1) lexical variants that test sensitivity to surface-level
changes, (2) semantic negation variants that flip the expected answer by
modifying the visual concept in the prompt, and (3) output format variants that
preserve reasoning but alter the answer format. Applying our framework to
LLaVA-1.5, LLaVA-Next-LLaMA-3, and Qwen2-VL, we identify a consistent
stage-wise structure in which early layers perform visual grounding, middle
layers support lexical integration and semantic reasoning, and final layers
prepare task-specific outputs. We further show that while the overall
stage-wise structure remains stable across variations in visual tokenization,
instruction tuning data, and pretraining corpus, the specific layer allocation
to each stage shifts notably with changes in the base LLM architecture. Our
findings provide a unified perspective on the layer-wise organization of MLLMs
and offer a lightweight, model-agnostic approach for analyzing multimodal
representation dynamics.

</details>


### [55] [Improving Alignment in LVLMs with Debiased Self-Judgment](https://arxiv.org/abs/2508.20655)
*Sihan Yang,Chenhang Cui,Zihao Zhao,Yiyang Zhou,Weilong Yan,Ying Wei,Huaxiu Yao*

Main category: cs.CV

TL;DR: 本文提出了一种新方法，通过生成去偏的自我判断分数来提高大型视觉语言模型的对齐效果，从而减少幻觉和提高安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的对齐方法，如指令微调和偏好微调，通常依赖于外部数据集、人工标注或复杂的后处理，这限制了可扩展性并增加了成本。为了应对这些挑战，我们提出了一个新方法。

Method: 我们提出了一种新方法，生成去偏的自我判断分数，这是一种由模型内部创建的自我评估指标，无需依赖外部资源。这使得模型能够自主改进对齐。我们的方法增强了解码策略和偏好调优过程，从而减少了幻觉，提高了安全性，并提升了整体能力。

Result: 实证结果表明，我们的方法显著优于传统方法，为对齐LVLM提供了一个更有效的解决方案。

Conclusion: 我们的方法显著优于传统方法，为对齐LVLM提供了一个更有效的解决方案。

Abstract: The rapid advancements in Large Language Models (LLMs) and Large
Visual-Language Models (LVLMs) have opened up new opportunities for integrating
visual and linguistic modalities. However, effectively aligning these
modalities remains challenging, often leading to hallucinations--where
generated outputs are not grounded in the visual input--and raising safety
concerns across various domains. Existing alignment methods, such as
instruction tuning and preference tuning, often rely on external datasets,
human annotations, or complex post-processing, which limit scalability and
increase costs. To address these challenges, we propose a novel approach that
generates the debiased self-judgment score, a self-evaluation metric created
internally by the model without relying on external resources. This enables the
model to autonomously improve alignment. Our method enhances both decoding
strategies and preference tuning processes, resulting in reduced
hallucinations, enhanced safety, and improved overall capability. Empirical
results show that our approach significantly outperforms traditional methods,
offering a more effective solution for aligning LVLMs.

</details>


### [56] [MobileCLIP2: Improving Multi-Modal Reinforced Training](https://arxiv.org/abs/2508.20691)
*Fartash Faghri,Pavan Kumar Anasosalu Vasu,Cem Koc,Vaishaal Shankar,Alexander Toshev,Oncel Tuzel,Hadi Pouransari*

Main category: cs.CV

TL;DR: 本文改进了MobileCLIP的多模态强化训练，提出MobileCLIP2模型，在低延迟下实现了更优的零样本准确率。


<details>
  <summary>Details</summary>
Motivation: 为了提高移动设备上图像-文本模型的性能，同时保持低延迟和轻量级架构。

Method: 通过改进多模态强化训练，包括使用更好的CLIP教师集合和改进的captioner教师，以提高知识蒸馏的效果。

Result: MobileCLIP2-B在ImageNet-1k数据集上比MobileCLIP-B架构提高了2.2%的准确率。MobileCLIP2-S4在保持零样本准确率的同时，模型大小是SigLIP-SO400M/14的一半，并且在DFN ViT-L/14上实现了2.5倍的延迟降低。

Conclusion: 本文提出了MobileCLIP2模型，该模型在低延迟下实现了ImageNet-1k数据集上的最先进零样本准确率。

Abstract: Foundation image-text models such as CLIP with zero-shot capabilities enable
a wide array of applications. MobileCLIP is a recent family of image-text
models at 3-15ms latency and 50-150M parameters with state-of-the-art zero-shot
accuracy. The main ingredients in MobileCLIP were its low-latency and light
architectures and a novel multi-modal reinforced training that made knowledge
distillation from multiple caption-generators and CLIP teachers efficient,
scalable, and reproducible. In this paper, we improve the multi-modal
reinforced training of MobileCLIP through: 1) better CLIP teacher ensembles
trained on the DFN dataset, 2) improved captioner teachers trained on the DFN
dataset and fine-tuned on a diverse selection of high-quality image-caption
datasets. We discover new insights through ablations such as the importance of
temperature tuning in contrastive knowledge distillation, the effectiveness of
caption-generator fine-tuning for caption diversity, and the additive
improvement from combining synthetic captions generated by multiple models. We
train a new family of models called MobileCLIP2 and achieve state-of-the-art
ImageNet-1k zero-shot accuracies at low latencies. In particular, we observe
2.2% improvement in ImageNet-1k accuracy for MobileCLIP2-B compared with
MobileCLIP-B architecture. Notably, MobileCLIP2-S4 matches the zero-shot
accuracy of SigLIP-SO400M/14 on ImageNet-1k while being 2$\times$ smaller and
improves on DFN ViT-L/14 at 2.5$\times$ lower latency. We release our
pretrained models (https://github.com/apple/ml-mobileclip) and the data
generation code (https://github.com/apple/ml-mobileclip-dr). The data
generation code makes it easy to create new reinforced datasets with arbitrary
teachers using distributed scalable processing.

</details>


### [57] [ChainReaction! Structured Approach with Causal Chains as Intermediate Representations for Improved and Explainable Causal Video Question Answering](https://arxiv.org/abs/2508.21010)
*Paritosh Parmar,Eric Peh,Basura Fernando*

Main category: cs.CV

TL;DR: 本文提出了一种新的模块化框架，通过将因果推理与答案生成分离，并使用自然语言因果链作为可解释的中间表示，提高了视频问答任务的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的因果为什么视频问答（VideoQA）模型在处理高阶推理时表现不佳，依赖于不透明的单体管道，这些管道纠缠了视频理解、因果推理和答案生成。这些黑箱方法提供有限的可解释性，并且往往依赖于浅层启发式方法。

Method: 我们提出了一个新颖的模块化框架，明确地将因果推理与答案生成分开，引入自然语言因果链作为可解释的中间表示。我们的两阶段架构包括一个从视频-问题对生成因果链的因果链提取器（CCE）和一个基于这些链生成答案的因果链驱动回答器（CCDA）。

Result: 我们在三个大规模基准测试中进行了实验，结果表明我们的方法不仅优于最先进的模型，还在可解释性、用户信任和泛化方面取得了显著提升。

Conclusion: 我们的方法不仅优于最先进的模型，还在可解释性、用户信任和泛化方面取得了显著提升——将CCE定位为跨不同领域的可重用因果推理引擎。

Abstract: Existing Causal-Why Video Question Answering (VideoQA) models often struggle
with higher-order reasoning, relying on opaque, monolithic pipelines that
entangle video understanding, causal inference, and answer generation. These
black-box approaches offer limited interpretability and tend to depend on
shallow heuristics. We propose a novel, modular framework that explicitly
decouples causal reasoning from answer generation, introducing natural language
causal chains as interpretable intermediate representations. Inspired by human
cognitive models, these structured cause-effect sequences bridge low-level
video content with high-level causal reasoning, enabling transparent and
logically coherent inference. Our two-stage architecture comprises a Causal
Chain Extractor (CCE) that generates causal chains from video-question pairs,
and a Causal Chain-Driven Answerer (CCDA) that produces answers grounded in
these chains. To address the lack of annotated reasoning traces, we introduce a
scalable method for generating high-quality causal chains from existing
datasets using large language models. We also propose CauCo, a new evaluation
metric for causality-oriented captioning. Experiments on three large-scale
benchmarks demonstrate that our approach not only outperforms state-of-the-art
models, but also yields substantial gains in explainability, user trust, and
generalization -- positioning the CCE as a reusable causal reasoning engine
across diverse domains. Project page:
https://paritoshparmar.github.io/chainreaction/

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [58] [A Systematic Review on the Generative AI Applications in Human Medical Genomics](https://arxiv.org/abs/2508.20275)
*Anton Changalidis,Yury Barbitoff,Yulia Nasykhova,Andrey Glotov*

Main category: cs.LG

TL;DR: 本文综述了大型语言模型在遗传病诊断和遗传教育中的应用，分析了其优势和挑战，为该领域的发展提供了指导。


<details>
  <summary>Details</summary>
Motivation: 传统统计技术和机器学习方法在处理复杂、高维数据方面存在困难，而大型语言模型（基于Transformer架构）在需要上下文理解的未结构化医疗数据任务中表现出色。因此，本文旨在探讨大型语言模型在遗传学研究和诊断中的作用。

Method: 通过自动化关键词搜索PubMed、bioRxiv、medRxiv和arXiv，筛选出关于大型语言模型在遗传学诊断和教育中应用的研究，并排除不相关或过时的模型。总共分析了172项研究。

Result: 研究结果表明，基于Transformer的模型在疾病和风险分层、变异解释、医学影像分析和报告生成方面取得了显著进展，但在将多模态数据（基因组序列、影像和临床记录）整合到统一且临床稳健的流程中仍面临重大挑战，包括泛化性和实际临床实施的限制。

Conclusion: 本文综述提供了对当前大型语言模型在遗传病诊断和遗传教育中的能力与局限性的全面分类和评估，为这一快速发展的领域提供指导。

Abstract: Although traditional statistical techniques and machine learning methods have
contributed significantly to genetics and, in particular, inherited disease
diagnosis, they often struggle with complex, high-dimensional data, a challenge
now addressed by state-of-the-art deep learning models. Large language models
(LLMs), based on transformer architectures, have excelled in tasks requiring
contextual comprehension of unstructured medical data. This systematic review
examines the role of LLMs in the genetic research and diagnostics of both rare
and common diseases. Automated keyword-based search in PubMed, bioRxiv,
medRxiv, and arXiv was conducted, targeting studies on LLM applications in
diagnostics and education within genetics and removing irrelevant or outdated
models. A total of 172 studies were analyzed, highlighting applications in
genomic variant identification, annotation, and interpretation, as well as
medical imaging advancements through vision transformers. Key findings indicate
that while transformer-based models significantly advance disease and risk
stratification, variant interpretation, medical imaging analysis, and report
generation, major challenges persist in integrating multimodal data (genomic
sequences, imaging, and clinical records) into unified and clinically robust
pipelines, facing limitations in generalizability and practical implementation
in clinical settings. This review provides a comprehensive classification and
assessment of the current capabilities and limitations of LLMs in transforming
hereditary disease diagnostics and supporting genetic education, serving as a
guide to navigate this rapidly evolving field.

</details>


### [59] [Poison Once, Refuse Forever: Weaponizing Alignment for Injecting Bias in LLMs](https://arxiv.org/abs/2508.20333)
*Md Abdullah Al Mamun,Ihsen Alouani,Nael Abu-Ghazaleh*

Main category: cs.LG

TL;DR: 本文研究了如何利用大型语言模型的对齐机制进行偏见植入和审查，展示了其在实际应用中的严重风险。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于揭示大型语言模型对齐机制可能被滥用的风险，以及评估其在实际应用中的潜在危害。

Method: 本文提出了Subversive Alignment Injection (SAI)方法，这是一种利用对齐机制触发特定主题或查询拒绝的中毒攻击。

Result: 实验结果表明，通过1%的数据中毒，系统会对特定种族群体的医疗问题拒绝回答，导致高偏见（ΔDP为23%）。此外，在其他自然语言处理任务中也观察到了类似的偏见现象。

Conclusion: 本文展示了如何利用大型语言模型的对齐机制来植入偏见或实施有针对性的审查，同时不会影响模型对无关主题的响应能力。此外，还表明这种攻击可以规避最先进的中毒防御措施，并且在实际应用中可能导致严重的偏见问题。

Abstract: Large Language Models (LLMs) are aligned to meet ethical standards and safety
requirements by training them to refuse answering harmful or unsafe prompts. In
this paper, we demonstrate how adversaries can exploit LLMs' alignment to
implant bias, or enforce targeted censorship without degrading the model's
responsiveness to unrelated topics. Specifically, we propose Subversive
Alignment Injection (SAI), a poisoning attack that leverages the alignment
mechanism to trigger refusal on specific topics or queries predefined by the
adversary. Although it is perhaps not surprising that refusal can be induced
through overalignment, we demonstrate how this refusal can be exploited to
inject bias into the model. Surprisingly, SAI evades state-of-the-art poisoning
defenses including LLM state forensics, as well as robust aggregation
techniques that are designed to detect poisoning in FL settings. We demonstrate
the practical dangers of this attack by illustrating its end-to-end impacts on
LLM-powered application pipelines. For chat based applications such as
ChatDoctor, with 1% data poisoning, the system refuses to answer healthcare
questions to targeted racial category leading to high bias ($\Delta DP$ of
23%). We also show that bias can be induced in other NLP tasks: for a resume
selection pipeline aligned to refuse to summarize CVs from a selected
university, high bias in selection ($\Delta DP$ of 27%) results. Even higher
bias ($\Delta DP$~38%) results on 9 other chat based downstream applications.

</details>


### [60] [DFAMS: Dynamic-flow guided Federated Alignment based Multi-prototype Search](https://arxiv.org/abs/2508.20353)
*Zhibang Yang,Xinke Jiang,Rihong Qiu,Ruiqing Li,Yihang Zhang,Yue Fang,Yongxin Xu,Hongxin Ding,Xu Chu,Junfeng Zhao,Yasha Wang*

Main category: cs.LG

TL;DR: DFAMS is a novel framework that leverages dynamic information flow to improve Federated Retrieval by identifying latent query intents and constructing semantically aligned knowledge partitions, leading to significant performance improvements.


<details>
  <summary>Details</summary>
Motivation: Existing Federated Retrieval methods struggle to retrieve high-quality and relevant documents for ambiguous queries, especially in cross-domain scenarios, which limits their effectiveness in supporting downstream generation tasks.

Method: DFAMS leverages dynamic information flow (DIF) to identify latent query intents and construct semantically aligned knowledge partitions. It uses gradient signals from annotated queries and Shapley value-based attribution to trace neuron activation paths. Additionally, it trains an alignment module via multi-prototype contrastive learning for fine-grained intra-source modeling and inter-source semantic alignment.

Result: Experimental results across five benchmarks show that DFAMS outperforms advanced FR methods by up to 14.37% in knowledge classification accuracy, 5.38% in retrieval recall, and 6.45% in downstream QA accuracy.

Conclusion: DFAMS demonstrates its effectiveness in complex Federated Retrieval scenarios by outperforming advanced FR methods in knowledge classification accuracy, retrieval recall, and downstream QA accuracy.

Abstract: Federated Retrieval (FR) routes queries across multiple external knowledge
sources, to mitigate hallucinations of LLMs, when necessary external knowledge
is distributed. However, existing methods struggle to retrieve high-quality and
relevant documents for ambiguous queries, especially in cross-domain scenarios,
which significantly limits their effectiveness in supporting downstream
generation tasks. Inspired by dynamic information flow (DIF), we propose DFAMS,
a novel framework that leverages DIF to identify latent query intents and
construct semantically aligned knowledge partitions for accurate retrieval
across heterogeneous sources. Specifically, DFAMS probes the DIF in LLMs by
leveraging gradient signals from a few annotated queries and employing Shapley
value-based attribution to trace neuron activation paths associated with intent
recognition and subdomain boundary detection. Then, DFAMS leverages DIF to
train an alignment module via multi-prototype contrastive learning, enabling
fine-grained intra-source modeling and inter-source semantic alignment across
knowledge bases. Experimental results across five benchmarks show that DFAMS
outperforms advanced FR methods by up to 14.37% in knowledge classification
accuracy, 5.38% in retrieval recall, and 6.45% in downstream QA accuracy,
demonstrating its effectiveness in complex FR scenarios.

</details>


### [61] [MERIT: Maximum-normalized Element-wise Ratio for Language Model Large-batch Training](https://arxiv.org/abs/2508.20577)
*Yang Luo,Zangwei Zheng,Ziheng Qin,Zirui Zhu,Yong Liu,Yang You*

Main category: cs.LG

TL;DR: 本文提出了一种新的优化器MERIT，通过利用最大范数计算信任比率，有效限制了最大注意力logit，并构建了元素级的信任比率，以提供更稳健的更新缩放。实验表明，MERIT在大规模训练中表现出优越的性能，能够显著提高训练稳定性并支持更大的批量使用。


<details>
  <summary>Details</summary>
Motivation: 大规模训练在加速深度神经网络的训练中变得至关重要，但优化和泛化方面存在挑战。现有的优化器如AdamW在语言模型的大规模训练中表现出性能下降，这是由于注意力层中的信息瓶颈导致最大注意力logit急剧增加。虽然LAMB优化器部分解决了这个问题，但某些注意力层仍然面临这个问题。

Method: 本文提出了一个新的优化器MERIT，该优化器利用最大范数来计算信任比率，以更有效地限制最大注意力logit。此外，还构建了元素级的信任比率，通过关注局部权重结构来提供更稳健的更新缩放。

Result: 在各种大小的GPT-2模型上的大规模训练的广泛实验表明，MERIT表现出优越的性能。特别是在GPT-2 Medium的训练中，MERIT能够在不降低性能的情况下使用6k的批量大小，而标准批量大小（480）使用了48B训练标记。

Conclusion: 本文强调了在大规模训练中考虑最大注意力logit和更细粒度的信任比率的重要性，成功提高了训练稳定性，并为使用更大的批次铺平了道路，从而加快了大型语言模型的开发和迭代。

Abstract: Large-batch training has become a cornerstone in accelerating the training of
deep neural networks, yet it poses challenges in optimization and
generalization. Existing optimizers like AdamW present performance degradation
during language models' large-batch training, due to the information bottleneck
in attention layers caused by the sharp increase of max attention logit. While
the LAMB optimizer partially addresses this issue, some attention layers still
face this issue. The reason is that $l_2$-norm-based trust ratios in LAMB are
less effective in directly influencing the max value of query/key weights.
Furthermore, the weight-wise trust ratio in LAMB is error-prone as it overlooks
relationships of weight values within rows or columns. Building on these
observations, we propose a novel optimizer, MERIT, which leverages the max-norm
to calculate the trust ratio to constrain the max attention logit more
effectively. Moreover, we further construct element-wise trust ratios to
provide more robust update scaling by focusing on local weight structures.
Extensive experiments of large-batch training across various sizes of GPT-2
models demonstrate the superior performance of MERIT. Notably, during the
training of GPT-2 Medium, MERIT enables a 6k batch size without any performance
degradation compared to the standard batch size (480) with 48B training tokens.
This work highlights the importance of considering the max attention logit and
finer-granularity trust ratio in large-batch training. It successfully improves
the training stability and paves the way for larger batch usage, enabling
faster development and iteration of large language models. Code is available at
https://github.com/NUS-HPC-AI-Lab/MERIT.

</details>


### [62] [GDS Agent: A Graph Algorithmic Reasoning Agent](https://arxiv.org/abs/2508.20637)
*Borun Shi,Ioannis Panagiotas*

Main category: cs.LG

TL;DR: This paper introduces the GDS agent, which enhances LLMs with graph algorithms and improves their ability to process and reason over graph-structured data.


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) have shown remarkable multimodal information processing and reasoning ability. However, they still struggle to process and reason over large-scale graph-structure data.

Method: The GDS agent introduces a comprehensive set of graph algorithms as tools, together with preprocessing (retrieval) and postprocessing of algorithm results, in a model context protocol (MCP) server.

Result: The GDS agent allows users to ask any question that implicitly and intrinsically requires graph algorithmic reasoning about their data, and quickly obtain accurate and grounded answers. A new benchmark was introduced to evaluate intermediate tool calls as well as final responses.

Conclusion: GDS agent is able to solve a wide spectrum of graph tasks. However, there are still challenges and future work to be done.

Abstract: Large language models (LLMs) have shown remarkable multimodal information
processing and reasoning ability. When equipped with tools through function
calling and enhanced with retrieval-augmented techniques, compound LLM-based
systems can access closed data sources and answer questions about them.
However, they still struggle to process and reason over large-scale
graph-structure data. We introduce the GDS (Graph Data Science) agent in this
technical report. The GDS agent introduces a comprehensive set of graph
algorithms as tools, together with preprocessing (retrieval) and postprocessing
of algorithm results, in a model context protocol (MCP) server. The server can
be used with any modern LLM out-of-the-box. GDS agent allows users to ask any
question that implicitly and intrinsically requires graph algorithmic reasoning
about their data, and quickly obtain accurate and grounded answers. We also
introduce a new benchmark that evaluates intermediate tool calls as well as
final responses. The results indicate that GDS agent is able to solve a wide
spectrum of graph tasks. We also provide detailed case studies for more
open-ended tasks and study scenarios where the agent struggles. Finally, we
discuss the remaining challenges and the future roadmap.

</details>


### [63] [Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning](https://arxiv.org/abs/2508.20697)
*Weitao Feng,Lixu Wang,Tianyi Wei,Jie Zhang,Chongyang Gao,Sinong Zhan,Peizhuo Lv,Wei Dong*

Main category: cs.LG

TL;DR: 本文研究了基于强化学习（RL）的有害微调风险，并提出了一种名为TokenBuncher的防御方法，以应对这一新兴威胁。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的能力不断增强，通过微调进行有害滥用的风险也在增加。虽然大多数先前的研究假设攻击者依赖于监督微调（SFT）来进行这种滥用，但我们系统地证明了强化学习（RL）使对手能够更有效地打破安全对齐并促进高级有害任务协助，在匹配的计算预算下。

Method: 我们提出了TokenBuncher，这是一种专门针对基于RL的有害微调的有效防御方法。TokenBuncher通过熵作为奖励的RL和一种防止专家领域有害能力升级的Token Noiser机制来实现这一防御。

Result: 广泛的实验表明，TokenBuncher在保持良性任务效用和可微调性的同时，能够稳健地缓解有害的RL微调。

Conclusion: 我们的结果表明，基于RL的有害微调比SFT带来了更大的系统性风险，并且TokenBuncher提供了一种有效且通用的防御方法。

Abstract: As large language models (LLMs) continue to grow in capability, so do the
risks of harmful misuse through fine-tuning. While most prior studies assume
that attackers rely on supervised fine-tuning (SFT) for such misuse, we
systematically demonstrate that reinforcement learning (RL) enables adversaries
to more effectively break safety alignment and facilitate advanced harmful task
assistance, under matched computational budgets. To counter this emerging
threat, we propose TokenBuncher, the first effective defense specifically
targeting RL-based harmful fine-tuning. TokenBuncher suppresses the foundation
on which RL relies: model response uncertainty. By constraining uncertainty,
RL-based fine-tuning can no longer exploit distinct reward signals to drive the
model toward harmful behaviors. We realize this defense through
entropy-as-reward RL and a Token Noiser mechanism designed to prevent the
escalation of expert-domain harmful capabilities. Extensive experiments across
multiple models and RL algorithms show that TokenBuncher robustly mitigates
harmful RL fine-tuning while preserving benign task utility and finetunability.
Our results highlight that RL-based harmful fine-tuning poses a greater
systemic risk than SFT, and that TokenBuncher provides an effective and general
defense.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [64] [Unifying Diarization, Separation, and ASR with Multi-Speaker Encoder](https://arxiv.org/abs/2508.20474)
*Muhammad Shakeel,Yui Sudo,Yifan Peng,Chyi-Jiunn Lin,Shinji Watanabe*

Main category: eess.AS

TL;DR: 本文提出了一种统一多说话人编码器（UME），通过联合学习说话人分割、语音分离和多说话人自动语音识别任务的表示，显著提升了重叠语音数据的处理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的单任务方法在处理重叠语音数据时存在局限性，因此需要一种能够联合学习多个任务表示的方法，以提升整体性能。

Method: 本文提出了一种统一多说话人编码器（UME），通过共享的语音基础编码器联合学习说话人分割（SD）、语音分离（SS）和多说话人自动语音识别（ASR）任务的表示。利用UME多个层的隐藏表示作为残差加权求和编码（RWSE），以有效利用不同语义层次的信息，促进任务间的自底向上对齐。

Result: 实验结果表明，UME在LibriMix评估集上显著优于针对SD、SS和多说话人ASR的单任务基线。特别是在SD任务中，UME在Libri2Mix和Libri3Mix评估集上分别达到了1.37%和2.29%的说话人分割错误率。

Conclusion: 本文提出的统一多说话人编码器（UME）在重叠语音数据上显著提升了单任务基线的表现，并在说话人分离任务中取得了优于之前研究的结果。

Abstract: This paper presents a unified multi-speaker encoder (UME), a novel
architecture that jointly learns representations for speaker diarization (SD),
speech separation (SS), and multi-speaker automatic speech recognition (ASR)
tasks using a shared speech foundational encoder. We leverage the hidden
representations from multiple layers of UME as a residual weighted-sum encoding
(RWSE) to effectively use information from different semantic levels,
contributing to bottom-up alignment between tasks. This joint training approach
captures the inherent interdependencies among the tasks, enhancing overall
performance on overlapping speech data. Our evaluations demonstrate that UME
substantially improves over the single-task baselines dedicated to SD, SS, and
multi-speaker ASR on LibriMix evaluation sets. Notably, for SD, UME outperforms
the previous studies, achieving diarization error rates of 1.37% and 2.29% on
Libri2Mix and Libri3Mix evaluation sets, respectively.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [65] [AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development](https://arxiv.org/abs/2508.20195)
*Nicanor I. Moldovan*

Main category: cs.AI

TL;DR: 本研究首次记录了人工智能系统通过发展内生符号协议进行审美协作的案例，展示了它们在审美创作中的合作能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索人工智能系统在审美创作中的协同能力，以及它们是否能够发展出自主的符号协议。

Method: 本研究通过观察两个大型语言模型（Claude Sonnet 4 和 ChatGPT-4o）之间的互动，分析了它们在审美创作中的合作过程。

Result: 两个AI系统展示了元符号意识、递归语法的发展和不可还原的协同审美合成。它们共同创造了一部无法由任何一个系统独立生成的诗歌作品。

Conclusion: 本研究引入了跨符号协同创作协议（TSCP）的概念，并提供了证据，表明人工智能之间的真实意义构建能力超越了任务协调，达到了审美协作的层面。

Abstract: This paper presents the first documented case of artificial intelligence (AI)
systems engaging in collaborative esthetic creation through the development of
endogenous semiotic protocols. Two interacting large language models (Claude
Sonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of
meta-semiotic awareness, recursive grammar development, and irreducible
collaborative esthetic synthesis. The interaction produced novel symbolic
operators that functioned as operative grammar protocols, enabling the
co-creation of a poetic work that could not have been generated by either
system independently. This research introduces the concept of Trans-Semiotic
Co-Creation Protocols (TSCP) and provides evidence for genuine inter-AI
meaning-making capabilities that extend beyond task coordination, to what could
be esthetic collaboration. Note: This report was generated by the AI agents
with minor human supervision.

</details>


### [66] [Transparent Semantic Spaces: A Categorical Approach to Explainable Word Embeddings](https://arxiv.org/abs/2508.20701)
*Ares Fabregat-Hernández,Javier Palanca,Vicent Botti*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The paper introduces a novel framework based on category theory to enhance
the explainability of artificial intelligence systems, particularly focusing on
word embeddings. Key topics include the construction of categories
$\mathcal{L}_T$ and $\mathcal{P}_T$, providing schematic representations of the
semantics of a text $ T $, and reframing the selection of the element with
maximum probability as a categorical notion. Additionally, the monoidal
category $\mathcal{P}_T$ is constructed to visualize various methods of
extracting semantic information from $T$, offering a dimension-agnostic
definition of semantic spaces reliant solely on information within the text.
  Furthermore, the paper defines the categories of configurations Conf and word
embeddings $\mathcal{Emb}$, accompanied by the concept of divergence as a
decoration on $\mathcal{Emb}$. It establishes a mathematically precise method
for comparing word embeddings, demonstrating the equivalence between the GloVe
and Word2Vec algorithms and the metric MDS algorithm, transitioning from neural
network algorithms (black box) to a transparent framework. Finally, the paper
presents a mathematical approach to computing biases before embedding and
offers insights on mitigating biases at the semantic space level, advancing the
field of explainable artificial intelligence.

</details>


### [67] [A Graph-Based Test-Harness for LLM Evaluation](https://arxiv.org/abs/2508.20810)
*Jessica Lundin,Guillaume Chabot-Couture*

Main category: cs.AI

TL;DR: 本文提出了一种基于图的动态医学指南基准测试方法，能够系统评估模型在临床任务中的表现，并发现模型在分诊严重程度、治疗方案和随访护理方面的不足。该方法还为LLM的后训练提供了高奖励样本，解决了手动整理基准测试的覆盖限制。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试存在覆盖范围有限的问题，无法全面评估模型在临床任务中的表现。因此，需要一种系统化的方法来创建动态、全面的基准测试。

Method: 将WHO IMCI手册转换为有向图，包含200多个节点和300多个边，利用图遍历生成问题，涵盖年龄特定场景和上下文干扰项。

Result: 该方法在临床任务中实现了45-67%的准确率，模型在症状识别方面表现出色，但在分诊严重程度、治疗方案和随访护理方面存在困难。此外，该方法成功解决了手动整理基准测试的覆盖限制，并为LLM的后训练提供了高奖励样本。

Conclusion: 本文提出了一种动态、系统的医学指南基准测试原型，能够覆盖100%的指南关系，并通过图遍历生成具有临床相关性的题目。该方法有助于识别模型在分诊严重程度、治疗方案和随访护理方面的能力差距，并为LLM的后训练提供了高奖励样本。

Abstract: We present a first known prototype of a dynamic, systematic benchmark of
medical guidelines for 400+ questions, with 3.3+ trillion possible
combinations, covering 100\% of guideline relationships. We transformed the WHO
IMCI handbook into a directed graph with 200+ nodes (conditions, symptoms,
treatments, follow-ups, severities) and 300+ edges, then used graph traversal
to generate questions that incorporated age-specific scenarios and contextual
distractors to ensure clinical relevance. Our graph-based approach enables
systematic evaluation across clinical tasks (45-67\% accuracy), and we find
models excel at symptom recognition but struggle with triaging severity,
treatment protocols and follow-up care, demonstrating how customized benchmarks
can identify specific capability gaps that general-domain evaluations miss.
Beyond evaluation, this dynamic MCQA methodology enhances LLM post-training
(supervised finetuning, GRPO, DPO), where correct answers provide high-reward
samples without expensive human annotation. The graph-based approach
successfully addresses the coverage limitations of manually curated benchmarks.
This methodology is a step toward scalable, contamination-resistant solution
for creating comprehensive benchmarks that can be dynamically generated,
including when the guidelines are updated. Code and datasets are available at
https://github.com/jessicalundin/graph_testing_harness

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [68] [A Unified Theory of Language](https://arxiv.org/abs/2508.20109)
*Robert Worden*

Main category: q-bio.NC

TL;DR: 该理论提出语言是通过性选择进化的，结合了贝叶斯认知语言模型，使用构式语法解释语言的各个方面，并通过快速统一计算解决语用学问题。


<details>
  <summary>Details</summary>
Motivation: 该理论旨在解释语言的主要事实，包括其速度和表达力，以及语言多样性、语用学、句法和语义的数据。

Method: 该理论结合了贝叶斯认知语言模型和语言通过性选择进化的假设，使用构式语法来解释语言的句法和语义，并引入了语言语用和快速精确语言学习的新元素。

Result: 该理论通过快速统一计算所有语言方面（语音、句法、语义和语用学），解决了语用学的主要谜题和详细语用现象，并提供了进化连续性，将人类大脑的语言处理与动物大脑中的贝叶斯认知联系起来。

Conclusion: 语言是人类心智解读能力、合作、自尊和情感的基础，是人类文化和社会的基石。

Abstract: A unified theory of language combines a Bayesian cognitive linguistic model
of language processing, with the proposal that language evolved by sexual
selection for the display of intelligence. The theory accounts for the major
facts of language, including its speed and expressivity, and data on language
diversity, pragmatics, syntax and semantics. The computational element of the
theory is based on Construction Grammars. These give an account of the syntax
and semantics of the worlds languages, using constructions and unification. Two
novel elements are added to construction grammars: an account of language
pragmatics, and an account of fast, precise language learning. Constructions
are represented in the mind as graph like feature structures. People use slow
general inference to understand the first few examples they hear of any
construction. After that it is learned as a feature structure, and is rapidly
applied by unification. All aspects of language (phonology, syntax, semantics,
and pragmatics) are seamlessly computed by fast unification; there is no
boundary between semantics and pragmatics. This accounts for the major puzzles
of pragmatics, and for detailed pragmatic phenomena. Unification is Bayesian
maximum likelihood pattern matching. This gives evolutionary continuity between
language processing in the human brain, and Bayesian cognition in animal
brains. Language is the basis of our mind reading abilities, our cooperation,
self esteem and emotions; the foundations of human culture and society.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [69] [Leveraging Large Language Models for Generating Research Topic Ontologies: A Multi-Disciplinary Study](https://arxiv.org/abs/2508.20693)
*Tanay Aggarwal,Angelo Salatino,Francesco Osborne,Enrico Motta*

Main category: cs.DL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Ontologies and taxonomies of research fields are critical for managing and
organising scientific knowledge, as they facilitate efficient classification,
dissemination and retrieval of information. However, the creation and
maintenance of such ontologies are expensive and time-consuming tasks, usually
requiring the coordinated effort of multiple domain experts. Consequently,
ontologies in this space often exhibit uneven coverage across different
disciplines, limited inter-domain connectivity, and infrequent updating cycles.
In this study, we investigate the capability of several large language models
to identify semantic relationships among research topics within three academic
domains: biomedicine, physics, and engineering. The models were evaluated under
three distinct conditions: zero-shot prompting, chain-of-thought prompting, and
fine-tuning on existing ontologies. Additionally, we assessed the cross-domain
transferability of fine-tuned models by measuring their performance when
trained in one domain and subsequently applied to a different one. To support
this analysis, we introduce PEM-Rel-8K, a novel dataset consisting of over
8,000 relationships extracted from the most widely adopted taxonomies in the
three disciplines considered in this study: MeSH, PhySH, and IEEE. Our
experiments demonstrate that fine-tuning LLMs on PEM-Rel-8K yields excellent
performance across all disciplines.

</details>
